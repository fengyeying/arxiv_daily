<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri  1 Mar 24  to  Mon  4 Mar 24, announced Tue,  5 Mar 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item757">Cross-lists</a></li>
<li><a href="#item847">Replacements</a></li>
</ul>
<small>[ total of 1342 entries:  <b>1-1342</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue,  5 Mar 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00765" title="Abstract">arXiv:2403.00765</a> [<a href="/pdf/2403.00765" title="Download PDF">pdf</a>, <a href="/format/2403.00765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Architecture for Unattended Containerized (Deep) Reinforcement  Learning with Webots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haubold%2C+T">Tobias Haubold</a>, 
<a href="/search/cs?searchtype=author&query=Linke%2C+P">Petra Linke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Latex with llncs.cls, 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As data science applications gain adoption across industries, the tooling
landscape matures to facilitate the life cycle of such applications and provide
solutions to the challenges involved to boost the productivity of the people
involved. Reinforcement learning with agents in a 3D world could still face
challenges: the knowledge required to use a simulation software as well as the
utilization of a standalone simulation software in unattended training
pipelines.
<br />In this paper we review tools and approaches to train reinforcement learning
agents for robots in 3D worlds with respect to the robot Robotino and argue
that the separation of the simulation environment for creators of virtual
worlds and the model development environment for data scientists is not a well
covered topic. Often both are the same and data scientists require knowledge of
the simulation software to work directly with their APIs. Moreover, sometimes
creators of virtual worlds and data scientists even work on the same files. We
want to contribute to that topic by describing an approach where data
scientists don't require knowledge about the simulation software. Our approach
uses the standalone simulation software Webots, the Robot Operating System to
communicate with simulated robots as well as the simulation software itself and
container technology to separate the simulation from the model development
environment. We put emphasize on the APIs the data scientists work with and the
use of a standalone simulation software in unattended training pipelines. We
show the parts that are specific to the Robotino and the robot task to learn.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00766" title="Abstract">arXiv:2403.00766</a> [<a href="/pdf/2403.00766" title="Download PDF">pdf</a>, <a href="/format/2403.00766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fair and Firm Real-Time Scheduling in DNN Multi-Tenant  Multi-Accelerator Systems via Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Russo%2C+E">Enrico Russo</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+F+G">Francesco Giulio Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Palesi%2C+M">Maurizio Palesi</a>, 
<a href="/search/cs?searchtype=author&query=Ascia%2C+G">Giuseppe Ascia</a>, 
<a href="/search/cs?searchtype=author&query=Patti%2C+D">Davide Patti</a>, 
<a href="/search/cs?searchtype=author&query=Catania%2C+V">Vincenzo Catania</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper addresses the critical challenge of managing Quality of Service
(QoS) in cloud services, focusing on the nuances of individual tenant
expectations and varying Service Level Indicators (SLIs). It introduces a novel
approach utilizing Deep Reinforcement Learning for tenant-specific QoS
management in multi-tenant, multi-accelerator cloud environments. The chosen
SLI, deadline hit rate, allows clients to tailor QoS for each service request.
A novel online scheduling algorithm for Deep Neural Networks in
multi-accelerator systems is proposed, with a focus on guaranteeing
tenant-wise, model-specific QoS levels while considering real-time constraints.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00769" title="Abstract">arXiv:2403.00769</a> [<a href="/pdf/2403.00769" title="Download PDF">pdf</a>, <a href="/ps/2403.00769" title="Download PostScript">ps</a>, <a href="/format/2403.00769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text mining in education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira-Mello%2C+R">R. Ferreira-Mello</a>, 
<a href="/search/cs?searchtype=author&query=Andre%2C+M">M. Andre</a>, 
<a href="/search/cs?searchtype=author&query=Pinheiro%2C+A">A. Pinheiro</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+E">E. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+C">C. Romero</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Wiley Interdisciplinary Reviews: Data Mining and Knowledge
  Discovery (2019); 9(6):e1332
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The explosive growth of online education environments is generating a massive
volume of data, specially in text format from forums, chats, social networks,
assessments, essays, among others. It produces exciting challenges on how to
mine text data in order to find useful knowledge for educational stakeholders.
Despite the increasing number of educational applications of text mining
published recently, we have not found any paper surveying them. In this line,
this work presents a systematic overview of the current status of the
Educational Text Mining field. Our final goal is to answer three main research
questions: Which are the text mining techniques most used in educational
environments? Which are the most used educational resources? And which are the
main applications or educational goals? Finally, we outline the conclusions and
the more interesting future trends.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00773" title="Abstract">arXiv:2403.00773</a> [<a href="/pdf/2403.00773" title="Download PDF">pdf</a>, <a href="/format/2403.00773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misconduct in Post-Selections and Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Juyang Weng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, published in peer-viewed conference proceedings, Proc. 2023 the 8th International Conf. on Control, Robotics and Cybernetics (CRC 2023), pp. 1-9, IEEE Press, ISBN: 979-8-3503-3057-1, Changsha, China, Dec. 22-24, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This is a theoretical paper on "Deep Learning" misconduct in particular and
Post-Selection in general. As far as the author knows, the first peer-reviewed
papers on Deep Learning misconduct are [32], [37], [36]. Regardless of learning
modes, e.g., supervised, reinforcement, adversarial, and evolutional, almost
all machine learning methods (except for a few methods that train a sole
system) are rooted in the same misconduct -- cheating and hiding -- (1)
cheating in the absence of a test and (2) hiding bad-looking data. It was
reasoned in [32], [37], [36] that authors must report at least the average
error of all trained networks, good and bad, on the validation set (called
general cross-validation in this paper). Better, report also five percentage
positions of ranked errors. From the new analysis here, we can see that the
hidden culprit is Post-Selection. This is also true for Post-Selection on
hand-tuned or searched hyperparameters, because they are random, depending on
random observation data. Does cross-validation on data splits rescue
Post-Selections from the Misconducts (1) and (2)? The new result here says: No.
Specifically, this paper reveals that using cross-validation for data splits is
insufficient to exonerate Post-Selections in machine learning. In general,
Post-Selections of statistical learners based on their errors on the validation
set are statistically invalid.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00780" title="Abstract">arXiv:2403.00780</a> [<a href="/pdf/2403.00780" title="Download PDF">pdf</a>, <a href="/ps/2403.00780" title="Download PostScript">ps</a>, <a href="/format/2403.00780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical and Experimental Insights into Data Mining Techniques for  Crime Prediction: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taha%2C+K">Kamal Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This survey paper presents a comprehensive analysis of crime prediction
methodologies, exploring the various techniques and technologies utilized in
this area. The paper covers the statistical methods, machine learning
algorithms, and deep learning techniques employed to analyze crime data, while
also examining their effectiveness and limitations. We propose a methodological
taxonomy that classifies crime prediction algorithms into specific techniques.
This taxonomy is structured into four tiers, including methodology category,
methodology sub-category, methodology techniques, and methodology
sub-techniques. Empirical and experimental evaluations are provided to rank the
different techniques. The empirical evaluation assesses the crime prediction
techniques based on four criteria, while the experimental evaluation ranks the
algorithms that employ the same sub-technique, the different sub-techniques
that employ the same technique, the different techniques that employ the same
methodology sub-category, the different methodology sub-categories within the
same category, and the different methodology categories. The combination of
methodological taxonomy, empirical evaluations, and experimental comparisons
allows for a nuanced and comprehensive understanding of crime prediction
algorithms, aiding researchers in making informed decisions. Finally, the paper
provides a glimpse into the future of crime prediction techniques, highlighting
potential advancements and opportunities for further research in this field
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00781" title="Abstract">arXiv:2403.00781</a> [<a href="/pdf/2403.00781" title="Download PDF">pdf</a>, <a href="/format/2403.00781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender  Chatbots through an LLM-Augmented Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhongqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Khatibi%2C+E">Elahe Khatibi</a>, 
<a href="/search/cs?searchtype=author&query=Nagesh%2C+N">Nitish Nagesh</a>, 
<a href="/search/cs?searchtype=author&query=Abbasian%2C+M">Mahyar Abbasian</a>, 
<a href="/search/cs?searchtype=author&query=Azimi%2C+I">Iman Azimi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ramesh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+A+M">Amir M. Rahmani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The IEEE/ACM international conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">The profound impact of food on health necessitates advanced
nutrition-oriented food recommendation services. Conventional methods often
lack the crucial elements of personalization, explainability, and
interactivity. While Large Language Models (LLMs) bring interpretability and
explainability, their standalone use falls short of achieving true
personalization. In this paper, we introduce ChatDiet, a novel LLM-powered
framework designed specifically for personalized nutrition-oriented food
recommendation chatbots. ChatDiet integrates personal and population models,
complemented by an orchestrator, to seamlessly retrieve and process pertinent
information. The result is a dynamic delivery of personalized and explainable
food recommendations, tailored to individual user preferences. Our evaluation
of ChatDiet includes a compelling case study, where we establish a causal
personal model to estimate individual nutrition effects. Our assessments,
including a food recommendation test showcasing a 92\% effectiveness rate,
coupled with illustrative dialogue examples, underscore ChatDiet's strengths in
explainability, personalization, and interactivity.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00783" title="Abstract">arXiv:2403.00783</a> [<a href="/pdf/2403.00783" title="Download PDF">pdf</a>, <a href="/format/2403.00783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+H+H">Hankz Hankui Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Plan synthesis aims to generate a course of actions or policies to transit
given initial states to goal states, provided domain models that could be
designed by experts or learnt from training data or interactions with the
world. Intrigued by the claims of emergent planning capabilities in large
language models (LLMs), works have been proposed to investigate the planning
effectiveness of LLMs, without considering any utilization of off-the-shelf
planning techniques in LLMs. In this paper, we aim to further study the insight
of the planning capability of LLMs by investigating the roles of LLMs in
off-the-shelf planning frameworks. To do this, we investigate the effectiveness
of embedding LLMs into one of the well-known planning frameworks, graph-based
planning, proposing a novel LLMs-based planning framework with LLMs embedded in
two levels of planning graphs, i.e., mutual constraints generation level and
constraints solving level. We empirically exhibit the effectiveness of our
proposed framework in various planning domains.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00784" title="Abstract">arXiv:2403.00784</a> [<a href="/pdf/2403.00784" title="Download PDF">pdf</a>, <a href="/format/2403.00784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing BERT for Information Retrieval: Survey, Applications,  Resources, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiajia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J+X">Jimmy X. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xinhui Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junmei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+A+J">Angela J. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Bhuiyan%2C+A">Amran Bhuiyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent years have witnessed a substantial increase in the use of deep
learning to solve various natural language processing (NLP) problems. Early
deep learning models were constrained by their sequential or unidirectional
nature, such that they struggled to capture the contextual relationships across
text inputs. The introduction of bidirectional encoder representations from
transformers (BERT) leads to a robust encoder for the transformer model that
can understand the broader context and deliver state-of-the-art performance
across various NLP tasks. This has inspired researchers and practitioners to
apply BERT to practical problems, such as information retrieval (IR). A survey
that focuses on a comprehensive analysis of prevalent approaches that apply
pretrained transformer encoders like BERT to IR can thus be useful for academia
and the industry. In light of this, we revisit a variety of BERT-based methods
in this survey, cover a wide range of techniques of IR, and group them into six
high-level categories: (i) handling long documents, (ii) integrating semantic
information, (iii) balancing effectiveness and efficiency, (iv) predicting the
weights of terms, (v) query expansion, and (vi) document expansion. We also
provide links to resources, including datasets and toolkits, for BERT-based IR
systems. A key highlight of our survey is the comparison between BERT's
encoder-based models and the latest generative Large Language Models (LLMs),
such as ChatGPT, which rely on decoders. Despite the popularity of LLMs, we
find that for specific tasks, finely tuned BERT encoders still outperform, and
at a lower deployment cost. Finally, we summarize the comprehensive outcomes of
the survey and suggest directions for future research in the area.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00786" title="Abstract">arXiv:2403.00786</a> [<a href="/pdf/2403.00786" title="Download PDF">pdf</a>, <a href="/format/2403.00786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Contrastive Learning for Few-shot Geolocation of Social Posts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Menglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+K+H">Kwan Hui Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper contains 7-page main content and 2-page references and was submitted to IJCAI2024 for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Social geolocation is an important problem of predicting the originating
locations of social media posts. However, this task is challenging due to the
need for a substantial volume of training data, alongside well-annotated
labels. These issues are further exacerbated by new or less popular locations
with insufficient labels, further leading to an imbalanced dataset. In this
paper, we propose \textbf{ContrastGeo}, a \textbf{Contrast}ive learning
enhanced framework for few-shot social \textbf{Geo}location. Specifically, a
Tweet-Location Contrastive learning objective is introduced to align
representations of tweets and locations within tweet-location pairs. To capture
the correlations between tweets and locations, a Tweet-Location Matching
objective is further adopted into the framework and refined via an online hard
negative mining approach. We also develop three fusion strategies with various
fusion encoders to better generate joint representations of tweets and
locations. Comprehensive experiments on three social media datasets highlight
ContrastGeo's superior performance over several state-of-the-art baselines in
few-shot social geolocation.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00787" title="Abstract">arXiv:2403.00787</a> [<a href="/pdf/2403.00787" title="Download PDF">pdf</a>, <a href="/format/2403.00787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reusable MLOps: Reusable Deployment, Reusable Infrastructure and  Hot-Swappable Machine Learning models and services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panchal%2C+D">D Panchal</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+P">P Verma</a>, 
<a href="/search/cs?searchtype=author&query=Baran%2C+I">I Baran</a>, 
<a href="/search/cs?searchtype=author&query=Musgrove%2C+D">D Musgrove</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">D Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Although Machine Learning model building has become increasingly accessible
due to a plethora of tools, libraries and algorithms being available freely,
easy operationalization of these models is still a problem. It requires
considerable expertise in data engineering, software development, cloud and
DevOps. It also requires planning, agreement, and vision of how the model is
going to be used by the business applications once it is in production, how it
is going to be continuously trained on fresh incoming data, and how and when a
newer model would replace an existing model. This leads to developers and data
scientists working in silos and making suboptimal decisions. It also leads to
wasted time and effort. We introduce the Acumos AI platform we developed and we
demonstrate some unique novel capabilities that the Acumos model runner
possesses, that can help solve the above problems. We introduce a new
sustainable concept in the field of AI/ML operations - called Reusable MLOps -
where we reuse the existing deployment and infrastructure to serve new models
by hot-swapping them without tearing down the infrastructure or the
microservice, thus achieving reusable deployment and operations for AI/ML
models while still having continuously trained models in production.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00788" title="Abstract">arXiv:2403.00788</a> [<a href="/pdf/2403.00788" title="Download PDF">pdf</a>, <a href="/ps/2403.00788" title="Download PostScript">ps</a>, <a href="/format/2403.00788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRECISE Framework: GPT-based Text For Improved Readability, Reliability,  and Understandability of Radiology Reports For Patient-Centered Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+S">Satvik Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+L">Liam Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Muppuri%2C+M">Meghana Muppuri</a>, 
<a href="/search/cs?searchtype=author&query=Dheer%2C+S">Suhani Dheer</a>, 
<a href="/search/cs?searchtype=author&query=Garza-Frias%2C+E">Emiliano Garza-Frias</a>, 
<a href="/search/cs?searchtype=author&query=Awan%2C+K">Komal Awan</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Aakash Jha</a>, 
<a href="/search/cs?searchtype=author&query=Dezube%2C+M">Michael Dezube</a>, 
<a href="/search/cs?searchtype=author&query=Tabari%2C+A">Azadeh Tabari</a>, 
<a href="/search/cs?searchtype=author&query=Bridge%2C+C+P">Christopher P. Bridge</a>, 
<a href="/search/cs?searchtype=author&query=Daye%2C+D">Dania Daye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study introduces and evaluates the PRECISE framework, utilizing OpenAI's
GPT-4 to enhance patient engagement by providing clearer and more accessible
chest X-ray reports at a sixth-grade reading level. The framework was tested on
500 reports, demonstrating significant improvements in readability,
reliability, and understandability. Statistical analyses confirmed the
effectiveness of the PRECISE approach, highlighting its potential to foster
patient-centric care delivery in healthcare decision-making.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00790" title="Abstract">arXiv:2403.00790</a> [<a href="/pdf/2403.00790" title="Download PDF">pdf</a>, <a href="/ps/2403.00790" title="Download PostScript">ps</a>, <a href="/format/2403.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structuring Concept Space with the Musical Circle of Fifths by Utilizing  Music Grammar Based Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moyo%2C+T">Tofara Moyo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we explore the intriguing similarities between the structure
of a discrete neural network, such as a spiking network, and the composition of
a piano piece. While both involve nodes or notes that are activated
sequentially or in parallel, the latter benefits from the rich body of music
theory to guide meaningful combinations. We propose a novel approach that
leverages musical grammar to regulate activations in a spiking neural network,
allowing for the representation of symbols as attractors. By applying rules for
chord progressions from music theory, we demonstrate how certain activations
naturally follow others, akin to the concept of attraction. Furthermore, we
introduce the concept of modulating keys to navigate different basins of
attraction within the network. Ultimately, we show that the map of concepts in
our model is structured by the musical circle of fifths, highlighting the
potential for leveraging music theory principles in deep learning algorithms.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00791" title="Abstract">arXiv:2403.00791</a> [<a href="/pdf/2403.00791" title="Download PDF">pdf</a>, <a href="/format/2403.00791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL  2024
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edwards%2C+C">Carl Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lawrence Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The dataset, finetuned baselines, and evaluation code are released publicly at <a href="https://github.com/language-plus-molecules/LPM-24-Dataset">this https URL</a> through <a href="https://huggingface.co/language-plus-molecules">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Language-molecule models have emerged as an exciting direction for molecular
discovery and understanding. However, training these models is challenging due
to the scarcity of molecule-language pair datasets. At this point, datasets
have been released which are 1) small and scraped from existing databases, 2)
large but noisy and constructed by performing entity linking on the scientific
literature, and 3) built by converting property prediction datasets to natural
language using templates. In this document, we detail the $\textit{L+M-24}$
dataset, which has been created for the Language + Molecules Workshop shared
task at ACL 2024. In particular, $\textit{L+M-24}$ is designed to focus on
three key benefits of natural language in molecule design: compositionality,
functionality, and abstraction.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00792" title="Abstract">arXiv:2403.00792</a> [<a href="/pdf/2403.00792" title="Download PDF">pdf</a>, <a href="/format/2403.00792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory and Computation of Substructure Characteristic Modes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+M">Mats Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Jelinek%2C+L">Lukas Jelinek</a>, 
<a href="/search/cs?searchtype=author&query=Capek%2C+M">Miloslav Capek</a>, 
<a href="/search/cs?searchtype=author&query=Lundgren%2C+J">Johan Lundgren</a>, 
<a href="/search/cs?searchtype=author&query=Schab%2C+K">Kurt Schab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The problem of substructure characteristic modes is reformulated using a
scattering matrix-based formulation, generalizing subregion characteristic mode
decomposition to arbitrary computational tools. It is shown that the scattering
formulation is identical to the classical formulation based on the background
Green's function for lossless systems. The scattering formulation, however,
opens a variety of new subregion scenarios unavailable within previous
formulations, including cases with lumped or wave ports or subregions in
circuits. Thanks to its scattering nature, the formulation is solver-agnostic
with the possibility to utilize an arbitrary full-wave method.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00793" title="Abstract">arXiv:2403.00793</a> [<a href="/pdf/2403.00793" title="Download PDF">pdf</a>, <a href="/format/2403.00793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ad Recommendation in a Collapsed and Entangled World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junwei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Ximei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haibin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+S">Shijie Quan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xueming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dapeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we present an industry ad recommendation system, paying
attention to the challenges and practices of learning appropriate
representations. Our study begins by showcasing our approaches to preserving
priors when encoding features of diverse types into embedding representations.
Specifically, we address sequence features, numeric features, pre-trained
embedding features, as well as sparse ID features. Moreover, we delve into two
pivotal challenges associated with feature representation: the dimensional
collapse of embeddings and the interest entanglement across various tasks or
scenarios. Subsequently, we propose several practical approaches to effectively
tackle these two challenges. We then explore several training techniques to
facilitate model optimization, reduce bias, and enhance exploration.
Furthermore, we introduce three analysis tools that enable us to
comprehensively study feature correlation, dimensional collapse, and interest
entanglement. This work builds upon the continuous efforts of Tencent's ads
recommendation team in the last decade. It not only summarizes general design
principles but also presents a series of off-the-shelf solutions and analysis
tools. The reported performance is based on our online advertising platform,
which handles hundreds of billions of requests daily, serving millions of ads
to billions of users.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00794" title="Abstract">arXiv:2403.00794</a> [<a href="/pdf/2403.00794" title="Download PDF">pdf</a>, <a href="/format/2403.00794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+Z">Zachary Horvitz</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Aditya%2C+R">Rahul Aditya</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+H">Harshvardhan Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+K">Kathleen McKeown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Humor is a fundamental facet of human cognition and interaction. Yet, despite
recent advances in natural language processing, humor detection remains a
challenging task that is complicated by the scarcity of datasets that pair
humorous texts with similar non-humorous counterparts. In our work, we
investigate whether large language models (LLMs), can generate synthetic data
for humor detection via editing texts. We benchmark LLMs on an existing human
dataset and show that current LLMs display an impressive ability to `unfun'
jokes, as judged by humans and as measured on the downstream task of humor
detection. We extend our approach to a code-mixed English-Hindi humor dataset,
where we find that GPT-4's synthetic data is highly rated by bilingual
annotators and provides challenging adversarial examples for humor classifiers.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00795" title="Abstract">arXiv:2403.00795</a> [<a href="/pdf/2403.00795" title="Download PDF">pdf</a>, <a href="/ps/2403.00795" title="Download PostScript">ps</a>, <a href="/format/2403.00795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Executing Natural Language-Described Algorithms with Large Language  Models: An Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qiming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaojie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Executing computer programs described in natural language has long been a
pursuit of computer science. With the advent of enhanced natural language
understanding capabilities exhibited by large language models (LLMs), the path
toward this goal has been illuminated. In this paper, we seek to examine the
capacity of present-day LLMs to comprehend and execute algorithms outlined in
natural language. We established an algorithm test set sourced from
Introduction to Algorithm, a well-known textbook that contains many
representative widely-used algorithms. To systematically assess LLMs' code
execution abilities, we selected 30 algorithms, generated 300 random-sampled
instances in total, and evaluated whether popular LLMs can understand and
execute these algorithms. Our findings reveal that LLMs, notably GPT-4, can
effectively execute programs described in natural language, as long as no heavy
numeric computation is involved. We believe our findings contribute to
evaluating LLMs' code execution abilities and would encourage further
investigation and application for the computation power of LLMs.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00798" title="Abstract">arXiv:2403.00798</a> [<a href="/pdf/2403.00798" title="Download PDF">pdf</a>, <a href="/format/2403.00798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helen: Optimizing CTR Prediction Models with Frequency-wise Hessian  Eigenvalue Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zirui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zangwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the ACM Web Conference 2024 (WWW '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Click-Through Rate (CTR) prediction holds paramount significance in online
advertising and recommendation scenarios. Despite the proliferation of recent
CTR prediction models, the improvements in performance have remained limited,
as evidenced by open-source benchmark assessments. Current researchers tend to
focus on developing new models for various datasets and settings, often
neglecting a crucial question: What is the key challenge that truly makes CTR
prediction so demanding?
<br />In this paper, we approach the problem of CTR prediction from an optimization
perspective. We explore the typical data characteristics and optimization
statistics of CTR prediction, revealing a strong positive correlation between
the top hessian eigenvalue and feature frequency. This correlation implies that
frequently occurring features tend to converge towards sharp local minima,
ultimately leading to suboptimal performance. Motivated by the recent
advancements in sharpness-aware minimization (SAM), which considers the
geometric aspects of the loss landscape during optimization, we present a
dedicated optimizer crafted for CTR prediction, named Helen. Helen incorporates
frequency-wise Hessian eigenvalue regularization, achieved through adaptive
perturbations based on normalized feature frequencies.
<br />Empirical results under the open-source benchmark framework underscore
Helen's effectiveness. It successfully constrains the top eigenvalue of the
Hessian matrix and demonstrates a clear advantage over widely used optimization
algorithms when applied to seven popular models across three public benchmark
datasets on BARS. Our code locates at github.com/NUS-HPC-AI-Lab/Helen.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00799" title="Abstract">arXiv:2403.00799</a> [<a href="/pdf/2403.00799" title="Download PDF">pdf</a>, <a href="/format/2403.00799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Data Ability Boundary in LLMs&#x27; Math Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yezeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiaqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Ji Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are displaying emergent abilities for math
reasoning tasks,and there is a growing attention on enhancing the ability of
open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to
explore a general data strategy for supervised data to help optimize and expand
math reasoning ability.Firstly, we determine the ability boundary of reasoning
paths augmentation by identifying these paths' minimal optimal set.Secondly, we
validate that different abilities of the model can be cumulatively enhanced by
Mix of Minimal Optimal Sets of corresponding types of data, while our models
MMOS achieve SOTA performance on series base models under much lower
construction costs.Besides, we point out GSM-HARD is not really hard and
today's LLMs no longer lack numerical robustness.Also, we provide an Auto
Problem Generator for robustness testing and educational applications.Our code
and data are publicly available at https://github.com/cyzhh/MMOS.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00800" title="Abstract">arXiv:2403.00800</a> [<a href="/pdf/2403.00800" title="Download PDF">pdf</a>, <a href="/format/2403.00800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by  Imitating Human Thought Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yezeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although large language models demonstrate emergent abilities in solving math
word problems, there is a challenging task in complex multi-step mathematical
reasoning tasks. To improve model performance on mathematical reasoning tasks,
previous work has conducted supervised fine-tuning on open-source models by
improving the quality and quantity of data. In this paper, we propose a novel
approach, named Brain, to imitate human thought processes to enhance
mathematical reasoning abilities, using the Frontal Lobe Model to generate
plans, and then employing the Parietal Lobe Model to generate code and execute
to obtain answers. First, we achieve SOTA performance in comparison with Code
LLaMA 7B based models through this method. Secondly, we find that plans can be
explicitly extracted from natural language, code, or formal language. Our code
and data are publicly available at https://github.com/cyzhh/Brain.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00801" title="Abstract">arXiv:2403.00801</a> [<a href="/pdf/2403.00801" title="Download PDF">pdf</a>, <a href="/format/2403.00801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Retrieval: Building an Information Retrieval System with One Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiaoyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaojie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Cheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Ben He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The rise of large language models (LLMs) has transformed the role of
information retrieval (IR) systems in the way to humans accessing information.
Due to the isolated architecture and the limited interaction, existing IR
systems are unable to fully accommodate the shift from directly providing
information to humans to indirectly serving large language models. In this
paper, we propose Self-Retrieval, an end-to-end, LLM-driven information
retrieval architecture that can fully internalize the required abilities of IR
systems into a single LLM and deeply leverage the capabilities of LLMs during
IR process. Specifically, Self-retrieval internalizes the corpus to retrieve
into a LLM via a natural language indexing architecture. Then the entire
retrieval process is redefined as a procedure of document generation and
self-assessment, which can be end-to-end executed using a single large language
model. Experimental results demonstrate that Self-Retrieval not only
significantly outperforms previous retrieval approaches by a large margin, but
also can significantly boost the performance of LLM-driven downstream
applications like retrieval augumented generation.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00802" title="Abstract">arXiv:2403.00802</a> [<a href="/pdf/2403.00802" title="Download PDF">pdf</a>, <a href="/format/2403.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Theoretical Understanding of Two-Stage Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+A+K">Amit Kumar Jaiswal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages (including references and appendix), 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Production-grade recommender systems rely heavily on a large-scale corpus
used by online media services, including Netflix, Pinterest, and Amazon. These
systems enrich recommendations by learning users' and items' embeddings
projected in a low-dimensional space with two-stage models (two deep neural
networks), which facilitate their embedding constructs to predict users'
feedback associated with items. Despite its popularity for recommendations, its
theoretical behaviors remain comprehensively unexplored. We study the
asymptotic behaviors of the two-stage recommender that entail a strong
convergence to the optimal recommender system. We establish certain theoretical
properties and statistical assurance of the two-stage recommender. In addition
to asymptotic behaviors, we demonstrate that the two-stage recommender system
attains faster convergence by relying on the intrinsic dimensions of the input
features. Finally, we show numerically that the two-stage recommender enables
encapsulating the impacts of items' and users' attributes on ratings, resulting
in better performance compared to existing methods conducted using synthetic
and real-world data experiments.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00803" title="Abstract">arXiv:2403.00803</a> [<a href="/pdf/2403.00803" title="Download PDF">pdf</a>, <a href="/format/2403.00803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiMAML: Personalization of Deep Recommender Models via Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+P">Prakruthi Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+G">Gaurav Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jalali%2C+Z+S">Zeinab S. Jalali</a>, 
<a href="/search/cs?searchtype=author&query=Bharill%2C+V">Varun Bharill</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+Y">Yunbo Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Nigam%2C+A">Aastha Nigam</a>, 
<a href="/search/cs?searchtype=author&query=Venugopalan%2C+D">Divya Venugopalan</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aman Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Borisyuk%2C+F">Fedor Borisyuk</a>, 
<a href="/search/cs?searchtype=author&query=Keerthi%2C+S">Sathiya Keerthi</a>, 
<a href="/search/cs?searchtype=author&query=Muralidharan%2C+A">Ajith Muralidharan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of recommender systems, the ubiquitous adoption of deep neural
networks has emerged as a dominant paradigm for modeling diverse business
objectives. As user bases continue to expand, the necessity of personalization
and frequent model updates have assumed paramount significance to ensure the
delivery of relevant and refreshed experiences to a diverse array of members.
In this work, we introduce an innovative meta-learning solution tailored to the
personalization of models for individual members and other entities, coupled
with the frequent updates based on the latest user interaction signals.
Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to
adapt per-task sub-networks using recent user interaction data. Given the near
infeasibility of productionizing original MAML-based models in online
recommendation systems, we propose an efficient strategy to operationalize
meta-learned sub-networks in production, which involves transforming them into
fixed-sized vectors, termed meta embeddings, thereby enabling the seamless
deployment of models with hundreds of billions of parameters for online
serving. Through extensive experimentation on production data drawn from
various applications at LinkedIn, we demonstrate that the proposed solution
consistently outperforms the baseline models of those applications, including
strong baselines such as using wide-and-deep ID based personalization approach.
Our approach has enabled the deployment of a range of highly personalized AI
models across diverse LinkedIn applications, leading to substantial
improvements in business metrics as well as refreshed experience for our
members.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00804" title="Abstract">arXiv:2403.00804</a> [<a href="/pdf/2403.00804" title="Download PDF">pdf</a>, <a href="/format/2403.00804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Customer Issues through Topological Natural Language Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pi%2C+S">Shu-Ting Pi</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Sidarth Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuying Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Michael Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in KDD 2023 Workshop on Decision Intelligence and Analytics for Online Marketplaces
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">E-commerce companies deal with a high volume of customer service requests
daily. While a simple annotation system is often used to summarize the topics
of customer contacts, thoroughly exploring each specific issue can be
challenging. This presents a critical concern, especially during an emerging
outbreak where companies must quickly identify and address specific issues. To
tackle this challenge, we propose a novel machine learning algorithm that
leverages natural language techniques and topological data analysis to monitor
emerging and trending customer issues. Our approach involves an end-to-end deep
learning framework that simultaneously tags the primary question sentence of
each customer's transcript and generates sentence embedding vectors. We then
whiten the embedding vectors and use them to construct an undirected graph.
From there, we define trending and emerging issues based on the topological
properties of each transcript. We have validated our results through various
methods and found that they are highly consistent with news sources.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00805" title="Abstract">arXiv:2403.00805</a> [<a href="/pdf/2403.00805" title="Download PDF">pdf</a>, <a href="/ps/2403.00805" title="Download PostScript">ps</a>, <a href="/format/2403.00805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Dynamic Distributed Planning Approach: Application to DPDP  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tolba%2C+Z">Zakaria Tolba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's thesis, in French language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this work, we proposed a new dynamic distributed planning approach that is
able to take into account the changes that the agent introduces on his set of
actions to be planned in order to take into account the changes that occur in
his environment. Our approach fits into the context of distributed planning for
distributed plans where each agent can produce its own plans. According to our
approach the generation of the plans is based on the satisfaction of the
constraints by the use of the genetic algorithms. Our approach is to generate,
a new plan by each agent, whenever there is a change in its set of actions to
plan. This in order to take into account the new actions introduced in its new
plan. In this new plan, the agent takes, each time, as a new action set to plan
all the old un-executed actions of the old plan and the new actions engendered
by the changes and as a new initial state; the state in which the set of
actions of the agent undergoes a change. In our work, we used a concrete case
to illustrate and demonstrate the utility of our approach.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00806" title="Abstract">arXiv:2403.00806</a> [<a href="/pdf/2403.00806" title="Download PDF">pdf</a>, <a href="/ps/2403.00806" title="Download PostScript">ps</a>, <a href="/format/2403.00806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced User Interaction in Operating Systems through Machine Learning  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenran Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+C">Chunhe Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the large language model showing human-like logical reasoning and
understanding ability, whether agents based on the large language model can
simulate the interaction behavior of real users, so as to build a reliable
virtual recommendation A/B test scene to help the application of recommendation
research is an urgent, important and economic value problem. The combination of
interaction design and machine learning can provide a more efficient and
personalized user experience for products and services. This personalized
service can meet the specific needs of users and improve user satisfaction and
loyalty. Second, the interactive system can understand the user's views and
needs for the product by providing a good user interface and interactive
experience, and then use machine learning algorithms to improve and optimize
the product. This iterative optimization process can continuously improve the
quality and performance of the product to meet the changing needs of users. At
the same time, designers need to consider how these algorithms and tools can be
combined with interactive systems to provide a good user experience. This paper
explores the potential applications of large language models, machine learning
and interaction design for user interaction in recommendation systems and
operating systems. By integrating these technologies, more intelligent and
personalized services can be provided to meet user needs and promote continuous
improvement and optimization of products. This is of great value for both
recommendation research and user experience applications.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00807" title="Abstract">arXiv:2403.00807</a> [<a href="/pdf/2403.00807" title="Download PDF">pdf</a>, <a href="/ps/2403.00807" title="Download PostScript">ps</a>, <a href="/format/2403.00807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Cloud-Based Large Language Model Processing with Elasticsearch  and Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+C">Chunhe Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenran Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Digital Libraries (cs.DL)

</div>
<p class="mathjax">Large Language Models (LLMs) are a class of generative AI models built using
the Transformer network, capable of leveraging vast datasets to identify,
summarize, translate, predict, and generate language. LLMs promise to
revolutionize society, yet training these foundational models poses immense
challenges. Semantic vector search within large language models is a potent
technique that can significantly enhance search result accuracy and relevance.
Unlike traditional keyword-based search methods, semantic search utilizes the
meaning and context of words to grasp the intent behind queries and deliver
more precise outcomes. Elasticsearch emerges as one of the most popular tools
for implementing semantic search an exceptionally scalable and robust search
engine designed for indexing and searching extensive datasets. In this article,
we delve into the fundamentals of semantic search and explore how to harness
Elasticsearch and Transformer models to bolster large language model processing
paradigms. We gain a comprehensive understanding of semantic search principles
and acquire practical skills for implementing semantic search in real-world
model application scenarios.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00808" title="Abstract">arXiv:2403.00808</a> [<a href="/pdf/2403.00808" title="Download PDF">pdf</a>, <a href="/format/2403.00808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPED: An Implicit Perspective for Relational Triple Extraction based on  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, committed to NAACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Relational triple extraction is a fundamental task in the field of
information extraction, and a promising framework based on table filling has
recently gained attention as a potential baseline for entity relation
extraction. However, inherent shortcomings such as redundant information and
incomplete triple recognition remain problematic. To address these challenges,
we propose an Implicit Perspective for relational triple Extraction based on
Diffusion model (IPED), an innovative approach for extracting relational
triples. Our classifier-free solution adopts an implicit strategy using block
coverage to complete the tables, avoiding the limitations of explicit tagging
methods. Additionally, we introduce a generative model structure, the
block-denoising diffusion model, to collaborate with our implicit perspective
and effectively circumvent redundant information disruptions. Experimental
results on two popular datasets demonstrate that IPED achieves state-of-the-art
performance while gaining superior inference speed and low computational
complexity. To support future research, we have made our source code publicly
available online.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00809" title="Abstract">arXiv:2403.00809</a> [<a href="/pdf/2403.00809" title="Download PDF">pdf</a>, <a href="/format/2403.00809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of  Dedicated Models Versus ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelious%2C+A">Abdelhak Kelious</a>, 
<a href="/search/cs?searchtype=author&query=Okirim%2C+M">Mounir Okirim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study introduces a dedicated model aimed at solving the BRAINTEASER task
9 , a novel challenge designed to assess models lateral thinking capabilities
through sentence and word puzzles. Our model demonstrates remarkable efficacy,
securing Rank 1 in sentence puzzle solving during the test phase with an
overall score of 0.98. Additionally, we explore the comparative performance of
ChatGPT, specifically analyzing how variations in temperature settings affect
its ability to engage in lateral thinking and problem-solving. Our findings
indicate a notable performance disparity between the dedicated model and
ChatGPT, underscoring the potential of specialized approaches in enhancing
creative reasoning in AI.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00810" title="Abstract">arXiv:2403.00810</a> [<a href="/pdf/2403.00810" title="Download PDF">pdf</a>, <a href="/format/2403.00810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Cognitive Agents with a Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Simmons%2C+R">Reid Simmons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models contain noisy general knowledge of the world, yet are
hard to train or fine-tune. On the other hand cognitive architectures have
excellent interpretability and are flexible to update but require a lot of
manual work to instantiate. In this work, we combine the best of both worlds:
bootstrapping a cognitive-based model with the noisy knowledge encoded in large
language models. Through an embodied agent doing kitchen tasks, we show that
our proposed framework yields better efficiency compared to an agent based
entirely on large language models. Our experiments indicate that large language
models are a good source of information for cognitive architectures, and the
cognitive architecture in turn can verify and update the knowledge of large
language models to a specific domain.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00811" title="Abstract">arXiv:2403.00811</a> [<a href="/pdf/2403.00811" title="Download PDF">pdf</a>, <a href="/format/2403.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Bias in High-Stakes Decision-Making with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echterhoff%2C+J">Jessica Echterhoff</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Alessa%2C+A">Abeer Alessa</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zexue He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) offer significant potential as tools to support
an expanding range of decision-making tasks. However, given their training on
human (created) data, LLMs can inherit both societal biases against protected
groups, as well as be subject to cognitive bias. Such human-like bias can
impede fair and explainable decisions made with LLM assistance. Our work
introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate
cognitive bias in LLMs, particularly in high-stakes decision-making tasks.
Inspired by prior research in psychology and cognitive sciences, we develop a
dataset containing 16,800 prompts to evaluate different cognitive biases (e.g.,
prompt-induced, sequential, inherent). We test various bias mitigation
strategies, amidst proposing a novel method using LLMs to debias their own
prompts. Our analysis provides a comprehensive picture on the presence and
effects of cognitive bias across different commercial and open-source models.
We demonstrate that our self-help debiasing effectively mitigate cognitive bias
without having to manually craft examples for each bias type.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00812" title="Abstract">arXiv:2403.00812</a> [<a href="/pdf/2403.00812" title="Download PDF">pdf</a>, <a href="/format/2403.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoRA Meets Dropout under a Unified Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiyue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Boyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the remarkable capabilities, large language models (LLMs) have emerged
as essential elements in numerous NLP applications, while parameter-efficient
finetuning, especially LoRA, has gained popularity as a lightweight approach
for model customization. Meanwhile, various dropout methods, initially designed
for full finetuning with all the parameters updated, alleviates overfitting
associated with excessive parameter redundancy. Hence, a possible contradiction
arises from negligible trainable parameters of LoRA and the effectiveness of
previous dropout methods, which has been largely overlooked. To fill this gap,
we first confirm that parameter-efficient LoRA is also overfitting-prone. We
then revisit transformer-specific dropout methods, and establish their
equivalence and distinctions mathematically and empirically. Building upon this
comparative analysis, we introduce a unified framework for a comprehensive
investigation, which instantiates these methods based on dropping position,
structural pattern and compensation measure. Through this framework, we reveal
the new preferences and performance comparisons of them when involved with
limited trainable parameters. This framework also allows us to amalgamate the
most favorable aspects into a novel dropout method named HiddenKey. Extensive
experiments verify the remarkable superiority and sufficiency of HiddenKey
across multiple models and tasks, which highlights it as the preferred approach
for high-performance and parameter-efficient finetuning of LLMs.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00813" title="Abstract">arXiv:2403.00813</a> [<a href="/pdf/2403.00813" title="Download PDF">pdf</a>, <a href="/format/2403.00813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UrbanGPT: Spatio-Temporal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhonghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiabin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Long Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Spatio-temporal prediction aims to forecast and gain insights into the
ever-changing dynamics of urban environments across both time and space. Its
purpose is to anticipate future patterns, trends, and events in diverse facets
of urban life, including transportation, population movement, and crime rates.
Although numerous efforts have been dedicated to developing neural network
techniques for accurate predictions on spatio-temporal data, it is important to
note that many of these methods heavily depend on having sufficient labeled
data to generate precise spatio-temporal representations. Unfortunately, the
issue of data scarcity is pervasive in practical urban sensing scenarios.
Consequently, it becomes necessary to build a spatio-temporal model with strong
generalization capabilities across diverse spatio-temporal learning scenarios.
Taking inspiration from the remarkable achievements of large language models
(LLMs), our objective is to create a spatio-temporal LLM that can exhibit
exceptional generalization capabilities across a wide range of downstream urban
tasks. To achieve this objective, we present the UrbanGPT, which seamlessly
integrates a spatio-temporal dependency encoder with the instruction-tuning
paradigm. This integration enables LLMs to comprehend the complex
inter-dependencies across time and space, facilitating more comprehensive and
accurate predictions under data scarcity. To validate the effectiveness of our
approach, we conduct extensive experiments on various public datasets, covering
different spatio-temporal prediction tasks. The results consistently
demonstrate that our UrbanGPT, with its carefully designed architecture,
consistently outperforms state-of-the-art baselines. These findings highlight
the potential of building large language models for spatio-temporal learning,
particularly in zero-shot scenarios where labeled data is scarce.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00814" title="Abstract">arXiv:2403.00814</a> [<a href="/pdf/2403.00814" title="Download PDF">pdf</a>, <a href="/ps/2403.00814" title="Download PostScript">ps</a>, <a href="/format/2403.00814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gender Biased Legal Case Retrieval System on Users&#x27; Decision Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yueyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beining Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10pages, in Chinese language. Accepted by CCIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In the last decade, legal case search has become an important part of a legal
practitioner's work. During legal case search, search engines retrieval a
number of relevant cases from huge amounts of data and serve them to users.
However, it is uncertain whether these cases are gender-biased and whether such
bias has impact on user perceptions. We designed a new user experiment
framework to simulate the judges' reading of relevant cases. 72 participants
with backgrounds in legal affairs invited to conduct the experiment.
Participants were asked to simulate the role of the judge in conducting a legal
case search on 3 assigned cases and determine the sentences of the defendants
in these cases. Gender of the defendants in both the task and relevant cases
was edited to statistically measure the effect of gender bias in the legal case
search results on participants' perceptions. The results showed that gender
bias in the legal case search results did not have a significant effect on
judges' perceptions.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00815" title="Abstract">arXiv:2403.00815</a> [<a href="/pdf/2403.00815" title="Download PDF">pdf</a>, <a href="/format/2403.00815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic  Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenqi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuchen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Bowen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+D">May D. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+J+C">Joyce C. Ho</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Other Quantitative Biology (q-bio.OT)

</div>
<p class="mathjax">We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical
predictions on Electronic Health Records (EHRs). RAM-EHR first collects
multiple knowledge sources, converts them into text format, and uses dense
retrieval to obtain information related to medical concepts. This strategy
addresses the difficulties associated with complex names for the concepts.
RAM-EHR then augments the local EHR predictive model co-trained with
consistency regularization to capture complementary information from patient
visits and summarized knowledge. Experiments on two EHR datasets show the
efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in
AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized
knowledge from RAM-EHR for clinical prediction tasks. The code will be
published at \url{https://github.com/ritaranx/RAM-EHR}.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00816" title="Abstract">arXiv:2403.00816</a> [<a href="/pdf/2403.00816" title="Download PDF">pdf</a>, <a href="/format/2403.00816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document  Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yongqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Document Visual Question Answering (DVQA) is a task that involves responding
to queries based on the content of images. Existing work is limited to locating
information within a single page and does not facilitate cross-page
question-and-answer interaction. Furthermore, the token length limitation
imposed on inputs to the model may lead to truncation of segments pertinent to
the answer. In this study, we introduce a simple but effective methodology
called CFRet-DVQA, which focuses on retrieval and efficient tuning to address
this critical issue effectively. For that, we initially retrieve multiple
segments from the document that correlate with the question at hand.
Subsequently, we leverage the advanced reasoning abilities of the large
language model (LLM), further augmenting its performance through instruction
tuning. This approach enables the generation of answers that align with the
style of the document labels. The experiments demonstrate that our methodology
achieved state-of-the-art or competitive results with both single-page and
multi-page documents in various fields.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00817" title="Abstract">arXiv:2403.00817</a> [<a href="/pdf/2403.00817" title="Download PDF">pdf</a>, <a href="/format/2403.00817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Calibrated Estimator for Recommendation on Data Missing Not At  Random
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kweon%2C+W">Wonbin Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hwanjo Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recommender systems often suffer from selection bias as users tend to rate
their preferred items. The datasets collected under such conditions exhibit
entries missing not at random and thus are not randomized-controlled trials
representing the target population. To address this challenge, a doubly robust
estimator and its enhanced variants have been proposed as they ensure
unbiasedness when accurate imputed errors or predicted propensities are
provided. However, we argue that existing estimators rely on miscalibrated
imputed errors and propensity scores as they depend on rudimentary models for
estimation. We provide theoretical insights into how miscalibrated imputation
and propensity models may limit the effectiveness of doubly robust estimators
and validate our theorems using real-world datasets. On this basis, we propose
a Doubly Calibrated Estimator that involves the calibration of both the
imputation and propensity models. To achieve this, we introduce calibration
experts that consider different logit distributions across users. Moreover, we
devise a tri-level joint learning framework, allowing the simultaneous
optimization of calibration experts alongside prediction and imputation models.
Through extensive experiments on real-world datasets, we demonstrate the
superiority of the Doubly Calibrated Estimator in the context of debiased
recommendation tasks.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00818" title="Abstract">arXiv:2403.00818</a> [<a href="/pdf/2403.00818" title="Download PDF">pdf</a>, <a href="/format/2403.00818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DenseMamba: State Space Models with Dense Hidden Connection for  Efficient Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yehui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) face a daunting challenge due to the excessive
computational and memory requirements of the commonly used Transformer
architecture. While state space model (SSM) is a new type of foundational
network architecture offering lower computational complexity, their performance
has yet to fully rival that of Transformers. This paper introduces DenseSSM, a
novel approach to enhance the flow of hidden information between layers in
SSMs. By selectively integrating shallowlayer hidden states into deeper layers,
DenseSSM retains fine-grained information crucial for the final output. Dense
connections enhanced DenseSSM still maintains the training parallelizability
and inference efficiency. The proposed method can be widely applicable to
various SSM types like RetNet and Mamba. With similar model size, DenseSSM
achieves significant improvements, exemplified by DenseRetNet outperforming the
original RetNet with up to 5% accuracy improvement on public benchmarks.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00820" title="Abstract">arXiv:2403.00820</a> [<a href="/pdf/2403.00820" title="Download PDF">pdf</a>, <a href="/format/2403.00820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval Augmented Generation Systems: Automatic Dataset Creation,  Evaluation and Boolean Agent Setup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kenneweg%2C+T">Tristan Kenneweg</a>, 
<a href="/search/cs?searchtype=author&query=Kenneweg%2C+P">Philip Kenneweg</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+B">Barbara Hammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Was handed in to IJCNN prior to preprint publication here. Was neither accepted nor rejected at date of publication here
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Retrieval Augmented Generation (RAG) systems have seen huge popularity in
augmenting Large-Language Model (LLM) outputs with domain specific and time
sensitive data. Very recently a shift is happening from simple RAG setups that
query a vector database for additional information with every user input to
more sophisticated forms of RAG. However, different concrete approaches compete
on mostly anecdotal evidence at the moment. In this paper we present a rigorous
dataset creation and evaluation workflow to quantitatively compare different
RAG strategies. We use a dataset created this way for the development and
evaluation of a boolean agent RAG setup: A system in which a LLM can decide
whether to query a vector database or not, thus saving tokens on questions that
can be answered with internal knowledge. We publish our code and generated
dataset online.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00821" title="Abstract">arXiv:2403.00821</a> [<a href="/pdf/2403.00821" title="Download PDF">pdf</a>, <a href="/format/2403.00821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer  Medication Effects Using Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kobara%2C+S">Seibi Kobara</a>, 
<a href="/search/cs?searchtype=author&query=Rafiei%2C+A">Alireza Rafiei</a>, 
<a href="/search/cs?searchtype=author&query=Nateghi%2C+M">Masoud Nateghi</a>, 
<a href="/search/cs?searchtype=author&query=Bozkurt%2C+S">Selen Bozkurt</a>, 
<a href="/search/cs?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+A">Abeed Sarker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Breast cancer is a significant public health concern and is the leading cause
of cancer-related deaths among women. Despite advances in breast cancer
treatments, medication non-adherence remains a major problem. As electronic
health records do not typically capture patient-reported outcomes that may
reveal information about medication-related experiences, social media presents
an attractive resource for enhancing our understanding of the patients'
treatment experiences. In this paper, we developed natural language processing
(NLP) based methodologies to study information posted by an automatically
curated breast cancer cohort from social media. We employed a transformer-based
classifier to identify breast cancer patients/survivors on X (Twitter) based on
their self-reported information, and we collected longitudinal data from their
profiles. We then designed a multi-layer rule-based model to develop a breast
cancer therapy-associated side effect lexicon and detect patterns of medication
usage and associated side effects among breast cancer patients. 1,454,637 posts
were available from 583,962 unique users, of which 62,042 were detected as
breast cancer members using our transformer-based model. 198 cohort members
mentioned breast cancer medications with tamoxifen as the most common. Our side
effect lexicon identified well-known side effects of hormone and chemotherapy.
Furthermore, it discovered a subject feeling towards cancer and medications,
which may suggest a pre-clinical phase of side effects or emotional distress.
This analysis highlighted not only the utility of NLP techniques in
unstructured social media data to identify self-reported breast cancer posts,
medication usage patterns, and treatment side effects but also the richness of
social data on such clinical questions.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00822" title="Abstract">arXiv:2403.00822</a> [<a href="/pdf/2403.00822" title="Download PDF">pdf</a>, <a href="/format/2403.00822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InteraRec: Interactive Recommendations Using Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karra%2C+S+R">Saketh Reddy Karra</a>, 
<a href="/search/cs?searchtype=author&query=Tulabandhula%2C+T">Theja Tulabandhula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Weblogs, comprised of records detailing user activities on any website, offer
valuable insights into user preferences, behavior, and interests. Numerous
recommendation algorithms, employing strategies such as collaborative
filtering, content-based filtering, and hybrid methods, leverage the data mined
through these weblogs to provide personalized recommendations to users. Despite
the abundance of information available in these weblogs, identifying and
extracting pertinent information and key features necessitates extensive
engineering endeavors. The intricate nature of the data also poses a challenge
for interpretation, especially for non-experts. In this study, we introduce a
sophisticated and interactive recommendation framework denoted as InteraRec,
which diverges from conventional approaches that exclusively depend on weblogs
for recommendation generation. This framework captures high-frequency
screenshots of web pages as users navigate through a website. Leveraging
state-of-the-art multimodal large language models (MLLMs), it extracts valuable
insights into user preferences from these screenshots by generating a user
behavioral summary based on predefined keywords. Subsequently, this summary is
utilized as input to an LLM-integrated optimization setup to generate tailored
recommendations. Through our experiments, we demonstrate the effectiveness of
InteraRec in providing users with valuable and personalized offerings.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00823" title="Abstract">arXiv:2403.00823</a> [<a href="/pdf/2403.00823" title="Download PDF">pdf</a>, <a href="/format/2403.00823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting to Teammates in a Cooperative Language Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Archibald%2C+C">Christopher Archibald</a>, 
<a href="/search/cs?searchtype=author&query=Brosnahan%2C+S">Spencer Brosnahan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The game of Codenames has recently emerged as a domain of interest for
intelligent agent design. The game is unique due to the way that language and
coordination between teammates play important roles. Previous approaches to
designing agents for this game have utilized a single internal language model
to determine action choices. This often leads to good performance with some
teammates and inferior performance with other teammates, as the agent cannot
adapt to any specific teammate. In this paper we present the first adaptive
agent for playing Codenames. We adopt an ensemble approach with the goal of
determining, during the course of interacting with a specific teammate, which
of our internal expert agents, each potentially with its own language model, is
the best match. One difficulty faced in this approach is the lack of a single
numerical metric that accurately captures the performance of a Codenames team.
Prior Codenames research has utilized a handful of different metrics to
evaluate agent teams. We propose a novel single metric to evaluate the
performance of a Codenames team, whether playing a single team (solitaire)
game, or a competitive game against another team. We then present and analyze
an ensemble agent which selects an internal expert on each turn in order to
maximize this proposed metric. Experimental analysis shows that this ensemble
approach adapts to individual teammates and often performs nearly as well as
the best internal expert with a teammate. Crucially, this success does not
depend on any previous knowledge about the teammates, the ensemble agents, or
their compatibility. This research represents an important step to making
language-based agents for cooperative language settings like Codenames more
adaptable to individual teammates.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00824" title="Abstract">arXiv:2403.00824</a> [<a href="/pdf/2403.00824" title="Download PDF">pdf</a>, <a href="/format/2403.00824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Flow Routes: Automatically Interpreting Language Models at  Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrando%2C+J">Javier Ferrando</a>, 
<a href="/search/cs?searchtype=author&query=Voita%2C+E">Elena Voita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Information flows by routes inside the network via mechanisms implemented in
the model. These routes can be represented as graphs where nodes correspond to
token representations and edges to operations inside the network. We
automatically build these graphs in a top-down manner, for each prediction
leaving only the most important nodes and edges. In contrast to the existing
workflows relying on activation patching, we do this through attribution: this
allows us to efficiently uncover existing circuits with just a single forward
pass. Additionally, the applicability of our method is far beyond patching: we
do not need a human to carefully design prediction templates, and we can
extract information flow routes for any prediction (not just the ones among the
allowed templates). As a result, we can talk about model behavior in general,
for specific types of predictions, or different domains. We experiment with
Llama 2 and show that the role of some attention heads is overall important,
e.g. previous token heads and subword merging heads. Next, we find similarities
in Llama 2 behavior when handling tokens of the same part of speech. Finally,
we show that some model components can be specialized on domains such as coding
or multilingual texts.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00825" title="Abstract">arXiv:2403.00825</a> [<a href="/pdf/2403.00825" title="Download PDF">pdf</a>, <a href="/ps/2403.00825" title="Download PostScript">ps</a>, <a href="/format/2403.00825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing effectiveness of regularization methods on text  classification: Simple and complex model in data shortage situation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongga Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yim%2C+J">Jaeseung Yim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seohee Park</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+C">Changwon Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text classification is the task of assigning a document to a predefined
class. However, it is expensive to acquire enough labeled documents or to label
them. In this paper, we study the regularization methods' effects on various
classification models when only a few labeled data are available. We compare a
simple word embedding-based model, which is simple but effective, with complex
models (CNN and BiLSTM). In supervised learning, adversarial training can
further regularize the model. When an unlabeled dataset is available, we can
regularize the model using semi-supervised learning methods such as the Pi
model and virtual adversarial training. We evaluate the regularization effects
on four text classification datasets (AG news, DBpedia, Yahoo! Answers, Yelp
Polarity), using only 0.1% to 0.5% of the original labeled training documents.
The simple model performs relatively well in fully supervised learning, but
with the help of adversarial training and semi-supervised learning, both simple
and complex models can be regularized, showing better results for complex
models. Although the simple model is robust to overfitting, a complex model
with well-designed prior beliefs can be also robust to overfitting.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00826" title="Abstract">arXiv:2403.00826</a> [<a href="/pdf/2403.00826" title="Download PDF">pdf</a>, <a href="/format/2403.00826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMGuard: Guarding Against Unsafe LLM Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+S">Shubh Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Hira%2C+M">Medha Hira</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Shubham Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+S">Sukriti Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Arnav Goel</a>, 
<a href="/search/cs?searchtype=author&query=Dadu%2C+N">Niharika Dadu</a>, 
<a href="/search/cs?searchtype=author&query=DB%2C+K">Kirushikesh DB</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S">Sameep Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Madaan%2C+N">Nishtha Madaan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in demonstration track of AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although the rise of Large Language Models (LLMs) in enterprise settings
brings new opportunities and capabilities, it also brings challenges, such as
the risk of generating inappropriate, biased, or misleading content that
violates regulations and can have legal concerns. To alleviate this, we present
"LLMGuard", a tool that monitors user interactions with an LLM application and
flags content against specific behaviours or conversation topics. To do this
robustly, LLMGuard employs an ensemble of detectors.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00827" title="Abstract">arXiv:2403.00827</a> [<a href="/pdf/2403.00827" title="Download PDF">pdf</a>, <a href="/format/2403.00827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Refinement of Language Models from External Proxy Metrics Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramji%2C+K">Keshav Ramji</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Young-Suk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Astudillo%2C+R+F">Ram&#xf3;n Fernandez Astudillo</a>, 
<a href="/search/cs?searchtype=author&query=Sultan%2C+M+A">Md Arafat Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Naseem%2C+T">Tahira Naseem</a>, 
<a href="/search/cs?searchtype=author&query=Munawar%2C+A">Asim Munawar</a>, 
<a href="/search/cs?searchtype=author&query=Florian%2C+R">Radu Florian</a>, 
<a href="/search/cs?searchtype=author&query=Roukos%2C+S">Salim Roukos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">It is often desirable for Large Language Models (LLMs) to capture multiple
objectives when providing a response. In document-grounded response generation,
for example, agent responses are expected to be relevant to a user's query
while also being grounded in a given document. In this paper, we introduce
Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine
its own initial response along key dimensions of quality guided by external
metrics feedback, yielding an overall better final response. ProMiSe leverages
feedback on response quality through principle-specific proxy metrics, and
iteratively refines its response one principle at a time. We apply ProMiSe to
open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its
performance on document-grounded question answering datasets, MultiDoc2Dial and
QuAC, demonstrating that self-refinement improves response quality. We further
show that fine-tuning Llama-2-13B-Chat on the synthetic dialogue data generated
by ProMiSe yields significant performance improvements over the zero-shot
baseline as well as a supervised fine-tuned model on human annotated data.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00828" title="Abstract">arXiv:2403.00828</a> [<a href="/pdf/2403.00828" title="Download PDF">pdf</a>, <a href="/format/2403.00828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Detection Method for Large Language Models-Generated  Scientific Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alhijawi%2C+B">Bushra Alhijawi</a>, 
<a href="/search/cs?searchtype=author&query=Jarrar%2C+R">Rawan Jarrar</a>, 
<a href="/search/cs?searchtype=author&query=AbuAlRub%2C+A">Aseel AbuAlRub</a>, 
<a href="/search/cs?searchtype=author&query=Bader%2C+A">Arwa Bader</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual
content is written and communicated. These models have the potential to
generate scientific content that is indistinguishable from that written by
humans. Hence, LLMs carry severe consequences for the scientific community,
which relies on the integrity and reliability of publications. This research
paper presents a novel ChatGPT-generated scientific text detection method,
AI-Catcher. AI-Catcher integrates two deep learning models, multilayer
perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the
feature representations of the linguistic and statistical features. The CNN
extracts high-level representations of the sequential patterns from the textual
content. AI-Catcher is a multimodal model that fuses hidden patterns derived
from MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset
is collected to enhance AI-generated text detection tools, AIGTxt. AIGTxt
contains 3000 records collected from published academic articles across ten
domains and divided into three classes: Human-written, ChatGPT-generated, and
Mixed text. Several experiments are conducted to evaluate the performance of
AI-Catcher. The comparative results demonstrate the capability of AI-Catcher to
distinguish between human-written and ChatGPT-generated scientific text more
accurately than alternative methods. On average, AI-Catcher improved accuracy
by 37.4%.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00829" title="Abstract">arXiv:2403.00829</a> [<a href="/pdf/2403.00829" title="Download PDF">pdf</a>, <a href="/format/2403.00829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TroubleLLM: Align to Red Team Expert
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuoer Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shiwen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Changhua Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) become the start-of-the-art solutions for a
variety of natural language tasks and are integrated into real-world
applications. However, LLMs can be potentially harmful in manifesting
undesirable safety issues like social biases and toxic content. It is
imperative to assess its safety issues before deployment. However, the quality
and diversity of test prompts generated by existing methods are still far from
satisfactory. Not only are these methods labor-intensive and require large
budget costs, but the controllability of test prompt generation is lacking for
the specific testing domain of LLM applications. With the idea of LLM for LLM
testing, we propose the first LLM, called TroubleLLM, to generate controllable
test prompts on LLM safety issues. Extensive experiments and human evaluation
illustrate the superiority of TroubleLLM on generation quality and generation
controllability.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00830" title="Abstract">arXiv:2403.00830</a> [<a href="/pdf/2403.00830" title="Download PDF">pdf</a>, <a href="/format/2403.00830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedAide: Leveraging Large Language Models for On-Premise Medical  Assistance on Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basit%2C+A">Abdul Basit</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+K">Khizar Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Hanif%2C+M+A">Muhammad Abdullah Hanif</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 11 figures, ACM conference paper, 33 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) are revolutionizing various domains with their
remarkable natural language processing (NLP) abilities. However, deploying LLMs
in resource-constrained edge computing and embedded systems presents
significant challenges. Another challenge lies in delivering medical assistance
in remote areas with limited healthcare facilities and infrastructure. To
address this, we introduce MedAide, an on-premise healthcare chatbot. It
leverages tiny-LLMs integrated with LangChain, providing efficient edge-based
preliminary medical diagnostics and support. MedAide employs model
optimizations for minimal memory footprint and latency on embedded edge devices
without server infrastructure. The training process is optimized using low-rank
adaptation (LoRA). Additionally, the model is trained on diverse medical
datasets, employing reinforcement learning from human feedback (RLHF) to
enhance its domain-specific capabilities. The system is implemented on various
consumer GPUs and Nvidia Jetson development board. MedAide achieves 77\%
accuracy in medical consultations and scores 56 in USMLE benchmark, enabling an
energy-efficient healthcare assistance platform that alleviates privacy
concerns due to edge-based deployment, thereby empowering the community.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00832" title="Abstract">arXiv:2403.00832</a> [<a href="/pdf/2403.00832" title="Download PDF">pdf</a>, <a href="/format/2403.00832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Session-based Recommendation via Path Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Shuo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores providing explainability for session-based recommendation
(SR) by path reasoning. Current SR models emphasize accuracy but lack
explainability, while traditional path reasoning prioritizes knowledge graph
exploration, ignoring sequential patterns present in the session history.
Therefore, we propose a generalized hierarchical reinforcement learning
framework for SR, which improves the explainability of existing SR models via
Path Reasoning, namely PR4SR. Considering the different importance of items to
the session, we design the session-level agent to select the items in the
session as the starting point for path reasoning and the path-level agent to
perform path reasoning. In particular, we design a multi-target reward
mechanism to adapt to the skip behaviors of sequential patterns in SR, and
introduce path midpoint reward to enhance the exploration efficiency in
knowledge graphs. To improve the completeness of the knowledge graph and to
diversify the paths of explanation, we incorporate extracted feature
information from images into the knowledge graph. We instantiate PR4SR in five
state-of-the-art SR models (i.e., GRU4REC, NARM, GCSAN, SR-GNN, SASRec) and
compare it with other explainable SR frameworks, to demonstrate the
effectiveness of PR4SR for recommendation and explanation tasks through
extensive experiments with these approaches on four datasets.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00833" title="Abstract">arXiv:2403.00833</a> [<a href="/pdf/2403.00833" title="Download PDF">pdf</a>, <a href="/format/2403.00833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position Paper: Agent AI Towards a Holistic Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiuyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wake%2C+N">Naoki Wake</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+B">Bidipta Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Durante%2C+Z">Zane Durante</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+R">Ran Gong</a>, 
<a href="/search/cs?searchtype=author&query=Taori%2C+R">Rohan Taori</a>, 
<a href="/search/cs?searchtype=author&query=Noda%2C+Y">Yusuke Noda</a>, 
<a href="/search/cs?searchtype=author&query=Terzopoulos%2C+D">Demetri Terzopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Kuno%2C+N">Noboru Kuno</a>, 
<a href="/search/cs?searchtype=author&query=Famoti%2C+A">Ade Famoti</a>, 
<a href="/search/cs?searchtype=author&query=Llorens%2C+A">Ashley Llorens</a>, 
<a href="/search/cs?searchtype=author&query=Langford%2C+J">John Langford</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+H">Hoi Vo</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Ikeuchi%2C+K">Katsu Ikeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures. arXiv admin note: substantial text overlap with <a href="/abs/2401.03568">arXiv:2401.03568</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent advancements in large foundation models have remarkably enhanced our
understanding of sensory information in open-world environments. In leveraging
the power of foundation models, it is crucial for AI research to pivot away
from excessive reductionism and toward an emphasis on systems that function as
cohesive wholes. Specifically, we emphasize developing Agent AI -- an embodied
system that integrates large foundation models into agent actions. The emerging
field of Agent AI spans a wide range of existing embodied and agent-based
multimodal interactions, including robotics, gaming, and healthcare systems,
etc. In this paper, we propose a novel large action model to achieve embodied
intelligent behavior, the Agent Foundation Model. On top of this idea, we
discuss how agent AI exhibits remarkable capabilities across a variety of
domains and tasks, challenging our understanding of learning and cognition.
Furthermore, we discuss the potential of Agent AI from an interdisciplinary
perspective, underscoring AI cognition and consciousness within scientific
discourse. We believe that those discussions serve as a basis for future
research directions and encourage broader societal engagement.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00834" title="Abstract">arXiv:2403.00834</a> [<a href="/pdf/2403.00834" title="Download PDF">pdf</a>, <a href="/format/2403.00834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Reality for Understanding Artificial-Intelligence-driven  Scientific Discovery with an Application in Quantum Optics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+P">Philipp Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Arlt%2C+S">S&#xf6;ren Arlt</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz-Gonzalez%2C+C">Carlos Ruiz-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xuemei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+C">Carla Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Krenn%2C+M">Mario Krenn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Generative Artificial Intelligence (AI) models can propose solutions to
scientific problems beyond human capability. To truly make conceptual
contributions, researchers need to be capable of understanding the AI-generated
structures and extracting the underlying concepts and ideas. When algorithms
provide little explanatory reasoning alongside the output, scientists have to
reverse-engineer the fundamental insights behind proposals based solely on
examples. This task can be challenging as the output is often highly complex
and thus not immediately accessible to humans. In this work we show how
transferring part of the analysis process into an immersive Virtual Reality
(VR) environment can assist researchers in developing an understanding of
AI-generated solutions. We demonstrate the usefulness of VR in finding
interpretable configurations of abstract graphs, representing Quantum Optics
experiments. Thereby, we can manually discover new generalizations of
AI-discoveries as well as new understanding in experimental quantum optics.
Furthermore, it allows us to customize the search space in an informed way - as
a human-in-the-loop - to achieve significantly faster subsequent discovery
iterations. As concrete examples, with this technology, we discover a new
resource-efficient 3-dimensional entanglement swapping scheme, as well as a
3-dimensional 4-particle Greenberger-Horne-Zeilinger-state analyzer. Our
results show the potential of VR for increasing a human researcher's ability to
derive knowledge from graph-based generative AI that, which is a common
abstract data representation used in diverse fields of science.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00835" title="Abstract">arXiv:2403.00835</a> [<a href="/pdf/2403.00835" title="Download PDF">pdf</a>, <a href="/format/2403.00835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLLMs: Consistency Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kou%2C+S">Siqi Kou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lanxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhezhi He</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Parallel decoding methods such as Jacobi decoding show promise for more
efficient LLM inference as it breaks the sequential nature of the LLM decoding
process and transforms it into parallelizable computation. However, in
practice, it achieves little speedup compared to traditional autoregressive
(AR) decoding, primarily because Jacobi decoding seldom accurately predicts
more than one token in a single fixed-point iteration step. To address this, we
develop a new approach aimed at realizing fast convergence from any state to
the fixed point on a Jacobi trajectory. This is accomplished by refining the
target LLM to consistently predict the fixed point given any state as input.
Extensive experiments demonstrate the effectiveness of our method, showing
2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving
generation quality across both domain-specific and open-domain benchmarks.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00839" title="Abstract">arXiv:2403.00839</a> [<a href="/pdf/2403.00839" title="Download PDF">pdf</a>, <a href="/format/2403.00839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToolNet: Connecting Large Language Models with Massive Tools via Tool  Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xukun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhiyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Lirong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">While achieving remarkable progress in a broad range of tasks, large language
models (LLMs) remain significantly limited in properly using massive external
tools. Existing in-context learning approaches simply format tools into a list
of plain text descriptions and input them to LLMs, from which, LLMs generate a
sequence of tool calls to solve problems step by step. Such a paradigm ignores
the intrinsic dependency between tools and offloads all reasoning loads to
LLMs, making them restricted to a limited number of specifically designed
tools. It thus remains challenging for LLMs to operate on a library of massive
tools, casting a great limitation when confronted with real-world scenarios.
This paper proposes ToolNet, a plug-and-play framework that scales up the
number of tools to thousands with a moderate increase in token consumption.
ToolNet organizes tools into a directed graph. Each node represents a tool, and
weighted edges denote tool transition. Starting from an initial tool node, an
LLM navigates in the graph by iteratively choosing the next one from its
successors until the task is resolved. Extensive experiments show that ToolNet
can achieve impressive results in challenging multi-hop tool learning datasets
and is resilient to tool failures.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00840" title="Abstract">arXiv:2403.00840</a> [<a href="/pdf/2403.00840" title="Download PDF">pdf</a>, <a href="/ps/2403.00840" title="Download PostScript">ps</a>, <a href="/format/2403.00840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EyeGPT: Ophthalmic Assistant with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaolan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Pusheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Le Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingpu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Danli Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mingguang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 4 figures, 1 table, 2 supplementary figures and 9 supplementary tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial intelligence (AI) has gained significant attention in healthcare
consultation due to its potential to improve clinical workflow and enhance
medical communication. However, owing to the complex nature of medical
information, large language models (LLM) trained with general world knowledge
might not possess the capability to tackle medical-related tasks at an expert
level. Here, we introduce EyeGPT, a specialized LLM designed specifically for
ophthalmology, using three optimization strategies including role-playing,
finetuning, and retrieval-augmented generation. In particular, we proposed a
comprehensive evaluation framework that encompasses a diverse dataset, covering
various subspecialties of ophthalmology, different users, and diverse inquiry
intents. Moreover, we considered multiple evaluation metrics, including
accuracy, understandability, trustworthiness, empathy, and the proportion of
hallucinations. By assessing the performance of different EyeGPT variants, we
identify the most effective one, which exhibits comparable levels of
understandability, trustworthiness, and empathy to human ophthalmologists (all
Ps&gt;0.05). Overall, ur study provides valuable insights for future research,
facilitating comprehensive comparisons and evaluations of different strategies
for developing specialized LLMs in ophthalmology. The potential benefits
include enhancing the patient experience in eye care and optimizing
ophthalmologists' services.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00841" title="Abstract">arXiv:2403.00841</a> [<a href="/pdf/2403.00841" title="Download PDF">pdf</a>, <a href="/format/2403.00841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Fictitious Self-Play for Competitive Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiji Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=yu%2C+Y">Yong yu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Offline Reinforcement Learning (RL) has received significant interest due to
its ability to improve policies in previously collected datasets without online
interactions. Despite its success in the single-agent setting, offline
multi-agent RL remains a challenge, especially in competitive games. Firstly,
unaware of the game structure, it is impossible to interact with the opponents
and conduct a major learning paradigm, self-play, for competitive games.
Secondly, real-world datasets cannot cover all the state and action space in
the game, resulting in barriers to identifying Nash equilibrium (NE). To
address these issues, this paper introduces Off-FSP, the first practical
model-free offline RL algorithm for competitive games. We start by simulating
interactions with various opponents by adjusting the weights of the fixed
dataset with importance sampling. This technique allows us to learn best
responses to different opponents and employ the Offline Self-Play learning
framework. In this framework, we further implement Fictitious Self-Play (FSP)
to approximate NE. In partially covered real-world datasets, our methods show
the potential to approach NE by incorporating any single-agent offline RL
method. Experimental results in Leduc Hold'em Poker show that our method
significantly improves performances compared with state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00843" title="Abstract">arXiv:2403.00843</a> [<a href="/pdf/2403.00843" title="Download PDF">pdf</a>, <a href="/format/2403.00843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Long-Term Recommendation with Bi-level Learnable Large  Language Model Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditional recommendation setting tends to excessively cater to users'
immediate interests and neglect their long-term engagement. To address it, it
is crucial to incorporate planning capabilities into the recommendation
decision-making process to develop policies that take into account both
immediate interests and long-term engagement. Despite Reinforcement Learning
(RL) can learn planning capacity by maximizing cumulative reward, the scarcity
of recommendation data presents challenges such as instability and
susceptibility to overfitting when training RL models from scratch.
<br />In this context, we propose to leverage the remarkable planning capabilities
over sparse data of Large Language Models (LLMs) for long-term recommendation.
The key lies in enabling a language model to understand and apply task-solving
principles effectively in personalized recommendation scenarios, as the model's
pre-training may not naturally encompass these principles, necessitating the
need to inspire or teach the model. To achieve this, we propose a Bi-level
Learnable LLM Planner framework, which combines macro-learning and
micro-learning through a hierarchical mechanism. The framework includes a
Planner and Reflector for acquiring high-level guiding principles and an
Actor-Critic component for planning personalization. Extensive experiments
validate the superiority of the framework in learning to plan for long-term
recommendations.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00844" title="Abstract">arXiv:2403.00844</a> [<a href="/pdf/2403.00844" title="Download PDF">pdf</a>, <a href="/format/2403.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower-Left Partial AUC: An Effective and Efficient Optimization Metric  for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junkang Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2024; 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimization metrics are crucial for building recommendation systems at
scale. However, an effective and efficient metric for practical use remains
elusive. While Top-K ranking metrics are the gold standard for optimization,
they suffer from significant computational overhead. Alternatively, the more
efficient accuracy and AUC metrics often fall short of capturing the true
targets of recommendation tasks, leading to suboptimal performance. To overcome
this dilemma, we propose a new optimization metric, Lower-Left Partial AUC
(LLPAUC), which is computationally efficient like AUC but strongly correlates
with Top-K ranking metrics. Compared to AUC, LLPAUC considers only the partial
area under the ROC curve in the Lower-Left corner to push the optimization
focus on Top-K. We provide theoretical validation of the correlation between
LLPAUC and Top-K ranking metrics and demonstrate its robustness to noisy user
feedback. We further design an efficient point-wise recommendation loss to
maximize LLPAUC and evaluate it on three datasets, validating its effectiveness
and robustness.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00845" title="Abstract">arXiv:2403.00845</a> [<a href="/pdf/2403.00845" title="Download PDF">pdf</a>, <a href="/ps/2403.00845" title="Download PostScript">ps</a>, <a href="/format/2403.00845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Online Learning Algorithms for CTR Prediction in Ad Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhe Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liaw%2C+C">Christopher Liaw</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we investigate the online learning problem of revenue
maximization in ad auctions, where the seller needs to learn the click-through
rates (CTRs) of each ad candidate and charge the price of the winner through a
pay-per-click manner. We focus on two models of the advertisers' strategic
behaviors. First, we assume that the advertiser is completely myopic; i.e.~in
each round, they aim to maximize their utility only for the current round. In
this setting, we develop an online mechanism based on upper-confidence bounds
that achieves a tight $O(\sqrt{T})$ regret in the worst-case and negative
regret when the values are static across all the auctions and there is a gap
between the highest expected value (i.e.~value multiplied by their CTR) and
second highest expected value ad. Next, we assume that the advertiser is
non-myopic and cares about their long term utility. This setting is much more
complex since an advertiser is incentivized to influence the mechanism by
bidding strategically in earlier rounds. In this setting, we provide an
algorithm to achieve negative regret for the static valuation setting (with a
positive gap), which is in sharp contrast with the prior work that shows
$O(T^{2/3})$ regret when the valuation is generated by adversary.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00849" title="Abstract">arXiv:2403.00849</a> [<a href="/pdf/2403.00849" title="Download PDF">pdf</a>, <a href="/format/2403.00849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuraLUT: Hiding Neural Network Density in Boolean Synthesizable  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andronic%2C+M">Marta Andronic</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Field-Programmable Gate Array (FPGA) accelerators have proven successful in
handling latency- and resource-critical deep neural network (DNN) inference
tasks. Among the most computationally intensive operations in a neural network
(NN) is the dot product between the feature and weight vectors. Thus, some
previous FPGA acceleration works have proposed mapping neurons with quantized
inputs and outputs directly to lookup tables (LUTs) for hardware
implementation. In these works, the boundaries of the neurons coincide with the
boundaries of the LUTs. We propose relaxing these boundaries and mapping entire
sub-networks to a single LUT. As the sub-networks are absorbed within the LUT,
the NN topology and precision within a partition do not affect the size of the
lookup tables generated. Therefore, we utilize fully connected layers with
floating-point precision inside each partition, which benefit from being
universal function approximators, with rigid sparsity and quantization enforced
only between partitions, where the NN topology becomes exposed to the circuit
topology. Although cheap to implement, this approach can lead to very deep NNs,
and so to tackle challenges like vanishing gradients, we also introduce skip
connections inside the partitions. The resulting methodology can be seen as
training DNNs with a specific sparsity pattern that allows them to be mapped to
much shallower circuit-level networks, thereby significantly improving latency.
We validate our proposed method on a known latency-critical task, jet
substructure tagging, and on the classical computer vision task, the digit
classification using MNIST. Our approach allows for greater function
expressivity within the LUTs compared to existing work, leading to lower
latency NNs for the same accuracy.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00853" title="Abstract">arXiv:2403.00853</a> [<a href="/pdf/2403.00853" title="Download PDF">pdf</a>, <a href="/format/2403.00853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Momentum Methods Under Biased Gradient Estimations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beikmohammadi%2C+A">Ali Beikmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Khirirat%2C+S">Sarit Khirirat</a>, 
<a href="/search/cs?searchtype=author&query=Magn%C3%BAsson%2C+S">Sindri Magn&#xfa;sson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Distributed stochastic gradient methods are gaining prominence in solving
large-scale machine learning problems that involve data distributed across
multiple nodes. However, obtaining unbiased stochastic gradients, which have
been the focus of most theoretical research, is challenging in many distributed
machine learning applications. The gradient estimations easily become biased,
for example, when gradients are compressed or clipped, when data is shuffled,
and in meta-learning and reinforcement learning. In this work, we establish
non-asymptotic convergence bounds on distributed momentum methods under biased
gradient estimation on both general non-convex and $\mu$-PL non-convex
problems. Our analysis covers general distributed optimization problems, and we
work out the implications for special cases where gradient estimates are
biased, i.e., in meta-learning and when the gradients are compressed or
clipped. Our numerical experiments on training deep neural networks with
Top-$K$ sparsification and clipping verify faster convergence performance of
momentum methods than traditional biased gradient descent.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00858" title="Abstract">arXiv:2403.00858</a> [<a href="/pdf/2403.00858" title="Download PDF">pdf</a>, <a href="/format/2403.00858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Alignment of Draft Model for Speculative Decoding with  Chat-Fine-Tuned LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+R">Raghavv Goel</a>, 
<a href="/search/cs?searchtype=author&query=Gagrani%2C+M">Mukul Gagrani</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+W">Wonseok Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lott%2C+C">Christopher Lott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Text generation with Large Language Models (LLMs) is known to be memory bound
due to the combination of their auto-regressive nature, huge parameter counts,
and limited memory bandwidths, often resulting in low token rates. Speculative
decoding has been proposed as a solution for LLM inference acceleration.
However, since draft models are often unavailable in the modern open-source LLM
families, e.g., for Llama 2 7B, training a high-quality draft model is required
to enable inference acceleration via speculative decoding. In this paper, we
propose a simple draft model training framework for direct alignment to
chat-capable target models. With the proposed framework, we train Llama 2 Chat
Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of
the original size. Our training framework only consists of pretraining,
distillation dataset generation, and finetuning with knowledge distillation,
with no additional alignment procedure. For the finetuning step, we use
instruction-response pairs generated by target model for distillation in
plausible data distribution, and propose a new Total Variation Distance++
(TVD++) loss that incorporates variance reduction techniques inspired from the
policy gradient method in reinforcement learning. Our empirical results show
that Llama 2 Chat Drafter 115M with speculative decoding achieves up to 2.3
block efficiency and 2.4$\times$ speed-up relative to autoregressive decoding
on various tasks with no further task-specific fine-tuning.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00859" title="Abstract">arXiv:2403.00859</a> [<a href="/pdf/2403.00859" title="Download PDF">pdf</a>, <a href="/format/2403.00859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Team Formation amidst Conflicts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikolaou%2C+I">Iasonas Nikolaou</a>, 
<a href="/search/cs?searchtype=author&query=Terzi%2C+E">Evimaria Terzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this work, we formulate the problem of team formation amidst conflicts.
The goal is to assign individuals to tasks, with given capacities, taking into
account individuals' task preferences and the conflicts between them. Using
dependent rounding schemes as our main toolbox, we provide efficient
approximation algorithms. Our framework is extremely versatile and can model
many different real-world scenarios as they arise in educational settings and
human-resource management. We test and deploy our algorithms on real-world
datasets and we show that our algorithms find assignments that are better than
those found by natural baselines. In the educational setting we also show how
our assignments are far better than those done manually by human experts. In
the human resource management application we show how our assignments increase
the diversity of teams. Finally, using a synthetic dataset we demonstrate that
our algorithms scale very well in practice.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00860" title="Abstract">arXiv:2403.00860</a> [<a href="/pdf/2403.00860" title="Download PDF">pdf</a>, <a href="/format/2403.00860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Algorithms for Exact Enumeration of Deep Neural Network  Activation Regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drammis%2C+S">Sabrina Drammis</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bowen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+K">Karthik Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Berwick%2C+R+C">Robert C. Berwick</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+N+A">Nancy A. Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Ajemian%2C+R">Robert Ajemian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">A feedforward neural network using rectified linear units constructs a
mapping from inputs to outputs by partitioning its input space into a set of
convex regions where points within a region share a single affine
transformation. In order to understand how neural networks work, when and why
they fail, and how they compare to biological intelligence, we need to
understand the organization and formation of these regions. Step one is to
design and implement algorithms for exact region enumeration in networks beyond
toy examples.
<br />In this work, we present parallel algorithms for exact enumeration in deep
(and shallow) neural networks. Our work has three main contributions: (1) we
present a novel algorithm framework and parallel algorithms for region
enumeration; (2) we implement one of our algorithms on a variety of network
architectures and experimentally show how the number of regions dictates
runtime; and (3) we show, using our algorithm's output, how the dimension of a
region's affine transformation impacts further partitioning of the region by
deeper layers.
<br />To our knowledge, we run our implemented algorithm on networks larger than
all of the networks used in the existing region enumeration literature.
Further, we experimentally demonstrate the importance of parallelism for region
enumeration of any reasonably sized network.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00861" title="Abstract">arXiv:2403.00861</a> [<a href="/pdf/2403.00861" title="Download PDF">pdf</a>, <a href="/ps/2403.00861" title="Download PostScript">ps</a>, <a href="/format/2403.00861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy,  Survey and Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sambasivan%2C+L+K">Lokesh Kumar Sambasivan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+M">Mingang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+P">Prakhar Mehrotra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative AI applications, such as ChatGPT or DALL-E, have shown the world
their impressive capabilities in generating human-like text or image. Diving
deeper, the science stakeholder for those AI applications are Deep Generative
Models, a.k.a DGMs, which are designed to learn the underlying distribution of
the data and generate new data points that are statistically similar to the
original dataset. One critical question is raised: how can we leverage DGMs
into morden retail supply chain realm? To address this question, this paper
expects to provide a comprehensive review of DGMs and discuss their existing
and potential usecases in retail supply chain, by (1) providing a taxonomy and
overview of state-of-the-art DGMs and their variants, (2) reviewing existing
DGM applications in retail supply chain from a end-to-end view of point, and
(3) discussing insights and potential directions on how DGMs can be further
utilized on solving retail supply chain problems.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00862" title="Abstract">arXiv:2403.00862</a> [<a href="/pdf/2403.00862" title="Download PDF">pdf</a>, <a href="/format/2403.00862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and  Safety Adherence in Chinese Journalistic Editorial Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming-Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shengbin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haiying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+F">Feiyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Keming Mao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yi Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study presents NewsBench, a novel benchmark framework developed to
evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic
Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap
between journalistic ethics and the risks associated with AI utilization.
Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including
safety and journalistic writing with 4 detailed facets), and spanning 24 news
topics domains, NewsBench employs two GPT-4 based automatic evaluation
protocols validated by human assessment. Our comprehensive analysis of 11 LLMs
highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative
deficiency in journalistic ethic adherence during creative writing tasks. These
findings underscore the need for enhanced ethical guidance in AI-generated
journalistic content, marking a step forward in aligning AI capabilities with
journalistic standards and safety considerations.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00863" title="Abstract">arXiv:2403.00863</a> [<a href="/pdf/2403.00863" title="Download PDF">pdf</a>, <a href="/format/2403.00863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Ensemble: Optimal Large Language Model Ensemble Method for  E-commerce Product Attribute Value Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chenhao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zezhong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianpeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+K">Kaushiki Nag</a>, 
<a href="/search/cs?searchtype=author&query=Korpeoglu%2C+E">Evren Korpeoglu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sushant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Achan%2C+K">Kannan Achan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Product attribute value extraction is a pivotal component in Natural Language
Processing (NLP) and the contemporary e-commerce industry. The provision of
precise product attribute values is fundamental in ensuring high-quality
recommendations and enhancing customer satisfaction. The recently emerging
Large Language Models (LLMs) have demonstrated state-of-the-art performance in
numerous attribute extraction tasks, without the need for domain-specific
training data. Nevertheless, varying strengths and weaknesses are exhibited by
different LLMs due to the diversity in data, architectures, and
hyperparameters. This variation makes them complementary to each other, with no
single LLM dominating all others. Considering the diverse strengths and
weaknesses of LLMs, it becomes necessary to develop an ensemble method that
leverages their complementary potentials. In this paper, we propose a novel
algorithm called LLM-ensemble to ensemble different LLMs' outputs for attribute
value extraction. We iteratively learn the weights for different LLMs to
aggregate the labels with weights to predict the final attribute value. Not
only can our proposed method be proven theoretically optimal, but it also
ensures efficient computation, fast convergence, and safe deployment. We have
also conducted extensive experiments with various state-of-the-art LLMs,
including Llama2-13B, Llama2-70B, PaLM-2, GPT-3.5, and GPT-4, on Walmart's
internal data. Our offline metrics demonstrate that the LLM-ensemble method
outperforms all the state-of-the-art single LLMs on Walmart's internal dataset.
This method has been launched in several production models, leading to improved
Gross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate
(CVR), and Add-to-Cart Rate (ATC).
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00864" title="Abstract">arXiv:2403.00864</a> [<a href="/pdf/2403.00864" title="Download PDF">pdf</a>, <a href="/ps/2403.00864" title="Download PostScript">ps</a>, <a href="/format/2403.00864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Logistic Map for Pseudorandom Number Generation in Game  Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenxiao Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Many popular video games use pseudorandom number generators to create
randomly distributed locations for game objects as highly unpredictable as
possible. Some scenarios like game competition also need reproducible
randomness, namely the random results can be reproducible if given the same
seed input. Existing random generation methods have limited choices for seed
input. To address this limitation, this study analyzes a chaotic map called the
Logistic Map for game development. After analyzing the properties of this
chaotic map, I developed a pseudorandom sequence generation algorithm and a
generation algorithm of random locations of game objects. Experiments on the
game of Snake demonstrate that the Logistic Map is viable for game development.
The reproducible randomness is also realized with the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00865" title="Abstract">arXiv:2403.00865</a> [<a href="/pdf/2403.00865" title="Download PDF">pdf</a>, <a href="/format/2403.00865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Efficient Local Search for Genetic Programming Based Loss  Function Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raymond%2C+C">Christian Raymond</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bing Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengjie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2209.08907">arXiv:2209.08907</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we develop upon the topic of loss function learning, an
emergent meta-learning paradigm that aims to learn loss functions that
significantly improve the performance of the models trained under them.
Specifically, we propose a new meta-learning framework for task and
model-agnostic loss function learning via a hybrid search approach. The
framework first uses genetic programming to find a set of symbolic loss
functions. Second, the set of learned loss functions is subsequently
parameterized and optimized via unrolled differentiation. The versatility and
performance of the proposed framework are empirically validated on a diverse
set of supervised learning tasks. Results show that the learned loss functions
bring improved convergence, sample efficiency, and inference performance on
tabulated, computer vision, and natural language processing problems, using a
variety of task-specific neural network architectures.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00867" title="Abstract">arXiv:2403.00867</a> [<a href="/pdf/2403.00867" title="Download PDF">pdf</a>, <a href="/format/2403.00867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by  Exploring Refusal Loss Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaomeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://huggingface.co/spaces/TrustSafeAI/GradientCuff-Jailbreak-Defense">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) are becoming a prominent generative AI tool,
where the user enters a query and the LLM generates an answer. To reduce harm
and misuse, efforts have been made to align these LLMs to human values using
advanced training techniques such as Reinforcement Learning from Human Feedback
(RLHF). However, recent studies have highlighted the vulnerability of LLMs to
adversarial jailbreak attempts aiming at subverting the embedded safety
guardrails. To address this challenge, this paper defines and investigates the
Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect
jailbreak attempts. Gradient Cuff exploits the unique properties observed in
the refusal loss landscape, including functional values and its smoothness, to
design an effective two-step detection strategy. Experimental results on two
aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak
attacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can
significantly improve the LLM's rejection capability for malicious jailbreak
queries, while maintaining the model's performance for benign user queries by
adjusting the detection threshold.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00868" title="Abstract">arXiv:2403.00868</a> [<a href="/pdf/2403.00868" title="Download PDF">pdf</a>, <a href="/format/2403.00868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoftTiger: A Clinical Foundation Model for Healthcare Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ye Chen</a>, 
<a href="/search/cs?searchtype=author&query=Couto%2C+I">Igor Couto</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Cong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Dorneles%2C+B">Bruno Dorneles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We release and introduce SoftTiger, a clinical large language model (CLaM)
designed as a foundation model for healthcare workflows. The narrative and
unstructured nature of clinical notes is a major obstacle for healthcare
intelligentization. We address a critical problem of structuring clinical notes
into clinical data, according to international interoperability standards. We
collect and annotate data for three critical subtasks, namely, international
patient summary, clinical impression and medical encounter. We then supervised
fine-tuned a state-of-the-art LLM using public and credentialed clinical data.
The training is orchestrated in a way that the target model can first support
basic clinical tasks such as abbreviation expansion and temporal information
extraction, and then learn to perform more complex downstream clinical tasks
such as impression and encounter summary. Moreover, we address, several
modeling challenges in the healthcare context, e.g., extra long context window.
Our blind pairwise evaluation shows that SoftTiger outperforms other popular
open-source models and GPT-3.5, comparable to Gemini-pro, and only has a mild
gap from GPT-4. We believe that LLMs may become a step-stone towards healthcare
digitalization and democratization. Therefore, we publicly release SoftTiger
models at scales of 13 billion and 70 billion parameters, as well as datasets
and code for our innovative scalable evaluation, hopefully, making a
significant contribution to the healthcare industry.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00869" title="Abstract">arXiv:2403.00869</a> [<a href="/pdf/2403.00869" title="Download PDF">pdf</a>, <a href="/format/2403.00869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Multivariate Time Series Forecasting with Mutual  Information-driven Cross-Variable and Temporal Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Shiyi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Liangjian Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiduo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuanhang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhongwen Rao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Lujia Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent advancements have underscored the impact of deep learning techniques
on multivariate time series forecasting (MTSF). Generally, these techniques are
bifurcated into two categories: Channel-independence and Channel-mixing
approaches. Although Channel-independence methods typically yield better
results, Channel-mixing could theoretically offer improvements by leveraging
inter-variable correlations. Nonetheless, we argue that the integration of
uncorrelated information in channel-mixing methods could curtail the potential
enhancement in MTSF model performance. To substantiate this claim, we introduce
the Cross-variable Decorrelation Aware feature Modeling (CDAM) for
Channel-mixing approaches, aiming to refine Channel-mixing by minimizing
redundant information between channels while enhancing relevant mutual
information. Furthermore, we introduce the Temporal correlation Aware Modeling
(TAM) to exploit temporal correlations, a step beyond conventional single-step
forecasting methods. This strategy maximizes the mutual information between
adjacent sub-sequences of both the forecasted and target series. Combining CDAM
and TAM, our novel framework significantly surpasses existing models, including
those previously considered state-of-the-art, in comprehensive tests.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00871" title="Abstract">arXiv:2403.00871</a> [<a href="/pdf/2403.00871" title="Download PDF">pdf</a>, <a href="/format/2403.00871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teach LLMs to Phish: Stealing Private Information from Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panda%2C+A">Ashwinee Panda</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaoqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+P">Prateek Mittal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">When large language models are trained on private data, it can be a
significant privacy risk for them to memorize and regurgitate sensitive
information. In this work, we propose a new practical data extraction attack
that we call "neural phishing". This attack enables an adversary to target and
extract sensitive or personally identifiable information (PII), e.g., credit
card numbers, from a model trained on user data with upwards of 10% attack
success rates, at times, as high as 50%. Our attack assumes only that an
adversary can insert as few as 10s of benign-appearing sentences into the
training dataset using only vague priors on the structure of the user data.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00872" title="Abstract">arXiv:2403.00872</a> [<a href="/pdf/2403.00872" title="Download PDF">pdf</a>, <a href="/format/2403.00872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy  in Large-Scale Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Volvovsky%2C+S">Shai Volvovsky</a>, 
<a href="/search/cs?searchtype=author&query=Marcassa%2C+M">Marco Marcassa</a>, 
<a href="/search/cs?searchtype=author&query=Panbiharwala%2C+M">Mustafa Panbiharwala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The task of converting natural language queries into SQL queries is
intricate, necessitating a blend of precise techniques for an accurate
translation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a
significant development in this domain. This paper introduces DFIN (Decomposed
Focused-In-Context), an innovative extension of DIN-SQL that enhances
Text-to-SQL conversion by addressing schema linking errors, which are a major
source of inaccuracies. DFIN uniquely alternates between prompting techniques
and Retrieval-Augmented Generation (RAG), adapting to the size and complexity
of the database schema. A preprocessing phase embeds database definitions and
leverages annotated files, akin to those in the BIRD dataset, facilitating the
runtime retrieval of pertinent schema information. This strategy significantly
reduces the token count for schema linking prompts, enabling the use of a
standard GPT-4 model over its larger context variant, thus handling large-scale
databases more effectively and economically. Our evaluation on the BIRD
dataset, a challenging real-world benchmark, demonstrates that DFIN not only
scales efficiently but also improves accuracy, achieving a score of 51.69. This
improvement surpasses DIN-SQL method (the current third-place), which is the
highest-ranked model employing in-context learning rather than fine-tuning,
previously scoring 50.72. The advancement of DFIN underscores the evolving
capabilities of in-context learning methodologies combined with advanced
language models, offering a promising avenue for future research in complex
Text-to-SQL conversion tasks.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00873" title="Abstract">arXiv:2403.00873</a> [<a href="/pdf/2403.00873" title="Download PDF">pdf</a>, <a href="/ps/2403.00873" title="Download PostScript">ps</a>, <a href="/format/2403.00873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-empowered Federated Learning: Benefits, Challenges, and  Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zeju Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianguo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuting Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) is a distributed machine learning approach that
protects user data privacy by training models locally on clients and
aggregating them on a parameter server. While effective at preserving privacy,
FL systems face limitations such as single points of failure, lack of
incentives, and inadequate security. To address these challenges, blockchain
technology is integrated into FL systems to provide stronger security,
fairness, and scalability. However, blockchain-empowered FL (BC-FL) systems
introduce additional demands on network, computing, and storage resources. This
survey provides a comprehensive review of recent research on BC-FL systems,
analyzing the benefits and challenges associated with blockchain integration.
We explore why blockchain is applicable to FL, how it can be implemented, and
the challenges and existing solutions for its integration. Additionally, we
offer insights on future research directions for the BC-FL system.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00876" title="Abstract">arXiv:2403.00876</a> [<a href="/pdf/2403.00876" title="Download PDF">pdf</a>, <a href="/format/2403.00876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Order and World Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinghua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ravishankar%2C+V">Vinit Ravishankar</a>, 
<a href="/search/cs?searchtype=author&query=Garneau%2C+N">Nicolas Garneau</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B8gaard%2C+A">Anders S&#xf8;gaard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Word order is an important concept in natural language, and in this work, we
study how word order affects the induction of world knowledge from raw text
using language models. We use word analogies to probe for such knowledge.
Specifically, in addition to the natural word order, we first respectively
extract texts of six fixed word orders from five languages and then pretrain
the language models on these texts. Finally, we analyze the experimental
results of the fixed word orders on word analogies and show that i) certain
fixed word orders consistently outperform or underperform others, though the
specifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in
pre-trained language models, and the natural word order typically yields
mediocre results. The source code will be made publicly available at
https://github.com/lshowway/probing_by_analogy.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00877" title="Abstract">arXiv:2403.00877</a> [<a href="/pdf/2403.00877" title="Download PDF">pdf</a>, <a href="/format/2403.00877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disaggregated Multi-Tower: Topology-aware Modeling Technique for  Efficient Large-Scale Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Buyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+M">Michael Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yinbin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Ching-Hsiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yuchen Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarayanan%2C+G">Guna Lakshminarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+E+D">Ellie Dingqiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Mudigere%2C+D">Dheevatsa Mudigere</a>, 
<a href="/search/cs?searchtype=author&query=Naumov%2C+M">Maxim Naumov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR)

</div>
<p class="mathjax">We study a mismatch between the deep learning recommendation models' flat
architecture, common distributed training paradigm and hierarchical data center
topology. To address the associated inefficiencies, we propose Disaggregated
Multi-Tower (DMT), a modeling technique that consists of (1)
Semantic-preserving Tower Transform (SPTT), a novel training paradigm that
decomposes the monolithic global embedding lookup process into disjoint towers
to exploit data center locality; (2) Tower Module (TM), a synergistic dense
component attached to each tower to reduce model complexity and communication
volume through hierarchical feature interaction; and (3) Tower Partitioner
(TP), a feature partitioner to systematically create towers with meaningful
feature interactions and load balanced assignments to preserve model quality
and training throughput via learned embeddings. We show that DMT can achieve up
to 1.9x speedup compared to the state-of-the-art baselines without losing
accuracy across multiple generations of hardware at large data center scales.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00878" title="Abstract">arXiv:2403.00878</a> [<a href="/pdf/2403.00878" title="Download PDF">pdf</a>, <a href="/format/2403.00878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crimson: Empowering Strategic Reasoning in Cybersecurity through Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiandong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bowen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Mingxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Q">Qingnan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Changling Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduces Crimson, a system that enhances the strategic reasoning
capabilities of Large Language Models (LLMs) within the realm of cybersecurity.
By correlating CVEs with MITRE ATT&amp;CK techniques, Crimson advances threat
anticipation and strategic defense efforts. Our approach includes defining and
evaluating cybersecurity strategic tasks, alongside implementing a
comprehensive human-in-the-loop data-synthetic workflow to develop the
CVE-to-ATT&amp;CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning
abilities through a novel Retrieval-Aware Training (RAT) process and its
refined iteration, RAT-R.
<br />Our findings demonstrate that an LLM fine-tuned with our techniques,
possessing 7 billion parameters, approaches the performance level of GPT-4,
showing markedly lower rates of hallucination and errors, and surpassing other
models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of
embedding models significantly improves performance within cybersecurity
contexts, underscoring the efficacy of our methodology. By leveraging Crimson
to convert raw vulnerability data into structured and actionable insights, we
bolster proactive cybersecurity defenses.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00880" title="Abstract">arXiv:2403.00880</a> [<a href="/pdf/2403.00880" title="Download PDF">pdf</a>, <a href="/format/2403.00880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Granularity Medication Recommendation Based on Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shunpan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yulei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As medical demands grow and machine learning technology advances, AI-based
diagnostic and treatment systems are garnering increasing attention. Medication
recommendation aims to integrate patients' long-term health records with
medical knowledge, recommending accuracy and safe medication combinations for
specific conditions. However, most existing researches treat medication
recommendation systems merely as variants of traditional recommendation
systems, overlooking the heterogeneity between medications and diseases. To
address this challenge, we propose DGMed, a framework for medication
recommendation. DGMed utilizes causal inference to uncover the connections
among medical entities and presents an innovative feature alignment method to
tackle heterogeneity issues. Specifically, this study first applies causal
inference to analyze the quantified therapeutic effects of medications on
specific diseases from historical records, uncovering potential links between
medical entities. Subsequently, we integrate molecular-level knowledge,
aligning the embeddings of medications and diseases within the molecular space
to effectively tackle their heterogeneity. Ultimately, based on relationships
at the entity level, we adaptively adjust the recommendation probabilities of
medication and recommend medication combinations according to the patient's
current health condition. Experimental results on a real-world dataset show
that our method surpasses existing state-of-the-art baselines in four
evaluation metrics, demonstrating superior performance in both accuracy and
safety aspects. Compared to the sub-optimal model, our approach improved
accuracy by 4.40%, reduced the risk of side effects by 6.14%, and increased
time efficiency by 47.15%.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00881" title="Abstract">arXiv:2403.00881</a> [<a href="/pdf/2403.00881" title="Download PDF">pdf</a>, <a href="/format/2403.00881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedRDMA: Communication-Efficient Cross-Silo Federated LLM via Chunked  RDMA Transmission
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Dongqi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Ao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Communication overhead is a significant bottleneck in federated learning
(FL), which has been exaggerated with the increasing size of AI models. In this
paper, we propose FedRDMA, a communication-efficient cross-silo FL system that
integrates RDMA into the FL communication protocol. To overcome the limitations
of RDMA in wide-area networks (WANs), FedRDMA divides the updated model into
chunks and designs a series of optimization techniques to improve the
efficiency and robustness of RDMA-based communication. We implement FedRDMA
atop the industrial federated learning framework and evaluate it on a
real-world cross-silo FL scenario. The experimental results show that \sys can
achieve up to 3.8$\times$ speedup in communication efficiency compared to
traditional TCP/IP-based FL systems.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00884" title="Abstract">arXiv:2403.00884</a> [<a href="/pdf/2403.00884" title="Download PDF">pdf</a>, <a href="/format/2403.00884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text classification of column headers with a controlled vocabulary:  leveraging LLMs for metadata enrichment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martorana%2C+M">Margherita Martorana</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+T">Tobias Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Stork%2C+L">Lise Stork</a>, 
<a href="/search/cs?searchtype=author&query=van+Ossenbruggen%2C+J">Jacco van Ossenbruggen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Traditional dataset retrieval systems index on metadata information rather
than on the data values. Thus relying primarily on manual annotations and
high-quality metadata, processes known to be labour-intensive and challenging
to automate. We propose a method to support metadata enrichment with topic
annotations of column headers using three Large Language Models (LLMs):
ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to
classify column headers based on domain-specific topics from a controlled
vocabulary. We evaluate our approach by assessing the internal consistency of
the LLMs, the inter-machine alignment, and the human-machine agreement for the
topic classification task. Additionally, we investigate the impact of
contextual information (i.e. dataset description) on the classification
outcomes. Our results suggest that ChatGPT and GoogleGemini outperform
GoogleBard for internal consistency as well as LLM-human-alignment.
Interestingly, we found that context had no impact on the LLMs performances.
This work proposes a novel approach that leverages LLMs for text classification
using a controlled topic vocabulary, which has the potential to facilitate
automated metadata enrichment, thereby enhancing dataset retrieval and the
Findability, Accessibility, Interoperability and Reusability (FAIR) of research
data on the Web.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00886" title="Abstract">arXiv:2403.00886</a> [<a href="/pdf/2403.00886" title="Download PDF">pdf</a>, <a href="/format/2403.00886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating and Correcting Performative Effects of Decision Support  Systems via Causal Domain Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boeken%2C+P">Philip Boeken</a>, 
<a href="/search/cs?searchtype=author&query=Zoeter%2C+O">Onno Zoeter</a>, 
<a href="/search/cs?searchtype=author&query=Mooij%2C+J+M">Joris M. Mooij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CLeaR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">When predicting a target variable $Y$ from features $X$, the prediction
$\hat{Y}$ can be performative: an agent might act on this prediction, affecting
the value of $Y$ that we eventually observe. Performative predictions are
deliberately prevalent in algorithmic decision support, where a Decision
Support System (DSS) provides a prediction for an agent to affect the value of
the target variable. When deploying a DSS in high-stakes settings (e.g.
healthcare, law, predictive policing, or child welfare screening) it is
imperative to carefully assess the performative effects of the DSS. In the case
that the DSS serves as an alarm for a predicted negative outcome, naive
retraining of the prediction model is bound to result in a model that
underestimates the risk, due to effective workings of the previous model. In
this work, we propose to model the deployment of a DSS as causal domain shift
and provide novel cross-domain identification results for the conditional
expectation $E[Y | X]$, allowing for pre- and post-hoc assessment of the
deployment of the DSS, and for retraining of a model that assesses the risk
under a baseline policy where the DSS is not deployed. Using a running example,
we empirically show that a repeated regression procedure provides a practical
framework for estimating these quantities, even when the data is affected by
sample selection bias and selective labelling, offering for a practical,
unified solution for multiple forms of target variable bias.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00888" title="Abstract">arXiv:2403.00888</a> [<a href="/pdf/2403.00888" title="Download PDF">pdf</a>, <a href="/format/2403.00888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Margin Discrepancy-based Adversarial Training for Multi-Domain Text  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-domain text classification (MDTC) endeavors to harness available
resources from correlated domains to enhance the classification accuracy of the
target domain. Presently, most MDTC approaches that embrace adversarial
training and the shared-private paradigm exhibit cutting-edge performance.
Unfortunately, these methods face a non-negligible challenge: the absence of
theoretical guarantees in the design of MDTC algorithms. The dearth of
theoretical underpinning poses a substantial impediment to the advancement of
MDTC algorithms. To tackle this problem, we first provide a theoretical
analysis of MDTC by decomposing the MDTC task into multiple domain adaptation
tasks. We incorporate the margin discrepancy as the measure of domain
divergence and establish a new generalization bound based on Rademacher
complexity. Subsequently, we propose a margin discrepancy-based adversarial
training (MDAT) approach for MDTC, in accordance with our theoretical analysis.
To validate the efficacy of the proposed MDAT method, we conduct empirical
studies on two MDTC benchmarks. The experimental results demonstrate that our
MDAT approach surpasses state-of-the-art baselines on both datasets.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00889" title="Abstract">arXiv:2403.00889</a> [<a href="/pdf/2403.00889" title="Download PDF">pdf</a>, <a href="/format/2403.00889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-bound Contextual Bio-ID Generation for Minimalist Wearables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orzikulova%2C+A">Adiba Orzikulova</a>, 
<a href="/search/cs?searchtype=author&query=Vasile%2C+D+A">Diana A. Vasile</a>, 
<a href="/search/cs?searchtype=author&query=Kawsar%2C+F">Fahim Kawsar</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Chulhong Min</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">As wearable devices become increasingly miniaturized and powerful, a new
opportunity arises for instant and dynamic device-to-device collaboration and
human-to-device interaction. However, this progress presents a unique
challenge: these minimalist wearables lack inherent mechanisms for real-time
authentication, posing significant risks to data privacy and overall security.
To address this, we introduce Proteus that realizes an innovative concept of
time-bound contextual bio-IDs, which are generated from on-device sensor data
and embedded into a common latent space. These bio-IDs act as a time-bound
unique user identifier that can be used to identify the wearer in a certain
context. Proteus enables dynamic and contextual device collaboration as well as
robust human-to-device interaction. Our evaluations demonstrate the
effectiveness of our method, particularly in the context of minimalist
wearables.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00890" title="Abstract">arXiv:2403.00890</a> [<a href="/pdf/2403.00890" title="Download PDF">pdf</a>, <a href="/ps/2403.00890" title="Download PostScript">ps</a>, <a href="/format/2403.00890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Android Malware Detection Through Data Augmentation Using  Wasserstein Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stalin%2C+K">Kawana Stalin</a>, 
<a href="/search/cs?searchtype=author&query=Mekoya%2C+M+B">Mikias Berhanu Mekoya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have demonstrated their versatility
across various applications, including data augmentation and malware detection.
This research explores the effectiveness of utilizing GAN-generated data to
train a model for the detection of Android malware. Given the considerable
storage requirements of Android applications, the study proposes a method to
synthetically represent data using GANs, thereby reducing storage demands. The
proposed methodology involves creating image representations of features
extracted from an existing dataset. A GAN model is then employed to generate a
more extensive dataset consisting of realistic synthetic grayscale images.
Subsequently, this synthetic dataset is utilized to train a Convolutional
Neural Network (CNN) designed to identify previously unseen Android malware
applications. The study includes a comparative analysis of the CNN's
performance when trained on real images versus synthetic images generated by
the GAN. Furthermore, the research explores variations in performance between
the Wasserstein Generative Adversarial Network (WGAN) and the Deep
Convolutional Generative Adversarial Network (DCGAN). The investigation extends
to studying the impact of image size and malware obfuscation on the
classification model's effectiveness. The data augmentation approach
implemented in this study resulted in a notable performance enhancement of the
classification model, ranging from 1.5% to 7%, depending on the dataset. The
achieved F1 score reached 97.5%. Keywords--Generative Adversarial Networks,
Android Malware, Data Augmentation, Wasserstein Generative Adversarial Network
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00891" title="Abstract">arXiv:2403.00891</a> [<a href="/pdf/2403.00891" title="Download PDF">pdf</a>, <a href="/format/2403.00891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Regularization-based Transfer Learning Method for Information  Extraction via Instructed Graph Decoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kedi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shunyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Information extraction (IE) aims to extract complex structured information
from the text. Numerous datasets have been constructed for various IE tasks,
leading to time-consuming and labor-intensive data annotations. Nevertheless,
most prevailing methods focus on training task-specific models, while the
common knowledge among different IE tasks is not explicitly modeled. Moreover,
the same phrase may have inconsistent labels in different tasks, which poses a
big challenge for knowledge transfer using a unified model. In this study, we
propose a regularization-based transfer learning method for IE (TIE) via an
instructed graph decoder. Specifically, we first construct an instruction pool
for datasets from all well-known IE tasks, and then present an instructed graph
decoder, which decodes various complex structures into a graph uniformly based
on corresponding instructions. In this way, the common knowledge shared with
existing datasets can be learned and transferred to a new dataset with new
labels. Furthermore, to alleviate the label inconsistency problem among various
IE tasks, we introduce a task-specific regularization strategy, which does not
update the gradients of two tasks with 'opposite direction'. We conduct
extensive experiments on 12 datasets spanning four IE tasks, and the results
demonstrate the great advantages of our proposed method
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00892" title="Abstract">arXiv:2403.00892</a> [<a href="/pdf/2403.00892" title="Download PDF">pdf</a>, <a href="/format/2403.00892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerFlowMultiNet: Multigraph Neural Networks for Unbalanced Three-Phase  Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghamizi%2C+S">Salah Ghamizi</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+J">Jun Cao</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+A">Aoxiang Ma</a>, 
<a href="/search/eess?searchtype=author&query=Rodriguez%2C+P">Pedro Rodriguez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Efficiently solving unbalanced three-phase power flow in distribution grids
is pivotal for grid analysis and simulation. There is a pressing need for
scalable algorithms capable of handling large-scale unbalanced power grids that
can provide accurate and fast solutions. To address this, deep learning
techniques, especially Graph Neural Networks (GNNs), have emerged. However,
existing literature primarily focuses on balanced networks, leaving a critical
gap in supporting unbalanced three-phase power grids. This letter introduces
PowerFlowMultiNet, a novel multigraph GNN framework explicitly designed for
unbalanced three-phase power grids. The proposed approach models each phase
separately in a multigraph representation, effectively capturing the inherent
asymmetry in unbalanced grids. A graph embedding mechanism utilizing message
passing is introduced to capture spatial dependencies within the power system
network. PowerFlowMultiNet outperforms traditional methods and other deep
learning approaches in terms of accuracy and computational speed. Rigorous
testing reveals significantly lower error rates and a notable hundredfold
increase in computational speed for large power networks compared to
model-based methods.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00894" title="Abstract">arXiv:2403.00894</a> [<a href="/pdf/2403.00894" title="Download PDF">pdf</a>, <a href="/format/2403.00894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A systematic evaluation of large language models for generating  programming code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wenpin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhicheng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">We systematically evaluated the performance of seven large language models in
generating programming code using various prompt strategies, programming
languages, and task difficulties. GPT-4 substantially outperforms other large
language models, including Gemini Ultra and Claude 2. The coding performance of
GPT-4 varies considerably with different prompt strategies. In most LeetCode
and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the
optimal prompt strategy outperforms 85 percent of human participants.
Additionally, GPT-4 demonstrates strong capabilities in translating code
between different programming languages and in learning from past errors. The
computational efficiency of the code generated by GPT-4 is comparable to that
of human programmers. These results suggest that GPT-4 has the potential to
serve as a reliable assistant in programming code generation and software
development.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00895" title="Abstract">arXiv:2403.00895</a> [<a href="/pdf/2403.00895" title="Download PDF">pdf</a>, <a href="/format/2403.00895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Graph-Sequential Representation Learning for Accurate  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baikalov%2C+V">Vladimir Baikalov</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+E">Evgeny Frolov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, submitted to WWW'24, short-paper track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Many recent advancements in recommender systems have focused on developing
sequence-based and graph-based approaches. Both approaches proved useful in
modeling intricate relationships within behavioral data, leading to promising
outcomes in personalized ranking and next-item recommendation tasks while
maintaining good scalability. However, they capture very different signals from
data. While the former approach represents users directly through ordered
interactions with recent items, the latter one aims to capture indirect
dependencies across the interactions graph. This paper presents a novel
multi-representational learning framework that exploits the synergies between
these two paradigms. Our empirical evaluation on several datasets demonstrates
that mutual training of sequential and graph components with the proposed
framework significantly improves recommendations performance.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00896" title="Abstract">arXiv:2403.00896</a> [<a href="/pdf/2403.00896" title="Download PDF">pdf</a>, <a href="/format/2403.00896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kedi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yishen He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since large language models (LLMs) achieve significant success in recent
years, the hallucination issue remains a challenge, numerous benchmarks are
proposed to detect the hallucination. Nevertheless, some of these benchmarks
are not naturally generated by LLMs but are intentionally induced. Also, many
merely focus on the factuality hallucination while ignoring the faithfulness
hallucination. Additionally, although dialogue pattern is more widely utilized
in the era of LLMs, current benchmarks only concentrate on sentence-level and
passage-level hallucination. In this study, we propose DiaHalu, the first
dialogue-level hallucination evaluation benchmark to our knowledge. Initially,
we integrate the collected topics into system prompts and facilitate a dialogue
between two ChatGPT3.5. Subsequently, we manually modify the contents that do
not adhere to human language conventions and then have LLMs re-generate,
simulating authentic human-machine interaction scenarios. Finally, professional
scholars annotate all the samples in the dataset. DiaHalu covers four common
multi-turn dialogue domains and five hallucination subtypes, extended from
factuality and faithfulness hallucination. Experiments through some well-known
LLMs and detection methods on the dataset show that DiaHalu is a challenging
benchmark, holding significant value for further research.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00898" title="Abstract">arXiv:2403.00898</a> [<a href="/pdf/2403.00898" title="Download PDF">pdf</a>, <a href="/ps/2403.00898" title="Download PostScript">ps</a>, <a href="/format/2403.00898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Algorithm Configuration Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iommazzo%2C+G">Gabriele Iommazzo</a>, 
<a href="/search/cs?searchtype=author&query=D%27Ambrosio%2C+C">Claudia D&#x27;Ambrosio</a>, 
<a href="/search/cs?searchtype=author&query=Frangioni%2C+A">Antonio Frangioni</a>, 
<a href="/search/cs?searchtype=author&query=Liberti%2C+L">Leo Liberti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Pardalos, P.M., Prokopyev, O.A. (eds) Encyclopedia of
  Optimization. Springer, Cham. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">The field of algorithmic optimization has significantly advanced with the
development of methods for the automatic configuration of algorithmic
parameters. This article delves into the Algorithm Configuration Problem,
focused on optimizing parametrized algorithms for solving specific instances of
decision/optimization problems. We present a comprehensive framework that not
only formalizes the Algorithm Configuration Problem, but also outlines
different approaches for its resolution, leveraging machine learning models and
heuristic strategies. The article categorizes existing methodologies into
per-instance and per-problem approaches, distinguishing between offline and
online strategies for model construction and deployment. By synthesizing these
approaches, we aim to provide a clear pathway for both understanding and
addressing the complexities inherent in algorithm configuration.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00923" title="Abstract">arXiv:2403.00923</a> [<a href="/pdf/2403.00923" title="Download PDF">pdf</a>, <a href="/format/2403.00923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Interpretable Ensemble of Graph and Language Models for Improving  Search Relevance in E-Commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+N">Nurendra Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+E+W">Edward W Huang</a>, 
<a href="/search/cs?searchtype=author&query=Subbian%2C+K">Karthik Subbian</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+C+K">Chandan K. Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The Web Conference 2024 (Industry)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The problem of search relevance in the E-commerce domain is a challenging one
since it involves understanding the intent of a user's short nuanced query and
matching it with the appropriate products in the catalog. This problem has
traditionally been addressed using language models (LMs) and graph neural
networks (GNNs) to capture semantic and inter-product behavior signals,
respectively. However, the rapid development of new architectures has created a
gap between research and the practical adoption of these techniques. Evaluating
the generalizability of these models for deployment requires extensive
experimentation on complex, real-world datasets, which can be non-trivial and
expensive. Furthermore, such models often operate on latent space
representations that are incomprehensible to humans, making it difficult to
evaluate and compare the effectiveness of different models. This lack of
interpretability hinders the development and adoption of new techniques in the
field. To bridge this gap, we propose Plug and Play Graph LAnguage Model
(PP-GLAM), an explainable ensemble of plug and play models. Our approach uses a
modular framework with uniform data processing pipelines. It employs additive
explanation metrics to independently decide whether to include (i) language
model candidates, (ii) GNN model candidates, and (iii) inter-product behavioral
signals. For the task of search relevance, we show that PP-GLAM outperforms
several state-of-the-art baselines as well as a proprietary model on real-world
multilingual, multi-regional e-commerce datasets. To promote better model
comprehensibility and adoption, we also provide an analysis of the
explainability and computational complexity of our model. We also provide the
public codebase and provide a deployment strategy for practical implementation.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00929" title="Abstract">arXiv:2403.00929</a> [<a href="/pdf/2403.00929" title="Download PDF">pdf</a>, <a href="/format/2403.00929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for  Data-Efficient Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Nasiriany%2C+S">Soroush Nasiriany</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Quantao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning has shown great potential for enabling robots to acquire
complex manipulation behaviors. However, these algorithms suffer from high
sample complexity in long-horizon tasks, where compounding errors accumulate
over the task horizons. We present PRIME (PRimitive-based IMitation with data
Efficiency), a behavior primitive-based framework designed for improving the
data efficiency of imitation learning. PRIME scaffolds robot tasks by
decomposing task demonstrations into primitive sequences, followed by learning
a high-level control policy to sequence primitives through imitation learning.
Our experiments demonstrate that PRIME achieves a significant performance
improvement in multi-stage manipulation tasks, with 10-34% higher success rates
in simulation over state-of-the-art baselines and 20-48% on physical hardware.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00930" title="Abstract">arXiv:2403.00930</a> [<a href="/pdf/2403.00930" title="Download PDF">pdf</a>, <a href="/ps/2403.00930" title="Download PostScript">ps</a>, <a href="/format/2403.00930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-free Adversarial Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuezhou Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper initiates the study of scale-free learning in Markov Decision
Processes (MDPs), where the scale of rewards/losses is unknown to the learner.
We design a generic algorithmic framework, \underline{S}cale
\underline{C}lipping \underline{B}ound (\texttt{SCB}), and instantiate this
framework in both the adversarial Multi-armed Bandit (MAB) setting and the
adversarial MDP setting. Through this framework, we achieve the first minimax
optimal expected regret bound and the first high-probability regret bound in
scale-free adversarial MABs, resolving an open problem raised in
\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth
to the first scale-free RL algorithm with a $\tilde{\mathcal{O}}(\sqrt{T})$
high-probability regret guarantee.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00932" title="Abstract">arXiv:2403.00932</a> [<a href="/pdf/2403.00932" title="Download PDF">pdf</a>, <a href="/format/2403.00932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Knowledge Distillation via Synthetic Text  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flemings%2C+J">James Flemings</a>, 
<a href="/search/cs?searchtype=author&query=Annavaram%2C+M">Murali Annavaram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Large Language models (LLMs) are achieving state-of-the-art performance in
many different downstream tasks. However, the increasing urgency of data
privacy requires LLMs to train with Differential Privacy (DP) on private data.
Concurrently it is also necessary to compress LLMs for real-life deployments on
resource-constrained devices or latency-sensitive applications. Differential
privacy and model compression generally must trade off utility loss to achieve
their objectives. Moreover, concurrently achieving both can result in even more
utility loss. To this end, we propose a novel differentially private knowledge
distillation algorithm that exploits synthetic data generated by a
differentially private LLM. The knowledge of a teacher model is transferred
onto the student in two ways: one way from the synthetic data itself, the hard
labels, and the other way by the output distribution of the teacher model
evaluated on the synthetic data, the soft labels. Furthermore, if the teacher
and student share a similar architectural structure, we can further distill
knowledge by exploiting hidden representations. Our results show that our
framework substantially improves the utility over existing baselines with
strong privacy parameters, {\epsilon} = 2, validating that we can successfully
compress autoregressive LLMs while preserving the privacy of training data.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00934" title="Abstract">arXiv:2403.00934</a> [<a href="/pdf/2403.00934" title="Download PDF">pdf</a>, <a href="/ps/2403.00934" title="Download PostScript">ps</a>, <a href="/format/2403.00934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Automated Modular Formal Verification of Critical Software:  Liveness and Completeness Thresholds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reinhard%2C+T">Tobias Reinhard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Dissertation, 226 pages (68 pages body + 141 pages appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this dissertation we describe two contributions to the state of the art in
reasoning about liveness and safety, respectively.
<br />Programs for multiprocessor machines commonly perform busy waiting for
synchronization. We propose the first separation logic for modularly verifying
termination of such programs under fair scheduling. Our logic requires the
proof author to associate a ghost signal with each busy-waiting loop and allows
such loops to iterate while their corresponding signal $s$ is not set. The
proof author further has to define a well-founded order on signals and to prove
that if the looping thread holds an obligation to set a signal $s'$, then $s'$
is ordered above $s$. By using conventional shared state invariants to
associate the state of ghost signals with the state of data structures,
programs busy-waiting for arbitrary conditions over arbitrary data structures
can be verified.
<br />Moreover, we present the first study of completeness thresholds for bounded
memory safety proofs. Specifically, we consider heap-manipulating programs that
iterate over arrays without allocating or freeing memory. In this setting, we
present the first notion of completeness thresholds for program verification
which reduce unbounded memory safety proofs to bounded ones. Furthermore, we
demonstrate that we can characterise completeness thresholds for simple classes
of array traversing programs. Finally, we suggest avenues of research to scale
this technique theoretically, i.e., to larger classes of programs (heap
manipulation, tree-like data structures), and practically by highlighting
automation opportunities.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00935" title="Abstract">arXiv:2403.00935</a> [<a href="/pdf/2403.00935" title="Download PDF">pdf</a>, <a href="/format/2403.00935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning for Security: Challenges and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A+S">Adrian Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Iyengar%2C+A">Arun Iyengar</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+A">Ashish Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many machine learning and data mining algorithms rely on the assumption that
the training and testing data share the same feature space and distribution.
However, this assumption may not always hold. For instance, there are
situations where we need to classify data in one domain, but we only have
sufficient training data available from a different domain. The latter data may
follow a distinct distribution. In such cases, successfully transferring
knowledge across domains can significantly improve learning performance and
reduce the need for extensive data labeling efforts. Transfer learning (TL) has
thus emerged as a promising framework to tackle this challenge, particularly in
security-related tasks. This paper aims to review the current advancements in
utilizing TL techniques for security. The paper includes a discussion of the
existing research gaps in applying TL in the security domain, as well as
exploring potential future research directions and issues that arise in the
context of TL-assisted security solutions.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00939" title="Abstract">arXiv:2403.00939</a> [<a href="/pdf/2403.00939" title="Download PDF">pdf</a>, <a href="/format/2403.00939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G3DR: Generative 3D Reconstruction in ImageNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+P">Pradyumna Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Elezi%2C+I">Ismail Elezi</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce a novel 3D generative method, Generative 3D Reconstruction
(G3DR) in ImageNet, capable of generating diverse and high-quality 3D objects
from single images, addressing the limitations of existing methods. At the
heart of our framework is a novel depth regularization technique that enables
the generation of scenes with high-geometric fidelity. G3DR also leverages a
pretrained language-vision model, such as CLIP, to enable reconstruction in
novel views and improve the visual realism of generations. Additionally, G3DR
designs a simple but effective sampling procedure to further improve the
quality of generations. G3DR offers diverse and efficient 3D asset generation
based on class or text conditioning. Despite its simplicity, G3DR is able to
beat state-of-theart methods, improving over them by up to 22% in perceptual
metrics and 90% in geometry scores, while needing only half of the training
time. Code is available at https://github.com/preddy5/G3DR
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00942" title="Abstract">arXiv:2403.00942</a> [<a href="/pdf/2403.00942" title="Download PDF">pdf</a>, <a href="/format/2403.00942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilience of Entropy Model in Distributed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Milin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abdi%2C+M">Mohammad Abdi</a>, 
<a href="/search/cs?searchtype=author&query=Rifat%2C+S">Shahriar Rifat</a>, 
<a href="/search/cs?searchtype=author&query=Restuccia%2C+F">Francesco Restuccia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Distributed deep neural networks (DNNs) have emerged as a key technique to
reduce communication overhead without sacrificing performance in edge computing
systems. Recently, entropy coding has been introduced to further reduce the
communication overhead. The key idea is to train the distributed DNN jointly
with an entropy model, which is used as side information during inference time
to adaptively encode latent representations into bit streams with variable
length. To the best of our knowledge, the resilience of entropy models is yet
to be investigated. As such, in this paper we formulate and investigate the
resilience of entropy models to intentional interference (e.g., adversarial
attacks) and unintentional interference (e.g., weather changes and motion
blur). Through an extensive experimental campaign with 3 different DNN
architectures, 2 entropy models and 4 rate-distortion trade-off factors, we
demonstrate that the entropy attacks can increase the communication overhead by
up to 95%. By separating compression features in frequency and spatial domain,
we propose a new defense mechanism that can reduce the transmission overhead of
the attacked input by about 9% compared to unperturbed data, with only about 2%
accuracy loss. Importantly, the proposed defense mechanism is a standalone
approach which can be applied in conjunction with approaches such as
adversarial training to further improve robustness. Code will be shared for
reproducibility.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00943" title="Abstract">arXiv:2403.00943</a> [<a href="/pdf/2403.00943" title="Download PDF">pdf</a>, <a href="/ps/2403.00943" title="Download PostScript">ps</a>, <a href="/format/2403.00943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Hardness of Fair Allocation under Ternary Valuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fitzsimmons%2C+Z">Zack Fitzsimmons</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Vignesh Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Zick%2C+Y">Yair Zick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the problem of fair allocation of indivisible items when agents have
ternary additive valuations -- each agent values each item at some fixed
integer values $a$, $b$, or $c$ that are common to all agents. The notions of
fairness we consider are max Nash welfare (MNW), when $a$, $b$, and $c$ are
non-negative, and max egalitarian welfare (MEW). We show that for any distinct
non-negative $a$, $b$, and $c$, maximizing Nash welfare is APX-hard -- i.e.,
the problem does not admit a PTAS unless P = NP. We also show that for any
distinct $a$, $b$, and $c$, maximizing egalitarian welfare is APX-hard except
for a few cases when $b = 0$ that admit efficient algorithms. These results
make significant progress towards completely characterizing the complexity of
computing exact MNW allocations and MEW allocations. En route, we resolve open
questions left by prior work regarding the complexity of computing MNW
allocations under bivalued valuations, and MEW allocations under ternary mixed
manna.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00944" title="Abstract">arXiv:2403.00944</a> [<a href="/pdf/2403.00944" title="Download PDF">pdf</a>, <a href="/format/2403.00944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Dynamic Balance in a Rat Robot via the Lateral Flexion of a  Soft Actuated Spine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zitao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+G">Genghang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Balancing oneself using the spine is a physiological alignment of the body
posture in the most efficient manner by the muscular forces for mammals. For
this reason, we can see many disabled quadruped animals can still stand or walk
even with three limbs. This paper investigates the optimization of dynamic
balance during trot gait based on the spatial relationship between the center
of mass (CoM) and support area influenced by spinal flexion. During trotting,
the robot balance is significantly influenced by the distance of the CoM to the
support area formed by diagonal footholds. In this context, lateral spinal
flexion, which is able to modify the position of footholds, holds promise for
optimizing balance during trotting. This paper explores this phenomenon using a
rat robot equipped with a soft actuated spine. Based on the lateral flexion of
the spine, we establish a kinematic model to quantify the impact of spinal
flexion on robot balance during trot gait. Subsequently, we develop an
optimized controller for spinal flexion, designed to enhance balance without
altering the leg locomotion. The effectiveness of our proposed controller is
evaluated through extensive simulations and physical experiments conducted on a
rat robot. Compared to both a non-spine based trot gait controller and a trot
gait controller with lateral spinal flexion, our proposed optimized controller
effectively improves the dynamic balance of the robot and retains the desired
locomotion during trotting.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00946" title="Abstract">arXiv:2403.00946</a> [<a href="/pdf/2403.00946" title="Download PDF">pdf</a>, <a href="/format/2403.00946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning with Very Large Dropout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bottou%2C+L">L&#xe9;on Bottou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">It is impossible today to pretend that the practice of machine learning is
compatible with the idea that training and testing data follow the same
distribution. Several authors have recently used ensemble techniques to show
how scenarios involving multiple data distributions are best served by
representations that are both richer than those obtained by regularizing for
the best in-distribution performance, and richer than those obtained under the
influence of the implicit sparsity bias of common stochastic gradient
procedures.
<br />This contribution investigates the use of very high dropout rates instead of
ensembles to obtain such rich representations. Although training a deep network
from scratch using such dropout rates is virtually impossible, fine-tuning a
large pre-trained model under such conditions is not only possible but also
achieves out-of-distribution performances that exceed those of both ensembles
and weight averaging methods such as model soups. This result has practical
significance because the importance of the fine-tuning scenario has
considerably grown in recent years. This result also provides interesting
insights on the nature of rich representations and on the intrinsically linear
nature of fine-tuning a large network using a comparatively small dataset.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00952" title="Abstract">arXiv:2403.00952</a> [<a href="/pdf/2403.00952" title="Download PDF">pdf</a>, <a href="/format/2403.00952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MediSwift: Efficient Sparse Pre-trained Biomedical Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thangarasa%2C+V">Vithursan Thangarasa</a>, 
<a href="/search/cs?searchtype=author&query=Salem%2C+M">Mahmoud Salem</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Shreyas Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+K">Kevin Leong</a>, 
<a href="/search/cs?searchtype=author&query=Hestness%2C+J">Joel Hestness</a>, 
<a href="/search/cs?searchtype=author&query=Lie%2C+S">Sean Lie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are typically trained on general source data for
various domains, but a recent surge in domain-specific LLMs has shown their
potential to outperform general-purpose models in domain-specific tasks (e.g.,
biomedicine). Although domain-specific pre-training enhances efficiency and
leads to smaller models, the computational costs of training these LLMs remain
high, posing budgeting challenges. We introduce MediSwift, a suite of
biomedical LMs that leverage sparse pre-training on domain-specific biomedical
text data. By inducing up to 75% weight sparsity during the pre-training phase,
MediSwift achieves a 2-2.5x reduction in training FLOPs. Notably, all sparse
pre-training was performed on the Cerebras CS-2 system, which is specifically
designed to realize the acceleration benefits from unstructured weight
sparsity, thereby significantly enhancing the efficiency of the MediSwift
models. Through subsequent dense fine-tuning and strategic soft prompting,
MediSwift models outperform existing LLMs up to 7B parameters on biomedical
tasks, setting new benchmarks w.r.t efficiency-accuracy on tasks such as
PubMedQA. Our results show that sparse pre-training, along with dense
fine-tuning and soft prompting, offers an effective method for creating
high-performing, computationally efficient models in specialized domains.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00953" title="Abstract">arXiv:2403.00953</a> [<a href="/pdf/2403.00953" title="Download PDF">pdf</a>, <a href="/ps/2403.00953" title="Download PostScript">ps</a>, <a href="/format/2403.00953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge  Graph Construction Based on Ontologies-enhanced Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cross%2C+A">Adam Cross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objectives: Our objective is to create an end-to-end system called AutoRD,
which automates extracting information from clinical text about rare diseases.
We have conducted various tests to evaluate the performance of AutoRD and
highlighted its strengths and limitations in this paper.
<br />Materials and Methods: Our system, AutoRD, is a software pipeline involving
data preprocessing, entity extraction, relation extraction, entity calibration,
and knowledge graph construction. We implement this using large language models
and medical knowledge graphs developed from open-source medical ontologies. We
quantitatively evaluate our system on entity extraction, relation extraction,
and the performance of knowledge graph construction.
<br />Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement
compared to the base LLM. In detail, AutoRD achieves an overall entity
extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%,
symptom_and_sign: 46.1%, anaphor: 67.5%) and an overall relation extraction F1
score of 38.6% (produces: 34.7%, increases_risk_of: 12.4%, is_a: 37.4%,
is_acronym: 44.1%, is_synonym: 16.3%, anaphora: 57.5%). Our qualitative
experiment also demonstrates that the performance in constructing the knowledge
graph is commendable.
<br />Discussion: AutoRD demonstrates the potential of LLM applications in rare
disease detection. This improvement is attributed to several design, including
the integration of ontologies-enhanced LLMs.
<br />Conclusion: AutoRD is an automated end-to-end system for extracting rare
disease information from text to build knowledge graphs. It uses
ontologies-enhanced LLMs for a robust medical knowledge base. The superior
performance of AutoRD is validated by experimental evaluations, demonstrating
the potential of LLMs in healthcare.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00954" title="Abstract">arXiv:2403.00954</a> [<a href="/pdf/2403.00954" title="Download PDF">pdf</a>, <a href="/format/2403.00954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClassInSight: Designing Conversation Support Tools to Visualize  Classroom Discussion for Personalized Teacher Professional Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngoon%2C+T+J">Tricia J. Ngoon</a>, 
<a href="/search/cs?searchtype=author&query=Sushil%2C+S">S Sushil</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+A">Angela Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+U">Ung-Sang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Venkatraman%2C+S">Saranya Venkatraman</a>, 
<a href="/search/cs?searchtype=author&query=Thawani%2C+N">Neil Thawani</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Clarke%2C+S">Sherice Clarke</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+J">John Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Ogan%2C+A">Amy Ogan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Teaching is one of many professions for which personalized feedback and
reflection can help improve dialogue and discussion between the professional
and those they serve. However, professional development (PD) is often
impersonal as human observation is labor-intensive. Data-driven PD tools in
teaching are of growing interest, but open questions about how professionals
engage with their data in practice remain. In this paper, we present
ClassInSight, a tool that visualizes three levels of teachers' discussion data
and structures reflection. Through 22 reflection sessions and interviews with 5
high school science teachers, we found themes related to dissonance,
contextualization, and sustainability in how teachers engaged with their data
in the tool and in how their professional vision, the use of professional
expertise to interpret events, shifted over time. We discuss guidelines for
these conversational support tools to support personalized PD in professions
beyond teaching where conversation and interaction are important.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00955" title="Abstract">arXiv:2403.00955</a> [<a href="/pdf/2403.00955" title="Download PDF">pdf</a>, <a href="/format/2403.00955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Presence and the State-of-Practice of Software Architects in the  Brazilian Industry - A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neto%2C+V+V+G">Valdemar Vicente Graciano Neto</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+D+L">Diana Lorena Santos</a>, 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7a%2C+A+G">Andrey Gon&#xe7;alves Fran&#xe7;a</a>, 
<a href="/search/cs?searchtype=author&query=Frantz%2C+R+Z">Rafael Z. Frantz</a>, 
<a href="/search/cs?searchtype=author&query=de%2C+E">Edson de Oliveira-Jr</a>, 
<a href="/search/cs?searchtype=author&query=Mohsin%2C+A">Ahmad Mohsin</a>, 
<a href="/search/cs?searchtype=author&query=Kassab%2C+M">Mohamad Kassab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context: Software architecture intensely impacts the software quality.
Therefore, the professional assigned to carry out the design, maintenance and
evolution of architectures needs to have certain knowledge and skills in order
not to compromise the resulting application. Objective: The aim of this work is
to understand the characteristics of the companies regarding the presence or
absence of software architects in Brazil. Method: This work uses the Survey
research as a means to collect evidence from professionals with the software
architect profile, besides descriptive statistics and thematic analysis to
analyze the results. Results: The study collected data from 105 professionals
distributed in 24 Brazilian states. Results reveal that (i) not all companies
have a software architect, (ii) in some cases, other professionals perform the
activities of a software architect and (iii) there are companies that, even
having a software architecture professional, have other roles also performing
the duties of such a professional. Conclusions: Professionals hired as software
architects have higher salaries than those hired in other roles that carry out
such activity, although many of those other professionals still have duties
that are typical of software architects.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00956" title="Abstract">arXiv:2403.00956</a> [<a href="/pdf/2403.00956" title="Download PDF">pdf</a>, <a href="/format/2403.00956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suturing Tasks Automation Based on Skills Learned From Demonstrations: A  Simulation Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haoying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yiwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kazanzides%2C+P">Peter Kazanzides</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+G+S">Gregory S. Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this work, we develop an open-source surgical simulation environment that
includes a realistic model obtained by MRI-scanning a physical phantom, for the
purpose of training and evaluating a Learning from Demonstration (LfD)
algorithm for autonomous suturing. The LfD algorithm utilizes Dynamic Movement
Primitives (DMP) and Locally Weighted Regression (LWR), but focuses on the
needle trajectory, rather than the instruments, to obtain better generality
with respect to needle grasps. We conduct a user study to collect multiple
suturing demonstrations and perform a comprehensive analysis of the ability of
the LfD algorithm to generalize from a demonstration at one location in one
phantom to different locations in the same phantom and to a different phantom.
Our results indicate good generalization, on the order of 91.5%, when learning
from more experienced subjects, indicating the need to integrate skill
assessment in the future.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00963" title="Abstract">arXiv:2403.00963</a> [<a href="/pdf/2403.00963" title="Download PDF">pdf</a>, <a href="/format/2403.00963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree-Regularized Tabular Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Table Representation Learning Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Tabular neural network (NN) has attracted remarkable attentions and its
recent advances have gradually narrowed the performance gap with respect to
tree-based models on many public datasets. While the mainstreams focus on
calibrating NN to fit tabular data, we emphasize the importance of homogeneous
embeddings and alternately concentrate on regularizing tabular inputs through
supervised pretraining. Specifically, we extend a recent work (DeepTLF) and
utilize the structure of pretrained tree ensembles to transform raw variables
into a single vector (T2V), or an array of tokens (T2T). Without loss of space
efficiency, these binarized embeddings can be consumed by canonical tabular NN
with fully-connected or attention-based building blocks. Through quantitative
experiments on 88 OpenML datasets with binary classification task, we validated
that the proposed tree-regularized representation not only tapers the
difference with respect to tree-based models, but also achieves on-par and
better performance when compared with advanced NN models. Most importantly, it
possesses better robustness and can be easily scaled and generalized as
standalone encoder for tabular modality. Codes:
https://github.com/milanlx/tree-regularized-embedding.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00964" title="Abstract">arXiv:2403.00964</a> [<a href="/pdf/2403.00964" title="Download PDF">pdf</a>, <a href="/format/2403.00964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM  Hallucination Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borra%2C+F">Federico Borra</a>, 
<a href="/search/cs?searchtype=author&query=Savelli%2C+C">Claudio Savelli</a>, 
<a href="/search/cs?searchtype=author&query=Rosso%2C+G">Giacomo Rosso</a>, 
<a href="/search/cs?searchtype=author&query=Koudounas%2C+A">Alkis Koudounas</a>, 
<a href="/search/cs?searchtype=author&query=Giobergia%2C+F">Flavio Giobergia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under revision at SemEval 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In Natural Language Generation (NLG), contemporary Large Language Models
(LLMs) face several challenges, such as generating fluent yet inaccurate
outputs and reliance on fluency-centric metrics. This often leads to neural
networks exhibiting "hallucinations". The SHROOM challenge focuses on
automatically identifying these hallucinations in the generated text. To tackle
these issues, we introduce two key components, a data augmentation pipeline
incorporating LLM-assisted pseudo-labelling and sentence rephrasing, and a
voting ensemble from three models pre-trained on Natural Language Inference
(NLI) tasks and fine-tuned on diverse datasets.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00970" title="Abstract">arXiv:2403.00970</a> [<a href="/pdf/2403.00970" title="Download PDF">pdf</a>, <a href="/ps/2403.00970" title="Download PostScript">ps</a>, <a href="/format/2403.00970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nussbaum Function Based Approach for Tracking Control of Robot  Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nohooji%2C+H+R">Hamed Rahimi Nohooji</a>, 
<a href="/search/cs?searchtype=author&query=Voos%2C+H">Holger Voos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper introduces a novel Nussbaum function-based PID control for robotic
manipulators. The integration of the Nussbaum function into the PID framework
provides a solution with a simple structure that effectively tackles the
challenge of unknown control directions. Stability is achieved through a
combination of neural network-based estimation and Lyapunov analysis,
facilitating automatic gain adjustment without the need for system dynamics.
Our approach offers a gain determination with minimum parameter requirements,
significantly reducing the complexity and enhancing the efficiency of robotic
manipulator control. The paper guarantees that all signals within the
closed-loop system remain bounded. Lastly, numerical simulations validate the
theoretical framework, confirming the effectiveness of the proposed control
strategy in enhancing robotic manipulator control.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00972" title="Abstract">arXiv:2403.00972</a> [<a href="/pdf/2403.00972" title="Download PDF">pdf</a>, <a href="/format/2403.00972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Police Force Resource Allocation using Adversarial Optimal  Transport with Incomplete Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yinan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Juntao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Adversarial optimal transport has been proven useful as a mathematical
formulation to model resource allocation problems to maximize the efficiency of
transportation with an adversary, who modifies the data. It is often the case,
however, that only the adversary knows which nodes are malicious and which are
not. In this paper we formulate the problem of seeking adversarial optimal
transport into Bayesian games. We construct the concept of Bayesian equilibrium
and design a distributed algorithm that achieve those equilibria, making our
model applicable to large-scale networks. Keywords: game theory, crime control,
Markov games
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00974" title="Abstract">arXiv:2403.00974</a> [<a href="/pdf/2403.00974" title="Download PDF">pdf</a>, <a href="/ps/2403.00974" title="Download PostScript">ps</a>, <a href="/format/2403.00974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motif distribution and function of sparse deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahn%2C+O+T">Olivia T. Zahn</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+T+L">Thomas L. Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We characterize the connectivity structure of feed-forward, deep neural
networks (DNNs) using network motif theory. To address whether a particular
motif distribution is characteristic of the training task, or function of the
DNN, we compare the connectivity structure of 350 DNNs trained to simulate a
bio-mechanical flight control system with different randomly initialized
parameters. We develop and implement algorithms for counting second- and
third-order motifs and calculate their significance using their Z-score. The
DNNs are trained to solve the inverse problem of the flight dynamics model in
Bustamante, et al. (2022) (i.e., predict the controls necessary for controlled
flight from the initial and final state-space inputs) and are sparsified
through an iterative pruning and retraining algorithm Zahn, et al. (2022). We
show that, despite random initialization of network parameters, enforced
sparsity causes DNNs to converge to similar connectivity patterns as
characterized by their motif distributions. The results suggest how neural
network function can be encoded in motif distributions, suggesting a variety of
experiments for informing function and control.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00975" title="Abstract">arXiv:2403.00975</a> [<a href="/pdf/2403.00975" title="Download PDF">pdf</a>, <a href="/format/2403.00975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equipment Health Assessment: Time Series Analysis for Wind Turbine  Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Backhus%2C+J">Jana Backhus</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A+R">Aniruddha Rajendra Rao</a>, 
<a href="/search/cs?searchtype=author&query=Venkatraman%2C+C">Chandrasekar Venkatraman</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+A">Abhishek Padmanabhan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A+V">A.Vinoth Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+C">Chetan Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 Pages, 17 Figures, 3 Tables, Submitted at Applied Sciences (MDPI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Functional Analysis (math.FA); Applications (stat.AP)

</div>
<p class="mathjax">In this study, we leverage SCADA data from diverse wind turbines to predict
power output, employing advanced time series methods, specifically Functional
Neural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key
innovation lies in the ensemble of FNN and LSTM models, capitalizing on their
collective learning. This ensemble approach outperforms individual models,
ensuring stable and accurate power output predictions. Additionally, machine
learning techniques are applied to detect wind turbine performance
deterioration, enabling proactive maintenance strategies and health assessment.
Crucially, our analysis reveals the uniqueness of each wind turbine,
necessitating tailored models for optimal predictions. These insight
underscores the importance of providing automatized customization for different
turbines to keep human modeling effort low. Importantly, the methodologies
developed in this analysis are not limited to wind turbines; they can be
extended to predict and optimize performance in various machinery, highlighting
the versatility and applicability of our research across diverse industrial
contexts.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00976" title="Abstract">arXiv:2403.00976</a> [<a href="/pdf/2403.00976" title="Download PDF">pdf</a>, <a href="/format/2403.00976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Spatial-Temporal Calibration for Camera and Global Pose Sensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Junlin Song</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+A">Antoine Richard</a>, 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M">Miguel Olivares-Mendez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In robotics, motion capture systems have been widely used to measure the
accuracy of localization algorithms. Moreover, this infrastructure can also be
used for other computer vision tasks, such as the evaluation of Visual
(-Inertial) SLAM dynamic initialization, multi-object tracking, or automatic
annotation. Yet, to work optimally, these functionalities require having
accurate and reliable spatial-temporal calibration parameters between the
camera and the global pose sensor. In this study, we provide two novel
solutions to estimate these calibration parameters. Firstly, we design an
offline target-based method with high accuracy and consistency.
Spatial-temporal parameters, camera intrinsic, and trajectory are optimized
simultaneously. Then, we propose an online target-less method, eliminating the
need for a calibration target and enabling the estimation of time-varying
spatial-temporal parameters. Additionally, we perform detailed observability
analysis for the target-less method. Our theoretical findings regarding
observability are validated by simulation experiments and provide explainable
guidelines for calibration. Finally, the accuracy and consistency of two
proposed methods are evaluated with hand-held real-world datasets where
traditional hand-eye calibration method do not work.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00977" title="Abstract">arXiv:2403.00977</a> [<a href="/pdf/2403.00977" title="Download PDF">pdf</a>, <a href="/format/2403.00977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Up Adaptive Filter Optimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casebeer%2C+J">Jonah Casebeer</a>, 
<a href="/search/cs?searchtype=author&query=Bryan%2C+N+J">Nicholas J. Bryan</a>, 
<a href="/search/cs?searchtype=author&query=Smaragdis%2C+P">Paris Smaragdis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce a new online adaptive filtering method called supervised
multi-step adaptive filters (SMS-AF). Our method uses neural networks to
control or optimize linear multi-delay or multi-channel frequency-domain
filters and can flexibly scale-up performance at the cost of increased compute
-- a property rarely addressed in the AF literature, but critical for many
applications. To do so, we extend recent work with a set of improvements
including feature pruning, a supervised loss, and multiple optimization steps
per time-frame. These improvements work in a cohesive manner to unlock scaling.
Furthermore, we show how our method relates to Kalman filtering and
meta-adaptive filtering, making it seamlessly applicable to a diverse set of AF
tasks. We evaluate our method on acoustic echo cancellation (AEC) and
multi-channel speech enhancement tasks and compare against several baselines on
standard synthetic and real-world datasets. Results show our method performance
scales with inference cost and model capacity, yields multi-dB performance
gains for both tasks, and is real-time capable on a single CPU core.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00980" title="Abstract">arXiv:2403.00980</a> [<a href="/pdf/2403.00980" title="Download PDF">pdf</a>, <a href="/format/2403.00980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found  Using Counterfactuals As Guides?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aryal%2C+S">Saugat Aryal</a>, 
<a href="/search/cs?searchtype=author&query=Keane%2C+M+T">Mark T. Keane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recently, counterfactuals using "if-only" explanations have become very
popular in eXplainable AI (XAI), as they describe which changes to
feature-inputs of a black-box AI system result in changes to a (usually
negative) decision-outcome. Even more recently, semi-factuals using "even-if"
explanations have gained more attention. They elucidate the feature-input
changes that do \textit{not} change the decision-outcome of the AI system, with
a potential to suggest more beneficial recourses. Some semi-factual methods use
counterfactuals to the query-instance to guide semi-factual production
(so-called counterfactual-guided methods), whereas others do not (so-called
counterfactual-free methods). In this work, we perform comprehensive tests of 8
semi-factual methods on 7 datasets using 5 key metrics, to determine whether
counterfactual guidance is necessary to find the best semi-factuals. The
results of these tests suggests not, but rather that computing other aspects of
the decision space lead to better semi-factual XAI.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00981" title="Abstract">arXiv:2403.00981</a> [<a href="/pdf/2403.00981" title="Download PDF">pdf</a>, <a href="/format/2403.00981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Conceptual Model for Data Storytelling Highlights in Business  Intelligence Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vassiliadis%2C+P">Panos Vassiliadis</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+P">Patrick Marcel</a>, 
<a href="/search/cs?searchtype=author&query=Outa%2C+F+E">Faten El Outa</a>, 
<a href="/search/cs?searchtype=author&query=Peralta%2C+V">Veronika Peralta</a>, 
<a href="/search/cs?searchtype=author&query=Gkitsakis%2C+D">Dimos Gkitsakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">We introduce a conceptual model for highlights to support data analysis and
storytelling in the domain of Business Intelligence, via the automated
extraction, representation, and exploitation of highlights revealing key facts
that are hidden in the data with which a data analyst works. The model builds
on the concepts of Holistic and Elementary Highlights, along with their
context, constituents and interrelationships, whose synergy can identify
internal properties, patterns and key facts in a dataset being analyzed.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00982" title="Abstract">arXiv:2403.00982</a> [<a href="/pdf/2403.00982" title="Download PDF">pdf</a>, <a href="/format/2403.00982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LocalRQA: From Generating Data to Locally Training, Testing, and  Deploying Retrieval-Augmented QA Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yunan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieval-augmented question-answering systems combine retrieval techniques
with large language models to provide answers that are more accurate and
informative. Many existing toolkits allow users to quickly build such systems
using off-the-shelf models, but they fall short in supporting researchers and
developers to customize the model training, testing, and deployment process. We
propose LocalRQA, an open-source toolkit that features a wide selection of
model training algorithms, evaluation methods, and deployment tools curated
from the latest research. As a showcase, we build QA systems using online
documentation obtained from Databricks and Faire's websites. We find 7B-models
trained and deployed using LocalRQA reach a similar performance compared to
using OpenAI's text-ada-002 and GPT-4-turbo.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00986" title="Abstract">arXiv:2403.00986</a> [<a href="/pdf/2403.00986" title="Download PDF">pdf</a>, <a href="/format/2403.00986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging Text Transformer Models from Different Initializations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+N">Neha Verma</a>, 
<a href="/search/cs?searchtype=author&query=Elbayad%2C+M">Maha Elbayad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work on one-shot permutation-based model merging has shown impressive
low- or zero-barrier mode connectivity between models from completely different
initializations. However, this line of work has not yet extended to the
Transformer architecture, despite its dominant popularity in the language
domain. Therefore, in this work, we investigate the extent to which separate
Transformer minima learn similar features, and propose a model merging
technique to investigate the relationship between these minima in the loss
landscape. The specifics of the architecture, like its residual connections,
multi-headed attention, and discrete, sequential input, require specific
interventions in order to compute model permutations that remain within the
same functional equivalence class. In merging these models with our method, we
consistently find lower loss barriers between minima compared to model
averaging for several models trained on a masked-language modeling task or
fine-tuned on a language understanding benchmark. Our results show that the
minima of these models are less sharp and isolated than previously understood,
and provide a basis for future work on merging separately trained Transformer
models.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00987" title="Abstract">arXiv:2403.00987</a> [<a href="/pdf/2403.00987" title="Download PDF">pdf</a>, <a href="/format/2403.00987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite Distributed Learning and Synchronization of Nonlinear  Multi-Agent Systems with Complete Uncertain Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jandaghi%2C+E">Emadodin Jandaghi</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+D+L">Dalton L. Stein</a>, 
<a href="/search/cs?searchtype=author&query=Hoburg%2C+A">Adam Hoburg</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingxi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chengzhi Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper addresses the challenging problem of composite synchronization and
learning control in a network of multi-agent robotic manipulator systems
operating under heterogeneous nonlinear uncertainties within a leader-follower
framework. A novel two-layer distributed adaptive learning control strategy is
introduced, comprising a first-layer distributed cooperative estimator and a
second-layer decentralized deterministic learning controller. The primary
objective of the first layer is to facilitate each robotic agent's estimation
of the leader's information. The second layer is responsible for both enabling
individual robot agents to track desired reference trajectories and accurately
identifying and learning their nonlinear uncertain dynamics. The proposed
distributed learning control scheme represents an advancement in the existing
literature due to its ability to manage robotic agents with completely
uncertain dynamics including uncertain mass matrices. This framework allows the
robotic control to be environment-independent which can be used in various
settings, from underwater to space where identifying system dynamics parameters
is challenging. The stability and parameter convergence of the closed-loop
system are rigorously analyzed using the Lyapunov method. Numerical simulations
conducted on multi-agent robot manipulators validate the effectiveness of the
proposed scheme. The identified nonlinear dynamics can be saved and reused
whenever the system restarts.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00988" title="Abstract">arXiv:2403.00988</a> [<a href="/pdf/2403.00988" title="Download PDF">pdf</a>, <a href="/format/2403.00988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Robot Formations: Balancing Range-Based Observability and  User-Defined Configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+S">Syed Shabbir Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Shalaby%2C+M+A">Mohammed Ayman Shalaby</a>, 
<a href="/search/cs?searchtype=author&query=Ny%2C+J+L">Jerome Le Ny</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James Richard Forbes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, submitted to IEEE International Conference on Intelligent Robots and Systems 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces a set of customizable and novel cost functions that
enable the user to easily specify desirable robot formations, such as a
``high-coverage'' infrastructure-inspection formation, while maintaining high
relative pose estimation accuracy. The overall cost function balances the need
for the robots to be close together for good ranging-based relative
localization accuracy and the need for the robots to achieve specific tasks,
such as minimizing the time taken to inspect a given area. The formations found
by minimizing the aggregated cost function are evaluated in a coverage path
planning task in simulation and experiment, where the robots localize
themselves and unknown landmarks using a simultaneous localization and mapping
algorithm based on the extended Kalman filter. Compared to an optimal formation
that maximizes ranging-based relative localization accuracy, these formations
significantly reduce the time to cover a given area with minimal impact on
relative pose estimation accuracy.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00989" title="Abstract">arXiv:2403.00989</a> [<a href="/pdf/2403.00989" title="Download PDF">pdf</a>, <a href="/format/2403.00989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Non-Interactive Simulation of Distributed Sources with Finite  Alphabets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salehi%2C+H+A">Hojat Allah Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Shirani%2C+F">Farhad Shirani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP); Probability (math.PR)

</div>
<p class="mathjax">This work presents a Fourier analysis framework for the non-interactive
source simulation (NISS) problem. Two distributed agents observe a pair of
sequences $X^d$ and $Y^d$ drawn according to a joint distribution $P_{X^dY^d}$.
The agents aim to generate outputs $U=f_d(X^d)$ and $V=g_d(Y^d)$ with a joint
distribution sufficiently close in total variation to a target distribution
$Q_{UV}$. Existing works have shown that the NISS problem with finite-alphabet
outputs is decidable. For the binary-output NISS, an upper-bound to the input
complexity was derived which is
$O(\exp\operatorname{poly}(\frac{1}{\epsilon}))$. In this work, the input
complexity and algorithm design are addressed in several classes of NISS
scenarios. For binary-output NISS scenarios with doubly-symmetric binary
inputs, it is shown that the input complexity is
$\Theta(\log{\frac{1}{\epsilon}})$, thus providing a super-exponential
improvement in input complexity. An explicit characterization of the simulating
pair of functions is provided. For general finite-input scenarios, a
constructive algorithm is introduced that explicitly finds the simulating
functions $(f_d(X^d),g_d(Y^d))$. The approach relies on a novel Fourier
analysis framework. Various numerical simulations of NISS scenarios with IID
inputs are provided. Furthermore, to illustrate the general applicability of
the Fourier framework, several examples with non-IID inputs, including
entanglement-assisted NISS and NISS with Markovian inputs are provided.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00990" title="Abstract">arXiv:2403.00990</a> [<a href="/pdf/2403.00990" title="Download PDF">pdf</a>, <a href="/format/2403.00990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulation Comparison for Timeline Construction using LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+K">Kimihiro Hasegawa</a>, 
<a href="/search/cs?searchtype=author&query=Kandukuri%2C+N">Nikhil Kandukuri</a>, 
<a href="/search/cs?searchtype=author&query=Holm%2C+S">Susan Holm</a>, 
<a href="/search/cs?searchtype=author&query=Yamakawa%2C+Y">Yukari Yamakawa</a>, 
<a href="/search/cs?searchtype=author&query=Mitamura%2C+T">Teruko Mitamura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Constructing a timeline requires identifying the chronological order of
events in an article. In prior timeline construction datasets, temporal orders
are typically annotated by either event-to-time anchoring or event-to-event
pairwise ordering, both of which suffer from missing temporal information. To
mitigate the issue, we develop a new evaluation dataset, TimeSET, consisting of
single-document timelines with document-level order annotation. TimeSET
features saliency-based event selection and partial ordering, which enable a
practical annotation workload. Aiming to build better automatic timeline
construction systems, we propose a novel evaluation framework to compare
multiple task formulations with TimeSET by prompting open LLMs, i.e., Llama 2
and Flan-T5. Considering that identifying temporal orders of events is a core
subtask in timeline construction, we further benchmark open LLMs on existing
event temporal ordering datasets to gain a robust understanding of their
capabilities. Our experiments show that (1) NLI formulation with Flan-T5
demonstrates a strong performance among others, while (2) timeline construction
and event temporal ordering are still challenging tasks for few-shot LLMs. Our
code and data are available at https://github.com/kimihiroh/timeset.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00991" title="Abstract">arXiv:2403.00991</a> [<a href="/pdf/2403.00991" title="Download PDF">pdf</a>, <a href="/format/2403.00991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SELFI: Autonomous Self-Improvement with Reinforcement Learning for  Social Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirose%2C+N">Noriaki Hirose</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Stachowicz%2C+K">Kyle Stachowicz</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+A">Ajay Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Autonomous self-improving robots that interact and improve with experience
are key to the real-world deployment of robotic systems. In this paper, we
propose an online learning method, SELFI, that leverages online robot
experience to rapidly fine-tune pre-trained control policies efficiently. SELFI
applies online model-free reinforcement learning on top of offline model-based
learning to bring out the best parts of both learning paradigms. Specifically,
SELFI stabilizes the online learning process by incorporating the same
model-based learning objective from offline pre-training into the Q-values
learned with online model-free reinforcement learning. We evaluate SELFI in
multiple real-world environments and report improvements in terms of collision
avoidance, as well as more socially compliant behavior, measured by a human
user study. SELFI enables us to quickly learn useful robotic behaviors with
less human interventions such as pre-emptive behavior for the pedestrians,
collision avoidance for small and transparent objects, and avoiding travel on
uneven floor surfaces. We provide supplementary videos to demonstrate the
performance of our fine-tuned policy on our project page.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00992" title="Abstract">arXiv:2403.00992</a> [<a href="/pdf/2403.00992" title="Download PDF">pdf</a>, <a href="/ps/2403.00992" title="Download PostScript">ps</a>, <a href="/format/2403.00992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing a Novel Quantum-Resistant Secret Key Establishment Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lizama-P%C3%A9rez%2C+L+A">Luis Adri&#xe1;n Lizama-P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We introduce a new approach for secret key establishment that resists quantum
cryptanalysis. The method claims full secrecy as its primary goal. Our approach
guarantees private communication at a crucial moment in the quantum revolution.
We will discuss how the system achieves homomorphic encryption. Comparatively,
our system provides the smallest public and private key sizes available.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00993" title="Abstract">arXiv:2403.00993</a> [<a href="/pdf/2403.00993" title="Download PDF">pdf</a>, <a href="/format/2403.00993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Information Structure in Reinforcement Learning for  Partially-Observable Sequential Teams and Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altabaa%2C+A">Awni Altabaa</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">In a sequential decision-making problem, the information structure is the
description of how events in the system occurring at different points in time
affect each other. Classical models of reinforcement learning (e.g., MDPs,
POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular
information structure, while more general models like predictive state
representations do not explicitly model the information structure. By contrast,
real-world sequential decision-making problems typically involve a complex and
time-varying interdependence of system variables, requiring a rich and flexible
representation of information structure.
<br />In this paper, we argue for the perspective that explicit representation of
information structures is an important component of analyzing and solving
reinforcement learning problems. We propose novel reinforcement learning models
with an explicit representation of information structure, capturing classical
models as special cases. We show that this leads to a richer analysis of
sequential decision-making problems and enables more tailored algorithm design.
In particular, we characterize the "complexity" of the observable dynamics of
any sequential decision-making problem through a graph-theoretic analysis of
the DAG representation of its information structure. The central quantity in
this analysis is the minimal set of variables that $d$-separates the past
observations from future observations. Furthermore, through constructing a
generalization of predictive state representations, we propose tailored
reinforcement learning algorithms and prove that the sample complexity is in
part determined by the information structure. This recovers known tractability
results and gives a novel perspective on reinforcement learning in general
sequential decision-making problems, providing a systematic way of identifying
new tractable classes of problems.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00994" title="Abstract">arXiv:2403.00994</a> [<a href="/pdf/2403.00994" title="Download PDF">pdf</a>, <a href="/format/2403.00994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Prompt-Based Large Language Models: Predicting Pandemic  Health Decisions and Outcomes Through Social Media Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaohan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Carik%2C+B">Buse Carik</a>, 
<a href="/search/cs?searchtype=author&query=Gunturi%2C+U+S">Uma Sushmitha Gunturi</a>, 
<a href="/search/cs?searchtype=author&query=Reyna%2C+V">Valerie Reyna</a>, 
<a href="/search/cs?searchtype=author&query=Rho%2C+E+H">Eugenia H. Rho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We introduce a multi-step reasoning framework using prompt-based LLMs to
examine the relationship between social media language patterns and trends in
national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the
importance of gists of causal coherence in effective health communication, we
introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework,
to identify gists at-scale. Using RBIC, we systematically extract gists from
subreddit discussions opposing COVID-19 health measures (Study 1). We then
track how these gists evolve across key events (Study 2) and assess their
influence on online engagement (Study 3). Finally, we investigate how the
volume of gists is associated with national health trends like vaccine uptake
and hospitalizations (Study 4). Our work is the first to empirically link
social media linguistic patterns to real-world public health trends,
highlighting the potential of prompt-based LLMs in identifying critical online
discussion patterns that can form the basis of public health communication
strategies.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00995" title="Abstract">arXiv:2403.00995</a> [<a href="/pdf/2403.00995" title="Download PDF">pdf</a>, <a href="/format/2403.00995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spark Optimizer for Adaptive, Fine-Grained Parameter Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenghao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guyard%2C+P">Philippe Guyard</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+Y">Yanlei Diao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">As Spark becomes a common big data analytics platform, its growing complexity
makes automatic tuning of numerous parameters critical for performance. Our
work on Spark parameter tuning is particularly motivated by two recent trends:
Spark's Adaptive Query Execution (AQE) based on runtime statistics, and the
increasingly popular Spark cloud deployments that make cost-performance
reasoning crucial for the end user. This paper presents our design of a Spark
optimizer that controls all tunable parameters (collectively called a
"configuration") of each query in the new AQE architecture to explore its
performance benefits and, at the same time, casts the tuning problem in the
theoretically sound multi-objective optimization setting to better adapt to
user cost-performance preferences.
<br />To this end, we propose a novel hybrid compile-time/runtime approach to
multi-granularity tuning of diverse, correlated Spark parameters, as well as a
suite of modeling and optimization techniques to solve the tuning problem in
the MOO setting while meeting the stringent time constraint of 1-2 seconds for
cloud use. Our evaluation results using the TPC-H and TPC-DS benchmarks
demonstrate the superior performance of our approach: (i) When prioritizing
latency, it achieves an average of 61% and 64% reduction for TPC-H and TPC-DS,
respectively, under the solving time of 0.62-0.83 sec, outperforming the most
competitive MOO method that reduces only 18-25% latency with high solving time
of 2.4-15 sec. (ii) When shifting preferences between latency and cost, our
approach dominates the solutions from alternative methods by a wide margin,
exhibiting superior adaptability to varying preferences.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00998" title="Abstract">arXiv:2403.00998</a> [<a href="/pdf/2403.00998" title="Download PDF">pdf</a>, <a href="/format/2403.00998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictions from language models for multiple-choice tasks are not  robust under variation of scoring methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsvilodub%2C+P">Polina Tsvilodub</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hening Wang</a>, 
<a href="/search/cs?searchtype=author&query=Grosch%2C+S">Sharon Grosch</a>, 
<a href="/search/cs?searchtype=author&query=Franke%2C+M">Michael Franke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper systematically compares different methods of deriving item-level
predictions of language models for multiple-choice tasks. It compares scoring
methods for answer options based on free generation of responses, various
probability-based scores, a Likert-scale style rating method, and embedding
similarity. In a case study on pragmatic language interpretation, we find that
LLM predictions are not robust under variation of method choice, both within a
single LLM and across different LLMs. As this variability entails pronounced
researcher degrees of freedom in reporting results, knowledge of the
variability is crucial to secure robustness of results and research integrity.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00999" title="Abstract">arXiv:2403.00999</a> [<a href="/pdf/2403.00999" title="Download PDF">pdf</a>, <a href="/format/2403.00999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Dataset Distillation with Subtask Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez-Melis%2C+D">David Alvarez-Melis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">What does a neural network learn when training from a task-specific dataset?
Synthesizing this knowledge is the central idea behind Dataset Distillation,
which recent work has shown can be used to compress large datasets into a small
set of input-label pairs ($\textit{prototypes}$) that capture essential aspects
of the original dataset. In this paper, we make the key observation that
existing methods distilling into explicit prototypes are very often suboptimal,
incurring in unexpected storage cost from distilled labels. In response, we
propose $\textit{Distributional Dataset Distillation}$ (D3), which encodes the
data using minimal sufficient per-class statistics and paired with a decoder,
we distill dataset into a compact distributional representation that is more
memory-efficient compared to prototype-based methods. To scale up the process
of learning these representations, we propose $\textit{Federated
distillation}$, which decomposes the dataset into subsets, distills them in
parallel using sub-task experts and then re-aggregates them. We thoroughly
evaluate our algorithm on a three-dimensional metric and show that our method
achieves state-of-the-art results on TinyImageNet and ImageNet-1K.
Specifically, we outperform the prior art by $6.9\%$ on ImageNet-1K under the
storage budget of 2 images per class.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01002" title="Abstract">arXiv:2403.01002</a> [<a href="/pdf/2403.01002" title="Download PDF">pdf</a>, <a href="/format/2403.01002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Structuring Improves LLM-Based Evaluation of Clinical Text  Summaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gero%2C+Z">Zelalem Gero</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+C">Chandan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiqing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+T">Tristan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Summarizing clinical text is crucial in health decision-support and clinical
research. Large language models (LLMs) have shown the potential to generate
accurate clinical text summaries, but still struggle with issues regarding
grounding and evaluation, especially in safety-critical domains such as health.
Holistically evaluating text summaries is challenging because they may contain
unsubstantiated information. Here, we explore a general mitigation framework
using Attribute Structuring (AS), which structures the summary evaluation
process. It decomposes the evaluation process into a grounded procedure that
uses an LLM for relatively simple structuring and scoring tasks, rather than
the full task of holistic summary evaluation. Experiments show that AS
consistently improves the correspondence between human annotations and
automated metrics in clinical text summarization. Additionally, AS yields
interpretations in the form of a short text span corresponding to each output,
which enables efficient human auditing, paving the way towards trustworthy
evaluation of clinical information in resource-constrained scenarios. We
release our code, prompts, and an open-source benchmark at
https://github.com/microsoft/attribute-structuring.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01003" title="Abstract">arXiv:2403.01003</a> [<a href="/pdf/2403.01003" title="Download PDF">pdf</a>, <a href="/format/2403.01003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlaKat: A Machine Learning-Based Categorization Framework for Flaky  Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shizhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R+Z+H">Ryan Zheng He Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tahvildari%2C+L">Ladan Tahvildari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Flaky tests can pass or fail non-deterministically, without alterations to a
software system. Such tests are frequently encountered by developers and hinder
the credibility of test suites. State-of-the-art research incorporates machine
learning solutions into flaky test detection and achieves reasonably good
accuracy. Moreover, the majority of automated flaky test repair solutions are
designed for specific types of flaky tests. This research work proposes a novel
categorization framework, called FlaKat, which uses machine-learning
classifiers for fast and accurate prediction of the category of a given flaky
test that reflects its root cause. Sampling techniques are applied to address
the imbalance between flaky test categories in the International Dataset of
Flaky Test (IDoFT). A new evaluation metric, called Flakiness Detection
Capacity (FDC), is proposed for measuring the accuracy of classifiers from the
perspective of information theory and provides proof for its effectiveness. The
final FDC results are also in agreement with F1 score regarding which
classifier yields the best flakiness classification.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01004" title="Abstract">arXiv:2403.01004</a> [<a href="/pdf/2403.01004" title="Download PDF">pdf</a>, <a href="/format/2403.01004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing parabolic operators in thermodynamic MHD models II: Evaluating  a Practical Time Step Limit for Unconditionally Stable Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caplan%2C+R+M">Ronald M. Caplan</a>, 
<a href="/search/cs?searchtype=author&query=Johnston%2C+C+D">Craig D. Johnston</a>, 
<a href="/search/cs?searchtype=author&query=Daldoff%2C+L+K+S">Lars K. S. Daldoff</a>, 
<a href="/search/cs?searchtype=author&query=Linker%2C+J+A">Jon A. Linker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures. ASTRONUM 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Unconditionally stable time stepping schemes are useful and often practically
necessary for advancing parabolic operators in multi-scale systems. However,
serious accuracy problems may emerge when taking time steps that far exceed the
explicit stability limits. In our previous work, we compared the accuracy and
performance of advancing parabolic operators in a thermodynamic MHD model using
an implicit method and an explicit super time-stepping (STS) method. We found
that while the STS method outperformed the implicit one with overall good
results, it was not able to damp oscillatory behavior in the solution
efficiently, hindering its practical use. In this follow-up work, we evaluate
an easy-to-implement method for selecting a practical time step limit (PTL) for
unconditionally stable schemes. This time step is used to `cycle' the
operator-split thermal conduction and viscosity parabolic operators. We test
the new time step with both an implicit and STS scheme for accuracy,
performance, and scaling. We find that, for our test cases here, the PTL
dramatically improves the STS solution, matching or improving the solution of
the original implicit scheme, while retaining most of its performance and
scaling advantages. The PTL shows promise to allow more accurate use of
unconditionally stable schemes for parabolic operators and reliable use of STS
methods.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01005" title="Abstract">arXiv:2403.01005</a> [<a href="/pdf/2403.01005" title="Download PDF">pdf</a>, <a href="/format/2403.01005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Optimization for PDE Control with a Warm Start
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiangyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
<a href="/search/eess?searchtype=author&query=Benosman%2C+M">Mouhacine Benosman</a>, 
<a href="/search/eess?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Dimensionality reduction is crucial for controlling nonlinear partial
differential equations (PDE) through a "reduce-then-design" strategy, which
identifies a reduced-order model and then implements model-based control
solutions. However, inaccuracies in the reduced-order modeling can
substantially degrade controller performance, especially in PDEs with chaotic
behavior. To address this issue, we augment the reduce-then-design procedure
with a policy optimization (PO) step. The PO step fine-tunes the model-based
controller to compensate for the modeling error from dimensionality reduction.
This augmentation shifts the overall strategy into
reduce-then-design-then-adapt, where the model-based controller serves as a
warm start for PO. Specifically, we study the state-feedback tracking control
of PDEs that aims to align the PDE state with a specific constant target
subject to a linear-quadratic cost. Through extensive experiments, we show that
a few iterations of PO can significantly improve the model-based controller
performance. Our approach offers a cost-effective alternative to PDE control
using end-to-end reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01008" title="Abstract">arXiv:2403.01008</a> [<a href="/pdf/2403.01008" title="Download PDF">pdf</a>, <a href="/format/2403.01008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BasedAI: A decentralized P2P network for Zero Knowledge Large Language  Models (ZK-LLMs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wellington%2C+S">Sean Wellington</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">BasedAI is a distributed network of machines which introduces decentralized
infrastructure capable of integrating Fully Homomorphic Encryption (FHE) with
any large language model (LLM) connected to its network. The proposed framework
embeds a default mechanism, called "Cerberus Squeezing", into the mining
process which enables the transformation of a standard LLMs into encrypted
zero-knowledge LLMs, or "ZK-LLMs", leveraging insights from generative
adversarial networks for data privacy. This novel quantization mechanism
empowers BasedAI miners to process and respond to prompts derived from User
interaction with LLMs without the need for decrypting ei- ther the queries or
their corresponding responses. The introduction of Cerberus Squeezing
significantly improves performance degradation caused by quantized functions in
current FHE-compliant computing environments by proactively optimizing calls
between users, miners, and validators.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01009" title="Abstract">arXiv:2403.01009</a> [<a href="/pdf/2403.01009" title="Download PDF">pdf</a>, <a href="/format/2403.01009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Evaluation of SEANet: a Software-defined Networking Platform  for the Internet of Underwater Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unal%2C+D">Deniz Unal</a>, 
<a href="/search/cs?searchtype=author&query=Falleni%2C+S">Sara Falleni</a>, 
<a href="/search/cs?searchtype=author&query=Enhos%2C+K">Kerem Enhos</a>, 
<a href="/search/cs?searchtype=author&query=Demirors%2C+E">Emrecan Demirors</a>, 
<a href="/search/cs?searchtype=author&query=Basagni%2C+S">Stefano Basagni</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Investigating and safeguarding our oceans is vital for a host of applications
and tasks, including combating climate change, ensuring the integrity of subsea
infrastructures, and for coastal protection. Achieving these essential
functions depends on the deployment of cost-effective, versatile underwater
sensor networks that can efficiently collect and transmit data to land.
However, the success of such networks is currently hindered by the significant
limitations of existing underwater modems, which limits their operational use
to a narrow range of applications. This paper presents and evaluates the
performance of the SEANet software-defined networking platform, for the
Internet of Underwater Things (IoUT), addressing the limitations of existing
underwater communication technologies. It presents the development and
comprehensive testing of an adaptable, high-data-rate, and integration-friendly
underwater platform that reconfigures in real-time to meet the demands of
various marine applications. With an acoustic front end, the platform
significantly outperforms conventional modems, achieving more than double the
data rate at 150 kbit/s. Experiments conducted in oceanic conditions
demonstrate its capabilities in channel characterization, OFDM link
establishment, and compatibility with the JANUS communication standard. Our
platform advances the IoUT by providing a versatile, scalable solution that can
incorporate multiple physical layers and support an array of tasks, making it
pivotal for real-time ocean data analysis and the expansion of ocean-related
digital applications.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01013" title="Abstract">arXiv:2403.01013</a> [<a href="/pdf/2403.01013" title="Download PDF">pdf</a>, <a href="/ps/2403.01013" title="Download PostScript">ps</a>, <a href="/format/2403.01013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Holistic Power Optimization Approach for Microgrid Control Based on  Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+F">Fulong Yao</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+W">Wanqing Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Forshaw%2C+M">Matthew Forshaw</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Y">Yang Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The global energy landscape is undergoing a transformation towards
decarbonization, sustainability, and cost-efficiency. In this transition,
microgrid systems integrated with renewable energy sources (RES) and energy
storage systems (ESS) have emerged as a crucial component. However, optimizing
the operational control of such an integrated energy system lacks a holistic
view of multiple environmental, infrastructural and economic considerations,
not to mention the need to factor in the uncertainties from both the supply and
demand. This paper presents a holistic datadriven power optimization approach
based on deep reinforcement learning (DRL) for microgrid control considering
the multiple needs of decarbonization, sustainability and cost-efficiency.
First, two data-driven control schemes, namely the prediction-based (PB) and
prediction-free (PF) schemes, are devised to formulate the control problem
within a Markov decision process (MDP). Second, a multivariate objective
(reward) function is designed to account for the market profits, carbon
emissions, peak load, and battery degradation of the microgrid system. Third,
we develop a Double Dueling Deep Q Network (D3QN) architecture to optimize the
power flows for real-time energy management and determine charging/discharging
strategies of ESS. Finally, extensive simulations are conducted to demonstrate
the effectiveness and superiority of the proposed approach through a
comparative analysis. The results and analysis also suggest the respective
circumstances for using the two control schemes in practical implementations
with uncertainties.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01014" title="Abstract">arXiv:2403.01014</a> [<a href="/pdf/2403.01014" title="Download PDF">pdf</a>, <a href="/format/2403.01014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case for Validation Buffer in Pessimistic Actor-Critic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nauman%2C+M">Michal Nauman</a>, 
<a href="/search/cs?searchtype=author&query=Ostaszewski%2C+M">Mateusz Ostaszewski</a>, 
<a href="/search/cs?searchtype=author&query=Cygan%2C+M">Marek Cygan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we investigate the issue of error accumulation in critic
networks updated via pessimistic temporal difference objectives. We show that
the critic approximation error can be approximated via a recursive fixed-point
model similar to that of the Bellman value. We use such recursive definition to
retrieve the conditions under which the pessimistic critic is unbiased.
Building on these insights, we propose Validation Pessimism Learning (VPL)
algorithm. VPL uses a small validation buffer to adjust the levels of pessimism
throughout the agent training, with the pessimism set such that the
approximation error of the critic targets is minimized. We investigate the
proposed approach on a variety of locomotion and manipulation tasks and report
improvements in sample efficiency and performance.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01015" title="Abstract">arXiv:2403.01015</a> [<a href="/pdf/2403.01015" title="Download PDF">pdf</a>, <a href="/format/2403.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Randomized Controlled Trial on Anonymizing Reviewers to Each Other in  Peer Review Discussions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Charvi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiangchen Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Stelmakh%2C+I">Ivan Stelmakh</a>, 
<a href="/search/cs?searchtype=author&query=Daum%C3%A9%2C+H">Hal Daum&#xe9; III</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N+B">Nihar B. Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Peer review often involves reviewers submitting their independent reviews,
followed by a discussion among reviewers of each paper. A question among
policymakers is whether the reviewers of a paper should be anonymous to each
other during the discussion. We shed light on this by conducting a randomized
controlled trial at the UAI 2022 conference. We randomly split the reviewers
and papers into two conditions--one with anonymous discussions and the other
with non-anonymous discussions, and conduct an anonymous survey of all
reviewers, to address the following questions: 1. Do reviewers discuss more in
one of the conditions? Marginally more in anonymous (n = 2281, p = 0.051). 2.
Does seniority have more influence on final decisions when non-anonymous? Yes,
the decisions are closer to senior reviewers' scores in the non-anonymous
condition than in anonymous (n = 484, p = 0.04). 3. Are reviewers more polite
in one of the conditions? No significant difference in politeness of reviewers'
text-based responses (n = 1125, p = 0.72). 4. Do reviewers' self-reported
experiences differ across the two conditions? No significant difference for
each of the five questions asked (n = 132 and p &gt; 0.3). 5. Do reviewers prefer
one condition over the other? Yes, there is a weak preference for anonymous
discussions (n = 159 and Cohen's d= 0.25). 6. What do reviewers consider
important to make policy on anonymity among reviewers? Reviewers' feeling of
safety in expressing their opinions was rated most important, while polite
communication among reviewers was rated least important (n = 159). 7. Have
reviewers experienced dishonest behavior due to non-anonymity in discussions?
Yes, roughly 7% of respondents answered affirmatively (n = 167). Overall, this
experiment reveals evidence supporting an anonymous discussion setup in the
peer-review process, in terms of the evaluation criteria considered.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01022" title="Abstract">arXiv:2403.01022</a> [<a href="/pdf/2403.01022" title="Download PDF">pdf</a>, <a href="/format/2403.01022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Strike UAVs for Counterterrorism Missions: Challenges and  Preliminary Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aljohani%2C+M">Meshari Aljohani</a>, 
<a href="/search/cs?searchtype=author&query=Mukkamalai%2C+R">Ravi Mukkamalai</a>, 
<a href="/search/cs?searchtype=author&query=Olariu%2C+S">Stephen Olariu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unmanned Aircraft Vehicles (UAVs) are becoming a crucial tool in modern
warfare, primarily due to their cost-effectiveness, risk reduction, and ability
to perform a wider range of activities. The use of autonomous UAVs to conduct
strike missions against highly valuable targets is the focus of this research.
Due to developments in ledger technology, smart contracts, and machine
learning, such activities formerly carried out by professionals or remotely
flown UAVs are now feasible. Our study provides the first in-depth analysis of
challenges and preliminary solutions for successful implementation of an
autonomous UAV mission. Specifically, we identify challenges that have to be
overcome and propose possible technical solutions for the challenges
identified. We also derive analytical expressions for the success probability
of an autonomous UAV mission, and describe a machine learning model to train
the UAV.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01023" title="Abstract">arXiv:2403.01023</a> [<a href="/pdf/2403.01023" title="Download PDF">pdf</a>, <a href="/format/2403.01023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning via Lattice Joint Source-Channel Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azimi-Abarghouyi%2C+S+M">Seyed Mohammad Azimi-Abarghouyi</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a universal federated learning framework that enables
over-the-air computation via digital communications, using a new joint
source-channel coding scheme. Without relying on channel state information at
devices, this scheme employs lattice codes to both quantize model parameters
and exploit interference from the devices. A novel two-layer receiver structure
at the server is designed to reliably decode an integer combination of the
quantized model parameters as a lattice point for the purpose of aggregation.
Numerical experiments validate the effectiveness of the proposed scheme. Even
with the challenges posed by channel conditions and device heterogeneity, the
proposed scheme markedly surpasses other over-the-air FL strategies.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01024" title="Abstract">arXiv:2403.01024</a> [<a href="/pdf/2403.01024" title="Download PDF">pdf</a>, <a href="/format/2403.01024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reservoir Computing Using Measurement-Controlled Quantum Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A+H">A.H.Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Maksymov%2C+I+S">Ivan S.Maksymov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Physical reservoir computing (RC) is a machine learning algorithm that
employs the dynamics of a physical system to forecast highly nonlinear and
chaotic phenomena. In this paper, we introduce a quantum RC system that employs
the dynamics of a probed atom in a cavity. The atom experiences coherent
driving at a particular rate, leading to a measurement-controlled quantum
evolution. The proposed quantum reservoir can make fast and reliable forecasts
using a small number of artificial neurons compared with the traditional RC
algorithm. We theoretically validate the operation of the reservoir,
demonstrating its potential to be used in error-tolerant applications, where
approximate computing approaches may be used to make feasible forecasts in
conditions of limited computational and energy resources.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01025" title="Abstract">arXiv:2403.01025</a> [<a href="/pdf/2403.01025" title="Download PDF">pdf</a>, <a href="/ps/2403.01025" title="Download PostScript">ps</a>, <a href="/format/2403.01025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sufficient Epistemic Condition for Solving Stabilizing Agreement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cignarale%2C+G">Giorgio Cignarale</a>, 
<a href="/search/cs?searchtype=author&query=Felber%2C+S">Stephan Felber</a>, 
<a href="/search/cs?searchtype=author&query=Galeana%2C+H+R">Hugo Rincon Galeana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In this paper we provide a first-ever epistemic formulation of stabilizing
agreement, defined as the non-terminating variant of the well established
consensus problem. In stabilizing agreements, agents are given (possibly
different) initial values, with the goal to eventually always decide on the
same value. While agents are allowed to change their decisions finitely often,
they are required to agree on the same value eventually. We capture these
properties in temporal epistemic logic and we use the Runs and Systems
framework to formally reason about stabilizing agreement problems. We then
epistemically formalize the conditions for solving stabilizing agreement, and
identify the knowledge that the agents acquire during any execution to choose a
particular value under our system assumptions. This first formalization of a
sufficient condition for solving stabilizing agreement sets the stage for a
planned necessary and sufficient epistemic characterization of stabilizing
agreement.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01027" title="Abstract">arXiv:2403.01027</a> [<a href="/pdf/2403.01027" title="Download PDF">pdf</a>, <a href="/format/2403.01027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Potential for Building Sector Retrofits to Mitigate ERCOT  Electricity Shortfalls During Winter Storm Uri
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Skiles%2C+M+J">Matthew J. Skiles</a>, 
<a href="/search/eess?searchtype=author&query=Rhodes%2C+J+D">Joshua D. Rhodes</a>, 
<a href="/search/eess?searchtype=author&query=Webber%2C+M+E">Michael E. Webber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This analysis investigates energy performance of the residential and
commercial building sectors in the Electric Reliability Council of Texas
(ERCOT) during Winter Storm Uri. ERCOT electricity demand was modeled for the
ERCOT baseline building stock as well as for the baseline building stock
retrofitted with an efficiency upgrade package, an electrification upgrade
package, and an efficiency + electrification upgrade package. The
electrification scenario that retrofitted buildings with air-source heat pumps
(ASHPs) would have lowered ERCOT daily peak electricity demand relative to the
baseline scenario for every day of the year, except during the week of Winter
Storm Uri. As the mean outdoor temperature dropped below -5{\deg}C (23{\deg}F),
diminishing ASHP efficiency would have resulted in electrification scenario
demand exceeding the two distinct baseline scenario daily demand peaks on
February 15th and 16th (87.3 GW and 88.7 GW) to hit 111.8 GW and 117.5 GW. The
efficiency package would have lowered daily peak demand on these days to 67.0
GW and 68.0 GW. The efficiency + electrification package would have lowered
peak demand on these days to 81.5 GW and 85.6 GW. When electricity shortfall
profiles were produced by comparing modeled electricity demand to actual ERCOT
electricity generation during the storm, the results indicate that the
electrification scenario electricity shortfall (1741 GWh) would have been
larger than for the baseline scenario (1225 GWh) and the electricity shortfalls
for the efficiency scenario (347 GWh) and efficiency + electrification scenario
(704 GWh) would have been lower than the baseline. The efficiency,
electrification, and efficiency + electrification scenarios would all have
lowered summer daily peak demand due to improvements in building cooling
efficiency and would have lowered annual electricity consumption by 5.9%, 6.8%,
and 11.9%, respectively.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01031" title="Abstract">arXiv:2403.01031</a> [<a href="/pdf/2403.01031" title="Download PDF">pdf</a>, <a href="/format/2403.01031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peacock: A Family of Arabic Multimodal Large Language Models and  Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alwajih%2C+F">Fakhraddin Alwajih</a>, 
<a href="/search/cs?searchtype=author&query=Nagoudi%2C+E+M+B">El Moatez Billah Nagoudi</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+G">Gagan Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A">Abdelrahman Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal large language models (MLLMs) have proven effective in a wide
range of tasks requiring complex reasoning and linguistic comprehension.
However, due to a lack of high-quality multimodal resources in languages other
than English, success of MLLMs remains relatively limited to English-based
settings. This poses significant challenges in developing comparable models for
other languages, including even those with large speaker populations such as
Arabic. To alleviate this challenge, we introduce a comprehensive family of
Arabic MLLMs, dubbed \textit{Peacock}, with strong vision and language
capabilities. Through comprehensive qualitative and quantitative analysis, we
demonstrate the solid performance of our models on various visual reasoning
tasks and further show their emerging dialectal potential. Additionally, we
introduce ~\textit{Henna}, a new benchmark specifically designed for assessing
MLLMs on aspects related to Arabic culture, setting the first stone for
culturally-aware Arabic MLLMs.The GitHub repository for the \textit{Peacock}
project is available at \url{https://github.com/UBC-NLP/peacock}.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01036" title="Abstract">arXiv:2403.01036</a> [<a href="/pdf/2403.01036" title="Download PDF">pdf</a>, <a href="/format/2403.01036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear dynamics and stability analysis of locally-active Mott  memristors using a physics-based compact model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+W">Wei Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 33 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Locally-active memristors are a class of emerging nonlinear dynamic circuit
elements that hold promise for scalable yet biomimetic neuromorphic circuits.
Starting from a physics-based compact model, we performed small-signal
linearization analyses and applied Chua's local activity theory to a
one-dimensional locally-active vanadium dioxide Mott memristor based on an
insulator-to-metal phase transition. This approach allows a connection between
the dynamical behaviors of a Mott memristor and its physical device parameters,
which could guide materials and device development for neuromorphic circuit
applications. We also examined the applicability of local analyses on a
second-order circuit consists of a vanadium dioxide memristor coupled to an
external reactive element, specifically a parallel capacitor. Finally, we show
that global nonlinear techniques including nullclines and phase portraits
provide insights on instabilities and persistent oscillations near
non-hyperbolic fixed points, such as the creation of a stable limit cycle in a
supercritical Hopf bifurcation, with some of the bifurcation characteristics
distinctive from the general predictions.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01038" title="Abstract">arXiv:2403.01038</a> [<a href="/pdf/2403.01038" title="Download PDF">pdf</a>, <a href="/format/2403.01038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoAttacker: A Large Language Model Guided System to Implement  Automatic Cyber-attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiacen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Stokes%2C+J+W">Jack W. Stokes</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+G">Geoff McDonald</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xuesong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+D">David Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Adith Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive results on natural
language tasks, and security researchers are beginning to employ them in both
offensive and defensive systems. In cyber-security, there have been multiple
research efforts that utilize LLMs focusing on the pre-breach stage of attacks
like phishing and malware generation. However, so far there lacks a
comprehensive study regarding whether LLM-based systems can be leveraged to
simulate the post-breach stage of attacks that are typically human-operated, or
"hands-on-keyboard" attacks, under various attack techniques and environments.
<br />As LLMs inevitably advance, they may be able to automate both the pre- and
post-breach attack stages. This shift may transform organizational attacks from
rare, expert-led events to frequent, automated operations requiring no
expertise and executed at automation speed and scale. This risks fundamentally
changing global computer security and correspondingly causing substantial
economic impacts, and a goal of this work is to better understand these risks
now so we can better prepare for these inevitable ever-more-capable LLMs on the
horizon. On the immediate impact side, this research serves three purposes.
First, an automated LLM-based, post-breach exploitation framework can help
analysts quickly test and continually improve their organization's network
security posture against previously unseen attacks. Second, an LLM-based
penetration test system can extend the effectiveness of red teams with a
limited number of human analysts. Finally, this research can help defensive
systems and teams learn to detect novel attack behaviors preemptively before
their use in the wild....
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01042" title="Abstract">arXiv:2403.01042</a> [<a href="/pdf/2403.01042" title="Download PDF">pdf</a>, <a href="/ps/2403.01042" title="Download PostScript">ps</a>, <a href="/format/2403.01042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Public Projects with Preferences and Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monroe%2C+M">Mary Monroe</a>, 
<a href="/search/cs?searchtype=author&query=Waggoner%2C+B">Bo Waggoner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In the public projects problem, a group of decisionmakers aggregate their
preferences to choose one alternative. Recent work on public projects has
proposed the Quadratic Transfers Mechanism (QTM) and shown asymptotic welfare
guarantees in some cases. We begin by giving new non-asymptotic Price of
Anarchy guarantees for the QTM.
<br />We then incorporate an alternative philosophy toward group decisionmaking,
aggregation of information about which is the best alternative. We propose a
public projects mechanism based on the QTM that aggregates both preferences and
predictions, modeled as forecasts of the projects' welfare impacts. When the
predictions come from a prediction market or wagering mechanism, we show the
entire mechanism is robust to manipulation and give Price of Anarchy
guarantees, though under strong assumptions on the mechanism's knowledge. Our
results focus primarily on the case of deciding between two alternatives,
showing the Price of Anarchy tends to $1$ as natural measures of the "size" of
the population grow large. In most cases, the mechanisms achieve a balanced
budget as well.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01046" title="Abstract">arXiv:2403.01046</a> [<a href="/pdf/2403.01046" title="Download PDF">pdf</a>, <a href="/format/2403.01046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex  Lasso Models with Reflection Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeger%2C+E">Emi Zeger</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mishkin%2C+A">Aaron Mishkin</a>, 
<a href="/search/cs?searchtype=author&query=Ergen%2C+T">Tolga Ergen</a>, 
<a href="/search/cs?searchtype=author&query=Cand%C3%A8s%2C+E">Emmanuel Cand&#xe8;s</a>, 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We prove that training neural networks on 1-D data is equivalent to solving a
convex Lasso problem with a fixed, explicitly defined dictionary matrix of
features. The specific dictionary depends on the activation and depth. We
consider 2-layer networks with piecewise linear activations, deep narrow ReLU
networks with up to 4 layers, and rectangular and tree networks with sign
activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer
creates features that represent reflections of training data about themselves.
The Lasso representation sheds insight to globally optimal networks and the
solution landscape.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01048" title="Abstract">arXiv:2403.01048</a> [<a href="/pdf/2403.01048" title="Download PDF">pdf</a>, <a href="/ps/2403.01048" title="Download PostScript">ps</a>, <a href="/format/2403.01048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking the Diebold Signature Variant -- RSA Signatures with  Unverified High-order Padding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gardner%2C+R+W">Ryan W. Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Kohno%2C+T">Tadayoshi Kohno</a>, 
<a href="/search/cs?searchtype=author&query=Yasinsac%2C+A">Alec Yasinsac</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We examine a natural but improper implementation of RSA signature
verification deployed on the widely used Diebold Touch Screen and Optical Scan
voting machines. In the implemented scheme, the verifier fails to examine a
large number of the high-order bits of signature padding and the public
exponent is three. We present an very mathematically simple attack that enables
an adversary to forge signatures on arbitrary messages in a negligible amount
of time.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01050" title="Abstract">arXiv:2403.01050</a> [<a href="/pdf/2403.01050" title="Download PDF">pdf</a>, <a href="/format/2403.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphMini: Accelerating Graph Pattern Matching Using Auxiliary Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Juelin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Polisetty%2C+S">Sandeep Polisetty</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hui Guan</a>, 
<a href="/search/cs?searchtype=author&query=Serafini%2C+M">Marco Serafini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Graph pattern matching is a fundamental problem encountered by many common
graph mining tasks and the basic building block of several graph mining
systems.
<br />This paper explores for the first time how to proactively prune graphs to
speed up graph pattern matching by leveraging the structure of the query
pattern and the input graph.
<br />We propose building auxiliary graphs, which are different pruned versions of
the graph, during query execution.
<br />This requires careful balancing between the upfront cost of building and
managing auxiliary graphs and the gains of faster set operations.
<br />To this end, we propose GraphMini, a new system that uses query compilation
and a new cost model to minimize the cost of building and maintaining auxiliary
graphs and maximize gains.
<br />Our evaluation shows that using GraphMini can achieve one order of magnitude
speedup compared to state-of-the-art subgraph enumeration systems on commonly
used benchmarks.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01053" title="Abstract">arXiv:2403.01053</a> [<a href="/pdf/2403.01053" title="Download PDF">pdf</a>, <a href="/format/2403.01053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing Unseen: Discover Novel Biomedical Concepts via  GeometryConstrained Probabilistic Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine learning holds tremendous promise for transforming the fundamental
practice of scientific discovery by virtue of its data-driven nature. With the
ever-increasing stream of research data collection, it would be appealing to
autonomously explore patterns and insights from observational data for
discovering novel classes of phenotypes and concepts. However, in the
biomedical domain, there are several challenges inherently presented in the
cumulated data which hamper the progress of novel class discovery. The
non-i.i.d. data distribution accompanied by the severe imbalance among
different groups of classes essentially leads to ambiguous and biased semantic
representations. In this work, we present a geometry-constrained probabilistic
modeling treatment to resolve the identified issues. First, we propose to
parameterize the approximated posterior of instance embedding as a marginal von
MisesFisher distribution to account for the interference of distributional
latent bias. Then, we incorporate a suite of critical geometric properties to
impose proper constraints on the layout of constructed embedding space, which
in turn minimizes the uncontrollable risk for unknown class learning and
structuring. Furthermore, a spectral graph-theoretic method is devised to
estimate the number of potential novel classes. It inherits two intriguing
merits compared to existent approaches, namely high computational efficiency
and flexibility for taxonomy-adaptive estimation. Extensive experiments across
various biomedical scenarios substantiate the effectiveness and general
applicability of our method.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01055" title="Abstract">arXiv:2403.01055</a> [<a href="/pdf/2403.01055" title="Download PDF">pdf</a>, <a href="/format/2403.01055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Full Authorship with AI: Supporting Revision with AI-Generated  Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Flanagan%2C+R+C">Ray C. Flanagan</a>, 
<a href="/search/cs?searchtype=author&query=Haviland%2C+N+E">Noelle E. Haviland</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">ZeAi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yakubu%2C+S+N">Souad N. Yakubu</a>, 
<a href="/search/cs?searchtype=author&query=Maru%2C+E+A">Edom A. Maru</a>, 
<a href="/search/cs?searchtype=author&query=Arnold%2C+K+C">Kenneth C. Arnold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures; Accepted to 5th Workshop on Human-AI Co-Creation with Generative Models (HAI-GEN) at ACM IUI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Large language models (LLMs) are shaping a new user interface (UI) paradigm
in writing tools by enabling users to generate text through prompts. This
paradigm shifts some creative control from the user to the system, thereby
diminishing the user's authorship and autonomy in the writing process. To
restore autonomy, we introduce Textfocals, a UI prototype designed to
investigate a human-centered approach that emphasizes the user's role in
writing. Textfocals supports the writing process by providing LLM-generated
summaries, questions, and advice (i.e., LLM views) in a sidebar of a text
editor, encouraging reflection and self-driven revision in writing without
direct text generation. Textfocals' UI affordances, including contextually
adaptive views and scaffolding for prompt selection and customization, offer a
novel way to interact with LLMs where users maintain full authorship of their
writing. A formative user study with Textfocals showed promising evidence that
this approach might help users develop underdeveloped ideas, cater to the
rhetorical audience, and clarify their writing. However, the study also showed
interaction design challenges related to document navigation and scoping,
prompt engineering, and context management. Our work highlights the breadth of
the design space of writing support interfaces powered by generative AI that
maintain authorship integrity.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01058" title="Abstract">arXiv:2403.01058</a> [<a href="/pdf/2403.01058" title="Download PDF">pdf</a>, <a href="/format/2403.01058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Field Classifiers via Target Encoding and Classification Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xindi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zeke Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Buhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yunfeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingming Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Main Conference; 17 pages; 11 figures; 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural field methods have seen great progress in various long-standing tasks
in computer vision and computer graphics, including novel view synthesis and
geometry reconstruction. As existing neural field methods try to predict some
coordinate-based continuous target values, such as RGB for Neural Radiance
Field (NeRF), all of these methods are regression models and are optimized by
some regression loss. However, are regression models really better than
classification models for neural field methods? In this work, we try to visit
this very fundamental but overlooked question for neural fields from a machine
learning perspective. We successfully propose a novel Neural Field Classifier
(NFC) framework which formulates existing neural field methods as
classification tasks rather than regression tasks. The proposed NFC can easily
transform arbitrary Neural Field Regressor (NFR) into its classification
variant via employing a novel Target Encoding module and optimizing a
classification loss. By encoding a continuous regression target into a
high-dimensional discrete encoding, we naturally formulate a multi-label
classification task. Extensive experiments demonstrate the impressive
effectiveness of NFC at the nearly free extra computational costs. Moreover,
NFC also shows robustness to sparse inputs, corrupted images, and dynamic
scenes.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01059" title="Abstract">arXiv:2403.01059</a> [<a href="/pdf/2403.01059" title="Download PDF">pdf</a>, <a href="/format/2403.01059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Mean-Zero Disagreement-Regularized Imitation Learning  (CMZ-DRIL)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ford%2C+N">Noah Ford</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+R+W">Ryan W. Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Juhl%2C+A">Austin Juhl</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+N">Nathan Larson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine-learning paradigms such as imitation learning and reinforcement
learning can generate highly performant agents in a variety of complex
environments. However, commonly used methods require large quantities of data
and/or a known reward function. This paper presents a method called Continuous
Mean-Zero Disagreement-Regularized Imitation Learning (CMZ-DRIL) that employs a
novel reward structure to improve the performance of imitation-learning agents
that have access to only a handful of expert demonstrations. CMZ-DRIL uses
reinforcement learning to minimize uncertainty among an ensemble of agents
trained to model the expert demonstrations. This method does not use any
environment-specific rewards, but creates a continuous and mean-zero reward
function from the action disagreement of the agent ensemble. As demonstrated in
a waypoint-navigation environment and in two MuJoCo environments, CMZ-DRIL can
generate performant agents that behave more similarly to the expert than
primary previous approaches in several key metrics.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01061" title="Abstract">arXiv:2403.01061</a> [<a href="/pdf/2403.01061" title="Download PDF">pdf</a>, <a href="/format/2403.01061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reading Subtext: Evaluating Large Language Models on Short Story  Summarization with Writers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subbiah%2C+M">Melanie Subbiah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sean Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L+B">Lydia B. Chilton</a>, 
<a href="/search/cs?searchtype=author&query=McKeown%2C+K">Kathleen McKeown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We evaluate recent Large language Models (LLMs) on the challenging task of
summarizing short stories, which can be lengthy, and include nuanced subtext or
scrambled timelines. Importantly, we work directly with authors to ensure that
the stories have not been shared online (and therefore are unseen by the
models), and to obtain informed evaluations of summary quality using judgments
from the authors themselves. Through quantitative and qualitative analysis
grounded in narrative theory, we compare GPT-4, Claude-2.1, and LLama-2-70B. We
find that all three models make faithfulness mistakes in over 50% of summaries
and struggle to interpret difficult subtext. However, at their best, the models
can provide thoughtful thematic analysis of stories. We additionally
demonstrate that LLM judgments of summary quality do not match the feedback
from the writers.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01063" title="Abstract">arXiv:2403.01063</a> [<a href="/pdf/2403.01063" title="Download PDF">pdf</a>, <a href="/format/2403.01063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songhua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinke Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenxuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongde Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuxiang Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-domain aspect-based sentiment analysis (ABSA) seeks to capture
fine-grained sentiment across diverse domains. While existing research narrowly
focuses on single-domain applications constrained by methodological limitations
and data scarcity, the reality is that sentiment naturally traverses multiple
domains. Although large language models (LLMs) offer a promising solution for
ABSA, it is difficult to integrate effectively with established techniques,
including graph-based models and linguistics, because modifying their internal
architecture is not easy. To alleviate this problem, we propose a novel
framework, Feature-aware In-context Learning for Multi-domain ABSA (FaiMA). The
core insight of FaiMA is to utilize in-context learning (ICL) as a
feature-aware mechanism that facilitates adaptive learning in multi-domain ABSA
tasks. Specifically, we employ a multi-head graph attention network as a text
encoder optimized by heuristic rules for linguistic, domain, and sentiment
features. Through contrastive learning, we optimize sentence representations by
focusing on these diverse features. Additionally, we construct an efficient
indexing mechanism, allowing FaiMA to stably retrieve highly relevant examples
across multiple dimensions for any given input. To evaluate the efficacy of
FaiMA, we build the first multi-domain ABSA benchmark dataset. Extensive
experimental results demonstrate that FaiMA achieves significant performance
improvements in multiple domains compared to baselines, increasing F1 by 2.07%
on average. Source code and data sets are anonymously available at
https://github.com/SupritYoung/FaiMA.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01068" title="Abstract">arXiv:2403.01068</a> [<a href="/pdf/2403.01068" title="Download PDF">pdf</a>, <a href="/format/2403.01068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Continuous Force-Torque Sensor Bias Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadeau%2C+P">Philippe Nadeau</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+M+R">Miguel Rogel Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Wise%2C+E">Emmett Wise</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report STARS-2024-001, University of Toronto Institute for Aerospace Studies (7 pages, 0 figure)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Six axis force-torque sensors are commonly attached to the wrist of serial
robots to measure the external forces and torques acting on the robot's
end-effector. These measurements are used for load identification, contact
detection, and human-robot interaction amongst other applications. Typically,
the measurements obtained from the force-torque sensor are more accurate than
estimates computed from joint torque readings, as the former is independent of
the robot's dynamic and kinematic models. However, the force-torque sensor
measurements are affected by a bias that drifts over time, caused by the
compounding effects of temperature changes, mechanical stresses, and other
factors. In this work, we present a pipeline that continuously estimates the
bias and the drift of the bias of a force-torque sensor attached to the wrist
of a robot. The first component of the pipeline is a Kalman filter that
estimates the kinematic state (position, velocity, and acceleration) of the
robot's joints. The second component is a kinematic model that maps the
joint-space kinematics to the task-space kinematics of the force-torque sensor.
Finally, the third component is a Kalman filter that estimates the bias and the
drift of the bias of the force-torque sensor assuming that the inertial
parameters of the gripper attached to the distal end of the force-torque sensor
are known with certainty.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01069" title="Abstract">arXiv:2403.01069</a> [<a href="/pdf/2403.01069" title="Download PDF">pdf</a>, <a href="/format/2403.01069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMCRIT: Teaching Large Language Models to Use Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weizhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gall%C3%A9%2C+M">Matthias Gall&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 tables, 3 figures in the main text
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Humans follow criteria when they execute tasks, and these criteria are
directly used to assess the quality of task completion. Therefore, having
models learn to use criteria to provide feedback can help humans or models to
perform tasks better. However, existing research in this field tends to
consider only a limited set of criteria or quality assessment aspects. To fill
this gap, we propose a general framework that enables large language models
(LLMs) to use comprehensive criteria for a task in delivering natural language
feedback on task execution. In particular, we present a model-in-the-loop
framework that semi-automatically derives criteria from collected guidelines
for different writing tasks and constructs in-context demonstrations for each
criterion. We choose three tasks from real-world scenarios to operationalize
this idea: paper introduction writing, Python code writing, and Reddit post
writing, and evaluate our feedback generation framework using different LLMs.
The results reveal the fine-grained effects of incorporating criteria and
demonstrations and provide valuable insights on how to teach LLMs to use
criteria more effectively.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01071" title="Abstract">arXiv:2403.01071</a> [<a href="/pdf/2403.01071" title="Download PDF">pdf</a>, <a href="/format/2403.01071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphRCG: Self-conditioned Graph Generation via Bootstrapped  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph generation generally aims to create new graphs that closely align with
a specific graph distribution. Existing works often implicitly capture this
distribution through the optimization of generators, potentially overlooking
the intricacies of the distribution itself. Furthermore, these approaches
generally neglect the insights offered by the learned distribution for graph
generation. In contrast, in this work, we propose a novel self-conditioned
graph generation framework designed to explicitly model graph distributions and
employ these distributions to guide the generation process. We first perform
self-conditioned modeling to capture the graph distributions by transforming
each graph sample into a low-dimensional representation and optimizing a
representation generator to create new representations reflective of the
learned distribution. Subsequently, we leverage these bootstrapped
representations as self-conditioned guidance for the generation process,
thereby facilitating the generation of graphs that more accurately reflect the
learned distributions. We conduct extensive experiments on generic and
molecular graph datasets across various fields. Our framework demonstrates
superior performance over existing state-of-the-art graph generation methods in
terms of graph quality and fidelity to training data.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01072" title="Abstract">arXiv:2403.01072</a> [<a href="/pdf/2403.01072" title="Download PDF">pdf</a>, <a href="/ps/2403.01072" title="Download PostScript">ps</a>, <a href="/format/2403.01072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Free Guarantees for Systems with Decision-Dependent Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Heling Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ratliff%2C+L+J">Lillian J. Ratliff</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+R">Roy Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In many real-world dynamical systems, obtaining precise models of system
uncertainty remains a challenge. It may be difficult to estimate noise
distributions or robustness bounds, especially when the
distributions/robustness bounds vary with different control inputs in unknown
ways. Addressing this challenge, this paper presents a novel iterative method
tailored for systems with decision-dependent noise without prior knowledge of
the distributions. Our approach finds the open-loop control law that minimizes
the worst-case loss, given that the noise induced by this control lies in its
$(1 - p)$-confidence set for a predetermined $p$. At each iteration, we use a
quantile method inspired by conformal prediction to empirically estimate the
confidence set shaped by the preceding control law. These derived confidence
sets offer distribution-free guarantees on the system's noise, guiding a robust
control formulation that targets worst-case loss minimization. Under specific
regularity conditions, our method is shown to converge to a near-optimal
open-loop control. While our focus is on open-loop controls, the adaptive,
data-driven nature of our approach suggests its potential applicability across
diverse scenarios and extensions.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01076" title="Abstract">arXiv:2403.01076</a> [<a href="/pdf/2403.01076" title="Download PDF">pdf</a>, <a href="/format/2403.01076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Usable Predictions from Quantized Networks through  Uncertainty Quantification for OOD Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+R">Rishi Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Srinath Srinivasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">OOD detection has become more pertinent with advances in network design and
increased task complexity. Identifying which parts of the data a given network
is misclassifying has become as valuable as the network's overall performance.
We can compress the model with quantization, but it suffers minor performance
loss. The loss of performance further necessitates the need to derive the
confidence estimate of the network's predictions. In line with this thinking,
we introduce an Uncertainty Quantification(UQ) technique to quantify the
uncertainty in the predictions from a pre-trained vision model. We subsequently
leverage this information to extract valuable predictions while ignoring the
non-confident predictions. We observe that our technique saves up to 80% of
ignored samples from being misclassified. The code for the same is available
here.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01078" title="Abstract">arXiv:2403.01078</a> [<a href="/pdf/2403.01078" title="Download PDF">pdf</a>, <a href="/format/2403.01078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x393;$-VAE: Curvature regularized variational autoencoders for  uncovering emergent low dimensional geometric structure in high dimensional  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+Z">Jason Z. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Perrin-Gilbert%2C+N">Nicolas Perrin-Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Narmanli%2C+E">Erkan Narmanli</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+P">Paul Klein</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+C+R">Christopher R. Myers</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+I">Itai Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Waterfall%2C+J+J">Joshua J. Waterfall</a>, 
<a href="/search/cs?searchtype=author&query=Sethna%2C+J+P">James P. Sethna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biological Physics (physics.bio-ph); Genomics (q-bio.GN)

</div>
<p class="mathjax">Natural systems with emergent behaviors often organize along low-dimensional
subsets of high-dimensional spaces. For example, despite the tens of thousands
of genes in the human genome, the principled study of genomics is fruitful
because biological processes rely on coordinated organization that results in
lower dimensional phenotypes. To uncover this organization, many nonlinear
dimensionality reduction techniques have successfully embedded high-dimensional
data into low-dimensional spaces by preserving local similarities between data
points. However, the nonlinearities in these methods allow for too much
curvature to preserve general trends across multiple non-neighboring data
clusters, thereby limiting their interpretability and generalizability to
out-of-distribution data. Here, we address both of these limitations by
regularizing the curvature of manifolds generated by variational autoencoders,
a process we coin ``$\Gamma$-VAE''. We demonstrate its utility using two
example data sets: bulk RNA-seq from the The Cancer Genome Atlas (TCGA) and the
Genotype Tissue Expression (GTEx); and single cell RNA-seq from a lineage
tracing experiment in hematopoietic stem cell differentiation. We find that the
resulting regularized manifolds identify mesoscale structure associated with
different cancer cell types, and accurately re-embed tissues from completely
unseen, out-of distribution cancers as if they were originally trained on them.
Finally, we show that preserving long-range relationships to differentiated
cells separates undifferentiated cells -- which have not yet specialized --
according to their eventual fate. Broadly, we anticipate that regularizing the
curvature of generative models will enable more consistent, predictive, and
generalizable models in any high-dimensional system with emergent
low-dimensional behavior.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01079" title="Abstract">arXiv:2403.01079</a> [<a href="/pdf/2403.01079" title="Download PDF">pdf</a>, <a href="/format/2403.01079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching MLP More Graph Information: A Three-stage Multitask Knowledge  Distillation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+E">Erfei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghua Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, with Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study the challenging problem for inference tasks on large-scale graph
datasets of Graph Neural Networks: huge time and memory consumption, and try to
overcome it by reducing reliance on graph structure. Even though distilling
graph knowledge to student MLP is an excellent idea, it faces two major
problems of positional information loss and low generalization. To solve the
problems, we propose a new three-stage multitask distillation framework. In
detail, we use Positional Encoding to capture positional information. Also, we
introduce Neural Heat Kernels responsible for graph data processing in GNN and
utilize hidden layer outputs matching for better performance of student MLP's
hidden layers. To the best of our knowledge, it is the first work to include
hidden layer distillation for student MLP on graphs and to combine graph
Positional Encoding with MLP. We test its performance and robustness with
several settings and draw the conclusion that our work can outperform well with
good stability.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01081" title="Abstract">arXiv:2403.01081</a> [<a href="/pdf/2403.01081" title="Download PDF">pdf</a>, <a href="/format/2403.01081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAB: Large-Scale Alignment for ChatBots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudalairaj%2C+S">Shivchander Sudalairaj</a>, 
<a href="/search/cs?searchtype=author&query=Bhandwaldar%2C+A">Abhishek Bhandwaldar</a>, 
<a href="/search/cs?searchtype=author&query=Pareja%2C+A">Aldo Pareja</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+D+D">David D. Cox</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces LAB (Large-scale Alignment for chatBots), a novel
methodology designed to overcome the scalability challenges in the
instruction-tuning phase of large language model (LLM) training. Leveraging a
taxonomy-guided synthetic data generation process and a multi-phase tuning
framework, LAB significantly reduces reliance on expensive human annotations
and proprietary models like GPT-4. We demonstrate that LAB-trained models can
achieve competitive performance across several benchmarks compared to models
trained with traditional human-annotated or GPT-4 generated synthetic data.
Thus offering a scalable, cost-effective solution for enhancing LLM
capabilities and instruction-following behaviors without the drawbacks of
catastrophic forgetting, marking a step forward in the efficient training of
LLMs for a wide range of applications.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01083" title="Abstract">arXiv:2403.01083</a> [<a href="/pdf/2403.01083" title="Download PDF">pdf</a>, <a href="/format/2403.01083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Night Visibility: Adaptive Multi-Scale Fusion of Infrared and  Visible Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+S">Shufan Pei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junhong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiesong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chia-Wen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In addition to low light, night images suffer degradation from light effects
(e.g., glare, floodlight, etc). However, existing nighttime visibility
enhancement methods generally focus on low-light regions, which neglects, or
even amplifies the light effects. To address this issue, we propose an Adaptive
Multi-scale Fusion network (AMFusion) with infrared and visible images, which
designs fusion rules according to different illumination regions. First, we
separately fuse spatial and semantic features from infrared and visible images,
where the former are used for the adjustment of light distribution and the
latter are used for the improvement of detection accuracy. Thereby, we obtain
an image free of low light and light effects, which improves the performance of
nighttime object detection. Second, we utilize detection features extracted by
a pre-trained backbone that guide the fusion of semantic features. Hereby, we
design a Detection-guided Semantic Fusion Module (DSFM) to bridge the domain
gap between detection and semantic features. Third, we propose a new
illumination loss to constrain fusion image with normal light intensity.
Experimental results demonstrate the superiority of AMFusion with better visual
quality and detection accuracy. The source code will be released after the peer
review process.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01085" title="Abstract">arXiv:2403.01085</a> [<a href="/pdf/2403.01085" title="Download PDF">pdf</a>, <a href="/format/2403.01085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strongly Subcubic Combinatorial Algorithm for Triangle Detection with  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumitrescu%2C+A">Adrian Dumitrescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We revisit the algorithmic problem of finding a triangle in a graph: We give
a randomized combinatorial algorithm for triangle detection in a given
$n$-vertex graph with $m$ edges running in $O(n^{7/3})$ time, or alternatively
in $O(m^{4/3})$ time. This may come as a surprise since it invalidates several
conjectures in the literature. In particular,
<br />- the $O(n^{7/3})$ runtime surpasses the long-standing fastest algorithm for
triangle detection based on matrix multiplication running in $O(n^\omega) =
O(n^{2.372})$ time, due to Itai and Rodeh (1978).
<br />- the $O(m^{4/3})$ runtime surpasses the long-standing fastest algorithm for
triangle detection in sparse graphs based on matrix multiplication running in
$O(m^{2\omega/(\omega+1)})= O(m^{1.407})$ time due to Alon, Yuster, and Zwick
(1997).
<br />- the $O(n^{7/3})$ time algorithm for triangle detection leads to a
$O(n^{25/9} \log{n})$ time combinatorial algorithm for $n \times n$ Boolean
matrix multiplication, by a reduction of V. V. Williams and R.~R.~Williams
(2018).This invalidates a conjecture of A.~Abboud and V. V. Williams (FOCS
2014).
<br />- the $O(m^{4/3})$ runtime invalidates a conjecture of A.~Abboud and V. V.
Williams (FOCS 2014) that any combinatorial algorithm for triangle detection
requires $m^{3/2 -o(1)}$ time.
<br />- as a direct application of the triangle detection algorithm, we obtain a
faster exact algorithm for the $k$-clique problem, surpassing an almost $40$
years old algorithm of Ne{\v{s}}et{\v{r}}il and Poljak (1985). This result
strongly disproves the combinatorial $k$-clique conjecture.
<br />- as another direct application of the triangle detection algorithm, we
obtain a faster exact algorithm for the \textsc{Max-Cut} problem, surpassing an
almost $20$ years old algorithm of R.~R.~Williams (2005).
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01086" title="Abstract">arXiv:2403.01086</a> [<a href="/pdf/2403.01086" title="Download PDF">pdf</a>, <a href="/format/2403.01086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> phloSAR: a Portable, High-Flow Pressure Supply and Regulator Enabling  Untethered Operation of Large Pneumatic Soft Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahlquist%2C+M">Maxwell Ahlquist</a>, 
<a href="/search/cs?searchtype=author&query=Jitosho%2C+R">Rianna Jitosho</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jiawen Bao</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE International Conference on Soft Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Pneumatic actuation benefits soft robotics by facilitating compliance,
enabling large volume change, and concentrating actuator weight away from the
end-effector. However, portability is compromised when pneumatic actuators are
tethered to cumbersome air and power supplies. While there are existing options
for portable pneumatic systems, they are limited in dynamic capabilities,
constraining their applicability to low pressure and/or small-volume soft
robots. In this work, we propose a portable, high-flow pressure supply and
regulator (phloSAR) for use in untethered, weight-constrained, dynamic soft
robot applications. PhloSAR leverages high-flow proportional valves, an
integrated pressure reservoir, and Venturi vacuum generation to achieve
portability and dynamic performance. We present a set of models that describe
the system dynamics, experimentally validate them on physical hardware, and
discuss the influence of design parameters on system operation. Lastly, we
integrate a proof-of-concept prototype with a soft robot arm mounted on an
aerial vehicle to demonstrate the system's applicability to mobile robotics.
Our system enables new opportunities in mobile soft robotics by making
untethered pneumatic supply and regulation available to a wider range of soft
robots.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01087" title="Abstract">arXiv:2403.01087</a> [<a href="/pdf/2403.01087" title="Download PDF">pdf</a>, <a href="/format/2403.01087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Accurate Lip-to-Speech Synthesis in-the-Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hegde%2C+S">Sindhu Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+R">Rudrabha Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C.V. Jawahar</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V">Vinay Namboodiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages of content, 1 page of references and 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 31st ACM International Conference on
  Multimedia, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we introduce a novel approach to address the task of
synthesizing speech from silent videos of any in-the-wild speaker solely based
on lip movements. The traditional approach of directly generating speech from
lip videos faces the challenge of not being able to learn a robust language
model from speech alone, resulting in unsatisfactory outcomes. To overcome this
issue, we propose incorporating noisy text supervision using a state-of-the-art
lip-to-text network that instills language information into our model. The
noisy text is generated using a pre-trained lip-to-text model, enabling our
approach to work without text annotations during inference. We design a visual
text-to-speech network that utilizes the visual stream to generate accurate
speech, which is in-sync with the silent input video. We perform extensive
experiments and ablation studies, demonstrating our approach's superiority over
the current state-of-the-art methods on various benchmark datasets. Further, we
demonstrate an essential practical application of our method in assistive
technology by generating speech for an ALS patient who has lost the voice but
can make mouth movements. Our demo video, code, and additional details can be
found at
\url{<a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/ms-l2s-itw">this http URL</a>}.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01089" title="Abstract">arXiv:2403.01089</a> [<a href="/pdf/2403.01089" title="Download PDF">pdf</a>, <a href="/ps/2403.01089" title="Download PostScript">ps</a>, <a href="/format/2403.01089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Hydrodynamic Fabrication of Microstructures using Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clinkinbeard%2C+N+R">Nicholus R. Clinkinbeard</a>, 
<a href="/search/cs?searchtype=author&query=Montazami%2C+R">Reza Montazami</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+N+N">Nicole N. Hashemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Manufacturing of microstructures using a microfluidic device is a largely
empirical effort due to the multi-physical nature of the fabrication process.
As such, models are desired that will predict microstructure performance
characteristics (e.g., size, porosity, and stiffness) based on known inputs,
such as sheath and core fluid flow rates. Potentially more useful is the
prospect of inputting desired performance characteristics into a design model
to extract appropriate manufacturing parameters. In this study, we demonstrate
that deep neural networks (DNNs) trained with sparse datasets augmented by
synthetic data can produce accurate predictive and design models. For our
predictive model with known sheath and core flow rates and bath solution
percentage, calculated solid microfiber dimensions are shown to be greater than
95% accurate, with porosity and Young's modulus exhibiting greater than 90%
accuracy for a majority of conditions. Likewise, the design model is able to
recover sheath and core flow rates with 95% accuracy when provided values for
microfiber dimensions, porosity, and Young's modulus. As a result, DNN-based
modeling of the microfiber fabrication process demonstrates high potential for
reducing time to manufacture of microstructures with desired characteristics.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01090" title="Abstract">arXiv:2403.01090</a> [<a href="/pdf/2403.01090" title="Download PDF">pdf</a>, <a href="/format/2403.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing Frissons among Online Video Viewers: Exploring the Design of  Affective Communication for Aesthetic Chills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojuan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CHI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">On online video platforms, viewers often lack a channel to sense others' and
express their affective state on the fly compared to co-located group-viewing.
This study explored the design of complementary affective communication
specifically for effortless, spontaneous sharing of frissons during video
watching. Also known as aesthetic chills, frissons are instant
psycho-physiological reactions like goosebumps and shivers to arousing stimuli.
We proposed an approach that unobtrusively detects viewers' frissons using skin
electrodermal activity sensors and presents the aggregated data alongside
online videos. Following a design process of brainstorming, focus group
interview (N=7), and design iterations, we proposed three different designs to
encode viewers' frisson experiences, namely, ambient light, icon, and
vibration. A mixed-methods within-subject study (N=48) suggested that our
approach offers a non-intrusive and efficient way to share viewers' frisson
moments, increases the social presence of others as if watching together, and
can create affective contagion among viewers.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01091" title="Abstract">arXiv:2403.01091</a> [<a href="/pdf/2403.01091" title="Download PDF">pdf</a>, <a href="/format/2403.01091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for  Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yusheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Siyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jingyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiting Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Information Fusion 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper investigates traffic forecasting, which attempts to forecast the
future state of traffic based on historical situations. This problem has
received ever-increasing attention in various scenarios and facilitated the
development of numerous downstream applications such as urban planning and
transportation management. However, the efficacy of existing methods remains
sub-optimal due to their tendency to model temporal and spatial relationships
independently, thereby inadequately accounting for complex high-order
interactions of both worlds. Moreover, the diversity of transitional patterns
in traffic forecasting makes them challenging to capture for existing
approaches, warranting a deeper exploration of their diversity. Toward this
end, this paper proposes Conjoint Spatio-Temporal graph neural network
(abbreviated as COOL), which models heterogeneous graphs from prior and
posterior information to conjointly capture high-order spatio-temporal
relationships. On the one hand, heterogeneous graphs connecting sequential
observation are constructed to extract composite spatio-temporal relationships
via prior message passing. On the other hand, we model dynamic relationships
using constructed affinity and penalty graphs, which guide posterior message
passing to incorporate complementary semantic information into node
representations. Moreover, to capture diverse transitional properties to
enhance traffic forecasting, we propose a conjoint self-attention decoder that
models diverse temporal patterns from both multi-rank and multi-scale views.
Experimental results on four popular benchmark datasets demonstrate that our
proposed COOL provides state-of-the-art performance compared with the
competitive baselines.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01092" title="Abstract">arXiv:2403.01092</a> [<a href="/pdf/2403.01092" title="Download PDF">pdf</a>, <a href="/format/2403.01092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pairwise Alignment Improves Graph Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Deyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code and data are available at: <a href="https://github.com/Graph-COM/Pair-Align">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph-based methods, pivotal for label inference over interconnected objects
in many real-world applications, often encounter generalization challenges, if
the graph used for model training differs significantly from the graph used for
testing. This work delves into Graph Domain Adaptation (GDA) to address the
unique complexities of distribution shifts over graph data, where
interconnected data points experience shifts in features, labels, and in
particular, connecting patterns. We propose a novel, theoretically principled
method, Pairwise Alignment (Pair-Align) to counter graph structure shift by
mitigating conditional structure shift (CSS) and label shift (LS). Pair-Align
uses edge weights to recalibrate the influence among neighboring nodes to
handle CSS and adjusts the classification loss with label weights to handle LS.
Our method demonstrates superior performance in real-world applications,
including node classification with region shift in social networks, and the
pileup mitigation task in particle colliding experiments. For the first
application, we also curate the largest dataset by far for GDA studies. Our
method shows strong performance in synthetic and other existing benchmark
datasets.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01095" title="Abstract">arXiv:2403.01095</a> [<a href="/pdf/2403.01095" title="Download PDF">pdf</a>, <a href="/ps/2403.01095" title="Download PostScript">ps</a>, <a href="/format/2403.01095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inevitable-Metaverse: A Novel Twitter Dataset for Public Sentiments on  Metaverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayawi%2C+K">Kadhim Hayawi</a>, 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+S">Sakib Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Serhani%2C+M+A">Mohamed Adel Serhani</a>, 
<a href="/search/cs?searchtype=author&query=Alothali%2C+E">Eiman Alothali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Metaverse has emerged as a novel technology with the objective to merge the
physical world into the virtual world. This technology has seen a lot of
interest and investment in recent times from prominent organizations including
Facebook which has changed its company name to Meta with the goal of being the
leader in developing this technology. Although people in general are excited
about the prospects of metaverse due to potential use cases such as virtual
meetings and virtual learning environments, there are also concerns due to
potential negative consequences. For instance, people are concerned about their
data privacy as well as spending a lot of their time on the metaverse leading
to negative impacts in real life. Therefore, this research aims to further
investigate the public sentiments regarding metaverse on social media. A total
of 86565 metaverse-related tweets were used to perform lexicon-based sentiment
analysis. Furthermore, various machine and deep learning models with various
text features were utilized to predict the sentiment class. The BERT
transformer model was demonstrated to be the best at predicting the sentiment
categories with 92.6% accuracy and 0.91 F-measure on the test dataset. Finally,
the implications and future research directions were also discussed.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01100" title="Abstract">arXiv:2403.01100</a> [<a href="/pdf/2403.01100" title="Download PDF">pdf</a>, <a href="/format/2403.01100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Security in 6G for Sustainable Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I">Ijaz Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I">Ijaz Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Harjula%2C+E">Erkki Harjula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,2 figures, accepted by NCDHWS, to be published by Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">6G will fulfill the requirements of future digital healthcare systems through
emerging decentralized computing and secure communications technologies.
Digital healthcare solutions employ numerous low-power and resource-constrained
connected things, such as the Internet of Medical Things (IoMT). However, the
current digital healthcare solutions will face two major challenges. First, the
proposed solutions are based on the traditional IoT-Cloud model that will
experience latency and reliability challenges to meet the expectations and
requirements of digital healthcare, while potentially inflicting heavy network
load. Second, the existing digital healthcare solutions will face security
challenges due to the inherent limitations of IoMT caused by the lack of
resources for proper security in those devices. Therefore, in this research, we
present a decentralized adaptive security architecture for the successful
deployment of digital healthcare. The proposed architecture leverages the
edge-cloud continuum to meet the performance, efficiency, and reliability
requirements. It can adapt the security solution at run-time to meet the
limited capacity of IoMT devices without compromising the security of critical
data. Finally, the research outlines comprehensive methodologies for validating
the proposed security architecture.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01101" title="Abstract">arXiv:2403.01101</a> [<a href="/pdf/2403.01101" title="Download PDF">pdf</a>, <a href="/format/2403.01101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Alignment: Rethinking Efficient Active Learning via Proxy in the  Context of Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Ziting Wen</a>, 
<a href="/search/cs?searchtype=author&query=Pizarro%2C+O">Oscar Pizarro</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+S">Stefan Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Fine-tuning the pre-trained model with active learning holds promise for
reducing annotation costs. However, this combination introduces significant
computational costs, particularly with the growing scale of pre-trained models.
Recent research has proposed proxy-based active learning, which pre-computes
features to reduce computational costs. Yet, this approach often incurs a
significant loss in active learning performance, which may even outweigh the
computational cost savings. In this paper, we argue the performance drop stems
not only from pre-computed features' inability to distinguish between
categories of labeled samples, resulting in the selection of redundant samples
but also from the tendency to compromise valuable pre-trained information when
fine-tuning with samples selected through the proxy model. To address this
issue, we propose a novel method called aligned selection via proxy to update
pre-computed features while selecting a proper training method to inherit
valuable pre-training information. Extensive experiments validate that our
method significantly improves the total cost of efficient active learning while
maintaining computational efficiency.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01102" title="Abstract">arXiv:2403.01102</a> [<a href="/pdf/2403.01102" title="Download PDF">pdf</a>, <a href="/format/2403.01102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time hybrid controls of energy storage and load shedding for  integrated power and energy systems of ships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vu%2C+L">Linh Vu</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T">Thai-Thanh Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+B+L">Bang Le-Huy Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Anam%2C+M+I">Md Isfakul Anam</a>, 
<a href="/search/eess?searchtype=author&query=Vu%2C+T">Tuyen Vu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 17 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Electric Power Systems Research, volume 229, pages 110191, year
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents an original energy management methodology to enhance the
resilience of ship power systems. The integration of various energy storage
systems (ESS), including battery energy storage systems (BESS) and
super-capacitor energy storage systems (SCESS), in modern ship power systems
poses challenges in designing an efficient energy management system (EMS). The
EMS proposed in this paper aims to achieve multiple objectives. The primary
objective is to minimize shed loads, while the secondary objective is to
effectively manage different types of ESS. Considering the diverse ramp-rate
characteristics of generators, SCESS, and BESS, the proposed EMS exploits these
differences to determine an optimal long-term schedule for minimizing shed
loads. Furthermore, the proposed EMS balances the state-of-charge (SoC) of ESS
and prioritizes the SCESS's SoC levels to ensure the efficient operation of
BESS and SCESS. For better computational efficiency, we introduce the receding
horizon optimization method, enabling real-time EMS implementation. A
comparison with the fixed horizon optimization (FHO) validates its
effectiveness. Simulation studies and results demonstrate that the proposed EMS
efficiently manages generators, BESS, and SCESS, ensuring system resilience
under generation shortages. Additionally, the proposed methodology
significantly reduces the computational burden compared to the FHO technique
while maintaining acceptable resilience performance.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01105" title="Abstract">arXiv:2403.01105</a> [<a href="/pdf/2403.01105" title="Download PDF">pdf</a>, <a href="/format/2403.01105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth Information Assisted Collaborative Mutual Promotion Network for  Single Image Dehazing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yafei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huafeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recovering a clear image from a single hazy image is an open inverse problem.
Although significant research progress has been made, most existing methods
ignore the effect that downstream tasks play in promoting upstream dehazing.
From the perspective of the haze generation mechanism, there is a potential
relationship between the depth information of the scene and the hazy image.
Based on this, we propose a dual-task collaborative mutual promotion framework
to achieve the dehazing of a single image. This framework integrates depth
estimation and dehazing by a dual-task interaction mechanism and achieves
mutual enhancement of their performance. To realize the joint optimization of
the two tasks, an alternative implementation mechanism with the difference
perception is developed. On the one hand, the difference perception between the
depth maps of the dehazing result and the ideal image is proposed to promote
the dehazing network to pay attention to the non-ideal areas of the dehazing.
On the other hand, by improving the depth estimation performance in the
difficult-to-recover areas of the hazy image, the dehazing network can
explicitly use the depth information of the hazy image to assist the clear
image recovery. To promote the depth estimation, we propose to use the
difference between the dehazed image and the ground truth to guide the depth
estimation network to focus on the dehazed unideal areas. It allows dehazing
and depth estimation to leverage their strengths in a mutually reinforcing
manner. Experimental results show that the proposed method can achieve better
performance than that of the state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01106" title="Abstract">arXiv:2403.01106</a> [<a href="/pdf/2403.01106" title="Download PDF">pdf</a>, <a href="/format/2403.01106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Text Style Transfer With Self-Explanation From LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Honglong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yuezhang">Yuezhang</a> (Music)Li, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuexin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Le Hou</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Mageed%2C+M">Muhammad Abdul-Mageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text Style Transfer (TST) seeks to alter the style of text while retaining
its core content. Given the constraints of limited parallel datasets for TST,
we propose CoTeX, a framework that leverages large language models (LLMs)
alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills
the complex rewriting and reasoning capabilities of LLMs into more streamlined
models capable of working with both non-parallel and parallel data. Through
experimentation across four TST datasets, CoTeX is shown to surpass traditional
supervised fine-tuning and knowledge distillation methods, particularly in
low-resource settings. We conduct a comprehensive evaluation, comparing CoTeX
against current unsupervised, supervised, in-context learning (ICL) techniques,
and instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering
transparent explanations for its style transfer process.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01108" title="Abstract">arXiv:2403.01108</a> [<a href="/pdf/2403.01108" title="Download PDF">pdf</a>, <a href="/format/2403.01108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face Swap via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feifei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This technical report presents a diffusion model based framework for face
swapping between two portrait images. The basic framework consists of three
components, i.e., IP-Adapter, ControlNet, and Stable Diffusion's inpainting
pipeline, for face feature encoding, multi-conditional generation, and face
inpainting respectively. Besides, I introduce facial guidance optimization and
CodeFormer based blending to further improve the generation quality.
<br />Specifically, we engage a recent light-weighted customization method (i.e.,
DreamBooth-LoRA), to guarantee the identity consistency by 1) using a rare
identifier "sks" to represent the source identity, and 2) injecting the image
features of source portrait into each cross-attention layer like the text
features. Then I resort to the strong inpainting ability of Stable Diffusion,
and utilize canny image and face detection annotation of the target portrait as
the conditions, to guide ContorlNet's generation and align source portrait with
the target portrait. To further correct face alignment, we add the facial
guidance loss to optimize the text embedding during the sample generation.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01110" title="Abstract">arXiv:2403.01110</a> [<a href="/pdf/2403.01110" title="Download PDF">pdf</a>, <a href="/format/2403.01110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grid-based Fast and Structural Visual Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhihe%2C+Z">Zhang Zhihe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the field of Simultaneous Localization and Mapping (SLAM), researchers
have always pursued better performance in terms of accuracy and time cost.
Traditional algorithms typically rely on fundamental geometric elements in
images to establish connections between frames. However, these elements suffer
from disadvantages such as uneven distribution and slow extraction. In
addition, geometry elements like lines have not been fully utilized in the
process of pose estimation. To address these challenges, we propose GFS-VO, a
grid-based RGB-D visual odometry algorithm that maximizes the utilization of
both point and line features. Our algorithm incorporates fast line extraction
and a stable line homogenization scheme to improve feature processing. To fully
leverage hidden elements in the scene, we introduce Manhattan Axes (MA) to
provide constraints between local map and current frame. Additionally, we have
designed an algorithm based on breadth-first search for extracting plane normal
vectors. To evaluate the performance of GFS-VO, we conducted extensive
experiments. The results demonstrate that our proposed algorithm exhibits
significant improvements in both time cost and accuracy compared to existing
approaches.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01112" title="Abstract">arXiv:2403.01112</a> [<a href="/pdf/2403.01112" title="Download PDF">pdf</a>, <a href="/format/2403.01112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Episodic Memory Utilization of Cooperative Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Na%2C+H">Hyungho Na</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Yunkyeong Seo</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+I">Il-chul Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In cooperative multi-agent reinforcement learning (MARL), agents aim to
achieve a common goal, such as defeating enemies or scoring a goal. Existing
MARL algorithms are effective but still require significant learning time and
often get trapped in local optima by complex tasks, subsequently failing to
discover a goal-reaching policy. To address this, we introduce Efficient
episodic Memory Utilization (EMU) for MARL, with two primary objectives: (a)
accelerating reinforcement learning by leveraging semantically coherent memory
from an episodic buffer and (b) selectively promoting desirable transitions to
prevent local convergence. To achieve (a), EMU incorporates a trainable
encoder/decoder structure alongside MARL, creating coherent memory embeddings
that facilitate exploratory memory recall. To achieve (b), EMU introduces a
novel reward structure called episodic incentive based on the desirability of
states. This reward improves the TD target in Q-learning and acts as an
additional incentive for desirable transitions. We provide theoretical support
for the proposed incentive and demonstrate the effectiveness of EMU compared to
conventional episodic control. The proposed method is evaluated in StarCraft II
and Google Research Football, and empirical results indicate further
performance improvement over state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01116" title="Abstract">arXiv:2403.01116</a> [<a href="/pdf/2403.01116" title="Download PDF">pdf</a>, <a href="/format/2403.01116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MulCogBench: A Multi-modal Cognitive Benchmark Dataset for Evaluating  Chinese and English Computational Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+C">Chengqing Zong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained computational language models have recently made remarkable
progress in harnessing the language abilities which were considered unique to
humans. Their success has raised interest in whether these models represent and
process language like humans. To answer this question, this paper proposes
MulCogBench, a multi-modal cognitive benchmark dataset collected from native
Chinese and English participants. It encompasses a variety of cognitive data,
including subjective semantic ratings, eye-tracking, functional magnetic
resonance imaging (fMRI), and magnetoencephalography (MEG). To assess the
relationship between language models and cognitive data, we conducted a
similarity-encoding analysis which decodes cognitive data based on its pattern
similarity with textual embeddings. Results show that language models share
significant similarities with human cognitive data and the similarity patterns
are modulated by the data modality and stimuli complexity. Specifically,
context-aware models outperform context-independent models as language stimulus
complexity increases. The shallow layers of context-aware models are better
aligned with the high-temporal-resolution MEG signals whereas the deeper layers
show more similarity with the high-spatial-resolution fMRI. These results
indicate that language models have a delicate relationship with brain language
representations. Moreover, the results between Chinese and English are highly
consistent, suggesting the generalizability of these findings across languages.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01118" title="Abstract">arXiv:2403.01118</a> [<a href="/pdf/2403.01118" title="Download PDF">pdf</a>, <a href="/format/2403.01118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Testing for Visual Grounding via Image-Aware Property  Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Z">Zhiyuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fanjiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to the advantages of fusing information from various modalities,
multimodal learning is gaining increasing attention. Being a fundamental task
of multimodal learning, Visual Grounding (VG), aims to locate objects in images
through natural language expressions. Ensuring the quality of VG models
presents significant challenges due to the complex nature of the task. In the
black box scenario, existing adversarial testing techniques often fail to fully
exploit the potential of both modalities of information. They typically apply
perturbations based solely on either the image or text information,
disregarding the crucial correlation between the two modalities, which would
lead to failures in test oracles or an inability to effectively challenge VG
models. To this end, we propose PEELING, a text perturbation approach via
image-aware property reduction for adversarial testing of the VG model. The
core idea is to reduce the property-related information in the original
expression meanwhile ensuring the reduced expression can still uniquely
describe the original object in the image. To achieve this, PEELING first
conducts the object and properties extraction and recombination to generate
candidate property reduction expressions. It then selects the satisfied
expressions that accurately describe the original object while ensuring no
other objects in the image fulfill the expression, through querying the image
with a visual understanding technique. We evaluate PEELING on the
state-of-the-art VG model, i.e. OFA-VG, involving three commonly used datasets.
Results show that the adversarial tests generated by PEELING achieves 21.4% in
MultiModal Impact score (MMI), and outperforms state-of-the-art baselines for
images and texts by 8.2%--15.1%.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01121" title="Abstract">arXiv:2403.01121</a> [<a href="/pdf/2403.01121" title="Download PDF">pdf</a>, <a href="/format/2403.01121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenGraph: Towards Open Graph Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+B">Ben Kao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph learning has become indispensable for interpreting and harnessing
relational data in diverse fields, ranging from recommendation systems to
social network analysis. In this context, a variety of GNNs have emerged as
promising methodologies for encoding the structural information of graphs. By
effectively capturing the graph's underlying structure, these GNNs have shown
great potential in enhancing performance in graph learning tasks, such as link
prediction and node classification. However, despite their successes, a
significant challenge persists: these advanced methods often face difficulties
in generalizing to unseen graph data that significantly differs from the
training instances. In this work, our aim is to advance the graph learning
paradigm by developing a general graph foundation model. This model is designed
to understand the complex topological patterns present in diverse graph data,
enabling it to excel in zero-shot graph learning tasks across different
downstream datasets. To achieve this goal, we address several key technical
challenges in our OpenGraph model. Firstly, we propose a unified graph
tokenizer to adapt our graph model to generalize well on unseen graph data,
even when the underlying graph properties differ significantly from those
encountered during training. Secondly, we develop a scalable graph transformer
as the foundational encoder, which effectively captures node-wise dependencies
within the global topological context. Thirdly, we introduce a data
augmentation mechanism enhanced by a LLM to alleviate the limitations of data
scarcity in real-world scenarios. Extensive experiments validate the
effectiveness of our framework. By adapting our OpenGraph to new graph
characteristics and comprehending the nuances of diverse graphs, our approach
achieves remarkable zero-shot graph learning performance across various
settings and domains.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01123" title="Abstract">arXiv:2403.01123</a> [<a href="/pdf/2403.01123" title="Download PDF">pdf</a>, <a href="/format/2403.01123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELA: Efficient Local Attention for Deep Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yi Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The attention mechanism has gained significant recognition in the field of
computer vision due to its ability to effectively enhance the performance of
deep neural networks. However, existing methods often struggle to effectively
utilize spatial information or, if they do, they come at the cost of reducing
channel dimensions or increasing the complexity of neural networks. In order to
address these limitations, this paper introduces an Efficient Local Attention
(ELA) method that achieves substantial performance improvements with a simple
structure. By analyzing the limitations of the Coordinate Attention method, we
identify the lack of generalization ability in Batch Normalization, the adverse
effects of dimension reduction on channel attention, and the complexity of
attention generation process. To overcome these challenges, we propose the
incorporation of 1D convolution and Group Normalization feature enhancement
techniques. This approach enables accurate localization of regions of interest
by efficiently encoding two 1D positional feature maps without the need for
dimension reduction, while allowing for a lightweight implementation. We
carefully design three hyperparameters in ELA, resulting in four different
versions: ELA-T, ELA-B, ELA-S, and ELA-L, to cater to the specific requirements
of different visual tasks such as image classification, object detection and
sementic segmentation. ELA can be seamlessly integrated into deep CNN networks
such as ResNet, MobileNet, and DeepLab. Extensive evaluations on the ImageNet,
MSCOCO, and Pascal VOC datasets demonstrate the superiority of the proposed ELA
module over current state-of-the-art methods in all three aforementioned visual
tasks.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01124" title="Abstract">arXiv:2403.01124</a> [<a href="/pdf/2403.01124" title="Download PDF">pdf</a>, <a href="/format/2403.01124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-guided Explorable Image Super-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandikota%2C+K+V">Kanchana Vaishnavi Gandikota</a>, 
<a href="/search/cs?searchtype=author&query=Chandramouli%2C+P">Paramanand Chandramouli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce the problem of zero-shot text-guided exploration
of the solutions to open-domain image super-resolution. Our goal is to allow
users to explore diverse, semantically accurate reconstructions that preserve
data consistency with the low-resolution inputs for different large
downsampling factors without explicitly training for these specific
degradations. We propose two approaches for zero-shot text-guided
super-resolution - i) modifying the generative process of text-to-image
\textit{T2I} diffusion models to promote consistency with low-resolution
inputs, and ii) incorporating language guidance into zero-shot diffusion-based
restoration methods. We show that the proposed approaches result in diverse
solutions that match the semantic meaning provided by the text prompt while
preserving data consistency with the degraded inputs. We evaluate the proposed
baselines for the task of extreme super-resolution and demonstrate advantages
in terms of restoration quality, diversity, and explorability of solutions.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01127" title="Abstract">arXiv:2403.01127</a> [<a href="/pdf/2403.01127" title="Download PDF">pdf</a>, <a href="/format/2403.01127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards RehabCoach: Design and Preliminary Evaluation of a  Conversational Agent Supporting Unsupervised Therapy after Stroke
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devittori%2C+G">Giada Devittori</a>, 
<a href="/search/cs?searchtype=author&query=Akeddar%2C+M">Mehdi Akeddar</a>, 
<a href="/search/cs?searchtype=author&query=Retevoi%2C+A">Alexandra Retevoi</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+F">Fabian Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Cvetkova%2C+V">Viktoria Cvetkova</a>, 
<a href="/search/cs?searchtype=author&query=Dinacci%2C+D">Daria Dinacci</a>, 
<a href="/search/cs?searchtype=author&query=Califfi%2C+A">Antonella Califfi</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+P">Paolo Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Petrillo%2C+C">Claudio Petrillo</a>, 
<a href="/search/cs?searchtype=author&query=Kowatsch%2C+T">Tobias Kowatsch</a>, 
<a href="/search/cs?searchtype=author&query=Lambercy%2C+O">Olivier Lambercy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Unsupervised therapy after stroke is a promising way to boost therapy dose
without significantly increasing the workload on healthcare professionals.
However, it raises important challenges, such as lower adherence to therapy in
the absence of social interaction with therapists. We present the initial
prototype of RehabCoach, a novel smartphone-based app with conversational agent
to support unsupervised therapy. RehabCoach is designed to increase patients
engagement and adherence to therapy and to provide information (e.g., about
stroke, health) in an interactive and user-friendly manner. We report on the
design and usability evaluation of the first prototype of RehabCoach, assessed
by four stroke patients and five healthcare professionals, who interacted with
the app in a single testing session. Task completion time and success rates
were measured for 15 representative tasks, and participants assessed usability
via questionnaires and a semi-structured interview. Results show that it was
feasible for stroke patients to successfully interact with RehabCoach (task
success $\geq$ 93 $\%$) without requiring extensive training. Participants
positively rated the usability of RehabCoach (mean mHealth App Usability
Questionnaire score: 1.3 for primary users, 1.4 for healthcare professionals,
on a scale from 1 (positive evaluation) to 7). The feedback collected in this
work opens the door to further enhance RehabCoach as an interactive digital
tool to support unsupervised rehabilitation.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01128" title="Abstract">arXiv:2403.01128</a> [<a href="/pdf/2403.01128" title="Download PDF">pdf</a>, <a href="/format/2403.01128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity Analysis On Loss Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faroz%2C+S">Salman Faroz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Gradients can be employed for sensitivity analysis. Here, we leverage the
advantages of the Loss Landscape to comprehend which independent variables
impact the dependent variable. We seek to grasp the loss landscape by utilizing
first, second, and third derivatives through automatic differentiation. we know
that Spearman's rank correlation coefficient can detect the monotonic
relationship between two variables. However, I have found that second-order
gradients, with certain configurations and parameters, provide information that
can be visualized similarly to Spearman's results.In our approach, we
incorporate a loss function with an activation function, resulting in a
non-linear pattern. Each exploration of the loss landscape through retraining
yields new valuable information. Furthermore, the first and third derivatives
are also beneficial, as they indicate the extent to which independent variables
influence the dependent variable.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01129" title="Abstract">arXiv:2403.01129</a> [<a href="/pdf/2403.01129" title="Download PDF">pdf</a>, <a href="/format/2403.01129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic 3D Point Cloud Sequences as 2D Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yiming Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dynamic 3D point cloud sequences serve as one of the most common and
practical representation modalities of dynamic real-world environments.
However, their unstructured nature in both spatial and temporal domains poses
significant challenges to effective and efficient processing. Existing deep
point cloud sequence modeling approaches imitate the mature 2D video learning
mechanisms by developing complex spatio-temporal point neighbor grouping and
feature aggregation schemes, often resulting in methods lacking effectiveness,
efficiency, and expressive power. In this paper, we propose a novel generic
representation called \textit{Structured Point Cloud Videos} (SPCVs).
Intuitively, by leveraging the fact that 3D geometric shapes are essentially 2D
manifolds, SPCV re-organizes a point cloud sequence as a 2D video with spatial
smoothness and temporal consistency, where the pixel values correspond to the
3D coordinates of points. The structured nature of our SPCV representation
allows for the seamless adaptation of well-established 2D image/video
techniques, enabling efficient and effective processing and analysis of 3D
point cloud sequences. To achieve such re-organization, we design a
self-supervised learning pipeline that is geometrically regularized and driven
by self-reconstructive and deformation field learning objectives. Additionally,
we construct SPCV-based frameworks for both low-level and high-level 3D point
cloud sequence processing and analysis tasks, including action recognition,
temporal interpolation, and compression. Extensive experiments demonstrate the
versatility and superiority of the proposed SPCV, which has the potential to
offer new possibilities for deep learning on unstructured 3D point cloud
sequences. Code will be released at https://github.com/ZENGYIMING-EAMON/SPCV.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01132" title="Abstract">arXiv:2403.01132</a> [<a href="/pdf/2403.01132" title="Download PDF">pdf</a>, <a href="/ps/2403.01132" title="Download PostScript">ps</a>, <a href="/format/2403.01132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPIPN: A Multi Physics-Informed PointNet for solving parametric  acoustic-structure systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinhong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zhijian Zha</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The number of figures is 16. The number of tables is 5. The number of words is 9717
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Machine learning is employed for solving physical systems governed by general
nonlinear partial differential equations (PDEs). However, complex multi-physics
systems such as acoustic-structure coupling are often described by a series of
PDEs that incorporate variable physical quantities, which are referred to as
parametric systems. There are lack of strategies for solving parametric systems
governed by PDEs that involve explicit and implicit quantities. In this paper,
a deep learning-based Multi Physics-Informed PointNet (MPIPN) is proposed for
solving parametric acoustic-structure systems. First, the MPIPN induces an
enhanced point-cloud architecture that encompasses explicit physical quantities
and geometric features of computational domains. Then, the MPIPN extracts local
and global features of the reconstructed point-cloud as parts of solving
criteria of parametric systems, respectively. Besides, implicit physical
quantities are embedded by encoding techniques as another part of solving
criteria. Finally, all solving criteria that characterize parametric systems
are amalgamated to form distinctive sequences as the input of the MPIPN, whose
outputs are solutions of systems. The proposed framework is trained by adaptive
physics-informed loss functions for corresponding computational domains. The
framework is generalized to deal with new parametric conditions of systems. The
effectiveness of the MPIPN is validated by applying it to solve steady
parametric acoustic-structure coupling systems governed by the Helmholtz
equations. An ablation experiment has been implemented to demonstrate the
efficacy of physics-informed impact with a minority of supervised data. The
proposed method yields reasonable precision across all computational domains
under constant parametric conditions and changeable combinations of parametric
conditions for acoustic-structure systems.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01133" title="Abstract">arXiv:2403.01133</a> [<a href="/pdf/2403.01133" title="Download PDF">pdf</a>, <a href="/format/2403.01133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models as Virtual Annotators for Time-series  Physical Sensing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hota%2C+A">Aritra Hota</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Soumyajit Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sandip Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Traditional human-in-the-loop-based annotation for time-series data like
inertial data often requires access to alternate modalities like video or audio
from the environment. These alternate sources provide the necessary information
to the human annotator, as the raw numeric data is often too obfuscated even
for an expert. However, this traditional approach has many concerns surrounding
overall cost, efficiency, storage of additional modalities, time, scalability,
and privacy. Interestingly, recent large language models (LLMs) are also
trained with vast amounts of publicly available alphanumeric data, which allows
them to comprehend and perform well on tasks beyond natural language
processing. Naturally, this opens up a potential avenue to explore LLMs as
virtual annotators where the LLMs will be directly provided the raw sensor data
for annotation instead of relying on any alternate modality. Naturally, this
could mitigate the problems of the traditional human-in-the-loop approach.
Motivated by this observation, we perform a detailed study in this paper to
assess whether the state-of-the-art (SOTA) LLMs can be used as virtual
annotators for labeling time-series physical sensing data. To perform this in a
principled manner, we segregate the study into two major phases. In the first
phase, we investigate the challenges an LLM like GPT-4 faces in comprehending
raw sensor data. Considering the observations from phase 1, in the next phase,
we investigate the possibility of encoding the raw sensor data using SOTA SSL
approaches and utilizing the projected time-series data to get annotations from
the LLM. Detailed evaluation with four benchmark HAR datasets shows that
SSL-based encoding and metric-based guidance allow the LLM to make more
reasonable decisions and provide accurate annotations without requiring
computationally expensive fine-tuning or sophisticated prompt engineering.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01136" title="Abstract">arXiv:2403.01136</a> [<a href="/pdf/2403.01136" title="Download PDF">pdf</a>, <a href="/format/2403.01136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition  and Adaptive Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Juntao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+B">Borui Wan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yanghua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haibin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recent breakthroughs in Large-scale language models (LLMs) have demonstrated
impressive performance on various tasks. The immense sizes of LLMs have led to
very high resource demand and cost for running the models. Though the models
are largely served using uniform high-caliber GPUs nowadays, utilizing a
heterogeneous cluster with a mix of available high- and low-capacity GPUs can
potentially substantially reduce the serving cost. There is a lack of designs
to support efficient LLM serving using a heterogeneous cluster, while the
current solutions focus on model partition and uniform compression among
homogeneous devices. This paper proposes LLM-PQ, a system that advocates
adaptive model quantization and phase-aware partition to improve LLM serving
efficiency on heterogeneous GPU clusters. We carefully decide on
mixed-precision model quantization together with phase-aware model partition
and micro-batch sizing in distributed LLM serving with an efficient algorithm,
to greatly enhance inference throughput while fulfilling user-specified model
quality targets. Extensive experiments on production inference workloads in 11
different clusters demonstrate that LLM-PQ achieves up to 2.88x (2.26x on
average) throughput improvement in inference, showing great advantages over
state-of-the-art works.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01137" title="Abstract">arXiv:2403.01137</a> [<a href="/pdf/2403.01137" title="Download PDF">pdf</a>, <a href="/format/2403.01137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural radiance fields-based holography [Invited]
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minsung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kumano%2C+K">Kai Kumano</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+T">Tomoyoshi Ito</a>, 
<a href="/search/cs?searchtype=author&query=Shimobaba%2C+T">Tomoyoshi Shimobaba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This study presents a novel approach for generating holograms based on the
neural radiance fields (NeRF) technique. Generating three-dimensional (3D) data
is difficult in hologram computation. NeRF is a state-of-the-art technique for
3D light-field reconstruction from 2D images based on volume rendering. The
NeRF can rapidly predict new-view images that do not include a training
dataset. In this study, we constructed a rendering pipeline directly from a 3D
light field generated from 2D images by NeRF for hologram generation using deep
neural networks within a reasonable time. The pipeline comprises three main
components: the NeRF, a depth predictor, and a hologram generator, all
constructed using deep neural networks. The pipeline does not include any
physical calculations. The predicted holograms of a 3D scene viewed from any
direction were computed using the proposed pipeline. The simulation and
experimental results are presented.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01139" title="Abstract">arXiv:2403.01139</a> [<a href="/pdf/2403.01139" title="Download PDF">pdf</a>, <a href="/format/2403.01139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParallelPARC: A Scalable Pipeline for Generating Natural-Language  Analogies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sultan%2C+O">Oren Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Yosef%2C+R">Ron Yosef</a>, 
<a href="/search/cs?searchtype=author&query=Shahaf%2C+D">Dafna Shahaf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Analogy-making is central to human cognition, allowing us to adapt to novel
situations -- an ability that current AI systems still lack. Most analogy
datasets today focus on simple analogies (e.g., word analogies); datasets
including complex types of analogies are typically manually curated and very
small. We believe that this holds back progress in computational analogy. In
this work, we design a data generation pipeline, ParallelPARC (Parallel
Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to
create complex, paragraph-based analogies, as well as distractors, both simple
and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset
of analogies between scientific processes. We publish a gold-set, validated by
humans, and a silver-set, generated automatically. We test LLMs' and humans'
analogy recognition in binary and multiple-choice settings, and found that
humans outperform the best models (~13% gap) after a light supervision. We
demonstrate that our silver-set is useful for training models. Lastly, we show
challenging distractors confuse LLMs, but not humans. We hope our pipeline will
encourage research in this emerging field.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01142" title="Abstract">arXiv:2403.01142</a> [<a href="/pdf/2403.01142" title="Download PDF">pdf</a>, <a href="/format/2403.01142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-guided Low-light Image Enhancement with Inertial Bregman  Alternating Linearized Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chaoyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhongming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Prior-based methods for low-light image enhancement often face challenges in
extracting available prior information from dim images. To overcome this
limitation, we introduce a simple yet effective Retinex model with the proposed
edge extraction prior. More specifically, we design an edge extraction network
to capture the fine edge features from the low-light image directly. Building
upon the Retinex theory, we decompose the low-light image into its illumination
and reflectance components and introduce an edge-guided Retinex model for
enhancing low-light images. To solve the proposed model, we propose a novel
inertial Bregman alternating linearized minimization algorithm. This algorithm
addresses the optimization problem associated with the edge-guided Retinex
model, enabling effective enhancement of low-light images. Through rigorous
theoretical analysis, we establish the convergence properties of the algorithm.
Besides, we prove that the proposed algorithm converges to a stationary point
of the problem through nonconvex optimization theory. Furthermore, extensive
experiments are conducted on multiple real-world low-light image datasets to
demonstrate the efficiency and superiority of the proposed scheme.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01144" title="Abstract">arXiv:2403.01144</a> [<a href="/pdf/2403.01144" title="Download PDF">pdf</a>, <a href="/format/2403.01144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extrapolated Plug-and-Play Three-Operator Splitting Methods for  Nonconvex Optimization with Applications to Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+Z">Zhongming Wu</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+C">Chaoyan Huang</a>, 
<a href="/search/math?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper investigates the convergence properties and applications of the
three-operator splitting method, also known as Davis-Yin splitting (DYS)
method, integrated with extrapolation and Plug-and-Play (PnP) denoiser within a
nonconvex framework. We first propose an extrapolated DYS method to effectively
solve a class of structural nonconvex optimization problems that involve
minimizing the sum of three possible nonconvex functions. Our approach provides
an algorithmic framework that encompasses both extrapolated forward-backward
splitting and extrapolated Douglas-Rachford splitting methods.To establish the
convergence of the proposed method, we rigorously analyze its behavior based on
the Kurdyka-{\L}ojasiewicz property, subject to some tight parameter
conditions. Moreover, we introduce two extrapolated PnP-DYS methods with
convergence guarantee, where the traditional regularization prior is replaced
by a gradient step-based denoiser. This denoiser is designed using a
differentiable neural network and can be reformulated as the proximal operator
of a specific nonconvex functional. We conduct extensive experiments on image
deblurring and image super-resolution problems, where our results showcase the
advantage of the extrapolation strategy and the superior performance of the
learning-based model that incorporates the PnP denoiser in terms of achieving
high-quality recovery images.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01146" title="Abstract">arXiv:2403.01146</a> [<a href="/pdf/2403.01146" title="Download PDF">pdf</a>, <a href="/ps/2403.01146" title="Download PostScript">ps</a>, <a href="/format/2403.01146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutation Analysis with Execution Taints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopinath%2C+R">Rahul Gopinath</a>, 
<a href="/search/cs?searchtype=author&query=Goerz%2C+P">Philipp Goerz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mutation analysis is one of the most effective, but costly means of assessing
the ability of software test suites to prevent bugs. Traditional mutation
analysis involves producing and evaluating syntactic variants of the original
to check whether the test suite under evaluation is capable of distinguishing
between the variant and the original in terms of behavior.
<br />Evaluating each mutant separately means a large amount of redundant
computation, both between the original program and mutants, and also between
different mutants. Previous work explored numerous means of removing
redundancy. However, some amount of redundancy has remained especially in the
post-mutation phase.
<br />In this paper, we propose execution taints--A novel technique that repurposes
dynamic data-flow taints for mutation analysis. Our technique is the only
technique that can remove the redundancy in post-mutation phase, achieving
better efficiency in mutation analysis. We further leverage memoization to
eliminate redundant execution between program variants.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01147" title="Abstract">arXiv:2403.01147</a> [<a href="/pdf/2403.01147" title="Download PDF">pdf</a>, <a href="/ps/2403.01147" title="Download PostScript">ps</a>, <a href="/format/2403.01147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Model for Traffic Incident Detection based on Generative  Adversarial Networks and Transformer Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xinying Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Doudou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jianli Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In addition to enhancing traffic safety and facilitating prompt emergency
response, traffic incident detection plays an indispensable role in intelligent
transportation systems by providing real-time traffic status information. This
enables the realization of intelligent traffic control and management. Previous
research has identified that apart from employing advanced algorithmic models,
the effectiveness of detection is also significantly influenced by challenges
related to acquiring large datasets and addressing dataset imbalances. A hybrid
model combining transformer and generative adversarial networks (GANs) is
proposed to address these challenges. Experiments are conducted on four real
datasets to validate the superiority of the transformer in traffic incident
detection. Additionally, GANs are utilized to expand the dataset and achieve a
balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against
the baseline model. The results demonstrate that the proposed model enhances
the dataset size, balances the dataset, and improves the performance of traffic
incident detection in various aspects.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01152" title="Abstract">arXiv:2403.01152</a> [<a href="/pdf/2403.01152" title="Download PDF">pdf</a>, <a href="/format/2403.01152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of AI-generated Text Forensic Systems: Detection, Attribution,  and Characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumarage%2C+T">Tharindu Kumarage</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+G">Garima Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+P">Paras Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Moraffah%2C+R">Raha Moraffah</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Garland%2C+J">Joshua Garland</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We have witnessed lately a rapid proliferation of advanced Large Language
Models (LLMs) capable of generating high-quality text. While these LLMs have
revolutionized text generation across various domains, they also pose
significant risks to the information ecosystem, such as the potential for
generating convincing propaganda, misinformation, and disinformation at scale.
This paper offers a review of AI-generated text forensic systems, an emerging
field addressing the challenges of LLM misuses. We present an overview of the
existing efforts in AI-generated text forensics by introducing a detailed
taxonomy, focusing on three primary pillars: detection, attribution, and
characterization. These pillars enable a practical understanding of
AI-generated text, from identifying AI-generated content (detection),
determining the specific AI model involved (attribution), and grouping the
underlying intents of the text (characterization). Furthermore, we explore
available resources for AI-generated text forensics research and discuss the
evolving challenges and future directions of forensic systems in an AI era.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01155" title="Abstract">arXiv:2403.01155</a> [<a href="/pdf/2403.01155" title="Download PDF">pdf</a>, <a href="/format/2403.01155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query Recovery from Easy to Hard: Jigsaw Attack against SSE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+H">Hao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianglong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L+T">Laurence T. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaitai Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, accepted in USENIX Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Searchable symmetric encryption schemes often unintentionally disclose
certain sensitive information, such as access, volume, and search patterns.
Attackers can exploit such leakages and other available knowledge related to
the user's database to recover queries. We find that the effectiveness of query
recovery attacks depends on the volume/frequency distribution of keywords.
Queries containing keywords with high volumes/frequencies are more susceptible
to recovery, even when countermeasures are implemented. Attackers can also
effectively leverage these ``special'' queries to recover all others.
<br />By exploiting the above finding, we propose a Jigsaw attack that begins by
accurately identifying and recovering those distinctive queries. Leveraging the
volume, frequency, and co-occurrence information, our attack achieves $90\%$
accuracy in three tested datasets, which is comparable to previous attacks (Oya
et al., USENIX' 22 and Damie et al., USENIX' 21). With the same runtime, our
attack demonstrates an advantage over the attack proposed by Oya et al
(approximately $15\%$ more accuracy when the keyword universe size is 15k).
Furthermore, our proposed attack outperforms existing attacks against widely
studied countermeasures, achieving roughly $60\%$ and $85\%$ accuracy against
the padding and the obfuscation, respectively. In this context, with a large
keyword universe ($\geq$3k), it surpasses current state-of-the-art attacks by
more than $20\%$.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01156" title="Abstract">arXiv:2403.01156</a> [<a href="/pdf/2403.01156" title="Download PDF">pdf</a>, <a href="/format/2403.01156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auxiliary Tasks Enhanced Dual-affinity Learning for Weakly Supervised  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bennamoun%2C+M">Mohammed Bennamoun</a>, 
<a href="/search/cs?searchtype=author&query=Boussaid%2C+F">Farid Boussaid</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Sohel%2C+F">Ferdous Sohel</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Transactions on Neural Networks and Learning Systems. arXiv admin note: substantial text overlap with <a href="/abs/2107.11787">arXiv:2107.11787</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most existing weakly supervised semantic segmentation (WSSS) methods rely on
Class Activation Mapping (CAM) to extract coarse class-specific localization
maps using image-level labels. Prior works have commonly used an off-line
heuristic thresholding process that combines the CAM maps with off-the-shelf
saliency maps produced by a general pre-trained saliency model to produce more
accurate pseudo-segmentation labels. We propose AuxSegNet+, a weakly supervised
auxiliary learning framework to explore the rich information from these
saliency maps and the significant inter-task correlation between saliency
detection and semantic segmentation. In the proposed AuxSegNet+, saliency
detection and multi-label image classification are used as auxiliary tasks to
improve the primary task of semantic segmentation with only image-level
ground-truth labels. We also propose a cross-task affinity learning mechanism
to learn pixel-level affinities from the saliency and segmentation feature
maps. In particular, we propose a cross-task dual-affinity learning module to
learn both pairwise and unary affinities, which are used to enhance the
task-specific features and predictions by aggregating both query-dependent and
query-independent global context for both saliency detection and semantic
segmentation. The learned cross-task pairwise affinity can also be used to
refine and propagate CAM maps to provide better pseudo labels for both tasks.
Iterative improvement of segmentation performance is enabled by cross-task
affinity learning and pseudo-label updating. Extensive experiments demonstrate
the effectiveness of the proposed approach with new state-of-the-art WSSS
results on the challenging PASCAL VOC and MS COCO benchmarks.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01157" title="Abstract">arXiv:2403.01157</a> [<a href="/pdf/2403.01157" title="Download PDF">pdf</a>, <a href="/ps/2403.01157" title="Download PostScript">ps</a>, <a href="/format/2403.01157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Different Debt: An Addition to the Technical Debt Dataset and a  Demonstration Using Developer Personality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graf-Vlachy%2C+L">Lorenz Graf-Vlachy</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S">Stefan Wagner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 7th International Conference on Technical Debt (TechDebt) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background: The "Technical Debt Dataset" (TDD) is a comprehensive dataset on
technical debt (TD) in the main branches of more than 30 Java projects.
However, some TD items produced by SonarQube are not included for many commits,
for instance because the commits failed to compile. This has limited previous
studies using the dataset. Aims and Method: In this paper, we provide an
addition to the dataset that includes an analysis of 278,320 commits of all
branches in a superset of 37 projects using Teamscale. We then demonstrate the
utility of the dataset by exploring the relationship between developer
personality by replicating a prior study. Results: The new dataset allows us to
use a larger sample than prior work could, and we analyze the personality of
111 developers and 5,497 of their commits. The relationships we find between
developer personality and the introduction and removal of TD differ from those
found in prior work. Conclusions: We offer a dataset that may enable future
studies into the topic of TD and we provide additional insights on how
developer personality relates to TD.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01162" title="Abstract">arXiv:2403.01162</a> [<a href="/pdf/2403.01162" title="Download PDF">pdf</a>, <a href="/ps/2403.01162" title="Download PostScript">ps</a>, <a href="/format/2403.01162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Envy-Free House Allocation with Minimum Subsidy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choo%2C+D">Davin Choo</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Y+H">Yan Hao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Suksompong%2C+W">Warut Suksompong</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+N">Nicholas Teh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">House allocation refers to the problem where $m$ houses are to be allocated
to $n$ agents so that each agent receives one house. Since an envy-free house
allocation does not always exist, we consider finding such an allocation in the
presence of subsidy. We show that computing an envy-free allocation with
minimum subsidy is NP-hard in general, but can be done efficiently if $m$
differs from $n$ by an additive constant or if the agents have identical
utilities.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01163" title="Abstract">arXiv:2403.01163</a> [<a href="/pdf/2403.01163" title="Download PDF">pdf</a>, <a href="/format/2403.01163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning  Diverse Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Weihao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Keqing He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yejie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dayuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained language models have been successful in many scenarios. However,
their usefulness in task-oriented dialogues is limited due to the intrinsic
linguistic differences between general text and task-oriented dialogues.
Current task-oriented dialogue pre-training methods rely on a contrastive
framework, which faces challenges such as selecting true positives and hard
negatives, as well as lacking diversity. In this paper, we propose a novel
dialogue pre-training model called BootTOD. It learns task-oriented dialogue
representations via a self-bootstrapping framework. Unlike contrastive
counterparts, BootTOD aligns context and context+response representations and
dismisses the requirements of contrastive pairs. BootTOD also uses multiple
appropriate response targets to model the intrinsic one-to-many diversity of
human conversations. Experimental results show that BootTOD outperforms strong
TOD baselines on diverse downstream dialogue tasks.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01164" title="Abstract">arXiv:2403.01164</a> [<a href="/pdf/2403.01164" title="Download PDF">pdf</a>, <a href="/format/2403.01164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeteGen: Heterogeneous Parallel Inference for Large Language Models on  Resource-Constrained Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuanlei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Bin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haotian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shenggan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MLSys 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In recent times, the emergence of Large Language Models (LLMs) has resulted
in increasingly larger model size, posing challenges for inference on
low-resource devices. Prior approaches have explored offloading to facilitate
low-memory inference but often suffer from efficiency due to I/O bottlenecks.
To achieve low-latency LLMs inference on resource-constrained devices, we
introduce HeteGen, a novel approach that presents a principled framework for
heterogeneous parallel computing using CPUs and GPUs. Based on this framework,
HeteGen further employs heterogeneous parallel computing and asynchronous
overlap for LLMs to mitigate I/O bottlenecks. Our experiments demonstrate a
substantial improvement in inference speed, surpassing state-of-the-art methods
by over 317% at most.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01165" title="Abstract">arXiv:2403.01165</a> [<a href="/pdf/2403.01165" title="Download PDF">pdf</a>, <a href="/format/2403.01165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient  Fine-Tuning of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linhai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Deyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guoqiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code and results will be available at <a href="https://github.com/callanwu/STAR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Though Large Language Models (LLMs) have demonstrated the powerful
capabilities of few-shot learning through prompting methods, supervised
training is still necessary for complex reasoning tasks. Because of their
extensive parameters and memory consumption, both Parameter-Efficient
Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been
proposed for LLMs. Nevertheless, the issue of large annotated data consumption,
the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is
to combine the PEFT method with active learning. However, the experimental
results show that such a combination is not trivial and yields inferior
results. Through probe experiments, such observation might be explained by two
main reasons: uncertainty gap and poor model calibration. Therefore, in this
paper, we propose a novel approach to effectively integrate uncertainty-based
active learning and LoRA. Specifically, for the uncertainty gap, we introduce a
dynamic uncertainty measurement that combines the uncertainty of the base model
and the uncertainty of the full model during the iteration of active learning.
For poor model calibration, we incorporate the regularization method during
LoRA training to keep the model from being over-confident, and the Monte-Carlo
dropout mechanism is employed to enhance the uncertainty estimation.
Experimental results show that the proposed approach outperforms existing
baseline models on three complex reasoning tasks.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01166" title="Abstract">arXiv:2403.01166</a> [<a href="/pdf/2403.01166" title="Download PDF">pdf</a>, <a href="/format/2403.01166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable  Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linhai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Deyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guoqiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code and results will be available at <a href="https://github.com/callanwu/DINER">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Though notable progress has been made, neural-based aspect-based sentiment
analysis (ABSA) models are prone to learn spurious correlations from annotation
biases, resulting in poor robustness on adversarial data transformations. Among
the debiasing solutions, causal inference-based methods have attracted much
research attention, which can be mainly categorized into causal intervention
methods and counterfactual reasoning methods. However, most of the present
debiasing methods focus on single-variable causal inference, which is not
suitable for ABSA with two input variables (the target aspect and the review).
In this paper, we propose a novel framework based on multi-variable causal
inference for debiasing ABSA. In this framework, different types of biases are
tackled based on different causal intervention methods. For the review branch,
the bias is modeled as indirect confounding from context, where backdoor
adjustment intervention is employed for debiasing. For the aspect branch, the
bias is described as a direct correlation with labels, where counterfactual
reasoning is adopted for debiasing. Extensive experiments demonstrate the
effectiveness of the proposed method compared to various baselines on the two
widely used real-world aspect robustness test set datasets.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01169" title="Abstract">arXiv:2403.01169</a> [<a href="/pdf/2403.01169" title="Download PDF">pdf</a>, <a href="/format/2403.01169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn Suspected Anomalies from Event Prompts for Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chenchen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuexian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaohao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiafei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jiangbo Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most models for weakly supervised video anomaly detection (WS-VAD) rely on
multiple instance learning, aiming to distinguish normal and abnormal snippets
without specifying the type of anomaly. The ambiguous nature of anomaly
definitions across contexts introduces bias in detecting abnormal and normal
snippets within the abnormal bag. Taking the first step to show the model why
it is anomalous, a novel framework is proposed to guide the learning of
suspected anomalies from event prompts. Given a textual prompt dictionary of
potential anomaly events and the captions generated from anomaly videos, the
semantic anomaly similarity between them could be calculated to identify the
suspected anomalous events for each video snippet. It enables a new
multi-prompt learning process to constrain the visual-semantic features across
all videos, as well as provides a new way to label pseudo anomalies for
self-training. To demonstrate effectiveness, comprehensive experiments and
detailed ablation studies are conducted on four datasets, namely XD-Violence,
UCF-Crime, TAD, and ShanghaiTech. Our proposed model outperforms most
state-of-the-art methods in terms of AP or AUC (82.6\%, 87.7\%, 93.1\%, and
97.4\%). Furthermore, it shows promising performance in open-set and
cross-dataset cases.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01172" title="Abstract">arXiv:2403.01172</a> [<a href="/pdf/2403.01172" title="Download PDF">pdf</a>, <a href="/format/2403.01172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Run-time Introspection of 2D Object Detection in Automated Driving  Systems Using Learning Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yatbaz%2C+H+Y">Hakan Yekta Yatbaz</a>, 
<a href="/search/cs?searchtype=author&query=Dianati%2C+M">Mehrdad Dianati</a>, 
<a href="/search/cs?searchtype=author&query=Koufos%2C+K">Konstantinos Koufos</a>, 
<a href="/search/cs?searchtype=author&query=Woodman%2C+R">Roger Woodman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Intelligent Vehicles. 15 pages, 7 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reliable detection of various objects and road users in the surrounding
environment is crucial for the safe operation of automated driving systems
(ADS). Despite recent progresses in developing highly accurate object detectors
based on Deep Neural Networks (DNNs), they still remain prone to detection
errors, which can lead to fatal consequences in safety-critical applications
such as ADS. An effective remedy to this problem is to equip the system with
run-time monitoring, named as introspection in the context of autonomous
systems. Motivated by this, we introduce a novel introspection solution, which
operates at the frame level for DNN-based 2D object detection and leverages
neural network activation patterns. The proposed approach pre-processes the
neural activation patterns of the object detector's backbone using several
different modes. To provide extensive comparative analysis and fair comparison,
we also adapt and implement several state-of-the-art (SOTA) introspection
mechanisms for error detection in 2D object detection, using one-stage and
two-stage object detectors evaluated on KITTI and BDD datasets. We compare the
performance of the proposed solution in terms of error detection, adaptability
to dataset shift, and, computational and memory resource requirements. Our
performance evaluation shows that the proposed introspection solution
outperforms SOTA methods, achieving an absolute reduction in the missed error
ratio of 9% to 17% in the BDD dataset.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01174" title="Abstract">arXiv:2403.01174</a> [<a href="/pdf/2403.01174" title="Download PDF">pdf</a>, <a href="/format/2403.01174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent and Asymptotically Statistically-Efficient Solution to Camera  Motion Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guangyang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Q">Qingcheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghan Li</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+B">Biqiang Mu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Ling Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junfeng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given 2D point correspondences between an image pair, inferring the camera
motion is a fundamental issue in the computer vision community. The existing
works generally set out from the epipolar constraint and estimate the essential
matrix, which is not optimal in the maximum likelihood (ML) sense. In this
paper, we dive into the original measurement model with respect to the rotation
matrix and normalized translation vector and formulate the ML problem. We then
propose a two-step algorithm to solve it: In the first step, we estimate the
variance of measurement noises and devise a consistent estimator based on bias
elimination; In the second step, we execute a one-step Gauss-Newton iteration
on manifold to refine the consistent estimate. We prove that the proposed
estimate owns the same asymptotic statistical properties as the ML estimate:
The first is consistency, i.e., the estimate converges to the ground truth as
the point number increases; The second is asymptotic efficiency, i.e., the mean
squared error of the estimate converges to the theoretical lower bound --
Cramer-Rao bound. In addition, we show that our algorithm has linear time
complexity. These appealing characteristics endow our estimator with a great
advantage in the case of dense point correspondences. Experiments on both
synthetic data and real images demonstrate that when the point number reaches
the order of hundreds, our estimator outperforms the state-of-the-art ones in
terms of estimation accuracy and CPU time.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01180" title="Abstract">arXiv:2403.01180</a> [<a href="/pdf/2403.01180" title="Download PDF">pdf</a>, <a href="/format/2403.01180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misconfiguration in O-RAN: Analysis of the impact of AI/ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yungaicela-Naula%2C+N">Noe Yungaicela-Naula</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vishal Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Scott-Hayward%2C+S">Sandra Scott-Hayward</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">User demand on network communication infrastructure has never been greater
with applications such as extended reality, holographic telepresence, and
wireless brain-computer interfaces challenging current networking capabilities.
Open RAN (O-RAN) is critical to supporting new and anticipated uses of 6G and
beyond. It promotes openness and standardisation, increased flexibility through
the disaggregation of Radio Access Network (RAN) components, supports
programmability, flexibility, and scalability with technologies such as
Software-Defined Networking (SDN), Network Function Virtualization (NFV), and
cloud, and brings automation through the RAN Intelligent Controller (RIC).
Furthermore, the use of xApps, rApps, and Artificial Intelligence/Machine
Learning (AI/ML) within the RIC enables efficient management of complex RAN
operations. However, due to the open nature of O-RAN and its support for
heterogeneous systems, the possibility of misconfiguration problems becomes
critical. In this paper, we present a thorough analysis of the potential
misconfiguration issues in O-RAN with respect to integration and operation, the
use of SDN and NFV, and, specifically, the use of AI/ML. The opportunity for
AI/ML to be used to identify these misconfigurations is investigated. A case
study is presented to illustrate the direct impact on the end user of
conflicting policies amongst xApps along with a potential AI/ML-based solution
to this problem. This research presents a first analysis of the impact of AI/ML
on misconfiguration challenges in O-RAN
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01181" title="Abstract">arXiv:2403.01181</a> [<a href="/pdf/2403.01181" title="Download PDF">pdf</a>, <a href="/format/2403.01181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shaping Multi-Robot Patrol Performance with Heterogeneity in Individual  Learning Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=York%2C+C">Connor York</a>, 
<a href="/search/cs?searchtype=author&query=Madin%2C+Z+R">Zachary R Madin</a>, 
<a href="/search/cs?searchtype=author&query=O%27Dowd%2C+P">Paul O&#x27;Dowd</a>, 
<a href="/search/cs?searchtype=author&query=Hunt%2C+E+R">Edmund R Hunt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Individual differences in learning behavior within social groups, whether in
humans, other animals, or among robots, can have significant effects on
collective task performance. This is because it can affect individuals'
response to the environment and their interactions with each other. In recent
years there has been rising interest in the question of how individual
differences, whether in learning or other traits, affect collective outcomes:
studied, for example, in social insect foraging behavior. Multi-robot, 'swarm'
systems have a heritage of bioinspiration from such examples, and here we
consider whether heterogeneity in a learning behavior called latent inhibition
(LI) may be useful for a team of patrolling robots tasked with environmental
monitoring and anomaly detection. Individuals with high LI can be seen as
better at learning to be inattentive to irrelevant or unrewarding stimuli,
while low LI individuals might be seen as 'distractible' and yet, more
positively, more exploratory. We introduce a simple model of the effects of LI
as the probability of re-searching a location for a reward (anomalous reading)
where it has previously been found to be unrewarding (irrelevant). In simulated
patrols, we find that a negatively skewed distribution of mostly high LI
robots, and just a single low LI robot, is collectively most effective at
monitoring dynamic environments. These results are an example of 'functional
heterogeneity' in 'swarm engineering' and could inform predictions for
ecological distributions of learning traits within social groups.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01182" title="Abstract">arXiv:2403.01182</a> [<a href="/pdf/2403.01182" title="Download PDF">pdf</a>, <a href="/format/2403.01182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> d-DSE: Distinct Dynamic Searchable Encryption Resisting Volume Leakage  in Encrypted Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L+T">Laurence T. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaitai Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23pages, 13 figures, will be published in USENIX Security'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Dynamic Searchable Encryption (DSE) has emerged as a solution to efficiently
handle and protect large-scale data storage in encrypted databases (EDBs).
Volume leakage poses a significant threat, as it enables adversaries to
reconstruct search queries and potentially compromise the security and privacy
of data. Padding strategies are common countermeasures for the leakage, but
they significantly increase storage and communication costs. In this work, we
develop a new perspective to handle volume leakage. We start with distinct
search and further explore a new concept called \textit{distinct} DSE
(\textit{d}-DSE).
<br />We also define new security notions, in particular Distinct with
Volume-Hiding security, as well as forward and backward privacy, for the new
concept. Based on \textit{d}-DSE, we construct the \textit{d}-DSE designed EDB
with related constructions for distinct keyword (d-KW-\textit{d}DSE), keyword
(KW-\textit{d}DSE), and join queries (JOIN-\textit{d}DSE) and update queries in
encrypted databases. We instantiate a concrete scheme \textsf{BF-SRE},
employing Symmetric Revocable Encryption. We conduct extensive experiments on
real-world datasets, such as Crime, Wikipedia, and Enron, for performance
evaluation. The results demonstrate that our scheme is practical in data search
and with comparable computational performance to the SOTA DSE scheme
(\textsf{MITRA}*, \textsf{AURA}) and padding strategies (\textsf{SEAL},
\textsf{ShieldDB}). Furthermore, our proposal sharply reduces the communication
cost as compared to padding strategies, with roughly 6.36 to 53.14x advantage
for search queries.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01183" title="Abstract">arXiv:2403.01183</a> [<a href="/pdf/2403.01183" title="Download PDF">pdf</a>, <a href="/format/2403.01183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Self-Supervised Learning for Scene Recognition in Child  Sexual Abuse Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valois%2C+P+H+V">Pedro H. V. Valois</a>, 
<a href="/search/cs?searchtype=author&query=Macedo%2C+J">Jo&#xe3;o Macedo</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+L+S+F">Leo S. F. Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+J+A+d">Jefersson A. dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+S">Sandra Avila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, 4 tables. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Crime in the 21st century is split into a virtual and real world. However,
the former has become a global menace to people's well-being and security in
the latter. The challenges it presents must be faced with unified global
cooperation, and we must rely more than ever on automated yet trustworthy tools
to combat the ever-growing nature of online offenses. Over 10 million child
sexual abuse reports are submitted to the US National Center for Missing &amp;
Exploited Children every year, and over 80% originated from online sources.
Therefore, investigation centers and clearinghouses cannot manually process and
correctly investigate all imagery. In light of that, reliable automated tools
that can securely and efficiently deal with this data are paramount. In this
sense, the scene recognition task looks for contextual cues in the environment,
being able to group and classify child sexual abuse data without requiring to
be trained on sensitive material. The scarcity and limitations of working with
child sexual abuse images lead to self-supervised learning, a machine-learning
methodology that leverages unlabeled data to produce powerful representations
that can be more easily transferred to target tasks. This work shows that
self-supervised deep learning models pre-trained on scene-centric data can
reach 71.6% balanced accuracy on our indoor scene classification task and, on
average, 2.2 percentage points better performance than a fully supervised
version. We cooperate with Brazilian Federal Police experts to evaluate our
indoor classification model on actual child abuse material. The results
demonstrate a notable discrepancy between the features observed in widely used
scene datasets and those depicted on sensitive materials.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01185" title="Abstract">arXiv:2403.01185</a> [<a href="/pdf/2403.01185" title="Download PDF">pdf</a>, <a href="/format/2403.01185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Exploration and Exploitation in LLM using Soft RLLF for  Enhanced Negation Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha-Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+K">Ken Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> JURISIN 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Finetuning approaches in NLP often focus on exploitation rather than
exploration, which may lead to suboptimal models. Given the vast search space
of natural language, this limited exploration can restrict their performance in
complex, high-stakes domains, where accurate negation understanding and logical
reasoning abilities are crucial. To address this issue, we leverage
Reinforcement Learning from Logical Feedback (RLLF) to create an effective
balance between exploration and exploitation in LLMs. Our approach employs an
appropriate benchmark dataset for training and evaluation, highlighting the
importance of exploration in enhancing negation understanding capabilities. We
compare the performance of our RLLF-enhanced LLMs with baseline models trained
without RLLF, demonstrating the value of this balanced approach. Furthermore,
we showcase the potential of our method in legal AI applications by employing
transfer learning and evaluating its impact on negation understanding. Our
experimental results exhibit the effectiveness of balancing exploration and
exploitation with RLLF in improving LLMs' negation capabilities. This has
implications for the development of more accurate, reliable, and logically
consistent language models in high-stakes domains.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01186" title="Abstract">arXiv:2403.01186</a> [<a href="/pdf/2403.01186" title="Download PDF">pdf</a>, <a href="/ps/2403.01186" title="Download PostScript">ps</a>, <a href="/format/2403.01186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evault for legal records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+A">Anas S</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+A">Anuragav S</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+A">Abhishek R</a>, 
<a href="/search/cs?searchtype=author&query=K%2C+S">Sachin K</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Blockchain, evault, legal records
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Innovative solution for addressing the challenges in the legal records
management system through a blockchain-based eVault platform. Our objective is
to create a secure, transparent, and accessible ecosystem that caters to the
needs of all stakeholders, including lawyers, judges, clients, and registrars.
First and foremost, our solution is built on a robust blockchain platform like
Ethereum harnessing the power of smart contracts to manage access, permissions,
and transactions effectively. This ensures the utmost security and transparency
in every interaction within the system. To make our eVault system
user-friendly, we've developed intuitive interfaces for all stakeholders.
Lawyers, judges, clients, and even registrars can effortlessly upload and
retrieve legal documents, track changes, and share information within the
platform. But that's not all; we've gone a step further by incorporating a
document creation and saving feature within our app and website. This feature
allows users to generate and securely store legal documents, streamlining the
entire documentation process.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01187" title="Abstract">arXiv:2403.01187</a> [<a href="/pdf/2403.01187" title="Download PDF">pdf</a>, <a href="/ps/2403.01187" title="Download PostScript">ps</a>, <a href="/format/2403.01187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compositional Typed Semantics for Universal Dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradford%2C+L">Laurestine Bradford</a>, 
<a href="/search/cs?searchtype=author&query=O%27Donnell%2C+T+J">Timothy John O&#x27;Donnell</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 1 table. For related code, see <a href="https://github.com/McGill-NLP/ud-to-meaning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Languages may encode similar meanings using different sentence structures.
This makes it a challenge to provide a single set of formal rules that can
derive meanings from sentences in many languages at once. To overcome the
challenge, we can take advantage of language-general connections between
meaning and syntax, and build on cross-linguistically parallel syntactic
structures. We introduce UD Type Calculus, a compositional, principled, and
language-independent system of semantic types and logical forms for lexical
items which builds on a widely-used language-general dependency syntax
framework. We explain the essential features of UD Type Calculus, which all
involve giving dependency relations denotations just like those of words. These
allow UD-TC to derive correct meanings for sentences with a wide range of
syntactic structures by making use of dependency labels. Finally, we present
evaluation results on a large existing corpus of sentences and their logical
forms, showing that UD-TC can produce meanings comparable with our baseline.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01189" title="Abstract">arXiv:2403.01189</a> [<a href="/pdf/2403.01189" title="Download PDF">pdf</a>, <a href="/format/2403.01189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Unbiased Diffusion Models From Biased Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yeongmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+B">Byeonghu Na</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minsang Park</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">JoonHo Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wanmo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+I">Il-Chul Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With significant advancements in diffusion models, addressing the potential
risks of dataset bias becomes increasingly important. Since generated outputs
directly suffer from dataset bias, mitigating latent bias becomes a key factor
in improving sample quality and proportion. This paper proposes time-dependent
importance reweighting to mitigate the bias for the diffusion models. We
demonstrate that the time-dependent density ratio becomes more precise than
previous approaches, thereby minimizing error propagation in generative
learning. While directly applying it to score-matching is intractable, we
discover that using the time-dependent density ratio both for reweighting and
score correction can lead to a tractable form of the objective function to
regenerate the unbiased data density. Furthermore, we theoretically establish a
connection with traditional score-matching, and we demonstrate its convergence
to an unbiased distribution. The experimental evidence supports the usefulness
of the proposed method, which outperforms baselines including time-independent
importance reweighting on CIFAR-10, CIFAR-100, FFHQ, and CelebA with various
bias settings. Our code is available at https://github.com/alsdudrla10/TIW-DSM.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01193" title="Abstract">arXiv:2403.01193</a> [<a href="/pdf/2403.01193" title="Download PDF">pdf</a>, <a href="/format/2403.01193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foulds%2C+P+F+J+R">Philip Feldman. James R. Foulds</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shimei Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages, 1 Figure, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) like ChatGPT demonstrate the remarkable progress
of artificial intelligence. However, their tendency to hallucinate -- generate
plausible but false information -- poses a significant challenge. This issue is
critical, as seen in recent court cases where ChatGPT's use led to citations of
non-existent legal rulings. This paper explores how Retrieval-Augmented
Generation (RAG) can counter hallucinations by integrating external knowledge
with prompts. We empirically evaluate RAG against standard LLMs using prompts
designed to induce hallucinations. Our results show that RAG increases accuracy
in some cases, but can still be misled when prompts directly contradict the
model's pre-trained understanding. These findings highlight the complex nature
of hallucinations and the need for more robust solutions to ensure LLM
reliability in real-world applications. We offer practical recommendations for
RAG deployment and discuss implications for the development of more trustworthy
LLMs.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01194" title="Abstract">arXiv:2403.01194</a> [<a href="/pdf/2403.01194" title="Download PDF">pdf</a>, <a href="/format/2403.01194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Rapidly-exploring Random Tree Algorithms Applied  to Ship Trajectory Planning and Behavior Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tengesdal%2C+T">Trym Tengesdal</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+T+A">Tom Arne Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Johansen%2C+T+A">Tor Arne Johansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Rapidly Exploring Random Tree (RRT) algorithms are popular for sampling-based
planning for nonholonomic vehicles in unstructured environments. However, we
argue that previous work does not illuminate the challenges when employing such
algorithms. Thus, in this article, we do a first comparison study of the
performance of the following previously proposed RRT algorithm variants;
Potential-Quick RRT* (PQ-RRT*), Informed RRT* (IRRT*), RRT* and RRT, for
single-query nonholonomic motion planning over several cases in the
unstructured maritime environment. The practicalities of employing such
algorithms in the maritime domain are also discussed. On the side, we contend
that these algorithms offer value not only for Collision Avoidance Systems
(CAS) trajectory planning, but also for the verification of CAS through vessel
behavior generation.
<br />Naturally, optimal RRT variants yield more distance-optimal paths at the cost
of increased computational time due to the tree wiring process with nearest
neighbor consideration. PQ-RRT* achieves marginally better results than IRRT*
and RRT*, at the cost of higher tuning complexity and increased wiring time.
Based on the results, we argue that for time-critical applications the
considered RRT algorithms are, as stand-alone planners, more suitable for use
in smaller problems or problems with low obstacle congestion ratio. This is
attributed to the curse of dimensionality, and trade-off with available memory
and computational resources.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01196" title="Abstract">arXiv:2403.01196</a> [<a href="/pdf/2403.01196" title="Download PDF">pdf</a>, <a href="/format/2403.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation in the Covid domain: an English-Irish case study for  LoResMT 2021
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 4th Workshop on Technologies for MT of Low
  Resource Languages (LoResMT2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Translation models for the specific domain of translating Covid data from
English to Irish were developed for the LoResMT 2021 shared task. Domain
adaptation techniques, using a Covid-adapted generic 55k corpus from the
Directorate General of Translation, were applied. Fine-tuning, mixed
fine-tuning and combined dataset approaches were compared with models trained
on an extended in-domain dataset. As part of this study, an English-Irish
dataset of Covid related data, from the Health and Education domains, was
developed. The highest-performing model used a Transformer architecture trained
with an extended in-domain Covid dataset. In the context of this study, we have
demonstrated that extending an 8k in-domain baseline dataset by just 5k lines
improved the BLEU score by 27 points.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01197" title="Abstract">arXiv:2403.01197</a> [<a href="/pdf/2403.01197" title="Download PDF">pdf</a>, <a href="/format/2403.01197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+S">Shanghaoran Quan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The performance of the reward model (RM) is a critical factor in improving
the effectiveness of the large language model (LLM) during alignment
fine-tuning. There remain two challenges in RM training: 1) training the same
RM using various categories of data may cause its generalization performance to
suffer from multi-task disturbance, and 2) the human annotation consistency
rate is generally only $60\%$ to $75\%$, causing training data to contain a lot
of noise. To tackle these two challenges, we introduced the idea of
Mixture-of-Experts (MoE) into the field of RM for the first time. We propose
the Double-Layer MoE RM (DMoERM). The outer layer MoE is a sparse model. After
classifying an input into task categories, we route it to the corresponding
inner layer task-specific model. The inner layer MoE is a dense model. We
decompose the specific task into multiple capability dimensions and
individually fine-tune a LoRA expert on each one. Their outputs are then
synthesized by an MLP to compute the final rewards. To minimize costs, we call
a public LLM API to obtain the capability preference labels. The validation on
manually labeled datasets confirms that our model attains superior consistency
with human preference and outstrips advanced generative approaches. Meanwhile,
through BoN sampling and RL experiments, we demonstrate that our model
outperforms state-of-the-art ensemble methods of RM and mitigates the
overoptimization problem. Our code and dataset are available at:
https://github.com/quanshr/DMoERM-v1.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01199" title="Abstract">arXiv:2403.01199</a> [<a href="/pdf/2403.01199" title="Download PDF">pdf</a>, <a href="/ps/2403.01199" title="Download PostScript">ps</a>, <a href="/format/2403.01199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Case for Animal-Friendly AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghose%2C+S">Sankalpa Ghose</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+Y+F">Yip Fai Tse</a>, 
<a href="/search/cs?searchtype=author&query=Rasaee%2C+K">Kasra Rasaee</a>, 
<a href="/search/cs?searchtype=author&query=Sebo%2C+J">Jeff Sebo</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+P">Peter Singer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Workshop on Public Sector LLMs: Algorithmic and Sociotechnical Design. 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial intelligence is seen as increasingly important, and potentially
profoundly so, but the fields of AI ethics and AI engineering have not fully
recognized that these technologies, including large language models (LLMs),
will have massive impacts on animals. We argue that this impact matters,
because animals matter morally.
<br />As a first experiment in evaluating animal consideration in LLMs, we
constructed a proof-of-concept Evaluation System, which assesses LLM responses
and biases from multiple perspectives. This system evaluates LLM outputs by two
criteria: their truthfulness, and the degree of consideration they give to the
interests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using
a set of structured queries and predefined normative perspectives. Preliminary
results suggest that the outcomes of the tested models can be benchmarked
regarding the consideration they give to animals, and that generated positions
and biases might be addressed and mitigated with more developed and validated
systems.
<br />Our research contributes one possible approach to integrating animal ethics
in AI, opening pathways for future studies and practical applications in
various fields, including education, public policy, and regulation, that
involve or relate to animals and society. Overall, this study serves as a step
towards more useful and responsible AI systems that better recognize and
respect the vital interests and perspectives of all sentient beings.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01203" title="Abstract">arXiv:2403.01203</a> [<a href="/pdf/2403.01203" title="Download PDF">pdf</a>, <a href="/format/2403.01203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Label Calibration Semi-supervised Multi-Modal Entity Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+P">Pengnian Qi</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xigang Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chunlai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Biao Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Databases (cs.DB)

</div>
<p class="mathjax">Multi-modal entity alignment (MMEA) aims to identify equivalent entities
between two multi-modal knowledge graphs for integration. Unfortunately, prior
arts have attempted to improve the interaction and fusion of multi-modal
information, which have overlooked the influence of modal-specific noise and
the usage of labeled and unlabeled data in semi-supervised settings. In this
work, we introduce a Pseudo-label Calibration Multi-modal Entity Alignment
(PCMEA) in a semi-supervised way. Specifically, in order to generate holistic
entity representations, we first devise various embedding modules and attention
mechanisms to extract visual, structural, relational, and attribute features.
Different from the prior direct fusion methods, we next propose to exploit
mutual information maximization to filter the modal-specific noise and to
augment modal-invariant commonality. Then, we combine pseudo-label calibration
with momentum-based contrastive learning to make full use of the labeled and
unlabeled data, which improves the quality of pseudo-label and pulls aligned
entities closer. Finally, extensive experiments on two MMEA datasets
demonstrate the effectiveness of our PCMEA, which yields state-of-the-art
performance.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01204" title="Abstract">arXiv:2403.01204</a> [<a href="/pdf/2403.01204" title="Download PDF">pdf</a>, <a href="/ps/2403.01204" title="Download PostScript">ps</a>, <a href="/format/2403.01204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic gradient descent for streaming linear and rectified linear  systems with Massart noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Halyun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Needell%2C+D">Deanna Needell</a>, 
<a href="/search/cs?searchtype=author&query=Rebrova%2C+E">Elizaveta Rebrova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose SGD-exp, a stochastic gradient descent approach for linear and
ReLU regressions under Massart noise (adversarial semi-random corruption model)
for the fully streaming setting. We show novel nearly linear convergence
guarantees of SGD-exp to the true parameter with up to $50\%$ Massart
corruption rate, and with any corruption rate in the case of symmetric
oblivious corruptions. This is the first convergence guarantee result for
robust ReLU regression in the streaming setting, and it shows the improved
convergence rate over previous robust methods for $L_1$ linear regression due
to a choice of an exponentially decaying step size, known for its efficiency in
practice. Our analysis is based on the drift analysis of a discrete stochastic
process, which could also be interesting on its own.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01208" title="Abstract">arXiv:2403.01208</a> [<a href="/pdf/2403.01208" title="Download PDF">pdf</a>, <a href="/format/2403.01208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Science of Data Collection: Insights from Surveys can Improve  Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eckman%2C+S">Stephanie Eckman</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+B">Barbara Plank</a>, 
<a href="/search/cs?searchtype=author&query=Kreuter%2C+F">Frauke Kreuter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures. Position paper, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Whether future AI models make the world safer or less safe for humans rests
in part on our ability to efficiently collect accurate data from people about
what they want the models to do. However, collecting high quality data is
difficult, and most AI/ML researchers are not trained in data collection
methods. The growing emphasis on data-centric AI highlights the potential of
data to enhance model performance. It also reveals an opportunity to gain
insights from survey methodology, the science of collecting high-quality survey
data.
<br />In this position paper, we summarize lessons from the survey methodology
literature and discuss how they can improve the quality of training and
feedback data, which in turn improve model performance. Based on the cognitive
response process model, we formulate specific hypotheses about the aspects of
label collection that may impact training data quality. We also suggest
collaborative research ideas into how possible biases in data collection can be
mitigated, making models more accurate and human-centric.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01209" title="Abstract">arXiv:2403.01209</a> [<a href="/pdf/2403.01209" title="Download PDF">pdf</a>, <a href="/format/2403.01209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zirui Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Derong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qiyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinxiao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a novel framework for multi-label image recognition
without any training data, called data-free framework, which uses knowledge of
pre-trained Large Language Model (LLM) to learn prompts to adapt pretrained
Vision-Language Model (VLM) like CLIP to multilabel classification. Through
asking LLM by well-designed questions, we acquire comprehensive knowledge about
characteristics and contexts of objects, which provides valuable text
descriptions for learning prompts. Then we propose a hierarchical prompt
learning method by taking the multi-label dependency into consideration,
wherein a subset of category-specific prompt tokens are shared when the
corresponding objects exhibit similar attributes or are more likely to
co-occur. Benefiting from the remarkable alignment between visual and
linguistic semantics of CLIP, the hierarchical prompts learned from text
descriptions are applied to perform classification of images during inference.
Our framework presents a new way to explore the synergies between multiple
pre-trained models for novel category recognition. Extensive experiments on
three public datasets (MS-COCO, VOC2007, and NUS-WIDE) demonstrate that our
method achieves better results than the state-of-the-art methods, especially
outperforming the zero-shot multi-label recognition methods by 4.7% in mAP on
MS-COCO.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01210" title="Abstract">arXiv:2403.01210</a> [<a href="/pdf/2403.01210" title="Download PDF">pdf</a>, <a href="/format/2403.01210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with  Target Scattering Feature Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiahao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jiale Duan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Binyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haifeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural network-based Synthetic Aperture Radar (SAR) target recognition
models are susceptible to adversarial examples. Current adversarial example
generation methods for SAR imagery primarily operate in the 2D digital domain,
known as image adversarial examples. Recent work, while considering SAR imaging
scatter mechanisms, fails to account for the actual imaging process, rendering
attacks in the three-dimensional physical domain infeasible, termed pseudo
physics adversarial examples. To address these challenges, this paper proposes
SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by
altering the scattering feature parameters of target objects. Specifically, we
iteratively optimize the coherent energy accumulation of the target echo by
perturbing the reflection coefficient and scattering coefficient in the
scattering feature parameters of the three-dimensional target object, and
obtain the adversarial example after echo signal processing and imaging
processing in the RaySAR simulator. Experimental results show that compared to
digital adversarial attack methods, SAR-AE-SFP Attack significantly improves
attack efficiency on CNN-based models (over 30\%) and Transformer-based models
(over 13\%), demonstrating significant transferability of attack effects across
different models and perspectives.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01212" title="Abstract">arXiv:2403.01212</a> [<a href="/pdf/2403.01212" title="Download PDF">pdf</a>, <a href="/format/2403.01212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCIG: Two-Stage Controlled Image Generation with Quality Enhancement  through Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Salaheldin Mohamed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, significant progress has been made in the development of
text- to-image generation models. However, these models still face limitations
when it comes to achieving full controllability during the generation process.
Often, spe- cific training or the use of limited models is required, and even
then, they have certain restrictions. To address these challenges, A two-stage
method that effec- tively combines controllability and high quality in the
generation of images is proposed. This approach leverages the expertise of
pre-trained models to achieve precise control over the generated images, while
also harnessing the power of diffusion models to achieve state-of-the-art
quality. By separating controllability from high quality, This method achieves
outstanding results. It is compatible with both latent and image space
diffusion models, ensuring versatility and flexibil- ity. Moreover, This
approach consistently produces comparable outcomes to the current
state-of-the-art methods in the field. Overall, This proposed method rep-
resents a significant advancement in text-to-image generation, enabling
improved controllability without compromising on the quality of the generated
images.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01214" title="Abstract">arXiv:2403.01214</a> [<a href="/pdf/2403.01214" title="Download PDF">pdf</a>, <a href="/format/2403.01214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Box-supervised Instance Segmentation with Pseudo Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Ling Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Pengtao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L+Y">Lin Yuanbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+L">Linlin Ou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The realm of Weakly Supervised Instance Segmentation (WSIS) under box
supervision has garnered substantial attention, showcasing remarkable
advancements in recent years. However, the limitations of box supervision
become apparent in its inability to furnish effective information for
distinguishing foreground from background within the specified target box. This
research addresses this challenge by introducing pseudo-depth maps into the
training process of the instance segmentation network, thereby boosting its
performance by capturing depth differences between instances. These
pseudo-depth maps are generated using a readily available depth predictor and
are not necessary during the inference stage. To enable the network to discern
depth features when predicting masks, we integrate a depth prediction layer
into the mask prediction head. This innovative approach empowers the network to
simultaneously predict masks and depth, enhancing its ability to capture
nuanced depth-related information during the instance segmentation process. We
further utilize the mask generated in the training process as supervision to
distinguish the foreground from the background. When selecting the best mask
for each box through the Hungarian algorithm, we use depth consistency as one
calculation cost item. The proposed method achieves significant improvements on
Cityscapes and COCO dataset.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01215" title="Abstract">arXiv:2403.01215</a> [<a href="/pdf/2403.01215" title="Download PDF">pdf</a>, <a href="/ps/2403.01215" title="Download PostScript">ps</a>, <a href="/format/2403.01215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithm Level Error Detection for Number-Theoretic Transform  Assessed on FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+K">Kasra Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Aghapour%2C+S">Saeed Aghapour</a>, 
<a href="/search/cs?searchtype=author&query=Kermani%2C+M+M">Mehran Mozaffari Kermani</a>, 
<a href="/search/cs?searchtype=author&query=Azarderakhsh%2C+R">Reza Azarderakhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, 4 Figures, and 3 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Polynomial multiplication stands out as a highly demanding arithmetic process
in the development of post-quantum cryptosystems. The importance of
number-theoretic transform (NTT) extends beyond post-quantum cryptosystems,
proving valuable in enhancing existing security protocols such as digital
signature schemes and hash functions. Due to the potential for errors to
significantly disrupt the operation of secure, cryptographically-protected
systems, compromising data integrity, and safeguarding against side-channel
attacks initiated through faults it is essential to incorporate mitigating
error detection schemes. This paper introduces algorithm level fault detection
schemes in NTT multiplication, representing a significant enhancement compared
to previous research. We evaluate this through the simulation of a fault model,
ensuring that the conducted assessments accurately mirror the obtained results.
Consequently, we attain a notably comprehensive coverage of errors. Finally, we
assess the performance of our efficient error detection scheme on FPGAs to
showcase its implementation and resource requirements. Through implementation
of our error detection approach on Xilinx/AMD Zynq Ultrascale+ and Artix-7, we
achieve a comparable throughput with just a 9% increase in area and 13%
increase in latency compared to the original hardware implementations.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01216" title="Abstract">arXiv:2403.01216</a> [<a href="/pdf/2403.01216" title="Download PDF">pdf</a>, <a href="/format/2403.01216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> API Is Enough: Conformal Prediction for Large Language Models Without  Logit-Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jiayuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lu Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study aims to address the pervasive challenge of quantifying uncertainty
in large language models (LLMs) without logit-access. Conformal Prediction
(CP), known for its model-agnostic and distribution-free features, is a desired
approach for various LLMs and data distributions. However, existing CP methods
for LLMs typically assume access to the logits, which are unavailable for some
API-only LLMs. In addition, logits are known to be miscalibrated, potentially
leading to degraded CP performance. To tackle these challenges, we introduce a
novel CP method that (1) is tailored for API-only LLMs without logit-access;
(2) minimizes the size of prediction sets; and (3) ensures a statistical
guarantee of the user-defined coverage. The core idea of this approach is to
formulate nonconformity measures using both coarse-grained (i.e., sample
frequency) and fine-grained uncertainty notions (e.g., semantic similarity).
Experimental results on both close-ended and open-ended Question Answering
tasks show our approach can mostly outperform the logit-based CP baselines.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01218" title="Abstract">arXiv:2403.01218</a> [<a href="/pdf/2403.01218" title="Download PDF">pdf</a>, <a href="/format/2403.01218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense  of Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayes%2C+J">Jamie Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Shumailov%2C+I">Ilia Shumailov</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+E">Eleni Triantafillou</a>, 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+A">Amr Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Papernot%2C+N">Nicolas Papernot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The high cost of model training makes it increasingly desirable to develop
techniques for unlearning. These techniques seek to remove the influence of a
training example without having to retrain the model from scratch. Intuitively,
once a model has unlearned, an adversary that interacts with the model should
no longer be able to tell whether the unlearned example was included in the
model's training set or not. In the privacy literature, this is known as
membership inference. In this work, we discuss adaptations of Membership
Inference Attacks (MIAs) to the setting of unlearning (leading to their
``U-MIA'' counterparts). We propose a categorization of existing U-MIAs into
``population U-MIAs'', where the same attacker is instantiated for all
examples, and ``per-example U-MIAs'', where a dedicated attacker is
instantiated for each example. We show that the latter category, wherein the
attacker tailors its membership prediction to each example under attack, is
significantly stronger. Indeed, our results show that the commonly used U-MIAs
in the unlearning literature overestimate the privacy protection afforded by
existing unlearning techniques on both vision and language models. Our
investigation reveals a large variance in the vulnerability of different
examples to per-example U-MIAs. In fact, several unlearning algorithms lead to
a reduced vulnerability for some, but not all, examples that we wish to
unlearn, at the expense of increasing it for other examples. Notably, we find
that the privacy protection for the remaining training examples may worsen as a
consequence of unlearning. We also discuss the fundamental difficulty of
equally protecting all examples using existing unlearning schemes, due to the
different rates at which examples are unlearned. We demonstrate that naive
attempts at tailoring unlearning stopping criteria to different examples fail
to alleviate these issues.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01221" title="Abstract">arXiv:2403.01221</a> [<a href="/pdf/2403.01221" title="Download PDF">pdf</a>, <a href="/ps/2403.01221" title="Download PostScript">ps</a>, <a href="/format/2403.01221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Artelt%2C+A">Andr&#xe9; Artelt</a>, 
<a href="/search/cs?searchtype=author&query=Gregoriades%2C+A">Andreas Gregoriades</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counterfactual explanations constitute among the most popular methods for
analyzing the predictions of black-box systems since they can recommend
cost-efficient and actionable changes to the input to turn an undesired
system's output into a desired output. While most of the existing
counterfactual methods explain a single instance, several real-world use cases,
such as customer satisfaction, require the identification of a single
counterfactual that can satisfy multiple instances (e.g. customers)
simultaneously. In this work, we propose a flexible two-stage algorithm for
finding groups of instances along with cost-efficient multi-instance
counterfactual explanations. This is motivated by the fact that in most
previous works the aspect of finding such groups is not addressed.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01222" title="Abstract">arXiv:2403.01222</a> [<a href="/pdf/2403.01222" title="Download PDF">pdf</a>, <a href="/format/2403.01222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plaza-del-Arco%2C+F+M">Flor Miriam Plaza-del-Arco</a>, 
<a href="/search/cs?searchtype=author&query=Curry%2C+A">Alba Curry</a>, 
<a href="/search/cs?searchtype=author&query=Curry%2C+A+C">Amanda Cercas Curry</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Emotions are a central aspect of communication. Consequently, emotion
analysis (EA) is a rapidly growing field in natural language processing (NLP).
However, there is no consensus on scope, direction, or methods. In this paper,
we conduct a thorough review of 154 relevant NLP publications from the last
decade. Based on this review, we address four different questions: (1) How are
EA tasks defined in NLP? (2) What are the most prominent emotion frameworks and
which emotions are modeled? (3) Is the subjectivity of emotions considered in
terms of demographics and cultural factors? and (4) What are the primary NLP
applications for EA? We take stock of trends in EA and tasks, emotion
frameworks used, existing datasets, methods, and applications. We then discuss
four lacunae: (1) the absence of demographic and cultural aspects does not
account for the variation in how emotions are perceived, but instead assumes
they are universally experienced in the same manner; (2) the poor fit of
emotion categories from the two main emotion theories to the task; (3) the lack
of standardized EA terminology hinders gap identification, comparison, and
future goals; and (4) the absence of interdisciplinary research isolates EA
from insights in other fields. Our work will enable more focused research into
EA and a more holistic approach to modeling emotions in NLP.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01225" title="Abstract">arXiv:2403.01225</a> [<a href="/pdf/2403.01225" title="Download PDF">pdf</a>, <a href="/format/2403.01225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cost-Effective Cooperative Exploration and Inspection Strategy for  Heterogeneous Aerial System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinhang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Muqing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shenghai Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thien Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thien-Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Baseline method of CARIC at CDC 2023, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a cost-effective strategy for heterogeneous UAV
swarm systems for cooperative aerial inspection. Unlike previous swarm
inspection works, the proposed method does not rely on precise prior knowledge
of the environment and can complete full 3D surface coverage of objects in any
shape. In this work, agents are partitioned into teams, with each drone assign
a different task, including mapping, exploration, and inspection. Task
allocation is facilitated by assigning optimal inspection volumes to each team,
following best-first rules. A voxel map-based representation of the environment
is used for pathfinding, and a rule-based path-planning method is the core of
this approach. We achieved the best performance in all challenging experiments
with the proposed approach, surpassing all benchmark methods for similar tasks
across multiple evaluation trials. The proposed method is open source at
https://github.com/ntu-aris/caric_baseline and used as the baseline of the
Cooperative Aerial Robots Inspection Challenge at the 62nd IEEE Conference on
Decision and Control 2023.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01226" title="Abstract">arXiv:2403.01226</a> [<a href="/pdf/2403.01226" title="Download PDF">pdf</a>, <a href="/format/2403.01226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffSal: Joint Audio and Video Learning for Diffusion Saliency  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Junwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+T">Tao You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Y">Yufei Zha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, CVPR24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Audio-visual saliency prediction can draw support from diverse modality
complements, but further performance enhancement is still challenged by
customized architectures as well as task-specific loss functions. In recent
studies, denoising diffusion models have shown more promising in unifying task
frameworks owing to their inherent ability of generalization. Following this
motivation, a novel Diffusion architecture for generalized audio-visual
Saliency prediction (DiffSal) is proposed in this work, which formulates the
prediction problem as a conditional generative task of the saliency map by
utilizing input audio and video as the conditions. Based on the spatio-temporal
audio-visual features, an extra network Saliency-UNet is designed to perform
multi-modal attention modulation for progressive refinement of the ground-truth
saliency map from the noisy map. Extensive experiments demonstrate that the
proposed DiffSal can achieve excellent performance across six challenging
audio-visual benchmarks, with an average relative improvement of 6.3\% over the
previous state-of-the-art results by six metrics.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01229" title="Abstract">arXiv:2403.01229</a> [<a href="/pdf/2403.01229" title="Download PDF">pdf</a>, <a href="/format/2403.01229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REWIND Dataset: Privacy-preserving Speaking Status Segmentation from  Multimodal Body Movement Signals in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quiros%2C+J+V">Jose Vargas Quiros</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+C">Chirag Raman</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Stephanie Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gedik%2C+E">Ekin Gedik</a>, 
<a href="/search/cs?searchtype=author&query=Cabrera-Quiros%2C+L">Laura Cabrera-Quiros</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+H">Hayley Hung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Recognizing speaking in humans is a central task towards understanding social
interactions. Ideally, speaking would be detected from individual voice
recordings, as done previously for meeting scenarios. However, individual voice
recordings are hard to obtain in the wild, especially in crowded mingling
scenarios due to cost, logistics, and privacy concerns. As an alternative,
machine learning models trained on video and wearable sensor data make it
possible to recognize speech by detecting its related gestures in an
unobtrusive, privacy-preserving way. These models themselves should ideally be
trained using labels obtained from the speech signal. However, existing
mingling datasets do not contain high quality audio recordings. Instead,
speaking status annotations have often been inferred by human annotators from
video, without validation of this approach against audio-based ground truth. In
this paper we revisit no-audio speaking status estimation by presenting the
first publicly available multimodal dataset with high-quality individual speech
recordings of 33 subjects in a professional networking event. We present three
baselines for no-audio speaking status segmentation: a) from video, b) from
body acceleration (chest-worn accelerometer), c) from body pose tracks. In all
cases we predict a 20Hz binary speaking status signal extracted from the audio,
a time resolution not available in previous datasets. In addition to providing
the signals and ground truth necessary to evaluate a wide range of speaking
status detection methods, the availability of audio in REWIND makes it suitable
for cross-modality studies not feasible with previous mingling datasets.
Finally, our flexible data consent setup creates new challenges for multimodal
systems under missing modalities.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01231" title="Abstract">arXiv:2403.01231</a> [<a href="/pdf/2403.01231" title="Download PDF">pdf</a>, <a href="/format/2403.01231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Segmentation Models with Mask-Preserved Attribute Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zijin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kongming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhanyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jun Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When deploying segmentation models in practice, it is critical to evaluate
their behaviors in varied and complex scenes. Different from the previous
evaluation paradigms only in consideration of global attribute variations (e.g.
adverse weather), we investigate both local and global attribute variations for
robustness evaluation. To achieve this, we construct a mask-preserved attribute
editing pipeline to edit visual attributes of real images with precise control
of structural information. Therefore, the original segmentation labels can be
reused for the edited images. Using our pipeline, we construct a benchmark
covering both object and image attributes (e.g. color, material, pattern,
style). We evaluate a broad variety of semantic segmentation models, spanning
from conventional close-set models to recent open-vocabulary large models on
their robustness to different types of variations. We find that both local and
global attribute variations affect segmentation performances, and the
sensitivity of models diverges across different variation types. We argue that
local attributes have the same importance as global attributes, and should be
considered in the robustness evaluation of segmentation models. Code:
https://github.com/PRIS-CV/Pascal-EA.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01232" title="Abstract">arXiv:2403.01232</a> [<a href="/pdf/2403.01232" title="Download PDF">pdf</a>, <a href="/format/2403.01232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynormer: Polynomial-Expressive Graph Transformer in Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chenhui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zichao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph transformers (GTs) have emerged as a promising architecture that is
theoretically more expressive than message-passing graph neural networks
(GNNs). However, typical GT models have at least quadratic complexity and thus
cannot scale to large graphs. While there are several linear GTs recently
proposed, they still lag behind GNN counterparts on several popular graph
datasets, which poses a critical concern on their practical expressivity. To
balance the trade-off between expressivity and scalability of GTs, we propose
Polynormer, a polynomial-expressive GT model with linear complexity. Polynormer
is built upon a novel base model that learns a high-degree polynomial on input
features. To enable the base model permutation equivariant, we integrate it
with graph topology and node features separately, resulting in local and global
equivariant attention models. Consequently, Polynormer adopts a linear
local-to-global attention scheme to learn high-degree equivariant polynomials
whose coefficients are controlled by attention scores. Polynormer has been
evaluated on $13$ homophilic and heterophilic datasets, including large graphs
with millions of nodes. Our extensive experiment results show that Polynormer
outperforms state-of-the-art GNN and GT baselines on most datasets, even
without the use of nonlinear activation functions.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01233" title="Abstract">arXiv:2403.01233</a> [<a href="/pdf/2403.01233" title="Download PDF">pdf</a>, <a href="/format/2403.01233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Results and Lessons Learned from Autonomous Driving Transportation  Services in Airfield, Crowded Indoor, and Urban Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baek%2C+D">Doosan Baek</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Seung-Woo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-Hyun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous vehicles have been actively investigated over the past few
decades. Several recent works show the potential of autonomous driving
transportation services in urban environments with impressive experimental
results. However, these works note that autonomous vehicles are still
occasionally inferior to expert drivers in complex scenarios. Furthermore, they
do not focus on the possibilities of autonomous driving transportation services
in other areas beyond urban environments. This paper presents the research
results and lessons learned from autonomous driving transportation services in
airfield, crowded indoor, and urban environments. We discuss how we address
several unique challenges in these diverse environments. We also offer an
overview of remaining challenges that have not received much attention but must
be addressed. This paper aims to share our unique experience to support
researchers who are interested in realizing the potential of autonomous
vehicles in various real-world environments.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01234" title="Abstract">arXiv:2403.01234</a> [<a href="/pdf/2403.01234" title="Download PDF">pdf</a>, <a href="/ps/2403.01234" title="Download PostScript">ps</a>, <a href="/format/2403.01234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Deep Kernel Learning of Molecular Functionalities: Realizing  Dynamic Structural Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Ayana Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=and%2C+M+Z">Maxim Ziatdinov and</a>, 
<a href="/search/cs?searchtype=author&query=Kalinin%2C+S+V">Sergei V. Kalinin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Exploring molecular spaces is crucial for advancing our understanding of
chemical properties and reactions, leading to groundbreaking innovations in
materials science, medicine, and energy. This paper explores an approach for
active learning in molecular discovery using Deep Kernel Learning (DKL), a
novel approach surpassing the limits of classical Variational Autoencoders
(VAEs). Employing the QM9 dataset, we contrast DKL with traditional VAEs, which
analyze molecular structures based on similarity, revealing limitations due to
sparse regularities in latent spaces. DKL, however, offers a more holistic
perspective by correlating structure with properties, creating latent spaces
that prioritize molecular functionality. This is achieved by recalculating
embedding vectors iteratively, aligning with the experimental availability of
target properties. The resulting latent spaces are not only better organized
but also exhibit unique characteristics such as concentrated maxima
representing molecular functionalities and a correlation between predictive
uncertainty and error. Additionally, the formation of exclusion regions around
certain compounds indicates unexplored areas with potential for groundbreaking
functionalities. This study underscores DKL's potential in molecular research,
offering new avenues for understanding and discovering molecular
functionalities beyond classical VAE limitations.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01236" title="Abstract">arXiv:2403.01236</a> [<a href="/pdf/2403.01236" title="Download PDF">pdf</a>, <a href="/format/2403.01236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance evaluation of acceleration of convolutional layers on  OpenEdgeCGRA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carpentieri%2C+N">Nicol&#xf2; Carpentieri</a>, 
<a href="/search/cs?searchtype=author&query=Sapriza%2C+J">Juan Sapriza</a>, 
<a href="/search/cs?searchtype=author&query=Schiavone%2C+D">Davide Schiavone</a>, 
<a href="/search/cs?searchtype=author&query=Pagliari%2C+D+J">Daniele Jahier Pagliari</a>, 
<a href="/search/cs?searchtype=author&query=Atienza%2C+D">David Atienza</a>, 
<a href="/search/cs?searchtype=author&query=Martina%2C+M">Maurizio Martina</a>, 
<a href="/search/cs?searchtype=author&query=Burrello%2C+A">Alessio Burrello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Recently, efficiently deploying deep learning solutions on the edge has
received increasing attention. New platforms are emerging to support the
increasing demand for flexibility and high performance. In this work, we
explore the efficient mapping of convolutional layers on an open-hardware,
low-power Coarse-Grain Reconfigurable Array (CGRA), namely OpenEdgeCGRA. We
explore both direct implementations of convolution and solutions that transform
it into a matrix multiplication through an Im2col transformation, and
experiment with various tensor parallelism axes. We show that for this hardware
target, direct convolution, coupled with weight parallelism reaches the best
latency and energy efficiency, outperforming a CPU implementation by 3.4x and
9.9x in terms of energy and latency, respectively.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01238" title="Abstract">arXiv:2403.01238</a> [<a href="/pdf/2403.01238" title="Download PDF">pdf</a>, <a href="/format/2403.01238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Road to Portability: Compressing End-to-End Motion Planner for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kaituo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+D">Dongchun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">End-to-end motion planning models equipped with deep neural networks have
shown great potential for enabling full autonomous driving. However, the
oversized neural networks render them impractical for deployment on
resource-constrained systems, which unavoidably requires more computational
time and resources during reference.To handle this, knowledge distillation
offers a promising approach that compresses models by enabling a smaller
student model to learn from a larger teacher model. Nevertheless, how to apply
knowledge distillation to compress motion planners has not been explored so
far. In this paper, we propose PlanKD, the first knowledge distillation
framework tailored for compressing end-to-end motion planners. First,
considering that driving scenes are inherently complex, often containing
planning-irrelevant or even noisy information, transferring such information is
not beneficial for the student planner. Thus, we design an information
bottleneck based strategy to only distill planning-relevant information, rather
than transfer all information indiscriminately. Second, different waypoints in
an output planned trajectory may hold varying degrees of importance for motion
planning, where a slight deviation in certain crucial waypoints might lead to a
collision. Therefore, we devise a safety-aware waypoint-attentive distillation
module that assigns adaptive weights to different waypoints based on the
importance, to encourage the student to accurately mimic more crucial
waypoints, thereby improving overall safety. Experiments demonstrate that our
PlanKD can boost the performance of smaller planners by a large margin, and
significantly reduce their reference time.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01241" title="Abstract">arXiv:2403.01241</a> [<a href="/pdf/2403.01241" title="Download PDF">pdf</a>, <a href="/format/2403.01241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IntactKV: Improving Large Language Model Quantization by Keeping Pivot  Tokens Intact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruikang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haoli Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haokun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuening Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Han Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengzhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) excel in natural language processing but demand
intensive computation. To mitigate this, various quantization methods have been
explored, yet they compromise LLM performance. This paper unveils a previously
overlooked type of outlier in LLMs. Such outliers are found to allocate most of
the attention scores on initial tokens of input, termed as pivot tokens, which
is crucial to the performance of quantized LLMs. Given that, we propose
IntactKV to generate the KV cache of pivot tokens losslessly from the
full-precision model. The approach is simple and easy to combine with existing
quantization solutions. Besides, IntactKV can be calibrated as additional LLM
parameters to boost the quantized LLMs further. Mathematical analysis also
proves that IntactKV effectively reduces the upper bound of quantization error.
Empirical results show that IntactKV brings consistent improvement and achieves
lossless weight-only INT4 quantization on various downstream tasks, leading to
the new state-of-the-art for LLM quantization.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01242" title="Abstract">arXiv:2403.01242</a> [<a href="/pdf/2403.01242" title="Download PDF">pdf</a>, <a href="/format/2403.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Automation: Intent-Based User Instruction Classification with  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basyal%2C+L">Lochan Basyal</a>, 
<a href="/search/cs?searchtype=author&query=Gaudel%2C+B">Bijay Gaudel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Electric automation systems offer convenience and efficiency in controlling
electrical circuits and devices. Traditionally, these systems rely on
predefined commands for control, limiting flexibility and adaptability. In this
paper, we propose a novel approach to augment automation by introducing
intent-based user instruction classification using machine learning techniques.
Our system represents user instructions as intents, allowing for dynamic
control of electrical circuits without relying on predefined commands. Through
a machine learning model trained on a labeled dataset of user instructions, our
system classifies intents from user input, enabling a more intuitive and
adaptable control scheme. We present the design and implementation of our
intent-based electric automation system, detailing the development of the
machine learning model for intent classification. Experimental results
demonstrate the effectiveness of our approach in enhancing user experience and
expanding the capabilities of electric automation systems. Our work contributes
to the advancement of smart technologies by providing a more seamless
interaction between users and their environments.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01244" title="Abstract">arXiv:2403.01244</a> [<a href="/pdf/2403.01244" title="Download PDF">pdf</a>, <a href="/format/2403.01244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Catastrophic Forgetting in Large Language Models with  Self-Synthesized Rehearsal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Ante Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xinting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Junfeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) suffer from catastrophic forgetting during
continual learning. Conventional rehearsal-based methods rely on previous
training data to retain the model's ability, which may not be feasible in
real-world applications. When conducting continual learning based on a
publicly-released LLM checkpoint, the availability of the original training
data may be non-existent. To address this challenge, we propose a framework
called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic
instances for rehearsal. Concretely, we first employ the base LLM for
in-context learning to generate synthetic instances. Subsequently, we utilize
the latest LLM to refine the instance outputs based on the synthetic inputs,
preserving its acquired ability. Finally, we select diverse high-quality
synthetic instances for rehearsal in future stages. Experimental results
demonstrate that SSR achieves superior or comparable performance compared to
conventional rehearsal-based approaches while being more data-efficient.
Besides, SSR effectively preserves the generalization capabilities of LLMs in
general domains.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01245" title="Abstract">arXiv:2403.01245</a> [<a href="/pdf/2403.01245" title="Download PDF">pdf</a>, <a href="/format/2403.01245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AcME-AD: Accelerated Model Explanations for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaccaria%2C+V">Valentina Zaccaria</a>, 
<a href="/search/cs?searchtype=author&query=Dandolo%2C+D">David Dandolo</a>, 
<a href="/search/cs?searchtype=author&query=Masiero%2C+C">Chiara Masiero</a>, 
<a href="/search/cs?searchtype=author&query=Susto%2C+G+A">Gian Antonio Susto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Pursuing fast and robust interpretability in Anomaly Detection is crucial,
especially due to its significance in practical applications. Traditional
Anomaly Detection methods excel in outlier identification but are often
black-boxes, providing scant insights into their decision-making process. This
lack of transparency compromises their reliability and hampers their adoption
in scenarios where comprehending the reasons behind anomaly detection is vital.
At the same time, getting explanations quickly is paramount in practical
scenarios. To bridge this gap, we present AcME-AD, a novel approach rooted in
Explainable Artificial Intelligence principles, designed to clarify Anomaly
Detection models for tabular data. AcME-AD transcends the constraints of
model-specific or resource-heavy explainability techniques by delivering a
model-agnostic, efficient solution for interoperability. It offers local
feature importance scores and a what-if analysis tool, shedding light on the
factors contributing to each anomaly, thus aiding root cause analysis and
decision-making. This paper elucidates AcME-AD's foundation, its benefits over
existing methods, and validates its effectiveness with tests on both synthetic
and real datasets. AcME-AD's implementation and experiment replication code is
accessible in a public repository.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01246" title="Abstract">arXiv:2403.01246</a> [<a href="/pdf/2403.01246" title="Download PDF">pdf</a>, <a href="/format/2403.01246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Graph Attention based Disentanglement Multiple Instance Learning  for Brain Age Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+F">Fanzhe Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning techniques have demonstrated great potential for accurately
estimating brain age by analyzing Magnetic Resonance Imaging (MRI) data from
healthy individuals. However, current methods for brain age estimation often
directly utilize whole input images, overlooking two important considerations:
1) the heterogeneous nature of brain aging, where different brain regions may
degenerate at different rates, and 2) the existence of age-independent
redundancies in brain structure. To overcome these limitations, we propose a
Dual Graph Attention based Disentanglement Multi-instance Learning (DGA-DMIL)
framework for improving brain age estimation. Specifically, the 3D MRI data,
treated as a bag of instances, is fed into a 2D convolutional neural network
backbone, to capture the unique aging patterns in MRI. A dual graph attention
aggregator is then proposed to learn the backbone features by exploiting the
intra- and inter-instance relationships. Furthermore, a disentanglement branch
is introduced to separate age-related features from age-independent structural
representations to ameliorate the interference of redundant information on age
prediction. To verify the effectiveness of the proposed framework, we evaluate
it on two datasets, UK Biobank and ADNI, containing a total of 35,388 healthy
individuals. Our proposed model demonstrates exceptional accuracy in estimating
brain age, achieving a remarkable mean absolute error of 2.12 years in the UK
Biobank. The results establish our approach as state-of-the-art compared to
other competing brain age estimation models. In addition, the instance
contribution scores identify the varied importance of brain areas for aging
prediction, which provides deeper insights into the understanding of brain
aging.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01248" title="Abstract">arXiv:2403.01248</a> [<a href="/pdf/2403.01248" title="Download PDF">pdf</a>, <a href="/format/2403.01248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziniu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Iscen%2C+A">Ahmet Iscen</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aashi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Kipf%2C+T">Thomas Kipf</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yisong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+D+A">David A. Ross</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+A">Alireza Fathi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces SceneCraft, a Large Language Model (LLM) Agent
converting text descriptions into Blender-executable Python scripts which
render complex scenes with up to a hundred 3D assets. This process requires
complex spatial planning and arrangement. We tackle these challenges through a
combination of advanced abstraction, strategic planning, and library learning.
SceneCraft first models a scene graph as a blueprint, detailing the spatial
relationships among assets in the scene. SceneCraft then writes Python scripts
based on this graph, translating relationships into numerical constraints for
asset layout. Next, SceneCraft leverages the perceptual strengths of
vision-language foundation models like GPT-V to analyze rendered images and
iteratively refine the scene. On top of this process, SceneCraft features a
library learning mechanism that compiles common script functions into a
reusable library, facilitating continuous self-improvement without expensive
LLM parameter tuning. Our evaluation demonstrates that SceneCraft surpasses
existing LLM-based agents in rendering complex scenes, as shown by its
adherence to constraints and favorable human assessments. We also showcase the
broader application potential of SceneCraft by reconstructing detailed 3D
scenes from the Sintel movie and guiding a video generative model with
generated scenes as intermediary control signal.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01250" title="Abstract">arXiv:2403.01250</a> [<a href="/pdf/2403.01250" title="Download PDF">pdf</a>, <a href="/ps/2403.01250" title="Download PostScript">ps</a>, <a href="/format/2403.01250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Mobile Energy Storage Resources Based Distribution Network  Restoration in Interdependent Power-Transportation-Information Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhong%2C+J">Jian Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Q">Qiming Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+D">Dafu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+W">Wentao Shen</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+C">Chenlin Ji</a>, 
<a href="/search/eess?searchtype=author&query=Bie%2C+Z">Zhaohong Bie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The interactions between power, transportation, and information networks
(PTIN), are becoming more profound with the advent of smart city technologies.
Existing mobile energy storage resource (MESR)-based power distribution network
(PDN) restoration schemes often neglect the interdependencies among PTIN, thus,
efficient PDN restoration cannot be achieved. This paper outlines the
interacting factors of power supply demand, traffic operation efficiency,
communication coverage, electric vehicle (EV) deployment capability, and PDN
controllability among PTIN and further develops a PTIN-interacting model to
reflect the chained recovery effect of the MESR-based restoration process. On
this basis, a two-stage PDN restoration scheme is proposed that utilizes three
emergency resources, including EVs, mobile energy storage systems (MESSs), and
unmanned aerial vehicles (UAVs), to restore the power supply and communication
of PDNs. This scheme first improves the distribution automation function, EV
deployment capability, and traffic operation efficiency by prioritizing the
recovery of communication network (CN) and urban traffic network (UTN) loads.
Then, EVs and MESSs are further scheduled to achieve a better PDN restoration
effect with the support of the restored CNs and UTNs. Case studies on a PDN,
CN, and UTN integrated test system are conducted to verify the effectiveness of
the proposed scheme. The results show that the prioritized load recovery
operation for CN and UTN facilities in this scheme greatly improves the PDN
restoration effect.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01251" title="Abstract">arXiv:2403.01251</a> [<a href="/pdf/2403.01251" title="Download PDF">pdf</a>, <a href="/format/2403.01251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Greedy Coordinate Gradient via Probe Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenyue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianle Cai</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Shieh%2C+M">Michael Shieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Safety of Large Language Models (LLMs) has become a central issue given their
rapid progress and wide applications. Greedy Coordinate Gradient (GCG) is shown
to be effective in constructing prompts containing adversarial suffixes to
break the presumingly safe LLMs, but the optimization of GCG is time-consuming
and limits its practicality. To reduce the time cost of GCG and enable more
comprehensive studies of LLM safety, in this work, we study a new algorithm
called $\texttt{Probe sampling}$ to accelerate the GCG algorithm. At the core
of the algorithm is a mechanism that dynamically determines how similar a
smaller draft model's predictions are to the target model's predictions for
prompt candidates. When the target model is similar to the draft model, we rely
heavily on the draft model to filter out a large number of potential prompt
candidates to reduce the computation time. Probe sampling achieves up to $5.6$
times speedup using Llama2-7b and leads to equal or improved attack success
rate (ASR) on the AdvBench.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01253" title="Abstract">arXiv:2403.01253</a> [<a href="/pdf/2403.01253" title="Download PDF">pdf</a>, <a href="/ps/2403.01253" title="Download PostScript">ps</a>, <a href="/format/2403.01253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic SDN-based Microgrid Formation for Managing Communication  Failures in Distribution System Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhong%2C+J">Jian Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Bie%2C+Z">Zhaohong Bie</a>, 
<a href="/search/eess?searchtype=author&query=Shahidehpour%2C+M">Mohammad Shahidehpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Grid modernization has increased the reliance of power networks on cyber
networks within distribution systems (DSs), heightening their vulnerability to
disasters. Communication network failures significantly impede DS load recovery
by diminishing observation and control. Prior research has largely ignored the
need for integrated recovery of DS power and cyber networks' centralized
control. Indeed, communication network restoration is critical for speedy load
recovery through DS automation based microgrid formation. This paper exploits
the data routing capabilities of software-defined networking (SDN) to enhance
centralized control recovery in DS communication networks, incorporating it
into a comprehensive DS restoration model. This model, tailored to the control
requirements of load restoration, strategically allocates limited communication
resources to re-establish connections between the operation center and terminal
devices. Subsequently, DS automation is employed to orchestrate DS microgrid
formation for power resupply. Additionally, we introduce a cyclic algorithm
designed to optimize the load recovery via a multi-step, cooperative process.
The efficacy of the proposed method is demonstrated on IEEE 33-node and IEEE
123-node test feeders.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01254" title="Abstract">arXiv:2403.01254</a> [<a href="/pdf/2403.01254" title="Download PDF">pdf</a>, <a href="/format/2403.01254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RKHS-BA: A Semantic Correspondence-Free Multi-View Registration  Framework with Global Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingwei Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Eustice%2C+R">Ryan Eustice</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, technical report under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work reports a novel Bundle Adjustment (BA) formulation using a
Reproducing Kernel Hilbert Space (RKHS) representation called RKHS-BA. The
proposed formulation is correspondence-free, enables the BA to use RGB-D/LiDAR
and semantic labels in the optimization directly, and provides a generalization
for the photometric loss function commonly used in direct methods. RKHS-BA can
incorporate appearance and semantic labels within a continuous spatial-semantic
functional representation that does not require optimization via image
pyramids. We demonstrate its applications in sliding-window odometry and global
LiDAR mapping, which show highly robust performance in extremely challenging
scenes and the best trade-off of generalization and accuracy.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01255" title="Abstract">arXiv:2403.01255</a> [<a href="/pdf/2403.01255" title="Download PDF">pdf</a>, <a href="/format/2403.01255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Speech Recognition using Advanced Deep Learning Approaches: A  survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kheddar%2C+H">Hamza Kheddar</a>, 
<a href="/search/cs?searchtype=author&query=Hemis%2C+M">Mustapha Hemis</a>, 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">Recent advancements in deep learning (DL) have posed a significant challenge
for automatic speech recognition (ASR). ASR relies on extensive training
datasets, including confidential ones, and demands substantial computational
and storage resources. Enabling adaptive systems improves ASR performance in
dynamic environments. DL techniques assume training and testing data originate
from the same domain, which is not always true. Advanced DL techniques like
deep transfer learning (DTL), federated learning (FL), and reinforcement
learning (RL) address these issues. DTL allows high-performance models using
small yet related datasets, FL enables training on confidential data without
dataset possession, and RL optimizes decision-making in dynamic environments,
reducing computation costs. This survey offers a comprehensive review of DTL,
FL, and RL-based ASR frameworks, aiming to provide insights into the latest
developments and aid researchers and professionals in understanding the current
challenges. Additionally, transformers, which are advanced DL techniques
heavily used in proposed ASR frameworks, are considered in this survey for
their ability to capture extensive dependencies in the input ASR sequence. The
paper starts by presenting the background of DTL, FL, RL, and Transformers and
then adopts a well-designed taxonomy to outline the state-of-the-art
approaches. Subsequently, a critical analysis is conducted to identify the
strengths and weaknesses of each framework. Additionally, a comparative study
is presented to highlight the existing challenges, paving the way for future
research opportunities.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01256" title="Abstract">arXiv:2403.01256</a> [<a href="/pdf/2403.01256" title="Download PDF">pdf</a>, <a href="/ps/2403.01256" title="Download PostScript">ps</a>, <a href="/format/2403.01256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Microgrid Formation Considering Communication Interruptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhong%2C+J">Jian Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+Y">Young-Jin Kim</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yuxiong Huang</a>, 
<a href="/search/eess?searchtype=author&query=Teng%2C+M">Mengjie Teng</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+Y">Yiheng Bian</a>, 
<a href="/search/eess?searchtype=author&query=Bie%2C+Z">Zhaohong Bie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Distribution system (DS) communication failures following extreme events
often degrade monitoring and control functions, thus preventing the acquisition
of complete global DS component state information, on which existing
post-disaster DS restoration methods are based. This letter proposes methods of
inferring the states of DS components in the case of incomplete component state
information. By using the known DS information, the operating states of
unobservable DS branches and buses can be inferred, providing complete
information for DS performance restoration before full communication recovery
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01257" title="Abstract">arXiv:2403.01257</a> [<a href="/pdf/2403.01257" title="Download PDF">pdf</a>, <a href="/ps/2403.01257" title="Download PostScript">ps</a>, <a href="/format/2403.01257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Scalable Network Slicing with Plug-and-Play Support for Power  Distribution System Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhong%2C+J">Jian Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yuqi Qian</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+Y">Yiheng Bian</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yuxiong Huang</a>, 
<a href="/search/eess?searchtype=author&query=Bie%2C+Z">Zhaohong Bie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the rapid development of power distribution systems (PDSs), the number
of terminal devices and the types of delivered services involved are constantly
growing. These trends make the operations of PDSs highly dependent on the
support of advanced communication networks, which face two related challenges.
The first is to provide sufficient flexibility, resilience, and security to
meet varying demands and ensure the proper operation of gradually diversifying
network services. The second is to realize the automatic identification of
terminal devices, thus reducing the network maintenance burden. To solve these
problems, this paper presents a novel multiservice network integration and
device authentication slice-based network slicing scheme. In this scheme, the
integration of PDS communication networks enables network resource sharing, and
recovery from communication interruption is achieved through network slicing in
the integrated network. Authentication servers periodically poll terminal
devices, adjusting network slice ranges based on authentication results,
thereby facilitating dynamic network slicing. Additionally, secure
plug-and-play support for PDS terminal devices and network protection are
achieved through device identification and dynamic adjustment of network
slices. On this basis, a network optimization and upgrading methodology for
load balancing and robustness enhancement is further proposed. This approach is
designed to improve the performance of PDS communication networks, adapting to
ongoing PDS development and the evolution of PDS services. The simulation
results show that the proposed schemes endow a PDS communication network with
favorable resource utilization, fault recovery, terminal device plug-and-play
support, load balancing, and improved network robustness.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01261" title="Abstract">arXiv:2403.01261</a> [<a href="/pdf/2403.01261" title="Download PDF">pdf</a>, <a href="/format/2403.01261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSL-LPA: Fast Label Propagation Algorithm (LPA) for Community Detection  with no Internally-Disconnected Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 1 table. arXiv admin note: text overlap with <a href="/abs/2402.11454">arXiv:2402.11454</a>, <a href="/abs/2312.08140">arXiv:2312.08140</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Community detection is the problem of identifying tightly connected clusters
of nodes within a network. Efficient parallel algorithms for this play a
crucial role in various applications, especially as datasets expand to
significant sizes. The Label Propagation Algorithm (LPA) is commonly employed
for this purpose due to its ease of parallelization, rapid execution, and
scalability. However, it may yield internally disconnected communities. This
technical report introduces GSL-LPA, derived from our parallelization of LPA,
namely GVE-LPA. Our experiments on a system with two 16-core Intel Xeon Gold
6226R processors show that GSL-LPA not only mitigates this issue but also
surpasses FLPA, igraph LPA, and NetworKit LPA by 55x, 10,300x, and 5.8x,
respectively, achieving a processing rate of 844 M edges/s on a 3.8 B edge
graph. Additionally, GSL-LPA scales at a rate of 1.6x for every doubling of
threads.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01263" title="Abstract">arXiv:2403.01263</a> [<a href="/pdf/2403.01263" title="Download PDF">pdf</a>, <a href="/ps/2403.01263" title="Download PostScript">ps</a>, <a href="/format/2403.01263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-image camera calibration with model-free distortion correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Genovese%2C+K">Katia Genovese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camera calibration is a process of paramount importance in computer vision
applications that require accurate quantitative measurements. The popular
method developed by Zhang relies on the use of a large number of images of a
planar grid of fiducial points captured in multiple poses. Although flexible
and easy to implement, Zhang's method has some limitations. The simultaneous
optimization of the entire parameter set, including the coefficients of a
predefined distortion model, may result in poor distortion correction at the
image boundaries or in miscalculation of the intrinsic parameters, even with a
reasonably small reprojection error. Indeed, applications involving image
stitching (e.g. multi-camera systems) require accurate mapping of distortion up
to the outermost regions of the image. Moreover, intrinsic parameters affect
the accuracy of camera pose estimation, which is fundamental for applications
such as vision servoing in robot navigation and automated assembly. This paper
proposes a method for estimating the complete set of calibration parameters
from a single image of a planar speckle pattern covering the entire sensor. The
correspondence between image points and physical points on the calibration
target is obtained using Digital Image Correlation. The effective focal length
and the extrinsic parameters are calculated separately after a prior evaluation
of the principal point. At the end of the procedure, a dense and uniform
model-free distortion map is obtained over the entire image. Synthetic data
with different noise levels were used to test the feasibility of the proposed
method and to compare its metrological performance with Zhang's method.
Real-world tests demonstrate the potential of the developed method to reveal
aspects of the image formation that are hidden by averaging over multiple
images.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01264" title="Abstract">arXiv:2403.01264</a> [<a href="/pdf/2403.01264" title="Download PDF">pdf</a>, <a href="/ps/2403.01264" title="Download PostScript">ps</a>, <a href="/format/2403.01264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Alternative Finite Difference WENO Schemes for Hyperbolic  Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balsara%2C+D+S">Dinshaw S. Balsara</a>, 
<a href="/search/math?searchtype=author&query=Bhoriya%2C+D">Deepak Bhoriya</a>, 
<a href="/search/math?searchtype=author&query=Shu%2C+C">Chi-Wang Shu</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+H">Harish Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Communications on Applied Mathematics and Computation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Higher order finite difference Weighted Essentially Non-Oscillatory (WENO)
schemes for conservation laws are extremely popular because, for
multidimensional problems, they offer high order accuracy at a fraction of the
cost of finite volume WENO or DG schemes. Such schemes come in two
formulations. The very popular classical finite difference WENO (FD-WENO)
method (Shu and Osher, J. Comput. Phys., 83 (1989) 32-78) relies two
reconstruction steps applied to two split fluxes. However, the method cannot
accommodate different types of Riemann solvers and cannot preserve free stream
boundary conditions on curvilinear meshes. This limits its utility. The
alternative finite difference WENO (AFD-WENO) method can overcome these
deficiencies, however, much less work has been done on this method. The reasons
are three-fold. First, it is difficult for the casual reader to understand the
intricate logic that requires higher order derivatives of the fluxes to be
evaluated at zone boundaries. The analytical methods for deriving the update
equation for AFD-WENO schemes are somewhat recondite. To overcome that
difficulty, we provide an easily accessible script that is based on a computer
algebra system in Appendix A of this paper. Second, the method relies on
interpolation rather than reconstruction, and WENO interpolation formulae have
not been documented in the literature as thoroughly as WENO reconstruction
formulae. In this paper, we explicitly provide all necessary WENO interpolation
formulae that are needed for implementing AFD-WENO up to ninth order. The third
reason is that AFD-WENO requires higher order derivatives of the fluxes to be
available at zone boundaries. Since those derivatives are usually obtained by
finite differencing the zone-centered fluxes, they become susceptible to a
Gibbs phenomenon when the solution ...
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01265" title="Abstract">arXiv:2403.01265</a> [<a href="/pdf/2403.01265" title="Download PDF">pdf</a>, <a href="/format/2403.01265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth Computation without Input Delay: Robust Tube-Based Model  Predictive Control for Robot Manipulator Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sima%2C+Q">Qie Sima</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianyin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Model Predictive Control (MPC) has exhibited remarkable capabilities in
optimizing objectives and meeting constraints. However, the substantial
computational burden associated with solving the Optimal Control Problem (OCP)
at each triggering instant introduces significant delays between state sampling
and control application. These delays limit the practicality of MPC in
resource-constrained systems when engaging in complex tasks. The intuition to
address this issue in this paper is that by predicting the successor state, the
controller can solve the OCP one time step ahead of time thus avoiding the
delay of the next action. To this end, we compute deviations between real and
nominal system states, predicting forthcoming real states as initial conditions
for the imminent OCP solution. Anticipatory computation stores optimal control
based on current nominal states, thus mitigating the delay effects.
Additionally, we establish an upper bound for linearization error, effectively
linearizing the nonlinear system, reducing OCP complexity, and enhancing
response speed. We provide empirical validation through two numerical
simulations and corresponding real-world robot tasks, demonstrating significant
performance improvements and augmented response speed (up to $90\%$) resulting
from the seamless integration of our proposed approach compared to conventional
time-triggered MPC strategies.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01266" title="Abstract">arXiv:2403.01266</a> [<a href="/pdf/2403.01266" title="Download PDF">pdf</a>, <a href="/ps/2403.01266" title="Download PostScript">ps</a>, <a href="/format/2403.01266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Alternative Finite Difference WENO Schemes for Hyperbolic  Systems with Non-Conservative Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balsara%2C+D+S">Dinshaw S. Balsara</a>, 
<a href="/search/math?searchtype=author&query=Bhoriya%2C+D">Deepak Bhoriya</a>, 
<a href="/search/math?searchtype=author&query=Shu%2C+C">Chi-Wang Shu</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+H">Harish Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Communications on Applied Mathematics and Computation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Higher order finite difference Weighted Essentially Non-Oscillatory (WENO)
schemes for conservation laws represent a technology that has been reasonably
consolidated. They are extremely popular because, when applied to
multidimensional problems, they offer high order accuracy at a fraction of the
cost of finite volume WENO or DG schemes. They come in two flavors. There is
the classical finite difference WENO (FD-WENO) method (Shu and Osher, J.
Comput. Phys., 83 (1989) 32-78). However, in recent years there is also an
alternative finite difference WENO (AFD-WENO) method which has recently been
formalized into a very useful general-purpose algorithm for conservation laws
(Balsara et al., Efficient Alternative Finite Difference WENO Schemes for
Hyperbolic Conservation Laws, submitted to CAMC (2023)). However, the FD-WENO
algorithm has only very recently been formulated for hyperbolic systems with
non-conservative products (Balsara et al., Efficient Finite Difference WENO
Scheme for Hyperbolic Systems with Non-Conservative Products, to appear CAMC
(2023)). In this paper we show that there are substantial advantages in
obtaining an AFD-WENO algorithm for hyperbolic systems with non-conservative
products. Such an algorithm is documented in this paper. We present an AFD-WENO
formulation in fluctuation form that is carefully engineered to retrieve the
flux form when that is warranted and nevertheless extends to non-conservative
products. The method is flexible because it allows any Riemann solver to be
used. The formulation we arrive at is such that when non-conservative products
are absent it reverts exactly to the formulation in the second citation above
which is in exact flux conservation form. The ability to transition to a
precise conservation form when non-conservative products are absent ensures,
via the Lax-Wendroff theorem, that shock locations will be exactly ...
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01267" title="Abstract">arXiv:2403.01267</a> [<a href="/pdf/2403.01267" title="Download PDF">pdf</a>, <a href="/format/2403.01267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting Language Models: Machine Unlearning via Selective Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pochinkov%2C+N">Nicholas Pochinkov</a>, 
<a href="/search/cs?searchtype=author&query=Schoots%2C+N">Nandi Schoots</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Understanding and shaping the behaviour of Large Language Models (LLMs) is
increasingly important as applications become more powerful and more frequently
adopted. This paper introduces a machine unlearning method specifically
designed for LLMs. We introduce a selective pruning method for LLMs that
removes neurons based on their relative importance on a targeted capability
compared to overall network performance. This approach is a compute- and
data-efficient method for identifying and removing neurons that enable specific
behaviours. Our findings reveal that both feed-forward and attention neurons in
LLMs are specialized; that is, for specific tasks, certain neurons are more
crucial than others.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01268" title="Abstract">arXiv:2403.01268</a> [<a href="/pdf/2403.01268" title="Download PDF">pdf</a>, <a href="/format/2403.01268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Against Data Reconstruction Attacks in Federated Learning: An  Information Theory Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuotao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaobing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by USENIX Security '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) trains a black-box and high-dimensional model among
different clients by exchanging parameters instead of direct data sharing,
which mitigates the privacy leak incurred by machine learning. However, FL
still suffers from membership inference attacks (MIA) or data reconstruction
attacks (DRA). In particular, an attacker can extract the information from
local datasets by constructing DRA, which cannot be effectively throttled by
existing techniques, e.g., Differential Privacy (DP).
<br />In this paper, we aim to ensure a strong privacy guarantee for FL under DRA.
We prove that reconstruction errors under DRA are constrained by the
information acquired by an attacker, which means that constraining the
transmitted information can effectively throttle DRA. To quantify the
information leakage incurred by FL, we establish a channel model, which depends
on the upper bound of joint mutual information between the local dataset and
multiple transmitted parameters. Moreover, the channel model indicates that the
transmitted information can be constrained through data space operation, which
can improve training efficiency and the model accuracy under constrained
information. According to the channel model, we propose algorithms to constrain
the information transmitted in a single round of local training. With a limited
number of training rounds, the algorithms ensure that the total amount of
transmitted information is limited. Furthermore, our channel model can be
applied to various privacy-enhancing techniques (such as DP) to enhance privacy
guarantees against DRA. Extensive experiments with real-world datasets validate
the effectiveness of our methods.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01270" title="Abstract">arXiv:2403.01270</a> [<a href="/pdf/2403.01270" title="Download PDF">pdf</a>, <a href="/ps/2403.01270" title="Download PostScript">ps</a>, <a href="/format/2403.01270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive cross-language framework for harmful content detection  with the aid of sentiment analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mohammad Dehghani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In today's digital world, social media plays a significant role in
facilitating communication and content sharing. However, the exponential rise
in user-generated content has led to challenges in maintaining a respectful
online environment. In some cases, users have taken advantage of anonymity in
order to use harmful language, which can negatively affect the user experience
and pose serious social problems. Recognizing the limitations of manual
moderation, automatic detection systems have been developed to tackle this
problem. Nevertheless, several obstacles persist, including the absence of a
universal definition for harmful language, inadequate datasets across
languages, the need for detailed annotation guideline, and most importantly, a
comprehensive framework. This study aims to address these challenges by
introducing, for the first time, a detailed framework adaptable to any
language. This framework encompasses various aspects of harmful language
detection. A key component of the framework is the development of a general and
detailed annotation guideline. Additionally, the integration of sentiment
analysis represents a novel approach to enhancing harmful language detection.
Also, a definition of harmful language based on the review of different related
concepts is presented. To demonstrate the effectiveness of the proposed
framework, its implementation in a challenging low-resource language is
conducted. We collected a Persian dataset and applied the annotation guideline
for harmful detection and sentiment analysis. Next, we present baseline
experiments utilizing machine and deep learning methods to set benchmarks.
Results prove the framework's high performance, achieving an accuracy of 99.4%
in offensive language detection and 66.2% in sentiment analysis.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01271" title="Abstract">arXiv:2403.01271</a> [<a href="/pdf/2403.01271" title="Download PDF">pdf</a>, <a href="/format/2403.01271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Employing LLMs for Incident Response Planning and Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hays%2C+S">Sam Hays</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+D+J">Dr. Jules White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Incident Response Planning (IRP) is essential for effective cybersecurity
management, requiring detailed documentation (or playbooks) to guide security
personnel during incidents. Yet, creating comprehensive IRPs is often hindered
by challenges such as complex systems, high turnover rates, and legacy
technologies lacking documentation. This paper argues that, despite these
obstacles, the development, review, and refinement of IRPs can be significantly
enhanced through the utilization of Large Language Models (LLMs) like ChatGPT.
By leveraging LLMs for tasks such as drafting initial plans, suggesting best
practices, and identifying documentation gaps, organizations can overcome
resource constraints and improve their readiness for cybersecurity incidents.
We discuss the potential of LLMs to streamline IRP processes, while also
considering the limitations and the need for human oversight in ensuring the
accuracy and relevance of generated content. Our findings contribute to the
cybersecurity field by demonstrating a novel approach to enhancing IRP with AI
technologies, offering practical insights for organizations seeking to bolster
their incident response capabilities.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01272" title="Abstract">arXiv:2403.01272</a> [<a href="/pdf/2403.01272" title="Download PDF">pdf</a>, <a href="/format/2403.01272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can a Confident Prior Replace a Cold Posterior?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marek%2C+M">Martin Marek</a>, 
<a href="/search/cs?searchtype=author&query=Paige%2C+B">Brooks Paige</a>, 
<a href="/search/cs?searchtype=author&query=Izmailov%2C+P">Pavel Izmailov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Benchmark datasets used for image classification tend to have very low levels
of label noise. When Bayesian neural networks are trained on these datasets,
they often underfit, misrepresenting the aleatoric uncertainty of the data. A
common solution is to cool the posterior, which improves fit to the training
data but is challenging to interpret from a Bayesian perspective. We explore
whether posterior tempering can be replaced by a confidence-inducing prior
distribution. First, we introduce a "DirClip" prior that is practical to sample
and nearly matches the performance of a cold posterior. Second, we introduce a
"confidence prior" that directly approximates a cold likelihood in the limit of
decreasing temperature but cannot be easily sampled. Lastly, we provide several
general insights into confidence-inducing priors, such as when they might
diverge and how fine-tuning can mitigate numerical instability.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01273" title="Abstract">arXiv:2403.01273</a> [<a href="/pdf/2403.01273" title="Download PDF">pdf</a>, <a href="/format/2403.01273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoMAD-Attention: Efficient LLM Inference on CPUs Through  Multiply-add-free Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J+W">Jonah Wonkyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Bowen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhaozhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Anshumali Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language model inference on Central Processing Units (CPU) is
challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix
operations in the attention computations. In this paper, we argue that there is
a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers,
which allow for ultra-low-latency lookups in batch. We leverage this unique
capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm
that replaces MAD operations with in-register lookups. Through hardware-aware
algorithmic designs, NoMAD-Attention achieves the computation of attention
scores using repeated fast accesses to SIMD registers despite their highly
limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based
LLMs without model finetuning. Empirical evaluations demonstrate that
NoMAD-Attention maintains the quality of the original LLMs well, and speeds up
the 4-bit quantized LLaMA-7B-based model by up to 2$\times$ at 16k context
length. Our results are reproducible at
https://github.com/tonyzhang617/nomad-dist.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01277" title="Abstract">arXiv:2403.01277</a> [<a href="/pdf/2403.01277" title="Download PDF">pdf</a>, <a href="/format/2403.01277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Integrated Task and Path Planning and Its Application to  Multi-Robot Pickup and Delivery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aryan%2C+A">Aman Aryan</a>, 
<a href="/search/cs?searchtype=author&query=Modi%2C+M">Manan Modi</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+I">Indranil Saha</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+R">Rupak Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Mohalik%2C+S">Swarup Mohalik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We propose a generic multi-robot planning mechanism that combines an optimal
task planner and an optimal path planner to provide a scalable solution for
complex multi-robot planning problems. The Integrated planner, through the
interaction of the task planner and the path planner, produces optimal
collision-free trajectories for the robots. We illustrate our general algorithm
on an object pick-and-drop planning problem in a warehouse scenario where a
group of robots is entrusted with moving objects from one location to another
in the workspace. We solve the task planning problem by reducing it into an
SMT-solving problem and employing the highly advanced SMT solver Z3 to solve
it. To generate collision-free movement of the robots, we extend the
state-of-the-art algorithm Conflict Based Search with Precedence Constraints
with several domain-specific constraints. We evaluate our integrated task and
path planner extensively on various instances of the object pick-and-drop
planning problem and compare its performance with a state-of-the-art
multi-robot classical planner. Experimental results demonstrate that our
planning mechanism can deal with complex planning problems and outperforms a
state-of-the-art classical planner both in terms of computation time and the
quality of the generated plan.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01278" title="Abstract">arXiv:2403.01278</a> [<a href="/pdf/2403.01278" title="Download PDF">pdf</a>, <a href="/format/2403.01278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Audio Generation Diversity with Visual Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zeyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuenan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio and sound generation has garnered significant attention in recent
years, with a primary focus on improving the quality of generated audios.
However, there has been limited research on enhancing the diversity of
generated audio, particularly when it comes to audio generation within specific
categories. Current models tend to produce homogeneous audio samples within a
category. This work aims to address this limitation by improving the diversity
of generated audio with visual information. We propose a clustering-based
method, leveraging visual information to guide the model in generating distinct
audio content within each category. Results on seven categories indicate that
extra visual input can largely enhance audio generation diversity. Audio
samples are available at https://zeyuxie29.github.io/DiverseAudioGeneration.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01281" title="Abstract">arXiv:2403.01281</a> [<a href="/pdf/2403.01281" title="Download PDF">pdf</a>, <a href="/format/2403.01281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Low-parameter Video Activity Localization in Collaborative Learning  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jatla%2C+V">Venkatesh Jatla</a>, 
<a href="/search/cs?searchtype=author&query=Teeparthi%2C+S">Sravani Teeparthi</a>, 
<a href="/search/cs?searchtype=author&query=Egala%2C+U">Ugesh Egala</a>, 
<a href="/search/cs?searchtype=author&query=Pattichis%2C+S+C">Sylvia Celedon Pattichis</a>, 
<a href="/search/cs?searchtype=author&query=Patticis%2C+M+S">Marios S. Patticis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Research on video activity detection has primarily focused on identifying
well-defined human activities in short video segments. The majority of the
research on video activity recognition is focused on the development of large
parameter systems that require training on large video datasets. This paper
develops a low-parameter, modular system with rapid inferencing capabilities
that can be trained entirely on limited datasets without requiring transfer
learning from large-parameter systems. The system can accurately detect and
associate specific activities with the students who perform the activities in
real-life classroom videos. Additionally, the paper develops an interactive
web-based application to visualize human activity maps over long real-life
classroom videos.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01286" title="Abstract">arXiv:2403.01286</a> [<a href="/pdf/2403.01286" title="Download PDF">pdf</a>, <a href="/format/2403.01286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Summary Paper: Use Case on Building Collaborative Safe Autonomous  Systems-A Robotdog for Guiding Visually Impaired People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malhotra%2C+A">Aman Malhotra</a>, 
<a href="/search/cs?searchtype=author&query=Saidi%2C+S">Selma Saidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">This is a summary paper of a use case of a Robotdog dedicated to guide
visually impaired people in complex environment like a smart intersection. In
such scenarios, the Robotdog has to autonomously decide whether it is safe to
cross the intersection or not in order to further guide the human. We leverage
data sharing and collaboration between the Robotdog and other autonomous
systems operating in the same environment. We propose a system architecture for
autonomous systems through a separation of a collaborative decision layer, to
enable collective decision making processes, where data about the environment,
relevant to the Robotdog decision, together with evidences for trustworthiness
about other systems and the environment are shared.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01289" title="Abstract">arXiv:2403.01289</a> [<a href="/pdf/2403.01289" title="Download PDF">pdf</a>, <a href="/format/2403.01289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greed is All You Need: An Evaluation of Tokenizer Inference Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uzan%2C+O">Omri Uzan</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+C+W">Craig W. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+C">Chris Tanner</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While subword tokenizers such as BPE and WordPiece are typically used to
build vocabularies for NLP models, the method of decoding text into a sequence
of tokens from these vocabularies is often left unspecified, or ill-suited to
the method in which they were constructed. We provide a controlled analysis of
seven tokenizer inference methods across four different algorithms and three
vocabulary sizes, performed on a novel intrinsic evaluation suite we curated
for English, combining measures rooted in morphology, cognition, and
information theory. We show that for the most commonly used tokenizers, greedy
inference performs surprisingly well; and that SaGe, a recently-introduced
contextually-informed tokenizer, outperforms all others on morphological
alignment.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01290" title="Abstract">arXiv:2403.01290</a> [<a href="/pdf/2403.01290" title="Download PDF">pdf</a>, <a href="/format/2403.01290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Ethereum Upgradable Smart Contracts and Their Security  Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuzhe Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Upgradeable smart contracts (USCs) have been widely adopted to enable
modifying deployed smart contracts. While USCs bring great flexibility to
developers, improper usage might introduce new security issues, potentially
allowing attackers to hijack USCs and their users. In this paper, we conduct a
large-scale measurement study to characterize USCs and their security
implications in the wild. We summarize six commonly used USC patterns and
develop a tool, USCDetector, to identify USCs without needing source code.
Particularly, USCDetector collects various information such as bytecode and
transaction information to construct upgrade chains for USCs and disclose
potentially vulnerable ones. We evaluate USCDetector using verified smart
contracts (i.e., with source code) as ground truth and show that USCDetector
can achieve high accuracy with a precision of 96.26%. We then use USCDetector
to conduct a large-scale study on Ethereum, covering a total of 60,251,064
smart contracts. USCDetecor constructs 10,218 upgrade chains and discloses
multiple real-world USCs with potential security issues.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01291" title="Abstract">arXiv:2403.01291</a> [<a href="/pdf/2403.01291" title="Download PDF">pdf</a>, <a href="/ps/2403.01291" title="Download PostScript">ps</a>, <a href="/format/2403.01291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fractional-order trace-dev-div inequality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carstensen%2C+C">Carsten Carstensen</a>, 
<a href="/search/math?searchtype=author&query=Heuer%2C+N">Norbert Heuer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">The trace-dev-div inequality in $H^s$ controls the trace in the norm of $H^s$
by that of the deviatoric part plus the $H^{s-1}$ norm of the divergence of a
quadratic tensor field different from the constant unit matrix. This is well
known for $s=0$ and established for orders $0\le s\le 1$ and arbitrary space
dimension in this note. For mixed and least-squares finite element error
analysis in linear elasticity, this inequality allows to establish robustness
with respect to the Lam\'e parameter $\lambda$.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01292" title="Abstract">arXiv:2403.01292</a> [<a href="/pdf/2403.01292" title="Download PDF">pdf</a>, <a href="/format/2403.01292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Intelligent Systems: From Illusion of Control to Inescapable  Delusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grumbach%2C+S">St&#xe9;phane Grumbach</a>, 
<a href="/search/cs?searchtype=author&query=Resta%2C+G">Giorgio Resta</a>, 
<a href="/search/cs?searchtype=author&query=Torlone%2C+R">Riccardo Torlone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, preliminary version, currently under submission to a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Autonomous systems, including generative AI, have been adopted faster than
previous digital innovations. Their impact on society might as well be more
profound, with a radical restructuring of the economy of knowledge and dramatic
consequences for social and institutional balances. Different attitudes to
control these systems have emerged rooted in the classical pillars of legal
systems, proprietary rights, and social responsibility. We show how an illusion
of control might be guiding governments and regulators, while autonomous
systems might be driving us to inescapable delusion.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01296" title="Abstract">arXiv:2403.01296</a> [<a href="/pdf/2403.01296" title="Download PDF">pdf</a>, <a href="/ps/2403.01296" title="Download PostScript">ps</a>, <a href="/format/2403.01296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-limited Shuffling for Distributed Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasi%2C+S">Shanuja Sasi</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnl%C3%BC%2C+O">Onur G&#xfc;nl&#xfc;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages and 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">This paper studies the shuffling phase in a distributed computing model with
rate-limited links between nodes. Each node is connected to all other nodes via
a noiseless broadcast link with a finite capacity. For this network, the
shuffling phase is described as a distributed index-coding problem to extend an
outer bound for the latter to the distributed computing problem. An inner bound
on the capacity region is also established by using the distributed
composite-coding scheme introduced for the distributed index-coding problem. We
consider some special cases of the distributed computing problem through two
examples for which we prove that the inner and outer bounds agree, thereby
establishing the capacity regions. We, then, generalize the special cases to
any number of nodes and computation loads under certain constraints.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01297" title="Abstract">arXiv:2403.01297</a> [<a href="/pdf/2403.01297" title="Download PDF">pdf</a>, <a href="/format/2403.01297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Evaluation of the ETSI DCC Adaptive Approach and Related  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+I">Ignacio Soto</a>, 
<a href="/search/cs?searchtype=author&query=Calderon%2C+M">Maria Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Urue%C3%B1a%2C+M">Manuel Urue&#xf1;a</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Oscar Amador, Ignacio Soto, Maria Calderon and Manuel Urue\~na,
  "Experimental Evaluation of the ETSI DCC Adaptive Approach and Related
  Algorithms," in IEEE Access, vol. 8, pp. 49798-49811, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Decentralized Congestion Control (DCC) mechanisms have been a core part of
protocol stacks for vehicular networks since their inception and
standardization. The ETSI ITS-G5 protocol stack for vehicular communications
considers the usage of DCC not only in the network or access layers, but also
as a part of the cross-layer architecture that influences how often messages
are generated and transmitted. ETSI DCC mechanisms have evolved from a reactive
approach based on a finite state machine, to an adaptive approach that relies
on a linear control algorithm. This linear control algorithm, called LIMERIC,
is the basis of the mechanism used in the ETSI DCC Adaptive Approach. The
behavior of this algorithm depends on a set of parameters. Different values for
these parameters have been proposed in the literature, including those defined
in the ETSI specification. A recent proposal is Dual-$\alpha$, which chooses
parameters to improve convergence and fairness when the algorithm has to react
to fast changes in the use of the shared medium (transitory situations). This
article evaluates, by means of simulations, the performance of the ETSI DCC
Adaptive Approach and related algorithms, considering both steady state and
transitory situations. Results show that a bad selection of parameters can make
a DCC algorithm ineffective, that the ETSI DCC Adaptive algorithm performs well
in steady state conditions, and that Dual-$\alpha$ performs as well in steady
state conditions and outperforms the ETSI DCC Adaptive Approach in transitory
scenarios.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01299" title="Abstract">arXiv:2403.01299</a> [<a href="/pdf/2403.01299" title="Download PDF">pdf</a>, <a href="/format/2403.01299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Photonic Physically Unclonable Function&#x27;s Resilience to  Multiple-Valued Machine Learning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henderson%2C+J+M">Jessie M. Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+E+R">Elena R. Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Harper%2C+C+A">Clayton A. Harper</a>, 
<a href="/search/cs?searchtype=author&query=Shahoei%2C+H">Hiva Shahoei</a>, 
<a href="/search/cs?searchtype=author&query=Oxford%2C+W+V">William V. Oxford</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+E+C">Eric C. Larson</a>, 
<a href="/search/cs?searchtype=author&query=MacFarlane%2C+D+L">Duncan L. MacFarlane</a>, 
<a href="/search/cs?searchtype=author&query=Thornton%2C+M+A">Mitchell A. Thornton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Physically unclonable functions (PUFs) identify integrated circuits using
nonlinearly-related challenge-response pairs (CRPs). Ideally, the relationship
between challenges and corresponding responses is unpredictable, even if a
subset of CRPs is known. Previous work developed a photonic PUF offering
improved security compared to non-optical counterparts. Here, we investigate
this PUF's susceptibility to Multiple-Valued-Logic-based machine learning
attacks. We find that approximately 1,000 CRPs are necessary to train models
that predict response bits better than random chance. Given the significant
challenge of acquiring a vast number of CRPs from a photonic PUF, our results
demonstrate photonic PUF resilience against such attacks.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01300" title="Abstract">arXiv:2403.01300</a> [<a href="/pdf/2403.01300" title="Download PDF">pdf</a>, <a href="/format/2403.01300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Mode Multiplexer: A Novel Framework for Unbiased Multispectral  Pedestrian Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeheon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Sebin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjoon Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+G">Hak Gu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">RGBT multispectral pedestrian detection has emerged as a promising solution
for safety-critical applications that require day/night operations. However,
the modality bias problem remains unsolved as multispectral pedestrian
detectors learn the statistical bias in datasets. Specifically, datasets in
multispectral pedestrian detection mainly distribute between ROTO (day) and
RXTO (night) data; the majority of the pedestrian labels statistically co-occur
with their thermal features. As a result, multispectral pedestrian detectors
show poor generalization ability on examples beyond this statistical
correlation, such as ROTX data. To address this problem, we propose a novel
Causal Mode Multiplexer (CMM) framework that effectively learns the causalities
between multispectral inputs and predictions. Moreover, we construct a new
dataset (ROTX-MP) to evaluate modality bias in multispectral pedestrian
detection. ROTX-MP mainly includes ROTX examples not presented in previous
datasets. Extensive experiments demonstrate that our proposed CMM framework
generalizes well on existing datasets (KAIST, CVC-14, FLIR) and the new
ROTX-MP. We will release our new dataset to the public for future research.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01301" title="Abstract">arXiv:2403.01301</a> [<a href="/pdf/2403.01301" title="Download PDF">pdf</a>, <a href="/format/2403.01301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supplier Recommendation in Online Procurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coscrato%2C+V">Victor Coscrato</a>, 
<a href="/search/cs?searchtype=author&query=Bridge%2C+D">Derek Bridge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Supply chain optimization is key to a healthy and profitable business. Many
companies use online procurement systems to agree contracts with suppliers. It
is vital that the most competitive suppliers are invited to bid for such
contracts. In this work, we propose a recommender system to assist with
supplier discovery in road freight online procurement. Our system is able to
provide personalized supplier recommendations, taking into account customer
needs and preferences. This is a novel application of recommender systems,
calling for design choices that fit the unique requirements of online
procurement. Our preliminary results, using real-world data, are promising.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01304" title="Abstract">arXiv:2403.01304</a> [<a href="/pdf/2403.01304" title="Download PDF">pdf</a>, <a href="/ps/2403.01304" title="Download PostScript">ps</a>, <a href="/format/2403.01304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Validity of Automatically Generated Feedback via  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scarlatos%2C+A">Alexander Scarlatos</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+D">Digory Smith</a>, 
<a href="/search/cs?searchtype=author&query=Woodhead%2C+S">Simon Woodhead</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+A">Andrew Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatically generating feedback via large language models (LLMs) in
intelligent tutoring systems and online learning platforms has the potential to
improve the learning outcomes of many students. However, both feedback
generation and evaluation are challenging: feedback content has to be valid
especially in subjects like math, which requires models to understand the
problem, the solution, and where the student's error lies. Feedback also has to
be pedagogically valid to reflect effective tutoring strategies, such as
explaining possible misconceptions and encouraging the student, among other
desirable features. In this work, we address both problems of automatically
generating and evaluating feedback while considering both correctness and
alignment. First, we propose a rubric for evaluating math feedback and show
that GPT-4 is able to effectively use it to annotate human-written and
LLM-generated feedback. Second, we propose a framework for feedback generation
that optimizes both correctness and alignment using reinforcement learning
(RL). Specifically, we use GPT-4's annotations to create preferences over
feedback pairs in an augmented dataset for training via direct preference
optimization (DPO). We show that our methods significantly increase the
correctness and alignment of generated feedback with Llama 2, an open-source
LLM, qualitatively analyze our generation and evaluation systems using case
studies, and outline several areas for future work.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01306" title="Abstract">arXiv:2403.01306</a> [<a href="/pdf/2403.01306" title="Download PDF">pdf</a>, <a href="/format/2403.01306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICC: Quantifying Image Caption Concreteness for Multimodal Dataset  Curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yanuka%2C+M">Moran Yanuka</a>, 
<a href="/search/cs?searchtype=author&query=Alper%2C+M">Morris Alper</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Web-scale training on paired text-image data is becoming increasingly central
to multimodal learning, but is challenged by the highly noisy nature of
datasets in the wild. Standard data filtering approaches succeed in removing
mismatched text-image pairs, but permit semantically related but highly
abstract or subjective text. These approaches lack the fine-grained ability to
isolate the most concrete samples that provide the strongest signal for
learning in a noisy dataset. In this work, we propose a new metric, image
caption concreteness, that evaluates caption text without an image reference to
measure its concreteness and relevancy for use in multimodal learning. Our
approach leverages strong foundation models for measuring visual-semantic
information loss in multimodal representations. We demonstrate that this
strongly correlates with human evaluation of concreteness in both single-word
and sentence-level texts. Moreover, we show that curation using ICC complements
existing approaches: It succeeds in selecting the highest quality samples from
multimodal web-scale datasets to allow for efficient training in
resource-constrained settings.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01308" title="Abstract">arXiv:2403.01308</a> [<a href="/pdf/2403.01308" title="Download PDF">pdf</a>, <a href="/format/2403.01308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VBART: The Turkish LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turker%2C+M">Meliksah Turker</a>, 
<a href="/search/cs?searchtype=author&query=Ari%2C+M+E">Mehmet Erdi Ari</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Aydin Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present VBART, the first Turkish sequence-to-sequence Large Language
Models (LLMs) pre-trained on a large corpus from scratch. VBART are compact
LLMs based on good ideas leveraged from BART and mBART models and come in two
sizes, Large and XLarge. Fine-tuned VBART models surpass the prior
state-of-the-art results in abstractive text summarization, title generation,
text paraphrasing, question answering and question generation tasks. They allow
fine-tuning for future text generation tasks and datasets, carving a new path
for Turkish Natural Language Processing (NLP) research. Our work shows that
having a pre-trained LLM for Turkish outperforms up to 3x multilingual models,
improving existing results and providing efficient models for training and
inference. Moreover, we show that our monolingual tokenizer is 7x more
efficient than OpenAI's multilingual tokenizer. Last but not least, we
introduce a method to enlarge an existing pre-trained LLM and question the
relevancy of Chinchilla Scaling Law to sequence-to-sequence masked language
models. Our fine-tuned models, tokenizer and cleaned web corpus of 135 GB are
publicly available at huggingface.co/vngrs-ai.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01309" title="Abstract">arXiv:2403.01309</a> [<a href="/pdf/2403.01309" title="Download PDF">pdf</a>, <a href="/format/2403.01309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VNLP: Turkish NLP Package
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turker%2C+M">Meliksah Turker</a>, 
<a href="/search/cs?searchtype=author&query=Ari%2C+M+E">Mehmet Erdi Ari</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Aydin Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we present VNLP: the first dedicated, complete, open-source,
well-documented, lightweight, production-ready, state-of-the-art Natural
Language Processing (NLP) package for the Turkish language. It contains a wide
variety of tools, ranging from the simplest tasks, such as sentence splitting
and text normalization, to the more advanced ones, such as text and token
classification models. Its token classification models are based on "Context
Model", a novel architecture that is both an encoder and an auto-regressive
model. NLP tasks solved by VNLP models include but are not limited to Sentiment
Analysis, Named Entity Recognition, Morphological Analysis \&amp; Disambiguation
and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings
and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source
GitHub repository, ReadtheDocs documentation, PyPi package for convenient
installation, Python and command-line API and a demo page to test all the
functionality. Consequently, our main contribution is a complete, compact,
easy-to-install and easy-to-use NLP package for Turkish.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01310" title="Abstract">arXiv:2403.01310</a> [<a href="/pdf/2403.01310" title="Download PDF">pdf</a>, <a href="/format/2403.01310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-Based Dietary Assessment: A Healthy Eating Plate Estimation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izbassar%2C+A">Assylzhan Izbassar</a>, 
<a href="/search/cs?searchtype=author&query=Shamoi%2C+P">Pakizar Shamoi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE for consideration
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The nutritional quality of diets has significantly deteriorated over the past
two to three decades, a decline often underestimated by the people. This
deterioration, coupled with a hectic lifestyle, has contributed to escalating
health concerns. Recognizing this issue, researchers at Harvard have advocated
for a balanced nutritional plate model to promote health. Inspired by this
research, our paper introduces an innovative Image-Based Dietary Assessment
system aimed at evaluating the healthiness of meals through image analysis. Our
system employs advanced image segmentation and classification techniques to
analyze food items on a plate, assess their proportions, and calculate meal
adherence to Harvard's healthy eating recommendations. This approach leverages
machine learning and nutritional science to empower individuals with actionable
insights for healthier eating choices. Our four-step framework involves
segmenting the image, classifying the items, conducting a nutritional
assessment based on the Harvard Healthy Eating Plate research, and offering
tailored recommendations. The prototype system has shown promising results in
promoting healthier eating habits by providing an accessible, evidence-based
tool for dietary assessment.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01314" title="Abstract">arXiv:2403.01314</a> [<a href="/pdf/2403.01314" title="Download PDF">pdf</a>, <a href="/format/2403.01314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superflows: A New Tool for Forensic Network Flow Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+M">Michael Collins</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+J+V">Jyotirmoy V. Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Dinesh%2C+D">Dristi Dinesh</a>, 
<a href="/search/cs?searchtype=author&query=Raghothaman%2C+M">Mukund Raghothaman</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Srivatsan Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuan Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Network security analysts gather data from diverse sources, from high-level
summaries of network flow and traffic volumes to low-level details such as
service logs from servers and the contents of individual packets. They validate
and check this data against traffic patterns and historical indicators of
compromise. Based on the results of this analysis, a decision is made to either
automatically manage the traffic or report it to an analyst for further
investigation. Unfortunately, due rapidly increasing traffic volumes, there are
far more events to check than operational teams can handle for effective
forensic analysis. However, just as packets are grouped into flows that share a
commonality, we argue that a high-level construct for grouping network flows
into a set a flows that share a hypothesis is needed to significantly improve
the quality of operational network response by increasing Events Per Analysts
Hour (EPAH).
<br />In this paper, we propose a formalism for describing a superflow construct,
which we characterize as an aggregation of one or more flows based on an
analyst-specific hypothesis about traffic behavior. We demonstrate simple
superflow constructions and representations, and perform a case study to
explain how the formalism can be used to reduce the volume of data for forensic
analysis.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01315" title="Abstract">arXiv:2403.01315</a> [<a href="/pdf/2403.01315" title="Download PDF">pdf</a>, <a href="/ps/2403.01315" title="Download PostScript">ps</a>, <a href="/format/2403.01315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-optimal Per-Action Regret Bounds for Sleeping Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+N+A">Nishant A. Mehta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We derive near-optimal per-action regret bounds for sleeping bandits, in
which both the sets of available arms and their losses in every round are
chosen by an adversary. In a setting with $K$ total arms and at most $A$
available arms in each round over $T$ rounds, the best known upper bound is
$O(K\sqrt{TA\ln{K}})$, obtained indirectly via minimizing internal sleeping
regrets. Compared to the minimax $\Omega(\sqrt{TA})$ lower bound, this upper
bound contains an extra multiplicative factor of $K\ln{K}$. We address this gap
by directly minimizing the per-action regret using generalized versions of
EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal
bounds of order $O(\sqrt{TA\ln{K}})$ and $O(\sqrt{T\sqrt{AK}})$. We extend our
results to the setting of bandits with advice from sleeping experts,
generalizing EXP4 along the way. This leads to new proofs for a number of
existing adaptive and tracking regret bounds for standard non-sleeping bandits.
Extending our results to the bandit version of experts that report their
confidences leads to new bounds for the confidence regret that depends
primarily on the sum of experts' confidences. We prove a lower bound, showing
that for any minimax optimal algorithms, there exists an action whose regret is
sublinear in $T$ but linear in the number of its active rounds.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01316" title="Abstract">arXiv:2403.01316</a> [<a href="/pdf/2403.01316" title="Download PDF">pdf</a>, <a href="/format/2403.01316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TUMTraf V2X Cooperative Perception Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+W">Walter Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Wardana%2C+G+A">Gerhard Arya Wardana</a>, 
<a href="/search/cs?searchtype=author&query=Sritharan%2C+S">Suren Sritharan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingcheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A+C">Alois C. Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cooperative perception offers several benefits for enhancing the capabilities
of autonomous vehicles and improving road safety. Using roadside sensors in
addition to onboard sensors increases reliability and extends the sensor range.
External sensors offer higher situational awareness for automated vehicles and
prevent occlusions. We propose CoopDet3D, a cooperative multi-modal fusion
model, and TUMTraf-V2X, a perception dataset, for the cooperative 3D object
detection and tracking task. Our dataset contains 2,000 labeled point clouds
and 5,000 labeled images from five roadside and four onboard sensors. It
includes 30k 3D boxes with track IDs and precise GPS and IMU data. We labeled
eight categories and covered occlusion scenarios with challenging driving
maneuvers, like traffic violations, near-miss events, overtaking, and U-turns.
Through multiple experiments, we show that our CoopDet3D camera-LiDAR fusion
model achieves an increase of +14.36 3D mAP compared to a vehicle camera-LiDAR
fusion model. Finally, we make our dataset, model, labeling tool, and dev-kit
publicly available on our website:
https://tum-traffic-dataset.github.io/tumtraf-v2x.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01317" title="Abstract">arXiv:2403.01317</a> [<a href="/pdf/2403.01317" title="Download PDF">pdf</a>, <a href="/format/2403.01317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More: Hop-Wise Graph Attention for Scalable and Generalizable  Learning on Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chenhui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zichao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunxi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sarar%2C+G">Gokce Sarar</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+R">Ryan Carey</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rajeev Jain</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at Design Automation Conference (DAC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">While graph neural networks (GNNs) have gained popularity for learning
circuit representations in various electronic design automation (EDA) tasks,
they face challenges in scalability when applied to large graphs and exhibit
limited generalizability to new designs. These limitations make them less
practical for addressing large-scale, complex circuit problems. In this work we
propose HOGA, a novel attention-based model for learning circuit
representations in a scalable and generalizable manner. HOGA first computes
hop-wise features per node prior to model training. Subsequently, the hop-wise
features are solely used to produce node representations through a gated
self-attention module, which adaptively learns important features among
different hops without involving the graph topology. As a result, HOGA is
adaptive to various structures across different circuits and can be efficiently
trained in a distributed manner. To demonstrate the efficacy of HOGA, we
consider two representative EDA tasks: quality of results (QoR) prediction and
functional reasoning. Our experimental results indicate that (1) HOGA reduces
estimation error over conventional GNNs by 46.76% for predicting QoR after
logic synthesis; (2) HOGA improves 10.0% reasoning accuracy over GNNs for
identifying functional blocks on unseen gate-level netlists after complex
technology mapping; (3) The training time for HOGA almost linearly decreases
with an increase in computing resources.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01323" title="Abstract">arXiv:2403.01323</a> [<a href="/pdf/2403.01323" title="Download PDF">pdf</a>, <a href="/format/2403.01323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A non-cubic space-filling modular robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hummer%2C+T">Tyler Hummer</a>, 
<a href="/search/cs?searchtype=author&query=Kriegman%2C+S">Sam Kriegman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Space-filling building blocks of diverse shape permeate nature at all levels
of organization, from atoms to honeycombs, and have proven useful in artificial
systems, from molecular containers to clay bricks. But, despite the wide
variety of space-filling polyhedra known to mathematics, only the cube has been
explored in robotics. Thus, here we roboticize a non-cubic space-filling shape:
the rhombic dodecahedron. This geometry offers an appealing alternative to
cubes as it greatly simplifies rotational motion of one cell about the edge of
another, and increases the number of neighbors each cell can communicate with
and hold on to. To better understand the challenges and opportunities of these
and other space-filling machines, we manufactured 48 rhombic dodecahedral cells
and used them to build various superstructures. We report locomotive ability of
some of the structures we built, and discuss the dis/advantages of the
different designs we tested. We also introduce a strategy for genderless
passive docking of cells that generalizes to any polyhedra with radially
symmetrical faces. Future work will allow the cells to freely roll/rotate about
one another so that they may realize the full potential of their unique shape.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01325" title="Abstract">arXiv:2403.01325</a> [<a href="/pdf/2403.01325" title="Download PDF">pdf</a>, <a href="/format/2403.01325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-VPT: Learning Novel View Representations with Neural Radiance  Fields via View Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linsheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liuchun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+K">Ken Deng</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P+H+S">Philip H.S. Torr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have garnered remarkable success in novel view
synthesis. Nonetheless, the task of generating high-quality images for novel
views persists as a critical challenge. While the existing efforts have
exhibited commendable progress, capturing intricate details, enhancing
textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics
warrant further focused attention and advancement. In this work, we propose
NeRF-VPT, an innovative method for novel view synthesis to address these
challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning
paradigm, wherein RGB information gained from preceding rendering outcomes
serves as instructive visual prompts for subsequent rendering stages, with the
aspiration that the prior knowledge embedded in the prompts can facilitate the
gradual enhancement of rendered image quality. NeRF-VPT only requires sampling
RGB data from previous stage renderings as priors at each training stage,
without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is
plug-and-play and can be readily integrated into existing methods. By
conducting comparative analyses of our NeRF-VPT against several NeRF-based
approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360,
Real Forward-Facing, Replica dataset, and a user-captured dataset, we
substantiate that our NeRF-VPT significantly elevates baseline performance and
proficiently generates more high-quality novel view images than all the
compared state-of-the-art methods. Furthermore, the cascading learning of
NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in
a significant enhancement of accuracy for sparse-view novel view synthesis. The
source code and dataset are available at
\url{https://github.com/Freedomcls/NeRF-VPT}.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01326" title="Abstract">arXiv:2403.01326</a> [<a href="/pdf/2403.01326" title="Download PDF">pdf</a>, <a href="/format/2403.01326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNA Family: Boosting Weight-Sharing NAS with Block-Wise Supervisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liuchun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiefeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+X">Xiaoyu Xian</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> T-PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Architecture Search (NAS), aiming at automatically designing neural
architectures by machines, has been considered a key step toward automatic
machine learning. One notable NAS branch is the weight-sharing NAS, which
significantly improves search efficiency and allows NAS algorithms to run on
ordinary computers. Despite receiving high expectations, this category of
methods suffers from low search effectiveness. By employing a generalization
boundedness tool, we demonstrate that the devil behind this drawback is the
untrustworthy architecture rating with the oversized search space of the
possible architectures. Addressing this problem, we modularize a large search
space into blocks with small search spaces and develop a family of models with
the distilling neural architecture (DNA) techniques. These proposed models,
namely a DNA family, are capable of resolving multiple dilemmas of the
weight-sharing NAS, such as scalability, efficiency, and multi-modal
compatibility. Our proposed DNA models can rate all architecture candidates, as
opposed to previous works that can only access a sub- search space using
heuristic algorithms. Moreover, under a certain computational complexity
constraint, our method can seek architectures with different depths and widths.
Extensive experimental evaluations show that our models achieve
state-of-the-art top-1 accuracy of 78.9% and 83.6% on ImageNet for a mobile
convolutional network and a small vision transformer, respectively.
Additionally, we provide in-depth empirical analysis and insights into neural
architecture ratings. Codes available: \url{https://github.com/changlin31/DNA}.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01327" title="Abstract">arXiv:2403.01327</a> [<a href="/pdf/2403.01327" title="Download PDF">pdf</a>, <a href="/ps/2403.01327" title="Download PostScript">ps</a>, <a href="/format/2403.01327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Euclidean distance compression via deep random features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leroux%2C+B">Brett Leroux</a>, 
<a href="/search/cs?searchtype=author&query=Rademacher%2C+L">Luis Rademacher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Motivated by the problem of compressing point sets into as few bits as
possible while maintaining information about approximate distances between
points, we construct random nonlinear maps $\varphi_\ell$ that compress point
sets in the following way. For a point set $S$, the map
$\varphi_\ell:\mathbb{R}^d \to N^{-1/2}\{-1,1\}^N$ has the property that
storing $\varphi_\ell(S)$ (a \emph{sketch} of $S$) allows one to report
pairwise squared distances between points in $S$ up to some multiplicative
$(1\pm \epsilon)$ error with high probability as long as the minimum distance
is not too small compared to $\epsilon$. The maps $\varphi_\ell$ are the
$\ell$-fold composition of a certain type of random feature mapping. Moreover,
we determine how large $N$ needs to be as a function of $\epsilon$ and other
parameters of the point set.
<br />Compared to existing techniques, our maps offer several advantages. The
standard method for compressing point sets by random mappings relies on the
Johnson-Lindenstrauss lemma which implies that if a set of $n$ points is mapped
by a Gaussian random matrix to $\mathbb{R}^k$ with $k =\Theta(\epsilon^{-2}\log
n)$, then pairwise distances between points are preserved up to a
multiplicative $(1\pm \epsilon)$ error with high probability. The main
advantage of our maps $\varphi_\ell$ over random linear maps is that ours map
point sets directly into the discrete cube $N^{-1/2}\{-1,1\}^N$ and so there is
no additional step needed to convert the sketch to bits. For some range of
parameters, our maps $\varphi_\ell$ produce sketches which require fewer bits
of storage space.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01329" title="Abstract">arXiv:2403.01329</a> [<a href="/pdf/2403.01329" title="Download PDF">pdf</a>, <a href="/format/2403.01329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaul%2C+N">Neta Shaul</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+U">Uriel Singer</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+T+Q">Ricky T. Q. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+M">Matthew Le</a>, 
<a href="/search/cs?searchtype=author&query=Thabet%2C+A">Ali Thabet</a>, 
<a href="/search/cs?searchtype=author&query=Pumarola%2C+A">Albert Pumarola</a>, 
<a href="/search/cs?searchtype=author&query=Lipman%2C+Y">Yaron Lipman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver
distillation approach to improve sample efficiency of Diffusion and Flow
models. BNS solvers are based on a family of non-stationary solvers that
provably subsumes existing numerical ODE solvers and consequently demonstrate
considerable improvement in sample approximation (PSNR) over these baselines.
Compared to model distillation, BNS solvers benefit from a tiny parameter space
($&lt;$200 parameters), fast optimization (two orders of magnitude faster),
maintain diversity of samples, and in contrast to previous solver distillation
approaches nearly close the gap from standard distillation methods such as
Progressive Distillation in the low-medium NFE regime. For example, BNS solver
achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We
experimented with BNS solvers for conditional image generation, text-to-image
generation, and text-2-audio generation showing significant improvement in
sample approximation (PSNR) in all.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01333" title="Abstract">arXiv:2403.01333</a> [<a href="/pdf/2403.01333" title="Download PDF">pdf</a>, <a href="/ps/2403.01333" title="Download PostScript">ps</a>, <a href="/format/2403.01333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Maximum Actuator Degradation for a Given $H_2/H_{\infty}$  Performance with Full-State Feedback Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Das%2C+H">Hrishav Das</a>, 
<a href="/search/eess?searchtype=author&query=Nychka%2C+E">Eliot Nychka</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+R">Raktim Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we address the issue of quantifying maximum actuator
degradation in linear time-invariant dynamical systems. We present a new
unified framework for computing the state-feedback controller gain that meets a
user-defined closed-loop performance criterion while also maximizing actuator
degradation. This degradation is modeled as a first-order filter with additive
noise. Our approach involves two novel convex optimization formulations that
concurrently determine the controller gain, maximize actuator degradation, and
maintain the desired closed-loop performance in both the $H_2$ and $H_{\infty}$
system norms. The results are limited to open-loop stable systems. We
demonstrate the application of our results through the design of a full-state
feedback controller for a model representing the longitudinal motion of the
F-16 aircraft.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01334" title="Abstract">arXiv:2403.01334</a> [<a href="/pdf/2403.01334" title="Download PDF">pdf</a>, <a href="/ps/2403.01334" title="Download PostScript">ps</a>, <a href="/format/2403.01334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of Linear Parameter Varying System to Investigate the  Impact of Varying Flow Rate on the Lithium-ion Batteries Thermal Management  System Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rabiee%2C+P">Pedram Rabiee</a>, 
<a href="/search/eess?searchtype=author&query=Saidi%2C+M+H">Mohammad Hassan Saidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Battery thermal management system is an indispensable part of the electric
vehicles working with Lithium-ion batteries. Accordingly, lithium-ion batteries
modeling, battery heat generation, and thermal management are the main focus of
researchers and car manufacturers. To fulfill the need of manufacturers in the
design process, a faster model than time-consuming Computational Fluid Dynamics
models (CFD) is required. Reduced Order Models (ROM) address this requirement
to maintain the accuracy of CFD models while could be compiled faster. Linear
Time Invariant (LTI) reduced order model has been used in the literature;
however, due to the limitation of LTI system, considering the constant flow
rate for the cooling fluid, a Linear Parameter Varying system with three
scheduling parameters was developed in this study. It is shown that LPV system
results could fit accurately to CFD results in conditions that LTI system
cannot maintain accuracy. Moreover, it is shown that applying varying water
flow rates could result in a smoother temperature profile.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01335" title="Abstract">arXiv:2403.01335</a> [<a href="/pdf/2403.01335" title="Download PDF">pdf</a>, <a href="/format/2403.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Hybrid Languages: A Recipe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andersen%2C+L">Leif Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Moy%2C+C">Cameron Moy</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Stephen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Felleisen%2C+M">Matthias Felleisen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The dominant programming languages support only linear text to express ideas.
Visual languages offer graphical representations for entire programs, when
viewed with special tools. Hybrid languages, with support from existing tools,
allow developers to express their ideas with a mix of textual and graphical
syntax tailored to an application domain. This mix puts both kinds of syntax on
equal footing and, importantly, the enriched language does not disrupt a
programmer's typical workflow. This paper presents a recipe for equipping
existing textual programming languages as well as accompanying IDEs with a
mechanism for creating and using graphical interactive syntax. It also presents
the first hybrid language and IDE created using the recipe.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01339" title="Abstract">arXiv:2403.01339</a> [<a href="/pdf/2403.01339" title="Download PDF">pdf</a>, <a href="/ps/2403.01339" title="Download PostScript">ps</a>, <a href="/format/2403.01339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform $\mathcal{C}^k$ Approximation of $G$-Invariant and Antisymmetric  Functions, Embedding Dimensions, and Polynomial Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+S">Soumya Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+K">Khoa Tran</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rahul Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Representation Theory (math.RT)

</div>
<p class="mathjax">For any subgroup $G$ of the symmetric group $\mathcal{S}_n$ on $n$ symbols,
we present results for the uniform $\mathcal{C}^k$ approximation of
$G$-invariant functions by $G$-invariant polynomials. For the case of totally
symmetric functions ($G = \mathcal{S}_n$), we show that this gives rise to the
sum-decomposition Deep Sets ansatz of Zaheer et al. (2018), where both the
inner and outer functions can be chosen to be smooth, and moreover, the inner
function can be chosen to be independent of the target function being
approximated. In particular, we show that the embedding dimension required is
independent of the regularity of the target function, the accuracy of the
desired approximation, as well as $k$. Next, we show that a similar procedure
allows us to obtain a uniform $\mathcal{C}^k$ approximation of antisymmetric
functions as a sum of $K$ terms, where each term is a product of a smooth
totally symmetric function and a smooth antisymmetric homogeneous polynomial of
degree at most $\binom{n}{2}$. We also provide upper and lower bounds on $K$
and show that $K$ is independent of the regularity of the target function, the
desired approximation accuracy, and $k$.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01342" title="Abstract">arXiv:2403.01342</a> [<a href="/pdf/2403.01342" title="Download PDF">pdf</a>, <a href="/ps/2403.01342" title="Download PostScript">ps</a>, <a href="/format/2403.01342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM4OPT: Unveiling the Potential of Large Language Models in Formulating  Mathematical Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+T">Tasnim Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Salimur Choudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In the rapidly evolving field of natural language processing, the translation
of linguistic descriptions into mathematical formulation of optimization
problems presents a formidable challenge, demanding intricate understanding and
processing capabilities from Large Language Models (LLMs). This study compares
prominent LLMs, including GPT-3.5, GPT-4, and Llama-2-7b, in zero-shot and
one-shot settings for this task. Our findings show GPT-4's superior
performance, particularly in the one-shot scenario. A central part of this
research is the introduction of `LM4OPT,' a progressive fine-tuning framework
for Llama-2-7b that utilizes noisy embeddings and specialized datasets.
However, this research highlights a notable gap in the contextual understanding
capabilities of smaller models such as Llama-2-7b compared to larger
counterparts, especially in processing lengthy and complex input contexts. Our
empirical investigation, utilizing the NL4Opt dataset, unveils that GPT-4
surpasses the baseline performance established by previous research, achieving
an F1-score of 0.63, solely based on the problem description in natural
language, and without relying on any additional named entity information.
GPT-3.5 follows closely, both outperforming the fine-tuned Llama-2-7b. These
findings not only benchmark the current capabilities of LLMs in a novel
application area but also lay the groundwork for future improvements in
mathematical formulation of optimization problems from natural language input.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01343" title="Abstract">arXiv:2403.01343</a> [<a href="/pdf/2403.01343" title="Download PDF">pdf</a>, <a href="/ps/2403.01343" title="Download PostScript">ps</a>, <a href="/format/2403.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effectiveness of a Training Program Based on Health Education to  Improve Health Empowerment Level among Refugees in Jordan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AlSharifin%2C+A">Ahmed AlSharifin</a>, 
<a href="/search/cs?searchtype=author&query=Megdadi%2C+M">Muayyad Megdadi</a>, 
<a href="/search/cs?searchtype=author&query=Shatnawi%2C+A">Amani Shatnawi</a>, 
<a href="/search/cs?searchtype=author&query=AlSobeh%2C+A">Anas AlSobeh</a>, 
<a href="/search/cs?searchtype=author&query=Akkawi%2C+A">Aya Akkawi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Dirasat: Human and Social Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Objectives: The study aimed to evaluate the effectiveness of a health
education-based training program in enhancing the level of health empowerment
among refugees in Jordan. Health empowerment is a key component to promote
health as it enables individuals to control and manage their health outcomes
and improve them. Refugees are a vulnerable population group with limited
access to healthcare.
<br />Methodology: The study sample consisted of 38 refugees in Irbid governorate,
Jordan, who were conveniently selected in coordination with some organizations
working in the field of asylum in the governorate. They were randomly divided
into two groups: an experimental group (n = 19) that received the health
education training program, and a control group (n = 19) that did not receive
any health education training. The Health Empowerment Scale (HES), a validated
tool, was used to collect data from both groups in the pre and post-tests, and
a follow-up test was conducted for members of the experimental group only.
Results: The results showed a statistically significant increase in the health
empowerment scores for the experimental group that received the training
program compared to the control group. The mean of the pre-test for the
experimental group was (1.97 - 0.27), and for the control group, it was (1.84 -
0.21). The post-test mean for the experimental group became (3.88 - 0.13),
while for the control group, it was (1.85 - 0.20). The follow-up test also
demonstrated that the enhanced health empowerment levels were maintained in the
experimental group, with no significant difference between the post-test and
follow-up scores, indicating the effectiveness of the health education training
program in enhancing health empowerment for refugees in Jordan.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01344" title="Abstract">arXiv:2403.01344</a> [<a href="/pdf/2403.01344" title="Download PDF">pdf</a>, <a href="/format/2403.01344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating the Bias in the Model for Continual Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+I">Inseop Chung</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+K">Kyomin Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jayeon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Continual Test-Time Adaptation (CTA) is a challenging task that aims to adapt
a source pre-trained model to continually changing target domains. In the CTA
setting, a model does not know when the target domain changes, thus facing a
drastic change in the distribution of streaming inputs during the test-time.
The key challenge is to keep adapting the model to the continually changing
target domains in an online manner. We find that a model shows highly biased
predictions as it constantly adapts to the chaining distribution of the target
data. It predicts certain classes more often than other classes, making
inaccurate over-confident predictions. This paper mitigates this issue to
improve performance in the CTA scenario. To alleviate the bias issue, we make
class-wise exponential moving average target prototypes with reliable target
samples and exploit them to cluster the target features class-wisely. Moreover,
we aim to align the target distributions to the source distribution by
anchoring the target feature to its corresponding source prototype. With
extensive experiments, our proposed method achieves noteworthy performance gain
when applied on top of existing CTA methods without substantial adaptation time
overhead.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01345" title="Abstract">arXiv:2403.01345</a> [<a href="/pdf/2403.01345" title="Download PDF">pdf</a>, <a href="/format/2403.01345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShapeBoost: Boosting Human Shape Estimation with Part-Based  Parameterization and Clothing-Preserving Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+S">Siyuan Bian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiasheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate human shape recovery from a monocular RGB image is a challenging
task because humans come in different shapes and sizes and wear different
clothes. In this paper, we propose ShapeBoost, a new human shape recovery
framework that achieves pixel-level alignment even for rare body shapes and
high accuracy for people wearing different types of clothes. Unlike previous
approaches that rely on the use of PCA-based shape coefficients, we adopt a new
human shape parameterization that decomposes the human shape into bone lengths
and the mean width of each part slice. This part-based parameterization
technique achieves a balance between flexibility and validity using a
semi-analytical shape reconstruction algorithm. Based on this new
parameterization, a clothing-preserving data augmentation module is proposed to
generate realistic images with diverse body shapes and accurate annotations.
Experimental results show that our method outperforms other state-of-the-art
methods in diverse body shape situations as well as in varied clothing
situations.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01346" title="Abstract">arXiv:2403.01346</a> [<a href="/pdf/2403.01346" title="Download PDF">pdf</a>, <a href="/format/2403.01346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improve Cost Efficiency of Active Learning over Noisy Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chong%2C+Z">Zan-Kai Chong</a>, 
<a href="/search/cs?searchtype=author&query=Ohsaki%2C+H">Hiroyuki Ohsaki</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+B">Bryan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Active learning is a learning strategy whereby the machine learning algorithm
actively identifies and labels data points to optimize its learning. This
strategy is particularly effective in domains where an abundance of unlabeled
data exists, but the cost of labeling these data points is prohibitively
expensive. In this paper, we consider cases of binary classification, where
acquiring a positive instance incurs a significantly higher cost compared to
that of negative instances. For example, in the financial industry, such as in
money-lending businesses, a defaulted loan constitutes a positive event leading
to substantial financial loss. To address this issue, we propose a shifted
normal distribution sampling function that samples from a wider range than
typical uncertainty sampling. Our simulation underscores that our proposed
sampling function limits both noisy and positive label selection, delivering
between 20% and 32% improved cost efficiency over different test datasets.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01347" title="Abstract">arXiv:2403.01347</a> [<a href="/pdf/2403.01347" title="Download PDF">pdf</a>, <a href="/ps/2403.01347" title="Download PostScript">ps</a>, <a href="/format/2403.01347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Repercussions of the COVID-19 Pandemic on Higher Education and its  implications for Syrian Refugees Students (An Analytical Descriptive Study)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsobeh%2C+A">Anas Alsobeh</a>, 
<a href="/search/cs?searchtype=author&query=Aloudat%2C+A">Ahlam Aloudat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Arabic language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This study aims to reveal the most important challenges and difficulties that
refugee students faced in Jordanian universities (e.g., Yarmouk University, AL
Al-Bayt, and the Private Zarqa University) due to the COVID-19 pandemic through
measuring a different of indicators that are related, in addition, to identify
some of the independent variables on e-educational challenges. In the study,
the analytical description approach was used. The data collection tool is a
questionnaire, which was distributed to a random sample of students
electronically. Results show that the necessity to implement educational and
psychological counseling programs and economic support programs to support the
e-Learning costs. The study confirmed that refugees are the most affected
students with the pandemic compared to the host community.
<br />Keywords: Syrian refugees, COVID-19, e-learning
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01348" title="Abstract">arXiv:2403.01348</a> [<a href="/pdf/2403.01348" title="Download PDF">pdf</a>, <a href="/ps/2403.01348" title="Download PostScript">ps</a>, <a href="/format/2403.01348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for  Indoor Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gufran%2C+D">Danish Gufran</a>, 
<a href="/search/cs?searchtype=author&query=Tiku%2C+S">Saideep Tiku</a>, 
<a href="/search/cs?searchtype=author&query=Pasricha%2C+S">Sudeep Pasricha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Indoor localization is a critical task in many embedded applications, such as
asset tracking, emergency response, and realtime navigation. In this article,
we propose a novel fingerprintingbased framework for indoor localization called
SANGRIA that uses stacked autoencoder neural networks with gradient boosted
trees. Our approach is designed to overcome the device heterogeneity challenge
that can create uncertainty in wireless signal measurements across embedded
devices used for localization. We compare SANGRIA to several state-of-the-art
frameworks and demonstrate 42.96% lower average localization error across
diverse indoor locales and heterogeneous devices.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01349" title="Abstract">arXiv:2403.01349</a> [<a href="/pdf/2403.01349" title="Download PDF">pdf</a>, <a href="/ps/2403.01349" title="Download PostScript">ps</a>, <a href="/format/2403.01349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OSM: Leveraging Model Checking for Observing Dynamic 1 behaviors in  Aspect-Oriented Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AlSobeh%2C+A">Anas AlSobeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the intricate domain of software systems verification, dynamically model
checking multifaceted system characteristics remains paramount, yet
challenging. This research proposes the advanced observe-based statistical
model-checking (OSM) framework, devised to craft executable formal models
directly from foundational system code. Leveraging model checking predicates,
the framework melds seamlessly with aspect-oriented programming paradigms,
yielding a potent method for the analytical verification of varied behavioral
attributes. Exploiting the transformative capacity of OSM framework, primary
system code undergoes a systematic metamorphosis into multifaceted analysis
constructs. This not only simplifies the model verification process but also
orchestrates feature interactions using an innovative observing join point
abstraction mechanism. Within this framework, components encompassing parsing,
formal verification, computational analytics, and rigorous validation are
intrinsically interwoven. Marrying the principles of model checking with
aspect-oriented (AO) modularization, OSM framework stands as a paragon,
proficiently scrutinizing and affirming system specifications. This ensures the
unyielding performance of electronic health record systems amidst shifting
preconditions. OSM framework offers runtime verification of both
object-oriented and AO deployments, positioning itself as an indispensable
open-source resource, poised to automate the enhancement of system performance
and scalability.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01351" title="Abstract">arXiv:2403.01351</a> [<a href="/pdf/2403.01351" title="Download PDF">pdf</a>, <a href="/ps/2403.01351" title="Download PostScript">ps</a>, <a href="/format/2403.01351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient FIR filtering with Bit Layer Multiply Accumulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liguori%2C+V">Vincenzo Liguori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Bit Layer Multiplier Accumulator (BLMAC) is an efficient method to perform
dot products without multiplications that exploits the bit level sparsity of
the weights. A total of 1,980,000 low, high, band pass and band stop type I FIR
filters were generated by systematically sweeping through the cut off
frequencies and by varying the number of taps from 55 to 255. After their
coefficients were quantized to 16 bits, applying the filter using a BLMAC
required, on average, from ~123.3 to ~513.6 additions, depending on the number
of taps. A BLMAC dot product machine, specialised for 127 taps FIR filters, was
designed for AMD FPGAs. The design footprint is ~110 LUTs, including
coefficient and sample storage and is able to apply the filter in ~232 clock
cycles on average. This implies a filtering rate of 1.4-3.4 Msamples/s,
depending on the FPGA family.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01352" title="Abstract">arXiv:2403.01352</a> [<a href="/pdf/2403.01352" title="Download PDF">pdf</a>, <a href="/ps/2403.01352" title="Download PostScript">ps</a>, <a href="/format/2403.01352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Uncertainty Sampling with Bell Curve Weight Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chong%2C+Z">Zan-Kai Chong</a>, 
<a href="/search/cs?searchtype=author&query=Ohsaki%2C+H">Hiroyuki Ohsaki</a>, 
<a href="/search/cs?searchtype=author&query=Goi%2C+B">Bok-Min Goi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Zan-Kai Chong, Hiroyuki Ohsaki, Bok-Min Goi, "Improving
  Uncertainty Sampling with Bell Curve Weight Function", International Journal
  of Applied Physics and Mathematics, Vol. 13, No. 4, pp. 44-52, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Typically, a supervised learning model is trained using passive learning by
randomly selecting unlabelled instances to annotate. This approach is effective
for learning a model, but can be costly in cases where acquiring labelled
instances is expensive. For example, it can be time-consuming to manually
identify spam mails (labelled instances) from thousands of emails (unlabelled
instances) flooding an inbox during initial data collection. Generally, we
answer the above scenario with uncertainty sampling, an active learning method
that improves the efficiency of supervised learning by using fewer labelled
instances than passive learning. Given an unlabelled data pool, uncertainty
sampling queries the labels of instances where the predicted probabilities, p,
fall into the uncertainty region, i.e., $p \approx 0.5$. The newly acquired
labels are then added to the existing labelled data pool to learn a new model.
Nonetheless, the performance of uncertainty sampling is susceptible to the area
of unpredictable responses (AUR) and the nature of the dataset. It is difficult
to determine whether to use passive learning or uncertainty sampling without
prior knowledge of a new dataset. To address this issue, we propose bell curve
sampling, which employs a bell curve weight function to acquire new labels.
With the bell curve centred at p=0.5, bell curve sampling selects instances
whose predicted values are in the uncertainty area most of the time without
neglecting the rest. Simulation results show that, most of the time bell curve
sampling outperforms uncertainty sampling and passive learning in datasets of
different natures and with AUR.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01354" title="Abstract">arXiv:2403.01354</a> [<a href="/pdf/2403.01354" title="Download PDF">pdf</a>, <a href="/format/2403.01354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Overview of Minimum Convex Cover and Maximum Hidden Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Browne%2C+R">Reilly Browne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">We give a review of results on the minimum convex cover and maximum hidden
set problems. In addition, we give some new results. First we show that it is
NP-hard to determine whether a polygon has the same convex cover number as its
hidden set number. We then give some important examples in which these
quantities don't always coincide. Finally, We present some consequences of
insights from Browne, Kasthurirangan, Mitchell and Polishchuk [FOCS, 2023] on
other classes of simple polygons.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01356" title="Abstract">arXiv:2403.01356</a> [<a href="/pdf/2403.01356" title="Download PDF">pdf</a>, <a href="/format/2403.01356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Privacy Enhancing in Blockchain-based IoT Environments via  Anonym Auditing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khordadpour%2C+P">Peyman Khordadpour</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+S">Saeed Ahmadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The integration of blockchain technology in Internet of Things (IoT)
environments is a revolutionary step towards ensuring robust security and
enhanced privacy. This paper delves into the unique challenges and solutions
associated with securing blockchain-based IoT systems, with a specific focus on
anonymous auditing to reinforce privacy and security. We propose a novel
framework that combines the decentralized nature of blockchain with advanced
security protocols tailored for IoT contexts. Central to our approach is the
implementation of anonymization techniques in auditing processes, ensuring user
privacy while maintaining the integrity and transparency of blockchain
transactions. We outline the architecture of blockchain in IoT environments,
emphasizing the workflow and specific security mechanisms employed.
Additionally, we introduce a security protocol that integrates
privacy-enhancing tools and anonymous auditing methods, including the use of
advanced cryptographic techniques for anonymity. This study also includes a
comparative analysis of our proposed framework against existing models in the
domain. Our work aims to provide a comprehensive blueprint for enhancing
security and privacy in blockchain-based IoT environments, paving the way for
more secure and private digital ecosystems.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01359" title="Abstract">arXiv:2403.01359</a> [<a href="/pdf/2403.01359" title="Download PDF">pdf</a>, <a href="/format/2403.01359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModelWriter: Text &amp; Model-Synchronized Document Engineering Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erata%2C+F">Ferhat Erata</a>, 
<a href="/search/cs?searchtype=author&query=Gardent%2C+C">Claire Gardent</a>, 
<a href="/search/cs?searchtype=author&query=Gyawali%2C+B">Bikash Gyawali</a>, 
<a href="/search/cs?searchtype=author&query=Shimorina%2C+A">Anastasia Shimorina</a>, 
<a href="/search/cs?searchtype=author&query=Lussaud%2C+Y">Yvan Lussaud</a>, 
<a href="/search/cs?searchtype=author&query=Tekinerdogan%2C+B">Bedir Tekinerdogan</a>, 
<a href="/search/cs?searchtype=author&query=Kardas%2C+G">Geylani Kardas</a>, 
<a href="/search/cs?searchtype=author&query=Monceaux%2C+A">Anne Monceaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The ModelWriter platform provides a generic framework for automated
traceability analysis. In this paper, we demonstrate how this framework can be
used to trace the consistency and completeness of technical documents that
consist of a set of System Installation Design Principles used by Airbus to
ensure the correctness of aircraft system installation. We show in particular,
how the platform allows the integration of two types of reasoning: reasoning
about the meaning of text using semantic parsing and description logic theorem
proving; and reasoning about document structure using first-order relational
logic and finite model finding for traceability analysis.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01361" title="Abstract">arXiv:2403.01361</a> [<a href="/pdf/2403.01361" title="Download PDF">pdf</a>, <a href="/format/2403.01361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Profit-maximization for Targeted Marketing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huh%2C+J+S">Joon Suk Huh</a>, 
<a href="/search/cs?searchtype=author&query=Vitercik%2C+E">Ellen Vitercik</a>, 
<a href="/search/cs?searchtype=author&query=Kandasamy%2C+K">Kirthevasan Kandasamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); General Economics (econ.GN); General Finance (q-fin.GN)

</div>
<p class="mathjax">We study a sequential profit-maximization problem, optimizing for both price
and ancillary variables like marketing expenditures. Specifically, we aim to
maximize profit over an arbitrary sequence of multiple demand curves, each
dependent on a distinct ancillary variable, but sharing the same price. A
prototypical example is targeted marketing, where a firm (seller) wishes to
sell a product over multiple markets. The firm may invest different marketing
expenditures for different markets to optimize customer acquisition, but must
maintain the same price across all markets. Moreover, markets may have
heterogeneous demand curves, each responding to prices and marketing
expenditures differently. The firm's objective is to maximize its gross profit,
the total revenue minus marketing costs.
<br />Our results are near-optimal algorithms for this class of problems in an
adversarial bandit setting, where demand curves are arbitrary non-adaptive
sequences, and the firm observes only noisy evaluations of chosen points on the
demand curves. We prove a regret upper bound of
$\widetilde{\mathcal{O}}\big(nT^{3/4}\big)$ and a lower bound of
$\Omega\big((nT)^{3/4}\big)$ for monotonic demand curves, and a regret bound of
$\widetilde{\Theta}\big(nT^{2/3}\big)$ for demands curves that are monotonic in
price and concave in the ancillary variables.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01364" title="Abstract">arXiv:2403.01364</a> [<a href="/pdf/2403.01364" title="Download PDF">pdf</a>, <a href="/format/2403.01364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Cross-lingual Representation for Semantic Retrieval with  Code-switching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maimaiti%2C+M">Mieradilijiang Maimaiti</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuanhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenpei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiyu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Semantic Retrieval (SR) has become an indispensable part of the FAQ system in
the task-oriented question-answering (QA) dialogue scenario. The demands for a
cross-lingual smart-customer-service system for an e-commerce platform or some
particular business conditions have been increasing recently. Most previous
studies exploit cross-lingual pre-trained models (PTMs) for multi-lingual
knowledge retrieval directly, while some others also leverage the continual
pre-training before fine-tuning PTMs on the downstream tasks. However, no
matter which schema is used, the previous work ignores to inform PTMs of some
features of the downstream task, i.e. train their PTMs without providing any
signals related to SR. To this end, in this work, we propose an Alternative
Cross-lingual PTM for SR via code-switching. We are the first to utilize the
code-switching approach for cross-lingual SR. Besides, we introduce the novel
code-switched continual pre-training instead of directly using the PTMs on the
SR tasks. The experimental results show that our proposed approach consistently
outperforms the previous SOTA methods on SR and semantic textual similarity
(STS) tasks with three business corpora and four open datasets in 20+
languages.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01365" title="Abstract">arXiv:2403.01365</a> [<a href="/pdf/2403.01365" title="Download PDF">pdf</a>, <a href="/format/2403.01365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Powered Reminders for Collaborative Tasks: Experiences and Futures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morrison%2C+K">Katelyn Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S">Shamsi Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+E">Eric Horvitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures, 3 tables, accepted to ACM CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Email continues to serve as a central medium for managing collaborations.
While unstructured email messaging is lightweight and conducive to
coordination, it is easy to overlook commitments and requests for
collaborations that are embedded in the text of free-flowing communications.
Twenty-one years ago, Bellotti et al. proposed TaskMaster with the goal of
redesigning the email interface to have explicit task management capabilities.
Recently, AI-based task recognition and reminder services have been introduced
in major email systems as one approach to managing asynchronous collaborations.
While these services have been provided to millions of people around the world,
there is little understanding of how people interact with and benefit from
them. We explore knowledge workers' experiences with Microsoft's Viva Daily
Briefing Email to better understand how AI-powered reminders can support
asynchronous collaborations. Through semi-structured interviews and surveys, we
shed light on how AI-powered reminders are incorporated into workflows to
support asynchronous collaborations. We identify what knowledge workers prefer
AI-powered reminders to remind them about and how they would like to interact
with these reminders. Using mixed methods and a self-assessment methodology, we
investigate the relationship between information workers' work styles and the
perceived value of the Viva Daily Briefing Email to identify users who are more
likely to benefit from AI-powered reminders for asynchronous collaborations. We
conclude by discussing the experiences and futures of AI-powered reminders for
collaborative tasks and asynchronous collaborations.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01367" title="Abstract">arXiv:2403.01367</a> [<a href="/pdf/2403.01367" title="Download PDF">pdf</a>, <a href="/ps/2403.01367" title="Download PostScript">ps</a>, <a href="/format/2403.01367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization decision model of vegetable stock and pricing based on  TCN-Attention and genetic algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Linhan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bohan Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCSMT2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">With the expansion of operational scale of supermarkets in China, the
vegetable market has grown considerably. The decision-making related to
procurement costs and allocation quantities of vegetables has become a pivotal
factor in determining the profitability of supermarkets. This paper analyzes
the relationship between pricing and allocation faced by supermarkets in
vegetable operations. Optimization algorithms are employed to determine
replenishment and pricing strategies. Linear regression is utilized to model
the historical data of various products, establishing the relationship between
sale prices and sales volumes for 61 products. By integrating historical data
on vegetable costs with time information based on the 24 solar terms, a cost
prediction model is trained using TCN-Attention. The Topis evaluation model
identifies the 32 most market-demanded products. A genetic algorithm is then
used to search for the globally optimized vegetable product allocation-pricing
decision.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01370" title="Abstract">arXiv:2403.01370</a> [<a href="/pdf/2403.01370" title="Download PDF">pdf</a>, <a href="/ps/2403.01370" title="Download PostScript">ps</a>, <a href="/format/2403.01370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth Estimation Algorithm Based on Transformer-Encoder and Feature  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Linhan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junbang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICAACE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research presents a novel depth estimation algorithm based on a
Transformer-encoder architecture, tailored for the NYU and KITTI Depth Dataset.
This research adopts a transformer model, initially renowned for its success in
natural language processing, to capture intricate spatial relationships in
visual data for depth estimation tasks. A significant innovation of the
research is the integration of a composite loss function that combines
Structural Similarity Index Measure (SSIM) with Mean Squared Error (MSE). This
combined loss function is designed to ensure the structural integrity of the
predicted depth maps relative to the original images (via SSIM) while
minimizing pixel-wise estimation errors (via MSE). This research approach
addresses the challenges of over-smoothing often seen in MSE-based losses and
enhances the model's ability to predict depth maps that are not only accurate
but also maintain structural coherence with the input images. Through rigorous
training and evaluation using the NYU Depth Dataset, the model demonstrates
superior performance, marking a significant advancement in single-image depth
estimation, particularly in complex indoor and traffic environments.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01373" title="Abstract">arXiv:2403.01373</a> [<a href="/pdf/2403.01373" title="Download PDF">pdf</a>, <a href="/format/2403.01373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating and Mitigating Number Hallucinations in Large Vision-Language  Models: A Consistency Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large vision language models have demonstrated remarkable efficacy in
addressing challenges related to both textual and visual content. Nevertheless,
these models are susceptible to various hallucinations. In this paper, we focus
on a new form of hallucination, specifically termed as number hallucination,
which denotes instances where models fail to accurately identify the quantity
of objects in an image. We establish a dataset and employ evaluation metrics to
assess number hallucination, revealing a pronounced prevalence of this issue
across mainstream large vision language models (LVLMs). Additionally, we delve
into a thorough analysis of number hallucination, examining inner and outer
inconsistency problem from two related perspectives. We assert that this
inconsistency is one cause of number hallucination and propose a consistency
training method as a means to alleviate such hallucination, which achieves an
average improvement of 8\% compared with direct finetuning method.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01374" title="Abstract">arXiv:2403.01374</a> [<a href="/pdf/2403.01374" title="Download PDF">pdf</a>, <a href="/format/2403.01374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Dynamic Light-Section 3D Reconstruction Method for Wide-Range  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mengjuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Shimasaki%2C+K">Kohei Shimasaki</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shaopeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qingyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ishii%2C+I">Idaku Ishii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,6 figures, Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Existing galvanometer-based laser scanning systems are challenging to apply
in multi-scale 3D reconstruction because of the difficulty in achieving a
balance between high reconstruction accuracy and a wide reconstruction range.
This paper presents a novel method that synchronizes laser scanning by
switching the field-of-view (FOV) of a camera using multi-galvanometers. In
addition to the advanced hardware setup, we establish a comprehensive
mathematical model of the system by modeling dynamic camera, dynamic laser, and
their combined interaction. We then propose a high-precision and flexible
calibration method by constructing an error model and minimizing the objective
function. Finally, we evaluate the performance of the proposed system by
scanning standard components. The evaluation results demonstrate that the
accuracy of the proposed 3D reconstruction system achieves 0.3 mm when the
measurement range is extended to 1100 mm $\times$ 1300 mm $\times$ 650 mm. With
the same reconstruction accuracy, the reconstruction range is expanded by a
factor of 25, indicating that the proposed method simultaneously allows for
high-precision and wide-range 3D reconstruction in industrial applications.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01381" title="Abstract">arXiv:2403.01381</a> [<a href="/pdf/2403.01381" title="Download PDF">pdf</a>, <a href="/format/2403.01381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA-MixNet: Structure-aware Mixup and Invariance Learning for  Scribble-supervised Road Extraction in Remote Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weisheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Mainstreamed weakly supervised road extractors rely on highly confident
pseudo-labels propagated from scribbles, and their performance often degrades
gradually as the image scenes tend various. We argue that such degradation is
due to the poor model's invariance to scenes with different complexities,
whereas existing solutions to this problem are commonly based on crafted priors
that cannot be derived from scribbles. To eliminate the reliance on such
priors, we propose a novel Structure-aware Mixup and Invariance Learning
framework (SA-MixNet) for weakly supervised road extraction that improves the
model invariance in a data-driven manner. Specifically, we design a
structure-aware Mixup scheme to paste road regions from one image onto another
for creating an image scene with increased complexity while preserving the
road's structural integrity. Then an invariance regularization is imposed on
the predictions of constructed and origin images to minimize their conflicts,
which thus forces the model to behave consistently on various scenes. Moreover,
a discriminator-based regularization is designed for enhancing the connectivity
meanwhile preserving the structure of roads. Combining these designs, our
framework demonstrates superior performance on the DeepGlobe, Wuhan, and
Massachusetts datasets outperforming the state-of-the-art techniques by 1.47%,
2.12%, 4.09% respectively in IoU metrics, and showing its potential of
plug-and-play. The code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01382" title="Abstract">arXiv:2403.01382</a> [<a href="/pdf/2403.01382" title="Download PDF">pdf</a>, <a href="/format/2403.01382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Question-Answer Generation for Long-Tail Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rohan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S">Sunitha Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haitian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+C">Christos Faloutsos</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+M">Minji Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at KDD 2023 KnowledgeNLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pretrained Large Language Models (LLMs) have gained significant attention for
addressing open-domain Question Answering (QA). While they exhibit high
accuracy in answering questions related to common knowledge, LLMs encounter
difficulties in learning about uncommon long-tail knowledge (tail entities).
Since manually constructing QA datasets demands substantial human resources,
the types of existing QA datasets are limited, leaving us with a scarcity of
datasets to study the performance of LLMs on tail entities. In this paper, we
propose an automatic approach to generate specialized QA datasets for tail
entities and present the associated research challenges. We conduct extensive
experiments by employing pretrained LLMs on our newly generated long-tail QA
datasets, comparing their performance with and without external resources
including Wikipedia and Wikidata knowledge graphs.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01384" title="Abstract">arXiv:2403.01384</a> [<a href="/pdf/2403.01384" title="Download PDF">pdf</a>, <a href="/ps/2403.01384" title="Download PostScript">ps</a>, <a href="/format/2403.01384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Compressibility of Quantized Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weilan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongchao Du</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+N">Nan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C+J">Chun Jason Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Deploying Large Language Models (LLMs) on edge or mobile devices offers
significant benefits, such as enhanced data privacy and real-time processing
capabilities. However, it also faces critical challenges due to the substantial
memory requirement of LLMs. Quantization is an effective way of reducing the
model size while maintaining good performance. However, even after
quantization, LLMs may still be too big to fit entirely into the limited memory
of edge or mobile devices and have to be partially loaded from the storage to
complete the inference. In this case, the I/O latency of model loading becomes
the bottleneck of the LLM inference latency. In this work, we take a
preliminary step of studying applying data compression techniques to reduce
data movement and thus speed up the inference of quantized LLM on
memory-constrained devices. In particular, we discussed the compressibility of
quantized LLMs, the trade-off between the compressibility and performance of
quantized LLMs, and opportunities to optimize both of them jointly.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01387" title="Abstract">arXiv:2403.01387</a> [<a href="/pdf/2403.01387" title="Download PDF">pdf</a>, <a href="/format/2403.01387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Federated Transfer Learning: Challenges,  Methods and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+F">Fuzhen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yiqi Tong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jin Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) is a novel distributed machine learning paradigm that
enables participants to collaboratively train a centralized model with privacy
preservation by eliminating the requirement of data sharing. In practice, FL
often involves multiple participants and requires the third party to aggregate
global information to guide the update of the target participant. Therefore,
many FL methods do not work well due to the training and test data of each
participant may not be sampled from the same feature space and the same
underlying distribution. Meanwhile, the differences in their local devices
(system heterogeneity), the continuous influx of online data (incremental
data), and labeled data scarcity may further influence the performance of these
methods. To solve this problem, federated transfer learning (FTL), which
integrates transfer learning (TL) into FL, has attracted the attention of
numerous researchers. However, since FL enables a continuous share of knowledge
among participants with each communication round while not allowing local data
to be accessed by other participants, FTL faces many unique challenges that are
not present in TL. In this survey, we focus on categorizing and reviewing the
current progress on federated transfer learning, and outlining corresponding
solutions and applications. Furthermore, the common setting of FTL scenarios,
available datasets, and significant related research are summarized in this
survey.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01389" title="Abstract">arXiv:2403.01389</a> [<a href="/pdf/2403.01389" title="Download PDF">pdf</a>, <a href="/format/2403.01389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusion of Gaussian Processes Predictions with Monte Carlo Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajirak%2C+M">Marzieh Ajirak</a>, 
<a href="/search/cs?searchtype=author&query=Waxman%2C+D">Daniel Waxman</a>, 
<a href="/search/cs?searchtype=author&query=Llorente%2C+F">Fernando Llorente</a>, 
<a href="/search/cs?searchtype=author&query=Djuric%2C+P+M">Petar M. Djuric</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In science and engineering, we often work with models designed for accurate
prediction of variables of interest. Recognizing that these models are
approximations of reality, it becomes desirable to apply multiple models to the
same data and integrate their outcomes. In this paper, we operate within the
Bayesian paradigm, relying on Gaussian processes as our models. These models
generate predictive probability density functions (pdfs), and the objective is
to integrate them systematically, employing both linear and log-linear pooling.
We introduce novel approaches for log-linear pooling, determining
input-dependent weights for the predictive pdfs of the Gaussian processes. The
aggregation of the pdfs is realized through Monte Carlo sampling, drawing
samples of weights from their posterior. The performance of these methods, as
well as those based on linear pooling, is demonstrated using a synthetic
dataset.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01390" title="Abstract">arXiv:2403.01390</a> [<a href="/pdf/2403.01390" title="Download PDF">pdf</a>, <a href="/format/2403.01390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Right for Right Reasons: Large Language Models for Verifiable  Commonsense Knowledge Graph Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toroghi%2C+A">Armin Toroghi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Willis Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pour%2C+M+M+A">Mohammad Mahdi Abdollah Pour</a>, 
<a href="/search/cs?searchtype=author&query=Sanner%2C+S">Scott Sanner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge Graph Question Answering (KGQA) methods seek to answer Natural
Language questions using the relational information stored in Knowledge Graphs
(KGs). With the recent advancements of Large Language Models (LLMs) and their
remarkable reasoning abilities, there is a growing trend to leverage them for
KGQA. However, existing methodologies have only focused on answering factual
questions, e.g., "In which city was Silvio Berlusconi's first wife born?",
leaving questions involving commonsense reasoning that real-world users may
pose more often, e.g., "Do I need separate visas to see the Venus of Willendorf
and attend the Olympics this summer?" unaddressed. In this work, we first
observe that existing LLM-based methods for KGQA struggle with hallucination on
such questions, especially on queries targeting long-tail entities (e.g.,
non-mainstream and recent entities), thus hindering their applicability in
real-world applications especially since their reasoning processes are not
easily verifiable. In response, we propose Right for Right Reasons (R3), a
commonsense KGQA methodology that allows for a verifiable reasoning procedure
by axiomatically surfacing intrinsic commonsense knowledge of LLMs and
grounding every factual reasoning step on KG triples. Through experimental
evaluations across three different tasks--question answering, claim
verification, and preference matching--our findings showcase R3 as a superior
approach, outperforming existing methodologies and notably reducing instances
of hallucination and reasoning errors.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01394" title="Abstract">arXiv:2403.01394</a> [<a href="/pdf/2403.01394" title="Download PDF">pdf</a>, <a href="/ps/2403.01394" title="Download PostScript">ps</a>, <a href="/format/2403.01394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successful Transmission Probability and SIR Meta Distribution Analysis  for Multi-Antenna Cache-Enabled Networks with Interference Nulling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tianming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaodong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peilin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuai Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper investigates a multi-antenna cache-enabled network with
interference nulling (IN) employed at base stations. Two IN schemes, namely,
the fixed IN scheme and the flexible IN scheme are considered to improve the
received signal-to-interference ratio (SIR) at users. To thoroughly explore the
effects of the caching parameter and the IN parameters on the network
performance, we focus on the analysis of not only the successful transmission
probability (STP) but the SIR meta distribution. For each IN scheme, the
expression for the STP is derived and an approximated expression for the SIR
meta distribution is also obtained by deriving the first and second moments of
an upper bound of the link reliability and utilizing the beta distribution.
With this analytical framework, we compare the performance of these two IN
schemes and gain some useful system design guidelines from the perspectives of
the STP and the SIR meta distribution by numerical simulations.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01395" title="Abstract">arXiv:2403.01395</a> [<a href="/pdf/2403.01395" title="Download PDF">pdf</a>, <a href="/format/2403.01395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring  Commonsense Reasoning and Long-Tail Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Willis Guo</a>, 
<a href="/search/cs?searchtype=author&query=Toroghi%2C+A">Armin Toroghi</a>, 
<a href="/search/cs?searchtype=author&query=Sanner%2C+S">Scott Sanner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge graph question answering (KGQA) is a well-established field that
seeks to provide factual answers to natural language (NL) questions by
leveraging knowledge graphs (KGs). However, existing KGQA datasets suffer from
two significant limitations: (1) no existing KGQA dataset requires commonsense
reasoning to arrive at an answer and (2) existing KGQA datasets focus on
popular entities for which large language models (LLMs) can directly answer
without hallucinating and without leveraging the KG. In this work, we seek a
novel KGQA dataset that supports commonsense reasoning and focuses on long-tail
entities (e.g., non-mainstream and recent entities) where LLMs frequently
hallucinate, and thus create the need for novel methodologies that leverage the
KG for factual and attributable commonsense inference. We create a novel
Commonsense Reasoning (CR) and Long-Tail (LT) KGQA dataset with two subtasks --
question answering and claim verification -- that address both limitations (1)
and (2). We construct CR-LT-KGQA by building extensions to existing reasoning
datasets StrategyQA and CREAK over Wikidata. While existing KGQA methods are
not applicable due to their lack of commonsense inference support, baseline
evaluation of LLMs on CR-LT KGQA demonstrate a high rate of hallucination.
Thus, CR-LT KGQA poses significant challenges for hallucination-prone LLMs,
hence paving the way for future commonsense KGQA research to provide accurate
and factual answers for long-tail entities in the era of LLMs.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01400" title="Abstract">arXiv:2403.01400</a> [<a href="/pdf/2403.01400" title="Download PDF">pdf</a>, <a href="/format/2403.01400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Weighing and Selecting for Integrating Multiple Graph  Pre-training Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tianyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yufei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haitao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent years have witnessed the great success of graph pre-training for graph
representation learning. With hundreds of graph pre-training tasks proposed,
integrating knowledge acquired from multiple pre-training tasks has become a
popular research topic. In this paper, we identify two important collaborative
processes for this topic: (1) select: how to select an optimal task combination
from a given task pool based on their compatibility, and (2) weigh: how to
weigh the selected tasks based on their importance. While there currently has
been a lot of work focused on weighing, comparatively little effort has been
devoted to selecting. This paper proposes a novel instance-level framework for
integrating multiple graph pre-training tasks, Weigh And Select (WAS), where
the two collaborative processes, weighing and selecting, are combined by
decoupled siamese networks. Specifically, it first adaptively learns an optimal
combination of tasks for each instance from a given task pool, based on which a
customized instance-level task weighing strategy is learned. Extensive
experiments on 16 graph datasets across node-level and graph-level downstream
tasks have demonstrated that by combining a few simple but classical tasks, WAS
can achieve comparable performance to other leading counterparts. The code is
available at https://github.com/TianyuFan0504/WAS.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01404" title="Abstract">arXiv:2403.01404</a> [<a href="/pdf/2403.01404" title="Download PDF">pdf</a>, <a href="/format/2403.01404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Is Missing in Multilingual Visual Reasoning and How to Fix It
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yueqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Khanuja%2C+S">Simran Khanuja</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">NLP models today strive for supporting multiple languages and modalities,
improving accessibility for diverse users. In this paper, we evaluate their
multilingual, multimodal capabilities by testing on a visual reasoning task. We
observe that proprietary systems like GPT-4V obtain the best performance on
this task now, but open models lag in comparison. Surprisingly, GPT-4V exhibits
similar performance between English and other languages, indicating the
potential for equitable system development across languages. Our analysis on
model failures reveals three key aspects that make this task challenging:
multilinguality, complex reasoning, and multimodality. To address these
challenges, we propose three targeted interventions including a translate-test
approach to tackle multilinguality, a visual programming approach to break down
complex reasoning, and a novel method that leverages image captioning to
address multimodality. Our interventions achieve the best open performance on
this task in a zero-shot setting, boosting open model LLaVA by 13.4%, while
also minorly improving GPT-4V's performance.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01407" title="Abstract">arXiv:2403.01407</a> [<a href="/pdf/2403.01407" title="Download PDF">pdf</a>, <a href="/format/2403.01407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Region-Transformer: Self-Attention Region Based Class-Agnostic Point  Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gyawali%2C+D">Dipesh Gyawali</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Karki%2C+B">BB Karki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 3 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 19th International Joint Conference on Computer Vision, Imaging
  and Computer Graphics Theory and Applications, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Point cloud segmentation, which helps us understand the environment of
specific structures and objects, can be performed in class-specific and
class-agnostic ways. We propose a novel region-based transformer model called
Region-Transformer for performing class-agnostic point cloud segmentation. The
model utilizes a region-growth approach and self-attention mechanism to
iteratively expand or contract a region by adding or removing points. It is
trained on simulated point clouds with instance labels only, avoiding semantic
labels. Attention-based networks have succeeded in many previous methods of
performing point cloud segmentation. However, a region-growth approach with
attention-based networks has yet to be used to explore its performance gain. To
our knowledge, we are the first to use a self-attention mechanism in a
region-growth approach. With the introduction of self-attention to
region-growth that can utilize local contextual information of neighborhood
points, our experiments demonstrate that the Region-Transformer model
outperforms previous class-agnostic and class-specific methods on indoor
datasets regarding clustering metrics. The model generalizes well to
large-scale scenes. Key advantages include capturing long-range dependencies
through self-attention, avoiding the need for semantic labels during training,
and applicability to a variable number of objects. The Region-Transformer model
represents a promising approach for flexible point cloud segmentation with
applications in robotics, digital twinning, and autonomous vehicles.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01410" title="Abstract">arXiv:2403.01410</a> [<a href="/pdf/2403.01410" title="Download PDF">pdf</a>, <a href="/format/2403.01410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barrier Functions Inspired Reward Shaping for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nilaksh">Nilaksh</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+A">Abhishek Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Shreenabh Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aayush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jagtap%2C+P">Pushpak Jagtap</a>, 
<a href="/search/cs?searchtype=author&query=Kolathaya%2C+S">Shishir Kolathaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 10 figures, Accepted as contributed paper at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Reinforcement Learning (RL) has progressed from simple control tasks to
complex real-world challenges with large state spaces. While RL excels in these
tasks, training time remains a limitation. Reward shaping is a popular
solution, but existing methods often rely on value functions, which face
scalability issues. This paper presents a novel safety-oriented reward-shaping
framework inspired by barrier functions, offering simplicity and ease of
implementation across various environments and tasks. To evaluate the
effectiveness of the proposed reward formulations, we conduct simulation
experiments on CartPole, Ant, and Humanoid environments, along with real-world
deployment on the Unitree Go1 quadruped robot. Our results demonstrate that our
method leads to 1.4-2.8 times faster convergence and as low as 50-60% actuation
effort compared to the vanilla reward. In a sim-to-real experiment with the Go1
robot, we demonstrated better control and dynamics of the bot with our reward
framework.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01411" title="Abstract">arXiv:2403.01411</a> [<a href="/pdf/2403.01411" title="Download PDF">pdf</a>, <a href="/format/2403.01411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OVEL: Large Language Model as Memory Manager for Online Video Entity  Linking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiquan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shisong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, multi-modal entity linking (MEL) has garnered increasing
attention in the research community due to its significance in numerous
multi-modal applications. Video, as a popular means of information
transmission, has become prevalent in people's daily lives. However, most
existing MEL methods primarily focus on linking textual and visual mentions or
offline videos's mentions to entities in multi-modal knowledge bases, with
limited efforts devoted to linking mentions within online video content. In
this paper, we propose a task called Online Video Entity Linking OVEL, aiming
to establish connections between mentions in online videos and a knowledge base
with high accuracy and timeliness. To facilitate the research works of OVEL, we
specifically concentrate on live delivery scenarios and construct a live
delivery entity linking dataset called LIVE. Besides, we propose an evaluation
metric that considers timelessness, robustness, and accuracy. Furthermore, to
effectively handle OVEL task, we leverage a memory block managed by a Large
Language Model and retrieve entity candidates from the knowledge base to
augment LLM performance on memory management. The experimental results prove
the effectiveness and efficiency of our method.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01412" title="Abstract">arXiv:2403.01412</a> [<a href="/pdf/2403.01412" title="Download PDF">pdf</a>, <a href="/format/2403.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth  Limited Optical Signal Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hangjie Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Bandwidth constraints during signal acquisition frequently impede real-time
detection applications. Hyperspectral data is a notable example, whose vast
volume compromises real-time hyperspectral detection. To tackle this hurdle, we
introduce a novel approach leveraging pre-acquisition modulation to reduce the
acquisition volume. This modulation process is governed by a deep learning
model, utilizing prior information. Central to our approach is LUM-ViT, a
Vision Transformer variant. Uniquely, LUM-ViT incorporates a learnable
under-sampling mask tailored for pre-acquisition modulation. To further
optimize for optical calculations, we propose a kernel-level weight
binarization technique and a three-stage fine-tuning strategy. Our evaluations
reveal that, by sampling a mere 10% of the original image pixels, LUM-ViT
maintains the accuracy loss within 1.8% on the ImageNet classification task.
The method sustains near-original accuracy when implemented on real-world
optical hardware, demonstrating its practicality. Code will be available at
https://github.com/MaxLLF/LUM-ViT.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01413" title="Abstract">arXiv:2403.01413</a> [<a href="/pdf/2403.01413" title="Download PDF">pdf</a>, <a href="/format/2403.01413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Design of Generative AI in Supporting Music-based  Reminiscence for Older Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yucheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wanling Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Doherty%2C+G">Gavin Doherty</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tonglin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Music-based reminiscence has the potential to positively impact the
psychological well-being of older adults. However, the aging process and
physiological changes, such as memory decline and limited verbal communication,
may impede the ability of older adults to recall their memories and life
experiences. Given the advanced capabilities of generative artificial
intelligence (AI) systems, such as generated conversations and images, and
their potential to facilitate the reminiscing process, this study aims to
explore the design of generative AI to support music-based reminiscence in
older adults. This study follows a user-centered design approach incorporating
various stages, including detailed interviews with two social workers and two
design workshops (involving ten older adults). Our work contributes to an
in-depth understanding of older adults' attitudes toward utilizing generative
AI for supporting music-based reminiscence and identifies concrete design
considerations for the future design of generative AI to enhance the
reminiscence experience of older adults.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01414" title="Abstract">arXiv:2403.01414</a> [<a href="/pdf/2403.01414" title="Download PDF">pdf</a>, <a href="/format/2403.01414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsigned Orthogonal Distance Fields: An Accurate Neural Implicit  Representation for Diverse 3D Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Long Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Nayu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yulong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shuhan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lin Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural implicit representation of geometric shapes has witnessed considerable
advancements in recent years. However, common distance field based implicit
representations, specifically signed distance field (SDF) for watertight shapes
or unsigned distance field (UDF) for arbitrary shapes, routinely suffer from
degradation of reconstruction accuracy when converting to explicit surface
points and meshes. In this paper, we introduce a novel neural implicit
representation based on unsigned orthogonal distance fields (UODFs). In UODFs,
the minimal unsigned distance from any spatial point to the shape surface is
defined solely in one orthogonal direction, contrasting with the
multi-directional determination made by SDF and UDF. Consequently, every point
in the 3D UODFs can directly access its closest surface points along three
orthogonal directions. This distinctive feature leverages the accurate
reconstruction of surface points without interpolation errors. We verify the
effectiveness of UODFs through a range of reconstruction examples, extending
from simple watertight or non-watertight shapes to complex shapes that include
hollows, internal or assembling structures.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01417" title="Abstract">arXiv:2403.01417</a> [<a href="/pdf/2403.01417" title="Download PDF">pdf</a>, <a href="/format/2403.01417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asyn2F: An Asynchronous Federated Learning Framework with Bidirectional  Model Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tien-Dung Cao</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+N+T">Nguyen T. Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+Q">Thai Q. Le</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+H+V+N">Hoang V.N. Dao</a>, 
<a href="/search/cs?searchtype=author&query=Truong-Huu%2C+T">Tram Truong-Huu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In federated learning, the models can be trained synchronously or
asynchronously. Many research works have focused on developing an aggregation
method for the server to aggregate multiple local models into the global model
with improved performance. They ignore the heterogeneity of the training
workers, which causes the delay in the training of the local models, leading to
the obsolete information issue. In this paper, we design and develop Asyn2F, an
Asynchronous Federated learning Framework with bidirectional model aggregation.
By bidirectional model aggregation, Asyn2F, on one hand, allows the server to
asynchronously aggregate multiple local models and results in a new global
model. On the other hand, it allows the training workers to aggregate the new
version of the global model into the local model, which is being trained even
in the middle of a training epoch. We develop Asyn2F considering the practical
implementation requirements such as using cloud services for model storage and
message queuing protocols for communications. Extensive experiments with
different datasets show that the models trained by Asyn2F achieve higher
performance compared to the state-of-the-art techniques. The experiments also
demonstrate the effectiveness, practicality, and scalability of Asyn2F, making
it ready for deployment in real scenarios.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01418" title="Abstract">arXiv:2403.01418</a> [<a href="/pdf/2403.01418" title="Download PDF">pdf</a>, <a href="/format/2403.01418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple-but-effective Baseline for Training-free Class-Agnostic  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuhao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J+Q">Javen Qinfeng Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class-Agnostic Counting (CAC) seeks to accurately count objects in a given
image with only a few reference examples. While previous methods achieving this
relied on additional training, recent efforts have shown that it's possible to
accomplish this without training by utilizing pre-existing foundation models,
particularly the Segment Anything Model (SAM), for counting via instance-level
segmentation. Although promising, current training-free methods still lag
behind their training-based counterparts in terms of performance. In this
research, we present a straightforward training-free solution that effectively
bridges this performance gap, serving as a strong baseline. The primary
contribution of our work lies in the discovery of four key technologies that
can enhance performance. Specifically, we suggest employing a superpixel
algorithm to generate more precise initial point prompts, utilizing an image
encoder with richer semantic knowledge to replace the SAM encoder for
representing candidate objects, and adopting a multiscale mechanism and a
transductive prototype scheme to update the representation of reference
examples. By combining these four technologies, our approach achieves
significant improvements over existing training-free methods and delivers
performance on par with training-based ones.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01420" title="Abstract">arXiv:2403.01420</a> [<a href="/pdf/2403.01420" title="Download PDF">pdf</a>, <a href="/format/2403.01420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Implicit Bias of Heterogeneity towards Invariance and Causality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yihong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cong Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">It is observed empirically that the large language models (LLM), trained with
a variant of regression loss using numerous corpus from the Internet, can
unveil causal associations to some extent. This is contrary to the traditional
wisdom that ``association is not causation'' and the paradigm of traditional
causal inference in which prior causal knowledge should be carefully
incorporated into the design of methods. It is a mystery why causality, in a
higher layer of understanding, can emerge from the regression task that pursues
associations. In this paper, we claim the emergence of causality from
association-oriented training can be attributed to the coupling effects from
the heterogeneity of the source data, stochasticity of training algorithms, and
over-parameterization of the learning models. We illustrate such an intuition
using a simple but insightful model that learns invariance, a quasi-causality,
using regression loss. To be specific, we consider multi-environment low-rank
matrix sensing problems where the unknown r-rank ground-truth d*d matrices
diverge across the environments but contain a lower-rank invariant, causal
part. In this case, running pooled gradient descent will result in biased
solutions that only learn associations in general. We show that running
large-batch Stochastic Gradient Descent, whose each batch being linear
measurement samples randomly selected from a certain environment, can
successfully drive the solution towards the invariant, causal solution under
certain conditions. This step is related to the relatively strong heterogeneity
of the environments, the large step size and noises in the optimization
algorithm, and the over-parameterization of the model. In summary, we unveil
another implicit bias that is a result of the symbiosis between the
heterogeneity of data and modern algorithms, which is, to the best of our
knowledge, first in the literature.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01422" title="Abstract">arXiv:2403.01422</a> [<a href="/pdf/2403.01422" title="Download PDF">pdf</a>, <a href="/format/2403.01422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MovieLLM: Enhancing Long Video Understanding with AI-Generated Movies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhende Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Jiamu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of multimodal models has marked a significant step forward in
how machines understand videos. These models have shown promise in analyzing
short video clips. However, when it comes to longer formats like movies, they
often fall short. The main hurdles are the lack of high-quality, diverse video
data and the intensive work required to collect or annotate such data. In the
face of these challenges, we propose MovieLLM, a novel framework designed to
create synthetic, high-quality data for long videos. This framework leverages
the power of GPT-4 and text-to-image models to generate detailed scripts and
corresponding visuals. Our approach stands out for its flexibility and
scalability, making it a superior alternative to traditional data collection
methods. Our extensive experiments validate that the data produced by MovieLLM
significantly improves the performance of multimodal models in understanding
complex video narratives, overcoming the limitations of existing datasets
regarding scarcity and bias.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01423" title="Abstract">arXiv:2403.01423</a> [<a href="/pdf/2403.01423" title="Download PDF">pdf</a>, <a href="/format/2403.01423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Certified Robustness against Graph Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuni Lai</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bailin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaihuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate certified robustness for GNNs under graph injection attacks.
Existing research only provides sample-wise certificates by verifying each node
independently, leading to very limited certifying performance. In this paper,
we present the first collective certificate, which certifies a set of target
nodes simultaneously. To achieve it, we formulate the problem as a binary
integer quadratic constrained linear programming (BQCLP). We further develop a
customized linearization technique that allows us to relax the BQCLP into
linear programming (LP) that can be efficiently solved. Through comprehensive
experiments, we demonstrate that our collective certification scheme
significantly improves certification performance with minimal computational
overhead. For instance, by solving the LP within 1 minute on the Citeseer
dataset, we achieve a significant increase in the certified ratio from 0.0% to
81.2% when the injected node number is 5% of the graph size. Our step marks a
crucial step towards making provable defense more practical.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01425" title="Abstract">arXiv:2403.01425</a> [<a href="/pdf/2403.01425" title="Download PDF">pdf</a>, <a href="/format/2403.01425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRPWarner: Warning the Risk of Contract-related Rug Pull in DeFi Smart  Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zewei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiachi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongjuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In recent years, Decentralized Finance (DeFi) grows rapidly due to the
development of blockchain technology and smart contracts. As of March 2023, the
estimated global cryptocurrency market cap has reached approximately $949
billion. However, security incidents continue to plague the DeFi ecosystem, and
one of the most notorious examples is the ``Rug Pull" scam. This type of
cryptocurrency scam occurs when the developer of a particular token project
intentionally abandons the project and disappears with investors' funds.
Despite it only emerging in recent years, Rug Pull events have already caused
significant financial losses. In this work, we manually collected and analyzed
103 real-world rug pull events, categorizing them based on their scam methods.
Two primary categories were identified: Contract-related Rug Pull (through
malicious functions in smart contracts) and Transaction-related Rug Pull
(through cryptocurrency trading without utilizing malicious functions). Based
on the analysis of rug pull events, we propose CRPWarner (short for
Contract-related Rug Pull Risk Warner) to identify malicious functions in smart
contracts and issue warnings regarding potential rug pulls. We evaluated
CRPWarner on 69 open-source smart contracts related to rug pull events and
achieved a 91.8% precision, 85.9% recall and 88.7% F1-score. Additionally, when
evaluating CRPWarner on 13,484 real token contracts on Ethereum, it
successfully detected 4168 smart contracts with malicious functions, including
zero-day examples. The precision of large-scale experiment reach 84.9%.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01426" title="Abstract">arXiv:2403.01426</a> [<a href="/pdf/2403.01426" title="Download PDF">pdf</a>, <a href="/format/2403.01426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introduction to Algogens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shachar%2C+A">Amir Shachar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This book introduces the concept of Algogens, a promising integration of
generative AI with traditional algorithms aimed at improving problem-solving
techniques across various fields. It provides an accessible overview of how
Algogens combine AI's innovative potential with algorithms' reliability to
tackle complex challenges more effectively than either could alone.
<br />The text explores the basics of Algogens, their development, applications,
and advantages, such as better adaptability and efficiency. Through examples
and case studies, readers will learn about Algogens' practical uses today and
their potential for future cybersecurity, healthcare, and environmental science
innovation.
<br />Acknowledging new technologies' challenges and ethical considerations, the
book offers a balanced look at the prospects and obstacles facing Algogens. It
invites a broad audience, including experts and newcomers, to engage with the
topic and consider Algogens' role in advancing our problem-solving
capabilities.
<br />This work is presented as a starting point for anyone interested in the
intersection of AI and algorithms, encouraging further exploration and
discussion on this emerging field. It aims to spark curiosity and contribute to
the ongoing conversation about how technology can evolve to meet the complex
demands of the AI era.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01427" title="Abstract">arXiv:2403.01427</a> [<a href="/pdf/2403.01427" title="Download PDF">pdf</a>, <a href="/format/2403.01427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logit Standardization in Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shangquan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wenqi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, accepted by The The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge distillation involves transferring soft labels from a teacher to a
student using a shared temperature-based softmax function. However, the
assumption of a shared temperature between teacher and student implies a
mandatory exact match between their logits in terms of logit range and
variance. This side-effect limits the performance of student, considering the
capacity discrepancy between them and the finding that the innate logit
relations of teacher are sufficient for student to learn. To address this
issue, we propose setting the temperature as the weighted standard deviation of
logit and performing a plug-and-play Z-score pre-process of logit
standardization before applying softmax and Kullback-Leibler divergence. Our
pre-process enables student to focus on essential logit relations from teacher
rather than requiring a magnitude match, and can improve the performance of
existing logit-based distillation methods. We also show a typical case where
the conventional setting of sharing temperature between teacher and student
cannot reliably yield the authentic distillation evaluation; nonetheless, this
challenge is successfully alleviated by our Z-score. We extensively evaluate
our method for various student and teacher models on CIFAR-100 and ImageNet,
showing its significant superiority. The vanilla knowledge distillation powered
by our pre-process can achieve favorable performance against state-of-the-art
methods, and other distillation variants can obtain considerable gain with the
assistance of our pre-process.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01428" title="Abstract">arXiv:2403.01428</a> [<a href="/pdf/2403.01428" title="Download PDF">pdf</a>, <a href="/format/2403.01428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization matters too: How localization error affects UAV flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Suquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanfan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shu&#x27;ang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qingmin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jincheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The maximum safe flight speed of a Unmanned Aerial Vehicle (UAV) is an
important indicator for measuring its efficiency in completing various tasks.
This indicator is influenced by numerous parameters such as UAV localization
error, perception range, and system latency. However, in terms of localization
errors, although there have been many studies dedicated to improving the
localization capability of UAVs, there is a lack of quantitative research on
their impact on speed. In this work, we model the relationship between various
parameters of the UAV and its maximum flight speed. We consider a scenario
similar to navigating through dense forests, where the UAV needs to quickly
avoid obstacles directly ahead and swiftly reorient after avoidance. Based on
this scenario, we studied how parameters such as localization error affect the
maximum safe speed during UAV flight, as well as the coupling relationships
between these parameters. Furthermore, we validated our model in a simulation
environment, and the results showed that the predicted maximum safe speed had
an error of less than 20% compared to the test speed. In high-density
situations, localization error has a significant impact on the UAV's maximum
safe flight speed. This model can help designers utilize more suitable software
and hardware to construct a UAV system.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01429" title="Abstract">arXiv:2403.01429</a> [<a href="/pdf/2403.01429" title="Download PDF">pdf</a>, <a href="/format/2403.01429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kubernetes in Action: Exploring the Performance of Kubernetes  Distributions in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aqasizade%2C+H">Hossein Aqasizade</a>, 
<a href="/search/cs?searchtype=author&query=Ataie%2C+E">Ehsan Ataie</a>, 
<a href="/search/cs?searchtype=author&query=Bastam%2C+M">Mostafa Bastam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Kubernetes has emerged as a leading open-source platform for container
orchestration, allowing organizations to efficiently manage and deploy
containerized applications at scale. This paper investigates the performance of
four Kubernetes distributions, namely Kubeadm, K3s, MicroK8s, and K0s when
running OpenFaaS as a containerized service on a cluster of computing nodes on
CloudLab. For this purpose, experiments are conducted to examine the
performance of two virtualization modes, namely HVM and PV, supported by Xen as
the underlying hypervisor. Moreover, two container runtimes that are integrated
with Kubernetes, namely Docker, and Containerd, are examined to assess their
performance on both disk-intensive and CPU-intensive workloads. After
determining the appropriate underlying Xen mode and container runtime, the
Kubernetes distributions are set up and their performance is measured using
various metrics, such as request rate, CPU utilization, and scaling behavior.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01430" title="Abstract">arXiv:2403.01430</a> [<a href="/pdf/2403.01430" title="Download PDF">pdf</a>, <a href="/format/2403.01430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Diffusion Process in SE(3)-invariant Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiachen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianshu Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Sampling viable 3D structures (e.g., molecules and point clouds) with
SE(3)-invariance using diffusion-based models proved promising in a variety of
real-world applications, wherein SE(3)-invariant properties can be naturally
characterized by the inter-point distance manifold. However, due to the
non-trivial geometry, we still lack a comprehensive understanding of the
diffusion mechanism within such SE(3)-invariant space. This study addresses
this gap by mathematically delineating the diffusion mechanism under
SE(3)-invariance, via zooming into the interaction behavior between coordinates
and the inter-point distance manifold through the lens of differential
geometry. Upon this analysis, we propose accurate and projection-free diffusion
SDE and ODE accordingly. Such formulations enable enhancing the performance and
the speed of generation pathways; meanwhile offering valuable insights into
other systems incorporating SE(3)-invariance.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01431" title="Abstract">arXiv:2403.01431</a> [<a href="/pdf/2403.01431" title="Download PDF">pdf</a>, <a href="/format/2403.01431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yongchao Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Min Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+S">Shuping Hui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of composed image retrieval (CIR) aims to retrieve images based on
the query image and the text describing the users' intent. Existing methods
have made great progress with the advanced large vision-language (VL) model in
CIR task, however, they generally suffer from two main issues: lack of labeled
triplets for model training and difficulty of deployment on resource-restricted
environments when deploying the large vision-language model. To tackle the
above problems, we propose Image2Sentence based Asymmetric zero-shot composed
image retrieval (ISA), which takes advantage of the VL model and only relies on
unlabeled images for composition learning. In the framework, we propose a new
adaptive token learner that maps an image to a sentence in the word embedding
space of VL model. The sentence adaptively captures discriminative visual
information and is further integrated with the text modifier. An asymmetric
structure is devised for flexible deployment, in which the lightweight model is
adopted for the query side while the large VL model is deployed on the gallery
side. The global contrastive distillation and the local alignment
regularization are adopted for the alignment between the light model and the VL
model for CIR task. Our experiments demonstrate that the proposed ISA could
better cope with the real retrieval scenarios and further improve retrieval
accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01432" title="Abstract">arXiv:2403.01432</a> [<a href="/pdf/2403.01432" title="Download PDF">pdf</a>, <a href="/format/2403.01432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine Tuning vs. Retrieval Augmented Generation for Less Popular  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soudani%2C+H">Heydar Soudani</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+E">Evangelos Kanoulas</a>, 
<a href="/search/cs?searchtype=author&query=Hasibi%2C+F">Faegheh Hasibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) memorize a vast amount of factual knowledge,
exhibiting strong performance across diverse tasks and domains. However, it has
been observed that the performance diminishes when dealing with less-popular or
low-frequency concepts and entities, for example in domain specific
applications. The two prominent approaches to enhance the performance of LLMs
on low-frequent topics are: Retrieval Augmented Generation (RAG) and
fine-tuning (FT) over synthetic data. This paper explores and evaluates the
impact of RAG and FT on customizing LLMs in handling low-frequency entities on
question answering task. Our findings indicate that FT significantly boosts the
performance across entities of varying popularity, especially in the most and
least popular groups, while RAG surpasses other methods. Additionally, the
success of both RAG and FT approaches is amplified by advancements in retrieval
and data augmentation techniques. We release our data and code at
https://github.com/HeydarSoudani/RAGvsFT.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01433" title="Abstract">arXiv:2403.01433</a> [<a href="/pdf/2403.01433" title="Download PDF">pdf</a>, <a href="/format/2403.01433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainMass: Advancing Brain Network Analysis for Diagnosis with  Large-scale Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanwu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chenfei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+G">Guinan Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Z">Zhikai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hairui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+P">Piu Chan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Ting Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Foundation models pretrained on large-scale datasets via self-supervised
learning demonstrate exceptional versatility across various tasks. Due to the
heterogeneity and hard-to-collect medical data, this approach is especially
beneficial for medical image analysis and neuroscience research, as it
streamlines broad downstream tasks without the need for numerous costly
annotations. However, there has been limited investigation into brain network
foundation models, limiting their adaptability and generalizability for broad
neuroscience studies. In this study, we aim to bridge this gap. In particular,
(1) we curated a comprehensive dataset by collating images from 30 datasets,
which comprises 70,781 samples of 46,686 participants. Moreover, we introduce
pseudo-functional connectivity (pFC) to further generates millions of augmented
brain networks by randomly dropping certain timepoints of the BOLD signal. (2)
We propose the BrainMass framework for brain network self-supervised learning
via mask modeling and feature alignment. BrainMass employs Mask-ROI Modeling
(MRM) to bolster intra-network dependencies and regional specificity.
Furthermore, Latent Representation Alignment (LRA) module is utilized to
regularize augmented brain networks of the same participant with similar
topological properties to yield similar latent representations by aligning
their latent embeddings. Extensive experiments on eight internal tasks and
seven external brain disorder diagnosis tasks show BrainMass's superior
performance, highlighting its significant generalizability and adaptability.
Nonetheless, BrainMass demonstrates powerful few/zero-shot learning abilities
and exhibits meaningful interpretation to various diseases, showcasing its
potential use for clinical applications.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01437" title="Abstract">arXiv:2403.01437</a> [<a href="/pdf/2403.01437" title="Download PDF">pdf</a>, <a href="/format/2403.01437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPTSee: Enhancing Moment Retrieval and Highlight Detection via  Description-Based Similarity Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunzhuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zien Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yukun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Sidan Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Moment retrieval (MR) and highlight detection (HD) aim to identify relevant
moments and highlights in video from corresponding natural language query.
Large language models (LLMs) have demonstrated proficiency in various computer
vision tasks. However, existing methods for MR\&amp;HD have not yet been integrated
with LLMs. In this letter, we propose a novel two-stage model that takes the
output of LLMs as the input to the second-stage transformer encoder-decoder.
First, MiniGPT-4 is employed to generate the detailed description of the video
frame and rewrite the query statement, fed into the encoder as new features.
Then, semantic similarity is computed between the generated description and the
rewritten queries. Finally, continuous high-similarity video frames are
converted into span anchors, serving as prior position information for the
decoder. Experiments demonstrate that our approach achieves a state-of-the-art
result, and by using only span anchors and similarity scores as outputs,
positioning accuracy outperforms traditional methods, like Moment-DETR.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01438" title="Abstract">arXiv:2403.01438</a> [<a href="/pdf/2403.01438" title="Download PDF">pdf</a>, <a href="/format/2403.01438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Collaborative Split Learning Framework for Smart Grid  Load Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+A">Asif Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Gope%2C+P">Prosanta Gope</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+B">Biplab Sikdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Accurate load forecasting is crucial for energy management, infrastructure
planning, and demand-supply balancing. Smart meter data availability has led to
the demand for sensor-based load forecasting. Conventional ML allows training a
single global model using data from multiple smart meters requiring data
transfer to a central server, raising concerns for network requirements,
privacy, and security. We propose a split learning-based framework for load
forecasting to alleviate this issue. We split a deep neural network model into
two parts, one for each Grid Station (GS) responsible for an entire
neighbourhood's smart meters and the other for the Service Provider (SP).
Instead of sharing their data, client smart meters use their respective GSs'
model split for forward pass and only share their activations with the GS.
Under this framework, each GS is responsible for training a personalized model
split for their respective neighbourhoods, whereas the SP can train a single
global or personalized model for each GS. Experiments show that the proposed
models match or exceed a centrally trained model's performance and generalize
well. Privacy is analyzed by assessing information leakage between data and
shared activations of the GS model split. Additionally, differential privacy
enhances local data privacy while examining its impact on performance. A
transformer model is used as our base learner.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01439" title="Abstract">arXiv:2403.01439</a> [<a href="/pdf/2403.01439" title="Download PDF">pdf</a>, <a href="/format/2403.01439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Adapter Meets Prompt Tuning: Parameter-Efficient Transfer  Learning for Point Cloud Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dingkang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingkui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yihan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhikang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024. Code is available at <a href="https://github.com/LMD0311/DAPT.">this https URL</a> We will post a camera-ready version later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud analysis has achieved outstanding performance by transferring
point cloud pre-trained models. However, existing methods for model adaptation
usually update all model parameters, i.e., full fine-tuning paradigm, which is
inefficient as it relies on high computational costs (e.g., training GPU
memory) and massive storage space. In this paper, we aim to study
parameter-efficient transfer learning for point cloud analysis with an ideal
trade-off between task performance and parameter efficiency. To achieve this
goal, we freeze the parameters of the default pre-trained models and then
propose the Dynamic Adapter, which generates a dynamic scale for each token,
considering the token significance to the downstream task. We further
seamlessly integrate Dynamic Adapter with Prompt Tuning (DAPT) by constructing
Internal Prompts, capturing the instance-specific features for interaction.
Extensive experiments conducted on five challenging datasets demonstrate that
the proposed DAPT achieves superior performance compared to the full
fine-tuning counterparts while significantly reducing the trainable parameters
and training GPU memory by 95% and 35%, respectively. Code is available at
https://github.com/LMD0311/DAPT.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01440" title="Abstract">arXiv:2403.01440</a> [<a href="/pdf/2403.01440" title="Download PDF">pdf</a>, <a href="/format/2403.01440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pyramid Feature Attention Network for Monocular Depth Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chenglei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Sidan Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep convolutional neural networks (DCNNs) have achieved great success in
monocular depth estimation (MDE). However, few existing works take the
contributions for MDE of different levels feature maps into account, leading to
inaccurate spatial layout, ambiguous boundaries and discontinuous object
surface in the prediction. To better tackle these problems, we propose a
Pyramid Feature Attention Network (PFANet) to improve the high-level context
features and low-level spatial features. In the proposed PFANet, we design a
Dual-scale Channel Attention Module (DCAM) to employ channel attention in
different scales, which aggregate global context and local information from the
high-level feature maps. To exploit the spatial relationship of visual
features, we design a Spatial Pyramid Attention Module (SPAM) which can guide
the network attention to multi-scale detailed information in the low-level
feature maps. Finally, we introduce scale-invariant gradient loss to increase
the penalty on errors in depth-wise discontinuous regions. Experimental results
show that our method outperforms state-of-the-art methods on the KITTI dataset.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01444" title="Abstract">arXiv:2403.01444</a> [<a href="/pdf/2403.01444" title="Download PDF">pdf</a>, <a href="/format/2403.01444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming  of Photo-Realistic Free-Viewpoint Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiakai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+H">Han Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhanjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+W">Wei Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 Accepted. Project Page: <a href="https://sjojok.github.io/3dgstream">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Constructing photo-realistic Free-Viewpoint Videos (FVVs) of dynamic scenes
from multi-view videos remains a challenging endeavor. Despite the remarkable
advancements achieved by current neural rendering techniques, these methods
generally require complete video sequences for offline training and are not
capable of real-time rendering. To address these constraints, we introduce
3DGStream, a method designed for efficient FVV streaming of real-world dynamic
scenes. Our method achieves fast on-the-fly per-frame reconstruction within 12
seconds and real-time rendering at 200 FPS. Specifically, we utilize 3D
Gaussians (3DGs) to represent the scene. Instead of the na\"ive approach of
directly optimizing 3DGs per-frame, we employ a compact Neural Transformation
Cache (NTC) to model the translations and rotations of 3DGs, markedly reducing
the training time and storage required for each FVV frame. Furthermore, we
propose an adaptive 3DG addition strategy to handle emerging objects in dynamic
scenes. Experiments demonstrate that 3DGStream achieves competitive performance
in terms of rendering speed, image quality, training time, and model storage
when compared with state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01446" title="Abstract">arXiv:2403.01446</a> [<a href="/pdf/2403.01446" title="Download PDF">pdf</a>, <a href="/format/2403.01446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GuardT2I: Defending Text-to-Image Models from Adversarial Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jianyuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in Text-to-Image (T2I) models have raised significant
safety concerns about their potential misuse for generating inappropriate or
Not-Safe-For-Work (NSFW) contents, despite existing countermeasures such as
NSFW classifiers or model fine-tuning for inappropriate concept removal.
Addressing this challenge, our study unveils GuardT2I, a novel moderation
framework that adopts a generative approach to enhance T2I models' robustness
against adversarial prompts. Instead of making a binary classification,
GuardT2I utilizes a Large Language Model (LLM) to conditionally transform text
guidance embeddings within the T2I models into natural language for effective
adversarial prompt detection, without compromising the models' inherent
performance. Our extensive experiments reveal that GuardT2I outperforms leading
commercial solutions like OpenAI-Moderation and Microsoft Azure Moderator by a
significant margin across diverse adversarial scenarios.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01449" title="Abstract">arXiv:2403.01449</a> [<a href="/pdf/2403.01449" title="Download PDF">pdf</a>, <a href="/format/2403.01449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUFOMap: Efficient Dynamic Awareness Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duberg%2C+D">Daniel Duberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">MingKai Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jensfelt%2C+P">Patric Jensfelt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors hold equal contribution. 8 pages, 7 figures, project page <a href="https://kin-zhang.github.io/dufomap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The dynamic nature of the real world is one of the main challenges in
robotics. The first step in dealing with it is to detect which parts of the
world are dynamic. A typical benchmark task is to create a map that contains
only the static part of the world to support, for example, localization and
planning. Current solutions are often applied in post-processing, where
parameter tuning allows the user to adjust the setting for a specific dataset.
In this paper, we propose DUFOMap, a novel dynamic awareness mapping framework
designed for efficient online processing. Despite having the same parameter
settings for all scenarios, it performs better or is on par with
state-of-the-art methods. Ray casting is utilized to identify and classify
fully observed empty regions. Since these regions have been observed empty, it
follows that anything inside them at another time must be dynamic. Evaluation
is carried out in various scenarios, including outdoor environments in KITTI
and Argoverse 2, open areas on the KTH campus, and with different sensor types.
DUFOMap outperforms the state of the art in terms of accuracy and computational
efficiency. The source code, benchmarks, and links to the datasets utilized are
provided. See https://kin-zhang.github.io/dufomap for more details.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01450" title="Abstract">arXiv:2403.01450</a> [<a href="/pdf/2403.01450" title="Download PDF">pdf</a>, <a href="/format/2403.01450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision-Free Robot Navigation in Crowded Environments using Learning  based Convex Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhuanglei Wen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mingze Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The advent of deep reinforcement learning (DRL) has significantly expanded
the application range for autonomous robots. However, safe navigation in
crowded and complex environments remains a persistent challenge. This study
proposes a robot navigation strategy that utilizes DRL, conceptualizing the
observation as the convex static obstacle-free region, a departure from
traditional reliance on raw sensor inputs. The novelty of this work is
threefold: (1) Formulating an action space that includes both short-term and
long-term reference points, based on the robot's kinematic limits and the
convex region computed from 2D LiDAR sensor data. (2) Exploring a hybrid
solution that combines DRL with Model Predictive Control (MPC). (3) Designing a
customized state space and reward function based on the static obstacle-free
region, reference points, and the trajectory optimized by MPC. The
effectiveness of these improvements has been confirmed through experimental
results, demonstrating improved navigation performance in crowded and complex
environments.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01451" title="Abstract">arXiv:2403.01451</a> [<a href="/pdf/2403.01451" title="Download PDF">pdf</a>, <a href="/format/2403.01451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Data Provenance and Model Transparency in Federated Learning  Systems - A Database Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+M">Michael Gu</a>, 
<a href="/search/cs?searchtype=author&query=Naraparaju%2C+R">Ramasoumya Naraparaju</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongfang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) presents a promising paradigm for training machine
learning models across decentralized edge devices while preserving data
privacy. Ensuring the integrity and traceability of data across these
distributed environments, however, remains a critical challenge. The ability to
create transparent artificial intelligence, such as detailing the training
process of a machine learning model, has become an increasingly prominent
concern due to the large number of sensitive (hyper)parameters it utilizes;
thus, it is imperative to strike a reasonable balance between openness and the
need to protect sensitive information.
<br />In this paper, we propose one of the first approaches to enhance data
provenance and model transparency in federated learning systems. Our
methodology leverages a combination of cryptographic techniques and efficient
model management to track the transformation of data throughout the FL process,
and seeks to increase the reproducibility and trustworthiness of a trained FL
model. We demonstrate the effectiveness of our approach through experimental
evaluations on diverse FL scenarios, showcasing its ability to tackle
accountability and explainability across the board.
<br />Our findings show that our system can greatly enhance data transparency in
various FL environments by storing chained cryptographic hashes and client
model snapshots in our proposed design for data decoupled FL. This is made
possible by also employing multiple optimization techniques which enables
comprehensive data provenance without imposing substantial computational loads.
Extensive experimental results suggest that integrating a database subsystem
into federated learning systems can improve data provenance in an efficient
manner, encouraging secure FL adoption in privacy-sensitive applications and
paving the way for future advancements in FL transparency and security
features.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01454" title="Abstract">arXiv:2403.01454</a> [<a href="/pdf/2403.01454" title="Download PDF">pdf</a>, <a href="/ps/2403.01454" title="Download PostScript">ps</a>, <a href="/format/2403.01454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Length RLL Sequences in de Bruijn Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chee%2C+Y+M">Yeow Meng Chee</a>, 
<a href="/search/cs?searchtype=author&query=Etzion%2C+T">Tuvi Etzion</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+L">Tien Long Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+D+H">Duy Hoang Ta</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+V+D">Vinh Duc Tran</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+K">Van Khu Vu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A timing and synchronization system based on a de Bruijn sequence has been
proposed and studied recently for a channel associated with quantum
communication that requires reliable synchronization. To avoid a long period of
no-pulse in such a system on-off pulses are used to simulate a zero and on-on
pulses are used to simulate a one. However, these sequences have high
redundancy. To reduce the redundancy, run-length limited sequences in the de
Bruijn graph are proposed for the same purpose. The maximum length of such
sequences in the de Bruijn graph is studied and an efficient algorithm to
construct a large set of these sequences is presented. A maximum length
sequence for which the position of each window can be computed efficiently is
constructed. Finally, an enumeration of the number of such sequences is given
and some generalizations are discussed.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01456" title="Abstract">arXiv:2403.01456</a> [<a href="/pdf/2403.01456" title="Download PDF">pdf</a>, <a href="/ps/2403.01456" title="Download PostScript">ps</a>, <a href="/format/2403.01456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate  Models for IRT Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingshen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiajun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xinying Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Item difficulty plays a crucial role in adaptive testing. However, few works
have focused on generating questions of varying difficulty levels, especially
for multiple-choice (MC) cloze tests. We propose training pre-trained language
models (PLMs) as surrogate models to enable item response theory (IRT)
assessment, avoiding the need for human test subjects. We also propose two
strategies to control the difficulty levels of both the gaps and the
distractors using ranking rules to reduce invalid distractors. Experimentation
on a benchmark dataset demonstrates that our proposed framework and methods can
effectively control and evaluate the difficulty levels of MC cloze tests.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01457" title="Abstract">arXiv:2403.01457</a> [<a href="/pdf/2403.01457" title="Download PDF">pdf</a>, <a href="/format/2403.01457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logic Rules as Explanations for Legal Case Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kepu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by lrec-coling 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, we address the issue of using logic rules to explain the
results from legal case retrieval. The task is critical to legal case retrieval
because the users (e.g., lawyers or judges) are highly specialized and require
the system to provide logical, faithful, and interpretable explanations before
making legal decisions. Recently, research efforts have been made to learn
explainable legal case retrieval models. However, these methods usually select
rationales (key sentences) from the legal cases as explanations, failing to
provide faithful and logically correct explanations. In this paper, we propose
Neural-Symbolic enhanced Legal Case Retrieval (NS-LCR), a framework that
explicitly conducts reasoning on the matching of legal cases through learning
case-level and law-level logic rules. The learned rules are then integrated
into the retrieval process in a neuro-symbolic manner. Benefiting from the
logic and interpretable nature of the logic rules, NS-LCR is equipped with
built-in faithful explainability. We also show that NS-LCR is a model-agnostic
framework that can be plugged in for multiple legal retrieval models. To
showcase NS-LCR's superiority, we enhance existing benchmarks by adding
manually annotated logic rules and introducing a novel explainability metric
using Large Language Models (LLMs). Our comprehensive experiments reveal
NS-LCR's effectiveness for ranking, alongside its proficiency in delivering
reliable explanations for legal case retrieval.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01460" title="Abstract">arXiv:2403.01460</a> [<a href="/pdf/2403.01460" title="Download PDF">pdf</a>, <a href="/format/2403.01460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Step Multi-View Clustering Based on Transition Probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenhui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Quanxue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Cheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The large-scale multi-view clustering algorithms, based on the anchor graph,
have shown promising performance and efficiency and have been extensively
explored in recent years. Despite their successes, current methods lack
interpretability in the clustering process and do not sufficiently consider the
complementary information across different views. To address these
shortcomings, we introduce the One-Step Multi-View Clustering Based on
Transition Probability (OSMVC-TP). This method adopts a probabilistic approach,
which leverages the anchor graph, representing the transition probabilities
from samples to anchor points. Our method directly learns the transition
probabilities from anchor points to categories, and calculates the transition
probabilities from samples to categories, thus obtaining soft label matrices
for samples and anchor points, enhancing the interpretability of clustering.
Furthermore, to maintain consistency in labels across different views, we apply
a Schatten p-norm constraint on the tensor composed of the soft labels. This
approach effectively harnesses the complementary information among the views.
Extensive experiments have confirmed the effectiveness and robustness of
OSMVC-TP.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01461" title="Abstract">arXiv:2403.01461</a> [<a href="/pdf/2403.01461" title="Download PDF">pdf</a>, <a href="/format/2403.01461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Answerability in Retrieval-Augmented Open-Domain Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdumalikov%2C+R">Rustam Abdumalikov</a>, 
<a href="/search/cs?searchtype=author&query=Minervini%2C+P">Pasquale Minervini</a>, 
<a href="/search/cs?searchtype=author&query=Kementchedjhieva%2C+Y">Yova Kementchedjhieva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The performance of Open-Domain Question Answering (ODQA) retrieval systems
can exhibit sub-optimal behavior, providing text excerpts with varying degrees
of irrelevance. Unfortunately, many existing ODQA datasets lack examples
specifically targeting the identification of irrelevant text excerpts. Previous
attempts to address this gap have relied on a simplistic approach of pairing
questions with random text excerpts. This paper aims to investigate the
effectiveness of models trained using this randomized strategy, uncovering an
important limitation in their ability to generalize to irrelevant text excerpts
with high semantic overlap. As a result, we observed a substantial decrease in
predictive accuracy, from 98% to 1%. To address this limitation, we discovered
an efficient approach for training models to recognize such excerpts. By
leveraging unanswerable pairs from the SQuAD 2.0 dataset, our models achieve a
nearly perfect (~100%) accuracy when confronted with these challenging text
excerpts.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01463" title="Abstract">arXiv:2403.01463</a> [<a href="/pdf/2403.01463" title="Download PDF">pdf</a>, <a href="/format/2403.01463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Authentic Algorithm for Ciphering and Deciphering Called Latin  Djokovic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babuc%2C+D">Diogen Babuc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Five pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer and Information Engineering,
  Vol:17, No:10, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The question that is a motivation of writing is how many devote themselves to
discovering something in the world of science where much is discerned and
revealed, but at the same time, much is unknown. The insightful elements of
this algorithm are the ciphering and deciphering algorithms of Playfair,
Caesar, and Vigenere. Only a few of their main properties are taken and
modified, with the aim of forming a specific functionality of the algorithm
called Latin Djokovic. Specifically, a string is entered as input data. A key k
is given, with a random value between the values a and b = a + 3. The obtained
value is stored in a variable with the aim of being constant during the run of
the algorithm. In correlation to the given key, the string is divided into
several groups of substrings, and each substring has a length of k characters.
The next step involves encoding each substring from the list of existing
substrings. Encoding is performed using the basis of the Caesar algorithm,
i.e., shifting with k characters. However, that k is incremented by 1 when
moving to the next substring in that list. When the value of k becomes greater
than b + 1, it will return to its initial value. The algorithm is executed,
following the same procedure, until the last substring in the list is
traversed. Using this polyalphabetic method, ciphering and deciphering of
strings are achieved. The algorithm also works for a 100-character string. The
x character is not used when the number of characters in a substring is
incompatible with the expected length. The algorithm is simple to implement,
but it is questionable if it works better than the other methods from the point
of view of execution time and storage space.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01465" title="Abstract">arXiv:2403.01465</a> [<a href="/pdf/2403.01465" title="Download PDF">pdf</a>, <a href="/ps/2403.01465" title="Download PostScript">ps</a>, <a href="/format/2403.01465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiview Subspace Clustering of Hyperspectral Images based on Graph  Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianju Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+R">Renxiang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by APWEB-WAIM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-dimensional and complex spectral structures make clustering of
hy-perspectral images (HSI) a challenging task. Subspace clustering has been
shown to be an effective approach for addressing this problem. However, current
subspace clustering algorithms are mainly designed for a single view and do not
fully exploit spatial or texture feature information in HSI. This study
proposed a multiview subspace clustering of HSI based on graph convolutional
networks. (1) This paper uses the powerful classification ability of graph
convolutional network and the learning ability of topologi-cal relationships
between nodes to analyze and express the spatial relation-ship of HSI. (2)
Pixel texture and pixel neighbor spatial-spectral infor-mation were sent to
construct two graph convolutional subspaces. (3) An attention-based fusion
module was used to adaptively construct a more discriminative feature map. The
model was evaluated on three popular HSI datasets, including Indian Pines,
Pavia University, and Houston. It achieved overall accuracies of 92.38%,
93.43%, and 83.82%, respectively and significantly outperformed the
state-of-the-art clustering methods. In conclusion, the proposed model can
effectively improve the clustering ac-curacy of HSI.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01467" title="Abstract">arXiv:2403.01467</a> [<a href="/pdf/2403.01467" title="Download PDF">pdf</a>, <a href="/format/2403.01467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborate to Adapt: Source-Free Graph Domain Adaptation via  Bi-directional Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Anhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+J">Jiajun Bu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised Graph Domain Adaptation (UGDA) has emerged as a practical
solution to transfer knowledge from a label-rich source graph to a completely
unlabelled target graph. However, most methods require a labelled source graph
to provide supervision signals, which might not be accessible in the real-world
settings due to regulations and privacy concerns. In this paper, we explore the
scenario of source-free unsupervised graph domain adaptation, which tries to
address the domain adaptation problem without accessing the labelled source
graph. Specifically, we present a novel paradigm called GraphCTA, which
performs model adaptation and graph adaptation collaboratively through a series
of procedures: (1) conduct model adaptation based on node's neighborhood
predictions in target graph considering both local and global information; (2)
perform graph adaptation by updating graph structure and node attributes via
neighborhood contrastive learning; and (3) the updated graph serves as an input
to facilitate the subsequent iteration of model adaptation, thereby
establishing a collaborative loop between model adaptation and graph
adaptation. Comprehensive experiments are conducted on various public datasets.
The experimental results demonstrate that our proposed model outperforms recent
source-free baselines by large margins.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01469" title="Abstract">arXiv:2403.01469</a> [<a href="/pdf/2403.01469" title="Download PDF">pdf</a>, <a href="/format/2403.01469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean  Healthcare Professional Licensing Examinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kweon%2C+S">Sunjun Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+B">Byungjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+R+W">Rae Woong Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce KorMedMCQA, the first Korean multiple-choice question answering
(MCQA) benchmark derived from Korean healthcare professional licensing
examinations, covering from the year 2012 to year 2023. This dataset consists
of a selection of questions from the license examinations for doctors, nurses,
and pharmacists, featuring a diverse array of subjects. We conduct baseline
experiments on various large language models, including
proprietary/open-source, multilingual/Korean-additional pretrained, and
clinical context pretrained models, highlighting the potential for further
enhancements. We make our data publicly available on HuggingFace and provide a
evaluation script via LM-Harness, inviting further exploration and advancement
in Korean healthcare environments.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01470" title="Abstract">arXiv:2403.01470</a> [<a href="/pdf/2403.01470" title="Download PDF">pdf</a>, <a href="/format/2403.01470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is in-domain data beneficial in transfer learning for landmarks  detection in x-ray images?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Via%2C+R">Roberto Di Via</a>, 
<a href="/search/cs?searchtype=author&query=Santacesaria%2C+M">Matteo Santacesaria</a>, 
<a href="/search/cs?searchtype=author&query=Odone%2C+F">Francesca Odone</a>, 
<a href="/search/cs?searchtype=author&query=Pastore%2C+V+P">Vito Paolo Pastore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, deep learning has emerged as a promising technique for
medical image analysis. However, this application domain is likely to suffer
from a limited availability of large public datasets and annotations. A common
solution to these challenges in deep learning is the usage of a transfer
learning framework, typically with a fine-tuning protocol, where a large-scale
source dataset is used to pre-train a model, further fine-tuned on the target
dataset. In this paper, we present a systematic study analyzing whether the
usage of small-scale in-domain x-ray image datasets may provide any improvement
for landmark detection over models pre-trained on large natural image datasets
only. We focus on the multi-landmark localization task for three datasets,
including chest, head, and hand x-ray images. Our results show that using
in-domain source datasets brings marginal or no benefit with respect to an
ImageNet out-of-domain pre-training. Our findings can provide an indication for
the development of robust landmark detection systems in medical images when no
large annotated dataset is available.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01471" title="Abstract">arXiv:2403.01471</a> [<a href="/pdf/2403.01471" title="Download PDF">pdf</a>, <a href="/format/2403.01471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving correlations: A statistical method for generating synthetic  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%A4verg%C3%A5rd%2C+N">Nicklas J&#xe4;verg&#xe5;rd</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+R">Rainey Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Muntean%2C+A">Adrian Muntean</a>, 
<a href="/search/cs?searchtype=author&query=Forsman%2C+J">Jonas Forsman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">We propose a method to generate statistically representative synthetic data.
The main goal is to be able to maintain in the synthetic dataset the
correlations of the features present in the original one, while offering a
comfortable privacy level that can be eventually tailored on specific customer
demands.
<br />We describe in detail our algorithm used both for the analysis of the
original dataset and for the generation of the synthetic data points. The
approach is tested using a large energy-related dataset. We obtain good results
both qualitatively (e.g. via vizualizing correlation maps) and quantitatively
(in terms of suitable $\ell^1$-type error norms used as evaluation metrics).
<br />The proposed methodology is general in the sense that it does not rely on the
used test dataset. We expect it to be applicable in a much broader context than
indicated here.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01472" title="Abstract">arXiv:2403.01472</a> [<a href="/pdf/2403.01472" title="Download PDF">pdf</a>, <a href="/format/2403.01472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WARDEN: Multi-Directional Backdoor Watermarks for Embedding-as-a-Service  Copyright Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetty%2C+A">Anudeex Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yue Teng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Ke He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiongkai Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Embedding as a Service (EaaS) has become a widely adopted solution, which
offers feature extraction capabilities for addressing various downstream tasks
in Natural Language Processing (NLP). Prior studies have shown that EaaS can be
prone to model extraction attacks; nevertheless, this concern could be
mitigated by adding backdoor watermarks to the text embeddings and subsequently
verifying the attack models post-publication. Through the analysis of the
recent watermarking strategy for EaaS, EmbMarker, we design a novel CSE
(Clustering, Selection, Elimination) attack that removes the backdoor watermark
while maintaining the high utility of embeddings, indicating that the previous
watermarking approach can be breached. In response to this new threat, we
propose a new protocol to make the removal of watermarks more challenging by
incorporating multiple possible watermark directions. Our defense approach,
WARDEN, notably increases the stealthiness of watermarks and empirically has
been shown effective against CSE attack.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01475" title="Abstract">arXiv:2403.01475</a> [<a href="/pdf/2403.01475" title="Download PDF">pdf</a>, <a href="/format/2403.01475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Learning on Heterophilic Graph with Directional  Neighborhood Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qincheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiaqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+S">Sitao Luan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiao-Wen Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph Attention Network (GAT) is one of the most popular Graph Neural Network
(GNN) architecture, which employs the attention mechanism to learn edge weights
and has demonstrated promising performance in various applications. However,
since it only incorporates information from immediate neighborhood, it lacks
the ability to capture long-range and global graph information, leading to
unsatisfactory performance on some datasets, particularly on heterophilic
graphs. To address this limitation, we propose the Directional Graph Attention
Network (DGAT) in this paper. DGAT is able to combine the feature-based
attention with the global directional information extracted from the graph
topology. To this end, a new class of Laplacian matrices is proposed which can
provably reduce the diffusion distance between nodes. Based on the new
Laplacian, topology-guided neighbour pruning and edge adding mechanisms are
proposed to remove the noisy and capture the helpful long-range neighborhood
information. Besides, a global directional attention is designed to enable a
topological-aware information propagation. The superiority of the proposed DGAT
over the baseline GAT has also been verified through experiments on real-world
benchmarks and synthetic data sets. It also outperforms the state-of-the-art
(SOTA) models on 6 out of 7 real-world benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01476" title="Abstract">arXiv:2403.01476</a> [<a href="/pdf/2403.01476" title="Download PDF">pdf</a>, <a href="/format/2403.01476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCC: Color Classified Colorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gain%2C+M">Mrityunjoy Gain</a>, 
<a href="/search/cs?searchtype=author&query=Raha%2C+A+D">Avi Deb Raha</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+R">Rameswar Debnath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic colorization of gray images with objects of different colors and
sizes is challenging due to inter- and intra-object color variation and the
small area of the main objects due to extensive backgrounds. The learning
process often favors dominant features, resulting in a biased model. In this
paper, we formulate the colorization problem into a multinomial classification
problem and then apply a weighted function to classes. We propose a set of
formulas to transform color values into color classes and vice versa. Class
optimization and balancing feature distribution are the keys for good
performance. Observing class appearance on various extremely large-scale
real-time images in practice, we propose 215 color classes for our colorization
task. During training, we propose a class-weighted function based on true class
appearance in each batch to ensure proper color saturation of individual
objects. We establish a trade-off between major and minor classes to provide
orthodox class prediction by eliminating major classes' dominance over minor
classes. As we apply regularization to enhance the stability of the minor
class, occasional minor noise may appear at the object's edges. We propose a
novel object-selective color harmonization method empowered by the SAM to
refine and enhance these edges. We propose a new color image evaluation metric,
the Chromatic Number Ratio (CNR), to quantify the richness of color components.
We compare our proposed model with state-of-the-art models using five different
datasets: ADE, Celeba, COCO, Oxford 102 Flower, and ImageNet, in both
qualitative and quantitative approaches. The experimental results show that our
proposed model outstrips other models in visualization and CNR measurement
criteria while maintaining satisfactory performance in regression (MSE, PSNR),
similarity (SSIM, LPIPS, UIQI), and generative criteria (FID).
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01479" title="Abstract">arXiv:2403.01479</a> [<a href="/pdf/2403.01479" title="Download PDF">pdf</a>, <a href="/format/2403.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align-to-Distill: Trainable Attention Alignment for Knowledge  Distillation in Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Heegon Jin</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+S">Seonil Son</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jemin Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+H">Hyungjong Noh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yeonsoo Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of scalable deep models and large datasets has improved the
performance of Neural Machine Translation. Knowledge Distillation (KD) enhances
efficiency by transferring knowledge from a teacher model to a more compact
student model. However, KD approaches to Transformer architecture often rely on
heuristics, particularly when deciding which teacher layers to distill from. In
this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to
address the feature mapping problem by adaptively aligning student attention
heads with their teacher counterparts during training. The Attention Alignment
Module in A2D performs a dense head-by-head comparison between student and
teacher attention heads across layers, turning the combinatorial mapping
heuristics into a learning problem. Our experiments show the efficacy of A2D,
demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De-&gt;Dsb
and WMT-2014 En-&gt;De, respectively, compared to Transformer baselines.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01480" title="Abstract">arXiv:2403.01480</a> [<a href="/pdf/2403.01480" title="Download PDF">pdf</a>, <a href="/ps/2403.01480" title="Download PostScript">ps</a>, <a href="/format/2403.01480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Design of Uplink Integrated Sensing and  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Caijun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Wireless Communications, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate the issue of uplink integrated sensing and
communication (ISAC) in 6G wireless networks where the sensing echo signal and
the communication signal are received simultaneously at the base station (BS).
To effectively mitigate the mutual interference between sensing and
communication caused by the sharing of spectrum and hardware resources, we
provide a joint sensing transmit waveform and communication receive beamforming
design with the objective of maximizing the weighted sum of normalized sensing
rate and normalized communication rate. It is formulated as a computationally
complicated non-convex optimization problem, which is quite difficult to be
solved by conventional optimization methods. To this end, we first make a
series of equivalent transformation on the optimization problem to reduce the
design complexity, and then develop a deep learning (DL)-based scheme to
enhance the overall performance of ISAC. Both theoretical analysis and
simulation results confirm the effectiveness and robustness of the proposed
DL-based scheme for ISAC in 6G wireless networks.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01481" title="Abstract">arXiv:2403.01481</a> [<a href="/pdf/2403.01481" title="Download PDF">pdf</a>, <a href="/format/2403.01481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infusing Knowledge into Large Language Models with Contextual Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasisht%2C+K">Kinshuk Vasisht</a>, 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+B">Balaji Ganesan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikas Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+V">Vasudha Bhatnagar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, In Proceedings of ICON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge infusion is a promising method for enhancing Large Language Models
for domain-specific NLP tasks rather than pre-training models over large data
from scratch. These augmented LLMs typically depend on additional pre-training
or knowledge prompts from an existing knowledge graph, which is impractical in
many applications. In contrast, knowledge infusion directly from relevant
documents is more generalisable and alleviates the need for structured
knowledge graphs while also being useful for entities that are usually not
found in any knowledge graph. With this motivation, we propose a simple yet
generalisable approach for knowledge infusion by generating prompts from the
context in the input text. Our experiments show the effectiveness of our
approach which we evaluate by probing the fine-tuned LLMs.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01482" title="Abstract">arXiv:2403.01482</a> [<a href="/pdf/2403.01482" title="Download PDF">pdf</a>, <a href="/format/2403.01482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EAGLE: Eigen Aggregation Learning for Object-Centric Unsupervised  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Woojung Han</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+D">Dayun Ju</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Seong Jae Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation has innately relied on extensive pixel-level labeled
annotated data, leading to the emergence of unsupervised methodologies. Among
them, leveraging self-supervised Vision Transformers for unsupervised semantic
segmentation (USS) has been making steady progress with expressive deep
features. Yet, for semantically segmenting images with complex objects, a
predominant challenge remains: the lack of explicit object-level semantic
encoding in patch-level features. This technical limitation often leads to
inadequate segmentation of complex objects with diverse structures. To address
this gap, we present a novel approach, EAGLE, which emphasizes object-centric
representation learning for unsupervised semantic segmentation. Specifically,
we introduce EiCue, a spectral technique providing semantic and structural cues
through an eigenbasis derived from the semantic similarity matrix of deep image
features and color affinity from an image. Further, by incorporating our
object-centric contrastive loss with EiCue, we guide our model to learn
object-level representations with intra- and inter-image object-feature
consistency, thereby enhancing semantic accuracy. Extensive experiments on
COCO-Stuff, Cityscapes, and Potsdam-3 datasets demonstrate the state-of-the-art
USS results of EAGLE with accurate and consistent semantic segmentation across
complex scenes.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01483" title="Abstract">arXiv:2403.01483</a> [<a href="/pdf/2403.01483" title="Download PDF">pdf</a>, <a href="/format/2403.01483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BronchoCopilot: Towards Autonomous Robotic Bronchoscopy via Multimodal  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qingyao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bingyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongbin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Bronchoscopy plays a significant role in the early diagnosis and treatment of
lung diseases. This process demands physicians to maneuver the flexible
endoscope for reaching distal lesions, particularly requiring substantial
expertise when examining the airways of the upper lung lobe. With the
development of artificial intelligence and robotics, reinforcement learning
(RL) method has been applied to the manipulation of interventional surgical
robots. However, unlike human physicians who utilize multimodal information,
most of the current RL methods rely on a single modality, limiting their
performance. In this paper, we propose BronchoCopilot, a multimodal RL agent
designed to acquire manipulation skills for autonomous bronchoscopy.
BronchoCopilot specifically integrates images from the bronchoscope camera and
estimated robot poses, aiming for a higher success rate within challenging
airway environment. We employ auxiliary reconstruction tasks to compress
multimodal data and utilize attention mechanisms to achieve an efficient latent
representation of this data, serving as input for the RL module. This framework
adopts a stepwise training and fine-tuning approach to mitigate the challenges
of training difficulty. Our evaluation in the realistic simulation environment
reveals that BronchoCopilot, by effectively harnessing multimodal information,
attains a success rate of approximately 90\% in fifth generation airways with
consistent movements. Additionally, it demonstrates a robust capacity to adapt
to diverse cases.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01486" title="Abstract">arXiv:2403.01486</a> [<a href="/pdf/2403.01486" title="Download PDF">pdf</a>, <a href="/format/2403.01486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An RBF partition of unity method for geometry reconstruction and PDE  solution in thin structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Larsson%2C+E">Elisabeth Larsson</a>, 
<a href="/search/math?searchtype=author&query=Villard%2C+P">Pierre-Fr&#xe9;d&#xe9;ric Villard</a>, 
<a href="/search/math?searchtype=author&query=Tominec%2C+I">Igor Tominec</a>, 
<a href="/search/math?searchtype=author&query=Sundin%2C+U">Ulrika Sundin</a>, 
<a href="/search/math?searchtype=author&query=Michael%2C+A">Andreas Michael</a>, 
<a href="/search/math?searchtype=author&query=Cacciani%2C+N">Nicola Cacciani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 15 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The main respiratory muscle, the diaphragm, is an example of a thin
structure. We aim to perform detailed numerical simulations of the muscle
mechanics based on individual patient data. This requires a representation of
the diaphragm geometry extracted from medical image data. We design an adaptive
reconstruction method based on a least-squares radial basis function partition
of unity method. The method is adapted to thin structures by subdividing the
structure rather than the surrounding space, and by introducing an anisotropic
scaling of local subproblems. The resulting representation is an infinitely
smooth level set function, which is stabilized such that there are no spurious
zero level sets. We show reconstruction results for 2D cross sections of the
diaphragm geometry as well as for the full 3D geometry. We also show solutions
to basic PDE test problems in the reconstructed geometries.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01487" title="Abstract">arXiv:2403.01487</a> [<a href="/pdf/2403.01487" title="Download PDF">pdf</a>, <a href="/format/2403.01487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfiMM-HD: A Leap Forward in High-Resolution Multimodal Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haogeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+B">Bohan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yunzhe Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have experienced significant
advancements recently. Nevertheless, challenges persist in the accurate
recognition and comprehension of intricate details within high-resolution
images. Despite being indispensable for the development of robust MLLMs, this
area remains underinvestigated. To tackle this challenge, our work introduces
InfiMM-HD, a novel architecture specifically designed for processing images of
different resolutions with low computational overhead. This innovation
facilitates the enlargement of MLLMs to higher-resolution capabilities.
InfiMM-HD incorporates a cross-attention module and visual windows to reduce
computation costs. By integrating this architectural design with a four-stage
training pipeline, our model attains improved visual perception efficiently and
cost-effectively. Empirical study underscores the robustness and effectiveness
of InfiMM-HD, opening new avenues for exploration in related areas. Codes and
models can be found at https://huggingface.co/Infi-MM/infimm-hd
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01489" title="Abstract">arXiv:2403.01489</a> [<a href="/pdf/2403.01489" title="Download PDF">pdf</a>, <a href="/format/2403.01489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regeneration Based Training-free Attribution of Fake Images Generated by  Text-to-Image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meiling Li</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-image generative models have recently garnered significant attention
due to their ability to generate images based on prompt descriptions. While
these models have shown promising performance, concerns have been raised
regarding the potential misuse of the generated fake images. In response to
this, we have presented a simple yet effective training-free method to
attribute fake images generated by text-to-image models to their source models.
Given a test image to be attributed, we first inverse the textual prompt of the
image, and then put the reconstructed prompt into different candidate models to
regenerate candidate fake images. By calculating and ranking the similarity of
the test image and the candidate images, we can determine the source of the
image. This attribution allows model owners to be held accountable for any
misuse of their models. Note that our approach does not limit the number of
candidate text-to-image generative models. Comprehensive experiments reveal
that (1) Our method can effectively attribute fake images to their source
models, achieving comparable attribution performance with the state-of-the-art
method; (2) Our method has high scalability ability, which is well adapted to
real-world attribution scenarios. (3) The proposed method yields satisfactory
robustness to common attacks, such as Gaussian blurring, JPEG compression, and
Resizing. We also analyze the factors that influence the attribution
performance, and explore the boost brought by the proposed method as a plug-in
to improve the performance of existing SOTA. We hope our work can shed some
light on the solutions to addressing the source of AI-generated images, as well
as to prevent the misuse of text-to-image generative models.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01491" title="Abstract">arXiv:2403.01491</a> [<a href="/pdf/2403.01491" title="Download PDF">pdf</a>, <a href="/format/2403.01491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultimate codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurley%2C+T">Ted Hurley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">A linear block code over a field can be derived from a unit scheme. Looking
at codes as a structure within a unit scheme greatly extends the available of
codes, both linear block and convolutional, and allows the construction of
particular types of codes and to required length, rate, distance and over
specified fields as required. Properties of a code emanate from properties of
the unit from which it was derived. Orthogonal units and related orthogonal
type units, units in group rings and Fourier/Vandermonde are types of units
which are used to construct and analyse particular types of codes and to
construct these to predefined length, rate and distance. Dual containing codes,
which include self-dual codes, and complementary dual codes as well as codes to
specified rate and over specified finite fields are constructible. Low density
parity check linear and convolutional codes to required rates are constructed
using group rings. From a single unit, multiple codes of a required type are
derivable. Using the full unit, rather than just part of the unit, allows the
construction of convolutional codes to required types, rates and structure. The
distances of the convolutional codes are determinable from the constituents of
the unit used and are much better than the distance of an equivalent rate
linear code but also efficient convolutional decoding methods are applicable.
Dual-containing and complementary dual convolutional codes are constructed by
the unit-derived methods from suitable units. Dual-containing convolutional
codes are used to construct quantum error-correcting convolutional codes.
`Manufacturing' of different and sophisticated `models' is now possible.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01493" title="Abstract">arXiv:2403.01493</a> [<a href="/pdf/2403.01493" title="Download PDF">pdf</a>, <a href="/format/2403.01493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConvTimeNet: A Deep Hierarchical Fully Convolutional Model for  Multivariate Time Series Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingyue Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+T">Tingyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper introduces ConvTimeNet, a novel deep hierarchical fully
convolutional network designed to serve as a general-purpose model for time
series analysis. The key design of this network is twofold, designed to
overcome the limitations of traditional convolutional networks. Firstly, we
propose an adaptive segmentation of time series into sub-series level patches,
treating these as fundamental modeling units. This setting avoids the sparsity
semantics associated with raw point-level time steps. Secondly, we design a
fully convolutional block by skillfully integrating deepwise and pointwise
convolution operations, following the advanced building block style employed in
Transformer encoders. This backbone network allows for the effective capture of
both global sequence and cross-variable dependence, as it not only incorporates
the advancements of Transformer architecture but also inherits the inherent
properties of convolution. Furthermore, multi-scale representations of given
time series instances can be learned by controlling the kernel size flexibly.
Extensive experiments are conducted on both time series forecasting and
classification tasks. The results consistently outperformed strong baselines in
most situations in terms of effectiveness.The code is publicly available.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01497" title="Abstract">arXiv:2403.01497</a> [<a href="/pdf/2403.01497" title="Download PDF">pdf</a>, <a href="/format/2403.01497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning A Physical-aware Diffusion Model Based on Transformer for  Underwater Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chenyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weiling Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater visuals undergo various complex degradations, inevitably
influencing the efficiency of underwater vision tasks. Recently, diffusion
models were employed to underwater image enhancement (UIE) tasks, and gained
SOTA performance. However, these methods fail to consider the physical
properties and underwater imaging mechanisms in the diffusion process, limiting
information completion capacity of diffusion models. In this paper, we
introduce a novel UIE framework, named PA-Diff, designed to exploiting the
knowledge of physics to guide the diffusion process.
<br />PA-Diff consists of Physics Prior Generation (PPG) Branch and Physics-aware
Diffusion Transformer (PDT) Branch. Our designed PPG branch is a plug-and-play
network to produce the physics prior, which can be integrated into any deep
framework. With utilizing the physics prior knowledge to guide the diffusion
process, PDT branch can obtain underwater-aware ability and model the complex
distribution in real-world underwater scenes. Extensive experiments prove that
our method achieves best performance on UIE tasks.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01499" title="Abstract">arXiv:2403.01499</a> [<a href="/pdf/2403.01499" title="Download PDF">pdf</a>, <a href="/format/2403.01499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalising Flow-based Differentiable Particle Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiongjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, submitted to IEEE Transactions on Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Recently, there has been a surge of interest in incorporating neural networks
into particle filters, e.g. differentiable particle filters, to perform joint
sequential state estimation and model learning for non-linear non-Gaussian
state-space models in complex environments. Existing differentiable particle
filters are mostly constructed with vanilla neural networks that do not allow
density estimation. As a result, they are either restricted to a bootstrap
particle filtering framework or employ predefined distribution families (e.g.
Gaussian distributions), limiting their performance in more complex real-world
scenarios. In this paper we present a differentiable particle filtering
framework that uses (conditional) normalising flows to build its dynamic model,
proposal distribution, and measurement model. This not only enables valid
probability densities but also allows the proposed method to adaptively learn
these modules in a flexible way, without being restricted to predefined
distribution families. We derive the theoretical properties of the proposed
filters and evaluate the proposed normalising flow-based differentiable
particle filters' performance through a series of numerical experiments.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01501" title="Abstract">arXiv:2403.01501</a> [<a href="/pdf/2403.01501" title="Download PDF">pdf</a>, <a href="/format/2403.01501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Self-supervised Learning to Network Intrusion Detection for  Network Flows with Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guangwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+A">An He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15pages,8figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have garnered intensive attention for Network
Intrusion Detection System (NIDS) due to their suitability for representing the
network traffic flows. However, most present GNN-based methods for NIDS are
supervised or semi-supervised. Network flows need to be manually annotated as
supervisory labels, a process that is time-consuming or even impossible, making
NIDS difficult to adapt to potentially complex attacks, especially in
large-scale real-world scenarios. The existing GNN-based self-supervised
methods focus on the binary classification of network flow as benign or not,
and thus fail to reveal the types of attack in practice. This paper studies the
application of GNNs to identify the specific types of network flows in an
unsupervised manner. We first design an encoder to obtain graph embedding, that
introduces the graph attention mechanism and considers the edge information as
the only essential factor. Then, a self-supervised method based on graph
contrastive learning is proposed. The method samples center nodes, and for each
center node, generates subgraph by it and its direct neighbor nodes, and
corresponding contrastive subgraph from the interpolated graph, and finally
constructs positive and negative samples from subgraphs. Furthermore, a
structured contrastive loss function based on edge features and graph local
topology is introduced. To the best of our knowledge, it is the first GNN-based
self-supervised method for the multiclass classification of network flows in
NIDS. Detailed experiments conducted on four real-world databases (NF-Bot-IoT,
NF-Bot-IoT-v2, NF-CSE-CIC-IDS2018, and NF-CSE-CIC-IDS2018-v2) systematically
compare our model with the state-of-the-art supervised and self-supervised
models, illustrating the considerable potential of our method. Our code is
accessible through https://github.com/renj-xu/NEGSC.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01505" title="Abstract">arXiv:2403.01505</a> [<a href="/pdf/2403.01505" title="Download PDF">pdf</a>, <a href="/format/2403.01505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCott: Accelerating Diffusion Models with Stochastic Consistency  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongjian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qingsong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fueyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-jun Zha</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The iterative sampling procedure employed by diffusion models (DMs) often
leads to significant inference latency. To address this, we propose Stochastic
Consistency Distillation (SCott) to enable accelerated text-to-image
generation, where high-quality generations can be achieved with just 1-2
sampling steps, and further improvements can be obtained by adding additional
steps. In contrast to vanilla consistency distillation (CD) which distills the
ordinary differential equation solvers-based sampling process of a pretrained
teacher model into a student, SCott explores the possibility and validates the
efficacy of integrating stochastic differential equation (SDE) solvers into CD
to fully unleash the potential of the teacher. SCott is augmented with
elaborate strategies to control the noise strength and sampling process of the
SDE solver. An adversarial loss is further incorporated to strengthen the
sample quality with rare sampling steps. Empirically, on the MSCOCO-2017 5K
dataset with a Stable Diffusion-V1.5 teacher, SCott achieves an FID (Frechet
Inceptio Distance) of 22.1, surpassing that (23.4) of the 1-step InstaFlow (Liu
et al., 2023) and matching that of 4-step UFOGen (Xue et al., 2023b). Moreover,
SCott can yield more diverse samples than other consistency models for
high-resolution image generation (Luo et al., 2023a), with up to 16%
improvement in a qualified metric. The code and checkpoints are coming soon.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01507" title="Abstract">arXiv:2403.01507</a> [<a href="/pdf/2403.01507" title="Download PDF">pdf</a>, <a href="/format/2403.01507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISSF: The Intelligent Security Service Framework for Cloud-Native  Operation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yikuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Keman Huang</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+M">Michael Siegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The growing system complexity from microservice architectures and the
bilateral enhancement of artificial intelligence (AI) for both attackers and
defenders presents increasing security challenges for cloud-native operations.
In particular, cloud-native operators require a holistic view of the dynamic
security posture for the cloud-native environment from a defense aspect.
Additionally, both attackers and defenders can adopt advanced AI technologies.
This makes the dynamic interaction and benchmark among different intelligent
offense and defense strategies more crucial. Hence, following the multi-agent
deep reinforcement learning (RL) paradigm, this research develops an
agent-based intelligent security service framework (ISSF) for cloud-native
operation. It includes a dynamic access graph model to represent the
cloud-native environment and an action model to represent offense and defense
actions. Then we develop an approach to enable the training, publishing, and
evaluating of intelligent security services using diverse deep RL algorithms
and training strategies, facilitating their systematic development and
benchmark. The experiments demonstrate that our framework can sufficiently
model the security posture of a cloud-native system for defenders, effectively
develop and quantitatively benchmark different services for both attackers and
defenders and guide further service optimization.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01508" title="Abstract">arXiv:2403.01508</a> [<a href="/pdf/2403.01508" title="Download PDF">pdf</a>, <a href="/format/2403.01508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Reasoning on Uncertain Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+W">Weizhi Fei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The study of machine learning-based logical query-answering enables reasoning
with large-scale and incomplete knowledge graphs. This paper further advances
this line of research by considering the uncertainty in the knowledge. The
uncertain nature of knowledge is widely observed in the real world, but
\textit{does not} align seamlessly with the first-order logic underpinning
existing studies. To bridge this gap, we study the setting of soft queries on
uncertain knowledge, which is motivated by the establishment of soft constraint
programming. We further propose an ML-based approach with both forward
inference and backward calibration to answer soft queries on large-scale,
incomplete, and uncertain knowledge graphs. Theoretical discussions present
that our methods share the same complexity as state-of-the-art inference
algorithms for first-order queries. Empirical results justify the superior
performance of our approach against previous ML-based methods with number
embedding extensions.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01509" title="Abstract">arXiv:2403.01509</a> [<a href="/pdf/2403.01509" title="Download PDF">pdf</a>, <a href="/format/2403.01509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fantastic Semantics and Where to Find Them: Investigating Which Layers  of Generative LLMs Reflect Lexical Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+C">Cunliang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was completed on February 15th, 2024, and submitted to ACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models have achieved remarkable success in general language
understanding tasks. However, as a family of generative methods with the
objective of next token prediction, the semantic evolution with the depth of
these models are not fully explored, unlike their predecessors, such as
BERT-like architectures. In this paper, we specifically investigate the
bottom-up evolution of lexical semantics for a popular LLM, namely Llama2, by
probing its hidden states at the end of each layer using a contextualized word
identification task. Our experiments show that the representations in lower
layers encode lexical semantics, while the higher layers, with weaker semantic
induction, are responsible for prediction. This is in contrast to models with
discriminative objectives, such as mask language modeling, where the higher
layers obtain better lexical semantics. The conclusion is further supported by
the monotonic increase in performance via the hidden states for the last
meaningless symbols, such as punctuation, in the prompting strategy.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01510" title="Abstract">arXiv:2403.01510</a> [<a href="/pdf/2403.01510" title="Download PDF">pdf</a>, <a href="/format/2403.01510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Human Instance Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Q">Quanling Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+B">Bineng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peiqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hongxun Yao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE T-CSVT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human instance matting aims to estimate an alpha matte for each human
instance in an image, which is extremely challenging and has rarely been
studied so far. Despite some efforts to use instance segmentation to generate a
trimap for each instance and apply trimap-based matting methods, the resulting
alpha mattes are often inaccurate due to inaccurate segmentation. In addition,
this approach is computationally inefficient due to multiple executions of the
matting method. To address these problems, this paper proposes a novel
End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple
instance matting in a more efficient manner. Specifically, a general perception
network first extracts image features and decodes instance contexts into latent
codes. Then, a united guidance network exploits spatial attention and semantics
embedding to generate united semantics guidance, which encodes the locations
and semantic correspondences of all instances. Finally, an instance matting
network decodes the image features and united semantics guidance to predict all
instance-level alpha mattes. In addition, we construct a large-scale human
instance matting dataset (HIM-100K) comprising over 100,000 human images with
instance alpha matte labels. Experiments on HIM-100K demonstrate the proposed
E2E-HIM outperforms the existing methods on human instance matting with 50%
lower errors and 5X faster speed (6 instances in a 640X640 image). Experiments
on the PPM-100, RWP-636, and P3M datasets demonstrate that E2E-HIM also
achieves competitive performance on traditional human matting.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01512" title="Abstract">arXiv:2403.01512</a> [<a href="/pdf/2403.01512" title="Download PDF">pdf</a>, <a href="/format/2403.01512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Automated Driving for Bottleneck Scenarios in Mixed Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+M+V">M.V. Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Beyerer%2C+J">J. Beyerer</a>, 
<a href="/search/cs?searchtype=author&query=Buck%2C+H+S">H.S. Buck</a>, 
<a href="/search/cs?searchtype=author&query=Deml%2C+B">B. Deml</a>, 
<a href="/search/cs?searchtype=author&query=Ehrhardt%2C+S">S. Ehrhardt</a>, 
<a href="/search/cs?searchtype=author&query=Frese%2C+C">Ch. Frese</a>, 
<a href="/search/cs?searchtype=author&query=Kleiser%2C+D">D. Kleiser</a>, 
<a href="/search/cs?searchtype=author&query=Lauer%2C+M">M. Lauer</a>, 
<a href="/search/cs?searchtype=author&query=Roschani%2C+M">M. Roschani</a>, 
<a href="/search/cs?searchtype=author&query=Ruf%2C+M">M. Ruf</a>, 
<a href="/search/cs?searchtype=author&query=Stiller%2C+C">Ch. Stiller</a>, 
<a href="/search/cs?searchtype=author&query=Vortisch%2C+P">P. Vortisch</a>, 
<a href="/search/cs?searchtype=author&query=Ziehn%2C+J+R">J.R. Ziehn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 35th IEEE Intelligent Vehicles Symposium (IV 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Connected automated vehicles (CAV), which incorporate vehicle-to-vehicle
(V2V) communication into their motion planning, are expected to provide a wide
range of benefits for individual and overall traffic flow. A frequent
constraint or required precondition is that compatible CAVs must already be
available in traffic at high penetration rates. Achieving such penetration
rates incrementally before providing ample benefits for users presents a
chicken-and-egg problem that is common in connected driving development. Based
on the example of a cooperative driving function for bottleneck traffic flows
(e.g. at a roadblock), we illustrate how such an evolutionary, incremental
introduction can be achieved under transparent assumptions and objectives. To
this end, we analyze the challenge from the perspectives of automation
technology, traffic flow, human factors and market, and present a principle
that 1) accounts for individual requirements from each domain; 2) provides
benefits for any penetration rate of compatible CAVs between 0 % and 100 % as
well as upward-compatibility for expected future developments in traffic; 3)
can strictly limit the negative effects of cooperation for any participant and
4) can be implemented with close-to-market technology. We discuss the technical
implementation as well as the effect on traffic flow over a wide parameter
spectrum for human and technical aspects.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01517" title="Abstract">arXiv:2403.01517</a> [<a href="/pdf/2403.01517" title="Download PDF">pdf</a>, <a href="/format/2403.01517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatchU: Matching Unseen Objects for 6D Pose Estimation from RGB-D Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kuan-Ting Yu</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Ilic%2C+S">Slobodan Ilic</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent learning methods for object pose estimation require resource-intensive
training for each individual object instance or category, hampering their
scalability in real applications when confronted with previously unseen
objects. In this paper, we propose MatchU, a Fuse-Describe-Match strategy for
6D pose estimation from RGB-D images. MatchU is a generic approach that fuses
2D texture and 3D geometric cues for 6D pose prediction of unseen objects. We
rely on learning geometric 3D descriptors that are rotation-invariant by
design. By encoding pose-agnostic geometry, the learned descriptors naturally
generalize to unseen objects and capture symmetries. To tackle ambiguous
associations using 3D geometry only, we fuse additional RGB information into
our descriptor. This is achieved through a novel attention-based mechanism that
fuses cross-modal information, together with a matching loss that leverages the
latent space learned from RGB data to guide the descriptor learning process.
Extensive experiments reveal the generalizability of both the RGB-D fusion
strategy as well as the descriptor efficacy. Benefiting from the novel designs,
MatchU surpasses all existing methods by a significant margin in terms of both
accuracy and speed, even without the requirement of expensive re-training or
rendering.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01518" title="Abstract">arXiv:2403.01518</a> [<a href="/pdf/2403.01518" title="Download PDF">pdf</a>, <a href="/format/2403.01518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Dynamic Evaluation: Online Adaptation for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rannen-Triki%2C+A">Amal Rannen-Triki</a>, 
<a href="/search/cs?searchtype=author&query=Bornschein%2C+J">Jorg Bornschein</a>, 
<a href="/search/cs?searchtype=author&query=Pascanu%2C+R">Razvan Pascanu</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marcus Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Gy%C3%B6rgy%2C+A">Andras Gy&#xf6;rgy</a>, 
<a href="/search/cs?searchtype=author&query=Galashov%2C+A">Alexandre Galashov</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+Y+W">Yee Whye Teh</a>, 
<a href="/search/cs?searchtype=author&query=Titsias%2C+M+K">Michalis K. Titsias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the problem of online fine tuning the parameters of a language
model at test time, also known as dynamic evaluation. While it is generally
known that this approach improves the overall predictive performance,
especially when considering distributional shift between training and
evaluation data, we here emphasize the perspective that online adaptation turns
parameters into temporally changing states and provides a form of
context-length extension with memory in weights, more in line with the concept
of memory in neuroscience. We pay particular attention to the speed of
adaptation (in terms of sample efficiency),sensitivity to the overall
distributional drift, and the computational overhead for performing gradient
computations and parameter updates. Our empirical study provides insights on
when online adaptation is particularly interesting. We highlight that with
online adaptation the conceptual distinction between in-context learning and
fine tuning blurs: both are methods to condition the model on previously
observed tokens.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01521" title="Abstract">arXiv:2403.01521</a> [<a href="/pdf/2403.01521" title="Download PDF">pdf</a>, <a href="/format/2403.01521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Algorithm for Quasi-2D Coulomb Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gan%2C+Z">Zecheng Gan</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+X">Xuanzhao Gao</a>, 
<a href="/search/math?searchtype=author&query=Liang%2C+J">Jiuyang Liang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Z">Zhenli Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Quasi-2D Coulomb systems are of fundamental importance and have attracted
much attention in many areas nowadays. Their reduced symmetry gives rise to
interesting collective behaviors, but also brings great challenges for
particle-based simulations. Here, we propose a novel algorithm framework to
address the $\mathcal O(N^2)$ simulation complexity associated with the
long-range nature of Coulomb interactions. First, we introduce an efficient
Sum-of-Exponentials (SOE) approximation for the long-range kernel associated
with Ewald splitting, achieving uniform convergence in terms of inter-particle
distance, which reduces the complexity to $\mathcal{O}(N^{7/5})$. We then
introduce a random batch sampling method in the periodic dimensions, the
stochastic approximation is proven to be both unbiased and with reduced
variance via a tailored importance sampling strategy, further reducing the
computational cost to $\mathcal{O}(N)$. The performance of our algorithm is
demonstrated via varies numerical examples. Notably, it achieves a speedup of
$2\sim 3$ orders of magnitude comparing with Ewald2D method, enabling molecular
dynamics (MD) simulations with up to $10^6$ particles on a single core. The
present approach is therefore well-suited for large-scale particle-based
simulations of Coulomb systems under confinement, making it possible to
investigate the role of Coulomb interaction in many practical situations.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01528" title="Abstract">arXiv:2403.01528</a> [<a href="/pdf/2403.01528" title="Download PDF">pdf</a>, <a href="/format/2403.01528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Biomolecule and Natural Language through Multi-Modal  Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Survey Paper. 27 pages, 9 figures, and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The integration of biomolecular modeling with natural language (BL) has
emerged as a promising interdisciplinary area at the intersection of artificial
intelligence, chemistry and biology. This approach leverages the rich,
multifaceted descriptions of biomolecules contained within textual data sources
to enhance our fundamental understanding and enable downstream computational
tasks such as biomolecule property prediction. The fusion of the nuanced
narratives expressed through natural language with the structural and
functional specifics of biomolecules described via various molecular modeling
techniques opens new avenues for comprehensively representing and analyzing
biomolecules. By incorporating the contextual language data that surrounds
biomolecules into their modeling, BL aims to capture a holistic view
encompassing both the symbolic qualities conveyed through language as well as
quantitative structural characteristics. In this review, we provide an
extensive analysis of recent advancements achieved through cross modeling of
biomolecules and natural language. (1) We begin by outlining the technical
representations of biomolecules employed, including sequences, 2D graphs, and
3D structures. (2) We then examine in depth the rationale and key objectives
underlying effective multi-modal integration of language and molecular data
sources. (3) We subsequently survey the practical applications enabled to date
in this developing research area. (4) We also compile and summarize the
available resources and datasets to facilitate future work. (5) Looking ahead,
we identify several promising research directions worthy of further exploration
and investment to continue advancing the field. The related resources and
contents are updating in
\url{https://github.com/QizhiPei/Awesome-Biomolecule-Language-Cross-Modeling}.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01529" title="Abstract">arXiv:2403.01529</a> [<a href="/pdf/2403.01529" title="Download PDF">pdf</a>, <a href="/format/2403.01529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Incremental Model Based Reinforcement Learning: A One-Step Lookback  Approach for Continuous Robotics Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Model-based reinforcement learning (MBRL) attempts to use an available or a
learned model to improve the data efficiency of reinforcement learning. This
work proposes a one-step lookback approach that jointly learns the latent-space
model and the policy to realize the sample-efficient continuous robotic
control, wherein the control-theoretical knowledge is utilized to decrease the
model learning difficulty. Specifically, the so-called one-step backward data
is utilized to facilitate the incremental evolution model, an alternative
structured representation of the robotics evolution model in the MBRL field.
The incremental evolution model accurately predicts the robotics movement but
with low sample complexity. This is because the formulated incremental
evolution model degrades the model learning difficulty into a parametric matrix
learning problem, which is especially favourable to high-dimensional robotics
applications. The imagined data from the learned incremental evolution model is
used to supplement training data to enhance the sample efficiency. Comparative
numerical simulations on benchmark continuous robotics control problems are
conducted to validate the efficiency of our proposed one-step lookback
approach.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01533" title="Abstract">arXiv:2403.01533</a> [<a href="/pdf/2403.01533" title="Download PDF">pdf</a>, <a href="/ps/2403.01533" title="Download PostScript">ps</a>, <a href="/format/2403.01533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning predicts long-term mortality after acute myocardial  infarction using systolic time intervals and routinely collected clinical  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roodini%2C+B">Bijan Roodini</a>, 
<a href="/search/cs?searchtype=author&query=Khajehpiri%2C+B">Boshra Khajehpiri</a>, 
<a href="/search/cs?searchtype=author&query=Moghaddam%2C+a+A">amid Abrishami Moghaddam</a>, 
<a href="/search/cs?searchtype=author&query=Forouzanfar%2C+M">Mohamad Forouzanfar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in "Intelligent Medicine"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Precise estimation of cardiac patients' current and future comorbidities is
an important factor in prioritizing continuous physiological monitoring and new
therapies. ML models have shown satisfactory performance in short-term
mortality prediction of patients with heart disease, while their utility in
long-term predictions is limited. This study aims to investigate the
performance of tree-based ML models on long-term mortality prediction and the
effect of two recently introduced biomarkers on long-term mortality. This study
utilized publicly available data from CCHIA at the Ministry of Health and
Welfare, Taiwan, China. Medical records were used to gather demographic and
clinical data, including age, gender, BMI, percutaneous coronary intervention
(PCI) status, and comorbidities such as hypertension, dyslipidemia, ST-segment
elevation myocardial infarction (STEMI), and non-STEMI. Using medical and
demographic records as well as two recently introduced biomarkers, brachial
pre-ejection period (bPEP) and brachial ejection time (bET), collected from 139
patients with acute myocardial infarction, we investigated the performance of
advanced ensemble tree-based ML algorithms (random forest, AdaBoost, and
XGBoost) to predict all-cause mortality within 14 years. The developed ML
models achieved significantly better performance compared to the baseline LR
(C-Statistic, 0.80 for random forest, 0.79 for AdaBoost, and 0.78 for XGBoost,
vs 0.77 for LR) (P-RF&lt;0.001, PAdaBoost&lt;0.001, PXGBoost&lt;0.05). Adding bPEP and
bET to our feature set significantly improved the algorithms' performance,
leading to an absolute increase in C-Statistic of up to 0.03 (C-Statistic, 0.83
for random forest, 0.82 for AdaBoost, and 0.80 for XGBoost, vs 0.74 for LR)
(P-RF&lt;0.001, PAdaBoost&lt;0.001, PXGBoost&lt;0.05). This advancement may enable
better treatment prioritization for high-risk individuals.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01534" title="Abstract">arXiv:2403.01534</a> [<a href="/pdf/2403.01534" title="Download PDF">pdf</a>, <a href="/ps/2403.01534" title="Download PostScript">ps</a>, <a href="/format/2403.01534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional normality and finite-state dimensions revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+A">Alexander Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">The notion of a normal bit sequence was introduced by Borel in 1909; it was
the first definition of an individual random object. Normality is a weak notion
of randomness requiring only that all $2^n$ factors (substrings) of arbitrary
length~$n$ appear with the same limit frequency $2^{-n}$. Later many stronger
definitions of randomness were introduced, and in this context normality found
its place as ``randomness against a finite-memory adversary''. A quantitative
measure of finite-state compressibility was also introduced (the finite-state
dimension) and normality means that the finite state dimension is maximal
(equals~$1$).
<br />Recently Nandakumar, Pulari and S (2023) introduced the notion of relative
finite-state dimension for a binary sequence with respect to some other binary
sequence (treated as an oracle), and the corresponding notion of conditional
(relative) normality. (Different notions of conditional randomness were
considered before, but not for the finite memory case.) They establish
equivalence between the block frequency and the gambling approaches to
conditional normality and finite-state dimensions.
<br />In this note we revisit their definitions and explain how this equivalence
can be obtained easily by generalizing known characterizations of
(unconditional) normality and dimension in terms of compressibility
(finite-state complexity), superadditive complexity measures and gambling
(finite-state gales), thus also answering some questions left open in the
above-mentioned paper.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01535" title="Abstract">arXiv:2403.01535</a> [<a href="/pdf/2403.01535" title="Download PDF">pdf</a>, <a href="/format/2403.01535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Graph Generator: Feature-Conditioned Graph Generation using  Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evdaimon%2C+I">Iakovos Evdaimon</a>, 
<a href="/search/cs?searchtype=author&query=Nikolentzos%2C+G">Giannis Nikolentzos</a>, 
<a href="/search/cs?searchtype=author&query=Chatzianastasis%2C+M">Michail Chatzianastasis</a>, 
<a href="/search/cs?searchtype=author&query=Abdine%2C+H">Hadi Abdine</a>, 
<a href="/search/cs?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph generation has emerged as a crucial task in machine learning, with
significant challenges in generating graphs that accurately reflect specific
properties. Existing methods often fall short in efficiently addressing this
need as they struggle with the high-dimensional complexity and varied nature of
graph properties. In this paper, we introduce the Neural Graph Generator (NGG),
a novel approach which utilizes conditioned latent diffusion models for graph
generation. NGG demonstrates a remarkable capacity to model complex graph
patterns, offering control over the graph generation process. NGG employs a
variational graph autoencoder for graph compression and a diffusion process in
the latent vector space, guided by vectors summarizing graph statistics. We
demonstrate NGG's versatility across various graph generation tasks, showing
its capability to capture desired graph properties and generalize to unseen
graphs. This work signifies a significant shift in graph generation
methodologies, offering a more practical and efficient solution for generating
diverse types of graphs with specific characteristics.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01536" title="Abstract">arXiv:2403.01536</a> [<a href="/pdf/2403.01536" title="Download PDF">pdf</a>, <a href="/format/2403.01536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Ergodic Search with Kernel Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Muchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gaggar%2C+A">Ayush Gaggar</a>, 
<a href="/search/cs?searchtype=author&query=Trautman%2C+P">Peter Trautman</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T">Todd Murphey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ergodic search enables optimal exploration of an information distribution
while guaranteeing the asymptotic coverage of the search space. However,
current methods typically have exponential computation complexity in the search
space dimension and are restricted to Euclidean space. We introduce a
computationally efficient ergodic search method. Our contributions are
two-fold. First, we develop a kernel-based ergodic metric and generalize it
from Euclidean space to Lie groups. We formally prove the proposed metric is
consistent with the standard ergodic metric while guaranteeing linear
complexity in the search space dimension. Secondly, we derive the first-order
optimality condition of the kernel ergodic metric for nonlinear systems, which
enables efficient trajectory optimization. Comprehensive numerical benchmarks
show that the proposed method is at least two orders of magnitude faster than
the state-of-the-art algorithm. Finally, we demonstrate the proposed algorithm
with a peg-in-hole insertion task. We formulate the problem as a coverage task
in the space of SE(3) and use a 30-second-long human demonstration as the prior
distribution for ergodic coverage. Ergodicity guarantees the asymptotic
solution of the peg-in-hole problem so long as the solution resides within the
prior information distribution, which is seen in the 100\% success rate.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01537" title="Abstract">arXiv:2403.01537</a> [<a href="/pdf/2403.01537" title="Download PDF">pdf</a>, <a href="/format/2403.01537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Strategy Nash Equilibrium for Crowd Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Muchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+F">Francesca Baldini</a>, 
<a href="/search/cs?searchtype=author&query=Trautman%2C+P">Peter Trautman</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T">Todd Murphey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We address the problem of finding mixed-strategy Nash equilibrium for crowd
navigation. Mixed-strategy Nash equilibrium provides a rigorous model for the
robot to anticipate uncertain yet cooperative human behavior in crowds, but the
computation cost is often too high for scalable and real-time decision-making.
Here we prove that a simple iterative Bayesian updating scheme converges to the
Nash equilibrium of a mixed-strategy social navigation game. Furthermore, we
propose a data-driven framework to construct the game by initializing agent
strategies as Gaussian processes learned from human datasets. Based on the
proposed mixed-strategy Nash equilibrium model, we develop a sampling-based
crowd navigation framework that can be integrated into existing navigation
methods and runs in real-time on a laptop CPU. We evaluate our framework in
both simulated environments and real-world human datasets in unstructured
environments. Our framework consistently outperforms both non-learning and
learning-based methods on both safety and navigation efficiency and reaches
human-level crowd navigation performance on top of a meta-planner.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01538" title="Abstract">arXiv:2403.01538</a> [<a href="/pdf/2403.01538" title="Download PDF">pdf</a>, <a href="/ps/2403.01538" title="Download PostScript">ps</a>, <a href="/format/2403.01538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Preliminary Exploration of the Disruption of a Generative AI Systems:  Faculty/Staff and Student Perceptions of ChatGPT and its Capability of  Completing Undergraduate Engineering Coursework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+L">Lance White</a>, 
<a href="/search/cs?searchtype=author&query=Balart%2C+T">Trini Balart</a>, 
<a href="/search/cs?searchtype=author&query=Amani%2C+S">Sara Amani</a>, 
<a href="/search/cs?searchtype=author&query=Shryock%2C+D+K+J">Dr. Kristi J. Shryock</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+D+K+L">Dr. Karan L. Watson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The authors of this study aim to assess the capabilities of the OpenAI
ChatGPT tool to understand just how effective such a system might be for
students to utilize in their studies as well as deepen understanding of
faculty/staff and student perceptions about ChatGPT in general. The purpose of
what is learned from the study is to continue the design of a model to
facilitate the development of faculty for becoming adept at embracing change,
the DANCE model (Designing Adaptations for the Next Changes in Education). This
model is used in this study to help faculty with examining the impact that a
disruptive new tool, such as ChatGPT, can pose for the learning environment.
<br />The authors analyzed the performance of ChatGPT used to complete course
assignments at a variety of levels by novice engineering students working as
research assistants. Those completed works have been assessed by the faculty
who created those assignments to understand how these completed assignments
might compare with the performance of a typical student. A set of surveys
conducted by the authors of this work are discussed where students, faculty,
and staff respondents in March of 2023 addressed their perceptions of ChatGPT
(A follow-up survey is being administered now, February 2024). These survey
instruments were analyzed, and the data visualized in this work to bring
attention to relevant findings by the researchers. This work reports the
findings of the researchers with the purpose of sharing the current state of
this work at Texas A&amp;M University with the intention to provide insights to
scholars both at our own institution and around the world. This work is not
intended to be a finished work but reports these findings with full
transparency that this work is currently continuing as the researchers gather
new data and develop and validate various measurement instruments.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01540" title="Abstract">arXiv:2403.01540</a> [<a href="/pdf/2403.01540" title="Download PDF">pdf</a>, <a href="/format/2403.01540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized Hierarchical Federated Learning: A Robust Approach to  Statistical Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azimi-Abarghouyi%2C+S+M">Seyed Mohammad Azimi-Abarghouyi</a>, 
<a href="/search/cs?searchtype=author&query=Fodor%2C+V">Viktoria Fodor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper presents a novel hierarchical federated learning algorithm within
multiple sets that incorporates quantization for communication-efficiency and
demonstrates resilience to statistical heterogeneity. Unlike conventional
hierarchical federated learning algorithms, our approach combines gradient
aggregation in intra-set iterations with model aggregation in inter-set
iterations. We offer a comprehensive analytical framework to evaluate its
optimality gap and convergence rate, comparing these aspects with those of
conventional algorithms. Additionally, we develop a problem formulation to
derive optimal system parameters in a closed-form solution. Our findings reveal
that our algorithm consistently achieves high learning accuracy over a range of
parameters and significantly outperforms other hierarchical algorithms,
particularly in scenarios with heterogeneous data distributions.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01542" title="Abstract">arXiv:2403.01542</a> [<a href="/pdf/2403.01542" title="Download PDF">pdf</a>, <a href="/format/2403.01542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Robot Pacing Mismatch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Muchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Trautman%2C+P">Peter Trautman</a>, 
<a href="/search/cs?searchtype=author&query=Murphey%2C+T">Todd Murphey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2022 Robotics: Science and Systems (RSS) Workshop in Close Proximity Human-Robot Collaboration
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">A widely accepted explanation for robots planning overcautious or
overaggressive trajectories alongside human is that the crowd density exceeds a
threshold such that all feasible trajectories are considered unsafe -- the
freezing robot problem. However, even with low crowd density, the robot's
navigation performance could still drop drastically when in close proximity to
human. In this work, we argue that a broader cause of suboptimal navigation
performance near human is due to the robot's misjudgement for the human's
willingness (flexibility) to share space with others, particularly when the
robot assumes the human's flexibility holds constant during interaction, a
phenomenon of what we call human robot pacing mismatch. We show that the
necessary condition for solving pacing mismatch is to model the evolution of
both the robot and the human's flexibility during decision making, a strategy
called distribution space modeling. We demonstrate the advantage of
distribution space coupling through an anecdotal case study and discuss the
future directions of solving human robot pacing mismatch.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01543" title="Abstract">arXiv:2403.01543</a> [<a href="/pdf/2403.01543" title="Download PDF">pdf</a>, <a href="/format/2403.01543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Action Counting with Dynamic Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zishi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Q">Qiuyan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ci%2C+H">Hai Ci</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code: <a href="https://github.com/lizishi/DeTRC">this https URL</a>, proj page: <a href="https://shirleymaxx.github.io/DeTRC/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Temporal repetition counting aims to quantify the repeated action cycles
within a video. The majority of existing methods rely on the similarity
correlation matrix to characterize the repetitiveness of actions, but their
scalability is hindered due to the quadratic computational complexity. In this
work, we introduce a novel approach that employs an action query representation
to localize repeated action cycles with linear computational complexity. Based
on this representation, we further develop two key components to tackle the
essential challenges of temporal repetition counting. Firstly, to facilitate
open-set action counting, we propose the dynamic update scheme on action
queries. Unlike static action queries, this approach dynamically embeds video
features into action queries, offering a more flexible and generalizable
representation. Secondly, to distinguish between actions of interest and
background noise actions, we incorporate inter-query contrastive learning to
regularize the video representations corresponding to different action queries.
As a result, our method significantly outperforms previous works, particularly
in terms of long video sequences, unseen actions, and actions at various
speeds. On the challenging RepCountA benchmark, we outperform the
state-of-the-art method TransRAC by 26.5% in OBO accuracy, with a 22.7% mean
error decrease and 94.1% computational burden reduction. Code is available at
https://github.com/lizishi/DeTRC.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01545" title="Abstract">arXiv:2403.01545</a> [<a href="/pdf/2403.01545" title="Download PDF">pdf</a>, <a href="/ps/2403.01545" title="Download PostScript">ps</a>, <a href="/format/2403.01545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It Takes a Village: A Distributed Training Model for AI-based Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Estes%2C+C">Colleen Estes</a>, 
<a href="/search/cs?searchtype=author&query=Twomey%2C+B">Beth Twomey</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A">Annie Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">In Summer 2023, staff from the information technology and reference
departments at the University of Delaware Library, Museums and Press came
together in a unique partnership to pilot a low-cost AI-powered chatbot. The
goal of the pilot is to learn more about student and faculty interest in
engaging with this tool, and to better understand the labor required on the
staff side. Reference librarians and other public facing staff, including
student workers, were instrumental in helping to train the chatbot. This
article discusses the development of prompts, leveraging of existing data
sources for training materials, and workflows involved in the pilot. It argues
that, when implementing AI-based tools in the academic library, involving staff
from across the organization is essential to ensure buy-in and success.
Although chatbots are designed to hide the effort of the people behind them,
such labor can be substantial and needs to be recognized.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01546" title="Abstract">arXiv:2403.01546</a> [<a href="/pdf/2403.01546" title="Download PDF">pdf</a>, <a href="/format/2403.01546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Image Analysis in Single-Modal and Multimodal setting  using Deep Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pande%2C+S">Shivam Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 253 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hyperspectral imaging provides precise classification for land use and cover
due to its exceptional spectral resolution. However, the challenges of high
dimensionality and limited spatial resolution hinder its effectiveness. This
study addresses these challenges by employing deep learning techniques to
efficiently process, extract features, and classify data in an integrated
manner. To enhance spatial resolution, we integrate information from
complementary modalities such as LiDAR and SAR data through multimodal
learning. Moreover, adversarial learning and knowledge distillation are
utilized to overcome issues stemming from domain disparities and missing
modalities. We also tailor deep learning architectures to suit the unique
characteristics of HSI data, utilizing 1D convolutional and recurrent neural
networks to handle its continuous spectral dimension. Techniques like visual
attention and feedback connections within the architecture bolster the
robustness of feature extraction. Additionally, we tackle the issue of limited
training samples through self-supervised learning methods, employing
autoencoders for dimensionality reduction and exploring semi-supervised
learning techniques that leverage unlabeled data. Our proposed approaches are
evaluated across various HSI datasets, consistently outperforming existing
state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01547" title="Abstract">arXiv:2403.01547</a> [<a href="/pdf/2403.01547" title="Download PDF">pdf</a>, <a href="/format/2403.01547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructions of Control Sequence Set for Hierarchical Access in Data  Link Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xianhua%2C+N">Niu Xianhua</a>, 
<a href="/search/cs?searchtype=author&query=Jiabei%2C+M">Ma Jiabei</a>, 
<a href="/search/cs?searchtype=author&query=Enzhi%2C+Z">Zhou Enzhi</a>, 
<a href="/search/cs?searchtype=author&query=Yaoxuan%2C+W">Wang Yaoxuan</a>, 
<a href="/search/cs?searchtype=author&query=Bosen%2C+Z">Zeng Bosen</a>, 
<a href="/search/cs?searchtype=author&query=Zhiping%2C+L">Li Zhiping</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Time slots are a valuable channel resource in the data link network with time
division multiple access architecture. The need for finding a secure and
efficient way to meet the requirements of large access capacity, differentiated
access, maximum utilization of time slot resource and strong anti-eavesdropping
ability in data link networks is well motivated.In this paper, a control
sequence-based hierarchical access control scheme is proposed, which not only
achieves differentiated time slots allocation for the different needs and
levels of nodes, but also enhances randomness and anti-interception performance
in data link networks.Based on the scheme, a new theoretical bound is derived
to characterize parameter relationships for designing optimal hierarchical
control sequence(HCS) set. Moreover, two flexible classes of optimal
hierarchical control sequence sets are constructed.By our construction, the
terminal user in the data link can access hierarchically and randomly and
transmit data packets during its own hopping time slots of the successive
frames to prevent eavesdropping while maintaining high throughput.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01548" title="Abstract">arXiv:2403.01548</a> [<a href="/pdf/2403.01548" title="Download PDF">pdf</a>, <a href="/format/2403.01548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Sharpness as Alerts: An Inner Representation Perspective for  Hallucination Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+M">Miao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junteng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Teng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Siyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) frequently hallucinate and produce factual
errors, yet our understanding of why they make these errors remains limited. In
this study, we delve into the underlying mechanisms of LLM hallucinations from
the perspective of inner representations, and discover a salient pattern
associated with hallucinations: correct generations tend to have sharper
context activations in the hidden states of the in-context tokens, compared to
the incorrect ones. Leveraging this insight, we propose an entropy-based metric
to quantify the ``sharpness'' among the in-context hidden states and
incorporate it into the decoding process to formulate a constrained decoding
approach. Experiments on various knowledge-seeking and hallucination benchmarks
demonstrate our approach's consistent effectiveness, for example, achieving up
to an 8.6 point improvement on TruthfulQA. We believe this study can improve
our understanding of hallucinations and serve as a practical solution for
hallucination mitigation.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01549" title="Abstract">arXiv:2403.01549</a> [<a href="/pdf/2403.01549" title="Download PDF">pdf</a>, <a href="/format/2403.01549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Representation Learning with Meta Comprehensive  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huijie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+Y">Ying Ba</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lingyu Si</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-Supervised Learning (SSL) methods harness the concept of semantic
invariance by utilizing data augmentation strategies to produce similar
representations for different deformations of the same input. Essentially, the
model captures the shared information among multiple augmented views of
samples, while disregarding the non-shared information that may be beneficial
for downstream tasks. To address this issue, we introduce a module called
CompMod with Meta Comprehensive Regularization (MCR), embedded into existing
self-supervised frameworks, to make the learned representations more
comprehensive. Specifically, we update our proposed model through a bi-level
optimization mechanism, enabling it to capture comprehensive features.
Additionally, guided by the constrained extraction of features using maximum
entropy coding, the self-supervised learning model learns more comprehensive
features on top of learning consistent features. In addition, we provide
theoretical support for our proposed method from information theory and causal
counterfactual perspective. Experimental results show that our method achieves
significant improvement in classification, object detection and instance
segmentation tasks on multiple benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01554" title="Abstract">arXiv:2403.01554</a> [<a href="/pdf/2403.01554" title="Download PDF">pdf</a>, <a href="/format/2403.01554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers for Supervised Online Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bornschein%2C+J">Jorg Bornschein</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yazhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Rannen-Triki%2C+A">Amal Rannen-Triki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformers have become the dominant architecture for sequence modeling
tasks such as natural language processing or audio processing, and they are now
even considered for tasks that are not naturally sequential such as image
classification. Their ability to attend to and to process a set of tokens as
context enables them to develop in-context few-shot learning abilities.
However, their potential for online continual learning remains relatively
unexplored. In online continual learning, a model must adapt to a
non-stationary stream of data, minimizing the cumulative nextstep prediction
loss. We focus on the supervised online continual learning setting, where we
learn a predictor $x_t \rightarrow y_t$ for a sequence of examples $(x_t,
y_t)$. Inspired by the in-context learning capabilities of transformers and
their connection to meta-learning, we propose a method that leverages these
strengths for online continual learning. Our approach explicitly conditions a
transformer on recent observations, while at the same time online training it
with stochastic gradient descent, following the procedure introduced with
Transformer-XL. We incorporate replay to maintain the benefits of multi-epoch
training while adhering to the sequential protocol. We hypothesize that this
combination enables fast adaptation through in-context learning and sustained
longterm improvement via parametric learning. Our method demonstrates
significant improvements over previous state-of-the-art results on CLOC, a
challenging large-scale real-world benchmark for image geo-localization.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01558" title="Abstract">arXiv:2403.01558</a> [<a href="/pdf/2403.01558" title="Download PDF">pdf</a>, <a href="/format/2403.01558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt or Wait: Quality Adaptation for Cache-aided Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lampiris%2C+E">Eleftherios Lampiris</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Transactions on Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This work focuses on quality adaptation as a means to counter the effects of
channel degradation in wireless, cache- aided channels. We design a delivery
scheme which combines coded caching, superposition coding, and scalable source
coding, while keeping the caching scheme oblivious to channel qualities. By
properly adjusting the quality at the degraded users we are able to satisfy all
demands in a time-efficient manner. In addition, superposition coding allows us
to serve high-rate users with high content quality without subjecting them to a
delay penalty caused by users with lower rate channels. We design a
communication framework that covers all possible channel rate and quality
configurations and we further provide algorithms that can optimise the served
quality. An interesting outcome of this work is that a modest quality reduction
at the degraded users can counter the effects of significant channel
degradation. For example, in a 100-user system with normalized cache size 1/10
at each user, if 10 users experience channel degradation of 60% compared to the
rate of the non-degraded users, we show that our transmission strategy leads to
a 85% quality at the degraded users and perfect quality at the non-degraded
users.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01560" title="Abstract">arXiv:2403.01560</a> [<a href="/pdf/2403.01560" title="Download PDF">pdf</a>, <a href="/format/2403.01560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking CLIP-based Video Learners in Cross-Domain Open-Vocabulary  Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kun-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiaming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yi-Xing Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Language-Image Pretraining (CLIP) has shown remarkable
open-vocabulary abilities across various image understanding tasks. Building
upon this impressive success, recent pioneer works have proposed to adapt the
powerful CLIP to video data, leading to efficient and effective video learners
for open-vocabulary action recognition. Inspired by the fact that humans
perform actions in diverse environments, our work delves into an intriguing
question: Can CLIP-based video learners effectively generalize to video domains
they have not encountered during training? To answer this, we establish a
CROSS-domain Open-Vocabulary Action recognition benchmark named XOV-Action, and
conduct a comprehensive evaluation of five state-of-the-art CLIP-based video
learners under various types of domain gaps. Our evaluation demonstrates that
previous methods exhibit limited action recognition performance in unseen video
domains, revealing potential challenges of the cross-domain open-vocabulary
action recognition task. To address this task, our work focuses on a critical
challenge, namely scene bias, and we accordingly contribute a novel scene-aware
video-text alignment method. Our key idea is to distinguish video
representations apart from scene-encoded text representations, aiming to learn
scene-agnostic video representations for recognizing actions across domains.
Extensive experimental results demonstrate the effectiveness of our method. The
benchmark and code will be available at
https://github.com/KunyuLin/XOV-Action/.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01564" title="Abstract">arXiv:2403.01564</a> [<a href="/pdf/2403.01564" title="Download PDF">pdf</a>, <a href="/format/2403.01564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking  with Limited Active Localization Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puthumanaillam%2C+G">Gokul Puthumanaillam</a>, 
<a href="/search/cs?searchtype=author&query=Vora%2C+M">Manav Vora</a>, 
<a href="/search/cs?searchtype=author&query=Ornik%2C+M">Melkior Ornik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> * Equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Optimal decision-making for trajectory tracking in partially observable,
stochastic environments where the number of active localization updates -- the
process by which the agent obtains its true state information from the sensors
-- are limited, presents a significant challenge. Traditional methods often
struggle to balance resource conservation, accurate state estimation and
precise tracking, resulting in suboptimal performance. This problem is
particularly pronounced in environments with large action spaces, where the
need for frequent, accurate state data is paramount, yet the capacity for
active localization updates is restricted by external limitations. This paper
introduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN)
and Model Predictive Control (MPC) to optimize trajectory tracking with
constrained active localization updates. The meta-trained DQN ensures adaptive
active localization scheduling, while the MPC leverages available state
information to improve tracking. The central contribution of this work is their
reciprocal interaction: DQN's update decisions inform MPC's control strategy,
and MPC's outcomes refine DQN's learning, creating a cohesive, adaptive system.
Empirical evaluations in simulated and real-world settings demonstrate that
ComTraQ-MPC significantly enhances operational efficiency and accuracy,
providing a generalizable and approximately optimal solution for trajectory
tracking in complex partially observable environments.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01566" title="Abstract">arXiv:2403.01566</a> [<a href="/pdf/2403.01566" title="Download PDF">pdf</a>, <a href="/format/2403.01566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive multiplication of $\mathcal{H}^2$-matrices with block-relative  error control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=B%C3%B6rm%2C+S">Steffen B&#xf6;rm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The discretization of non-local operators, e.g., solution operators of
partial differential equations or integral operators, leads to large densely
populated matrices. $\mathcal{H}^2$-matrices take advantage of local low-rank
structures in these matrices to provide an efficient data-sparse approximation
that allows us to handle large matrices efficiently, e.g., to reduce the
storage requirements to $\mathcal{O}(n k)$ for $n$-dimensional matrices with
local rank $k$, and to reduce the complexity of the matrix-vector
multiplication to $\mathcal{O}(n k)$ operations.
<br />In order to perform more advanced operations, e.g., to construct efficient
preconditioners or evaluate matrix functions, we require algorithms that take
$\mathcal{H}^2$-matrices as input and approximate the result again by
$\mathcal{H}^2$-matrices, ideally with controllable accuracy. In this
manuscript, we introduce an algorithm that approximates the product of two
$\mathcal{H}^2$-matrices and guarantees block-relative error estimates for the
submatrices of the result. It uses specialized tree structures to represent the
exact product in an intermediate step, thereby allowing us to apply
mathematically rigorous error control strategies.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01567" title="Abstract">arXiv:2403.01567</a> [<a href="/pdf/2403.01567" title="Download PDF">pdf</a>, <a href="/format/2403.01567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReMatch: Retrieval Enhanced Schema Matching with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheetrit%2C+E">Eitam Sheetrit</a>, 
<a href="/search/cs?searchtype=author&query=Brief%2C+M">Menachem Brief</a>, 
<a href="/search/cs?searchtype=author&query=Mishaeli%2C+M">Moshik Mishaeli</a>, 
<a href="/search/cs?searchtype=author&query=Elisha%2C+O">Oren Elisha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Schema matching is a crucial task in data integration, involving the
alignment of a source database schema with a target schema to establish
correspondence between their elements. This task is challenging due to textual
and semantic heterogeneity, as well as differences in schema sizes. Although
machine-learning-based solutions have been explored in numerous studies, they
often suffer from low accuracy, require manual mapping of the schemas for model
training, or need access to source schema data which might be unavailable due
to privacy concerns. In this paper we present a novel method, named ReMatch,
for matching schemas using retrieval-enhanced Large Language Models (LLMs). Our
method avoids the need for predefined mapping, any model training, or access to
data in the source database. In the ReMatch method the tables of the target
schema and the attributes of the source schema are first represented as
structured passage-based documents. For each source attribute document, we
retrieve $J$ documents, representing target schema tables, according to their
semantic relevance. Subsequently, we create a prompt for every source table,
comprising all its attributes and their descriptions, alongside all attributes
from the set of top $J$ target tables retrieved previously. We employ LLMs
using this prompt for the matching task, yielding a ranked list of $K$
potential matches for each source attribute. Our experimental results on large
real-world schemas demonstrate that ReMatch significantly improves matching
capabilities and outperforms other machine learning approaches. By eliminating
the requirement for training data, ReMatch becomes a viable solution for
real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01568" title="Abstract">arXiv:2403.01568</a> [<a href="/pdf/2403.01568" title="Download PDF">pdf</a>, <a href="/format/2403.01568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximations and Hardness of Packing Partially Ordered Items
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doron-Arad%2C+I">Ilan Doron-Arad</a>, 
<a href="/search/cs?searchtype=author&query=Kortsarz%2C+G">Guy Kortsarz</a>, 
<a href="/search/cs?searchtype=author&query=Naor%2C+J">Joseph Naor</a>, 
<a href="/search/cs?searchtype=author&query=Schieber%2C+B">Baruch Schieber</a>, 
<a href="/search/cs?searchtype=author&query=Shachnai%2C+H">Hadas Shachnai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Motivated by applications in production planning and storage allocation in
hierarchical databases, we initiate the study of covering partially ordered
items (CPO). Given a capacity $k \in \mathbb{Z}^+$, and a directed graph
$G=(V,E)$ where each vertex has a size in $\{0,1, \ldots,k\}$, we seek a
collection of subsets of vertices $S_1, \ldots, S_m$ that cover all the
vertices, such that for any $1 \leq j \leq m$, the total size of vertices in
$S_j$ is bounded by $k$, and there are no edges from $V \setminus S_j$ to
$S_j$. The objective is to minimize the number of subsets $m$. CPO is closely
related to the rule caching problem (RCP) that is of wide interest in the
networking area. The input for RCP is a directed graph $G=(V,E)$, a profit
function $p:V \rightarrow \mathbb{Z}_{0}^+$, and $k \in \mathbb{Z}^+$. The
output is a subset $S \subseteq V$ of maximum profit such that $|S| \leq k$ and
there are no edges from $V \setminus S$ to $S$.
<br />Our main result is a $2$-approximation algorithm for CPO on out-trees,
complemented by an asymptotic $1.5$-hardness of approximation result. We also
give a two-way reduction between RCP and the densest $k$-subhypergraph problem,
surprisingly showing that the problems are equivalent w.r.t. polynomial-time
approximation within any factor $\rho \geq 1$. This implies that RCP cannot be
approximated within factor $|V|^{1-\eps}$ for any fixed $\eps&gt;0$, under
standard complexity assumptions. Prior to this work, RCP was just known to be
strongly NP-hard. We further show that there is no EPTAS for the special case
of RCP where the profits are uniform, assuming Gap-ETH. Since this variant
admits a PTAS, we essentially resolve the complexity status of this problem.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01569" title="Abstract">arXiv:2403.01569</a> [<a href="/pdf/2403.01569" title="Download PDF">pdf</a>, <a href="/format/2403.01569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kick Back &amp; Relax++: Scaling Beyond Ground-Truth Depth with SlowTV &amp;  CribsTV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spencer%2C+J">Jaime Spencer</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+C">Chris Russell</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+S">Simon Hadfield</a>, 
<a href="/search/cs?searchtype=author&query=Bowden%2C+R">Richard Bowden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Self-supervised learning is the key to unlocking generic computer vision
systems. By eliminating the reliance on ground-truth annotations, it allows
scaling to much larger data quantities. Unfortunately, self-supervised
monocular depth estimation (SS-MDE) has been limited by the absence of diverse
training data. Existing datasets have focused exclusively on urban driving in
densely populated cities, resulting in models that fail to generalize beyond
this domain.
<br />To address these limitations, this paper proposes two novel datasets: SlowTV
and CribsTV. These are large-scale datasets curated from publicly available
YouTube videos, containing a total of 2M training frames. They offer an
incredibly diverse set of environments, ranging from snowy forests to coastal
roads, luxury mansions and even underwater coral reefs. We leverage these
datasets to tackle the challenging task of zero-shot generalization,
outperforming every existing SS-MDE approach and even some state-of-the-art
supervised methods.
<br />The generalization capabilities of our models are further enhanced by a range
of components and contributions: 1) learning the camera intrinsics, 2) a
stronger augmentation regime targeting aspect ratio changes, 3) support frame
randomization, 4) flexible motion estimation, 5) a modern transformer-based
architecture. We demonstrate the effectiveness of each component in extensive
ablation experiments. To facilitate the development of future research, we make
the datasets, code and pretrained models available to the public at
https://github.com/jspenmar/slowtv_monodepth.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01570" title="Abstract">arXiv:2403.01570</a> [<a href="/pdf/2403.01570" title="Download PDF">pdf</a>, <a href="/format/2403.01570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERVAL: Synergy Learning between Vertical Models and LLMs towards  Oracle-Level Zero-shot Medical Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiahuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jintai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chaowen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaojun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent development of large language models (LLMs) has exhibited impressive
zero-shot proficiency on generic and common sense questions. However, LLMs'
application on domain-specific vertical questions still lags behind, primarily
due to the humiliation problems and deficiencies in vertical knowledge.
Furthermore, the vertical data annotation process often requires
labor-intensive expert involvement, thereby presenting an additional challenge
in enhancing the model's vertical capabilities. In this paper, we propose
SERVAL, a synergy learning pipeline designed for unsupervised development of
vertical capabilities in both LLMs and small models by mutual enhancement.
Specifically, SERVAL utilizes the LLM's zero-shot outputs as annotations,
leveraging its confidence to teach a robust vertical model from scratch.
Reversely, the trained vertical model guides the LLM fine-tuning to enhance its
zero-shot capability, progressively improving both models through an iterative
process. In medical domain, known for complex vertical knowledge and costly
annotations, comprehensive experiments show that, without access to any gold
labels, SERVAL with the synergy learning of OpenAI GPT-3.5 and a simple model
attains fully-supervised competitive performance across ten widely used medical
datasets. These datasets represent vertically specialized medical diagnostic
scenarios (e.g., diabetes, heart diseases, COVID-19), highlighting the
potential of SERVAL in refining the vertical capabilities of LLMs and training
vertical models from scratch, all achieved without the need for annotations.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01572" title="Abstract">arXiv:2403.01572</a> [<a href="/pdf/2403.01572" title="Download PDF">pdf</a>, <a href="/format/2403.01572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deeply Embedded Wages: Navigating Digital Payments in Data Work
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Posada%2C+J">Julian Posada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Many of the world's workers rely on digital platforms for their income. In
Venezuela, a nation grappling with extreme inflation and where most of the
workforce is self-employed, data production platforms for machine learning have
emerged as a viable opportunity for many to earn a flexible income in US
dollars. Platform workers are deeply interconnected within a vast network of
firms and entities that act as intermediaries for wage payments in digital
currencies and its subsequent conversion to the national currency, the bolivar.
Past research on embeddedness has noted that being intertwined in multi-tiered
socioeconomic networks of companies and individuals can offer significant
rewards to social participants, while also connoting a particular set of
limitations. This paper furnishes qualitative evidence regarding how this deep
embeddedness impacts platform workers in Venezuela. Given the backdrop of a
national crisis and rampant hyperinflation, the perks of receiving wages
through various financial platforms include access to a more stable currency
and the ability to save and invest outside the national financial system.
However, relying on numerous digital and local intermediaries often diminishes
income due to transaction fees. Moreover, this introduces heightened financial
risks, particularly due to the unpredictable nature of cryptocurrencies as an
investment. The over-reliance on external financial platforms erodes worker
autonomy through power dynamics that lean in favor of the platforms that set
the transaction rules and prices. These findings present a multifaceted
perspective on deep embeddedness in platform labor, highlighting how the
rewards of financial intermediation often come at a substantial cost for the
workers in unstable situations, who are saddled with escalating financial
risks.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01575" title="Abstract">arXiv:2403.01575</a> [<a href="/pdf/2403.01575" title="Download PDF">pdf</a>, <a href="/format/2403.01575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SARD: A Human-AI Collaborative Story Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radwan%2C+A+Y">Ahmed Y. Radwan</a>, 
<a href="/search/cs?searchtype=author&query=Alasmari%2C+K+M">Khaled M. Alasmari</a>, 
<a href="/search/cs?searchtype=author&query=Abdulbagi%2C+O+A">Omar A. Abdulbagi</a>, 
<a href="/search/cs?searchtype=author&query=Alghamdi%2C+E+A">Emad A. Alghamdi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative artificial intelligence (GenAI) has ushered in a new era for
storytellers, providing a powerful tool to ignite creativity and explore
uncharted narrative territories. As technology continues to advance, the
synergy between human creativity and AI-generated content holds the potential
to redefine the landscape of storytelling. In this work, we propose SARD, a
drag-and-drop visual interface for generating a multi-chapter story using large
language models. Our evaluation of the usability of SARD and its creativity
support shows that while node-based visualization of the narrative may help
writers build a mental model, it exerts unnecessary mental overhead to the
writer and becomes a source of distraction as the story becomes more
elaborated. We also found that AI generates stories that are less lexically
diverse, irrespective of the complexity of the story. We identified some
patterns and limitations of our tool that can guide the development of future
human-AI co-writing tools.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01579" title="Abstract">arXiv:2403.01579</a> [<a href="/pdf/2403.01579" title="Download PDF">pdf</a>, <a href="/format/2403.01579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Continuous Benchmarking Infrastructure for High-Performance Computing  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alt%2C+C">Christoph Alt</a>, 
<a href="/search/cs?searchtype=author&query=Lanser%2C+M">Martin Lanser</a>, 
<a href="/search/cs?searchtype=author&query=Plewinski%2C+J">Jonas Plewinski</a>, 
<a href="/search/cs?searchtype=author&query=Janki%2C+A">Atin Janki</a>, 
<a href="/search/cs?searchtype=author&query=Klawonn%2C+A">Axel Klawonn</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6stler%2C+H">Harald K&#xf6;stler</a>, 
<a href="/search/cs?searchtype=author&query=Selzer%2C+M">Michael Selzer</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCde%2C+U">Ulrich R&#xfc;de</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">For scientific software, especially those used for large-scale simulations,
achieving good performance and efficiently using the available hardware
resources is essential. It is important to regularly perform benchmarks to
ensure the efficient use of hardware and software when systems are changing and
the software evolves. However, this can become quickly very tedious when many
options for parameters, solvers, and hardware architectures are available. We
present a continuous benchmarking strategy that automates benchmarking new code
changes on high-performance computing clusters. This makes it possible to track
how each code change affects the performance and how it evolves.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01580" title="Abstract">arXiv:2403.01580</a> [<a href="/pdf/2403.01580" title="Download PDF">pdf</a>, <a href="/format/2403.01580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Neural Machine Translation of Low-Resource Languages: Corpus  Development, Human Evaluation and Explainable AI Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
<br />The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
<br />Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01582" title="Abstract">arXiv:2403.01582</a> [<a href="/pdf/2403.01582" title="Download PDF">pdf</a>, <a href="/format/2403.01582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Model-Agnostic Multi-Source-Free Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jiangbo Pei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingchao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-Source-Free Unsupervised Domain Adaptation (MSFDA) aims to transfer
knowledge from multiple well-labeled source domains to an unlabeled target
domain, using source models instead of source data. Existing MSFDA methods
limited that each source domain provides only a single model, with a uniform
structure. This paper introduces a new MSFDA setting: Model-Agnostic
Multi-Source-Free Unsupervised Domain Adaptation (MMDA), allowing diverse
source models with varying architectures, without quantitative restrictions.
While MMDA holds promising potential, incorporating numerous source models
poses a high risk of including undesired models, which highlights the source
model selection problem. To address it, we first provide a theoretical analysis
of this problem. We reveal two fundamental selection principles:
transferability principle and diversity principle, and introduce a selection
algorithm to integrate them. Then, considering the measure of transferability
is challenging, we propose a novel Source-Free Unsupervised Transferability
Estimation (SUTE). This novel formulation enables the assessment and comparison
of transferability across multiple source models with different architectures
in the context of domain shift, without requiring access to any target labels
or source data. Based on the above, we introduce a new framework to address
MMDA. Specifically, we first conduct source model selection based on the
proposed selection principles. Subsequently, we design two modules to aggregate
knowledge from included models and recycle useful knowledge from excluded
models. These modules enable us to leverage source knowledge efficiently and
effectively, thereby supporting us in learning a discriminative target model
via adaptation. We validate the effectiveness of our method through numerous
experimental results, and demonstrate that our approach achieves
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01586" title="Abstract">arXiv:2403.01586</a> [<a href="/pdf/2403.01586" title="Download PDF">pdf</a>, <a href="/format/2403.01586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoT Device Labeling Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyuhas%2C+B">Bar Meyuhas</a>, 
<a href="/search/cs?searchtype=author&query=Bremler-Barr%2C+A">Anat Bremler-Barr</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+T">Tal Shapira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The IoT market is diverse and characterized by a multitude of vendors that
support different device functions (e.g., speaker, camera, vacuum cleaner,
etc.). Within this market, IoT security and observability systems use real-time
identification techniques to manage these devices effectively. Most existing
IoT identification solutions employ machine learning techniques that assume the
IoT device, labeled by both its vendor and function, was observed during their
training phase. We tackle a key challenge in IoT labeling: how can an AI
solution label an IoT device that has never been seen before and whose label is
unknown?
<br />Our solution extracts textual features such as domain names and hostnames
from network traffic, and then enriches these features using Google search data
alongside catalog of vendors and device functions. The solution also integrates
an auto-update mechanism that uses Large Language Models (LLMs) to update these
catalogs with emerging device types. Based on the information gathered, the
device's vendor is identified through string matching with the enriched
features. The function is then deduced by LLMs and zero-shot classification
from a predefined catalog of IoT functions.
<br />In an evaluation of our solution on 97 unique IoT devices, our function
labeling approach achieved HIT1 and HIT2 scores of 0.7 and 0.77, respectively.
As far as we know, this is the first research to tackle AI-automated IoT
labeling.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01587" title="Abstract">arXiv:2403.01587</a> [<a href="/pdf/2403.01587" title="Download PDF">pdf</a>, <a href="/format/2403.01587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring the Seismic Behavior of a Scaled RC Frame with Intermediate  Ductility in a Shaking Table Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasef%2C+M">Mohammad Vasef</a>, 
<a href="/search/cs?searchtype=author&query=Marefat%2C+M+S">Mohammad Sadegh Marefat</a>, 
<a href="/search/cs?searchtype=author&query=Shid-Moosavi%2C+S">Sina Shid-Moosavi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P+%22">Peng &quot;Patrick&quot; Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8th World Conference on Structural Control and Monitoring (8WCSCM), Orlando, FL. (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">One of the commonly used seismic force-resisting systems in structures is
Reinforced Concrete (RC) Intermediate Moment Frames (IMF). Although using the
IMF is not allowed in high seismic hazard zones according to ASCE 7-10, it is
permitted in both Iran's 2800 Seismic Standard and New Zealand's Seismic Code.
This study investigates the seismic behavior of a reinforced concrete IMF
subjected to earthquake excitations using shaking table tests on a 2D RC
structural model which is designed under the regulations of ACI318-19. The
scale factor of 1/2.78 is selected for the frame fabrication due to the size
limit of the shaking table. The constructed model has three stories with a
height as 115 cm for each story, the clear length of beams as 151 cm, and
cross-sectional dimensions of columns and beams as 11 $\times$ 11 cm and 12
$\times$ 11 cm, respectively. The whole structure is supported by a foundation
that is 173 cm long, 52 cm wide, and 22 cm deep. Columns and beams are
reinforced with 8 mm diameter longitudinal ribbed bars and stirrups with 6 mm
diameter. The tests are conducted in stages with increasing peak ground
acceleration (PGA) till the failure of the frame. Sarpol-E-Zahab earthquake
seismic record is adopted for the experiment. The structural responses (e.g.,
displacements, longitudinal bars' strain, crack propagation, accelerations) are
monitored during the test using both conventional sensors and vison-based
sensors. As a comparative study, both conventional sensors and computer vision
techniques are used to monitor the health state and to analyze the structural
dynamics of the scaled RC frame structure.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01590" title="Abstract">arXiv:2403.01590</a> [<a href="/pdf/2403.01590" title="Download PDF">pdf</a>, <a href="/format/2403.01590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hidden Attention of Mamba Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Ameen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Zimerman%2C+I">Itamar Zimerman</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The Mamba layer offers an efficient selective state space model (SSM) that is
highly effective in modeling multiple domains including NLP, long-range
sequences processing, and computer vision. Selective SSMs are viewed as dual
models, in which one trains in parallel on the entire sequence via IO-aware
parallel scan, and deploys in an autoregressive manner. We add a third view and
show that such models can be viewed as attention-driven models. This new
perspective enables us to compare the underlying mechanisms to that of the
self-attention layers in transformers and allows us to peer inside the inner
workings of the Mamba model with explainability methods. Our code is publicly
available.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01594" title="Abstract">arXiv:2403.01594</a> [<a href="/pdf/2403.01594" title="Download PDF">pdf</a>, <a href="/format/2403.01594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never Tell the Trick: Covert Interactive Mixed Reality System for  Immersive Storytelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chanwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+K">Kyubeom Shim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Sanggyo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+G">Gwonu Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yongsoon Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented in IEEE VR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study explores the integration of Ultra-Wideband (UWB) technology into
Mixed Reality (MR) Systems for immersive storytelling. Addressing the
limitations of existing technologies like Microsoft Kinect and HTC Vive, the
research focuses on overcoming challenges in robustness to occlusion, tracking
volume, and cost efficiency in props tracking. Utilizing UWB technology, the
interactive MR system enhances the scope of performance art by enabling larger
tracking areas, more reliable and cheaper multi-prop tracking, and reducing
occlusion issues. Preliminary user tests suggest meaningful improvements in
immersive experience, promising a new possibility in Extended Reality (XR)
theater, performance art and immersive game.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01596" title="Abstract">arXiv:2403.01596</a> [<a href="/pdf/2403.01596" title="Download PDF">pdf</a>, <a href="/ps/2403.01596" title="Download PostScript">ps</a>, <a href="/format/2403.01596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Near Field Computation in the MLFMA Algorithm with Data  Redundancy and Performance Modeling on a Single GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+M">Morteza Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Torabi%2C+A">Abdolreza Torabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The Multilevel Fast Multipole Algorithm (MLFMA) has known applications in
scientific modeling in the fields of telecommunications, physics, mechanics,
and chemistry. Accelerating calculation of far-field using GPUs and GPU
clusters for large-scale problems has been studied for more than a decade. The
acceleration of the Near Field Computation (P2P operator) however was less of a
concern because it does not face the challenges of distributed processing which
does far field. This article proposes a modification of the P2P algorithm and
uses performance models to determine its optimality criteria. By modeling the
speedup, we found that making threads independence by creating redundancy in
the data makes the algorithm for lower dense (higher frequency) problems nearly
13 times faster than non-redundant mode.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01599" title="Abstract">arXiv:2403.01599</a> [<a href="/pdf/2403.01599" title="Download PDF">pdf</a>, <a href="/format/2403.01599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yulei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the problem of procedure planning in instructional videos, which
aims to make a goal-oriented sequence of action steps given partial visual
state observations. The motivation of this problem is to learn a structured and
plannable state and action space. Recent works succeeded in sequence modeling
of steps with only sequence-level annotations accessible during training, which
overlooked the roles of states in the procedures. In this work, we point out
that State CHangEs MAtter (SCHEMA) for procedure planning in instructional
videos. We aim to establish a more structured state space by investigating the
causal relations between steps and states in procedures. Specifically, we
explicitly represent each step as state changes and track the state changes in
procedures. For step representation, we leveraged the commonsense knowledge in
large language models (LLMs) to describe the state changes of steps via our
designed chain-of-thought prompting. For state change tracking, we align visual
state observations with language state descriptions via cross-modal contrastive
learning, and explicitly model the intermediate states of the procedure using
LLM-generated state descriptions. Experiments on CrossTask, COIN, and NIV
benchmark datasets demonstrate that our proposed SCHEMA model achieves
state-of-the-art performance and obtains explainable visualizations.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01600" title="Abstract">arXiv:2403.01600</a> [<a href="/pdf/2403.01600" title="Download PDF">pdf</a>, <a href="/format/2403.01600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model  for Policy Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aguilera%2C+A">Alba Aguilera</a>, 
<a href="/search/cs?searchtype=author&query=Montes%2C+N">Nieves Montes</a>, 
<a href="/search/cs?searchtype=author&query=Curto%2C+G">Georgina Curto</a>, 
<a href="/search/cs?searchtype=author&query=Sierra%2C+C">Carles Sierra</a>, 
<a href="/search/cs?searchtype=author&query=Osman%2C+N">Nardine Osman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the last decades, there has been a deceleration in the rates of poverty
reduction, suggesting that traditional redistributive approaches to poverty
mitigation could be losing effectiveness, and alternative insights to advance
the number one UN Sustainable Development Goal are required. The
criminalization of poor people has been denounced by several NGOs, and an
increasing number of voices suggest that discrimination against the poor (a
phenomenon known as \emph{aporophobia}) could be an impediment to mitigating
poverty. In this paper, we present the novel Aporophobia Agent-Based Model
(AABM) to provide evidence of the correlation between aporophobia and poverty
computationally. We present our use case built with real-world demographic data
and poverty-mitigation public policies (either enforced or under parliamentary
discussion) for the city of Barcelona. We classify policies as discriminatory
or non-discriminatory against the poor, with the support of specialized NGOs,
and we observe the results in the AABM in terms of the impact on wealth
inequality. The simulation provides evidence of the relationship between
aporophobia and the increase of wealth inequality levels, paving the way for a
new generation of poverty reduction policies that act on discrimination and
tackle poverty as a societal problem (not only a problem of the poor).
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01601" title="Abstract">arXiv:2403.01601</a> [<a href="/pdf/2403.01601" title="Download PDF">pdf</a>, <a href="/format/2403.01601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Technological Convergence in Encryption Technologies with  Proximity Indices: A Text Mining and Bibliometric Analysis using OpenAlex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tavazzi%2C+A">Alessandro Tavazzi</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+D+P">Dimitri Percia David</a>, 
<a href="/search/cs?searchtype=author&query=Jang-Jaccard%2C+J">Julian Jang-Jaccard</a>, 
<a href="/search/cs?searchtype=author&query=Mermoud%2C+A">Alain Mermoud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Identifying technological convergence among emerging technologies in
cybersecurity is crucial for advancing science and fostering innovation. Unlike
previous studies focusing on the binary relationship between a paper and the
concept it attributes to technology, our approach utilizes attribution scores
to enhance the relationships between research papers, combining keywords,
citation rates, and collaboration status with specific technological concepts.
The proposed method integrates text mining and bibliometric analyses to
formulate and predict technological proximity indices for encryption
technologies using the "OpenAlex" catalog. Our case study findings highlight a
significant convergence between blockchain and public-key cryptography,
evidenced by the increasing proximity indices. These results offer valuable
strategic insights for those contemplating investments in these domains.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01602" title="Abstract">arXiv:2403.01602</a> [<a href="/pdf/2403.01602" title="Download PDF">pdf</a>, <a href="/ps/2403.01602" title="Download PostScript">ps</a>, <a href="/format/2403.01602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Sizing of Hybrid Renewable Energy Based Microgrid System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rahman%2C+I">Irfan Rahman</a>, 
<a href="/search/eess?searchtype=author&query=Suha%2C+F">Farheen Suha</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+A">Ashik Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the decline of fossil fuel reserves and the escalating global average
temperature, the quest for environmentally friendly and renewable energy
sources has gained significant momentum. Focus has turned to wind and
photovoltaic energy, but their variable inputs necessitate energy storage for
reliable power. Economic viability of hybrid renewable power requires
meticulous optimization of generating units to ensure uninterrupted and
efficient energy production. This paper presents an optimal sizing approach for
a Wind-Photovoltaic-Biogas-Battery system using a single objective optimization
(SOO) method. A comprehensive comparative analysis is conducted, evaluating the
convergence speed and objective mean (for minimization) of seven metaheuristic
optimizers: Particle Swarm Optimization (PSO), Aquila Optimizer (AO), Pelican
Optimization Algorithm (POA), Dandelion Optimizing Algorithm (DOA), Gazelle
Optimization Algorithm (GOA), Zebra Optimization Algorithm (ZOA), and Osprey
Optimization Algorithm (OOA). The results demonstrate that the Pelican
Optimization Algorithm (POA) outperforms other existing algorithms, exhibiting
faster convergence and lower objective mean.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01605" title="Abstract">arXiv:2403.01605</a> [<a href="/pdf/2403.01605" title="Download PDF">pdf</a>, <a href="/format/2403.01605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Provable Log Density Policy Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katdare%2C+P">Pulkit Katdare</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Anant Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Policy gradient methods are a vital ingredient behind the success of modern
reinforcement learning. Modern policy gradient methods, although successful,
introduce a residual error in gradient estimation. In this work, we argue that
this residual term is significant and correcting for it could potentially
improve sample-complexity of reinforcement learning methods. To that end, we
propose log density gradient to estimate the policy gradient, which corrects
for this residual error term. Log density gradient method computes policy
gradient by utilising the state-action discounted distributional formulation.
We first present the equations needed to exactly find the log density gradient
for a tabular Markov Decision Processes (MDPs). For more complex environments,
we propose a temporal difference (TD) method that approximates log density
gradient by utilizing backward on-policy samples. Since backward sampling from
a Markov chain is highly restrictive we also propose a min-max optimization
that can approximate log density gradient using just on-policy samples. We also
prove uniqueness, and convergence under linear function approximation, for this
min-max optimization. Finally, we show that the sample complexity of our
min-max optimization to be of the order of $m^{-1/2}$, where $m$ is the number
of on-policy samples. We also demonstrate a proof-of-concept for our log
density gradient method on gridworld environment, and observe that our method
is able to improve upon the classical policy gradient method by a clear margin,
thus indicating a promising novel direction to develop reinforcement learning
algorithms that require fewer samples.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01606" title="Abstract">arXiv:2403.01606</a> [<a href="/pdf/2403.01606" title="Download PDF">pdf</a>, <a href="/format/2403.01606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Model Selection Technique for Spectral Clustering Based Motion  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zelek%2C+J">John Zelek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Computational Vision and Imaging Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Motion segmentation is a fundamental problem in computer vision and is
crucial in various applications such as robotics, autonomous driving and action
recognition. Recently, spectral clustering based methods have shown impressive
results on motion segmentation in dynamic environments. These methods perform
spectral clustering on motion affinity matrices to cluster objects or point
trajectories in the scene into different motion groups. However, existing
methods often need the number of motions present in the scene to be known,
which significantly reduces their practicality. In this paper, we propose a
unified model selection technique to automatically infer the number of motion
groups for spectral clustering based motion segmentation methods by combining
different existing model selection techniques together. We evaluate our method
on the KT3DMoSeg dataset and achieve competitve results comparing to the
baseline where the number of clusters is given as ground truth information.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01607" title="Abstract">arXiv:2403.01607</a> [<a href="/pdf/2403.01607" title="Download PDF">pdf</a>, <a href="/format/2403.01607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Respiratory motion forecasting with online learning of recurrent neural  networks for safety enhancement in externally guided radiotherapy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pohl%2C+M">Michel Pohl</a>, 
<a href="/search/cs?searchtype=author&query=Uesaka%2C+M">Mitsuru Uesaka</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+H">Hiroyuki Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Demachi%2C+K">Kazuyuki Demachi</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+R+B">Ritu Bhusal Chhatkuli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">In lung radiotherapy, infrared cameras can record the location of reflective
objects on the chest to infer the position of the tumor moving due to
breathing, but treatment system latencies hinder radiation beam precision.
Real-time recurrent learning (RTRL), is a potential solution as it can learn
patterns within non-stationary respiratory data but has high complexity. This
study assesses the capabilities of resource-efficient online RNN algorithms,
namely unbiased online recurrent optimization (UORO), sparse-1 step
approximation (SnAp-1), and decoupled neural interfaces (DNI) to forecast
respiratory motion during radiotherapy treatment accurately. We use time series
containing the 3D position of external markers on the chest of healthy
subjects. We propose efficient implementations for SnAp-1 and DNI based on
compression of the influence and immediate Jacobian matrices and an accurate
update of the linear coefficients used in credit assignment estimation,
respectively. The original sampling frequency was 10Hz; we performed resampling
at 3.33Hz and 30Hz. We use UORO, SnAp-1, and DNI to forecast each marker's 3D
position with horizons (the time interval in advance for which the prediction
is made) h&lt;=2.1s and compare them with RTRL, least mean squares, and linear
regression. RNNs trained online achieved similar or better accuracy than most
previous works using larger training databases and deep learning, even though
we used only the first minute of each sequence to predict motion within that
exact sequence. SnAp-1 had the lowest normalized root mean square errors
(nRMSE) averaged over the horizon values considered, equal to 0.335 and 0.157,
at 3.33Hz and 10.0Hz, respectively. Similarly, UORO had the highest accuracy at
30Hz, with an nRMSE of 0.0897. DNI's inference time, equal to 6.8ms per time
step at 30Hz (Intel Core i7-13700 CPU), was the lowest among the RNN methods
examined.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01609" title="Abstract">arXiv:2403.01609</a> [<a href="/pdf/2403.01609" title="Download PDF">pdf</a>, <a href="/ps/2403.01609" title="Download PostScript">ps</a>, <a href="/format/2403.01609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A &quot;User Experience 3.0 (UX3.0)&quot; Paradigm Framework: User Experience  Design for Human-Centered AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Over the last three decades, user experience (UX) practice can be divided
into three stages in terms of technology platform, user needs, design
philosophy, ecosystem, scope, focus, and methodology of UX practice. UX
practice is moving towards the intelligence era. Still, the existing UX
paradigm mainly aims at non-intelligent systems and lacks a systematic approach
to address UX for designing and developing human-centered AI products and
systems. The intelligence era has put forward new demands on the UX paradigm.
This paper proposes a "UX 3.0" paradigm framework and the corresponding UX
methodology for UX practice in the intelligence era. The "UX 3.0" paradigm
framework includes four categories of emerging experiences in the intelligence
era: ecosystem-based experience, innovation-enabled experience, AI-enabled
experience, and human-AI interaction-based experience, each compelling us to
enhance current UX practice in terms of design philosophy, scope, focus, and
methodology. We believe that the "UX 3.0" paradigm helps enhance existing UX
practice and provides methodological support for the research and applications
of UX in developing human-centered AI systems. Finally, this paper looks
forward to future work implementing the "UX 3.0" paradigm.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01611" title="Abstract">arXiv:2403.01611</a> [<a href="/pdf/2403.01611" title="Download PDF">pdf</a>, <a href="/format/2403.01611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Grasp Loop Signature: A Topological Representation for Manipulation  Planning with Ropes and Cables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitrano%2C+P">Peter Mitrano</a>, 
<a href="/search/cs?searchtype=author&query=Berenson%2C+D">Dmitry Berenson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept to ICRA 2024; Project Website: <a href="https://sites.google.com/view/doo-manipulation-signature/home">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic manipulation of deformable, one-dimensional objects (DOOs) like ropes
or cables has important potential applications in manufacturing, agriculture,
and surgery. In such environments, the task may involve threading through or
avoiding becoming tangled with objects like racks or frames. Grasping with
multiple grippers can create closed loops between the robot and DOO, and If an
obstacle lies within this loop, it may be impossible to reach the goal.
However, prior work has only considered the topology of the DOO in isolation,
ignoring the arms that are manipulating it. Searching over possible grasps to
accomplish the task without considering such topological information is very
inefficient, as many grasps will not lead to progress on the task due to
topological constraints. Therefore, we propose a grasp loop signature which
categorizes the topology of these grasp loops and show how it can be used to
guide planning. We perform experiments in simulation on two DOO manipulation
tasks to show that using the signature is faster and succeeds more often than
methods that rely on local geometry or finite-horizon planning. Finally, we
demonstrate using the signature in the real world to manipulate a cable in a
scene with obstacles using a dual-arm robot.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01614" title="Abstract">arXiv:2403.01614</a> [<a href="/pdf/2403.01614" title="Download PDF">pdf</a>, <a href="/ps/2403.01614" title="Download PostScript">ps</a>, <a href="/format/2403.01614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time optimization of thermoelectric coolers&#x27; performance based on  energy and exergy analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amiri-Margavi%2C+A">Alireza Amiri-Margavi</a>, 
<a href="/search/eess?searchtype=author&query=Jamali%2C+R">Reza Jamali</a>, 
<a href="/search/eess?searchtype=author&query=Hosseini%2C+S+A">Seyed Aria Hosseini</a>, 
<a href="/search/eess?searchtype=author&query=Torabi%2C+F">Farschad Torabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">New strategy is presented to optimize the performance of Thermoelectric (TE)
coolers. This approach breaks optimizing TE coolers free from traditional
methods of controlling temperature or engineering materials and the structural
properties of the junctions. We introduced a dimensionless figure, {\gamma},
that shows the ratio of the unavailable cooling capacity to the available
cooling capacity. This parameter relates the TE coolers' coefficient of
performance (COP) to the COP of the reversible cycle (second law of
thermodynamics efficiency) for a given electrical current. The theoretical
description of the model is presented, and it is shown that controlling
{\gamma} during the TE performance minimizes entropy generation and energy
loss, which leads to the maximum pumped heat. We validated this model against a
designed TE cooler. In this cooler, contrary to conventional TE coolers, where
the temperature of the cold space is generally controlled at a specific
temperature, and the performance of the cooler overlooked, the entropy
generation and heat loss are engineered, and the electrical current is tuned to
minimize {\gamma} by the controller so that the TE cooler works near to its
optimum performance at any time.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01615" title="Abstract">arXiv:2403.01615</a> [<a href="/pdf/2403.01615" title="Download PDF">pdf</a>, <a href="/format/2403.01615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tiantian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishna%2C+A">Anil Ramakrishna</a>, 
<a href="/search/cs?searchtype=author&query=Majmudar%2C+J">Jimit Majmudar</a>, 
<a href="/search/cs?searchtype=author&query=Peris%2C+C">Charith Peris</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+C">Clement Chung</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>, 
<a href="/search/cs?searchtype=author&query=Ziyadi%2C+M">Morteza Ziyadi</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rahul Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is a popular algorithm to train machine learning
models on user data constrained to edge devices (for example, mobile phones)
due to privacy concerns. Typically, FL is trained with the assumption that no
part of the user data can be egressed from the edge. However, in many
production settings, specific data-modalities/meta-data are limited to be on
device while others are not. For example, in commercial SLU systems, it is
typically desired to prevent transmission of biometric signals (such as audio
recordings of the input prompt) to the cloud, but egress of locally (i.e. on
the edge device) transcribed text to the cloud may be possible. In this work,
we propose a new algorithm called Partial Federated Learning (PartialFL), where
a machine learning model is trained using data where a subset of data
modalities or their intermediate representations can be made available to the
server. We further restrict our model training by preventing the egress of data
labels to the cloud for better privacy, and instead use a contrastive learning
based model objective. We evaluate our approach on two different multi-modal
datasets and show promising results with our proposed approach.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01616" title="Abstract">arXiv:2403.01616</a> [<a href="/pdf/2403.01616" title="Download PDF">pdf</a>, <a href="/format/2403.01616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Comprehensive Vietnamese Retrieval-Augmented Generation and  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duc%2C+N+Q">Nguyen Quang Duc</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+L+H">Le Hai Son</a>, 
<a href="/search/cs?searchtype=author&query=Nhan%2C+N+D">Nguyen Duc Nhan</a>, 
<a href="/search/cs?searchtype=author&query=Minh%2C+N+D+N">Nguyen Dich Nhat Minh</a>, 
<a href="/search/cs?searchtype=author&query=Huong%2C+L+T">Le Thanh Huong</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+D+V">Dinh Viet Sang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents our contributions towards advancing the state of
Vietnamese language understanding and generation through the development and
dissemination of open datasets and pre-trained models for Vietnamese
Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs).
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01619" title="Abstract">arXiv:2403.01619</a> [<a href="/pdf/2403.01619" title="Download PDF">pdf</a>, <a href="/format/2403.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum AUC Difference (SAUCD): Human-aligned 3D Shape Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luan%2C+T">Tianyu Luan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lele Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Junsong Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024. Project page: <a href="https://bit.ly/saucd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Existing 3D mesh shape evaluation metrics mainly focus on the overall shape
but are usually less sensitive to local details. This makes them inconsistent
with human evaluation, as human perception cares about both overall and
detailed shape. In this paper, we propose an analytic metric named Spectrum
Area Under the Curve Difference (SAUCD) that demonstrates better consistency
with human evaluation. To compare the difference between two shapes, we first
transform the 3D mesh to the spectrum domain using the discrete
Laplace-Beltrami operator and Fourier transform. Then, we calculate the Area
Under the Curve (AUC) difference between the two spectrums, so that each
frequency band that captures either the overall or detailed shape is equitably
considered. Taking human sensitivity across frequency bands into account, we
further extend our metric by learning suitable weights for each frequency band
which better aligns with human perception. To measure the performance of SAUCD,
we build a 3D mesh evaluation dataset called Shape Grading, along with manual
annotations from more than 800 subjects. By measuring the correlation between
our metric and human evaluation, we demonstrate that SAUCD is well aligned with
human evaluation, and outperforms previous 3D mesh metrics.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01621" title="Abstract">arXiv:2403.01621</a> [<a href="/pdf/2403.01621" title="Download PDF">pdf</a>, <a href="/ps/2403.01621" title="Download PostScript">ps</a>, <a href="/format/2403.01621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning vs Deep Learning: The Generalization Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bay%2C+Y+Y">Yong Yi Bay</a>, 
<a href="/search/cs?searchtype=author&query=Yearick%2C+K+A">Kathleen A. Yearick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The capacity to generalize beyond the range of training data is a pivotal
challenge, often synonymous with a model's utility and robustness. This study
investigates the comparative abilities of traditional machine learning (ML)
models and deep learning (DL) algorithms in terms of extrapolation -- a more
challenging aspect of generalization because it requires the model to make
inferences about data points that lie outside the domain it has been trained
on. We present an empirical analysis where both ML and DL models are trained on
an exponentially growing function and then tested on values outside the
training domain. The choice of this function allows us to distinctly showcase
the divergence in performance when models are required to predict beyond the
scope of their training data. Our findings suggest that deep learning models
possess inherent capabilities to generalize beyond the training scope, an
essential feature for real-world applications where data is often incomplete or
extends beyond the observed range. This paper argues for a nuanced
understanding of the structural differences between ML and DL models, with an
emphasis on the implications for both theoretical research and practical
deployment.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01622" title="Abstract">arXiv:2403.01622</a> [<a href="/pdf/2403.01622" title="Download PDF">pdf</a>, <a href="/format/2403.01622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-Centered Approach for Bootstrapping Causal Graph Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tram%2C+M+Q">Minh Q. Tram</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+N+B">Nolan B. Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Beksi%2C+W+J">William J. Beksi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI) Workshop on Causal Learning for Human-Robot Interaction (Causal-HRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Causal inference, a cornerstone in disciplines such as economics, genomics,
and medicine, is increasingly being recognized as fundamental to advancing the
field of robotics. In particular, the ability to reason about cause and effect
from observational data is crucial for robust generalization in robotic
systems. However, the construction of a causal graphical model, a mechanism for
representing causal relations, presents an immense challenge. Currently, a
nuanced grasp of causal inference, coupled with an understanding of causal
relationships, must be manually programmed into a causal graphical model. To
address this difficulty, we present initial results towards a human-centered
augmented reality framework for creating causal graphical models. Concretely,
our system bootstraps the causal discovery process by involving humans in
selecting variables, establishing relationships, performing interventions,
generating counterfactual explanations, and evaluating the resulting causal
graph at every step. We highlight the potential of our framework via a physical
robot manipulator on a pick-and-place task.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01623" title="Abstract">arXiv:2403.01623</a> [<a href="/pdf/2403.01623" title="Download PDF">pdf</a>, <a href="/format/2403.01623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ML4PhySim : Machine Learning for Physical Simulations Challenge (The  airfoil design)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yagoubi%2C+M">Mouadh Yagoubi</a>, 
<a href="/search/cs?searchtype=author&query=Leyli-Abadi%2C+M">Milad Leyli-Abadi</a>, 
<a href="/search/cs?searchtype=author&query=Danan%2C+D">David Danan</a>, 
<a href="/search/cs?searchtype=author&query=Brunet%2C+J">Jean-Patrick Brunet</a>, 
<a href="/search/cs?searchtype=author&query=Mazari%2C+J+A">Jocelyn Ahmed Mazari</a>, 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+F">Florent Bonnet</a>, 
<a href="/search/cs?searchtype=author&query=Farjallah%2C+A">Asma Farjallah</a>, 
<a href="/search/cs?searchtype=author&query=Schoenauer%2C+M">Marc Schoenauer</a>, 
<a href="/search/cs?searchtype=author&query=Gallinari%2C+P">Patrick Gallinari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The use of machine learning (ML) techniques to solve complex physical
problems has been considered recently as a promising approach. However, the
evaluation of such learned physical models remains an important issue for
industrial use. The aim of this competition is to encourage the development of
new ML techniques to solve physical problems using a unified evaluation
framework proposed recently, called Learning Industrial Physical Simulations
(LIPS). We propose learning a task representing a well-known physical use case:
the airfoil design simulation, using a dataset called AirfRANS. The global
score calculated for each submitted solution is based on three main categories
of criteria covering different aspects, namely: ML-related,
Out-Of-Distribution, and physical compliance criteria. To the best of our
knowledge, this is the first competition addressing the use of ML-based
surrogate approaches to improve the trade-off computational cost/accuracy of
physical simulation.The competition is hosted by the Codabench platform with
online training and evaluation of all submitted solutions.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01626" title="Abstract">arXiv:2403.01626</a> [<a href="/pdf/2403.01626" title="Download PDF">pdf</a>, <a href="/format/2403.01626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LLMs for Tabletop Exercises within the Security Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hays%2C+S">Sam Hays</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+D+J">Dr. Jules White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Tabletop exercises are a crucial component of many company's strategy to test
and evaluate its preparedness for security incidents in a realistic way.
Traditionally led by external firms specializing in cybersecurity, these
exercises can be costly, time-consuming, and may not always align precisely
with the client's specific needs. Large Language Models (LLMs) like ChatGPT
offer a compelling alternative. They enable faster iteration, provide rich and
adaptable simulations, and offer infinite patience in handling feedback and
recommendations. This approach can enhances the efficiency and relevance of
security preparedness exercises.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01627" title="Abstract">arXiv:2403.01627</a> [<a href="/pdf/2403.01627" title="Download PDF">pdf</a>, <a href="/format/2403.01627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acceleration of digital memcomputing by jumps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pershin%2C+Y+V">Yuriy V. Pershin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">In this article, we present the potential benefits of incorporating jumps
into the dynamics of digital memcomputing machines (DMMs), which have been
developed to address complex optimization problems. We illustrate the potential
speed improvement of a DMM solver with jumps over an unmodified DMM solver by
solving Boolean satisfiability (SAT) problems of different complicatedness. Our
findings suggest that jumps can modify scaling exponents and improve solving
times by up to 75 %. Interestingly, the advantages of jumps can be seen in
cases where the size of the jump is so large that otherwise the continuous
dynamics of voltage variables becomes almost binary.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01628" title="Abstract">arXiv:2403.01628</a> [<a href="/pdf/2403.01628" title="Download PDF">pdf</a>, <a href="/ps/2403.01628" title="Download PostScript">ps</a>, <a href="/format/2403.01628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent Advances, Applications, and Open Challenges in Machine Learning  for Health: Reflections from Research Roundtables at ML4H 2023 Symposium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hyewon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Jabbour%2C+S">Sarah Jabbour</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Thapta%2C+R">Rahul Thapta</a>, 
<a href="/search/cs?searchtype=author&query=Mozannar%2C+H">Hussein Mozannar</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W+J">William Jongwon Han</a>, 
<a href="/search/cs?searchtype=author&query=Mehandru%2C+N">Nikita Mehandru</a>, 
<a href="/search/cs?searchtype=author&query=Wornow%2C+M">Michael Wornow</a>, 
<a href="/search/cs?searchtype=author&query=Lialin%2C+V">Vladislav Lialin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Alejandro Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiacheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kocielnik%2C+R+D">Rafal Dariusz Kocielnik</a>, 
<a href="/search/cs?searchtype=author&query=Harrigian%2C+K">Keith Harrigian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Edward Lee</a>, 
<a href="/search/cs?searchtype=author&query=Vukadinovic%2C+M">Milos Vukadinovic</a>, 
<a href="/search/cs?searchtype=author&query=Balagopalan%2C+A">Aparna Balagopalan</a>, 
<a href="/search/cs?searchtype=author&query=Jeanselme%2C+V">Vincent Jeanselme</a>, 
<a href="/search/cs?searchtype=author&query=Matton%2C+K">Katherine Matton</a>, 
<a href="/search/cs?searchtype=author&query=Demirel%2C+I">Ilker Demirel</a>, 
<a href="/search/cs?searchtype=author&query=Fries%2C+J">Jason Fries</a>, 
<a href="/search/cs?searchtype=author&query=Rashidi%2C+P">Parisa Rashidi</a>, 
<a href="/search/cs?searchtype=author&query=Beaulieu-Jones%2C+B">Brett Beaulieu-Jones</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X+O">Xuhai Orson Xu</a>, 
<a href="/search/cs?searchtype=author&query=McDermott%2C+M">Matthew McDermott</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+T">Tristan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+M">Monica Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Ustun%2C+B">Berk Ustun</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+K">Kristen Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Gursoy%2C+G">Gamze Gursoy</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Marzyeh Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Pierson%2C+E">Emma Pierson</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">George Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kanjilal%2C+S">Sanjat Kanjilal</a>, 
<a href="/search/cs?searchtype=author&query=Oberst%2C+M">Michael Oberst</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Harvineet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Tom Hartvigsen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Helen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Okolo%2C+C+T">Chinasa T. Okolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ML4H 2023, Research Roundtables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The third ML4H symposium was held in person on December 10, 2023, in New
Orleans, Louisiana, USA. The symposium included research roundtable sessions to
foster discussions between participants and senior researchers on timely and
relevant topics for the \ac{ML4H} community. Encouraged by the successful
virtual roundtables in the previous year, we organized eleven in-person
roundtables and four virtual roundtables at ML4H 2022. The organization of the
research roundtables at the conference involved 17 Senior Chairs and 19 Junior
Chairs across 11 tables. Each roundtable session included invited senior chairs
(with substantial experience in the field), junior chairs (responsible for
facilitating the discussion), and attendees from diverse backgrounds with
interest in the session's topic. Herein we detail the organization process and
compile takeaways from these roundtable discussions, including recent advances,
applications, and open challenges for each topic. We conclude with a summary
and lessons learned across all roundtables. This document serves as a
comprehensive review paper, summarizing the recent advancements in machine
learning for healthcare as contributed by foremost researchers in the field.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01629" title="Abstract">arXiv:2403.01629</a> [<a href="/pdf/2403.01629" title="Download PDF">pdf</a>, <a href="/format/2403.01629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VR Research at Fraunofer IGD, Darmstadt, Germany
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felger%2C+W">Wolfgang Felger</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6bel%2C+M">Martin G&#xf6;bel</a>, 
<a href="/search/cs?searchtype=author&query=Reiners%2C+D">Dirk Reiners</a>, 
<a href="/search/cs?searchtype=author&query=Zachmann%2C+G">Gabriel Zachmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VR 2024 Workshop "Archiving VR"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We present a historical outline of the research and developments
<br />of Virtual Reality at the Fraunhofer Institute for Computer Graphics (IGD)
<br />in Darmstadt, Germany, from 1990 through 2000.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01630" title="Abstract">arXiv:2403.01630</a> [<a href="/pdf/2403.01630" title="Download PDF">pdf</a>, <a href="/format/2403.01630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relational to RDF Data Migration by Query Co-Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wisnesky%2C+R">Ryan Wisnesky</a>, 
<a href="/search/cs?searchtype=author&query=Filonik%2C+D">Daniel Filonik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In this paper we define a new algorithm to convert an input relational
database to an output set of RDF triples. The algorithm can be used to e.g.
load CSV data into a financial OWL ontology such as FIBO. The algorithm takes
as input a set of relational conjunctive (select-from-where) queries, one for
each input table, from the three column (subject, predicate, object) output RDF
schema to the input table's relational schema. The algorithm's output is the
only set of RDF triples for which a unique round-trip of the input data under
the relational queries exists. The output may contain blank nodes, is unique up
to unique isomorphism, and can be obtained using elementary formal methods
(equational theorem proving and term model construction specifically). We also
describe how (generalized) homomorphisms between graphs can be used to write
such relational conjunctive (select-from-where) queries, which, due to the lack
of structure in the three-column RDF schema, tend to be large in practice. We
demonstrate examples of both the algorithm and mapping language on the FIBO
financial ontology.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01631" title="Abstract">arXiv:2403.01631</a> [<a href="/pdf/2403.01631" title="Download PDF">pdf</a>, <a href="/format/2403.01631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TreeTracker Join: Turning the Tide When a Tuple Fails to Join
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zeyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Miranker%2C+D+P">Daniel P. Miranker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Many important query processing methods proactively use semijoins or
semijoin-like filters to delete dangling tuples, i.e., tuples that do not
appear in the final query result. Semijoin methods can achieve formal
optimality but have high upfront cost in practice. Filter methods reduce the
cost but lose the optimality guarantee.
<br />We propose a new join algorithm, TreeTracker Join ($\mathsf{TTJ}$), that
achieves the data complexity optimality for acyclic conjunctive queries (ACQs)
without semijoins or semijoin-like filters. $\mathsf{TTJ}$ leverages join
failure events, where a tuple from one of the relations of a binary join
operator fails to match any tuples from the other relation. $\mathsf{TTJ}$
starts join evaluation immediately and when join fails, $\mathsf{TTJ}$
identifies the tuple as dangling and prevents it from further consideration in
the execution of the query. The design of $\mathsf{TTJ}$ exploits the
connection between query evaluation and constraint satisfaction problem (CSP)
by treating a join tree of an ACQ as a constraint network and the query
evaluation as a CSP search problem. $\mathsf{TTJ}$ is a direct extension of a
CSP algorithm, TreeTracker, that embodies two search techniques backjumping and
no-good. We establish that join tree and plan can be constructed from each
other in order to incorporate the search techniques into physical operators in
the iterator form. We compare $\mathsf{TTJ}$ with hash-join, a classic semijoin
method: Yannakakis's algorithm, and two contemporary filter methods: Predicate
Transfer and Lookahead Information Passing. Favorable empirical results are
developed using standard query benchmarks: JOB, TPC-H, and SSB.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01632" title="Abstract">arXiv:2403.01632</a> [<a href="/pdf/2403.01632" title="Download PDF">pdf</a>, <a href="/format/2403.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving LLM Code Generation with Grammar Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ugare%2C+S">Shubham Ugare</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+T">Tarun Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hangoo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Misailovic%2C+S">Sasa Misailovic</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Formal Languages and Automata Theory (cs.FL); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">We present SynCode a novel framework for efficient and general syntactical
decoding of code with large language models (LLMs). SynCode leverages the
grammar of a programming language, utilizing an offline-constructed efficient
lookup table called DFA mask store based on language grammar terminals. We
demonstrate SynCode's soundness and completeness given the context-free grammar
(CFG) of the programming language, presenting its ability to retain
syntactically valid tokens while rejecting invalid ones. The framework
seamlessly integrates with any language defined by CFG, as evidenced by
experiments on CFGs for Python and Go. The results underscore the significant
reduction of 96.07% of syntax errors achieved when SynCode is combined with
state-of-the-art LLMs, showcasing its substantial impact on enhancing
syntactical precision in code generation.
<br />Our code is available at https://github.com/uiuc-focal-lab/syncode.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01633" title="Abstract">arXiv:2403.01633</a> [<a href="/pdf/2403.01633" title="Download PDF">pdf</a>, <a href="/format/2403.01633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical windows: non-asymptotic theory for feature emergence in  diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Marvin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sitan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">We develop theory to understand an intriguing property of diffusion models
for image generation that we term critical windows. Empirically, it has been
observed that there are narrow time intervals in sampling during which
particular features of the final image emerge, e.g. the image class or
background color (Ho et al., 2020b; Georgiev et al., 2023; Raya &amp; Ambrogioni,
2023; Sclocchi et al., 2024; Biroli et al., 2024). While this is advantageous
for interpretability as it implies one can localize properties of the
generation to a small segment of the trajectory, it seems at odds with the
continuous nature of the diffusion. We propose a formal framework for studying
these windows and show that for data coming from a mixture of strongly
log-concave densities, these windows can be provably bounded in terms of
certain measures of inter- and intra-group separation. We also instantiate
these bounds for concrete examples like well-conditioned Gaussian mixtures.
Finally, we use our bounds to give a rigorous interpretation of diffusion
models as hierarchical samplers that progressively "decide" output features
over a discrete sequence of times. We validate our bounds with synthetic
experiments. Additionally, preliminary experiments on Stable Diffusion suggest
critical windows may serve as a useful tool for diagnosing fairness and privacy
violations in real-world diffusion models.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01638" title="Abstract">arXiv:2403.01638</a> [<a href="/pdf/2403.01638" title="Download PDF">pdf</a>, <a href="/format/2403.01638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level Product Category Prediction through Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maia%2C+W+F">Wesley Ferreira Maia</a>, 
<a href="/search/cs?searchtype=author&query=Carmignani%2C+A">Angelo Carmignani</a>, 
<a href="/search/cs?searchtype=author&query=Bortoli%2C+G">Gabriel Bortoli</a>, 
<a href="/search/cs?searchtype=author&query=Maretti%2C+L">Lucas Maretti</a>, 
<a href="/search/cs?searchtype=author&query=Luz%2C+D">David Luz</a>, 
<a href="/search/cs?searchtype=author&query=Guzman%2C+D+C+F">Daniel Camilo Fuentes Guzman</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+M+J">Marcos Jardel Henriques</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+F+L">Francisco Louzada Neto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This article investigates applying advanced machine learning models,
specifically LSTM and BERT, for text classification to predict multiple
categories in the retail sector. The study demonstrates how applying data
augmentation techniques and the focal loss function can significantly enhance
accuracy in classifying products into multiple categories using a robust
Brazilian retail dataset. The LSTM model, enriched with Brazilian word
embedding, and BERT, known for its effectiveness in understanding complex
contexts, were adapted and optimized for this specific task. The results showed
that the BERT model, with an F1 Macro Score of up to $99\%$ for segments,
$96\%$ for categories and subcategories and $93\%$ for name products,
outperformed LSTM in more detailed categories. However, LSTM also achieved high
performance, especially after applying data augmentation and focal loss
techniques. These results underscore the effectiveness of NLP techniques in
retail and highlight the importance of the careful selection of modelling and
preprocessing strategies. This work contributes significantly to the field of
NLP in retail, providing valuable insights for future research and practical
applications.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01639" title="Abstract">arXiv:2403.01639</a> [<a href="/pdf/2403.01639" title="Download PDF">pdf</a>, <a href="/format/2403.01639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Insights for Diffusion Guidance: A Case Study for Gaussian  Mixture Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minshuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuting Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion models benefit from instillation of task-specific information into
the score function to steer the sample generation towards desired properties.
Such information is coined as guidance. For example, in text-to-image
synthesis, text input is encoded as guidance to generate semantically aligned
images. Proper guidance inputs are closely tied to the performance of diffusion
models. A common observation is that strong guidance promotes a tight alignment
to the task-specific information, while reducing the diversity of the generated
samples. In this paper, we provide the first theoretical study towards
understanding the influence of guidance on diffusion models in the context of
Gaussian mixture models. Under mild conditions, we prove that incorporating
diffusion guidance not only boosts classification confidence but also
diminishes distribution diversity, leading to a reduction in the differential
entropy of the output distribution. Our analysis covers the widely adopted
sampling schemes including DDPM and DDIM, and leverages comparison inequalities
for differential equations as well as the Fokker-Planck equation that
characterizes the evolution of probability density function, which may be of
independent theoretical interest.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01641" title="Abstract">arXiv:2403.01641</a> [<a href="/pdf/2403.01641" title="Download PDF">pdf</a>, <a href="/format/2403.01641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIO2: Online Correction of Object Labels for Deep Learning with  Incomplete Annotation in Remote Sensing Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+C+M">Conrad M Albrecht</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While the volume of remote sensing data is increasing daily, deep learning in
Earth Observation faces lack of accurate annotations for supervised
optimization. Crowdsourcing projects such as OpenStreetMap distribute the
annotation load to their community. However, such annotation inevitably
generates noise due to insufficient control of the label quality, lack of
annotators, frequent changes of the Earth's surface as a result of natural
disasters and urban development, among many other factors. We present
Adaptively trIggered Online Object-wise correction (AIO2) to address annotation
noise induced by incomplete label sets. AIO2 features an Adaptive Correction
Trigger (ACT) module that avoids label correction when the model training
under- or overfits, and an Online Object-wise Correction (O2C) methodology that
employs spatial information for automated label modification. AIO2 utilizes a
mean teacher model to enhance training robustness with noisy labels to both
stabilize the training accuracy curve for fitting in ACT and provide pseudo
labels for correction in O2C. Moreover, O2C is implemented online without the
need to store updated labels every training epoch. We validate our approach on
two building footprint segmentation datasets with different spatial
resolutions. Experimental results with varying degrees of building label noise
demonstrate the robustness of AIO2. Source code will be available at
https://github.com/zhu-xlab/AIO2.git.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01642" title="Abstract">arXiv:2403.01642</a> [<a href="/pdf/2403.01642" title="Download PDF">pdf</a>, <a href="/ps/2403.01642" title="Download PostScript">ps</a>, <a href="/format/2403.01642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blue and Green-Mode Energy-Efficient Chemiresistive Sensor Array  Realized by Rapid Ensemble Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+J">James Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Laan%2C+T">Timothy van der Laan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First version before submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
<p class="mathjax">The rapid advancement of Internet of Things (IoT) necessitates the
development of optimized Chemiresistive Sensor (CRS) arrays that are both
energy-efficient and capable. This study introduces a novel optimization
strategy that employs a rapid ensemble learning-based model committee approach
to achieve these goals. Utilizing machine learning models such as Elastic Net
Regression, Random Forests, and XGBoost, among others, the strategy identifies
the most impactful sensors in a CRS array for accurate classification: A
weighted voting mechanism is introduced to aggregate the models' opinions in
sensor selection, thereby setting up wo distinct working modes, termed "Blue"
and "Green". The Blue mode operates with all sensors for maximum detection
capability, while the Green mode selectively activates only key sensors,
significantly reducing energy consumption without compromising detection
accuracy. The strategy is validated through theoretical calculations and Monte
Carlo simulations, demonstrating its effectiveness and accuracy. The proposed
optimization strategy not only elevates the detection capability of CRS arrays
but also brings it closer to theoretical limits, promising significant
implications for the development of low-cost, easily fabricable next-generation
IoT sensor terminals.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01643" title="Abstract">arXiv:2403.01643</a> [<a href="/pdf/2403.01643" title="Download PDF">pdf</a>, <a href="/format/2403.01643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Need to Pay Better Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+M">Mehran Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+P">Peyman Hosseini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce three new attention mechanisms that outperform standard
multi-head attention in terms of efficiency and learning capabilities, thereby
improving the performance and broader deployability of Transformer models. Our
first contribution is Optimised Attention, which performs similarly to standard
attention, but has 3/4 as many parameters and one matrix multiplication fewer
per head. Next, we introduce Efficient Attention, which performs on par with
standard attention with only 1/2 as many parameters as many parameters and two
matrix multiplications fewer per head and is up to twice as fast as standard
attention. Lastly, we introduce Super Attention, which surpasses standard
attention by a significant margin in both vision and natural language
processing tasks while having fewer parameters and matrix multiplications. In
addition to providing rigorous mathematical comparisons, we evaluate the
presented attention mechanisms on MNIST, CIFAR100, IMDB Movie Reviews, and
Amazon Reviews datasets.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01644" title="Abstract">arXiv:2403.01644</a> [<a href="/pdf/2403.01644" title="Download PDF">pdf</a>, <a href="/format/2403.01644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OccFusion: A Straightforward and Effective Multi-Sensor Fusion Framework  for 3D Occupancy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhenxing Ming</a>, 
<a href="/search/cs?searchtype=author&query=Berrio%2C+J+S">Julie Stephany Berrio</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+M">Mao Shan</a>, 
<a href="/search/cs?searchtype=author&query=Worrall%2C+S">Stewart Worrall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper introduces OccFusion, a straightforward and efficient sensor
fusion framework for predicting 3D occupancy. A comprehensive understanding of
3D scenes is crucial in autonomous driving, and recent models for 3D semantic
occupancy prediction have successfully addressed the challenge of describing
real-world objects with varied shapes and classes. However, existing methods
for 3D occupancy prediction heavily rely on surround-view camera images, making
them susceptible to changes in lighting and weather conditions. By integrating
features from additional sensors, such as lidar and surround view radars, our
framework enhances the accuracy and robustness of occupancy prediction,
resulting in top-tier performance on the nuScenes benchmark. Furthermore,
extensive experiments conducted on the nuScenes dataset, including challenging
night and rainy scenarios, confirm the superior performance of our sensor
fusion strategy across various perception ranges. The code for this framework
will be made available at https://github.com/DanielMing123/OCCFusion.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01646" title="Abstract">arXiv:2403.01646</a> [<a href="/pdf/2403.01646" title="Download PDF">pdf</a>, <a href="/format/2403.01646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TweetInfo: An Interactive System to Mitigate Online Harm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahi%2C+G+K">Gautam Kishore Shahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The increase in active users on social networking sites (SNSs) has also
observed an increase in harmful content on social media sites. Harmful content
is described as an inappropriate activity to harm or deceive an individual or a
group of users. Alongside existing methods to detect misinformation and hate
speech, users still need to be well-informed about the harmfulness of the
content on SNSs. This study proposes a user-interactive system TweetInfo for
mitigating the consumption of harmful content by providing metainformation
about the posts. It focuses on two types of harmful content: hate speech and
misinformation. TweetInfo provides insights into tweets by doing content
analysis. Based on previous research, we have selected a list of
metainformation. We offer the option to filter content based on metainformation
Bot, Hate Speech, Misinformation, Verified Account, Sentiment, Tweet Category,
Language. The proposed user interface allows customising the user's timeline to
mitigate harmful content. This study present the demo version of the propose
user interface of TweetInfo.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01647" title="Abstract">arXiv:2403.01647</a> [<a href="/pdf/2403.01647" title="Download PDF">pdf</a>, <a href="/ps/2403.01647" title="Download PostScript">ps</a>, <a href="/format/2403.01647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Assisted Lifting Steps For Improved Fully Scalable Lossy  Image Compression in JPEG 2000
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Naman%2C+A">Aous Naman</a>, 
<a href="/search/cs?searchtype=author&query=Taubman%2C+D">David Taubman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This work proposes to augment the lifting steps of the conventional wavelet
transform with additional neural network assisted lifting steps. These
additional steps reduce residual redundancy (notably aliasing information)
amongst the wavelet subbands, and also improve the visual quality of
reconstructed images at reduced resolutions. The proposed approach involves two
steps, a high-to-low step followed by a low-to-high step. The high-to-low step
suppresses aliasing in the low-pass band by using the detail bands at the same
resolution, while the low-to-high step aims to further remove redundancy from
detail bands, so as to achieve higher energy compaction. The proposed two
lifting steps are trained in an end-to-end fashion; we employ a backward
annealing approach to overcome the non-differentiability of the quantization
and cost functions during back-propagation. Importantly, the networks employed
in this paper are compact and with limited non-linearities, allowing a fully
scalable system; one pair of trained network parameters are applied for all
levels of decomposition and for all bit-rates of interest. By employing the
proposed approach within the JPEG 2000 image coding standard, our method can
achieve up to 17.4% average BD bit-rate saving over a wide range of bit-rates,
while retaining quality and resolution scalability features of JPEG 2000.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01648" title="Abstract">arXiv:2403.01648</a> [<a href="/pdf/2403.01648" title="Download PDF">pdf</a>, <a href="/format/2403.01648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;I just hated it and I want my money back&quot;: Data-driven Understanding of  Mobile VPN Service Switching Preferences in The Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+R">Rohit Raj</a>, 
<a href="/search/cs?searchtype=author&query=Newar%2C+M">Mridul Newar</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+M">Mainack Mondal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This extended version of our USENIX Security '24 paper on users' VPN-switching behavior includes appendices for interested readers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Virtual Private Networks (VPNs) are a crucial Privacy-Enhancing Technology
(PET) leveraged by millions of users and catered by multiple VPN providers
worldwide; thus, understanding the user preferences for the choice of VPN apps
should be of importance and interest to the security community. To that end,
prior studies looked into the usage, awareness and adoption of VPN users and
the perceptions of providers. However, no study so far has looked into the user
preferences and underlying reasons for switching among VPN providers and
identified features that presumably enhance users' VPN experience. This work
aims to bridge this gap and shed light on the underlying factors that drive
existing users when they switch from one VPN to another. In this work, we
analyzed over 1.3 million reviews from 20 leading VPN apps, identifying 1,305
explicit mentions and intents to switch. Our NLP-based analysis unveiled
distinct clusters of factors motivating users to switch. An examination of 376
blogs from six popular VPN recommendation sites revealed biases in the content,
and we found ignorance towards user preferences. We conclude by identifying the
key implications of our work for different stakeholders. The data and code for
this work is available at https://github.com/Mainack/switch-vpn-datacode-sec24.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01649" title="Abstract">arXiv:2403.01649</a> [<a href="/pdf/2403.01649" title="Download PDF">pdf</a>, <a href="/ps/2403.01649" title="Download PostScript">ps</a>, <a href="/format/2403.01649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommendations for Government Development and Use of Advanced Automated  Systems to Make Decisions about Individuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Landau%2C+S">Susan Landau</a>, 
<a href="/search/cs?searchtype=author&query=Dempsey%2C+J+X">James X. Dempsey</a>, 
<a href="/search/cs?searchtype=author&query=Kamar%2C+E">Ece Kamar</a>, 
<a href="/search/cs?searchtype=author&query=Bellovin%2C+S+M">Steven M. Bellovin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Contestability -- the ability to effectively challenge a decision -- is
critical to the implementation of fairness. In the context of governmental
decision making about individuals, contestability is often constitutionally
required as an element of due process; specific procedures may be required by
state or federal law relevant to a particular program. In addition,
contestability can be a valuable way to discover systemic errors, contributing
to ongoing assessments and system improvement.
<br />On January 24-25, 2024, with support from the National Science Foundation and
the William and Flora Hewlett Foundation, we convened a diverse group of
government officials, representatives of leading technology companies,
technology and policy experts from academia and the non-profit sector,
advocates, and stakeholders for a workshop on advanced automated decision
making, contestability, and the law. Informed by the workshop's rich and
wide-ranging discussion, we offer these recommendations. A full report
summarizing the discussion is in preparation.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01652" title="Abstract">arXiv:2403.01652</a> [<a href="/pdf/2403.01652" title="Download PDF">pdf</a>, <a href="/format/2403.01652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Memory-Efficient Traffic Policing in Time-Sensitive Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuyan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiangrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tongqing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wenwen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+W">Wei Quan</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yihao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yinhan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhigang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Time-Sensitive Networking (TSN) is an emerging real-time Ethernet technology
that provides deterministic communication for time-critical traffic. At its
core, TSN relies on Time-Aware Shaper (TAS) for pre-allocating frames in
specific time intervals and Per-Stream Filtering and Policing (PSFP) for
mitigating the fatal disturbance of unavoidable frame drift. However, as first
identified in this work, PSFP incurs heavy memory consumption during policing,
hindering normal switching functionalities.
<br />This work proposes a lightweight policing design called FooDog, which could
facilitate sub-microsecond jitter with ultra-low memory consumption. FooDog
employs a period-wise and stream-wise structure to realize the memory-efficient
PSFP without loss of determinism. Results using commercial FPGAs in typical
aerospace scenarios show that FooDog could keep end-to-end time-sensitive
traffic jitter &lt;150 nanoseconds in the presence of abnormal traffic, comparable
to typical TSN performance without anomalies. Meanwhile, it consumes merely
hundreds of kilobits of memory, reducing &gt;90% of on-chip memory overheads than
unoptimized PSFP design.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01653" title="Abstract">arXiv:2403.01653</a> [<a href="/pdf/2403.01653" title="Download PDF">pdf</a>, <a href="/format/2403.01653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Day-ahead regional solar power forecasting with hierarchical temporal  convolutional neural networks using historical power generation and weather  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perera%2C+M">Maneesha Perera</a>, 
<a href="/search/cs?searchtype=author&query=De+Hoog%2C+J">Julian De Hoog</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+K">Kasun Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Senanayake%2C+D">Damith Senanayake</a>, 
<a href="/search/cs?searchtype=author&query=Halgamuge%2C+S">Saman Halgamuge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 16 figures, Accepted to the journal of Applied Energy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Regional solar power forecasting, which involves predicting the total power
generation from all rooftop photovoltaic systems in a region holds significant
importance for various stakeholders in the energy sector. However, the vast
amount of solar power generation and weather time series from geographically
dispersed locations that need to be considered in the forecasting process makes
accurate regional forecasting challenging. Therefore, previous work has limited
the focus to either forecasting a single time series (i.e., aggregated time
series) which is the addition of all solar generation time series in a region,
disregarding the location-specific weather effects or forecasting solar
generation time series of each PV site (i.e., individual time series)
independently using location-specific weather data, resulting in a large number
of forecasting models. In this work, we propose two deep-learning-based
regional forecasting methods that can effectively leverage both types of time
series (aggregated and individual) with weather data in a region. We propose
two hierarchical temporal convolutional neural network architectures (HTCNN)
and two strategies to adapt HTCNNs for regional solar power forecasting. At
first, we explore generating a regional forecast using a single HTCNN. Next, we
divide the region into multiple sub-regions based on weather information and
train separate HTCNNs for each sub-region; the forecasts of each sub-region are
then added to generate a regional forecast. The proposed work is evaluated
using a large dataset collected over a year from 101 locations across Western
Australia to provide a day ahead forecast. We compare our approaches with
well-known alternative methods and show that the sub-region HTCNN requires
fewer individual networks and achieves a forecast skill score of 40.2% reducing
a statistically significant error by 6.5% compared to the best counterpart.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01655" title="Abstract">arXiv:2403.01655</a> [<a href="/pdf/2403.01655" title="Download PDF">pdf</a>, <a href="/format/2403.01655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian inference via geometric optics approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sun%2C+Z">Zejun Sun</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+G">Guang-Hui Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Markov chain Monte Carlo (MCMC) simulations have been widely used to generate
samples from the complex posterior distribution in Bayesian inferences.
However, these simulations often require multiple computations of the forward
model in the likelihood function for each drawn sample. This computational
burden renders MCMC sampling impractical when the forward model is
computationally expensive, such as in the case of partial differential equation
models. In this paper, we propose a novel sampling approach called the
geometric optics approximation method (GOAM) for Bayesian inverse problems,
which entirely circumvents the need for MCMC simulations. Our method is rooted
in the problem of reflector shape design, which focuses on constructing a
reflecting surface that redirects rays from a source, with a predetermined
density, towards a target domain while achieving a desired density
distribution. The key idea is to consider the unnormalized Bayesian posterior
as the density on the target domain within the optical system and define a
geometric optics approximation measure with respect to posterior by a
reflecting surface. Consequently, once such a reflecting surface is obtained,
we can utilize it to draw an arbitrary number of independent and uncorrelated
samples from the posterior measure for Bayesian inverse problems. In theory, we
have shown that the geometric optics approximation measure is well-posed. The
efficiency and robustness of our proposed sampler, employing the geometric
optics approximation method, are demonstrated through several numerical
examples provided in this paper.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01660" title="Abstract">arXiv:2403.01660</a> [<a href="/pdf/2403.01660" title="Download PDF">pdf</a>, <a href="/format/2403.01660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry and Stability of Supervised Learning Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%A9moli%2C+F">Facundo M&#xe9;moli</a>, 
<a href="/search/cs?searchtype=author&query=Vose%2C+B">Brantley Vose</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+R+C">Robert C. Williamson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 87 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Metric Geometry (math.MG)

</div>
<p class="mathjax">We introduce a notion of distance between supervised learning problems, which
we call the Risk distance. This optimal-transport-inspired distance facilitates
stability results; one can quantify how seriously issues like sampling bias,
noise, limited data, and approximations might change a given problem by
bounding how much these modifications can move the problem under the Risk
distance. With the distance established, we explore the geometry of the
resulting space of supervised learning problems, providing explicit geodesics
and proving that the set of classification problems is dense in a larger class
of problems. We also provide two variants of the Risk distance: one that
incorporates specified weights on a problem's predictors, and one that is more
sensitive to the contours of a problem's risk landscape.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01662" title="Abstract">arXiv:2403.01662</a> [<a href="/pdf/2403.01662" title="Download PDF">pdf</a>, <a href="/ps/2403.01662" title="Download PostScript">ps</a>, <a href="/format/2403.01662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atropos-k is PSPACE-complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhujun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Burke and Teng introduced a two-player combinatorial game Atropos based on
Sperner's lemma, and showed that deciding whether one has a winning strategy
for Atropos is PSPACE-complete. In the original Atropos game, the players must
color a node adjacent to the last colored node. Burke and Teng also mentioned a
variant Atropos-k in which each move is at most of distance k of the previous
move, and asked a question on determining the computational complexity of this
variant. In this paper, we answer this question by showing that for any fixed
integer k (k&gt;=2), Atropos-k is PSPACE-complete by reduction from True
Quantified Boolean Formula (TQBF).
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01663" title="Abstract">arXiv:2403.01663</a> [<a href="/pdf/2403.01663" title="Download PDF">pdf</a>, <a href="/format/2403.01663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PillarGen: Enhancing Radar Point Cloud Density and Quality via  Pillar-based Point Generation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bang%2C+G">Geonho Bang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kwangjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Seong%2C+M">Minjae Seong</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaechang Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Pyo%2C+E">Eunjong Pyo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+W">Jun Won Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a novel point generation model, referred to as
Pillar-based Point Generation Network (PillarGen), which facilitates the
transformation of point clouds from one domain into another. PillarGen can
produce synthetic point clouds with enhanced density and quality based on the
provided input point clouds. The PillarGen model performs the following three
steps: 1) pillar encoding, 2) Occupied Pillar Prediction (OPP), and 3) Pillar
to Point Generation (PPG). The input point clouds are encoded using a pillar
grid structure to generate pillar features. Then, OPP determines the active
pillars used for point generation and predicts the center of points and the
number of points to be generated for each active pillar. PPG generates the
synthetic points for each active pillar based on the information provided by
OPP. We evaluate the performance of PillarGen using our proprietary radar
dataset, focusing on enhancing the density and quality of short-range radar
data using the long-range radar data as supervision. Our experiments
demonstrate that PillarGen outperforms traditional point upsampling methods in
quantitative and qualitative measures. We also confirm that when PillarGen is
incorporated into bird's eye view object detection, a significant improvement
in detection accuracy is achieved.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01666" title="Abstract">arXiv:2403.01666</a> [<a href="/pdf/2403.01666" title="Download PDF">pdf</a>, <a href="/format/2403.01666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Energy-Based Model via Diffusion Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+C">Cong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tian Han</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng-Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hauberg%2C+S">S&#xf8;ren Hauberg</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Generative models have shown strong generation ability while efficient
likelihood estimation is less explored. Energy-based models~(EBMs) define a
flexible energy function to parameterize unnormalized densities efficiently but
are notorious for being difficult to train. Adversarial EBMs introduce a
generator to form a minimax training game to avoid expensive MCMC sampling used
in traditional EBMs, but a noticeable gap between adversarial EBMs and other
strong generative models still exists. Inspired by diffusion-based models, we
embedded EBMs into each denoising step to split a long-generated process into
several smaller steps. Besides, we employ a symmetric Jeffrey divergence and
introduce a variational posterior distribution for the generator's training to
address the main challenges that exist in adversarial EBMs. Our experiments
show significant improvement in generation compared to existing adversarial
EBMs, while also providing a useful energy function for efficient density
estimation.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01669" title="Abstract">arXiv:2403.01669</a> [<a href="/pdf/2403.01669" title="Download PDF">pdf</a>, <a href="/format/2403.01669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying and Predicting Residential Building Flexibility Using  Machine Learning Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salter%2C+P">Patrick Salter</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiuhua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tabares-Velasco%2C+P+C">Paulo Cesar Tabares-Velasco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Residential buildings account for a significant portion (35\%) of the total
electricity consumption in the U.S. as of 2022. As more distributed energy
resources are installed in buildings, their potential to provide flexibility to
the grid increases. To tap into that flexibility provided by buildings,
aggregators or system operators need to quantify and forecast flexibility.
Previous works in this area primarily focused on commercial buildings, with
little work on residential buildings. To address the gap, this paper first
proposes two complementary flexibility metrics (i.e., power and energy
flexibility) and then investigates several mainstream machine learning-based
models for predicting the time-variant and sporadic flexibility of residential
buildings at four-hour and 24-hour forecast horizons. The
long-short-term-memory (LSTM) model achieves the best performance and can
predict power flexibility for up to 24 hours ahead with the average error
around 0.7 kW. However, for energy flexibility, the LSTM model is only
successful for loads with consistent operational patterns throughout the year
and faces challenges when predicting energy flexibility associated with HVAC
systems.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01671" title="Abstract">arXiv:2403.01671</a> [<a href="/pdf/2403.01671" title="Download PDF">pdf</a>, <a href="/format/2403.01671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permutation invariant functions: statistical tests, dimension reduction  in metric entropy and estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaimanowong%2C+W">Wee Chaimanowong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Ying Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Permutation invariance is among the most common symmetry that can be
exploited to simplify complex problems in machine learning (ML). There has been
a tremendous surge of research activities in building permutation invariant ML
architectures. However, less attention is given to how to statistically test
for permutation invariance of variables in a multivariate probability
distribution where the dimension is allowed to grow with the sample size. Also,
in terms of a statistical theory, little is known about how permutation
invariance helps with estimation in reducing dimensions. In this paper, we take
a step back and examine these questions in several fundamental problems: (i)
testing the assumption of permutation invariance of multivariate distributions;
(ii) estimating permutation invariant densities; (iii) analyzing the metric
entropy of smooth permutation invariant function classes and compare them with
their counterparts without imposing permutation invariance; (iv) kernel ridge
regression of permutation invariant functions in reproducing kernel Hilbert
space. In particular, our methods for (i) and (iv) are based on a sorting trick
and (ii) is based on an averaging trick. These tricks substantially simplify
the exploitation of permutation invariance.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01674" title="Abstract">arXiv:2403.01674</a> [<a href="/pdf/2403.01674" title="Download PDF">pdf</a>, <a href="/format/2403.01674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASPIRe: An Informative Trajectory Planner with Mutual Information  Approximation for Target Search and Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kangjie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yao Su</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Han Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Ji Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hangxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes an informative trajectory planning approach, namely,
\textit{adaptive particle filter tree with sigma point-based mutual information
reward approximation} (ASPIRe), for mobile target search and tracking (SAT) in
cluttered environments with limited sensing field of view. We develop a novel
sigma point-based approximation to accurately estimate mutual information (MI)
for general, non-Gaussian distributions utilizing particle representation of
the belief state, while simultaneously maintaining high computational
efficiency. Building upon the MI approximation, we develop the Adaptive
Particle Filter Tree (APFT) approach with MI as the reward, which features
belief state tree nodes for informative trajectory planning in continuous state
and measurement spaces. An adaptive criterion is proposed in APFT to adjust the
planning horizon based on the expected information gain. Simulations and
physical experiments demonstrate that ASPIRe achieves real-time computation and
outperforms benchmark methods in terms of both search efficiency and estimation
accuracy.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01680" title="Abstract">arXiv:2403.01680</a> [<a href="/pdf/2403.01680" title="Download PDF">pdf</a>, <a href="/format/2403.01680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Generalizable Incremental Learning for Vision-Language Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jieren Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haojian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Kun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianhua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunkuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents Incremental Vision-Language Object Detection (IVLOD), a
novel learning task designed to incrementally adapt pre-trained Vision-Language
Object Detection Models (VLODMs) to various specialized domains, while
simultaneously preserving their zero-shot generalization capabilities for the
generalized domain. To address this new challenge, we present the
Zero-interference Reparameterizable Adaptation (ZiRa), a novel method that
introduces Zero-interference Loss and reparameterization techniques to tackle
IVLOD without incurring additional inference costs or a significant increase in
memory usage. Comprehensive experiments on COCO and ODinW-13 datasets
demonstrate that ZiRa effectively safeguards the zero-shot generalization
ability of VLODMs while continuously adapting to new tasks. Specifically, after
training on ODinW-13 datasets, ZiRa exhibits superior performance compared to
CL-DETR and iDETR, boosting zero-shot generalizability by substantial 13.91 and
8.71 AP, respectively.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01683" title="Abstract">arXiv:2403.01683</a> [<a href="/pdf/2403.01683" title="Download PDF">pdf</a>, <a href="/format/2403.01683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DD-VNB: A Depth-based Dual-Loop Framework for Real-time Visually  Navigated Bronchoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qingyao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Huai Liao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bingyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ourselin%2C+S">Sebastien Ourselin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongbin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time 6 DOF localization of bronchoscopes is crucial for enhancing
intervention quality. However, current vision-based technologies struggle to
balance between generalization to unseen data and computational speed. In this
study, we propose a Depth-based Dual-Loop framework for real-time Visually
Navigated Bronchoscopy (DD-VNB) that can generalize across patient cases
without the need of re-training. The DD-VNB framework integrates two key
modules: depth estimation and dual-loop localization. To address the domain gap
among patients, we propose a knowledge-embedded depth estimation network that
maps endoscope frames to depth, ensuring generalization by eliminating
patient-specific textures. The network embeds view synthesis knowledge into a
cycle adversarial architecture for scale-constrained monocular depth
estimation. For real-time performance, our localization module embeds a fast
ego-motion estimation network into the loop of depth registration. The
ego-motion inference network estimates the pose change of the bronchoscope in
high frequency while depth registration against the pre-operative 3D model
provides absolute pose periodically. Specifically, the relative pose changes
are fed into the registration process as the initial guess to boost its
accuracy and speed. Experiments on phantom and in-vivo data from patients
demonstrate the effectiveness of our framework: 1) monocular depth estimation
outperforms SOTA, 2) localization achieves an accuracy of Absolute Tracking
Error (ATE) of 4.7 $\pm$ 3.17 mm in phantom and 6.49 $\pm$ 3.88 mm in patient
data, 3) with a frame-rate approaching video capture speed, 4) without the
necessity of case-wise network retraining. The framework's superior speed and
accuracy demonstrate its promising clinical potential for real-time
bronchoscopic navigation.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01690" title="Abstract">arXiv:2403.01690</a> [<a href="/pdf/2403.01690" title="Download PDF">pdf</a>, <a href="/format/2403.01690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singular value decompositions of third-order reduced biquaternion  tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+C">Cui-E Yu</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce the applications of third-order reduced
biquaternion tensors in color video processing. We first develop algorithms for
computing the singular value decomposition (SVD) of a third-order reduced
biquaternion tensor via a new Ht-product. As theoretical applications, we
define the Moore-Penrose inverse of a third-order reduced biquaternion tensor
and develop its characterizations. In addition, we discuss the general (or
Hermitian) solutions to reduced biquaternion tensor equation
$\mathcal{A}\ast_{Ht} \mathcal{X}=\mathcal{B}$ as well as its least-square
solution. Finally, we compress the color video by this SVD, and the
experimental data shows that our method is faster than the compared scheme.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01693" title="Abstract">arXiv:2403.01693</a> [<a href="/pdf/2403.01693" title="Download PDF">pdf</a>, <a href="/format/2403.01693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narasimhaswamy%2C+S">Supreeth Narasimhaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+U">Uttaran Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+I">Ishita Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Saayan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Hoai%2C+M">Minh Hoai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-image generative models can generate high-quality humans, but realism
is lost when generating hands. Common artifacts include irregular hand poses,
shapes, incorrect numbers of fingers, and physically implausible finger
orientations. To generate images with realistic hands, we propose a novel
diffusion-based architecture called HanDiffuser that achieves realism by
injecting hand embeddings in the generative process. HanDiffuser consists of
two components: a Text-to-Hand-Params diffusion model to generate SMPL-Body and
MANO-Hand parameters from input text prompts, and a Text-Guided
Hand-Params-to-Image diffusion model to synthesize images by conditioning on
the prompts and hand parameters generated by the previous component. We
incorporate multiple aspects of hand representation, including 3D shapes and
joint-level finger positions, orientations and articulations, for robust
learning and reliable performance during inference. We conduct extensive
quantitative and qualitative experiments and perform user studies to
demonstrate the efficacy of our method in generating images with high-quality
hands.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01694" title="Abstract">arXiv:2403.01694</a> [<a href="/pdf/2403.01694" title="Download PDF">pdf</a>, <a href="/format/2403.01694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tac-Man: Tactile-Informed Prior-Free Manipulation of Articulated Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhenghao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+L">Lecheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yixin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Althoefer%2C+K">Kaspar Althoefer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Integrating robotics into human-centric environments such as homes,
necessitates advanced manipulation skills as robotic devices will need to
engage with articulated objects like doors and drawers. Key challenges in
robotic manipulation are the unpredictability and diversity of these objects'
internal structures, which render models based on priors, both explicit and
implicit, inadequate. Their reliability is significantly diminished by
pre-interaction ambiguities, imperfect structural parameters, encounters with
unknown objects, and unforeseen disturbances. Here, we present a prior-free
strategy, Tac-Man, focusing on maintaining stable robot-object contact during
manipulation. Utilizing tactile feedback, but independent of object priors,
Tac-Man enables robots to proficiently handle a variety of articulated objects,
including those with complex joints, even when influenced by unexpected
disturbances. Demonstrated in both real-world experiments and extensive
simulations, it consistently achieves near-perfect success in dynamic and
varied settings, outperforming existing methods. Our results indicate that
tactile sensing alone suffices for managing diverse articulated objects,
offering greater robustness and generalization than prior-based approaches.
This underscores the importance of detailed contact modeling in complex
manipulation tasks, especially with articulated objects. Advancements in
tactile sensors significantly expand the scope of robotic applications in
human-centric environments, particularly where accurate models are difficult to
obtain.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01695" title="Abstract">arXiv:2403.01695</a> [<a href="/pdf/2403.01695" title="Download PDF">pdf</a>, <a href="/format/2403.01695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyCE: Dynamic Configurable Exiting for Deep Learning Compression and  Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cardiff%2C+B">Barry Cardiff</a>, 
<a href="/search/cs?searchtype=author&query=Frapp%C3%A9%2C+A">Antoine Frapp&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Larras%2C+B">Benoit Larras</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+D">Deepu John</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern deep learning (DL) models necessitate the employment of scaling and
compression techniques for effective deployment in resource-constrained
environments. Most existing techniques, such as pruning and quantization are
generally static. On the other hand, dynamic compression methods, such as early
exits, reduce complexity by recognizing the difficulty of input samples and
allocating computation as needed. Dynamic methods, despite their superior
flexibility and potential for co-existing with static methods, pose significant
challenges in terms of implementation due to any changes in dynamic parts will
influence subsequent processes. Moreover, most current dynamic compression
designs are monolithic and tightly integrated with base models, thereby
complicating the adaptation to novel base models. This paper introduces DyCE,
an dynamic configurable early-exit framework that decouples design
considerations from each other and from the base model. Utilizing this
framework, various types and positions of exits can be organized according to
predefined configurations, which can be dynamically switched in real-time to
accommodate evolving performance-complexity requirements. We also propose
techniques for generating optimized configurations based on any desired
trade-off between performance and computational complexity. This empowers
future researchers to focus on the improvement of individual exits without
latent compromise of overall system performance. The efficacy of this approach
is demonstrated through image classification tasks with deep CNNs. DyCE
significantly reduces the computational complexity by 23.5% of ResNet152 and
25.9% of ConvNextv2-tiny on ImageNet, with accuracy reductions of less than
0.5%. Furthermore, DyCE offers advantages over existing dynamic methods in
terms of real-time configuration and fine-grained performance tuning.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01697" title="Abstract">arXiv:2403.01697</a> [<a href="/pdf/2403.01697" title="Download PDF">pdf</a>, <a href="/format/2403.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dismantling Gender Blindness in Online Discussion of a Crime/Gender  Dichotomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yigang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+W">Weilun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qunfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 3 figures, Accepted for publication in Proceedings of the ACM on Human-Computer Interaction (CSCW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Contemporary feminists utilize social media for activism, while backlashes
come along. The gender-related discourses are often diminished when addressing
public events regarding sexism and gender inequality on social media platforms.
The dichotomized debate around the Tangshan beating incident in China
epitomized how criminal interpretations of gender-related violence became a
backlash against feminist expressions. By analyzing posts on Weibo using mixed
methods, we describe the emerging discursive patterns around crime and gender,
uncovering the inherent gender-blind sexism that refutes feminist discourses on
the social platform. We also highlight the critical restrictions facing
grassroots feminist activism in Chinese cyberspace and propose implications for
the design and research related to digital feminist activism.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01698" title="Abstract">arXiv:2403.01698</a> [<a href="/pdf/2403.01698" title="Download PDF">pdf</a>, <a href="/format/2403.01698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypertext Entity Extraction in Webpage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+B">Bo Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Daxin Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Webpage entity extraction is a fundamental natural language processing task
in both research and applications. Nowadays, the majority of webpage entity
extraction models are trained on structured datasets which strive to retain
textual content and its structure information. However, existing datasets all
overlook the rich hypertext features (e.g., font color, font size) which show
their effectiveness in previous works. To this end, we first collect a
\textbf{H}ypertext \textbf{E}ntity \textbf{E}xtraction \textbf{D}ataset
(\textit{HEED}) from the e-commerce domains, scraping both the text and the
corresponding explicit hypertext features with high-quality manual entity
annotations. Furthermore, we present the \textbf{Mo}E-based \textbf{E}ntity
\textbf{E}xtraction \textbf{F}ramework (\textit{MoEEF}), which efficiently
integrates multiple features to enhance model performance by Mixture of Experts
and outperforms strong baselines, including the state-of-the-art small-scale
models and GPT-3.5-turbo. Moreover, the effectiveness of hypertext features in
\textit{HEED} and several model components in \textit{MoEEF} are analyzed.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01699" title="Abstract">arXiv:2403.01699</a> [<a href="/pdf/2403.01699" title="Download PDF">pdf</a>, <a href="/format/2403.01699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brilla AI: AI Contestant for the National Science and Maths Quiz
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boateng%2C+G">George Boateng</a>, 
<a href="/search/cs?searchtype=author&query=Mensah%2C+J+A">Jonathan Abrefah Mensah</a>, 
<a href="/search/cs?searchtype=author&query=Yeboah%2C+K+T">Kevin Takyi Yeboah</a>, 
<a href="/search/cs?searchtype=author&query=Edor%2C+W">William Edor</a>, 
<a href="/search/cs?searchtype=author&query=Mensah-Onumah%2C+A+K">Andrew Kojo Mensah-Onumah</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+N+D">Naafi Dasana Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Yeboah%2C+N+S">Nana Sam Yeboah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. Under review at the 25th International Conference on AI in Education (AIED 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The African continent lacks enough qualified teachers which hampers the
provision of adequate learning support. An AI could potentially augment the
efforts of the limited number of teachers, leading to better learning outcomes.
Towards that end, this work describes and evaluates the first key output for
the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for
such an AI: "Build an AI to compete live in Ghana's National Science and Maths
Quiz (NSMQ) competition and win - performing better than the best contestants
in all rounds and stages of the competition". The NSMQ is an annual live
science and mathematics competition for senior secondary school students in
Ghana in which 3 teams of 2 students compete by answering questions across
biology, chemistry, physics, and math in 5 rounds over 5 progressive stages
until a winning team is crowned for that year. In this work, we built Brilla
AI, an AI contestant that we deployed to unofficially compete remotely and live
in the Riddles round of the 2023 NSMQ Grand Finale, the first of its kind in
the 30-year history of the competition. Brilla AI is currently available as a
web app that livestreams the Riddles round of the contest, and runs 4 machine
learning systems: (1) speech to text (2) question extraction (3) question
answering and (4) text to speech that work together in real-time to quickly and
accurately provide an answer, and then say it with a Ghanaian accent. In its
debut, our AI answered one of the 4 riddles ahead of the 3 human contesting
teams, unofficially placing second (tied). Improvements and extensions of this
AI could potentially be deployed to offer science tutoring to students and
eventually enable millions across Africa to have one-on-one learning
interactions, democratizing science education.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01700" title="Abstract">arXiv:2403.01700</a> [<a href="/pdf/2403.01700" title="Download PDF">pdf</a>, <a href="/format/2403.01700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Wake Word Spotting With Frame-Level Cross-Modal Attention Based  Audio-Visual Conformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent years, neural network-based Wake Word Spotting achieves good
performance on clean audio samples but struggles in noisy environments.
Audio-Visual Wake Word Spotting (AVWWS) receives lots of attention because
visual lip movement information is not affected by complex acoustic scenes.
Previous works usually use simple addition or concatenation for multi-modal
fusion. The inter-modal correlation remains relatively under-explored. In this
paper, we propose a novel module called Frame-Level Cross-Modal Attention
(FLCMA) to improve the performance of AVWWS systems. This module can help model
multi-modal information at the frame-level through synchronous lip movements
and speech signals. We train the end-to-end FLCMA based Audio-Visual Conformer
and further improve the performance by fine-tuning pre-trained uni-modal models
for the AVWWS task. The proposed system achieves a new state-of-the-art result
(4.57% WWS score) on the far-field MISP dataset.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01709" title="Abstract">arXiv:2403.01709</a> [<a href="/pdf/2403.01709" title="Download PDF">pdf</a>, <a href="/format/2403.01709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLMs Generate Architectural Design Decisions? -An Exploratory  Empirical study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhar%2C+R">Rudra Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Vaidhyanathan%2C+K">Karthik Vaidhyanathan</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+V">Vasudeva Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to IEEE ICSA 2024 (Main Track - Research Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Architectural Knowledge Management (AKM) involves the organized handling of
information related to architectural decisions and design within a project or
organization. An essential artifact of AKM is the Architecture Decision Records
(ADR), which documents key design decisions. ADRs are documents that capture
decision context, decision made and various aspects related to a design
decision, thereby promoting transparency, collaboration, and understanding.
Despite their benefits, ADR adoption in software development has been slow due
to challenges like time constraints and inconsistent uptake. Recent
advancements in Large Language Models (LLMs) may help bridge this adoption gap
by facilitating ADR generation. However, the effectiveness of LLM for ADR
generation or understanding is something that has not been explored. To this
end, in this work, we perform an exploratory study that aims to investigate the
feasibility of using LLM for the generation of ADRs given the decision context.
In our exploratory study, we utilize GPT and T5-based models with 0-shot,
few-shot, and fine-tuning approaches to generate the Decision of an ADR given
its Context. Our results indicate that in a 0-shot setting, state-of-the-art
models such as GPT-4 generate relevant and accurate Design Decisions, although
they fall short of human-level performance. Additionally, we observe that more
cost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot
setting, and smaller models such as Flan-T5 can yield comparable results after
fine-tuning. To conclude, this exploratory study suggests that LLM can generate
Design Decisions, but further research is required to attain human-level
generation and establish standardized widespread adoption.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01710" title="Abstract">arXiv:2403.01710</a> [<a href="/pdf/2403.01710" title="Download PDF">pdf</a>, <a href="/format/2403.01710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensor-based Multi-Robot Search and Coverage with Spatial Separation in  Unstructured Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chuanxiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yizhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenggang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B+M">Ben M. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-robot systems have increasingly become instrumental in tackling search
and coverage problems. However, the challenge of optimizing task efficiency
without compromising task success still persists, particularly in expansive,
unstructured environments with dense obstacles.
<br />This paper presents an innovative, decentralized Voronoi-based approach for
search and coverage to reactively navigate these complexities while maintaining
safety.
<br />This approach leverages the active sensing capabilities of multi-robot
systems to supplement GIS (Geographic Information System), offering a more
comprehensive and real-time understanding of the environment. Based on point
cloud data, which is inherently non-convex and unstructured, this method
efficiently generates collision-free Voronoi regions using only local sensing
information through spatial decomposition and spherical mirroring techniques.
<br />Then, deadlock-aware guided map integrated with a gradient-optimized,
centroid Voronoi-based coverage control policy, is constructed to improve
efficiency by avoiding exhaustive searches and local sensing pitfalls.
<br />The effectiveness of our algorithm has been validated through extensive
numerical simulations in high-fidelity environments, demonstrating significant
improvements in both task success rate, coverage ratio, and task execution time
compared with others.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01713" title="Abstract">arXiv:2403.01713</a> [<a href="/pdf/2403.01713" title="Download PDF">pdf</a>, <a href="/format/2403.01713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCA: Moment Channel Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangbo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Le Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zenan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nenggan Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Channel attention mechanisms endeavor to recalibrate channel weights to
enhance representation abilities of networks. However, mainstream methods often
rely solely on global average pooling as the feature squeezer, which
significantly limits the overall potential of models. In this paper, we
investigate the statistical moments of feature maps within a neural network.
Our findings highlight the critical role of high-order moments in enhancing
model capacity. Consequently, we introduce a flexible and comprehensive
mechanism termed Extensive Moment Aggregation (EMA) to capture the global
spatial context. Building upon this mechanism, we propose the Moment Channel
Attention (MCA) framework, which efficiently incorporates multiple levels of
moment-based information while minimizing additional computation costs through
our Cross Moment Convolution (CMC) module. The CMC module via channel-wise
convolution layer to capture multiple order moment information as well as cross
channel features. The MCA block is designed to be lightweight and easily
integrated into a variety of neural network architectures. Experimental results
on classical image classification, object detection, and instance segmentation
tasks demonstrate that our proposed method achieves state-of-the-art results,
outperforming existing channel attention methods.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01715" title="Abstract">arXiv:2403.01715</a> [<a href="/pdf/2403.01715" title="Download PDF">pdf</a>, <a href="/format/2403.01715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Job Seeking for People with Autism: Challenges and Design  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ara%2C+Z">Zinat Ara</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+A">Amrita Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Peppard%2C+D">Donna Peppard</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+D">Dongjun Chung</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+S">Slobodan Vucetic</a>, 
<a href="/search/cs?searchtype=author&query=Motti%2C+V+G">Vivian Genaro Motti</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+R">Sungsoo Ray Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Successful job search results from job seekers' well-shaped social
communication. While well-known differences in communication exist between
people with autism and neurotypicals, little is known about how people with
autism collaborate with their social surroundings to strive in the job market.
To better understand the practices and challenges of collaborative job seeking
for people with autism, we interviewed 20 participants including applicants
with autism, their social surroundings, and career experts. Through the
interviews, we identified social challenges that people with autism face during
their job seeking; the social support they leverage to be successful; and the
technological limitations that hinder their collaboration. We designed four
probes that represent major collaborative features found from the
interviews--executive planning, communication, stage-wise preparation, and
neurodivergent community formation--and discussed their potential usefulness
and impact through three focus groups. We provide implications regarding how
our findings can enhance collaborative job seeking experiences for people with
autism through new designs.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01718" title="Abstract">arXiv:2403.01718</a> [<a href="/pdf/2403.01718" title="Download PDF">pdf</a>, <a href="/ps/2403.01718" title="Download PostScript">ps</a>, <a href="/format/2403.01718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> L0 Regularization of Field-Aware Factorization Machine through Ising  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+Y">Yasuharu Okamoto</a> (1,2) ((1) Secure System Platform Research Laboratories, NEC Corporation, Nakahara-ku, Kawasaki, Kanagawa, Japan, (2) NEC-AIST Quantum Technology Cooperative Research Laboratories, Tsukuba, Ibaraki, Japan)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">We examined the use of the Ising model as an L0 regularization method for
field-aware factorization machines (FFM). This approach improves generalization
performance and has the advantage of simultaneously determining the best
feature combinations for each of several groups. We can deepen the
interpretation and understanding of the model from the similarities and
differences in the features selected in each group.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01722" title="Abstract">arXiv:2403.01722</a> [<a href="/pdf/2403.01722" title="Download PDF">pdf</a>, <a href="/format/2403.01722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Knowledge Gap in Designing Data Annotation Interfaces for  AI-powered Disaster Management Analytic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ara%2C+Z">Zinat Ara</a>, 
<a href="/search/cs?searchtype=author&query=Salemi%2C+H">Hossein Salemi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+R">Sungsoo Ray Hong</a>, 
<a href="/search/cs?searchtype=author&query=Senarath%2C+Y">Yasas Senarath</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+S">Steve Peterson</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+A+L">Amanda Lee Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+H">Hemant Purohit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Data annotation interfaces predominantly leverage ground truth labels to
guide annotators toward accurate responses. With the growing adoption of
Artificial Intelligence (AI) in domain-specific professional tasks, it has
become increasingly important to help beginning annotators identify how their
early-stage knowledge can lead to inaccurate answers, which in turn, helps to
ensure quality annotations at scale. To investigate this issue, we conducted a
formative study involving eight individuals from the field of disaster
management, each possessing varying levels of expertise. The goal was to
understand the prevalent factors contributing to disagreements among annotators
when classifying Twitter messages related to disasters and to analyze their
respective responses. Our analysis identified two primary causes of
disagreement between expert and beginner annotators: 1) a lack of contextual
knowledge or uncertainty about the situation, and 2) the absence of visual or
supplementary cues. Based on these findings, we designed a Context interface,
which generates aids that help beginners identify potential mistakes and
provide the hidden context of the presented tweet. The summative study compares
Context design with two widely used designs in data annotation UI, Highlight
and Reasoning-based interfaces. We found significant differences between these
designs in terms of attitudinal and behavioral data. We conclude with
implications for designing future interfaces aiming at closing the knowledge
gap among annotators.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01731" title="Abstract">arXiv:2403.01731</a> [<a href="/pdf/2403.01731" title="Download PDF">pdf</a>, <a href="/format/2403.01731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RISeg: Robot Interactive Object Segmentation via Body Frame-Invariant  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+H+H">Howard H. Qian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yangxiao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kejia Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Khargonkar%2C+N">Ninad Khargonkar</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Hang%2C+K">Kaiyu Hang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In order to successfully perform manipulation tasks in new environments, such
as grasping, robots must be proficient in segmenting unseen objects from the
background and/or other objects. Previous works perform unseen object instance
segmentation (UOIS) by training deep neural networks on large-scale data to
learn RGB/RGB-D feature embeddings, where cluttered environments often result
in inaccurate segmentations. We build upon these methods and introduce a novel
approach to correct inaccurate segmentation, such as under-segmentation, of
static image-based UOIS masks by using robot interaction and a designed body
frame-invariant feature. We demonstrate that the relative linear and rotational
velocities of frames randomly attached to rigid bodies due to robot
interactions can be used to identify objects and accumulate corrected
object-level segmentation masks. By introducing motion to regions of
segmentation uncertainty, we are able to drastically improve segmentation
accuracy in an uncertainty-driven manner with minimal, non-disruptive
interactions (ca. 2-3 per scene). We demonstrate the effectiveness of our
proposed interactive perception pipeline in accurately segmenting cluttered
scenes by achieving an average object segmentation accuracy rate of 80.7%, an
increase of 28.2% when compared with other state-of-the-art UOIS methods.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01733" title="Abstract">arXiv:2403.01733</a> [<a href="/pdf/2403.01733" title="Download PDF">pdf</a>, <a href="/format/2403.01733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Hand Reconstruction via Aggregating Intra and Inter Graphs Guided by  Prior Knowledge for Hand-Object Interaction Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shuang%2C+F">Feng Shuang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenbo He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaodong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D hand reconstruction has gained more attention in human-computer
cooperation, especially for hand-object interaction scenario. However, it still
remains huge challenge due to severe hand-occlusion caused by interaction,
which contain the balance of accuracy and physical plausibility, highly
nonlinear mapping of model parameters and occlusion feature enhancement. To
overcome these issues, we propose a 3D hand reconstruction network combining
the benefits of model-based and model-free approaches to balance accuracy and
physical plausibility for hand-object interaction scenario. Firstly, we present
a novel MANO pose parameters regression module from 2D joints directly, which
avoids the process of highly nonlinear mapping from abstract image feature and
no longer depends on accurate 3D joints. Moreover, we further propose a
vertex-joint mutual graph-attention model guided by MANO to jointly refine hand
meshes and joints, which model the dependencies of vertex-vertex and
joint-joint and capture the correlation of vertex-joint for aggregating
intra-graph and inter-graph node features respectively. The experimental
results demonstrate that our method achieves a competitive performance on
recently benchmark datasets HO3DV2 and Dex-YCB, and outperforms all only
model-base approaches and model-free approaches.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01734" title="Abstract">arXiv:2403.01734</a> [<a href="/pdf/2403.01734" title="Download PDF">pdf</a>, <a href="/format/2403.01734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Goal-Conditioned Reinforcement Learning for Safety-Critical  Tasks with Recovery Policy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chenyang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zichen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Renhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Junbo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Offline goal-conditioned reinforcement learning (GCRL) aims at solving
goal-reaching tasks with sparse rewards from an offline dataset. While prior
work has demonstrated various approaches for agents to learn near-optimal
policies, these methods encounter limitations when dealing with diverse
constraints in complex environments, such as safety constraints. Some of these
approaches prioritize goal attainment without considering safety, while others
excessively focus on safety at the expense of training efficiency. In this
paper, we study the problem of constrained offline GCRL and propose a new
method called Recovery-based Supervised Learning (RbSL) to accomplish
safety-critical tasks with various goals. To evaluate the method performance,
we build a benchmark based on the robot-fetching environment with a randomly
positioned obstacle and use expert or random policies to generate an offline
dataset. We compare RbSL with three offline GCRL algorithms and one offline
safe RL algorithm. As a result, our method outperforms the existing
state-of-the-art methods to a large extent. Furthermore, we validate the
practicality and effectiveness of RbSL by deploying it on a real Panda
manipulator. Code is available at https://github.com/Sunlighted/RbSL.git.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01736" title="Abstract">arXiv:2403.01736</a> [<a href="/pdf/2403.01736" title="Download PDF">pdf</a>, <a href="/format/2403.01736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Object Detection: A Study Based on YOLOv7 Integrated with  ShuffleNetv2 and Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wenkai Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As mobile computing technology rapidly evolves, deploying efficient object
detection algorithms on mobile devices emerges as a pivotal research area in
computer vision. This study zeroes in on optimizing the YOLOv7 algorithm to
boost its operational efficiency and speed on mobile platforms while ensuring
high accuracy. Leveraging a synergy of advanced techniques such as Group
Convolution, ShuffleNetV2, and Vision Transformer, this research has
effectively minimized the model's parameter count and memory usage, streamlined
the network architecture, and fortified the real-time object detection
proficiency on resource-constrained devices. The experimental outcomes reveal
that the refined YOLO model demonstrates exceptional performance, markedly
enhancing processing velocity while sustaining superior detection accuracy.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01738" title="Abstract">arXiv:2403.01738</a> [<a href="/pdf/2403.01738" title="Download PDF">pdf</a>, <a href="/format/2403.01738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComS2T: A complementary spatiotemporal learning system for data-adaptive  model evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qihe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jianpeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Spatiotemporal (ST) learning has become a crucial technique to enable smart
cities and sustainable urban development. Current ST learning models capture
the heterogeneity via various spatial convolution and temporal evolution
blocks. However, rapid urbanization leads to fluctuating distributions in urban
data and city structures over short periods, resulting in existing methods
suffering generalization and data adaptation issues. Despite efforts, existing
methods fail to deal with newly arrived observations and those methods with
generalization capacity are limited in repeated training. Motivated by
complementary learning in neuroscience, we introduce a prompt-based
complementary spatiotemporal learning termed ComS2T, to empower the evolution
of models for data adaptation. ComS2T partitions the neural architecture into a
stable neocortex for consolidating historical memory and a dynamic hippocampus
for new knowledge update. We first disentangle two disjoint structures into
stable and dynamic weights, and then train spatial and temporal prompts by
characterizing distribution of main observations to enable prompts adaptive to
new data. This data-adaptive prompt mechanism, combined with a two-stage
training process, facilitates fine-tuning of the neural architecture
conditioned on prompts, thereby enabling efficient adaptation during testing.
Extensive experiments validate the efficacy of ComS2T in adapting to various
spatiotemporal out-of-distribution scenarios while maintaining efficient
inference capabilities.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01740" title="Abstract">arXiv:2403.01740</a> [<a href="/pdf/2403.01740" title="Download PDF">pdf</a>, <a href="/format/2403.01740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEMOS: Dynamic Environment Motion Synthesis in 3D Scenes via Local  Spherical-BEV Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jingyu Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Min Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Motion synthesis in real-world 3D scenes has recently attracted much
attention. However, the static environment assumption made by most current
methods usually cannot be satisfied especially for real-time motion synthesis
in scanned point cloud scenes, if multiple dynamic objects exist, e.g., moving
persons or vehicles. To handle this problem, we propose the first Dynamic
Environment MOtion Synthesis framework (DEMOS) to predict future motion
instantly according to the current scene, and use it to dynamically update the
latent motion for final motion synthesis. Concretely, we propose a
Spherical-BEV perception method to extract local scene features that are
specifically designed for instant scene-aware motion prediction. Then, we
design a time-variant motion blending to fuse the new predicted motions into
the latent motion, and the final motion is derived from the updated latent
motions, benefitting both from motion-prior and iterative methods. We unify the
data format of two prevailing datasets, PROX and GTA-IM, and take them for
motion synthesis evaluation in 3D scenes. We also assess the effectiveness of
the proposed method in dynamic environments from GTA-IM and Semantic3D to check
the responsiveness. The results show our method outperforms previous works
significantly and has great performance in handling dynamic environments.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01742" title="Abstract">arXiv:2403.01742</a> [<a href="/pdf/2403.01742" title="Download PDF">pdf</a>, <a href="/format/2403.01742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-TS: Interpretable Diffusion for General Time Series Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xinyu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yan Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Denoising diffusion probabilistic models (DDPMs) are becoming the leading
paradigm for generative models. It has recently shown breakthroughs in audio
synthesis, time series imputation and forecasting. In this paper, we propose
Diffusion-TS, a novel diffusion-based framework that generates multivariate
time series samples of high quality by using an encoder-decoder transformer
with disentangled temporal representations, in which the decomposition
technique guides Diffusion-TS to capture the semantic meaning of time series
while transformers mine detailed sequential information from the noisy model
input. Different from existing diffusion-based approaches, we train the model
to directly reconstruct the sample instead of the noise in each diffusion step,
combining a Fourier-based loss term. Diffusion-TS is expected to generate time
series satisfying both interpretablity and realness. In addition, it is shown
that the proposed Diffusion-TS can be easily extended to conditional generation
tasks, such as forecasting and imputation, without any model changes. This also
motivates us to further explore the performance of Diffusion-TS under irregular
settings. Finally, through qualitative and quantitative experiments, results
show that Diffusion-TS achieves the state-of-the-art results on various
realistic analyses of time series.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01744" title="Abstract">arXiv:2403.01744</a> [<a href="/pdf/2403.01744" title="Download PDF">pdf</a>, <a href="/format/2403.01744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoteLLM: A Retrievable Large Language Model for Note Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shiwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a WWW'24 full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">People enjoy sharing "notes" including their experiences within online
communities. Therefore, recommending notes aligned with user interests has
become a crucial task. Existing online methods only input notes into BERT-based
models to generate note embeddings for assessing similarity. However, they may
underutilize some important cues, e.g., hashtags or categories, which represent
the key concepts of notes. Indeed, learning to generate hashtags/categories can
potentially enhance note embeddings, both of which compress key note
information into limited content. Besides, Large Language Models (LLMs) have
significantly outperformed BERT in understanding natural languages. It is
promising to introduce LLMs into note recommendation. In this paper, we propose
a novel unified framework called NoteLLM, which leverages LLMs to address the
item-to-item (I2I) note recommendation. Specifically, we utilize Note
Compression Prompt to compress a note into a single special token, and further
learn the potentially related notes' embeddings via a contrastive learning
approach. Moreover, we use NoteLLM to summarize the note and generate the
hashtag/category automatically through instruction tuning. Extensive
validations on real scenarios demonstrate the effectiveness of our proposed
method compared with the online baseline and show major improvements in the
recommendation system of Xiaohongshu.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01747" title="Abstract">arXiv:2403.01747</a> [<a href="/pdf/2403.01747" title="Download PDF">pdf</a>, <a href="/format/2403.01747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Self-Contained Answers: Entity-Based Answer Rewriting in  Conversational Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sekuli%C4%87%2C+I">Ivan Sekuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Balog%2C+K">Krisztian Balog</a>, 
<a href="/search/cs?searchtype=author&query=Crestani%2C+F">Fabio Crestani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Conversational information-seeking (CIS) is an emerging paradigm for
knowledge acquisition and exploratory search. Traditional web search interfaces
enable easy exploration of entities, but this is limited in conversational
settings due to the limited-bandwidth interface. This paper explore ways to
rewrite answers in CIS, so that users can understand them without having to
resort to external services or sources. Specifically, we focus on salient
entities -- entities that are central to understanding the answer. As our first
contribution, we create a dataset of conversations annotated with entities for
saliency. Our analysis of the collected data reveals that the majority of
answers contain salient entities. As our second contribution, we propose two
answer rewriting strategies aimed at improving the overall user experience in
CIS. One approach expands answers with inline definitions of salient entities,
making the answer self-contained. The other approach complements answers with
follow-up questions, offering users the possibility to learn more about
specific entities. Results of a crowdsourcing-based study indicate that
rewritten answers are clearly preferred over the original ones. We also find
that inline definitions tend to be favored over follow-up questions, but this
choice is highly subjective, thereby providing a promising future direction for
personalization.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01748" title="Abstract">arXiv:2403.01748</a> [<a href="/pdf/2403.01748" title="Download PDF">pdf</a>, <a href="/format/2403.01748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decode Neural signal as Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decoding language from brain dynamics is an important open direction in the
realm of brain-computer interface (BCI), especially considering the rapid
growth of large language models. Compared to invasive-based signals which
require electrode implantation surgery, non-invasive neural signals (e.g. EEG,
MEG) have attracted increasing attention considering their safety and
generality. However, the exploration is not adequate in three aspects: 1)
previous methods mainly focus on EEG but none of the previous works address
this problem on MEG with better signal quality; 2) prior works have
predominantly used ``teacher-forcing" during generative decoding, which is
impractical; 3) prior works are mostly ``BART-based" not fully auto-regressive,
which performs better in other sequence tasks. In this paper, we explore the
brain-to-text translation of MEG signals in a speech-decoding formation. Here
we are the first to investigate a cross-attention-based ``whisper" model for
generating text directly from MEG signals without teacher forcing. Our model
achieves impressive BLEU-1 scores of 60.30 and 52.89 without pretraining \&amp;
teacher-forcing on two major datasets (\textit{GWilliams} and
\textit{Schoffelen}). This paper conducts a comprehensive review to understand
how speech decoding formation performs on the neural decoding tasks, including
pretraining initialization, training \&amp; evaluation set splitting, augmentation,
and scaling law.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01749" title="Abstract">arXiv:2403.01749</a> [<a href="/pdf/2403.01749" title="Download PDF">pdf</a>, <a href="/format/2403.01749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Synthetic Data via Foundation Model APIs 2: Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Backurs%2C+A">Arturs Backurs</a>, 
<a href="/search/cs?searchtype=author&query=Gopi%2C+S">Sivakanth Gopi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Da Yu</a>, 
<a href="/search/cs?searchtype=author&query=Inan%2C+H+A">Huseyin A Inan</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+H">Harsha Nori</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haotian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+T">Yin Tat Lee</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yekhanin%2C+S">Sergey Yekhanin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text data has become extremely valuable due to the emergence of machine
learning algorithms that learn from it. A lot of high-quality text data
generated in the real world is private and therefore cannot be shared or used
freely due to privacy concerns. Generating synthetic replicas of private text
data with a formal privacy guarantee, i.e., differential privacy (DP), offers a
promising and scalable solution. However, existing methods necessitate DP
finetuning of large language models (LLMs) on private data to generate DP
synthetic data. This approach is not viable for proprietary LLMs (e.g.,
GPT-3.5) and also demands considerable computational resources for open-source
LLMs. Lin et al. (2024) recently introduced the Private Evolution (PE)
algorithm to generate DP synthetic images with only API access to diffusion
models. In this work, we propose an augmented PE algorithm, named Aug-PE, that
applies to the complex setting of text. We use API access to an LLM and
generate DP synthetic text without any model training. We conduct comprehensive
experiments on three benchmark datasets. Our results demonstrate that Aug-PE
produces DP synthetic text that yields competitive utility with the SOTA DP
finetuning baselines. This underscores the feasibility of relying solely on API
access of LLMs to produce high-quality DP synthetic texts, thereby facilitating
more accessible routes to privacy-preserving LLM applications. Our code and
data are available at https://github.com/AI-secure/aug-pe.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01752" title="Abstract">arXiv:2403.01752</a> [<a href="/pdf/2403.01752" title="Download PDF">pdf</a>, <a href="/ps/2403.01752" title="Download PostScript">ps</a>, <a href="/format/2403.01752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative and Interaction-aware Driver Model for Lane Change Maneuver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Woo%2C+J">Jemin Woo</a>, 
<a href="/search/eess?searchtype=author&query=Ahn%2C+C">Changsun Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">To achieve complete autonomous vehicles, it is crucial for autonomous
vehicles to communicate and interact with their surrounding vehicles.
Especially, since the lane change scenarios do not have traffic signals and
traffic rules, the interactions between vehicles need to be considered for the
autonomous vehicles. To address this issue, we propose a cooperative and
interaction-aware decision-making algorithm for autonomous vehicles that
stochastically considers the future behavior of surrounding vehicles based on
actual driving data. The algorithm is designed for both lane changing and lane
keeping vehicles, and effectively considers interaction by using an interaction
model based on relative information between vehicles with fewer states. To
design the decision-making, the interaction model is defined as Markov decision
process, and stochastic dynamic programming is used to solve the Markov
decision process. We validate the effectiveness of our proposed algorithm in
lane change scenarios that require interaction. Our results demonstrate that
the proposed algorithm enables cooperative and interaction-aware
decision-making while accommodating various driving styles. Additionally, by
comparing it with other methods, such as the intelligent driver model and game
theory-based decision-making, we validate the safety and comfortable
decision-making of our proposed algorithm. Furthermore, through driving with a
human-driven vehicle, it is confirmed that the proposed decision-making enables
to cooperatively and effectively drive with humans.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01753" title="Abstract">arXiv:2403.01753</a> [<a href="/pdf/2403.01753" title="Download PDF">pdf</a>, <a href="/format/2403.01753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training-Free Pretrained Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Ke Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huiqiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, model merging techniques have surfaced as a solution to combine
multiple single-talent models into a single multi-talent model. However,
previous endeavors in this field have either necessitated additional training
or fine-tuning processes, or require that the models possess the same
pre-trained initialization. In this work, we identify a common drawback in
prior works w.r.t. the inconsistency of unit similarity in the weight space and
the activation space. To address this inconsistency, we propose an innovative
model merging framework, coined as merging under dual-space constraints
(MuDSC). Specifically, instead of solely maximizing the objective of a single
space, we advocate for the exploration of permutation matrices situated in a
region with a unified high similarity in the dual space, achieved through the
linear combination of activation and weight similarity matrices. In order to
enhance usability, we have also incorporated adaptations for group structure,
including Multi-Head Attention and Group Normalization. Comprehensive
experimental comparisons demonstrate that MuDSC can significantly boost the
performance of merged models with various task combinations and architectures.
Furthermore, the visualization of the merged model within the multi-task loss
landscape reveals that MuDSC enables the merged model to reside in the
overlapping segment, featuring a unified lower loss for each task. Our code is
publicly available at https://github.com/zju-vipa/training_free_model_merging.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01754" title="Abstract">arXiv:2403.01754</a> [<a href="/pdf/2403.01754" title="Download PDF">pdf</a>, <a href="/format/2403.01754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Derivative-Free Optimization for Low-Rank Adaptation in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+F">Feihu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Parameter-efficient tuning methods such as LoRA could achieve comparable
performance to model tuning by tuning a small portion of the parameters.
However, substantial computational resources are still required, as this
process involves calculating gradients and performing back-propagation
throughout the model. Much effort has recently been devoted to utilizing the
derivative-free optimization method to eschew the computation of gradients and
showcase an augmented level of robustness in few-shot settings. In this paper,
we prepend the low-rank modules into each self-attention layer of the model and
employ two derivative-free optimization methods to optimize these low-rank
modules at each layer alternately. Extensive results on various tasks and
language models demonstrate that our proposed method achieves substantial
improvement and exhibits clear advantages in memory usage and convergence speed
compared to existing gradient-based parameter-efficient tuning and
derivative-free optimization methods in few-shot settings.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01755" title="Abstract">arXiv:2403.01755</a> [<a href="/pdf/2403.01755" title="Download PDF">pdf</a>, <a href="/format/2403.01755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Language Models Could Both Help and Harm Equity in Marine  Policymaking: The Case Study of the BBNJ Question-Answering Bot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+M">Matt Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=Lothian%2C+S">Sarah Lothian</a>, 
<a href="/search/cs?searchtype=author&query=O%27Neill%2C+B">Brian O&#x27;Neill</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Richard Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Ota%2C+Y">Yoshitaka Ota</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">AI Large Language Models (LLMs) like ChatGPT are set to reshape some aspects
of policymaking processes. Policy practitioners are already using ChatGPT for
help with a variety of tasks: from drafting statements, submissions, and
presentations, to conducting background research. We are cautiously hopeful
that LLMs could be used to promote a marginally more balanced footing among
decision makers in policy negotiations by assisting with certain tedious work,
particularly benefiting developing countries who face capacity constraints that
put them at a disadvantage in negotiations. However, the risks are particularly
concerning for environmental and marine policy uses, due to the urgency of
crises like climate change, high uncertainty, and trans-boundary impact.
<br />To explore the realistic potentials, limitations, and equity risks for LLMs
in marine policymaking, we present a case study of an AI chatbot for the
recently adopted Biodiversity Beyond National Jurisdiction Agreement (BBNJ),
and critique its answers to key policy questions. Our case study demonstrates
the dangers of LLMs in marine policymaking via their potential bias towards
generating text that favors the perspectives of mainly Western economic centers
of power, while neglecting developing countries' viewpoints. We describe
several ways these biases can enter the system, including: (1) biases in the
underlying foundational language models; (2) biases arising from the chatbot's
connection to UN negotiation documents, and (3) biases arising from the
application design. We urge caution in the use of generative AI in ocean policy
processes and call for more research on its equity and fairness implications.
Our work also underscores the need for developing countries' policymakers to
develop the technical capacity to engage with AI on their own terms.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01756" title="Abstract">arXiv:2403.01756</a> [<a href="/pdf/2403.01756" title="Download PDF">pdf</a>, <a href="/format/2403.01756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Guidance Mechanism for Handwritten Mathematical Expression  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yutian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wenjun Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jianguo Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Handwritten mathematical expression recognition (HMER) is challenging in OCR
tasks due to the complex layouts of mathematical expressions, suffering from
issues including over-parsing and under-parsing. To solve these, previous
methods utilize historical attention weights to improve the attention
mechanism. However, this approach has limitations in addressing under-parsing
since it cannot correct the erroneous attention on image regions that should be
parsed at subsequent decoding steps. When this happens, the attention module
incorporates future context into the current decoding step, thus confusing the
alignment process. To address this issue, we propose an attention guidance
mechanism to explicitly suppress attention weights in irrelevant regions and
enhance ones in appropriate regions, thereby inhibiting access to information
outside the intended context. Depending on the type of attention guidance, we
devise two complementary approaches to refine attention weights: self-guidance
that coordinates attention of multiple heads and neighbor-guidance that
integrates attention from adjacent time steps. Experiments show that our method
outperforms existing state-of-the-art methods, achieving expression recognition
rates of 60.75% / 61.81% / 63.30% on the CROHME 2014 / 2016 / 2019 datasets.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01757" title="Abstract">arXiv:2403.01757</a> [<a href="/pdf/2403.01757" title="Download PDF">pdf</a>, <a href="/format/2403.01757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Multimodal Integration Boost the Performance of LLM for  Optimization: Case Study on Capacitated Vehicle Routing Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Liang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K+C">Kay Chen Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages,3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
<p class="mathjax">Recently, large language models (LLMs) have notably positioned them as
capable tools for addressing complex optimization challenges. Despite this
recognition, a predominant limitation of existing LLM-based optimization
methods is their struggle to capture the relationships among decision variables
when relying exclusively on numerical text prompts, especially in
high-dimensional problems. Keeping this in mind, we first propose to enhance
the optimization performance using multimodal LLM capable of processing both
textual and visual prompts for deeper insights of the processed optimization
problem. This integration allows for a more comprehensive understanding of
optimization problems, akin to human cognitive processes. We have developed a
multimodal LLM-based optimization framework that simulates human
problem-solving workflows, thereby offering a more nuanced and effective
analysis. The efficacy of this method is evaluated through extensive empirical
studies focused on a well-known combinatorial optimization problem, i.e.,
capacitated vehicle routing problem. The results are compared against those
obtained from the LLM-based optimization algorithms that rely solely on textual
prompts, demonstrating the significant advantages of our multimodal approach.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01759" title="Abstract">arXiv:2403.01759</a> [<a href="/pdf/2403.01759" title="Download PDF">pdf</a>, <a href="/format/2403.01759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-world Machine Learning: A Review and New Outlooks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shijie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu-Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine learning has achieved remarkable success in many applications.
However, existing studies are largely based on the closed-world assumption,
which assumes that the environment is stationary, and the model is fixed once
deployed. In many real-world applications, this fundamental and rather naive
assumption may not hold because an open environment is complex, dynamic, and
full of unknowns. In such cases, rejecting unknowns, discovering novelties, and
then incrementally learning them, could enable models to be safe and evolve
continually as biological systems do. This paper provides a holistic view of
open-world machine learning by investigating unknown rejection, novel class
discovery, and class-incremental learning in a unified paradigm. The
challenges, principles, and limitations of current methodologies are discussed
in detail. Finally, we discuss several potential directions for future
research. This paper aims to provide a comprehensive introduction to the
emerging open-world machine learning paradigm, to help researchers build more
powerful AI systems in their respective fields, and to promote the development
of artificial general intelligence.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01766" title="Abstract">arXiv:2403.01766</a> [<a href="/pdf/2403.01766" title="Download PDF">pdf</a>, <a href="/format/2403.01766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Visual Perception of a Social Robot for Controlled and  In-the-wild Human-robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wangjie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Leimin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+T">Duy Tho Le</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+H">Hamid Rezatofighi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to HRI 2023 (LBR track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Social robots often rely on visual perception to understand their users and
the environment. Recent advancements in data-driven approaches for computer
vision have demonstrated great potentials for applying deep-learning models to
enhance a social robot's visual perception. However, the high computational
demands of deep-learning methods, as opposed to the more resource-efficient
shallow-learning models, bring up important questions regarding their effects
on real-world interaction and user experience. It is unclear how will the
objective interaction performance and subjective user experience be influenced
when a social robot adopts a deep-learning based visual perception model. We
employed state-of-the-art human perception and tracking models to improve the
visual perception function of the Pepper robot and conducted a controlled lab
study and an in-the-wild human-robot interaction study to evaluate this novel
perception function for following a specific user with other people present in
the scene.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01767" title="Abstract">arXiv:2403.01767</a> [<a href="/pdf/2403.01767" title="Download PDF">pdf</a>, <a href="/format/2403.01767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KeNet:Knowledge-enhanced Doc-Label Attention Network for Multi-label  text classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Liang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-Label Text Classification (MLTC) is a fundamental task in the field of
Natural Language Processing (NLP) that involves the assignment of multiple
labels to a given text. MLTC has gained significant importance and has been
widely applied in various domains such as topic recognition, recommendation
systems, sentiment analysis, and information retrieval. However, traditional
machine learning and Deep neural network have not yet addressed certain issues,
such as the fact that some documents are brief but have a large number of
labels and how to establish relationships between the labels. It is imperative
to additionally acknowledge that the significance of knowledge is substantiated
in the realm of MLTC. To address this issue, we provide a novel approach known
as Knowledge-enhanced Doc-Label Attention Network (KeNet). Specifically, we
design an Attention Network that incorporates external knowledge, label
embedding, and a comprehensive attention mechanism. In contrast to conventional
methods, we use comprehensive representation of documents, knowledge and labels
to predict all labels for each single text. Our approach has been validated by
comprehensive research conducted on three multi-label datasets. Experimental
results demonstrate that our method outperforms state-of-the-art MLTC method.
Additionally, a case study is undertaken to illustrate the practical
implementation of KeNet.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01768" title="Abstract">arXiv:2403.01768</a> [<a href="/pdf/2403.01768" title="Download PDF">pdf</a>, <a href="/format/2403.01768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Canonical Form of Datatic Description in Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+G">Guojian Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Ziang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The design of feedback controllers is undergoing a paradigm shift from
modelic (i.e., model-driven) control to datatic (i.e., data-driven) control.
Canonical form of state space model is an important concept in modelic control
systems, exemplified by Jordan form, controllable form and observable form,
whose purpose is to facilitate system analysis and controller synthesis. In the
realm of datatic control, there is a notable absence in the standardization of
data-based system representation. This paper for the first time introduces the
concept of canonical data form for the purpose of achieving more effective
design of datatic controllers. In a control system, the data sample in
canonical form consists of a transition component and an attribute component.
The former encapsulates the plant dynamics at the sampling time independently,
which is a tuple containing three elements: a state, an action and their
corresponding next state. The latter describes one or some artificial
characteristics of the current sample, whose calculation must be performed in
an online manner. The attribute of each sample must adhere to two requirements:
(1) causality, ensuring independence from any future samples; and (2) locality,
allowing dependence on historical samples but constrained to a finite
neighboring set. The purpose of adding attribute is to offer some kinds of
benefits for controller design in terms of effectiveness and efficiency. To
provide a more close-up illustration, we present two canonical data forms:
temporal form and spatial form, and demonstrate their advantages in reducing
instability and enhancing training efficiency in two datatic control systems.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01769" title="Abstract">arXiv:2403.01769</a> [<a href="/pdf/2403.01769" title="Download PDF">pdf</a>, <a href="/ps/2403.01769" title="Download PostScript">ps</a>, <a href="/format/2403.01769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safe Screening Rule with Bi-level Optimization of $&#x3bd;$ Support Vector  Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiji Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wanyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yitian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianhua Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Support vector machine (SVM) has achieved many successes in machine learning,
especially for a small sample problem. As a famous extension of the traditional
SVM, the $\nu$ support vector machine ($\nu$-SVM) has shown outstanding
performance due to its great model interpretability. However, it still faces
challenges in training overhead for large-scale problems. To address this
issue, we propose a safe screening rule with bi-level optimization for
$\nu$-SVM (SRBO-$\nu$-SVM) which can screen out inactive samples before
training and reduce the computational cost without sacrificing the prediction
accuracy. Our SRBO-$\nu$-SVM is strictly deduced by integrating the
Karush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex
problems and the $\nu$-property. Furthermore, we develop an efficient dual
coordinate descent method (DCDM) to further improve computational speed.
Finally, a unified framework for SRBO is proposed to accelerate many SVM-type
models, and it is successfully applied to one-class SVM. Experimental results
on 6 artificial data sets and 30 benchmark data sets have verified the
effectiveness and safety of our proposed methods in supervised and unsupervised
tasks.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01773" title="Abstract">arXiv:2403.01773</a> [<a href="/pdf/2403.01773" title="Download PDF">pdf</a>, <a href="/format/2403.01773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving out-of-distribution generalization in graphs via hierarchical  semantic environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piao%2C+Y">Yinhua Piao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangseon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yijingxiu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Out-of-distribution (OOD) generalization in the graph domain is challenging
due to complex distribution shifts and a lack of environmental contexts. Recent
methods attempt to enhance graph OOD generalization by generating flat
environments. However, such flat environments come with inherent limitations to
capture more complex data distributions. Considering the DrugOOD dataset, which
contains diverse training environments (e.g., scaffold, size, etc.), flat
contexts cannot sufficiently address its high heterogeneity. Thus, a new
challenge is posed to generate more semantically enriched environments to
enhance graph invariant learning for handling distribution shifts. In this
paper, we propose a novel approach to generate hierarchical semantic
environments for each graph. Firstly, given an input graph, we explicitly
extract variant subgraphs from the input graph to generate proxy predictions on
local environments. Then, stochastic attention mechanisms are employed to
re-extract the subgraphs for regenerating global environments in a hierarchical
manner. In addition, we introduce a new learning objective that guides our
model to learn the diversity of environments within the same hierarchy while
maintaining consistency across different hierarchies. This approach enables our
model to consider the relationships between environments and facilitates robust
graph invariant learning. Extensive experiments on real-world graph data have
demonstrated the effectiveness of our framework. Particularly, in the
challenging dataset DrugOOD, our method achieves up to 1.29\% and 2.83\%
improvement over the best baselines on IC50 and EC50 prediction tasks,
respectively.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01774" title="Abstract">arXiv:2403.01774</a> [<a href="/pdf/2403.01774" title="Download PDF">pdf</a>, <a href="/format/2403.01774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search  Results with Citations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haolin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Dezhang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Junlang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianhua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Enhancing the attribution in large language models (LLMs) is a crucial task.
One feasible approach is to enable LLMs to cite external sources that support
their generations. However, existing datasets and evaluation methods in this
domain still exhibit notable limitations. In this work, we formulate the task
of attributed query-focused summarization (AQFS) and present WebCiteS, a
Chinese dataset featuring 7k human-annotated summaries with citations. WebCiteS
derives from real-world user queries and web search results, offering a
valuable resource for model training and evaluation. Prior works in attribution
evaluation do not differentiate between groundedness errors and citation
errors. They also fall short in automatically verifying sentences that draw
partial support from multiple sources. We tackle these issues by developing
detailed metrics and enabling the automatic evaluator to decompose the
sentences into sub-claims for fine-grained verification. Our comprehensive
evaluation of both open-source and proprietary models on WebCiteS highlights
the challenge LLMs face in correctly citing sources, underscoring the necessity
for further improvement. The dataset and code will be open-sourced to
facilitate further research in this crucial field.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01777" title="Abstract">arXiv:2403.01777</a> [<a href="/pdf/2403.01777" title="Download PDF">pdf</a>, <a href="/format/2403.01777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lizhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haoyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+J">Jinkui Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Understanding the reasoning capabilities of Multimodal Large Language Models
(MLLMs) is an important area of research. In this study, we introduce a dynamic
benchmark, NPHardEval4V, aimed at addressing the existing gaps in evaluating
the pure reasoning abilities of MLLMs. Our benchmark aims to provide a venue to
disentangle the effect of various factors such as image recognition and
instruction following, from the overall performance of the models, allowing us
to focus solely on evaluating their reasoning abilities. Our findings reveal
significant discrepancies in reasoning abilities across different models and
highlight the relatively weak performance of MLLMs compared to LLMs in terms of
reasoning. We also investigate the impact of different prompting styles,
including visual, text, and combined vision and text prompts, on the reasoning
abilities of MLLMs, demonstrating the different impacts of multimodal inputs in
model performance. Unlike traditional benchmarks, which primarily focus on
static evaluations, our benchmark will update on a monthly basis to prevent
overfitting and ensure a more accurate evaluation of the models. We believe
that this benchmark can aid understand and guide the further development of
reasoning abilities in MLLMs. The benchmark dataset and code are available at
https://github.com/lizhouf/NPHardEval4V
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01778" title="Abstract">arXiv:2403.01778</a> [<a href="/pdf/2403.01778" title="Download PDF">pdf</a>, <a href="/format/2403.01778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOSCF: Efficient decoupling algorithms for finding the best rank-one  approximation of higher-order tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiao%2C+C">Chuanfu Xiao</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Z">Zeyu Li</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+C">Chao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Best rank-one approximation is one of the most fundamental tasks in tensor
computation. In order to fully exploit modern multi-core parallel computers, it
is necessary to develop decoupling algorithms for computing the best rank-one
approximation of higher-order tensors at large scales. In this paper, we first
build a bridge between the rank-one approximation of tensors and the
eigenvector-dependent nonlinear eigenvalue problem (NEPv), and then develop an
efficient decoupling algorithm, namely the higher-order self-consistent field
(HOSCF) algorithm, inspired by the famous self-consistent field (SCF) iteration
frequently used in computational chemistry. The convergence theory of the HOSCF
algorithm and an estimation of the convergence speed are further presented. In
addition, we propose an improved HOSCF (iHOSCF) algorithm that incorporates the
Rayleigh quotient iteration, which can significantly accelerate the convergence
of HOSCF. Numerical experiments show that the proposed algorithms can
efficiently converge to the best rank-one approximation of both synthetic and
real-world tensors and can scale with high parallel scalability on a modern
parallel computer.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01779" title="Abstract">arXiv:2403.01779</a> [<a href="/pdf/2403.01779" title="Download PDF">pdf</a>, <a href="/format/2403.01779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable  Virtual Try-on
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chengcai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-based virtual try-on (VTON), which aims to generate an outfitted image
of a target human wearing an in-shop garment, is a challenging image-synthesis
task calling for not only high fidelity of the outfitted human but also full
preservation of garment details. To tackle this issue, we propose Outfitting
over Try-on Diffusion (OOTDiffusion), leveraging the power of pretrained latent
diffusion models and designing a novel network architecture for realistic and
controllable virtual try-on. Without an explicit warping process, we propose an
outfitting UNet to learn the garment detail features, and merge them with the
target human body via our proposed outfitting fusion in the denoising process
of diffusion models. In order to further enhance the controllability of our
outfitting UNet, we introduce outfitting dropout to the training process, which
enables us to adjust the strength of garment features through classifier-free
guidance. Our comprehensive experiments on the VITON-HD and Dress Code datasets
demonstrate that OOTDiffusion efficiently generates high-quality outfitted
images for arbitrary human and garment images, which outperforms other VTON
methods in both fidelity and controllability, indicating an impressive
breakthrough in virtual try-on. Our source code is available at
https://github.com/levihsu/OOTDiffusion.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01780" title="Abstract">arXiv:2403.01780</a> [<a href="/pdf/2403.01780" title="Download PDF">pdf</a>, <a href="/format/2403.01780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph neural network for in-network placement of real-time metaverse  tasks in next-generation network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashid%2C+S+M">Sulaiman Muhammad Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Aliyu%2C+I">Ibrahim Aliyu</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+I">Il-Kwon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Um%2C+T">Tai-Won Um</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinsul Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">This study addresses the challenge of real-time metaverse applications by
proposing an in-network placement and task-offloading solution for
delay-constrained computing tasks in next-generation networks. The metaverse,
envisioned as a parallel virtual world, requires seamless real-time experiences
across diverse applications. The study introduces a software-defined networking
(SDN)-based architecture and employs graph neural network (GNN) techniques for
intelligent and adaptive task allocation in in-network computing (INC).
Considering time constraints and computing capabilities, the proposed model
optimally decides whether to offload rendering tasks to INC nodes or edge
server. Extensive experiments demonstrate the superior performance of the
proposed GNN model, achieving 97% accuracy compared to 72% for multilayer
perceptron (MLP) and 70% for decision trees (DTs). The study fills the research
gap in in-network placement for real-time metaverse applications, offering
insights into efficient rendering task handling.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01781" title="Abstract">arXiv:2403.01781</a> [<a href="/pdf/2403.01781" title="Download PDF">pdf</a>, <a href="/format/2403.01781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Efficient Optimal Transport and Functional Maps For  Unsupervised Shape Correspondence Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Tung Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shanlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+N">Nhat Ho</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of computer vision and graphics, accurately establishing
correspondences between geometric 3D shapes is pivotal for applications like
object tracking, registration, texture transfer, and statistical shape
analysis. Moving beyond traditional hand-crafted and data-driven feature
learning methods, we incorporate spectral methods with deep learning, focusing
on functional maps (FMs) and optimal transport (OT). Traditional OT-based
approaches, often reliant on entropy regularization OT in learning-based
framework, face computational challenges due to their quadratic cost. Our key
contribution is to employ the sliced Wasserstein distance (SWD) for OT, which
is a valid fast optimal transport metric in an unsupervised shape matching
framework. This unsupervised framework integrates functional map regularizers
with a novel OT-based loss derived from SWD, enhancing feature alignment
between shapes treated as discrete probability measures. We also introduce an
adaptive refinement process utilizing entropy regularized OT, further refining
feature alignments for accurate point-to-point correspondences. Our method
demonstrates superior performance in non-rigid shape matching, including
near-isometric and non-isometric scenarios, and excels in downstream tasks like
segmentation transfer. The empirical results on diverse datasets highlight our
framework's effectiveness and generalization capabilities, setting new
standards in non-rigid shape matching with efficient OT metrics and an adaptive
refinement module.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01782" title="Abstract">arXiv:2403.01782</a> [<a href="/pdf/2403.01782" title="Download PDF">pdf</a>, <a href="/format/2403.01782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning and Testing an Online Feedback Optimization Controller to Provide  Curative Distribution Grid Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ortmann%2C+L">Lukas Ortmann</a>, 
<a href="/search/eess?searchtype=author&query=B%C3%B6hm%2C+F">Fabian B&#xf6;hm</a>, 
<a href="/search/eess?searchtype=author&query=Klein-Helmkamp%2C+F">Florian Klein-Helmkamp</a>, 
<a href="/search/eess?searchtype=author&query=Ulbig%2C+A">Andreas Ulbig</a>, 
<a href="/search/eess?searchtype=author&query=Bolognani%2C+S">Saverio Bolognani</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Due to more volatile generation, flexibility will become more important in
transmission grids. One potential source of this flexibility can be
distribution grids. A flexibility request from the transmission grid to a
distribution grid then needs to be split up onto the different flexibility
providing units (FPU) in the distribution grid. One potential way to do this is
Online Feedback Optimization (OFO). OFO is a new control method that steers
power systems to the optimal solution of an optimization problem using minimal
model information and computation power. This paper will show how to choose the
optimization problem and how to tune the OFO controller. Afterward, we test the
resulting controller on a real distribution grid laboratory and show its
performance, its interaction with other controllers in the grid, and how it
copes with disturbances. Overall, the paper makes a clear recommendation on how
to phrase the optimization problem and tune the OFO controller. Furthermore, it
experimentally verifies that an OFO controller is a powerful tool to
disaggregate flexibility requests onto FPUs while satisfying operational
constraints inside the flexibility providing distribution grid.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01783" title="Abstract">arXiv:2403.01783</a> [<a href="/pdf/2403.01783" title="Download PDF">pdf</a>, <a href="/format/2403.01783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards A Diffractive Analysis of Prompt-Based Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajcic%2C+N">Nina Rajcic</a>, 
<a href="/search/cs?searchtype=author&query=Llano%2C+M+T">Maria Teresa Llano</a>, 
<a href="/search/cs?searchtype=author&query=McCormack%2C+J">Jon McCormack</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of paper accepted for CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recent developments in prompt-based generative AI has given rise to discourse
surrounding the perceived ethical concerns, economic implications, and
consequences for the future of cultural production. As generative imagery
becomes pervasive in mainstream society, dominated primarily by emerging
industry leaders, we encourage that the role of the CHI community be one of
inquiry; to investigate the numerous ways in which generative AI has the
potential to, and already is, augmenting human creativity. In this paper, we
conducted a diffractive analysis exploring the potential role of prompt-based
interfaces in artists' creative practice. Over a two week period, seven visual
artists were given access to a personalised instance of Stable Diffusion,
fine-tuned on a dataset of their work. In the following diffractive analysis,
we identified two dominant modes adopted by participants, AI for ideation, and
AI for production. We furthermore present a number of ethical design
considerations for the future development of generative AI interfaces.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01784" title="Abstract">arXiv:2403.01784</a> [<a href="/pdf/2403.01784" title="Download PDF">pdf</a>, <a href="/format/2403.01784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of  Code and Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yiqun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yang Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Large language models (LLMs) such as ChatGPT are increasingly proficient in
understanding and generating a mixture of code and text. Evaluation based on
such $\textit{mixture}$ can lead to a more comprehensive understanding of the
models' abilities in solving coding problems. However, in this context, current
evaluation methods are either limited in task coverage or lack standardization.
To address this issue, we propose using category theory as a framework for
evaluation. Specifically, morphisms within a code category can represent code
debugging and transformation, functors between two categories represent code
translation, and functors between a code category and a natural language
category represent code generation, explanation, and reproduction. We present
an automatic evaluation framework called $\textbf{CatCode}$
($\textbf{Cat}$egory $\textbf{Code}$) that can comprehensively assess the
coding abilities of LLMs, including ChatGPT, Text-Davinci, and CodeGeeX.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01785" title="Abstract">arXiv:2403.01785</a> [<a href="/pdf/2403.01785" title="Download PDF">pdf</a>, <a href="/format/2403.01785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What do neural networks listen to? Exploring the crucial bands in Speech  Enhancement using Sinc-convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+K">Kuan-Hsun Ho</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+J">Jeih-weih Hung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Berlin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This study introduces a reformed Sinc-convolution (Sincconv) framework
tailored for the encoder component of deep networks for speech enhancement
(SE). The reformed Sincconv, based on parametrized sinc functions as band-pass
filters, offers notable advantages in terms of training efficiency, filter
diversity, and interpretability. The reformed Sinc-conv is evaluated in
conjunction with various SE models, showcasing its ability to boost SE
performance. Furthermore, the reformed Sincconv provides valuable insights into
the specific frequency components that are prioritized in an SE scenario. This
opens up a new direction of SE research and improving our knowledge of their
operating dynamics.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01786" title="Abstract">arXiv:2403.01786</a> [<a href="/pdf/2403.01786" title="Download PDF">pdf</a>, <a href="/format/2403.01786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposing the Deception: Uncovering More Forgery Clues for Deepfake  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ba%2C+Z">Zhongjie Ba</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Li Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Deepfake technology has given rise to a spectrum of novel and compelling
applications. Unfortunately, the widespread proliferation of high-fidelity fake
videos has led to pervasive confusion and deception, shattering our faith that
seeing is believing. One aspect that has been overlooked so far is that current
deepfake detection approaches may easily fall into the trap of overfitting,
focusing only on forgery clues within one or a few local regions. Moreover,
existing works heavily rely on neural networks to extract forgery features,
lacking theoretical constraints guaranteeing that sufficient forgery clues are
extracted and superfluous features are eliminated. These deficiencies culminate
in unsatisfactory accuracy and limited generalizability in real-life scenarios.
<br />In this paper, we try to tackle these challenges through three designs: (1)
We present a novel framework to capture broader forgery clues by extracting
multiple non-overlapping local representations and fusing them into a global
semantic-rich feature. (2) Based on the information bottleneck theory, we
derive Local Information Loss to guarantee the orthogonality of local
representations while preserving comprehensive task-relevant information. (3)
Further, to fuse the local representations and remove task-irrelevant
information, we arrive at a Global Information Loss through the theoretical
analysis of mutual information. Empirically, our method achieves
state-of-the-art performance on five benchmark datasets.Our code is available
at \url{https://github.com/QingyuLiu/Exposing-the-Deception}, hoping to inspire
researchers.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01788" title="Abstract">arXiv:2403.01788</a> [<a href="/pdf/2403.01788" title="Download PDF">pdf</a>, <a href="/format/2403.01788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-stars LDP: A Novel Framework for (p, q)-clique Enumeration under Local  Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Henan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong-Hua Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zening Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">(p,q)-clique enumeration on a bipartite graph is critical for calculating
clustering coefficient and detecting densest subgraph. It is necessary to carry
out subgraph enumeration while protecting users' privacy from any potential
attacker as the count of subgraph may contain sensitive information. Most
recent studies focus on the privacy protection algorithms based on edge LDP
(Local Differential Privacy). However, these algorithms suffer a large
estimation error due to the great amount of required noise. In this paper, we
propose a novel idea of k-stars LDP and a novel k-stars LDP algorithm for (p,
q)-clique enumeration with a small estimation error, where a k-stars is a
star-shaped graph with k nodes connecting to one node. The effectiveness of
edge LDP relies on its capacity to obfuscate the existence of an edge between
the user and his one-hop neighbors. This is based on the premise that a user
should be aware of the existence of his one-hop neighbors. Similarly, we can
apply this premise to k-stars as well, where an edge is a specific genre of
1-stars. Based on this fact, we first propose the k-stars neighboring list to
enable our algorithm to obfuscate the existence of k-stars with Warner' s RR.
Then, we propose the absolute value correction technique and the k-stars
sampling technique to further reduce the estimation error. Finally, with the
two-round user-collector interaction mechanism, we propose our k-stars LDP
algorithm to count the number of (p, q)-clique while successfully protecting
users' privacy. Both the theoretical analysis and experiments have showed the
superiority of our algorithm over the algorithms based on edge LDP.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01789" title="Abstract">arXiv:2403.01789</a> [<a href="/pdf/2403.01789" title="Download PDF">pdf</a>, <a href="/format/2403.01789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DECOR: Enhancing Logic Locking Against Machine Learning-Based Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yinghua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+D">Subhajit Dutta Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Nuzzo%2C+P">Pierluigi Nuzzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages. Accepted at the International Symposium on Quality Electronic Design (ISQED), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Logic locking (LL) has gained attention as a promising intellectual property
protection measure for integrated circuits. However, recent attacks,
facilitated by machine learning (ML), have shown the potential to predict the
correct key in multiple LL schemes by exploiting the correlation of the correct
key value with the circuit structure. This paper presents a generic LL
enhancement method based on a randomized algorithm that can significantly
decrease the correlation between locked circuit netlist and correct key values
in an LL scheme. Numerical results show that the proposed method can
efficiently degrade the accuracy of state-of-the-art ML-based attacks down to
around 50%, resulting in negligible advantage versus random guessing.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01791" title="Abstract">arXiv:2403.01791</a> [<a href="/pdf/2403.01791" title="Download PDF">pdf</a>, <a href="/format/2403.01791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Recommender: An Exploratory Study of the Effects of Different AI  Roles in AI-Assisted Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Intelligence (AI) is increasingly employed in various
decision-making tasks, typically as a Recommender, providing recommendations
that the AI deems correct. However, recent studies suggest this may diminish
human analytical thinking and lead to humans' inappropriate reliance on AI,
impairing the synergy in human-AI teams. In contrast, human advisors in group
decision-making perform various roles, such as analyzing alternative options or
criticizing decision-makers to encourage their critical thinking. This
diversity of roles has not yet been empirically explored in AI assistance. In
this paper, we examine three AI roles: Recommender, Analyzer, and Devil's
Advocate, and evaluate their effects across two AI performance levels. Our
results show each role's distinct strengths and limitations in task
performance, reliance appropriateness, and user experience. Notably, the
Recommender role is not always the most effective, especially if the AI
performance level is low, the Analyzer role may be preferable. These insights
offer valuable implications for designing AI assistants with adaptive
functional roles according to different situations.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01792" title="Abstract">arXiv:2403.01792</a> [<a href="/pdf/2403.01792" title="Download PDF">pdf</a>, <a href="/format/2403.01792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConSep: a Noise- and Reverberation-Robust Speech Separation Framework by  Magnitude Conditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+K">Kuan-Hsun Ho</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+J">Jeih-weih Hung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Berlin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech separation has recently made significant progress thanks to the
fine-grained vision used in time-domain methods. However, several studies have
shown that adopting Short-Time Fourier Transform (STFT) for feature extraction
could be beneficial when encountering harsher conditions, such as noise or
reverberation. Therefore, we propose a magnitude-conditioned time-domain
framework, ConSep, to inherit the beneficial characteristics. The experiment
shows that ConSep promotes performance in anechoic, noisy, and reverberant
settings compared to two celebrated methods, SepFormer and Bi-Sep. Furthermore,
we visualize the components of ConSep to strengthen the advantages and cohere
with the actualities we have found in preliminary studies.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01795" title="Abstract">arXiv:2403.01795</a> [<a href="/pdf/2403.01795" title="Download PDF">pdf</a>, <a href="/format/2403.01795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankED: Addressing Imbalance and Uncertainty in Edge Detection Using  Ranking-based Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cetinkaya%2C+B">Bedrettin Cetinkaya</a>, 
<a href="/search/cs?searchtype=author&query=Kalkan%2C+S">Sinan Kalkan</a>, 
<a href="/search/cs?searchtype=author&query=Akbas%2C+E">Emre Akbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting edges in images suffers from the problems of (P1) heavy imbalance
between positive and negative classes as well as (P2) label uncertainty owing
to disagreement between different annotators. Existing solutions address P1
using class-balanced cross-entropy loss and dice loss and P2 by only predicting
edges agreed upon by most annotators. In this paper, we propose RankED, a
unified ranking-based approach that addresses both the imbalance problem (P1)
and the uncertainty problem (P2). RankED tackles these two problems with two
components: One component which ranks positive pixels over negative pixels, and
the second which promotes high confidence edge pixels to have more label
certainty. We show that RankED outperforms previous studies and sets a new
state-of-the-art on NYUD-v2, BSDS500 and Multi-cue datasets. Code is available
at https://ranked-cvpr24.github.io.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01797" title="Abstract">arXiv:2403.01797</a> [<a href="/pdf/2403.01797" title="Download PDF">pdf</a>, <a href="/format/2403.01797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing Graph Partitioning for Large-Scale Nearest Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gottesb%C3%BCren%2C+L">Lars Gottesb&#xfc;ren</a>, 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Jayaram%2C+R">Rajesh Jayaram</a>, 
<a href="/search/cs?searchtype=author&query=Lacki%2C+J">Jakub Lacki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">We consider the fundamental problem of decomposing a large-scale approximate
nearest neighbor search (ANNS) problem into smaller sub-problems. The goal is
to partition the input points into neighborhood-preserving shards, so that the
nearest neighbors of any point are contained in only a few shards. When a query
arrives, a routing algorithm is used to identify the shards which should be
searched for its nearest neighbors. This approach forms the backbone of
distributed ANNS, where the dataset is so large that it must be split across
multiple machines.
<br />In this paper, we design simple and highly efficient routing methods, and
prove strong theoretical guarantees on their performance. A crucial
characteristic of our routing algorithms is that they are inherently modular,
and can be used with any partitioning method. This addresses a key drawback of
prior approaches, where the routing algorithms are inextricably linked to their
associated partitioning method. In particular, our new routing methods enable
the use of balanced graph partitioning, which is a high-quality partitioning
method without a naturally associated routing algorithm. Thus, we provide the
first methods for routing using balanced graph partitioning that are extremely
fast to train, admit low latency, and achieve high recall. We provide a
comprehensive evaluation of our full partitioning and routing pipeline on
billion-scale datasets, where it outperforms existing scalable partitioning
methods by significant margins, achieving up to 2.14x higher QPS at 90%
recall$@10$ than the best competitor.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01798" title="Abstract">arXiv:2403.01798</a> [<a href="/pdf/2403.01798" title="Download PDF">pdf</a>, <a href="/format/2403.01798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fair and Efficient Learning-based Congestion Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xudong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Han Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+C">Chaoliang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xinchen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent years have witnessed a plethora of learning-based solutions for
congestion control (CC) that demonstrate better performance over traditional
TCP schemes. However, they fail to provide consistently good convergence
properties, including {\em fairness}, {\em fast convergence} and {\em
stability}, due to the mismatch between their objective functions and these
properties. Despite being intuitive, integrating these properties into existing
learning-based CC is challenging, because: 1) their training environments are
designed for the performance optimization of single flow but incapable of
cooperative multi-flow optimization, and 2) there is no directly measurable
metric to represent these properties into the training objective function.
<br />We present Astraea, a new learning-based congestion control that ensures fast
convergence to fairness with stability. At the heart of Astraea is a
multi-agent deep reinforcement learning framework that explicitly optimizes
these convergence properties during the training process by enabling the
learning of interactive policy between multiple competing flows, while
maintaining high performance. We further build a faithful multi-flow
environment that emulates the competing behaviors of concurrent flows,
explicitly expressing convergence properties to enable their optimization
during training. We have fully implemented Astraea and our comprehensive
experiments show that Astraea can quickly converge to fairness point and
exhibit better stability than its counterparts. For example, \sys achieves
near-optimal bandwidth sharing (i.e., fairness) when multiple flows compete for
the same bottleneck, delivers up to 8.4$\times$ faster convergence speed and
2.8$\times$ smaller throughput deviation, while achieving comparable or even
better performance over prior solutions.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01799" title="Abstract">arXiv:2403.01799</a> [<a href="/pdf/2403.01799" title="Download PDF">pdf</a>, <a href="/format/2403.01799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superpixel Graph Contrastive Clustering with Semantic-Invariant  Augmentations for Hyperspectral Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianhan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuheng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hyperspectral images (HSI) clustering is an important but challenging task.
The state-of-the-art (SOTA) methods usually rely on superpixels, however, they
do not fully utilize the spatial and spectral information in HSI 3-D structure,
and their optimization targets are not clustering-oriented. In this work, we
first use 3-D and 2-D hybrid convolutional neural networks to extract the
high-order spatial and spectral features of HSI through pre-training, and then
design a superpixel graph contrastive clustering (SPGCC) model to learn
discriminative superpixel representations. Reasonable augmented views are
crucial for contrastive clustering, and conventional contrastive learning may
hurt the cluster structure since different samples are pushed away in the
embedding space even if they belong to the same class. In SPGCC, we design two
semantic-invariant data augmentations for HSI superpixels: pixel sampling
augmentation and model weight augmentation. Then sample-level alignment and
clustering-center-level contrast are performed for better intra-class
similarity and inter-class dissimilarity of superpixel embeddings. We perform
clustering and network optimization alternatively. Experimental results on
several HSI datasets verify the advantages of the proposed method, e.g., on
India Pines, our model improves the clustering accuracy from 58.79% to 67.59%
compared to the SOTA method.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01800" title="Abstract">arXiv:2403.01800</a> [<a href="/pdf/2403.01800" title="Download PDF">pdf</a>, <a href="/format/2403.01800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AtomoVideo: High Fidelity Image-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Litong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Biao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, video generation has achieved significant rapid development based
on superior text-to-image generation techniques. In this work, we propose a
high fidelity framework for image-to-video generation, named AtomoVideo. Based
on multi-granularity image injection, we achieve higher fidelity of the
generated video to the given image. In addition, thanks to high quality
datasets and training strategies, we achieve greater motion intensity while
maintaining superior temporal consistency and stability. Our architecture
extends flexibly to the video frame prediction task, enabling long sequence
prediction through iterative generation. Furthermore, due to the design of
adapter training, our approach can be well combined with existing personalised
models and controllable modules. By quantitatively and qualitatively
evaluation, AtomoVideo achieves superior results compared to popular methods,
more examples can be found on our project website: https://atomo-
video.github.io/.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01801" title="Abstract">arXiv:2403.01801</a> [<a href="/pdf/2403.01801" title="Download PDF">pdf</a>, <a href="/format/2403.01801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLA: Cross-city Mobility Transformer for Human Trajectory Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tongya Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shunyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human trajectory data produced by daily mobile devices has proven its
usefulness in various substantial fields such as urban planning and epidemic
prevention. In terms of the individual privacy concern, human trajectory
simulation has attracted increasing attention from researchers, targeting at
offering numerous realistic mobility data for downstream tasks. Nevertheless,
the prevalent issue of data scarcity undoubtedly degrades the reliability of
existing deep learning models. In this paper, we are motivated to explore the
intriguing problem of mobility transfer across cities, grasping the universal
patterns of human trajectories to augment the powerful Transformer with
external mobility data. There are two crucial challenges arising in the
knowledge transfer across cities: 1) how to transfer the Transformer to adapt
for domain heterogeneity; 2) how to calibrate the Transformer to adapt for
subtly different long-tail frequency distributions of locations. To address
these challenges, we have tailored a Cross-city mObiLity trAnsformer (COLA)
with a dedicated model-agnostic transfer framework by effectively transferring
cross-city knowledge for human trajectory simulation. Firstly, COLA divides the
Transformer into the private modules for city-specific characteristics and the
shared modules for city-universal mobility patterns. Secondly, COLA leverages a
lightweight yet effective post-hoc adjustment strategy for trajectory
simulation, without disturbing the complex bi-level optimization of
model-agnostic knowledge transfer. Extensive experiments of COLA compared to
state-of-the-art single-city baselines and our implemented cross-city baselines
have demonstrated its superiority and effectiveness. The code is available at
https://github.com/Star607/Cross-city-Mobility-Transformer.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01802" title="Abstract">arXiv:2403.01802</a> [<a href="/pdf/2403.01802" title="Download PDF">pdf</a>, <a href="/format/2403.01802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TNF: Tri-branch Neural Fusion for Multimodal Medical Data Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sone%2C+S">Shusaku Sone</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>, 
<a href="/search/cs?searchtype=author&query=Oba%2C+Y">Yuki Oba</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaxin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a Tri-branch Neural Fusion (TNF) approach designed for
classifying multimodal medical images and tabular data. It also introduces two
solutions to address the challenge of label inconsistency in multimodal
classification. Traditional methods in multi-modality medical data
classification often rely on single-label approaches, typically merging
features from two distinct input modalities. This becomes problematic when
features are mutually exclusive or labels differ across modalities, leading to
reduced accuracy. To overcome this, our TNF approach implements a tri-branch
framework that manages three separate outputs: one for image modality, another
for tabular modality, and a third hybrid output that fuses both image and
tabular data. The final decision is made through an ensemble method that
integrates likelihoods from all three branches. We validate the effectiveness
of TNF through extensive experiments, which illustrate its superiority over
traditional fusion and ensemble methods in various convolutional neural
networks and transformer-based architectures across multiple datasets.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01803" title="Abstract">arXiv:2403.01803</a> [<a href="/pdf/2403.01803" title="Download PDF">pdf</a>, <a href="/format/2403.01803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAQIEL: Ultra-Light and Safe Manipulator with Passive 3D Wire Alignment  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Temma Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Bando%2C+M">Masahiro Bando</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at IEEE Robotics and Automation Letters (RA-L), website -<a href="https://tenrobo18.github.io/saqiel-ral2023-webpage/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Improving the safety of collaborative manipulators necessitates the reduction
of inertia in the moving part. Within this paper, we introduce a novel approach
in the form of a passive 3D wire aligner, serving as a lightweight and
low-friction power transmission mechanism, thus achieving the desired low
inertia in the manipulator's operation. Through the utilization of this
innovation, the consolidation of hefty actuators onto the root link becomes
feasible, consequently enabling a supple drive characterized by minimal
friction. To demonstrate the efficacy of this device, we fabricate an
ultralight 7 degrees of freedom (DoF) manipulator named SAQIEL, boasting a mere
1.5 kg weight for its moving components. Notably, to mitigate friction within
SAQIEL's actuation system, we employ a distinctive mechanism that directly
winds wires using motors, obviating the need for traditional gear or belt-based
speed reduction mechanisms. Through a series of empirical trials, we
substantiate that SAQIEL adeptly strikes balance between lightweight design,
substantial payload capacity, elevated velocity, precision, and adaptability.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01804" title="Abstract">arXiv:2403.01804</a> [<a href="/pdf/2403.01804" title="Download PDF">pdf</a>, <a href="/format/2403.01804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointCore: Efficient Unsupervised Point Cloud Anomaly Detector Using  Local-Global Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Baozhu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Q">Qiwei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingfeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaofen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangmin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Three-dimensional point cloud anomaly detection that aims to detect anomaly
data points from a training set serves as the foundation for a variety of
applications, including industrial inspection and autonomous driving. However,
existing point cloud anomaly detection methods often incorporate multiple
feature memory banks to fully preserve local and global representations, which
comes at the high cost of computational complexity and mismatches between
features. To address that, we propose an unsupervised point cloud anomaly
detection framework based on joint local-global features, termed PointCore. To
be specific, PointCore only requires a single memory bank to store local
(coordinate) and global (PointMAE) representations and different priorities are
assigned to these local-global features, thereby reducing the computational
cost and mismatching disturbance in inference. Furthermore, to robust against
the outliers, a normalization ranking method is introduced to not only adjust
values of different scales to a notionally common scale, but also transform
densely-distributed data into a uniform distribution. Extensive experiments on
Real3D-AD dataset demonstrate that PointCore achieves competitive inference
time and the best performance in both detection and localization as compared to
the state-of-the-art Reg3D-AD approach and several competitors.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01807" title="Abstract">arXiv:2403.01807</a> [<a href="/pdf/2403.01807" title="Download PDF">pdf</a>, <a href="/format/2403.01807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViewDiff: 3D-Consistent Image Generation with Text-to-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%B6llein%2C+L">Lukas H&#xf6;llein</a>, 
<a href="/search/cs?searchtype=author&query=Bo%C5%BEi%C4%8D%2C+A">Alja&#x17e; Bo&#x17e;i&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+N">Norman M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Novotny%2C+D">David Novotny</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+H">Hung-Yu Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Richardt%2C+C">Christian Richardt</a>, 
<a href="/search/cs?searchtype=author&query=Zollh%C3%B6fer%2C+M">Michael Zollh&#xf6;fer</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024, project page: <a href="https://lukashoel.github.io/ViewDiff/">this https URL</a>, video: <a href="https://www.youtube.com/watch?v=SdjoCqHzMMk">this https URL</a>, code: <a href="https://github.com/facebookresearch/ViewDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D asset generation is getting massive amounts of attention, inspired by the
recent success of text-guided 2D content creation. Existing text-to-3D methods
use pretrained text-to-image diffusion models in an optimization problem or
fine-tune them on synthetic data, which often results in non-photorealistic 3D
objects without backgrounds. In this paper, we present a method that leverages
pretrained text-to-image models as a prior, and learn to generate multi-view
images in a single denoising process from real-world data. Concretely, we
propose to integrate 3D volume-rendering and cross-frame-attention layers into
each block of the existing U-Net network of the text-to-image model. Moreover,
we design an autoregressive generation that renders more 3D-consistent images
at any viewpoint. We train our model on real-world datasets of objects and
showcase its capabilities to generate instances with a variety of high-quality
shapes and textures in authentic surroundings. Compared to the existing
methods, the results generated by our method are consistent, and have favorable
visual quality (-30% FID, -37% KID).
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01809" title="Abstract">arXiv:2403.01809</a> [<a href="/pdf/2403.01809" title="Download PDF">pdf</a>, <a href="/format/2403.01809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deployment Challenges of Industrial Intrusion Detection Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolsing%2C+K">Konrad Wolsing</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+E">Eric Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Basels%2C+F">Frederik Basels</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+P">Patrick Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Wehrle%2C+K">Klaus Wehrle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the escalating threats posed by cyberattacks on Industrial Control
Systems (ICSs), the development of customized Industrial Intrusion Detection
Systems (IIDSs) received significant attention in research. While existing
literature proposes effective IIDS solutions evaluated in controlled
environments, their deployment in real-world industrial settings poses several
challenges. This paper highlights two critical yet often overlooked aspects
that significantly impact their practical deployment, i.e., the need for
sufficient amounts of data to train the IIDS models and the challenges
associated with finding suitable hyperparameters, especially for IIDSs training
only on genuine ICS data. Through empirical experiments conducted on multiple
state-of-the-art IIDSs and diverse datasets, we establish the criticality of
these issues in deploying IIDSs. Our findings show the necessity of extensive
malicious training data for supervised IIDSs, which can be impractical
considering the complexity of recording and labeling attacks in actual
industrial environments. Furthermore, while other IIDSs circumvent the previous
issue by requiring only benign training data, these can suffer from the
difficulty of setting appropriate hyperparameters, which likewise can diminish
their performance. By shedding light on these challenges, we aim to enhance the
understanding of the limitations and considerations necessary for deploying
effective cybersecurity solutions in ICSs, which might be one reason why IIDSs
see few deployments.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01811" title="Abstract">arXiv:2403.01811</a> [<a href="/pdf/2403.01811" title="Download PDF">pdf</a>, <a href="/format/2403.01811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Multi-Domain Automatic Short Answer Grading through an  Explainable Neuro-Symbolic Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BCnnecke%2C+F">Felix K&#xfc;nnecke</a>, 
<a href="/search/cs?searchtype=author&query=Filighera%2C+A">Anna Filighera</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+C">Colin Leong</a>, 
<a href="/search/cs?searchtype=author&query=Steuer%2C+T">Tim Steuer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Grading short answer questions automatically with interpretable reasoning
behind the grading decision is a challenging goal for current transformer
approaches. Justification cue detection, in combination with logical reasoners,
has shown a promising direction for neuro-symbolic architectures in ASAG. But,
one of the main challenges is the requirement of annotated justification cues
in the students' responses, which only exist for a few ASAG datasets. To
overcome this challenge, we contribute (1) a weakly supervised annotation
procedure for justification cues in ASAG datasets, and (2) a neuro-symbolic
model for explainable ASAG based on justification cues. Our approach improves
upon the RMSE by 0.24 to 0.3 compared to the state-of-the-art on the Short
Answer Feedback dataset in a bilingual, multi-domain, and multi-question
training setup. This result shows that our approach provides a promising
direction for generating high-quality grades and accompanying explanations for
future research in ASAG and educational NLP.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01812" title="Abstract">arXiv:2403.01812</a> [<a href="/pdf/2403.01812" title="Download PDF">pdf</a>, <a href="/format/2403.01812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-based High-Speed Elongational Rheometer for Carreau-type  Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kannengiesser%2C+L">Lukas Kannengiesser</a>, 
<a href="/search/math?searchtype=author&query=Arne%2C+W">Walter Arne</a>, 
<a href="/search/math?searchtype=author&query=Bier%2C+A">Alexander Bier</a>, 
<a href="/search/math?searchtype=author&query=Marheineke%2C+N">Nicole Marheineke</a>, 
<a href="/search/math?searchtype=author&query=Schubert%2C+D+W">Dirk W. Schubert</a>, 
<a href="/search/math?searchtype=author&query=Wegener%2C+R">Raimund Wegener</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">For the simulation-based design of fiber melt spinning processes, the
accurate modeling of the processed polymer with regard to its material behavior
is crucial. In this work, we develop a high-speed elongational rheometer for
Carreau-type materials, making use of process simulations and fiber diameter
measurements. The procedure is based on a unified formulation of the fiber
spinning model for all material types (Newtonian and non-Newtonian), whose
material laws are strictly monotone in the strain rate. The parametrically
described material law for the elongational viscosity implies a nonlinear
optimization problem for the parameter identification, for which we propose an
efficient, robust gradient-based method. The work can be understood as a proof
of concept, a generalization to other, more complex materials is possible.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01813" title="Abstract">arXiv:2403.01813</a> [<a href="/pdf/2403.01813" title="Download PDF">pdf</a>, <a href="/format/2403.01813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Baseline for Efficient Hand Mesh Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhishan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=zhou%2C+S">Shihao.zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+M">Minqiang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajun Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D hand pose estimation has found broad application in areas such as gesture
recognition and human-machine interaction tasks. As performance improves, the
complexity of the systems also increases, which can limit the comparative
analysis and practical implementation of these methods. In this paper, we
propose a simple yet effective baseline that not only surpasses
state-of-the-art (SOTA) methods but also demonstrates computational efficiency.
To establish this baseline, we abstract existing work into two components: a
token generator and a mesh regressor, and then examine their core structures. A
core structure, in this context, is one that fulfills intrinsic functions,
brings about significant improvements, and achieves excellent performance
without unnecessary complexities. Our proposed approach is decoupled from any
modifications to the backbone, making it adaptable to any modern models. Our
method outperforms existing solutions, achieving state-of-the-art (SOTA)
results across multiple datasets. On the FreiHAND dataset, our approach
produced a PA-MPJPE of 5.7mm and a PA-MPVPE of 6.0mm. Similarly, on the Dexycb
dataset, we observed a PA-MPJPE of 5.5mm and a PA-MPVPE of 5.0mm. As for
performance speed, our method reached up to 33 frames per second (fps) when
using HRNet and up to 70 fps when employing FastViT-MA36
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01816" title="Abstract">arXiv:2403.01816</a> [<a href="/pdf/2403.01816" title="Download PDF">pdf</a>, <a href="/format/2403.01816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for  Adaptive Real-Time Subtask Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Instead of making behavioral decisions directly from the exponentially
expanding joint observational-action space, subtask-based multi-agent
reinforcement learning (MARL) methods enable agents to learn how to tackle
different subtasks. Most existing subtask-based MARL methods are based on
hierarchical reinforcement learning (HRL). However, these approaches often
limit the number of subtasks, perform subtask recognition periodically, and can
only identify and execute a specific subtask within the predefined fixed time
period, which makes them inflexible and not suitable for diverse and dynamic
scenarios with constantly changing subtasks. To break through above
restrictions, a \textbf{S}liding \textbf{M}ultidimensional t\textbf{A}sk window
based m\textbf{U}ti-agent reinforcement learnin\textbf{G} framework (SMAUG) is
proposed for adaptive real-time subtask recognition. It leverages a sliding
multidimensional task window to extract essential information of subtasks from
trajectory segments concatenated based on observed and predicted trajectories
in varying lengths. An inference network is designed to iteratively predict
future trajectories with the subtask-oriented policy network. Furthermore,
intrinsic motivation rewards are defined to promote subtask exploration and
behavior diversity. SMAUG can be integrated with any Q-learning-based approach.
Experiments on StarCraft II show that SMAUG not only demonstrates performance
superiority in comparison with all baselines but also presents a more prominent
and swift rise in rewards during the initial training stage.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01817" title="Abstract">arXiv:2403.01817</a> [<a href="/pdf/2403.01817" title="Download PDF">pdf</a>, <a href="/format/2403.01817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NusaBERT: Teaching IndoBERT to be Multilingual and Multicultural
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wongso%2C+W">Wilson Wongso</a>, 
<a href="/search/cs?searchtype=author&query=Setiawan%2C+D+S">David Samuel Setiawan</a>, 
<a href="/search/cs?searchtype=author&query=Limcorn%2C+S">Steven Limcorn</a>, 
<a href="/search/cs?searchtype=author&query=Joyoadikusumo%2C+A">Ananto Joyoadikusumo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Indonesia's linguistic landscape is remarkably diverse, encompassing over 700
languages and dialects, making it one of the world's most linguistically rich
nations. This diversity, coupled with the widespread practice of code-switching
and the presence of low-resource regional languages, presents unique challenges
for modern pre-trained language models. In response to these challenges, we
developed NusaBERT, building upon IndoBERT by incorporating vocabulary
expansion and leveraging a diverse multilingual corpus that includes regional
languages and dialects. Through rigorous evaluation across a range of
benchmarks, NusaBERT demonstrates state-of-the-art performance in tasks
involving multiple languages of Indonesia, paving the way for future natural
language understanding research for under-represented languages.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01818" title="Abstract">arXiv:2403.01818</a> [<a href="/pdf/2403.01818" title="Download PDF">pdf</a>, <a href="/format/2403.01818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AllSpark: Reborn Labeled Features from Unlabeled in Transformer for  Semi-Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate
the burden of time-consuming pixel-level manual labeling, which leverages
limited labeled data along with larger amounts of unlabeled data. Current
state-of-the-art methods train the labeled data with ground truths and
unlabeled data with pseudo labels. However, the two training flows are
separate, which allows labeled data to dominate the training process, resulting
in low-quality pseudo labels and, consequently, sub-optimal results. To
alleviate this issue, we present AllSpark, which reborns the labeled features
from unlabeled ones with the channel-wise cross-attention mechanism. We further
introduce a Semantic Memory along with a Channel Semantic Grouping strategy to
ensure that unlabeled features adequately represent labeled features. The
AllSpark shed new light on the architecture level designs of SSSS rather than
framework level, which avoids increasingly complicated training pipeline
designs. It can also be regarded as a flexible bottleneck module that can be
seamlessly integrated into a general transformer-based segmentation model. The
proposed AllSpark outperforms existing methods across all evaluation protocols
on Pascal, Cityscapes and COCO benchmarks without bells-and-whistles. Code and
model weights are available at: https://github.com/xmed-lab/AllSpark.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01820" title="Abstract">arXiv:2403.01820</a> [<a href="/pdf/2403.01820" title="Download PDF">pdf</a>, <a href="/format/2403.01820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Macroscopic auxiliary asymptotic preserving neural networks for the  linear radiative transfer equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+S">Song Jiang</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+W">Wenjun Sun</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+L">Liwei Xu</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+G">Guanyu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 29 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We develop a Macroscopic Auxiliary Asymptotic-Preserving Neural Network
(MA-APNN) method to solve the time-dependent linear radiative transfer
equations (LRTEs), which have a multi-scale nature and high dimensionality. To
achieve this, we utilize the Physics-Informed Neural Networks (PINNs) framework
and design a new adaptive exponentially weighted Asymptotic-Preserving (AP)
loss function, which incorporates the macroscopic auxiliary equation that is
derived from the original transfer equation directly and explicitly contains
the information of the diffusion limit equation. Thus, as the scale parameter
tends to zero, the loss function gradually transitions from the transport state
to the diffusion limit state. In addition, the initial data, boundary
conditions, and conservation laws serve as the regularization terms for the
loss. We present several numerical examples to demonstrate the effectiveness of
MA-APNNs.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01823" title="Abstract">arXiv:2403.01823</a> [<a href="/pdf/2403.01823" title="Download PDF">pdf</a>, <a href="/format/2403.01823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RT-H: Action Hierarchies Using Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belkhale%2C+S">Suneel Belkhale</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tianli Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sermanet%2C+P">Pierre Sermanet</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quon Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Tompson%2C+J">Jonathan Tompson</a>, 
<a href="/search/cs?searchtype=author&query=Chebotar%2C+Y">Yevgen Chebotar</a>, 
<a href="/search/cs?searchtype=author&query=Dwibedi%2C+D">Debidatta Dwibedi</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Language provides a way to break down complex concepts into digestible
pieces. Recent works in robot imitation learning use language-conditioned
policies that predict actions given visual observations and the high-level task
specified in language. These methods leverage the structure of natural language
to share data between semantically similar tasks (e.g., "pick coke can" and
"pick an apple") in multi-task datasets. However, as tasks become more
semantically diverse (e.g., "pick coke can" and "pour cup"), sharing data
between tasks becomes harder, so learning to map high-level tasks to actions
requires much more demonstration data. To bridge tasks and actions, our insight
is to teach the robot the language of actions, describing low-level motions
with more fine-grained phrases like "move arm forward". Predicting these
language motions as an intermediate step between tasks and actions forces the
policy to learn the shared structure of low-level motions across seemingly
disparate tasks. Furthermore, a policy that is conditioned on language motions
can easily be corrected during execution through human-specified language
motions. This enables a new paradigm for flexible policies that can learn from
human intervention in language. Our method RT-H builds an action hierarchy
using language motions: it first learns to predict language motions, and
conditioned on this and the high-level task, it predicts actions, using visual
context at all stages. We show that RT-H leverages this language-action
hierarchy to learn policies that are more robust and flexible by effectively
tapping into multi-task datasets. We show that these policies not only allow
for responding to language interventions, but can also learn from such
interventions and outperform methods that learn from teleoperated
interventions. Our website and videos are found at
https://rt-hierarchy.github.io.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01826" title="Abstract">arXiv:2403.01826</a> [<a href="/pdf/2403.01826" title="Download PDF">pdf</a>, <a href="/format/2403.01826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Shortest Path Query Algorithm Based on Optimized Adaptive  Topology Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+S">Shurong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Cong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Ling Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Urban rail transit is a fundamental component of public transportation,
however, commonly station-based path search algorithms often overlook the
impact of transfer times on search results, leading to decreased accuracy. To
solve this problem, this paper proposes a novel shortest path query algorithm
based on adaptive topology optimization called the Adaptive Topology Extension
Road Network Structure (ATEN). This algorithm categorizes transfer stations
into different types and treats travel time and transfer time equivalently as
weights for edges in the topological graph. The proposed algorithm introduces
virtual stations to differentiate between pedestrian paths and train paths,
eliminating the need for additional operations on transfer stations. The
algorithm controls the extent of expansion in the urban rail transit topology,
overcoming query errors caused by mishandling of transfer stations in the
existing algorithm. Finally, a series of simulation experiments were conducted
on Beijing's urban rail transit network to validate both correctness and
efficiency of the proposed adaptive topology optimization algorithm. The
results demonstrate significant advantages compared to existing similar
algorithms.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01827" title="Abstract">arXiv:2403.01827</a> [<a href="/pdf/2403.01827" title="Download PDF">pdf</a>, <a href="/ps/2403.01827" title="Download PostScript">ps</a>, <a href="/format/2403.01827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Fully Memristor-based Reservoir Computing for Temporal Data  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ankur Singh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sanghyeon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gunuk Wang</a>, 
<a href="/search/cs?searchtype=author&query=Daimari%2C+M">Maryaradhiya Daimari</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byung-Geun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 20 figures, Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reservoir computing (RC) offers a neuromorphic framework that is particularly
effective for processing spatiotemporal signals. Known for its temporal
processing prowess, RC significantly lowers training costs compared to
conventional recurrent neural networks. A key component in its hardware
deployment is the ability to generate dynamic reservoir states. Our research
introduces a novel dual-memory RC system, integrating a short-term memory via a
WOx-based memristor, capable of achieving 16 distinct states encoded over 4
bits, and a long-term memory component using a TiOx-based memristor within the
readout layer. We thoroughly examine both memristor types and leverage the RC
system to process temporal data sets. The performance of the proposed RC system
is validated through two benchmark tasks: isolated spoken digit recognition
with incomplete inputs and Mackey-Glass time series prediction. The system
delivered an impressive 98.84% accuracy in digit recognition and sustained a
low normalized root mean square error (NRMSE) of 0.036 in the time series
prediction task, underscoring its capability. This study illuminates the
adeptness of memristor-based RC systems in managing intricate temporal
challenges, laying the groundwork for further innovations in neuromorphic
computing.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01830" title="Abstract">arXiv:2403.01830</a> [<a href="/pdf/2403.01830" title="Download PDF">pdf</a>, <a href="/format/2403.01830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Smoothing for Motion Planning in Real-Time NMPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Reiter%2C+R">Rudolf Reiter</a>, 
<a href="/search/eess?searchtype=author&query=Baumg%C3%A4rtner%2C+K">Katrin Baumg&#xe4;rtner</a>, 
<a href="/search/eess?searchtype=author&query=Quirynen%2C+R">Rien Quirynen</a>, 
<a href="/search/eess?searchtype=author&query=Diehl%2C+M">Moritz Diehl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Nonlinear model predictive control (NMPC) is a popular strategy for solving
motion planning problems, including obstacle avoidance constraints, in
autonomous driving applications. Non-smooth obstacle shapes, such as
rectangles, introduce additional local minima in the underlying optimization
problem. Smooth over-approximations, e.g., ellipsoidal shapes, limit the
performance due to their conservativeness. We propose to vary the smoothness
and the related over-approximation by a homotopy. Instead of varying the
smoothness in consecutive sequential quadratic programming iterations, we use
formulations that decrease the smooth over-approximation from the end towards
the beginning of the prediction horizon. Thus, the real-time iterations
algorithm is applicable to the proposed NMPC formulation. Different
formulations are compared in simulation experiments and shown to successfully
improve performance indicators without increasing the computation time.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01832" title="Abstract">arXiv:2403.01832</a> [<a href="/pdf/2403.01832" title="Download PDF">pdf</a>, <a href="/ps/2403.01832" title="Download PostScript">ps</a>, <a href="/format/2403.01832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals  and Industrial Pragmatism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Khang%2C+M">Minsoo Khang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dahyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Data-centric Machine Learning Research (DMLR) Workshop at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper delves into the contrasting roles of data within academic and
industrial spheres, highlighting the divergence between Data-Centric AI and
Model-Agnostic AI approaches. We argue that while Data-Centric AI focuses on
the primacy of high-quality data for model performance, Model-Agnostic AI
prioritizes algorithmic flexibility, often at the expense of data quality
considerations. This distinction reveals that academic standards for data
quality frequently do not meet the rigorous demands of industrial applications,
leading to potential pitfalls in deploying academic models in real-world
settings. Through a comprehensive analysis, we address these disparities,
presenting both the challenges they pose and strategies for bridging the gap.
Furthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which
aims to reconcile these differences by integrating model considerations into
data optimization processes. This approach underscores the necessity for
evolving data requirements that are sensitive to the nuances of both academic
research and industrial deployment. By exploring these discrepancies, we aim to
foster a more nuanced understanding of data's role in AI development and
encourage a convergence of academic and industrial standards to enhance AI's
real-world applicability.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01839" title="Abstract">arXiv:2403.01839</a> [<a href="/pdf/2403.01839" title="Download PDF">pdf</a>, <a href="/ps/2403.01839" title="Download PostScript">ps</a>, <a href="/format/2403.01839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Polynomial-time Algorithms Parameterized by Vertex Integrity Using  Fast Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bentert%2C+M">Matthias Bentert</a>, 
<a href="/search/cs?searchtype=author&query=Heeger%2C+K">Klaus Heeger</a>, 
<a href="/search/cs?searchtype=author&query=Koana%2C+T">Tomohiro Koana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the computational complexity of several polynomial-time-solvable
graph problems parameterized by vertex integrity, a measure of a graph's
vulnerability to vertex removal in terms of connectivity. Vertex integrity is
the smallest number $\iota$ such that there is a set $S$ of $\iota' \le \iota$
vertices such that every connected component of $G-S$ contains at most
$\iota-\iota'$ vertices. It is known that the vertex integrity lies between the
well-studied parameters vertex cover number and tree-depth.
<br />Alon and Yuster [ESA 2007] designed algorithms for graphs with small vertex
cover number using fast matrix multiplications. We demonstrate that fast matrix
multiplication can also be effectively used when parameterizing by vertex
integrity $\iota$ by developing efficient algorithms for problems including an
$O(\iota^{\omega-1}n)$-time algorithm for computing the girth of a graph,
randomized $O(\iota^{\omega - 1}n)$-time algorithms for Maximum Matching and
for finding any induced four-vertex subgraph except for a clique or an
independent set, and an $O(\iota^{(\omega-1)/2}n^2) \subseteq O(\iota^{0.687}
n^2)$-time algorithm for All-Pairs Shortest Paths. These algorithms can be
faster than previous algorithms parameterized by tree-depth, for which fast
matrix multiplication is not known to be effective.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01840" title="Abstract">arXiv:2403.01840</a> [<a href="/pdf/2403.01840" title="Download PDF">pdf</a>, <a href="/format/2403.01840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeA: Human-object Interaction Detection using Free Annotation Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhenao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Weiying Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxiu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent human-object interaction (HOI) detection approaches rely on high cost
of manpower and require comprehensive annotated image datasets. In this paper,
we propose a novel self-adaption language-driven HOI detection method, termed
as FreeA, without labeling by leveraging the adaptability of CLIP to generate
latent HOI labels. To be specific, FreeA matches image features of human-object
pairs with HOI text templates, and a priori knowledge-based mask method is
developed to suppress improbable interactions. In addition, FreeA utilizes the
proposed interaction correlation matching method to enhance the likelihood of
actions related to a specified action, further refine the generated HOI labels.
Experiments on two benchmark datasets show that FreeA achieves state-of-the-art
performance among weakly supervised HOI models. Our approach is +8.58 mean
Average Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in
localizing and classifying the interactive actions than the newest weakly
model, and +1.68 mAP and +7.28 mAP than the latest weakly+ model, respectively.
Code will be available at https://drliuqi.github.io/.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01841" title="Abstract">arXiv:2403.01841</a> [<a href="/pdf/2403.01841" title="Download PDF">pdf</a>, <a href="/format/2403.01841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Pre-trained Language Models Great on Tabular Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiahuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongxia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danny Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jintai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024 as spotlight presentation (Notable Top 5%). Codes will be available soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The transferability of deep neural networks (DNNs) has made significant
progress in image and language processing. However, due to the heterogeneity
among tables, such DNN bonus is still far from being well exploited on tabular
data prediction (e.g., regression or classification tasks). Condensing
knowledge from diverse domains, language models (LMs) possess the capability to
comprehend feature names from various tables, potentially serving as versatile
learners in transferring knowledge across distinct tables and diverse
prediction tasks, but their discrete text representation space is inherently
incompatible with numerical feature values in tables. In this paper, we present
TP-BERTa, a specifically pre-trained LM model for tabular data prediction.
Concretely, a novel relative magnitude tokenization converts scalar numerical
feature values to finely discrete, high-dimensional tokens, and an
intra-feature attention approach integrates feature values with the
corresponding feature names. Comprehensive experiments demonstrate that our
pre-trained TP-BERTa leads the performance among tabular DNNs and is
competitive with Gradient Boosted Decision Tree models in typical tabular data
regime.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01845" title="Abstract">arXiv:2403.01845</a> [<a href="/pdf/2403.01845" title="Download PDF">pdf</a>, <a href="/format/2403.01845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NASH: Neural Architecture Search for Hardware-Optimized Machine Learning  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+M">Mengfei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Al-Ars%2C+Z">Zaid Al-Ars</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">As machine learning (ML) algorithms get deployed in an ever-increasing number
of applications, these algorithms need to achieve better trade-offs between
high accuracy, high throughput and low latency. This paper introduces NASH, a
novel approach that applies neural architecture search to machine learning
hardware. Using NASH, hardware designs can achieve not only high throughput and
low latency but also superior accuracy performance. We present four versions of
the NASH strategy in this paper, all of which show higher accuracy than the
original models. The strategy can be applied to various convolutional neural
networks, selecting specific model operations among many to guide the training
process toward higher accuracy. Experimental results show that applying NASH on
ResNet18 or ResNet34 achieves a top 1 accuracy increase of up to 3.1% and a top
5 accuracy increase of up to 2.2% compared to the non-NASH version when tested
on the ImageNet data set. We also integrated this approach into the FINN
hardware model synthesis tool to automate the application of our approach and
the generation of the hardware model. Results show that using FINN can achieve
a maximum throughput of 324.5 fps. In addition, NASH models can also result in
a better trade-off between accuracy and hardware resource utilization. The
accuracy-hardware (HW) Pareto curve shows that the models with the four NASH
versions represent the best trade-offs achieving the highest accuracy for a
given HW utilization. The code for our implementation is open-source and
publicly available on GitHub at https://github.com/MFJI/NASH.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01847" title="Abstract">arXiv:2403.01847</a> [<a href="/pdf/2403.01847" title="Download PDF">pdf</a>, <a href="/format/2403.01847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Simulation of Phase Transition with the Hyperbolic  Godunov-Peshkov-Romenski Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mossier%2C+P">Pascal Mossier</a>, 
<a href="/search/math?searchtype=author&query=J%C3%B6ns%2C+S">Steven J&#xf6;ns</a>, 
<a href="/search/math?searchtype=author&query=Chiocchetti%2C+S">Simone Chiocchetti</a>, 
<a href="/search/math?searchtype=author&query=Beck%2C+A+D">Andrea D. Beck</a>, 
<a href="/search/math?searchtype=author&query=Munz%2C+C">Claus-Dieter Munz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, a thermodynamically consistent solution of the interfacial
Riemann problem for the first-order hyperbolic continuum model of Godunov,
Peshkov and Romenski (GPR model) is presented. In the presence of phase
transition, interfa- cial physics are governed by molecular interaction on a
microscopic scale, beyond the scope of the macroscopic continuum model in the
bulk phases. The developed two-phase Riemann solvers tackle this multi-scale
problem, by incorporating a local thermodynamic model to predict the
interfacial entropy production. Using phenomenological relations of
non-equilibrium thermodynamics, interfacial mass and heat fluxes are derived
from the entropy production and provide closure at the phase boundary. We
employ the proposed Riemann solvers in an efficient sharp in- terface level-set
Ghost-Fluid framework to provide coupling conditions at phase in- terfaces
under phase transition. As a single-phase benchmark, a Rayleigh-B\'enard
convection is studied to compare the hyperbolic thermal relaxation formulation
of the GPR model against the hyperbolic-parabolic Euler-Fourier system. The
novel interfacial Riemann solvers are validated against molecular dynamics
simulations of evaporating shock tubes with the Lennard-Jones shifted and
truncated potential. On a macroscopic scale, evaporating shock tubes are
computed for the material n- Dodecane and compared against Euler-Fourier
results. Finally, the efficiency and robustness of the scheme is demonstrated
with shock-droplet interaction simula- tions that involve both phase transfer
and surface tension, while featuring severe interface deformations.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01848" title="Abstract">arXiv:2403.01848</a> [<a href="/pdf/2403.01848" title="Download PDF">pdf</a>, <a href="/format/2403.01848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CET2: Modelling Topic Transitions for Coherent and Engaging  Knowledge-Grounded Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qixian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jinlan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TASLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge-grounded dialogue systems aim to generate coherent and engaging
responses based on the dialogue contexts and selected external knowledge.
Previous knowledge selection methods tend to rely too heavily on the dialogue
contexts or over-emphasize the new information in the selected knowledge,
resulting in the selection of repetitious or incongruous knowledge and further
generating repetitive or incoherent responses, as the generation of the
response depends on the chosen knowledge. To address these shortcomings, we
introduce a Coherent and Engaging Topic Transition (CET2) framework to model
topic transitions for selecting knowledge that is coherent to the context of
the conversations while providing adequate knowledge diversity for topic
development. Our CET2 framework considers multiple factors for knowledge
selection, including valid transition logic from dialogue contexts to the
following topics and systematic comparisons between available knowledge
candidates. Extensive experiments on two public benchmarks demonstrate the
superiority and the better generalization ability of CET2 on knowledge
selection. This is due to our well-designed transition features and comparative
knowledge selection strategy, which are more transferable to conversations
about unseen topics. Analysis of fine-grained knowledge selection accuracy also
shows that CET2 can better balance topic entailment (contextual coherence) and
development (knowledge diversity) in dialogue than existing approaches.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01849" title="Abstract">arXiv:2403.01849</a> [<a href="/pdf/2403.01849" title="Download PDF">pdf</a>, <a href="/format/2403.01849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Prompt Word is Enough to Boost Adversarial Robustness for  Pre-trained Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haoyan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Spratling%2C+M">Michael Spratling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large pre-trained Vision-Language Models (VLMs) like CLIP, despite having
remarkable generalization ability, are highly vulnerable to adversarial
examples. This work studies the adversarial robustness of VLMs from the novel
perspective of the text prompt instead of the extensively studied model weights
(frozen in this work). We first show that the effectiveness of both adversarial
attack and defense are sensitive to the used text prompt. Inspired by this, we
propose a method to improve resilience to adversarial attacks by learning a
robust text prompt for VLMs. The proposed method, named Adversarial Prompt
Tuning (APT), is effective while being both computationally and data efficient.
Extensive experiments are conducted across 15 datasets and 4 data sparsity
schemes (from 1-shot to full training data settings) to show APT's superiority
over hand-engineered prompts and other state-of-the-art adaption methods. APT
demonstrated excellent abilities in terms of the in-distribution performance
and the generalization under input distribution shift and across datasets.
Surprisingly, by simply adding one learned word to the prompts, APT can
significantly boost the accuracy and robustness (epsilon=4/255) over the
hand-engineered prompts by +13% and +8.5% on average respectively. The
improvement further increases, in our most effective setting, to +26.4% for
accuracy and +16.7% for robustness. Code is available at
https://github.com/TreeLLi/APT.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01851" title="Abstract">arXiv:2403.01851</a> [<a href="/pdf/2403.01851" title="Download PDF">pdf</a>, <a href="/format/2403.01851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xin Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mixtral, a representative sparse mixture of experts (SMoE) language model,
has received significant attention due to its unique model design and superior
performance. Based on Mixtral-8x7B-v0.1, in this paper, we propose
Chinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language
abilities by adopting further pre-training and instruction fine-tuning.
Experimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct
successfully improve Chinese understanding and generation performance while
retaining the original English abilities. Then, we discuss several key
questions when performing language adaptation on large language models,
including the necessity of extending the language-specific vocabulary and the
choice of the initialization model (foundation model v.s. instruction model),
by providing empirical results and analysis. We also present the visualizations
of each expert to examine their importance on downstream tasks. Our resources
are publicly available through \url{https://github.com/ymcui/Chinese-Mixtral}.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01852" title="Abstract">arXiv:2403.01852</a> [<a href="/pdf/2403.01852" title="Download PDF">pdf</a>, <a href="/format/2403.01852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PLACE: Adaptive Layout-Semantic Fusion for Semantic Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhengyao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K">Kwan-Yee K. Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in large-scale pre-trained text-to-image models have led
to remarkable progress in semantic image synthesis. Nevertheless, synthesizing
high-quality images with consistent semantics and layout remains a challenge.
In this paper, we propose the adaPtive LAyout-semantiC fusion modulE (PLACE)
that harnesses pre-trained models to alleviate the aforementioned issues.
Specifically, we first employ the layout control map to faithfully represent
layouts in the feature space. Subsequently, we combine the layout and semantic
features in a timestep-adaptive manner to synthesize images with realistic
details. During fine-tuning, we propose the Semantic Alignment (SA) loss to
further enhance layout alignment. Additionally, we introduce the Layout-Free
Prior Preservation (LFP) loss, which leverages unlabeled data to maintain the
priors of pre-trained models, thereby improving the visual quality and semantic
consistency of synthesized images. Extensive experiments demonstrate that our
approach performs favorably in terms of visual quality, semantic consistency,
and layout alignment. The source code and model are available at
https://github.com/cszy98/PLACE/tree/main.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01857" title="Abstract">arXiv:2403.01857</a> [<a href="/pdf/2403.01857" title="Download PDF">pdf</a>, <a href="/ps/2403.01857" title="Download PostScript">ps</a>, <a href="/format/2403.01857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Model Learning vs. Direct Policy Optimization: A Comparative  Analysis of Learning from Human Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nika%2C+A">Andi Nika</a>, 
<a href="/search/cs?searchtype=author&query=Mandal%2C+D">Debmalya Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Kamalaruban%2C+P">Parameswaran Kamalaruban</a>, 
<a href="/search/cs?searchtype=author&query=Tzannetos%2C+G">Georgios Tzannetos</a>, 
<a href="/search/cs?searchtype=author&query=Radanovi%C4%87%2C+G">Goran Radanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we take a step towards a deeper understanding of learning from
human preferences by systematically comparing the paradigm of reinforcement
learning from human feedback (RLHF) with the recently proposed paradigm of
direct preference optimization (DPO). We focus our attention on the class of
loglinear policy parametrization and linear reward functions. In order to
compare the two paradigms, we first derive minimax statistical bounds on the
suboptimality gap induced by both RLHF and DPO, assuming access to an oracle
that exactly solves the optimization problems. We provide a detailed discussion
on the relative comparison between the two paradigms, simultaneously taking
into account the sample size, policy and reward class dimensions, and the
regularization temperature. Moreover, we extend our analysis to the approximate
optimization setting and derive exponentially decaying convergence rates for
both RLHF and DPO. Next, we analyze the setting where the ground-truth reward
is not realizable and find that, while RLHF incurs a constant additional error,
DPO retains its asymptotically decaying gap by just tuning the temperature
accordingly. Finally, we extend our comparison to the Markov decision process
setting, where we generalize our results with exact optimization. To the best
of our knowledge, we are the first to provide such a comparative analysis for
RLHF and DPO.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01858" title="Abstract">arXiv:2403.01858</a> [<a href="/pdf/2403.01858" title="Download PDF">pdf</a>, <a href="/format/2403.01858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Traditional Chinese Evaluation Suite for Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tam%2C+Z">Zhi-Rui Tam</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+Y">Ya-Ting Pai</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yen-Wei Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sega Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+H">Hong-Han Shuai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present TMMLU+, a comprehensive dataset designed for the Traditional
Chinese massive multitask language understanding dataset. TMMLU+ is a
multiple-choice question-answering dataset with 66 subjects from elementary to
professional level. Compared to its predecessor, TMMLU, TMMLU+ is six times
larger and boasts a more balanced subject distribution. We included benchmark
results in TMMLU+ from closed-source models and 24 open-weight Chinese large
language models of parameters ranging from 1.8B to 72B. Our findings reveal
that Traditional Chinese models still trail behind their Simplified Chinese
counterparts. Additionally, current large language models have yet to
outperform human performance in average scores. We publicly release our dataset
and the corresponding benchmark source code.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01859" title="Abstract">arXiv:2403.01859</a> [<a href="/pdf/2403.01859" title="Download PDF">pdf</a>, <a href="/format/2403.01859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CSE: Surface Anomaly Detection with Contrastively Selected Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomine%2C+S">Simon Thomine</a>, 
<a href="/search/cs?searchtype=author&query=Snoussi%2C+H">Hichem Snoussi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, VISAPP 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting surface anomalies of industrial materials poses a significant
challenge within a myriad of industrial manufacturing processes. In recent
times, various methodologies have emerged, capitalizing on the advantages of
employing a network pre-trained on natural images for the extraction of
representative features. Subsequently, these features are subjected to
processing through a diverse range of techniques including memory banks,
normalizing flow, and knowledge distillation, which have exhibited exceptional
accuracy. This paper revisits approaches based on pre-trained features by
introducing a novel method centered on target-specific embedding. To capture
the most representative features of the texture under consideration, we employ
a variant of a contrastive training procedure that incorporates both
artificially generated defective samples and anomaly-free samples during
training. Exploiting the intrinsic properties of surfaces, we derived a
meaningful representation from the defect-free samples during training,
facilitating a straightforward yet effective calculation of anomaly scores. The
experiments conducted on the MVTEC AD and TILDA datasets demonstrate the
competitiveness of our approach compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01860" title="Abstract">arXiv:2403.01860</a> [<a href="/pdf/2403.01860" title="Download PDF">pdf</a>, <a href="/format/2403.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaliGNNoma: GNN-Based Malicious Circuit Classifier for Secure Cloud  FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alrahis%2C+L">Lilas Alrahis</a>, 
<a href="/search/cs?searchtype=author&query=Nassar%2C+H">Hassan Nassar</a>, 
<a href="/search/cs?searchtype=author&query=Krautter%2C+J">Jonas Krautter</a>, 
<a href="/search/cs?searchtype=author&query=Gnad%2C+D">Dennis Gnad</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+L">Lars Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Henkel%2C+J">Jorg Henkel</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M">Mehdi Tahoori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will appear in the 2024 IEEE International Symposium on Hardware Oriented Security and Trust (HOST)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The security of cloud field-programmable gate arrays (FPGAs) faces challenges
from untrusted users attempting fault and side-channel attacks through
malicious circuit configurations. Fault injection attacks can result in denial
of service, disrupting functionality or leaking secret information. This threat
is further amplified in multi-tenancy scenarios. Detecting such threats before
loading onto the FPGA is crucial, but existing methods face difficulty
identifying sophisticated attacks.
<br />We present MaliGNNoma, a machine learning-based solution that accurately
identifies malicious FPGA configurations. Serving as a netlist scanning
mechanism, it can be employed by cloud service providers as an initial security
layer within a necessary multi-tiered security system. By leveraging the
inherent graph representation of FPGA netlists, MaliGNNoma employs a graph
neural network (GNN) to learn distinctive malicious features, surpassing
current approaches. To enhance transparency, MaliGNNoma utilizes a
parameterized explainer for the GNN, labeling the FPGA configuration and
pinpointing the sub-circuit responsible for the malicious classification.
<br />Through extensive experimentation on the ZCU102 board with a Xilinx
UltraScale+ FPGA, we validate the effectiveness of MaliGNNoma in detecting
malicious configurations, including sophisticated attacks, such as those based
on benign modules, like cryptography accelerators. MaliGNNoma achieves a
classification accuracy and precision of 98.24% and 97.88%, respectively,
surpassing state-of-the-art. We compare MaliGNNoma with five state-of-the-art
scanning methods, revealing that not all attack vectors detected by MaliGNNoma
are recognized by existing solutions, further emphasizing its effectiveness.
Additionally, we make MaliGNNoma and its associated dataset publicly available.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01861" title="Abstract">arXiv:2403.01861</a> [<a href="/pdf/2403.01861" title="Download PDF">pdf</a>, <a href="/format/2403.01861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jaehoon Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Inha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minje Kim</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+K">Kyungdon Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, Accepted to IEEE RA-L (First two authors contributed equally)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Indoor scenes we are living in are visually homogenous or textureless, while
they inherently have structural forms and provide enough structural priors for
3D scene reconstruction. Motivated by this fact, we propose a structure-aware
online signed distance fields (SDF) reconstruction framework in indoor scenes,
especially under the Atlanta world (AW) assumption. Thus, we dub this
incremental SDF reconstruction for AW as AiSDF. Within the online framework, we
infer the underlying Atlanta structure of a given scene and then estimate
planar surfel regions supporting the Atlanta structure. This Atlanta-aware
surfel representation provides an explicit planar map for a given scene. In
addition, based on these Atlanta planar surfel regions, we adaptively sample
and constrain the structural regularity in the SDF reconstruction, which
enables us to improve the reconstruction quality by maintaining a high-level
structure while enhancing the details of a given scene. We evaluate the
proposed AiSDF on the ScanNet and ReplicaCAD datasets, where we demonstrate
that the proposed framework is capable of reconstructing fine details of
objects implicitly, as well as structures explicitly in room-scale scenes.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01862" title="Abstract">arXiv:2403.01862</a> [<a href="/pdf/2403.01862" title="Download PDF">pdf</a>, <a href="/format/2403.01862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTS: Bringing Multi-Tenancy to Virtual Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thimmaraju%2C+K">Kashyap Thimmaraju</a>, 
<a href="/search/cs?searchtype=author&query=Hermak%2C+S">Saad Hermak</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9tv%C3%A1ri%2C+G">G&#xe1;bor R&#xe9;tv&#xe1;ri</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> USENIX ATC 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Multi-tenant cloud computing provides great benefits in terms of resource
sharing, elastic pricing, and scalability, however, it also changes the
security landscape and intro- duces the need for strong isolation between the
tenants, also inside the network. This paper is motivated by the observation
that while multi-tenancy is widely used in cloud computing, the virtual switch
designs currently used for network virtualization lack sufficient support for
tenant isolation. Hence, we present, implement, and evaluate a virtual switch
architecture, MTS, which brings secure design best-practice to the context of
multi-tenant virtual networking: compartmentalization of virtual switches,
least-privilege execution, complete mediation of all network communication, and
reducing the trusted computing base shared between tenants. We build MTS from
commodity components, providing an incrementally deployable and inexpensive
upgrade path to cloud operators. Our extensive experiments, extending to both
micro-benchmarks and cloud applications, show that, depending on the way it is
deployed, MTS may produce 1.5- 2x the throughput compared to state-of-the-art,
with similar or better latency and modest resource overhead (1 extra CPU). MTS
is available as open source software.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01863" title="Abstract">arXiv:2403.01863</a> [<a href="/pdf/2403.01863" title="Download PDF">pdf</a>, <a href="/format/2403.01863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Schema-Based Query Optimisation for Graph Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+C">Chandan Sharma</a> (TYREX), 
<a href="/search/cs?searchtype=author&query=Genev%C3%A8s%2C+P">Pierre Genev&#xe8;s</a> (TYREX), 
<a href="/search/cs?searchtype=author&query=Gesbert%2C+N">Nils Gesbert</a> (TYREX), 
<a href="/search/cs?searchtype=author&query=Laya%C3%AFda%2C+N">Nabil Laya&#xef;da</a> (TYREX)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Recursive graph queries are increasingly popular for extracting information
from interconnected data found in various domains such as social networks, life
sciences, and business analytics. Graph data often come with schema information
that describe how nodes and edges are organized. We propose a type inference
mechanism that enriches recursive graph queries with relevant structural
information contained in a graph schema. We show that this schema information
can be useful in order to improve the performance when evaluating acylic
recursive graph queries. Furthermore, we prove that the proposed method is
sound and complete, ensuring that the semantics of the query is preserved
during the schema-enrichment process.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01864" title="Abstract">arXiv:2403.01864</a> [<a href="/pdf/2403.01864" title="Download PDF">pdf</a>, <a href="/format/2403.01864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RCoCo: Contrastive Collective Link Prediction across Multiplex Network  in Riemannian Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Li Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Haohua Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Springer International Journal of Machine Learning and Cybernetics (JMLC), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Link prediction typically studies the probability of future interconnection
among nodes with the observation in a single social network. More often than
not, real scenario is presented as a multiplex network with common (anchor)
users active in multiple social networks. In the literature, most existing
works study either the intra-link prediction in a single network or inter-link
prediction among networks (a.k.a. network alignment), and consider two learning
tasks are independent from each other, which is still away from the fact. On
the representation space, the vast majority of existing methods are built upon
the traditional Euclidean space, unaware of the inherent geometry of social
networks. The third issue is on the scarce anchor users. Annotating anchor
users is laborious and expensive, and thus it is impractical to work with
quantities of anchor users. Herein, in light of the issues above, we propose to
study a challenging yet practical problem of Geometry-aware Collective Link
Prediction across Multiplex Network. To address this problem, we present a
novel contrastive model, RCoCo, which collaborates intra- and inter-network
behaviors in Riemannian spaces. In RCoCo, we design a curvature-aware graph
attention network ($\kappa-$GAT), conducting attention mechanism in Riemannian
manifold whose curvature is estimated by the Ricci curvatures over the network.
Thereafter, we formulate intra- and inter-contrastive loss in the manifolds, in
which we augment graphs by exploring the high-order structure of community and
information transfer on anchor users. Finally, we conduct extensive experiments
with 14 strong baselines on 8 real-world datasets, and show the effectiveness
of RCoCo.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01866" title="Abstract">arXiv:2403.01866</a> [<a href="/pdf/2403.01866" title="Download PDF">pdf</a>, <a href="/ps/2403.01866" title="Download PostScript">ps</a>, <a href="/format/2403.01866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circular Programs and Self-Referential Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allison%2C+L">Lloyd Allison</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Software Practice and Experience, 19(2), 99-109, 1989
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">A circular program creates a data structure whose computation depends upon
itself or refers to itself. The technique is used to implement the classic data
structures circular and doubly-linked lists, threaded trees and queues, in a
functional programming language. These structures are normally thought to
require updatable variables found in imperative languages. For example, a
functional program to per- form the breadth-first traversal of a tree is given.
Some of the examples result in circular data struc- tures when evaluated. Some
examples are particularly space-efficient by avoiding the creation of inter-
mediate temporary structures which would otherwise later become garbage.
Lastly, the technique can be applied in an imperative language to give an
elegant program.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01867" title="Abstract">arXiv:2403.01867</a> [<a href="/pdf/2403.01867" title="Download PDF">pdf</a>, <a href="/format/2403.01867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Separation Logic with Pointer Arithmetic and Inductive  Definitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wanyun Su</a> (LCS), 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhilin Wu</a> (LCS), 
<a href="/search/cs?searchtype=author&query=Sighireanu%2C+M">Mihaela Sighireanu</a> (LMF)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Pointer arithmetic is widely used in low-level programs, e.g. memory
allocators. The specification of such programs usually requires using pointer
arithmetic inside inductive definitions to define the common data structures,
e.g. heap lists in memory allocators. In this work, we investigate decision
problems for SLAH, a separation logic fragment that allows pointer arithmetic
inside inductive definitions, thus enabling specification of properties for
programs manipulating heap lists. Pointer arithmetic inside inductive
definitions is challenging for automated reasoning. We tackle this challenge
and achieve decision procedures for both satisfiability and entailment of SLAH
formulas. The crux of our decision procedure for satisfiability is to compute
summaries of inductive definitions. We show that although the summary is
naturally expressed as an existentially quantified non-linear arithmetic
formula, it can actually be transformed into an equivalent linear arithmetic
formula. The decision procedure for entailment, on the other hand, has to match
and split the spatial atoms according to the arithmetic relation between
address variables. We report on the implementation of these decision procedures
and their good performance in solving problems issued from the verification of
building block programs used in memory allocators.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01871" title="Abstract">arXiv:2403.01871</a> [<a href="/pdf/2403.01871" title="Download PDF">pdf</a>, <a href="/format/2403.01871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penetration Testing of 5G Core Network Web Technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giambartolomei%2C+F">Filippo Giambartolomei</a>, 
<a href="/search/cs?searchtype=author&query=Barcel%C3%B3%2C+M">Marc Barcel&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Brighente%2C+A">Alessandro Brighente</a>, 
<a href="/search/cs?searchtype=author&query=Urbieta%2C+A">Aitor Urbieta</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Thanks to technologies such as virtual network function the Fifth Generation
(5G) of mobile networks dynamically allocate resources to different types of
users in an on-demand fashion. Virtualization extends up to the 5G core, where
software-defined networks and network slicing implement a customizable
environment. These technologies can be controlled via application programming
interfaces and web technologies, inheriting hence their security risks and
settings. An attacker exploiting vulnerable implementations of the 5G core may
gain privileged control of the network assets and disrupt its availability.
However, there is currently no security assessment of the web security of the
5G core network.
<br />In this paper, we present the first security assessment of the 5G core from a
web security perspective. We use the STRIDE threat modeling approach to define
a complete list of possible threat vectors and associated attacks. Thanks to a
suite of security testing tools, we cover all of these threats and test the
security of the 5G core. In particular, we test the three most relevant
open-source 5G core implementations, i.e., Open5GS, Free5Gc, and
OpenAirInterface. Our analysis shows that all these cores are vulnerable to at
least two of our identified attack vectors, demanding increased security
measures in the development of future 5G core networks.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01872" title="Abstract">arXiv:2403.01872</a> [<a href="/pdf/2403.01872" title="Download PDF">pdf</a>, <a href="/ps/2403.01872" title="Download PostScript">ps</a>, <a href="/format/2403.01872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Canadian Traveller Problem on outerplanar graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beaudou%2C+L">Laurent Beaudou</a>, 
<a href="/search/cs?searchtype=author&query=Berg%C3%A9%2C+P">Pierre Berg&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Chernyshev%2C+V">Vsevolod Chernyshev</a>, 
<a href="/search/cs?searchtype=author&query=Dailly%2C+A">Antoine Dailly</a>, 
<a href="/search/cs?searchtype=author&query=Gerard%2C+Y">Yan Gerard</a>, 
<a href="/search/cs?searchtype=author&query=Lagoutte%2C+A">Aur&#xe9;lie Lagoutte</a>, 
<a href="/search/cs?searchtype=author&query=Limouzy%2C+V">Vincent Limouzy</a>, 
<a href="/search/cs?searchtype=author&query=Pastor%2C+L">Lucas Pastor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the PSPACE-complete $k$-Canadian Traveller Problem, where a weighted
graph $G=(V,E,\omega)$ with a source $s\in V$ and a target $t\in V$ are given.
This problem also has a hidden input $E_* \subsetneq E$ of cardinality at most
$k$ representing blocked edges. The objective is to travel from $s$ to $t$ with
the minimum distance. At the beginning of the walk, the blockages $E_*$ are
unknown: the traveller discovers that an edge is blocked when visiting one of
its endpoints. Online algorithms, also called strategies, have been proposed
for this problem and assessed with the competitive ratio, i.e. the ratio
between the distance actually traversed by the traveller divided by the
distance we would have traversed knowing the blockages in advance.
<br />Even though the optimal competitive ratio is $2k+1$ even on unit-weighted
planar graphs of treewidth 2, we design a polynomial-time strategy achieving
competitive ratio $9$ on unit-weighted outerplanar graphs. This value $9$ also
stands as a lower bound for this family of graphs as we prove that, for any
$\varepsilon &gt; 0$, no strategy can achieve a competitive ratio $9-\varepsilon$.
Finally, we show that it is not possible to achieve a constant competitive
ratio (independent of $G$ and $k$) on weighted outerplanar graphs.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01873" title="Abstract">arXiv:2403.01873</a> [<a href="/pdf/2403.01873" title="Download PDF">pdf</a>, <a href="/format/2403.01873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommending Missed Citations Identified by Reviewers: A New Task,  Dataset and Baselines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+K">Kehan Long</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shasha Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pancheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+C">Chenlong Bao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jintao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Citing comprehensively and appropriately has become a challenging task with
the explosive growth of scientific publications. Current citation
recommendation systems aim to recommend a list of scientific papers for a given
text context or a draft paper. However, none of the existing work focuses on
already included citations of full papers, which are imperfect and still have
much room for improvement. In the scenario of peer reviewing, it is a common
phenomenon that submissions are identified as missing vital citations by
reviewers. This may lead to a negative impact on the credibility and validity
of the research presented. To help improve citations of full papers, we first
define a novel task of Recommending Missed Citations Identified by Reviewers
(RMC) and construct a corresponding expert-labeled dataset called CitationR. We
conduct an extensive evaluation of several state-of-the-art methods on
CitationR. Furthermore, we propose a new framework RMCNet with an Attentive
Reference Encoder module mining the relevance between papers, already-made
citations, and missed citations. Empirical results prove that RMC is
challenging, with the proposed architecture outperforming previous methods in
all metrics. We release our dataset and benchmark models to motivate future
research on this challenging new task.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01874" title="Abstract">arXiv:2403.01874</a> [<a href="/pdf/2403.01874" title="Download PDF">pdf</a>, <a href="/format/2403.01874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Evaluation of Out-of-Distribution Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiashuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models, while progressively advanced, rely heavily on the
IID assumption, which is often unfulfilled in practice due to inevitable
distribution shifts. This renders them susceptible and untrustworthy for
deployment in risk-sensitive applications. Such a significant problem has
consequently spawned various branches of works dedicated to developing
algorithms capable of Out-of-Distribution (OOD) generalization. Despite these
efforts, much less attention has been paid to the evaluation of OOD
generalization, which is also a complex and fundamental problem. Its goal is
not only to assess whether a model's OOD generalization capability is strong or
not, but also to evaluate where a model generalizes well or poorly. This
entails characterizing the types of distribution shifts that a model can
effectively address, and identifying the safe and risky input regions given a
model. This paper serves as the first effort to conduct a comprehensive review
of OOD evaluation. We categorize existing research into three paradigms: OOD
performance testing, OOD performance prediction, and OOD intrinsic property
characterization, according to the availability of test data. Additionally, we
briefly discuss OOD evaluation in the context of pretrained models. In closing,
we propose several promising directions for future research in OOD evaluation.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01875" title="Abstract">arXiv:2403.01875</a> [<a href="/pdf/2403.01875" title="Download PDF">pdf</a>, <a href="/format/2403.01875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICLN: Input Convex Loss Network for Decision Focused Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Haeun Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Hyunglip Bae</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Minsu Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chanyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+C">Woo Chang Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In decision-making problem under uncertainty, predicting unknown parameters
is often considered independent of the optimization part. Decision-focused
Learning (DFL) is a task-oriented framework to integrate prediction and
optimization by adapting predictive model to give better decision for the
corresponding task. Here, an inevitable challenge arises when computing
gradients of the optimal decision with respect to the parameters. Existing
researches cope this issue by smoothly reforming surrogate optimization or
construct surrogate loss function that mimic task loss. However, they are
applied to restricted optimization domain or build functions in a local manner
leading a large computational time. In this paper, we propose Input Convex Loss
Network (ICLN), a novel global surrogate loss which can be implemented in a
general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks
which is guaranteed to be convex for some inputs, while keeping the global
structure for the other inputs. This enables ICLN to admit general DFL through
only a single surrogate loss without any sense for choosing appropriate
parametric forms. We confirm effectiveness and flexibility of ICLN by
evaluating our proposed model with three stochastic decision-making problems.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01876" title="Abstract">arXiv:2403.01876</a> [<a href="/pdf/2403.01876" title="Download PDF">pdf</a>, <a href="/format/2403.01876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D&#xe9;j&#xe0;Vu: KV-cache Streaming for Fast, Fault-tolerant Generative LLM  Serving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strati%2C+F">Foteini Strati</a>, 
<a href="/search/cs?searchtype=author&query=Mcallister%2C+S">Sara Mcallister</a>, 
<a href="/search/cs?searchtype=author&query=Phanishayee%2C+A">Amar Phanishayee</a>, 
<a href="/search/cs?searchtype=author&query=Tarnawski%2C+J">Jakub Tarnawski</a>, 
<a href="/search/cs?searchtype=author&query=Klimovic%2C+A">Ana Klimovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Distributed LLM serving is costly and often underutilizes hardware
accelerators due to three key challenges: bubbles in pipeline-parallel
deployments caused by the bimodal latency of prompt and token processing, GPU
memory overprovisioning, and long recovery times in case of failures. In this
paper, we propose D\'ej\`aVu, a system to address all these challenges using a
versatile and efficient KV cache streaming library (D\'ej\`aVuLib). Using
D\'ej\`aVuLib, we propose and implement efficient prompt-token disaggregation
to reduce pipeline bubbles, microbatch swapping for efficient GPU memory
management, and state replication for fault-tolerance. We highlight the
efficacy of these solutions on a range of large models across cloud
deployments.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01878" title="Abstract">arXiv:2403.01878</a> [<a href="/pdf/2403.01878" title="Download PDF">pdf</a>, <a href="/format/2403.01878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I DPID It My Way! A Covert Timing Channel in Software-Defined Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kr%C3%B6sche%2C+R">Robert Kr&#xf6;sche</a>, 
<a href="/search/cs?searchtype=author&query=Thimmaraju%2C+K">Kashyap Thimmaraju</a>, 
<a href="/search/cs?searchtype=author&query=Schiff%2C+L">Liron Schiff</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFIP Networking 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Software-defined networking is considered a promising new paradigm, enabling
more reliable and formally verifiable communication networks. However, this
paper shows that the separation of the control plane from the data plane, which
lies at the heart of Software-Defined Networks (SDNs), can be exploited for
covert channels based on SDN Teleportation, even when the data planes are
physically disconnected.
<br />This paper describes the theoretical model and design of our covert timing
channel based on SDN Teleportation. We implement our covert channel using a
popular SDN switch, Open vSwitch, and a popular SDN controller, ONOS. Our
evaluation of the prototype shows that even under load at the controller,
throughput rates of 20 bits per second are possible, with a communication
accuracy of approximately 90\%. We also discuss techniques to increase the
throughput further.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01879" title="Abstract">arXiv:2403.01879</a> [<a href="/pdf/2403.01879" title="Download PDF">pdf</a>, <a href="/format/2403.01879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High curvature means low-rank: On the sectional curvature of Grassmann  and Stiefel manifolds and the underlying matrix trace inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zimmermann%2C+R">Ralf Zimmermann</a>, 
<a href="/search/math?searchtype=author&query=Stoye%2C+J">Jakob Stoye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Methods and algorithms that work with data on nonlinear manifolds are
collectively summarised under the term `Riemannian computing'. In practice,
curvature can be a key limiting factor for the performance of Riemannian
computing methods. Yet, curvature can also be a powerful tool in the
theoretical analysis of Riemannian algorithms. In this work, we investigate the
sectional curvature of the Stiefel and Grassmann manifold from the quotient
space view point. On the Grassmannian, tight curvature bounds are known since
the late 1960ies. On the Stiefel manifold under the canonical metric, it was
believed that the sectional curvature does not exceed 5/4. For both of these
manifolds, the sectional curvature is given by the Frobenius norm of certain
structured commutator brackets of skew-symmetric matrices. We provide refined
inequalities for such terms and pay special attention to the maximizers of the
curvature bounds. In this way, we prove that the global bound of 5/4 for
Stiefel holds indeed. With this addition, a complete account of the curvature
bounds in all admissible dimensions is obtained. We observe that `high
curvature means low-rank', more precisely, for the Stiefel and Grassmann
manifolds, the global curvature maximum is attained at tangent plane sections
that are spanned by rank-two matrices. Numerical examples are included for
illustration purposes.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01882" title="Abstract">arXiv:2403.01882</a> [<a href="/pdf/2403.01882" title="Download PDF">pdf</a>, <a href="/format/2403.01882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Virtual Reality for Detection and Intervention of Depression - A  Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waqas%2C+M">Mohammad Waqas</a>, 
<a href="/search/cs?searchtype=author&query=Gururaj%2C+Y+P">Y Pawankumar Gururaj</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+V+D+S">V D Shanmukha Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Karri%2C+S+A">Sai Anirudh Karri</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+R">Raghu Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Azeemuddin%2C+S">Syed Azeemuddin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 3 tables, Conference full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The use of emerging technologies like Virtual Reality (VR) in therapeutic
settings has increased in the past few years. By incorporating VR, a mental
health condition like depression can be assessed effectively, while also
providing personalized motivation and meaningful engagement for treatment
purposes. The integration of external sensors further enhances the engagement
of the subjects with the VR scenes. This paper presents a comprehensive review
of existing literature on the detection and treatment of depression using VR.
It explores various types of VR scenes, external hardware, innovative metrics,
and targeted user studies conducted by researchers and professionals in the
field. The paper also discusses potential requirements for designing VR scenes
specifically tailored for depression assessment and treatment, with the aim of
guiding future practitioners in this area.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01886" title="Abstract">arXiv:2403.01886</a> [<a href="/pdf/2403.01886" title="Download PDF">pdf</a>, <a href="/format/2403.01886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FCDS: Fusing Constituency and Dependency Syntax into Document-Level  Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xudong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Bei Hui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appear in COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Document-level Relation Extraction (DocRE) aims to identify relation labels
between entities within a single document. It requires handling several
sentences and reasoning over them. State-of-the-art DocRE methods use a graph
structure to connect entities across the document to capture dependency syntax
information. However, this is insufficient to fully exploit the rich syntax
information in the document. In this work, we propose to fuse constituency and
dependency syntax into DocRE. It uses constituency syntax to aggregate the
whole sentence information and select the instructive sentences for the pairs
of targets. It exploits the dependency syntax in a graph structure with
constituency syntax enhancement and chooses the path between entity pairs based
on the dependency graph. The experimental results on datasets from various
domains demonstrate the effectiveness of the proposed method. The code is
publicly available at this url.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01887" title="Abstract">arXiv:2403.01887</a> [<a href="/pdf/2403.01887" title="Download PDF">pdf</a>, <a href="/ps/2403.01887" title="Download PostScript">ps</a>, <a href="/format/2403.01887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $3$-dimensional MRD codes of type $\langle x^{q^t},x+&#x3b4;  x^{q^{2t}},G(x) \rangle$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartoli%2C+D">Daniele Bartoli</a>, 
<a href="/search/cs?searchtype=author&query=Ghiandoni%2C+F">Francesco Ghiandoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">In this work we present results on the classification of
$\mathbb{F}_{q^n}$-linear MRD codes of dimension three. In particular, using
connections with certain algebraic varieties over finite fields, we provide
non-existence results for MRD codes $\mathcal{C}=\langle x^{q^t}, F(x), G(x)
\rangle \subseteq \mathcal{L}_{n,q}$ of exceptional type, i.e. such that
$\mathcal{C}$ is MRD over infinite many extensions of the field
$\mathbb{F}_{q^n}$. These results partially address a conjecture of Bartoli,
Zini and Zullo in 2023.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01888" title="Abstract">arXiv:2403.01888</a> [<a href="/pdf/2403.01888" title="Download PDF">pdf</a>, <a href="/format/2403.01888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on  Zero-Cost Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shuhei Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Mallik%2C+N">Neeratyoy Mallik</a>, 
<a href="/search/cs?searchtype=author&query=Bergman%2C+E">Edward Bergman</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AutoML Conference 2024 ABCD Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While deep learning has celebrated many successes, its results often hinge on
the meticulous selection of hyperparameters (HPs). However, the time-consuming
nature of deep learning training makes HP optimization (HPO) a costly endeavor,
slowing down the development of efficient HPO tools. While zero-cost
benchmarks, which provide performance and runtime without actual training,
offer a solution for non-parallel setups, they fall short in parallel setups as
each worker must communicate its queried runtime to return its evaluation in
the exact order. This work addresses this challenge by introducing a
user-friendly Python package that facilitates efficient parallel HPO with
zero-cost benchmarks. Our approach calculates the exact return order based on
the information stored in file system, eliminating the need for long waiting
times and enabling much faster HPO evaluations. We first verify the correctness
of our approach through extensive testing and the experiments with 6 popular
HPO libraries show its applicability to diverse libraries and its ability to
achieve over 1000x speedup compared to a traditional approach. Our package can
be installed via pip install mfhpo-simulator.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01890" title="Abstract">arXiv:2403.01890</a> [<a href="/pdf/2403.01890" title="Download PDF">pdf</a>, <a href="/format/2403.01890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aerial Tensile Perching and Disentangling Mechanism for Long-Term  Environmental Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Romanello%2C+L">Luca Romanello</a>, 
<a href="/search/cs?searchtype=author&query=Kovac%2C+M">Mirko Kovac</a>, 
<a href="/search/cs?searchtype=author&query=Armanini%2C+S+F">Sophie F. Armanini</a>, 
<a href="/search/cs?searchtype=author&query=Kocer%2C+B+B">Basaran Bahadir Kocer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, Accepted in IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Aerial robots show significant potential for forest canopy research and
environmental monitoring by providing data collection capabilities at high
spatial and temporal resolutions. However, limited flight endurance hinders
their application. Inspired by natural perching behaviours, we propose a
multi-modal aerial robot system that integrates tensile perching for energy
conservation and a suspended actuated pod for data collection. The system
consists of a quadrotor drone, a slewing ring mechanism allowing 360{\deg}
tether rotation, and a streamlined pod with two ducted propellers connected via
a tether. Winding and unwinding the tether allows the pod to move within the
canopy, and activating the propellers allows the tether to be wrapped around
branches for perching or disentangling. We experimentally determined the
minimum counterweights required for stable perching under various conditions.
Building on this, we devised and evaluated multiple perching and disentangling
strategies. Comparisons of perching and disentangling manoeuvres demonstrate
energy savings that could be further maximized with the use of the pod or
tether winding. These approaches can reduce energy consumption to only 22\% and
1.5\%, respectively, compared to a drone disentangling manoeuvre. We also
calculated the minimum idle time required by the proposed system after the
system perching and motor shut down to save energy on a mission, which is
48.9\% of the operating time. Overall, the integrated system expands the
operational capabilities and enhances the energy efficiency of aerial robots
for long-term monitoring tasks.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01891" title="Abstract">arXiv:2403.01891</a> [<a href="/pdf/2403.01891" title="Download PDF">pdf</a>, <a href="/format/2403.01891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gotta catch &#x27;em all, safely! Aerial-deployed soft underwater gripper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romanello%2C+L">Luca Romanello</a>, 
<a href="/search/cs?searchtype=author&query=Amir%2C+D+J">Daniel Joseph Amir</a>, 
<a href="/search/cs?searchtype=author&query=Stengel%2C+H">Heinrich Stengel</a>, 
<a href="/search/cs?searchtype=author&query=Kovac%2C+M">Mirko Kovac</a>, 
<a href="/search/cs?searchtype=author&query=Armanini%2C+S+F">Sophie F. Armanini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, Accepted in IEEE International Conference on Soft Robotics 2024 (Robosoft)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Underwater soft grippers exhibit potential for applications such as
monitoring, research, and object retrieval. However, existing underwater
gripping techniques frequently cause disturbances to ecosystems. In response to
this challenge, we present a novel underwater gripping framework comprising a
lightweight gripper affixed to a custom submarine pod deployable via drone.
This approach minimizes water disturbance and enables efficient navigation to
target areas, enhancing overall mission effectiveness. The pod allows for
underwater motion and is characterized by four degrees of freedom. It is
provided with a custom buoyancy system, two water pumps for differential thrust
and two for pitching. The system allows for buoyancy adjustments up to a depth
of 6 meters, as well as motion in the plane. The 3-fingered gripper is
manufactured out of silicone and was successfully tested on objects with
different shapes and sizes, demonstrating a maximum pulling force of up to 8 N
when underwater. The reliability of the submarine pod was tested in a water
tank by tracking its attitude and energy consumption during grasping maneuvers.
The system also accomplished a successful mission in a lake, where it was
deployed on a hexacopter. Overall, the integration of this system expands the
operational capabilities of underwater grasping, makes grasping missions more
efficient and easy to automate, as well as causing less disturbance to the
water ecosystem.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01895" title="Abstract">arXiv:2403.01895</a> [<a href="/pdf/2403.01895" title="Download PDF">pdf</a>, <a href="/format/2403.01895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Distance Metric Learning for Anomaly Detection Over  Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hanyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qinglin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Keting Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Distance-based time series anomaly detection methods are prevalent due to
their relative non-parametric nature and interpretability. However, the
commonly used Euclidean distance is sensitive to noise. While existing works
have explored dynamic time warping (DTW) for its robustness, they only support
supervised tasks over multivariate time series (MTS), leaving a scarcity of
unsupervised methods. In this work, we propose FCM-wDTW, an unsupervised
distance metric learning method for anomaly detection over MTS, which encodes
raw data into latent space and reveals normal dimension relationships through
cluster centers. FCM-wDTW introduces locally weighted DTW into fuzzy C-means
clustering and learns the optimal latent space efficiently, enabling anomaly
identification via data reconstruction. Experiments with 11 different types of
benchmarks demonstrate our method's competitive accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01896" title="Abstract">arXiv:2403.01896</a> [<a href="/pdf/2403.01896" title="Download PDF">pdf</a>, <a href="/format/2403.01896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Bounds on the Successful Adversarial Examples: Theory and  Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maeshima%2C+H">Hiroaki Maeshima</a>, 
<a href="/search/cs?searchtype=author&query=Otsuka%2C+A">Akira Otsuka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Adversarial example (AE) is an attack method for machine learning, which is
crafted by adding imperceptible perturbation to the data inducing
misclassification. In the current paper, we investigated the upper bound of the
probability of successful AEs based on the Gaussian Process (GP)
classification. We proved a new upper bound that depends on AE's perturbation
norm, the kernel function used in GP, and the distance of the closest pair with
different labels in the training dataset. Surprisingly, the upper bound is
determined regardless of the distribution of the sample dataset. We showed that
our theoretical result was confirmed through the experiment using ImageNet. In
addition, we showed that changing the parameters of the kernel function induces
a change of the upper bound of the probability of successful AEs.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01897" title="Abstract">arXiv:2403.01897</a> [<a href="/pdf/2403.01897" title="Download PDF">pdf</a>, <a href="/ps/2403.01897" title="Download PostScript">ps</a>, <a href="/format/2403.01897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fostering the Ecosystem of Open Neural Encoders for Portuguese with  Albertina PT* Family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+R">Rodrigo Santos</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+J">Jo&#xe3;o Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+L">Lu&#xed;s Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J">Jo&#xe3;o Silva</a>, 
<a href="/search/cs?searchtype=author&query=Branco%2C+A">Ant&#xf3;nio Branco</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+H+L">Henrique Lopes Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Os%C3%B3rio%2C+T+F">Tom&#xe1;s Freitas Os&#xf3;rio</a>, 
<a href="/search/cs?searchtype=author&query=Leite%2C+B">Bernardo Leite</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To foster the neural encoding of Portuguese, this paper contributes
foundation encoder models that represent an expansion of the still very scarce
ecosystem of large language models specifically developed for this language
that are fully open, in the sense that they are open source and openly
distributed for free under an open license for any purpose, thus including
research and commercial usages. Like most languages other than English,
Portuguese is low-resourced in terms of these foundational language resources,
there being the inaugural 900 million parameter Albertina and 335 million
Bertimbau. Taking this couple of models as an inaugural set, we present the
extension of the ecosystem of state-of-the-art open encoders for Portuguese
with a larger, top performance-driven model with 1.5 billion parameters, and a
smaller, efficiency-driven model with 100 million parameters. While achieving
this primary goal, further results that are relevant for this ecosystem were
obtained as well, namely new datasets for Portuguese based on the SuperGLUE
benchmark, which we also distribute openly.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01898" title="Abstract">arXiv:2403.01898</a> [<a href="/pdf/2403.01898" title="Download PDF">pdf</a>, <a href="/format/2403.01898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Learning-based Video Motion Magnification for Real-time  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ha%2C+H">Hyunwoo Ha</a>, 
<a href="/search/cs?searchtype=author&query=Hyun-Bin%2C+O">Oh Hyun-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Jun-Seong%2C+K">Kim Jun-Seong</a>, 
<a href="/search/cs?searchtype=author&query=Byung-Ki%2C+K">Kwon Byung-Ki</a>, 
<a href="/search/cs?searchtype=author&query=Sung-Bin%2C+K">Kim Sung-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Linh-Tam Tran</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Ji-Yun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+S">Sung-Ho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Video motion magnification is a technique to capture and amplify subtle
motion in a video that is invisible to the naked eye. The deep learning-based
prior work successfully demonstrates the modelling of the motion magnification
problem with outstanding quality compared to conventional signal
processing-based ones. However, it still lags behind real-time performance,
which prevents it from being extended to various online applications. In this
paper, we investigate an efficient deep learning-based motion magnification
model that runs in real time for full-HD resolution videos. Due to the
specified network design of the prior art, i.e. inhomogeneous architecture, the
direct application of existing neural architecture search methods is
complicated. Instead of automatic search, we carefully investigate the
architecture module by module for its role and importance in the motion
magnification task. Two key findings are 1) Reducing the spatial resolution of
the latent motion representation in the decoder provides a good trade-off
between computational efficiency and task quality, and 2) surprisingly, only a
single linear layer and a single branch in the encoder are sufficient for the
motion magnification task. Based on these findings, we introduce a real-time
deep learning-based motion magnification model with4.2X fewer FLOPs and is 2.7X
faster than the prior art while maintaining comparable quality.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01900" title="Abstract">arXiv:2403.01900</a> [<a href="/pdf/2403.01900" title="Download PDF">pdf</a>, <a href="/format/2403.01900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universality of reservoir systems with recurrent neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yasumoto%2C+H">Hiroki Yasumoto</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Toshiyuki Tanaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Approximation capability of reservoir systems whose reservoir is a recurrent
neural network (RNN) is discussed. In our problem setting, a reservoir system
approximates a set of functions just by adjusting its linear readout while the
reservoir is fixed. We will show what we call uniform strong universality of a
family of RNN reservoir systems for a certain class of functions to be
approximated. This means that, for any positive number, we can construct a
sufficiently large RNN reservoir system whose approximation error for each
function in the class of functions to be approximated is bounded from above by
the positive number. Such RNN reservoir systems are constructed via parallel
concatenation of RNN reservoirs.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01901" title="Abstract">arXiv:2403.01901</a> [<a href="/pdf/2403.01901" title="Download PDF">pdf</a>, <a href="/format/2403.01901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces  from Disentangled Audio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Jiazheng Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+J">Jun Dan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Ying Tai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baigui Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we abstract the process of people hearing speech, extracting
meaningful cues, and creating various dynamically audio-consistent talking
faces, termed Listening and Imagining, into the task of high-fidelity diverse
talking faces generation from a single audio. Specifically, it involves two
critical challenges: one is to effectively decouple identity, content, and
emotion from entangled audio, and the other is to maintain intra-video
diversity and inter-video consistency. To tackle the issues, we first dig out
the intricate relationships among facial factors and simplify the decoupling
process, tailoring a Progressive Audio Disentanglement for accurate facial
geometry and semantics learning, where each stage incorporates a customized
training module responsible for a specific factor. Secondly, to achieve
visually diverse and audio-synchronized animation solely from input audio
within a single model, we introduce the Controllable Coherent Frame generation,
which involves the flexible integration of three trainable adapters with frozen
Latent Diffusion Models (LDMs) to focus on maintaining facial geometry and
semantics, as well as texture and temporal coherence between frames. In this
way, we inherit high-quality diverse generation from LDMs while significantly
improving their controllability at a low training cost. Extensive experiments
demonstrate the flexibility and effectiveness of our method in handling this
paradigm. The codes will be released at
https://github.com/modelscope/facechain.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01902" title="Abstract">arXiv:2403.01902</a> [<a href="/pdf/2403.01902" title="Download PDF">pdf</a>, <a href="/format/2403.01902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Generation of Git Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Courtiel%2C+J">Julien Courtiel</a> (GREYC), 
<a href="/search/cs?searchtype=author&query=P%C3%A9pin%2C+M">Martin P&#xe9;pin</a> (GREYC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Version Control Systems, such as Git and Mercurial, manage the history of a
project as a Directed Acyclic Graph encoding the various divergences and
synchronizations happening in its life cycle. A popular workflow in the
industry, called the feature branch workflow, constrains these graphs to be of
a particular shape: a unique main branch, and non-interfering feature branches.
Here we focus on the uniform random generation of those graphs with n vertices,
including k on the main branch, for which we provide three algorithms, for
three different use-cases. The first, based on rejection, is efficient when
aiming for small values of k (more precisely whenever k = O($\sqrt$ n)). The
second takes as input any number k of commits in the main branch, but requires
costly precalculation. The last one is a Boltzmann generator and enables us to
generate very large graphs while targeting a constant k/n ratio. All these
algorithms are linear in the size of their outputs.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01903" title="Abstract">arXiv:2403.01903</a> [<a href="/pdf/2403.01903" title="Download PDF">pdf</a>, <a href="/format/2403.01903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Locality Meets Distributed Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akbari%2C+A">Amirreza Akbari</a>, 
<a href="/search/cs?searchtype=author&query=Coiteux-Roy%2C+X">Xavier Coiteux-Roy</a>, 
<a href="/search/cs?searchtype=author&query=d%27Amore%2C+F">Francesco d&#x27;Amore</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+F+L">Fran&#xe7;ois Le Gall</a>, 
<a href="/search/cs?searchtype=author&query=Lievonen%2C+H">Henrik Lievonen</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+D">Darya Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Modanese%2C+A">Augusto Modanese</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+S">Shreyas Pai</a>, 
<a href="/search/cs?searchtype=author&query=Renou%2C+M">Marc-Olivier Renou</a>, 
<a href="/search/cs?searchtype=author&query=Rozho%C5%88%2C+V">V&#xe1;clav Rozho&#x148;</a>, 
<a href="/search/cs?searchtype=author&query=Suomela%2C+J">Jukka Suomela</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Complexity (cs.CC); Probability (math.PR); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We extend the theory of locally checkable labeling problems (LCLs) from the
classical LOCAL model to a number of other models that have been studied
recently, including the quantum-LOCAL model, finitely-dependent processes,
non-signaling model, dynamic-LOCAL model, and online-LOCAL model [e.g. STOC
2024, ICALP 2023].
<br />First, we demonstrate the advantage that finitely-dependent processes have
over the classical LOCAL model. We show that all LCL problems solvable with
locality $O(\log^* n)$ in the LOCAL model admit a finitely-dependent
distribution (with constant locality). In particular, this gives a
finitely-dependent coloring for regular trees, answering an open question by
Holroyd [2023]. This also introduces a new formal barrier for understanding the
distributed quantum advantage: it is not possible to exclude quantum advantage
for any LCL in the $\Theta(\log^* n)$ complexity class by using non-signaling
arguments.
<br />Second, we put limits on the capabilities of all of these models. To this
end, we introduce a model called randomized online-LOCAL, which is strong
enough to simulate e.g. SLOCAL and dynamic-LOCAL, and we show that it is also
strong enough to simulate any non-signaling distribution and hence any
quantum-LOCAL algorithm. We prove the following result for trees: if we can
solve an LCL problem with locality $o(\log^{(5)} n)$ in the randomized
online-LOCAL model, we can solve it with locality $O(\log^* n)$ in the
classical deterministic LOCAL model.
<br />Put together, these results show that in trees the set of LCLs that can be
solved with locality $O(\log^* n)$ is the same across all these models:
locality $O(\log^* n)$ in quantum-LOCAL, non-signaling model, dynamic-LOCAL, or
online-LOCAL is not stronger than locality $O(\log^* n)$ in the classical
deterministic LOCAL model.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01909" title="Abstract">arXiv:2403.01909</a> [<a href="/pdf/2403.01909" title="Download PDF">pdf</a>, <a href="/format/2403.01909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ran%2C+L">Lingyan Ran</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yali Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+G">Guoqiang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semantic segmentation is an important and popular research area in computer
vision that focuses on classifying pixels in an image based on their semantics.
However, supervised deep learning requires large amounts of data to train
models and the process of labeling images pixel by pixel is time-consuming and
laborious. This review aims to provide a first comprehensive and organized
overview of the state-of-the-art research results on pseudo-label methods in
the field of semi-supervised semantic segmentation, which we categorize from
different perspectives and present specific methods for specific application
areas. In addition, we explore the application of pseudo-label technology in
medical and remote-sensing image segmentation. Finally, we also propose some
feasible future research directions to address the existing challenges.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01915" title="Abstract">arXiv:2403.01915</a> [<a href="/pdf/2403.01915" title="Download PDF">pdf</a>, <a href="/format/2403.01915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xT: Nested Tokenization for Larger Context in Large Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ritwik Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shufan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tyler Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Mangalam%2C+K">Karttikeya Mangalam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern computer vision pipelines handle large images in one of two
sub-optimal ways: down-sampling or cropping. These two methods incur
significant losses in the amount of information and context present in an
image. There are many downstream applications in which global context matters
as much as high frequency details, such as in real-world satellite imagery; in
such cases researchers have to make the uncomfortable choice of which
information to discard. We introduce xT, a simple framework for vision
transformers which effectively aggregates global context with local details and
can model large images end-to-end on contemporary GPUs. We select a set of
benchmark datasets across classic vision tasks which accurately reflect a
vision model's ability to understand truly large images and incorporate fine
details over large scales and assess our method's improvement on them. By
introducing a nested tokenization scheme for large images in conjunction with
long-sequence length models normally used for natural language processing, we
are able to increase accuracy by up to 8.6% on challenging classification tasks
and $F_1$ score by 11.6 on context-dependent segmentation in large images.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01918" title="Abstract">arXiv:2403.01918</a> [<a href="/pdf/2403.01918" title="Download PDF">pdf</a>, <a href="/format/2403.01918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Continuous Assurance Case Creation for ADS with the Evidential  Tool Bus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorokin%2C+L">Lev Sorokin</a>, 
<a href="/search/cs?searchtype=author&query=Bouchekir%2C+R">Radouane Bouchekir</a>, 
<a href="/search/cs?searchtype=author&query=Beyene%2C+T+A">Tewodros A. Beyene</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B+H">Brian Hsuan-Cheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Molin%2C+A">Adam Molin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International SafeAutonomy Workshop at EDCC '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">An assurance case has become an integral component for the certification of
safety-critical systems. While manually defining assurance case patterns can be
not avoided, system-specific instantiations of assurance case patterns are both
costly and time-consuming. It becomes especially complex to maintain an
assurance case for a system when the requirements of the System-Under-Assurance
change, or an assurance claim becomes invalid due to, e.g., degradation of a
systems component, as common when deploying learning-enabled components. In
this paper, we report on our preliminary experience leveraging the tool
integration framework Evidential Tool Bus (ETB) for the construction and
continuous maintenance of an assurance case from a predefined assurance case
pattern. Specifically, we demonstrate the assurance process on an industrial
Automated Valet Parking system from the automotive domain. We present the
formalization of the provided assurance case pattern in the ETB processable
logical specification language of workflows. Our findings show that ETB is able
to create and maintain evidence required for the construction of an assurance
case.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01919" title="Abstract">arXiv:2403.01919</a> [<a href="/pdf/2403.01919" title="Download PDF">pdf</a>, <a href="/format/2403.01919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Completion with Convex Optimization and Column Subset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krajewska%2C+A">Antonina Krajewska</a>, 
<a href="/search/cs?searchtype=author&query=Niewiadomska-Szynkiewicz%2C+E">Ewa Niewiadomska-Szynkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce a two-step method for the matrix recovery problem. Our approach
combines the theoretical foundations of the Column Subset Selection and
Low-rank Matrix Completion problems. The proposed method, in each step, solves
a convex optimization task. We present two algorithms that implement our
Columns Selected Matrix Completion (CSMC) method, each dedicated to a different
size problem. We performed a formal analysis of the presented method, in which
we formulated the necessary assumptions and the probability of finding a
correct solution. In the second part of the paper, we present the results of
the experimental work. Numerical experiments verified the correctness and
performance of the algorithms. To study the influence of the matrix size, rank,
and the proportion of missing elements on the quality of the solution and the
computation time, we performed experiments on synthetic data. The presented
method was applied to two real-life problems problems: prediction of movie
rates in a recommendation system and image inpainting. Our thorough analysis
shows that CSMC provides solutions of comparable quality to matrix completion
algorithms, which are based on convex optimization. However, CSMC offers
notable savings in terms of runtime.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01920" title="Abstract">arXiv:2403.01920</a> [<a href="/pdf/2403.01920" title="Download PDF">pdf</a>, <a href="/format/2403.01920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected Newton method for large-scale Bayesian linear inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+H">Haibo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Computing the regularized solution of Bayesian linear inverse problems as
well as the corresponding regularization parameter is highly desirable in many
applications. This paper proposes a novel iterative method, termed the
Projected Newton method (PNT), that can simultaneously update the
regularization parameter and solution step by step without requiring any
high-cost matrix inversions or decompositions. By reformulating the Tikhonov
regularization as a constrained minimization problem and writing its Lagrangian
function, a Newton-type method coupled with a Krylov subspace method, called
the generalized Golub-Kahan bidiagonalization, is employed for the
unconstrained Lagrangian function. The resulting PNT algorithm only needs
solving a small-scale linear system to get a descent direction of a merit
function at each iteration, thus significantly reducing computational overhead.
Rigorous convergence results are proved, showing that PNT always converges to
the unique regularized solution and the corresponding Lagrangian multiplier.
Experimental results on both small and large-scale Bayesian inverse problems
demonstrate its excellent convergence property, robustness and efficiency.
Given that the most demanding computational tasks in PNT are primarily
matrix-vector products, it is particularly well-suited for large-scale
problems.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01921" title="Abstract">arXiv:2403.01921</a> [<a href="/pdf/2403.01921" title="Download PDF">pdf</a>, <a href="/ps/2403.01921" title="Download PostScript">ps</a>, <a href="/format/2403.01921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with  Wider Topic Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almurqren%2C+L">Latifah Almurqren</a>, 
<a href="/search/cs?searchtype=author&query=Hodgson%2C+R">Ryan Hodgson</a>, 
<a href="/search/cs?searchtype=author&query=Cristea%2C+A">Alexandra Cristea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentiment analysis (SA) has been, and is still, a thriving research area.
However, the task of Arabic sentiment analysis (ASA) is still underrepresented
in the body of research. This study offers the first in-depth and in-breadth
analysis of existing ASA studies of textual content and identifies their common
themes, domains of application, methods, approaches, technologies and
algorithms used. The in-depth study manually analyses 133 ASA papers published
in the English language between 2002 and 2020 from four academic databases
(SAGE, IEEE, Springer, WILEY) and from Google Scholar. The in-breadth study
uses modern, automatic machine learning techniques, such as topic modelling and
temporal analysis, on Open Access resources, to reinforce themes and trends
identified by the prior study, on 2297 ASA publications between 2010-2020. The
main findings show the different approaches used for ASA: machine learning,
lexicon-based and hybrid approaches. Other findings include ASA 'winning'
algorithms (SVM, NB, hybrid methods). Deep learning methods, such as LSTM can
provide higher accuracy, but for ASA sometimes the corpora are not large enough
to support them. Additionally, whilst there are some ASA corpora and lexicons,
more are required. Specifically, Arabic tweets corpora and datasets are
currently only moderately sized. Moreover, Arabic lexicons that have high
coverage contain only Modern Standard Arabic (MSA) words, and those with Arabic
dialects are quite small. Thus, new corpora need to be created. On the other
hand, ASA tools are stringently lacking. There is a need to develop ASA tools
that can be used in industry, as well as in academia, for Arabic text SA.
Hence, our study offers insights into the challenges associated with ASA
research and provides suggestions for ways to move the field forward such as
lack of Dialectical Arabic resource, Arabic tweets, corpora and data sets for
SA.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01922" title="Abstract">arXiv:2403.01922</a> [<a href="/pdf/2403.01922" title="Download PDF">pdf</a>, <a href="/format/2403.01922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowPrecision: Advancing FPGA-Based Real-Time Fluid Flow Estimation with  Linear Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+T">Tianheng Ling</a>, 
<a href="/search/cs?searchtype=author&query=Hoever%2C+J">Julian Hoever</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+G">Gregor Schiele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, The 22nd International Conference on Pervasive Computing and Communications (PerCom 2024), PerConAI Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">In industrial and environmental monitoring, achieving real-time and precise
fluid flow measurement remains a critical challenge. This study applies linear
quantization in FPGA-based soft sensors for fluid flow estimation,
significantly enhancing Neural Network model precision by overcoming the
limitations of traditional fixed-point quantization. Our approach achieves up
to a 10.10% reduction in Mean Squared Error and a notable 9.39% improvement in
inference speed through targeted hardware optimizations. Validated across
multiple data sets, our findings demonstrate that the optimized FPGA-based
quantized models can provide efficient, accurate real-time inference, offering
a viable alternative to cloud-based processing in pervasive autonomous systems.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01924" title="Abstract">arXiv:2403.01924</a> [<a href="/pdf/2403.01924" title="Download PDF">pdf</a>, <a href="/format/2403.01924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Generate or to Retrieve? On the Effectiveness of Artificial Contexts  for Medical Open-Domain Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frisoni%2C+G">Giacomo Frisoni</a>, 
<a href="/search/cs?searchtype=author&query=Cocchieri%2C+A">Alessio Cocchieri</a>, 
<a href="/search/cs?searchtype=author&query=Presepi%2C+A">Alex Presepi</a>, 
<a href="/search/cs?searchtype=author&query=Moro%2C+G">Gianluca Moro</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zaiqiao Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Medical open-domain question answering demands substantial access to
specialized knowledge. Recent efforts have sought to decouple knowledge from
model parameters, counteracting architectural scaling and allowing for training
on common low-resource hardware. The retrieve-then-read paradigm has become
ubiquitous, with model predictions grounded on relevant knowledge pieces from
external repositories such as PubMed, textbooks, and UMLS. An alternative path,
still under-explored but made possible by the advent of domain-specific large
language models, entails constructing artificial contexts through prompting. As
a result, "to generate or to retrieve" is the modern equivalent of Hamlet's
dilemma. This paper presents MedGENIE, the first generate-then-read framework
for multiple-choice question answering in medicine. We conduct extensive
experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical
perspective by assuming a maximum of 24GB VRAM. MedGENIE sets a new
state-of-the-art (SOTA) in the open-book setting of each testbed, even allowing
a small-scale reader to outcompete zero-shot closed-book 175B baselines while
using up to 706$\times$ fewer parameters. Overall, our findings reveal that
generated passages are more effective than retrieved counterparts in attaining
higher accuracy.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01926" title="Abstract">arXiv:2403.01926</a> [<a href="/pdf/2403.01926" title="Download PDF">pdf</a>, <a href="/format/2403.01926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IndicVoices: Towards building an Inclusive Multilingual Speech Dataset  for Indian Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javed%2C+T">Tahir Javed</a>, 
<a href="/search/cs?searchtype=author&query=Nawale%2C+J+A">Janki Atul Nawale</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+E+I">Eldho Ittan George</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sakshi Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Bhogale%2C+K+S">Kaushal Santosh Bhogale</a>, 
<a href="/search/cs?searchtype=author&query=Mehendale%2C+D">Deovrat Mehendale</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+I+V">Ishvinder Virender Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Ananthanarayanan%2C+A">Aparna Ananthanarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Faquih%2C+H">Hafsah Faquih</a>, 
<a href="/search/cs?searchtype=author&query=Palit%2C+P">Pratiti Palit</a>, 
<a href="/search/cs?searchtype=author&query=Ravishankar%2C+S">Sneha Ravishankar</a>, 
<a href="/search/cs?searchtype=author&query=Sukumaran%2C+S">Saranya Sukumaran</a>, 
<a href="/search/cs?searchtype=author&query=Panchagnula%2C+T">Tripura Panchagnula</a>, 
<a href="/search/cs?searchtype=author&query=Murali%2C+S">Sunjay Murali</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+K+S">Kunal Sharad Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+A">Ambujavalli R</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+M+K">Manickam K M</a>, 
<a href="/search/cs?searchtype=author&query=Vaijayanthi%2C+C+V">C Venkata Vaijayanthi</a>, 
<a href="/search/cs?searchtype=author&query=Karunganni%2C+K+S+R">Krishnan Srinivasa Raghavan Karunganni</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Pratyush Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Khapra%2C+M+M">Mitesh M Khapra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present INDICVOICES, a dataset of natural and spontaneous speech
containing a total of 7348 hours of read (9%), extempore (74%) and
conversational (17%) audio from 16237 speakers covering 145 Indian districts
and 22 languages. Of these 7348 hours, 1639 hours have already been
transcribed, with a median of 73 hours per language. Through this paper, we
share our journey of capturing the cultural, linguistic and demographic
diversity of India to create a one-of-its-kind inclusive and representative
dataset. More specifically, we share an open-source blueprint for data
collection at scale comprising of standardised protocols, centralised tools, a
repository of engaging questions, prompts and conversation scenarios spanning
multiple domains and topics of interest, quality control mechanisms,
comprehensive transcription guidelines and transcription tools. We hope that
this open source blueprint will serve as a comprehensive starter kit for data
collection efforts in other multilingual regions of the world. Using
INDICVOICES, we build IndicASR, the first ASR model to support all the 22
languages listed in the 8th schedule of the Constitution of India. All the
data, tools, guidelines, models and other materials developed as a part of this
work will be made publicly available
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01928" title="Abstract">arXiv:2403.01928</a> [<a href="/pdf/2403.01928" title="Download PDF">pdf</a>, <a href="/format/2403.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZSL-RPPO: Zero-Shot Learning for Quadrupedal Locomotion in Challenging  Terrains using Recurrent Proximal Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bou-Ammar%2C+H">Haitham Bou-Ammar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+P">Peng Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present ZSL-RPPO, an improved zero-shot learning architecture that
overcomes the limitations of teacher-student neural networks and enables
generating robust, reliable, and versatile locomotion for quadrupedal robots in
challenging terrains. We propose a new algorithm RPPO (Recurrent Proximal
Policy Optimization) that directly trains recurrent neural network in partially
observable environments and results in more robust training using domain
randomization. Our locomotion controller supports extensive perturbation across
simulation-to-reality transfer for both intrinsic and extrinsic physical
parameters without further fine-tuning. This can avoid the significant decline
of student's performance during simulation-to-reality transfer and therefore
enhance the robustness and generalization of the locomotion controller. We
deployed our controller on the Unitree A1 and Aliengo robots in real
environment and exteroceptive perception is provided by either a solid-state
Lidar or a depth camera. Our locomotion controller was tested in various
challenging terrains like slippery surfaces, Grassy Terrain, and stairs. Our
experiment results and comparison show that our approach significantly
outperforms the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01929" title="Abstract">arXiv:2403.01929</a> [<a href="/pdf/2403.01929" title="Download PDF">pdf</a>, <a href="/format/2403.01929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Adapting Large Language Models for Few-Shot Multilingual  NLU: Are We There Yet?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razumovskaia%2C+E">Evgeniia Razumovskaia</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Supervised fine-tuning (SFT), supervised instruction tuning (SIT) and
in-context learning (ICL) are three alternative, de facto standard approaches
to few-shot learning. ICL has gained popularity recently with the advent of
LLMs due to its simplicity and sample efficiency. Prior research has conducted
only limited investigation into how these approaches work for multilingual
few-shot learning, and the focus so far has been mostly on their performance.
In this work, we present an extensive and systematic comparison of the three
approaches, testing them on 6 high- and low-resource languages, three different
NLU tasks, and a myriad of language and domain setups. Importantly, performance
is only one aspect of the comparison, where we also analyse the approaches
through the optics of their computational, inference and financial costs. Our
observations show that supervised instruction tuning has the best trade-off
between performance and resource requirements. As another contribution, we
analyse the impact of target language adaptation of pretrained LLMs and find
that the standard adaptation approaches can (superficially) improve target
language generation capabilities, but language understanding elicited through
ICL does not improve and remains limited, with low scores especially for
low-resource languages.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01931" title="Abstract">arXiv:2403.01931</a> [<a href="/pdf/2403.01931" title="Download PDF">pdf</a>, <a href="/format/2403.01931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VariErr NLI: Separating Annotation Error from Human Label Variation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber-Genzel%2C+L">Leon Weber-Genzel</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Siyao Peng</a>, 
<a href="/search/cs?searchtype=author&query=de+Marneffe%2C+M">Marie-Catherine de Marneffe</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+B">Barbara Plank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human label variation arises when annotators assign different labels to the
same item for valid reasons, while annotation errors occur when labels are
assigned for invalid reasons. These two issues are prevalent in NLP benchmarks,
yet existing research has studied them in isolation. To the best of our
knowledge, there exists no prior work that focuses on teasing apart error from
signal, especially in cases where signal is beyond black-and-white. To fill
this gap, we introduce a systematic methodology and a new dataset, VariErr
(variation versus error), focusing on the NLI task in English. We propose a
2-round annotation scheme with annotators explaining each label and
subsequently judging the validity of label-explanation pairs. \name{} contains
7,574 validity judgments on 1,933 explanations for 500 re-annotated NLI items.
We assess the effectiveness of various automatic error detection (AED) methods
and GPTs in uncovering errors versus human label variation. We find that
state-of-the-art AED methods significantly underperform compared to GPTs and
humans. While GPT-4 is the best system, it still falls short of human
performance. Our methodology is applicable beyond NLI, offering fertile ground
for future research on error versus plausible variation, which in turn can
yield better and more trustworthy NLP systems.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01932" title="Abstract">arXiv:2403.01932</a> [<a href="/pdf/2403.01932" title="Download PDF">pdf</a>, <a href="/format/2403.01932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Counting by Bridging 3D Point Clouds with Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianfang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Oehmcke%2C+S">Stefan Oehmcke</a>, 
<a href="/search/cs?searchtype=author&query=Gominski%2C+D+P+J">Dimitri Pierre Johannes Gominski</a>, 
<a href="/search/cs?searchtype=author&query=Gieseke%2C+F">Fabian Gieseke</a>, 
<a href="/search/cs?searchtype=author&query=Igel%2C+C">Christian Igel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate and consistent methods for counting trees based on remote sensing
data are needed to support sustainable forest management, assess climate change
mitigation strategies, and build trust in tree carbon credits. Two-dimensional
remote sensing imagery primarily shows overstory canopy, and it does not
facilitate easy differentiation of individual trees in areas with a dense
canopy and does not allow for easy separation of trees when the canopy is
dense. We leverage the fusion of three-dimensional LiDAR measurements and 2D
imagery to facilitate the accurate counting of trees. We compare a deep
learning approach to counting trees in forests using 3D airborne LiDAR data and
2D imagery. The approach is compared with state-of-the-art algorithms, like
operating on 3D point cloud and 2D imagery. We empirically evaluate the
different methods on the NeonTreeCount data set, which we use to define a
tree-counting benchmark. The experiments show that FuseCountNet yields more
accurate tree counts.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01942" title="Abstract">arXiv:2403.01942</a> [<a href="/pdf/2403.01942" title="Download PDF">pdf</a>, <a href="/format/2403.01942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Label Noise on Graph via Topological Sample Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the success of the carefully-annotated benchmarks, the effectiveness
of existing graph neural networks (GNNs) can be considerably impaired in
practice when the real-world graph data is noisily labeled. Previous
explorations in sample selection have been demonstrated as an effective way for
robust learning with noisy labels, however, the conventional studies focus on
i.i.d data, and when moving to non-iid graph data and GNNs, two notable
challenges remain: (1) nodes located near topological class boundaries are very
informative for classification but cannot be successfully distinguished by the
heuristic sample selection. (2) there is no available measure that considers
the graph topological information to promote sample selection in a graph. To
address this dilemma, we propose a $\textit{Topological Sample Selection}$
(TSS) method that boosts the informative sample selection process in a graph by
utilising topological information. We theoretically prove that our procedure
minimizes an upper bound of the expected risk under target clean distribution,
and experimentally show the superiority of our method compared with
state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01944" title="Abstract">arXiv:2403.01944</a> [<a href="/pdf/2403.01944" title="Download PDF">pdf</a>, <a href="/format/2403.01944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier-basis Functions to Bridge Augmentation Gap: Rethinking Frequency  Augmentation in Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaish%2C+P">Puru Vaish</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shunxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Strisciuglio%2C+N">Nicola Strisciuglio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Computer vision models normally witness degraded performance when deployed in
real-world scenarios, due to unexpected changes in inputs that were not
accounted for during training. Data augmentation is commonly used to address
this issue, as it aims to increase data variety and reduce the distribution gap
between training and test data. However, common visual augmentations might not
guarantee extensive robustness of computer vision models. In this paper, we
propose Auxiliary Fourier-basis Augmentation (AFA), a complementary technique
targeting augmentation in the frequency domain and filling the augmentation gap
left by visual augmentations. We demonstrate the utility of augmentation via
Fourier-basis additive noise in a straightforward and efficient adversarial
setting. Our results show that AFA benefits the robustness of models against
common corruptions, OOD generalization, and consistency of performance of
models against increasing perturbations, with negligible deficit to the
standard performance of models. It can be seamlessly integrated with other
augmentation techniques to further boost performance.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01946" title="Abstract">arXiv:2403.01946</a> [<a href="/pdf/2403.01946" title="Download PDF">pdf</a>, <a href="/format/2403.01946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Model of Symmetry Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allingham%2C+J+U">James Urquhart Allingham</a>, 
<a href="/search/cs?searchtype=author&query=Mlodozeniec%2C+B+K">Bruno Kacper Mlodozeniec</a>, 
<a href="/search/cs?searchtype=author&query=Padhy%2C+S">Shreyas Padhy</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Krueger%2C+D">David Krueger</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Nalisnick%2C+E">Eric Nalisnick</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Correctly capturing the symmetry transformations of data can lead to
efficient models with strong generalization capabilities, though methods
incorporating symmetries often require prior knowledge. While recent
advancements have been made in learning those symmetries directly from the
dataset, most of this work has focused on the discriminative setting. In this
paper, we construct a generative model that explicitly aims to capture
symmetries in the data, resulting in a model that learns which symmetries are
present in an interpretable way. We provide a simple algorithm for efficiently
learning our generative model and demonstrate its ability to capture symmetries
under affine and color transformations. Combining our symmetry model with
existing generative models results in higher marginal test-log-likelihoods and
robustness to data sparsification.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01952" title="Abstract">arXiv:2403.01952</a> [<a href="/pdf/2403.01952" title="Download PDF">pdf</a>, <a href="/ps/2403.01952" title="Download PostScript">ps</a>, <a href="/format/2403.01952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Challenges of Transforming UVL to IVML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P">Prankur Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Feichtinger%2C+K">Kevin Feichtinger</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+K">Klaus Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Eichelberger%2C+H">Holger Eichelberger</a>, 
<a href="/search/cs?searchtype=author&query=Rabiser%2C+R">Rick Rabiser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 6th International Workshop on Languages for Modelling Variability (MODEVAR'24) (arXiv:cs/<a href="/abs/2402.15511">2402.15511</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software product line techniques encourage the reuse and adaptation of
software components for creating customized products or software systems. These
different product variants have commonalities and differences, which are
managed by variability modeling. Over the past three decades, both academia and
industry have developed numerous variability modeling methods, each with its
own advantages and disadvantages. Many of these methods have demonstrated their
utility within specific domains or applications. However, comprehending the
capabilities and differences among these approaches to pinpoint the most
suitable one for a particular use case remains challenging. Thus, new modeling
techniques and tailored tools for handling variability are frequently created.
Transitioning between variability models through transformations from different
approaches can help in understanding the benefits and drawbacks of different
modeling approaches. However, implementing such transformations presents
challenges, such as semantic preservation and avoiding information loss.
TRAVART is a tool that helps with transitioning between different approaches by
enabling the transformation of variability models into other variability models
of different types. This paper discusses the challenges for such
transformations between UVL and IVML. It also presents a one-way transformation
from the UVL to IVML with as little information loss as possible.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01954" title="Abstract">arXiv:2403.01954</a> [<a href="/pdf/2403.01954" title="Download PDF">pdf</a>, <a href="/format/2403.01954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DECIDER: A Rule-Controllable Decoding Strategy for Language Generation  by Imitating Dual-System Cognitive Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qunxi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+K">Kun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Piji Li</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TKDE, 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Lexicon-based constrained decoding approaches aim to control the meaning or
style of the generated text through certain target concepts. Existing
approaches over-focus the targets themselves, leading to a lack of high-level
reasoning about how to achieve them. However, human usually tackles tasks by
following certain rules that not only focuses on the targets but also on
semantically relevant concepts that induce the occurrence of targets. In this
work, we present DECIDER, a rule-controllable decoding strategy for constrained
language generation inspired by dual-system cognitive theory. Specifically, in
DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner
that takes high-level rules as input. Then, the DECIDER allows rule signals to
flow into the PLM at each decoding step. Extensive experimental results
demonstrate that DECIDER can effectively follow given rules to guide generation
direction toward the targets in a more human-like manner.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01956" title="Abstract">arXiv:2403.01956</a> [<a href="/pdf/2403.01956" title="Download PDF">pdf</a>, <a href="/ps/2403.01956" title="Download PostScript">ps</a>, <a href="/format/2403.01956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Active-Passive RIS Transmitter Enabled Energy-Efficient  Multi-User Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+A">Ao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Li Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guangyu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A novel hybrid active-passive reconfigurable intelligent surface (RIS)
transmitter enabled downlink multi-user communication system is investigated.
Specifically, RISs are exploited to serve as transmitter antennas, where each
element can flexibly switch between active and passive modes to deliver
information to multiple users. The system energy efficiency (EE) maximization
problem is formulated by jointly optimizing the RIS element scheduling and
beamforming coefficients, as well as the power allocation coefficients, subject
to the user's individual rate requirement and the maximum RIS amplification
power constraint. Using the Dinkelbach relaxation, the original mixed-integer
nonlinear programming problem is transformed into a nonfractional optimization
problem with a two-layer structure, which is solved by the alternating
optimization approach. In particular, an exhaustive search method is proposed
to determine the optimal operating mode for each RIS element. Then, the RIS
beamforming and power allocation coefficients are properly designed in an
alternating manner. To overcome the potentially high complexity caused by
exhaustive searching, we further develop a joint RIS element mode and
beamforming optimization scheme by exploiting the Big-M formulation technique.
Numerical results validate that: 1) The proposed hybrid RIS scheme yields
higher EE than the baseline multi-antenna schemes employing fully
active/passive RIS or conventional radio frequency chains; 2) Both proposed
algorithms are effective in improving the system performance, especially the
latter can achieve precise design of RIS elements with low complexity; and 3)
For a fixed-size hybrid RIS, maximum EE can be reaped by setting only a
minority of elements to operate in the active mode.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01960" title="Abstract">arXiv:2403.01960</a> [<a href="/pdf/2403.01960" title="Download PDF">pdf</a>, <a href="/format/2403.01960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust audio deepfake detection system via multi-view feature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haochen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">With the advancement of generative modeling techniques, synthetic human
speech becomes increasingly indistinguishable from real, and tricky challenges
are elicited for the audio deepfake detection (ADD) system. In this paper, we
exploit audio features to improve the generalizability of ADD systems.
Investigation of the ADD task performance is conducted over a broad range of
audio features, including various handcrafted features and learning-based
features. Experiments show that learning-based audio features pretrained on a
large amount of data generalize better than hand-crafted features on
out-of-domain scenarios. Subsequently, we further improve the generalizability
of the ADD system using proposed multi-feature approaches to incorporate
complimentary information from features of different views. The model trained
on ASV2019 data achieves an equal error rate of 24.27\% on the In-the-Wild
dataset.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01962" title="Abstract">arXiv:2403.01962</a> [<a href="/pdf/2403.01962" title="Download PDF">pdf</a>, <a href="/format/2403.01962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Model-Based Approach on Learning Agile Motor Skills without  Reinforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haojie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tingguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Jiapeng Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lei Han</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Learning-based methods have improved locomotion skills of quadruped robots
through deep reinforcement learning. However, the sim-to-real gap and low
sample efficiency still limit the skill transfer. To address this issue, we
propose an efficient model-based learning framework that combines a world model
with a policy network. We train a differentiable world model to predict future
states and use it to directly supervise a Variational Autoencoder (VAE)-based
policy network to imitate real animal behaviors. This significantly reduces the
need for real interaction data and allows for rapid policy updates. We also
develop a high-level network to track diverse commands and trajectories. Our
simulated results show a tenfold sample efficiency increase compared to
reinforcement learning methods such as PPO. In real-world testing, our policy
achieves proficient command-following performance with only a two-minute data
collection period and generalizes well to new speeds and paths.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01965" title="Abstract">arXiv:2403.01965</a> [<a href="/pdf/2403.01965" title="Download PDF">pdf</a>, <a href="/ps/2403.01965" title="Download PostScript">ps</a>, <a href="/format/2403.01965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Deterministic Algorithms for Constant-Depth Factors of  Constant-Depth Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Mrinal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+V">Varun Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Saptharishi%2C+R">Ramprasad Saptharishi</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+B+L">Ben Lee Volk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We design a deterministic subexponential time algorithm that takes as input a
multivariate polynomial $f$ computed by a constant-depth circuit over rational
numbers, and outputs a list $L$ of circuits (of unbounded depth and possibly
with division gates) that contains all irreducible factors of $f$ computable by
constant-depth circuits. This list $L$ might also include circuits that are
spurious: they either do not correspond to factors of $f$ or are not even
well-defined, e.g. the input to a division gate is a sub-circuit that computes
the identically zero polynomial.
<br />The key technical ingredient of our algorithm is a notion of the
pseudo-resultant of $f$ and a factor $g$, which serves as a proxy for the
resultant of $g$ and $f/g$, with the advantage that the circuit complexity of
the pseudo-resultant is comparable to that of the circuit complexity of $f$ and
$g$. This notion, which might be of independent interest, together with the
recent results of Limaye, Srinivasan and Tavenas, helps us derandomize one key
step of multivariate polynomial factorization algorithms - that of
deterministically finding a good starting point for Newton Iteration for the
case when the input polynomial as well as the irreducible factor of interest
have small constant-depth circuits.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01966" title="Abstract">arXiv:2403.01966</a> [<a href="/pdf/2403.01966" title="Download PDF">pdf</a>, <a href="/format/2403.01966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Information Maximization with Distance-Aware Contrastive  Learning for Source-Free Cross-Domain Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huali Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+S">Shuaifeng Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shaojing Fu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongxiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TIP, 16 pages, 11 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing Cross-Domain Few-Shot Learning (CDFSL) methods require access to
source domain data to train a model in the pre-training phase. However, due to
increasing concerns about data privacy and the desire to reduce data
transmission and training costs, it is necessary to develop a CDFSL solution
without accessing source data. For this reason, this paper explores a
Source-Free CDFSL (SF-CDFSL) problem, in which CDFSL is addressed through the
use of existing pretrained models instead of training a model with source data,
avoiding accessing source data. This paper proposes an Enhanced Information
Maximization with Distance-Aware Contrastive Learning (IM-DCL) method to
address these challenges. Firstly, we introduce the transductive mechanism for
learning the query set. Secondly, information maximization (IM) is explored to
map target samples into both individual certainty and global diversity
predictions, helping the source model better fit the target data distribution.
However, IM fails to learn the decision boundary of the target task. This
motivates us to introduce a novel approach called Distance-Aware Contrastive
Learning (DCL), in which we consider the entire feature set as both positive
and negative sets, akin to Schrodinger's concept of a dual state. Instead of a
rigid separation between positive and negative sets, we employ a weighted
distance calculation among features to establish a soft classification of the
positive and negative sets for the entire feature set. Furthermore, we address
issues related to IM by incorporating contrastive constraints between object
features and their corresponding positive and negative sets. Evaluations of the
4 datasets in the BSCD-FSL benchmark indicate that the proposed IM-DCL, without
accessing the source domain, demonstrates superiority over existing methods,
especially in the distant domain task.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01968" title="Abstract">arXiv:2403.01968</a> [<a href="/pdf/2403.01968" title="Download PDF">pdf</a>, <a href="/format/2403.01968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Motion Handling and Interactive Prompting for Video Camouflaged  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Gepeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Keren Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qijun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camouflage poses challenges in distinguishing a static target, whereas any
movement of the target can break this disguise. Existing video camouflaged
object detection (VCOD) approaches take noisy motion estimation as input or
model motion implicitly, restricting detection performance in complex dynamic
scenes. In this paper, we propose a novel Explicit Motion handling and
Interactive Prompting framework for VCOD, dubbed EMIP, which handles motion
cues explicitly using a frozen pre-trained optical flow fundamental model. EMIP
is characterized by a two-stream architecture for simultaneously conducting
camouflaged segmentation and optical flow estimation. Interactions across the
dual streams are realized in an interactive prompting way that is inspired by
emerging visual prompt learning. Two learnable modules, i.e. the camouflaged
feeder and motion collector, are designed to incorporate segmentation-to-motion
and motion-to-segmentation prompts, respectively, and enhance outputs of the
both streams. The prompt fed to the motion stream is learned by supervising
optical flow in a self-supervised manner. Furthermore, we show that long-term
historical information can also be incorporated as a prompt into EMIP and
achieve more robust results with temporal consistency. Experimental results
demonstrate that our EMIP achieves new state-of-the-art records on popular VCOD
benchmarks. The code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01969" title="Abstract">arXiv:2403.01969</a> [<a href="/pdf/2403.01969" title="Download PDF">pdf</a>, <a href="/format/2403.01969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AS-ES Learning: Towards Efficient CoT Learning in Small Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+N">Nuwa Xi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Chain-of-Thought (CoT) serves as a critical emerging ability in LLMs,
especially when it comes to logical reasoning. Attempts have been made to
induce such ability in small models as well by distilling from the data with
CoT generated by Large Language Models (LLMs). However, existing methods often
simply generate and incorporate more data from LLMs and fail to note the
importance of efficiently utilizing existing CoT data. We here propose a new
training paradigm AS-ES (Abstractive Segments - Extractive Segments) learning,
which exploits the inherent information in CoT for iterative generation.
Experiments show that our methods surpass the direct seq2seq training on
CoT-extensive tasks like MWP and PET summarization, without data augmentation
or altering the model itself. Furthermore, we explore the reason behind the
inefficiency of small models in learning CoT and provide an explanation of why
AS-ES learning works, giving insights into the underlying mechanism of CoT.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01971" title="Abstract">arXiv:2403.01971</a> [<a href="/pdf/2403.01971" title="Download PDF">pdf</a>, <a href="/format/2403.01971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContrastRepair: Enhancing Conversation-Based Automated Program Repair  via Contrastive Test Case Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+J">Jiaolong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingfei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shangqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoning Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automated Program Repair (APR) aims to automatically generate patches for
rectifying software bugs. Recent strides in Large Language Models (LLM), such
as ChatGPT, have yielded encouraging outcomes in APR, especially within the
conversation-driven APR framework. Nevertheless, the efficacy of
conversation-driven APR is contingent on the quality of the feedback
information. In this paper, we propose ContrastRepair, a novel
conversation-based APR approach that augments conversation-driven APR by
providing LLMs with contrastive test pairs. A test pair consists of a failing
test and a passing test, which offer contrastive feedback to the LLM. Our key
insight is to minimize the difference between the generated passing test and
the given failing test, which can better isolate the root causes of bugs. By
providing informative and specific feedback, ContrastRepair enables the LLM to
produce effective bug fixes. The implementation of ContrastRepair is based on
the state-of-the-art LLM, ChatGPT, and it iteratively interacts with ChatGPT
until plausible patches are generated. We evaluate ContrastRepair on multiple
benchmark datasets, including Defects4j, QuixBugs, and HumanEval-Java. The
results demonstrate that ContrastRepair significantly outperforms existing
methods, achieving a new state-of-the-art in program repair. For instance,
among Defects4j 1.2 and 2.0, ContrastRepair correctly repairs 143 out of all
337 bug cases, while the best-performing baseline fixes 124 bugs.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01972" title="Abstract">arXiv:2403.01972</a> [<a href="/pdf/2403.01972" title="Download PDF">pdf</a>, <a href="/format/2403.01972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-perspective Improvement of Knowledge Graph Completion with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Derong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenxi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge graph completion (KGC) is a widely used method to tackle
incompleteness in knowledge graphs (KGs) by making predictions for missing
links. Description-based KGC leverages pre-trained language models to learn
entity and relation representations with their names or descriptions, which
shows promising results. However, the performance of description-based KGC is
still limited by the quality of text and the incomplete structure, as it lacks
sufficient entity descriptions and relies solely on relation names, leading to
sub-optimal results. To address this issue, we propose MPIKGC, a general
framework to compensate for the deficiency of contextualized knowledge and
improve KGC by querying large language models (LLMs) from various perspectives,
which involves leveraging the reasoning, explanation, and summarization
capabilities of LLMs to expand entity descriptions, understand relations, and
extract structures, respectively. We conducted extensive evaluation of the
effectiveness and improvement of our framework based on four description-based
KGC models and four datasets, for both link prediction and triplet
classification tasks.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01975" title="Abstract">arXiv:2403.01975</a> [<a href="/pdf/2403.01975" title="Download PDF">pdf</a>, <a href="/format/2403.01975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCEL (Object-Centric Event Log) 2.0 Specification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berti%2C+A">Alessandro Berti</a>, 
<a href="/search/cs?searchtype=author&query=Koren%2C+I">Istvan Koren</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+J+N">Jan Niklas Adams</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gyunam Park</a>, 
<a href="/search/cs?searchtype=author&query=Knopp%2C+B">Benedikt Knopp</a>, 
<a href="/search/cs?searchtype=author&query=Graves%2C+N">Nina Graves</a>, 
<a href="/search/cs?searchtype=author&query=Rafiei%2C+M">Majid Rafiei</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%9F%2C+L">Lukas Li&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Unterberg%2C+L+T+G">Leah Tacke Genannt Unterberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yisong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Schwanen%2C+C">Christopher Schwanen</a>, 
<a href="/search/cs?searchtype=author&query=Pegoraro%2C+M">Marco Pegoraro</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W+M+P">Wil M.P. van der Aalst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Object-Centric Event Logs (OCELs) form the basis for Object-Centric Process
Mining (OCPM). OCEL 1.0 was first released in 2020 and triggered the
development of a range of OCPM techniques. OCEL 2.0 forms the new, more
expressive standard, allowing for more extensive process analyses while
remaining in an easily exchangeable format. In contrast to the first OCEL
standard, it can depict changes in objects, provide information on object
relationships, and qualify these relationships to other objects or specific
events. Compared to XES, it is more expressive, less complicated, and better
readable. OCEL 2.0 offers three exchange formats: a relational database
(SQLite), XML, and JSON format. This OCEL 2.0 specification document provides
an introduction to the standard, its metamodel, and its exchange formats, aimed
at practitioners and researchers alike.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01976" title="Abstract">arXiv:2403.01976</a> [<a href="/pdf/2403.01976" title="Download PDF">pdf</a>, <a href="/format/2403.01976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciAssess: Benchmarking LLM Proficiency in Scientific Literature  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengxing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaochen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Junhan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongge Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mujie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+G">Guolin Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent breakthroughs in Large Language Models (LLMs) have revolutionized
natural language understanding and generation, igniting a surge of interest in
leveraging these technologies for the nuanced field of scientific literature
analysis. Existing benchmarks, however, inadequately evaluate the proficiency
of LLMs in the scientific domain, especially in scenarios involving complex
comprehension and multimodal data. In response, we introduced SciAssess, a
benchmark tailored for the in-depth analysis of scientific literature, crafted
to provide a thorough assessment of LLMs' efficacy. SciAssess focuses on
evaluating LLMs' abilities in memorization, comprehension, and analysis within
scientific contexts. It includes representative tasks from diverse scientific
fields, such as general chemistry, organic materials, and alloy materials. And
rigorous quality control measures ensure its reliability in terms of
correctness, anonymization, and copyright compliance. SciAssess evaluates
leading LLMs, including GPT-4, GPT-3.5-turbo, and Gemini, identifying their
strengths and areas for improvement and supporting the ongoing development of
LLM applications in scientific literature analysis. SciAssess and its resources
are made available at https://sci-assess.github.io, offering a valuable tool
for advancing LLM capabilities in scientific literature analysis.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01977" title="Abstract">arXiv:2403.01977</a> [<a href="/pdf/2403.01977" title="Download PDF">pdf</a>, <a href="/format/2403.01977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation  under Visual Corruptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piriyajitakonkij%2C+M">Maytus Piriyajitakonkij</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingfei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wei Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. Code will be available soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robot navigation under visual corruption presents a formidable challenge. To
address this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav,
for point-goal navigation under visual corruptions. Our "plug-and-play" method
incorporates a top-down decoder to a pre-trained navigation model. Firstly, the
pre-trained navigation model gets a corrupted image and extracts features.
Secondly, the top-down decoder produces the reconstruction given the high-level
features extracted by the pre-trained model. Then, it feeds the reconstruction
of a corrupted image back to the pre-trained model. Finally, the pre-trained
model does forward pass again to output action. Despite being trained solely on
clean images, the top-down decoder can reconstruct cleaner images from
corrupted ones without the need for gradient-based adaptation. The pre-trained
navigation model with our top-down decoder significantly enhances navigation
performance across almost all visual corruptions in our benchmarks. Our method
improves the success rate of point-goal navigation from the state-of-the-art
result of 46% to 94% on the most severe corruption. This suggests its potential
for broader application in robotic visual navigation.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01978" title="Abstract">arXiv:2403.01978</a> [<a href="/pdf/2403.01978" title="Download PDF">pdf</a>, <a href="/format/2403.01978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Anchor-based LiDAR 3D Object Detection via Point Assisted  Sample Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shitao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D object detection based on LiDAR point cloud and prior anchor boxes is a
critical technology for autonomous driving environment perception and
understanding. Nevertheless, an overlooked practical issue in existing methods
is the ambiguity in training sample allocation based on box Intersection over
Union (IoU_box). This problem impedes further enhancements in the performance
of anchor-based LiDAR 3D object detectors. To tackle this challenge, this paper
introduces a new training sample selection method that utilizes point cloud
distribution for anchor sample quality measurement, named Point Assisted Sample
Selection (PASS). This method has undergone rigorous evaluation on two widely
utilized datasets. Experimental results demonstrate that the application of
PASS elevates the average precision of anchor-based LiDAR 3D object detectors
to a novel state-of-the-art, thereby proving the effectiveness of the proposed
approach. The codes will be made available at
https://github.com/XJTU-Haolin/Point_Assisted_Sample_Selection.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01981" title="Abstract">arXiv:2403.01981</a> [<a href="/pdf/2403.01981" title="Download PDF">pdf</a>, <a href="/format/2403.01981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Explainability of Neural Rankers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandian%2C+S">Saran Pandian</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+D">Debasis Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=MacAvaney%2C+S">Sean MacAvaney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Information retrieval models have witnessed a paradigm shift from
unsupervised statistical approaches to feature-based supervised approaches to
completely data-driven ones that make use of the pre-training of large language
models. While the increasing complexity of the search models have been able to
demonstrate improvements in effectiveness (measured in terms of relevance of
top-retrieved results), a question worthy of a thorough inspection is - "how
explainable are these models?", which is what this paper aims to evaluate. In
particular, we propose a common evaluation platform to systematically evaluate
the explainability of any ranking model (the explanation algorithm being
identical for all the models that are to be evaluated). In our proposed
framework, each model, in addition to returning a ranked list of documents,
also requires to return a list of explanation units or rationales for each
document. This meta-information from each document is then used to measure how
locally consistent these rationales are as an intrinsic measure of
interpretability - one that does not require manual relevance assessments.
Additionally, as an extrinsic measure, we compute how relevant these rationales
are by leveraging sub-document level relevance assessments. Our findings show a
number of interesting observations, such as sentence-level rationales are more
consistent, an increase in complexity mostly leads to less consistent
explanations, and that interpretability measures offer a complementary
dimension of evaluation of IR systems because consistency is not
well-correlated with nDCG at top ranks.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01982" title="Abstract">arXiv:2403.01982</a> [<a href="/pdf/2403.01982" title="Download PDF">pdf</a>, <a href="/format/2403.01982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCEL 2.0 Resources -- www.ocel-standard.org
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koren%2C+I">Istvan Koren</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+N">Niklas Adams</a>, 
<a href="/search/cs?searchtype=author&query=Berti%2C+A">Alessandro Berti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Process mining has become a cornerstone of process analysis and improvement
over the last few years. With the widespread adoption of process mining tools
and libraries, the limitations of traditional process mining to deal with event
data with multiple case identifiers, i.e., object-centric event data, have
become apparent. As a response, the subfield of object-centric process mining
has formed, including a file format standardization attempt in the form of OCEL
1.0, unifying the insights of previous developments in capturing object-centric
event data. However, discussions among researchers and practitioners have shown
that the proposed OCEL 1.0 standard does not go far enough. OCEL 2.0 has been
proposed as an advanced refinement, including normative and explicit
object-to-object relationships, qualifiers for object-to-object and
event-to-object relationships, and evolving object attribute values. This
demonstration presents the OCEL 2.0 website available under the URL
https://www.ocel-standard.org as a one-stop shop for the detailed
specification, example event logs, and broad tool support to facilitate the
adoption of the format.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01983" title="Abstract">arXiv:2403.01983</a> [<a href="/pdf/2403.01983" title="Download PDF">pdf</a>, <a href="/ps/2403.01983" title="Download PostScript">ps</a>, <a href="/format/2403.01983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language and Speech Technology for Central Kurdish Varieties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+S">Sina Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Jaff%2C+D+Q">Daban Q. Jaff</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+M+I">Md Mahfuz Ibn Alam</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Kurdish, an Indo-European language spoken by over 30 million speakers, is
considered a dialect continuum and known for its diversity in language
varieties. Previous studies addressing language and speech technology for
Kurdish handle it in a monolithic way as a macro-language, resulting in
disparities for dialects and varieties for which there are few resources and
tools available. In this paper, we take a step towards developing resources for
language and speech technology for varieties of Central Kurdish, creating a
corpus by transcribing movies and TV series as an alternative to fieldwork.
Additionally, we report the performance of machine translation, automatic
speech recognition, and language identification as downstream tasks evaluated
on Central Kurdish varieties. Data and models are publicly available under an
open license at https://github.com/sinaahmadi/CORDI.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01985" title="Abstract">arXiv:2403.01985</a> [<a href="/pdf/2403.01985" title="Download PDF">pdf</a>, <a href="/format/2403.01985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers for Low-Resource Languages:Is F&#xe9;idir Linn!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of Machine Translation Summit XVIII: Research Track
  2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Transformer model is the state-of-the-art in Machine Translation.
However, in general, neural translation models often under perform on language
pairs with insufficient training data. As a consequence, relatively few
experiments have been carried out using this architecture on low-resource
language pairs. In this study, hyperparameter optimization of Transformer
models in translating the low-resource English-Irish language pair is
evaluated. We demonstrate that choosing appropriate parameters leads to
considerable performance improvements. Most importantly, the correct choice of
subword model is shown to be the biggest driver of translation performance.
SentencePiece models using both unigram and BPE approaches were appraised.
Variations on model architectures included modifying the number of layers,
testing various regularisation techniques and evaluating the optimal number of
heads for attention. A generic 55k DGT corpus and an in-domain 88k public admin
corpus were used for evaluation. A Transformer optimized model demonstrated a
BLEU score improvement of 7.8 points when compared with a baseline RNN model.
Improvements were observed across a range of metrics, including TER, indicating
a substantially reduced post editing effort for Transformer optimized models
with 16k BPE subword models. Bench-marked against Google Translate, our
translation engines demonstrated significant improvements. The question of
whether or not Transformers can be used effectively in a low-resource setting
of English-Irish translation has been addressed. Is f\'eidir linn - yes we can.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01988" title="Abstract">arXiv:2403.01988</a> [<a href="/pdf/2403.01988" title="Download PDF">pdf</a>, <a href="/format/2403.01988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FakeNewsGPT4: Advancing Multimodal Fake News Detection through  Knowledge-Augmented LVLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuannan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peipei Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekun Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiahao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lixiong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The massive generation of multimodal fake news exhibits substantial
distribution discrepancies, prompting the need for generalized detectors.
However, the insulated nature of training within specific domains restricts the
capability of classical detectors to obtain open-world facts. In this paper, we
propose FakeNewsGPT4, a novel framework that augments Large Vision-Language
Models (LVLMs) with forgery-specific knowledge for manipulation reasoning while
inheriting extensive world knowledge as complementary. Knowledge augmentation
in FakeNewsGPT4 involves acquiring two types of forgery-specific knowledge,
i.e., semantic correlation and artifact trace, and merging them into LVLMs.
Specifically, we design a multi-level cross-modal reasoning module that
establishes interactions across modalities for extracting semantic
correlations. Concurrently, a dual-branch fine-grained verification module is
presented to comprehend localized details to encode artifact traces. The
generated knowledge is translated into refined embeddings compatible with
LVLMs. We also incorporate candidate answer heuristics and soft prompts to
enhance input informativeness. Extensive experiments on the public benchmark
demonstrate that FakeNewsGPT4 achieves superior cross-domain performance
compared to previous methods. Code will be available.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01991" title="Abstract">arXiv:2403.01991</a> [<a href="/pdf/2403.01991" title="Download PDF">pdf</a>, <a href="/format/2403.01991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skater: A Novel Bi-modal Bi-copter Robot for Adaptive Locomotion in Air  and Diverse Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junxiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+N">Neng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this letter, we present a novel bi-modal bi-copter robot called Skater,
which is adaptable to air and various ground surfaces. Skater consists of a
bi-copter moving along its longitudinal direction with two passive wheels on
both sides. Using longitudinally arranged bi-copter as the unified actuation
system for both aerial and ground modes, this robot not only keeps concise and
lightweight mechanism, but also possesses exceptional terrain traversing
capability and strong steering capacity. Moreover, leveraging the vectored
thrust characteristic of bi-copters, Skater can actively generate the
centripetal force needed for steering, enabling it to achieve stable movement
even on slippery surfaces. Furthermore, we model the comprehensive dynamics of
Skater, analyze its differential flatness and introduce a controller using
nonlinear model predictive control for trajectory tracking. The outstanding
performance of the system is verified by extensive real-world experiments and
benchmark comparisons.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01993" title="Abstract">arXiv:2403.01993</a> [<a href="/pdf/2403.01993" title="Download PDF">pdf</a>, <a href="/format/2403.01993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Learning for Time-Resolved Angiographic Contrast Agent  Concentration Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maul%2C+N">Noah Maul</a>, 
<a href="/search/cs?searchtype=author&query=Birkhold%2C+A">Annette Birkhold</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+F">Fabian Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+M">Mareike Thies</a>, 
<a href="/search/cs?searchtype=author&query=Rohleder%2C+M">Maximilian Rohleder</a>, 
<a href="/search/cs?searchtype=author&query=Berg%2C+P">Philipp Berg</a>, 
<a href="/search/cs?searchtype=author&query=Kowarschik%2C+M">Markus Kowarschik</a>, 
<a href="/search/cs?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Three-dimensional Digital Subtraction Angiography (3D-DSA) is a
well-established X-ray-based technique for visualizing vascular anatomy.
Recently, four-dimensional DSA (4D-DSA) reconstruction algorithms have been
developed to enable the visualization of volumetric contrast flow dynamics
through time-series of volumes. . This reconstruction problem is ill-posed
mainly due to vessel overlap in the projection direction and geometric vessel
foreshortening, which leads to information loss in the recorded projection
images. However, knowledge about the underlying fluid dynamics can be leveraged
to constrain the solution space. In our work, we implicitly include this
information in a neural network-based model that is trained on a dataset of
image-based blood flow simulations. The model predicts the spatially averaged
contrast agent concentration for each centerline point of the vasculature over
time, lowering the overall computational demand. The trained network enables
the reconstruction of relative contrast agent concentrations with a mean
absolute error of 0.02 $\pm$ 0.02 and a mean absolute percentage error of 5.31
% $\pm$ 9.25 %. Moreover, the network is robust to varying degrees of vessel
overlap and vessel foreshortening. Our approach demonstrates the potential of
the integration of machine learning and blood flow simulations in time-resolved
angiographic flow reconstruction.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01994" title="Abstract">arXiv:2403.01994</a> [<a href="/pdf/2403.01994" title="Download PDF">pdf</a>, <a href="/format/2403.01994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vanilla Transformers are Transfer Capability Teachers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, Mixture of Experts (MoE) Transformers have garnered increasing
attention due to their advantages in model capacity and computational
efficiency. However, studies have indicated that MoE Transformers underperform
vanilla Transformers in many downstream tasks, significantly diminishing the
practical value of MoE models. To explain this issue, we propose that the
pre-training performance and transfer capability of a model are joint
determinants of its downstream task performance. MoE models, in comparison to
vanilla models, have poorer transfer capability, leading to their subpar
performance in downstream tasks. To address this issue, we introduce the
concept of transfer capability distillation, positing that although vanilla
models have weaker performance, they are effective teachers of transfer
capability. The MoE models guided by vanilla models can achieve both strong
pre-training performance and transfer capability, ultimately enhancing their
performance in downstream tasks. We design a specific distillation method and
conduct experiments on the BERT architecture. Experimental results show a
significant improvement in downstream performance of MoE models, and many
further evidences also strongly support the concept of transfer capability
distillation. Finally, we attempt to interpret transfer capability distillation
and provide some insights from the perspective of model feature.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01999" title="Abstract">arXiv:2403.01999</a> [<a href="/pdf/2403.01999" title="Download PDF">pdf</a>, <a href="/format/2403.01999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Oriented Retrieval Tuner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Si Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jie Bao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawei Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Dense Retrieval (DR) is now considered as a promising tool to enhance the
memorization capacity of Large Language Models (LLM) such as GPT3 and GPT-4 by
incorporating external memories. However, due to the paradigm discrepancy
between text generation of LLM and DR, it is still an open challenge to
integrate the retrieval and generation tasks in a shared LLM. In this paper, we
propose an efficient LLM-Oriented Retrieval Tuner, namely LMORT, which
decouples DR capacity from base LLM and non-invasively coordinates the
optimally aligned and uniform layers of the LLM towards a unified DR space,
achieving an efficient and effective DR without tuning the LLM itself. The
extensive experiments on six BEIR datasets show that our approach could achieve
competitive zero-shot retrieval performance compared to a range of strong DR
models while maintaining the generation ability of LLM.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02002" title="Abstract">arXiv:2403.02002</a> [<a href="/pdf/2403.02002" title="Download PDF">pdf</a>, <a href="/format/2403.02002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Quantitative Emotion Editing for Speech Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inoue%2C+S">Sho Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is submitted to IEEE Signal Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">It remains a significant challenge how to quantitatively control the
expressiveness of speech emotion in speech generation. In this work, we present
a novel approach for manipulating the rendering of emotions for speech
generation. We propose a hierarchical emotion distribution extractor, i.e.
Hierarchical ED, that quantifies the intensity of emotions at different levels
of granularity. Support vector machines (SVMs) are employed to rank emotion
intensity, resulting in a hierarchical emotional embedding. Hierarchical ED is
subsequently integrated into the FastSpeech2 framework, guiding the model to
learn emotion intensity at phoneme, word, and utterance levels. During
synthesis, users can manually edit the emotional intensity of the generated
voices. Both objective and subjective evaluations demonstrate the effectiveness
of the proposed network in terms of fine-grained quantitative emotion editing.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02004" title="Abstract">arXiv:2403.02004</a> [<a href="/pdf/2403.02004" title="Download PDF">pdf</a>, <a href="/ps/2403.02004" title="Download PostScript">ps</a>, <a href="/format/2403.02004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error bounds for particle gradient descent, and extensions of the  log-Sobolev and Talagrand inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caprio%2C+R">Rocco Caprio</a>, 
<a href="/search/cs?searchtype=author&query=Kuntz%2C+J">Juan Kuntz</a>, 
<a href="/search/cs?searchtype=author&query=Power%2C+S">Samuel Power</a>, 
<a href="/search/cs?searchtype=author&query=Johansen%2C+A+M">Adam M. Johansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA); Optimization and Control (math.OC); Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">We prove non-asymptotic error bounds for particle gradient descent
(PGD)~(Kuntz et al., 2023), a recently introduced algorithm for maximum
likelihood estimation of large latent variable models obtained by discretizing
a gradient flow of the free energy. We begin by showing that, for models
satisfying a condition generalizing both the log-Sobolev and the
Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively), the flow
converges exponentially fast to the set of minimizers of the free energy. We
achieve this by extending a result well-known in the optimal transport
literature (that the LSI implies the Talagrand inequality) and its counterpart
in the optimization literature (that the P{\L}I implies the so-called quadratic
growth condition), and applying it to our new setting. We also generalize the
Bakry--\'Emery Theorem and show that the LSI/P{\L}I generalization holds for
models with strongly concave log-likelihoods. For such models, we further
control PGD's discretization error, obtaining non-asymptotic error bounds.
While we are motivated by the study of PGD, we believe that the inequalities
and results we extend may be of independent interest.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02008" title="Abstract">arXiv:2403.02008</a> [<a href="/pdf/2403.02008" title="Download PDF">pdf</a>, <a href="/ps/2403.02008" title="Download PostScript">ps</a>, <a href="/format/2403.02008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster MEM-finding in $O (r + \bar{r} + g)$ space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gagie%2C+T">Travis Gagie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Suppose we are given a text $T [1..n]$, a straight-line program with $g$
rules for $T$ and an assignment of tags to the characters in $T$ such that the
Burrows-Wheeler Transform of $T$ has $r$ runs, the Burrows-Wheeler Transform of
the reverse of $T$ has $\bar{r}$ runs and the tag array -- the list of tags in
the lexicographic order of the suffixes starting at the characters the tags are
assigned to -- has $t$ runs. If the alphabet size is at most polylogarithmic in
$n$ then there is an $O (r + \bar{r} + g + t)$-space index for $T$ such that
when we are given a pattern $P [1..m]$ we can compute the maximal exact matches
(MEMs) of $P$ with respect to $T$ in $O (m)$ time plus $O (\log n)$ time per
MEM and then list the distinct tags assigned to the first characters of
occurrences of that MEM in constant time per tag listed, all correctly with
high probability.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02009" title="Abstract">arXiv:2403.02009</a> [<a href="/pdf/2403.02009" title="Download PDF">pdf</a>, <a href="/format/2403.02009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic Aware Probing: From Sentence Length Prediction to Idiom  Identification how reliant are Neural Language Models on Topic?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nedumpozhimana%2C+V">Vasudevan Nedumpozhimana</a>, 
<a href="/search/cs?searchtype=author&query=Kelleher%2C+J+D">John D. Kelleher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Transformer-based Neural Language Models achieve state-of-the-art performance
on various natural language processing tasks. However, an open question is the
extent to which these models rely on word-order/syntactic or word
co-occurrence/topic-based information when processing natural language. This
work contributes to this debate by addressing the question of whether these
models primarily use topic as a signal, by exploring the relationship between
Transformer-based models' (BERT and RoBERTa's) performance on a range of
probing tasks in English, from simple lexical tasks such as sentence length
prediction to complex semantic tasks such as idiom token identification, and
the sensitivity of these tasks to the topic information. To this end, we
propose a novel probing method which we call topic-aware probing. Our initial
results indicate that Transformer-based models encode both topic and non-topic
information in their intermediate layers, but also that the facility of these
models to distinguish idiomatic usage is primarily based on their ability to
identify and encode topic. Furthermore, our analysis of these models'
performance on other standard probing tasks suggests that tasks that are
relatively insensitive to the topic information are also tasks that are
relatively difficult for these models.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02010" title="Abstract">arXiv:2403.02010</a> [<a href="/pdf/2403.02010" title="Download PDF">pdf</a>, <a href="/format/2403.02010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA-SOT: Speaker-Aware Serialized Output Training for Multi-Talker ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiyun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Linhao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zejun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multi-talker automatic speech recognition plays a crucial role in scenarios
involving multi-party interactions, such as meetings and conversations. Due to
its inherent complexity, this task has been receiving increasing attention.
Notably, the serialized output training (SOT) stands out among various
approaches because of its simplistic architecture and exceptional performance.
However, the frequent speaker changes in token-level SOT (t-SOT) present
challenges for the autoregressive decoder in effectively utilizing context to
predict output sequences. To address this issue, we introduce a masked t-SOT
label, which serves as the cornerstone of an auxiliary training loss.
Additionally, we utilize a speaker similarity matrix to refine the
self-attention mechanism of the decoder. This strategic adjustment enhances
contextual relationships within the same speaker's tokens while minimizing
interactions between different speakers' tokens. We denote our method as
speaker-aware SOT (SA-SOT). Experiments on the Librispeech datasets demonstrate
that our SA-SOT obtains a relative cpWER reduction ranging from 12.75% to
22.03% on the multi-talker test sets. Furthermore, with more extensive
training, our method achieves an impressive cpWER of 3.41%, establishing a new
state-of-the-art result on the LibrispeechMix dataset.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02012" title="Abstract">arXiv:2403.02012</a> [<a href="/pdf/2403.02012" title="Download PDF">pdf</a>, <a href="/format/2403.02012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OTFS vs OFDM: Which is Superior in Multiuser LEO Satellite  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tantao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jinhong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Orthogonal time frequency space (OTFS) modulation, a delay-Doppler (DD)
domain communication scheme exhibiting strong robustness against the Doppler
shifts, has the potentials to be employed in LEO satellite communications.
However, the performance comparison with the orthogonal frequency division
multiplexing (OFDM) modulation and the resource allocation scheme for multiuser
OTFS-based LEO satellite communication system have rarely been investigated. In
this paper, we conduct a performance comparison under various channel
conditions between the OTFS and OFDM modulations, encompassing evaluations of
sum-rate and bit error ratio (BER). Additionally, we investigate the joint
optimal allocation of power and delay-Doppler resource blocks aiming at
maximizing sum-rate for multiuser downlink OTFS-based LEO satellite
communication systems. Unlike the conventional modulations relaying on complex
input-output relations within the Time-Frequency (TF) domain, the OTFS
modulation exploits both time and frequency diversities, i.e., delay and
Doppler shifts remain constant during a OTFS frame, which facilitates a DD
domain input-output simple relation for our investigation. We transform the
resulting non-convex and combinatorial optimization problem into an equivalent
difference of convex problem by decoupling the conditional constraints, and
solve the transformed problem via penalty convex-concave procedure algorithm.
Simulation results demonstrate that the OTFS modulation is robust to carrier
frequency offsets (CFO) caused by high-mobility of LEO satellites, and has
superior performance to the OFDM modulation. Moreover, numerical results
indicate that our proposed resource allocation scheme has higher sum-rate than
existed schemes for the OTFS modulation, such as delay divided multiple access
and Doppler divided multiple access, especially in the high signal-to-noise
ratio (SNR) regime.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02014" title="Abstract">arXiv:2403.02014</a> [<a href="/pdf/2403.02014" title="Download PDF">pdf</a>, <a href="/format/2403.02014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Hidden Links Between Unseen Security Entities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alfasi%2C+D">Daniel Alfasi</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+T">Tal Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+A+B">Anat Bremler Barr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The proliferation of software vulnerabilities poses a significant challenge
for security databases and analysts tasked with their timely identification,
classification, and remediation. With the National Vulnerability Database (NVD)
reporting an ever-increasing number of vulnerabilities, the traditional manual
analysis becomes untenably time-consuming and prone to errors. This paper
introduces VulnScopper, an innovative approach that utilizes multi-modal
representation learning, combining Knowledge Graphs (KG) and Natural Language
Processing (NLP), to automate and enhance the analysis of software
vulnerabilities. Leveraging ULTRA, a knowledge graph foundation model, combined
with a Large Language Model (LLM), VulnScopper effectively handles unseen
entities, overcoming the limitations of previous KG approaches. We evaluate
VulnScopper on two major security datasets, the NVD and the Red Hat CVE
database. Our method significantly improves the link prediction accuracy
between Common Vulnerabilities and Exposures (CVEs), Common Weakness
Enumeration (CWEs), and Common Platform Enumerations (CPEs). Our results show
that VulnScopper outperforms existing methods, achieving up to 78% Hits@10
accuracy in linking CVEs to CPEs and CWEs and presenting an 11.7% improvement
over large language models in predicting CWE labels based on the Red Hat
database. Based on the NVD, only 6.37% of the linked CPEs are being published
during the first 30 days; many of them are related to critical and high-risk
vulnerabilities which, according to multiple compliance frameworks (such as
CISA and PCI), should be remediated within 15-30 days. Our model can uncover
new products linked to vulnerabilities, reducing remediation time and improving
vulnerability management. We analyzed several CVEs from 2023 to showcase this
ability.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02018" title="Abstract">arXiv:2403.02018</a> [<a href="/pdf/2403.02018" title="Download PDF">pdf</a>, <a href="/format/2403.02018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Domain Policy Transfer with Effect Cycle-Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Ruiqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+T">Tianhong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Celiktutan%2C+O">Oya Celiktutan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to International Conference on Robotics and Automation (ICRA), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training a robotic policy from scratch using deep reinforcement learning
methods can be prohibitively expensive due to sample inefficiency. To address
this challenge, transferring policies trained in the source domain to the
target domain becomes an attractive paradigm. Previous research has typically
focused on domains with similar state and action spaces but differing in other
aspects. In this paper, our primary focus lies in domains with different state
and action spaces, which has broader practical implications, i.e. transfer the
policy from robot A to robot B. Unlike prior methods that rely on paired data,
we propose a novel approach for learning the mapping functions between state
and action spaces across domains using unpaired data. We propose effect cycle
consistency, which aligns the effects of transitions across two domains through
a symmetrical optimization structure for learning these mapping functions. Once
the mapping functions are learned, we can seamlessly transfer the policy from
the source domain to the target domain. Our approach has been tested on three
locomotion tasks and two robotic manipulation tasks. The empirical results
demonstrate that our method can reduce alignment errors significantly and
achieve better performance compared to the state-of-the-art method.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02019" title="Abstract">arXiv:2403.02019</a> [<a href="/pdf/2403.02019" title="Download PDF">pdf</a>, <a href="/format/2403.02019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning of Mealy Machines with Timers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruy%C3%A8re%2C+V">V&#xe9;ronique Bruy&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Garhewal%2C+B">Bharat Garhewal</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+A">Guillermo A. P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Staquet%2C+G">Ga&#xeb;tan Staquet</a>, 
<a href="/search/cs?searchtype=author&query=Vaandrager%2C+F+W">Frits W. Vaandrager</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 77 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present the first algorithm for query learning of a general class of Mealy
machines with timers (MMTs) in a black-box context. Our algorithm is an
extension of the L# algorithm of Vaandrager et al. to a timed setting. Like the
algorithm for learning timed automata proposed by Waga, our algorithm is
inspired by ideas of Maler &amp; Pnueli. Based on the elementary languages of, both
Waga's and our algorithm use symbolic queries, which are then implemented using
finitely many concrete queries. However, whereas Waga needs exponentially many
concrete queries to implement a single symbolic query, we only need a
polynomial number. This is because in order to learn a timed automaton, a
learner needs to determine the exact guard and reset for each transition (out
of exponentially many possibilities), whereas for learning an MMT a learner
only needs to figure out which of the preceding transitions caused a timeout.
As shown in our previous work, this can be done efficiently for a subclass of
MMTs that are race-avoiding: if a timeout is caused by a preceding input then a
slight change in the timing of this input will induce a corresponding change in
the timing of the timeout ("wiggling"). Experiments with a prototype
implementation, written in Rust, show that our algorithm is able to efficiently
learn realistic benchmarks.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02026" title="Abstract">arXiv:2403.02026</a> [<a href="/pdf/2403.02026" title="Download PDF">pdf</a>, <a href="/format/2403.02026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph drawing applications in combinatorial theory of maturity models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kajzer%2C+%C5%A0">&#x160;pela Kajzer</a>, 
<a href="/search/cs?searchtype=author&query=Dobler%2C+A">Alexander Dobler</a>, 
<a href="/search/cs?searchtype=author&query=Jerebic%2C+J">Janja Jerebic</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%B6llenburg%2C+M">Martin N&#xf6;llenburg</a>, 
<a href="/search/cs?searchtype=author&query=Orthaber%2C+J">Joachim Orthaber</a>, 
<a href="/search/cs?searchtype=author&query=Bokal%2C+D">Drago Bokal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">In this paper, we introduce tiled graphs as models of learning and maturing
processes. We show how tiled graphs can combine graphs of learning spaces or
antimatroids (partial hypercubes) and maturity models (total orders) to yield
models of learning processes. For the visualization of these processes it is a
natural approach to aim for certain optimal drawings. We show for most of the
more detailed models that the drawing problems resulting from them are
NP-complete. The terse model of a maturing process that ignores the details of
learning, however, results in a polynomially solvable graph drawing problem. In
addition, this model provides insight into the process by ordering the subjects
at each test of their maturity. We investigate extremal and random instances of
this problem, and provide exact results and bounds on their optimal crossing
number.
<br />Graph-theoretic models offer two approaches to the design of optimal maturity
models given observed data: (1) minimizing intra-subject inconsistencies, which
manifest as regressions of subjects, is modeled as the well-known feedback arc
set problem. We study the alternative of (2) finding a maturity model by
minimizing the inter-subject inconsistencies, which manifest as crossings in
the respective drawing. We show this to be NP-complete.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02029" title="Abstract">arXiv:2403.02029</a> [<a href="/pdf/2403.02029" title="Download PDF">pdf</a>, <a href="/format/2403.02029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the accuracy of the Newmark method through backward error  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tak%C3%A1cs%2C+D+M">Don&#xe1;t M. Tak&#xe1;cs</a>, 
<a href="/search/math?searchtype=author&query=F%C3%BCl%C3%B6p%2C+T">Tam&#xe1;s F&#xfc;l&#xf6;p</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We use backward error analysis for differential equations to obtain modified
or distorted equations describing the behaviour of the Newmark scheme applied
to the transient structural dynamics equation. Using these results, we show how
to construct compensation terms from the original parameters of the system,
which improve the performance of Newmark simulations without changing the time
step or modifying the scheme itself. Two such compensations are given: one
eliminates numerical damping, while the other achieves fourth-order accurate
calculations using the traditionally second-order Newmark method.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02035" title="Abstract">arXiv:2403.02035</a> [<a href="/pdf/2403.02035" title="Download PDF">pdf</a>, <a href="/ps/2403.02035" title="Download PostScript">ps</a>, <a href="/format/2403.02035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential Expressivity of ReLU$^k$ Neural Networks on Gevrey Classes  with Point Singularities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Opschoor%2C+J+A+A">Joost A. A. Opschoor</a>, 
<a href="/search/math?searchtype=author&query=Schwab%2C+C">Christoph Schwab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We analyze deep Neural Network emulation rates of smooth functions with point
singularities in bounded, polytopal domains $\mathrm{D} \subset \mathbb{R}^d$,
$d=2,3$. We prove exponential emulation rates in Sobolev spaces in terms of the
number of neurons and in terms of the number of nonzero coefficients for
Gevrey-regular solution classes defined in terms of weighted Sobolev scales in
$\mathrm{D}$, comprising the countably-normed spaces of I.M. Babu\v{s}ka and
B.Q. Guo.
<br />As intermediate result, we prove that continuous, piecewise polynomial high
order (``$p$-version'') finite elements with elementwise polynomial degree
$p\in\mathbb{N}$ on arbitrary, regular, simplicial partitions of polyhedral
domains $\mathrm{D} \subset \mathbb{R}^d$, $d\geq 2$ can be exactly emulated by
neural networks combining ReLU and ReLU$^2$ activations. On shape-regular,
simplicial partitions of polytopal domains $\mathrm{D}$, both the number of
neurons and the number of nonzero parameters are proportional to the number of
degrees of freedom of the finite element space, in particular for the
$hp$-Finite Element Method of I.M. Babu\v{s}ka and B.Q. Guo.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02037" title="Abstract">arXiv:2403.02037</a> [<a href="/pdf/2403.02037" title="Download PDF">pdf</a>, <a href="/format/2403.02037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Vision-Based 3D Object Detection and Monocular Depth Estimation  for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> HKUST PhD Thesis; <a href="https://github.com/Owen-Liuyuxuan/visionfactory">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This dissertation is a multifaceted contribution to the advancement of
vision-based 3D perception technologies. In the first segment, the thesis
introduces structural enhancements to both monocular and stereo 3D object
detection algorithms. By integrating ground-referenced geometric priors into
monocular detection models, this research achieves unparalleled accuracy in
benchmark evaluations for monocular 3D detection. Concurrently, the work
refines stereo 3D detection paradigms by incorporating insights and inferential
structures gleaned from monocular networks, thereby augmenting the operational
efficiency of stereo detection systems. The second segment is devoted to
data-driven strategies and their real-world applications in 3D vision
detection. A novel training regimen is introduced that amalgamates datasets
annotated with either 2D or 3D labels. This approach not only augments the
detection models through the utilization of a substantially expanded dataset
but also facilitates economical model deployment in real-world scenarios where
only 2D annotations are readily available. Lastly, the dissertation presents an
innovative pipeline tailored for unsupervised depth estimation in autonomous
driving contexts. Extensive empirical analyses affirm the robustness and
efficacy of this newly proposed pipeline. Collectively, these contributions lay
a robust foundation for the widespread adoption of vision-based 3D perception
technologies in autonomous driving applications.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02039" title="Abstract">arXiv:2403.02039</a> [<a href="/pdf/2403.02039" title="Download PDF">pdf</a>, <a href="/format/2403.02039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Frequency-Domain Approach for Enhanced Performance and Task  Flexibility in Finite-Time ILC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Haren%2C+M">Max van Haren</a>, 
<a href="/search/eess?searchtype=author&query=Tsurumoto%2C+K">Kentaro Tsurumoto</a>, 
<a href="/search/eess?searchtype=author&query=Mae%2C+M">Masahiro Mae</a>, 
<a href="/search/eess?searchtype=author&query=Blanken%2C+L">Lennart Blanken</a>, 
<a href="/search/eess?searchtype=author&query=Ohnishi%2C+W">Wataru Ohnishi</a>, 
<a href="/search/eess?searchtype=author&query=Oomen%2C+T">Tom Oomen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Iterative learning control (ILC) is capable of improving the tracking
performance of repetitive control systems by utilizing data from past
iterations. The aim of this paper is to achieve both task flexibility, which is
often achieved by ILC with basis functions, and the performance of
frequency-domain ILC, with an intuitive design procedure. The cost function of
norm-optimal ILC is determined that recovers frequency-domain ILC, and
consequently, the feedforward signal is parameterized in terms of basis
functions and frequency-domain ILC. The resulting method has the performance
and design procedure of frequency-domain ILC and the task flexibility of basis
functions ILC, and are complimentary to each other. Validation on a benchmark
example confirms the capabilities of the framework.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02041" title="Abstract">arXiv:2403.02041</a> [<a href="/pdf/2403.02041" title="Download PDF">pdf</a>, <a href="/format/2403.02041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Approach for Wikipedia-Scale Visual Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caron%2C+M">Mathilde Caron</a>, 
<a href="/search/cs?searchtype=author&query=Iscen%2C+A">Ahmet Iscen</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+A">Alireza Fathi</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we address web-scale visual entity recognition, specifically
the task of mapping a given query image to one of the 6 million existing
entities in Wikipedia. One way of approaching a problem of such scale is using
dual-encoder models (eg CLIP), where all the entity names and query images are
embedded into a unified space, paving the way for an approximate k-NN search.
Alternatively, it is also possible to re-purpose a captioning model to directly
generate the entity names for a given image. In contrast, we introduce a novel
Generative Entity Recognition (GER) framework, which given an input image
learns to auto-regressively decode a semantic and discriminative ``code''
identifying the target entity. Our experiments demonstrate the efficacy of this
GER paradigm, showcasing state-of-the-art performance on the challenging OVEN
benchmark. GER surpasses strong captioning, dual-encoder, visual matching and
hierarchical classification baselines, affirming its advantage in tackling the
complexities of web-scale recognition.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02042" title="Abstract">arXiv:2403.02042</a> [<a href="/pdf/2403.02042" title="Download PDF">pdf</a>, <a href="/format/2403.02042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network for Constraint Acquisition through Tailored Loss  Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyhmeister%2C+E">Eduardo Vyhmeister</a>, 
<a href="/search/cs?searchtype=author&query=Paez%2C+R">Rocio Paez</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+G">Gabriel Gonzalez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">The significance of learning constraints from data is underscored by its
potential applications in real-world problem-solving. While constraints are
popular for modeling and solving, the approaches to learning constraints from
data remain relatively scarce. Furthermore, the intricate task of modeling
demands expertise and is prone to errors, thus constraint acquisition methods
offer a solution by automating this process through learnt constraints from
examples or behaviours of solutions and non-solutions. This work introduces a
novel approach grounded in Deep Neural Network (DNN) based on Symbolic
Regression that, by setting suitable loss functions, constraints can be
extracted directly from datasets. Using the present approach, direct
formulation of constraints was achieved. Furthermore, given the broad
pre-developed architectures and functionalities of DNN, connections and
extensions with other frameworks could be foreseen.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02044" title="Abstract">arXiv:2403.02044</a> [<a href="/pdf/2403.02044" title="Download PDF">pdf</a>, <a href="/format/2403.02044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Reversal of Stochastic Maximum Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Taghvaei%2C+A">Amirhossein Taghvaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Stochastic maximum principle (SMP) specifies a necessary condition for the
solution of a stochastic optimal control problem. The condition involves a
coupled system of forward and backward stochastic differential equations
(FBSDE) for the state and the adjoint processes. Numerical solution of the
FBSDE is challenging because the boundary condition of the adjoint process is
specified at the terminal time, while the solution should be adaptable to the
forward in time filtration of a Wiener process. In this paper, a
"time-reversal" of the FBSDE system is proposed that involves integration with
respect to a backward in time Wiener process. The time-reversal is used to
propose an iterative Monte-Carlo procedure to solves the FBSDE system and its
time-reversal simultaneously. The procedure involves approximating the
{F\"ollmer's drift} and solving a regression problem between the state and its
adjoint at each time. The procedure is illustrated for the linear quadratic
(LQ) optimal control problem with a numerical example.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02053" title="Abstract">arXiv:2403.02053</a> [<a href="/pdf/2403.02053" title="Download PDF">pdf</a>, <a href="/ps/2403.02053" title="Download PostScript">ps</a>, <a href="/format/2403.02053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scoping Review of Energy-Efficient Driving Behaviors and Applied  State-of-the-Art AI Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhipeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%B8rgensen%2C+B+N">Bo N&#xf8;rregaard J&#xf8;rgensen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energies 2024, 17, 500
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The transportation sector remains a major contributor to greenhouse gas
emissions. The understanding of energy-efficient driving behaviors and
utilization of energy-efficient driving strategies are essential to reduce
vehicles' fuel consumption. However, there is no comprehensive investigation
into energy-efficient driving behaviors and strategies. Furthermore, many
state-of-the-art AI models have been applied for the analysis of eco-friendly
driving styles, but no overview is available. To fill the gap, this paper
conducts a thorough literature review on ecological driving behaviors and
styles and analyzes the driving factors influencing energy consumption and
state-of-the-art methodologies. With a thorough scoping review process, the
methodological and related data are compared. The results show that the factors
that impact driving behaviors can be summarized into eleven features including
speed, acceleration, deceleration, pedal, and so on. This paper finds that
supervised/unsupervised learning algorithms and reinforcement learning
frameworks have been popularly used to model the vehicle's energy consumption
with multi-dimensional data. Furthermore, the literature shows that the driving
data are collected from either simulators or real-world experiments, and the
real-world data are mainly stored and transmitted by meters, controller area
networks, onboard data services, smartphones, and additional sensors installed
in the vehicle. Based on driving behavior factors, driver characteristics, and
safety rules, this paper recommends nine energy-efficient driving styles
including four guidelines for the drivers' selection and adjustment of the
vehicle parameters, three recommendations for the energy-efficient driving
styles in different driving scenarios, and two subjective suggestions for
different types of drivers and employers.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02054" title="Abstract">arXiv:2403.02054</a> [<a href="/pdf/2403.02054" title="Download PDF">pdf</a>, <a href="/format/2403.02054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model-Based Evolutionary Optimizer: Reasoning with  elitism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brahmachary%2C+S">Shuvayan Brahmachary</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S+M">Subodh M. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+A">Aniruddha Panda</a>, 
<a href="/search/cs?searchtype=author&query=Koneripalli%2C+K">Kaushik Koneripalli</a>, 
<a href="/search/cs?searchtype=author&query=Sagotra%2C+A+K">Arun Kumar Sagotra</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+H">Harshil Patel</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Ankush Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Jagtap%2C+A+D">Ameya D. Jagtap</a>, 
<a href="/search/cs?searchtype=author&query=Kalyanaraman%2C+K">Kaushic Kalyanaraman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable reasoning
abilities, prompting interest in their application as black-box optimizers.
This paper asserts that LLMs possess the capability for zero-shot optimization
across diverse scenarios, including multi-objective and high-dimensional
problems. We introduce a novel population-based method for numerical
optimization using LLMs called Language-Model-Based Evolutionary Optimizer
(LEO). Our hypothesis is supported through numerical examples, spanning
benchmark and industrial engineering problems such as supersonic nozzle shape
optimization, heat transfer, and windfarm layout optimization. We compare our
method to several gradient-based and gradient-free optimization approaches.
While LLMs yield comparable results to state-of-the-art methods, their
imaginative nature and propensity to hallucinate demand careful handling. We
provide practical guidelines for obtaining reliable answers from LLMs and
discuss method limitations and potential research directions.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02059" title="Abstract">arXiv:2403.02059</a> [<a href="/pdf/2403.02059" title="Download PDF">pdf</a>, <a href="/format/2403.02059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Spectral Remote Sensing Image Retrieval Using Geospatial  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blumenstiel%2C+B">Benedikt Blumenstiel</a>, 
<a href="/search/cs?searchtype=author&query=Moor%2C+V">Viktoria Moor</a>, 
<a href="/search/cs?searchtype=author&query=Kienzler%2C+R">Romeo Kienzler</a>, 
<a href="/search/cs?searchtype=author&query=Brunschwiler%2C+T">Thomas Brunschwiler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image retrieval enables an efficient search through vast amounts of satellite
imagery and returns similar images to a query. Deep learning models can
identify images across various semantic concepts without the need for
annotations. This work proposes to use Geospatial Foundation Models, like
Prithvi, for remote sensing image retrieval with multiple benefits: i) the
models encode multi-spectral satellite data and ii) generalize without further
fine-tuning. We introduce two datasets to the retrieval task and observe a
strong performance: Prithvi processes six bands and achieves a mean Average
Precision of 97.62\% on BigEarthNet-43 and 44.51\% on ForestNet-12,
outperforming other RGB-based models. Further, we evaluate three compression
methods with binarized embeddings balancing retrieval speed and accuracy. They
match the retrieval speed of much shorter hash codes while maintaining the same
accuracy as floating-point embeddings but with a 32-fold compression. The code
is available at https://github.com/IBM/remote-sensing-image-retrieval.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02063" title="Abstract">arXiv:2403.02063</a> [<a href="/pdf/2403.02063" title="Download PDF">pdf</a>, <a href="/format/2403.02063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input  Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shuai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiuwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yijie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Rong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Li Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Novel-view synthesis with sparse input views is important for real-world
applications like AR/VR and autonomous driving. Recent methods have integrated
depth information into NeRFs for sparse input synthesis, leveraging depth prior
for geometric and spatial understanding. However, most existing works tend to
overlook inaccuracies within depth maps and have low time efficiency. To
address these issues, we propose a depth-guided robust and fast point cloud
fusion NeRF for sparse inputs. We perceive radiance fields as an explicit voxel
grid of features. A point cloud is constructed for each input view,
characterized within the voxel grid using matrices and vectors. We accumulate
the point cloud of each input view to construct the fused point cloud of the
entire scene. Each voxel determines its density and appearance by referring to
the point cloud of the entire scene. Through point cloud fusion and voxel grid
fine-tuning, inaccuracies in depth values are refined or substituted by those
from other views. Moreover, our method can achieve faster reconstruction and
greater compactness through effective vector-matrix decomposition. Experimental
results underline the superior performance and time efficiency of our approach
compared to state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02069" title="Abstract">arXiv:2403.02069</a> [<a href="/pdf/2403.02069" title="Download PDF">pdf</a>, <a href="/ps/2403.02069" title="Download PostScript">ps</a>, <a href="/format/2403.02069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperPredict: Estimating Hyperparameter Effects for Instance-Specific  Regularization in Deformable Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shuaibu%2C+A+L">Aisha L. Shuaibu</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+I+J+A">Ivor J. A. Simpson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Methods for medical image registration infer geometric transformations that
align pairs/groups of images by maximising an image similarity metric. This
problem is ill-posed as several solutions may have equivalent likelihoods, also
optimising purely for image similarity can yield implausible transformations.
For these reasons regularization terms are essential to obtain meaningful
registration results. However, this requires the introduction of at least one
hyperparameter often termed {\lambda}, that serves as a tradeoff between loss
terms. In some situations, the quality of the estimated transformation greatly
depends on hyperparameter choice, and different choices may be required
depending on the characteristics of the data. Analyzing the effect of these
hyperparameters requires labelled data, which is not commonly available at
test-time. In this paper, we propose a method for evaluating the influence of
hyperparameters and subsequently selecting an optimal value for given image
pairs. Our approach which we call HyperPredict, implements a Multi-Layer
Perceptron that learns the effect of selecting particular hyperparameters for
registering an image pair by predicting the resulting segmentation overlap and
measure of deformation smoothness. This approach enables us to select optimal
hyperparameters at test time without requiring labelled data, removing the need
for a one-size-fits-all cross-validation approach. Furthermore, the criteria
used to define optimal hyperparameter is flexible post-training, allowing us to
efficiently choose specific properties. We evaluate our proposed method on the
OASIS brain MR dataset using a recent deep learning approach(cLapIRN) and an
algorithmic method(Niftyreg). Our results demonstrate good performance in
predicting the effects of regularization hyperparameters and highlight the
benefits of our image-pair specific approach to hyperparameter selection.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02071" title="Abstract">arXiv:2403.02071</a> [<a href="/pdf/2403.02071" title="Download PDF">pdf</a>, <a href="/format/2403.02071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Efficient Approximation of the Maximum Distance to A Point Over an  Intersection of Balls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costandin%2C+B">Beniamin Costandin</a>, 
<a href="/search/cs?searchtype=author&query=Costandin%2C+M">Marius Costandin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper we study the NP-Hard problem of maximizing the distance over an
intersection of balls to a given point. We expand the results found in
\cite{funcos1}, where the authors characterize the farthest in an intersection
of balls $\mathcal{Q}$ to the given point $C_0$ by constructing some
intersection of halfspaces. In this paper, by slightly modifying the technique
found in literature, we characterize the farthest in an intersection of balls
$\mathcal{Q}$ with another intersection of balls $\mathcal{Q}_1$. As such,
going backwards, we are naturally able to find the given intersection of balls
$\mathcal{Q}$ as the max indicator intersection of balls of another one
$\mathcal{Q}_{-1}$. By repeating the process, we find a sequence of
intersection of balls $(\mathcal{Q}_{i})_{i \in \mathbb{Z}}$, which has
$\mathcal{Q}$ as an element, namely $\mathcal{Q}_{0}$ and show that
$\mathcal{Q}_{-\infty} = \mathcal{B}(C_0,R_0)$ where $R_0$ is the maximum
distance from $C_0$ to a point in $\mathcal{Q}$. As a final application of the
proposed theory we give a polynomial algorithm for computing the maximum
distance under an oracle which returns the volume of an intersection of balls,
showing that the later is NP-Hard. Finally, we present a randomized method %of
polynomial complexity which allows an approximation of the maximum distance.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02074" title="Abstract">arXiv:2403.02074</a> [<a href="/pdf/2403.02074" title="Download PDF">pdf</a>, <a href="/format/2403.02074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Linda Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Combining images from multi-modalities is beneficial to explore various
information in computer vision, especially in the medical domain. As an
essential part of clinical diagnosis, multi-modal brain tumor segmentation aims
to delineate the malignant entity involving multiple modalities. Although
existing methods have shown remarkable performance in the task, the information
exchange for cross-scale and high-level representations fusion in spatial and
modality are limited in these methods. In this paper, we present a novel
Modality Aware and Shift Mixer that integrates intra-modality and
inter-modality dependencies of multi-modal images for effective and robust
brain tumor segmentation. Specifically, we introduce a Modality-Aware module
according to neuroimaging studies for modeling the specific modality pair
relationships at low levels, and a Modality-Shift module with specific mosaic
patterns is developed to explore the complex relationships across modalities at
high levels via the self-attention. Experimentally, we outperform previous
state-of-the-art approaches on the public Brain Tumor Segmentation (BraTS 2021
segmentation) dataset. Further qualitative experiments demonstrate the efficacy
and robustness of MASM.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02075" title="Abstract">arXiv:2403.02075</a> [<a href="/pdf/2403.02075" title="Download PDF">pdf</a>, <a href="/format/2403.02075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with  Non-linear Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+W">Weiyi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Ruei-Sung Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dan Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In Multiple Object Tracking, objects often exhibit non-linear motion of
acceleration and deceleration, with irregular direction changes.
Tacking-by-detection (TBD) with Kalman Filter motion prediction works well in
pedestrian-dominant scenarios but falls short in complex situations when
multiple objects perform non-linear and diverse motion simultaneously. To
tackle the complex non-linear motion, we propose a real-time diffusion-based
MOT approach named DiffMOT. Specifically, for the motion predictor component,
we propose a novel Decoupled Diffusion-based Motion Predictor (D MP). It models
the entire distribution of various motion presented by the data as a whole. It
also predicts an individual object's motion conditioning on an individual's
historical motion information. Furthermore, it optimizes the diffusion process
with much less sampling steps. As a MOT tracker, the DiffMOT is real-time at
22.7FPS, and also outperforms the state-of-the-art on DanceTrack and SportsMOT
datasets with 63.4 and 76.2 in HOTA metrics, respectively. To the best of our
knowledge, DiffMOT is the first to introduce a diffusion probabilistic model
into the MOT to tackle non-linear motion prediction.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02076" title="Abstract">arXiv:2403.02076</a> [<a href="/pdf/2403.02076" title="Download PDF">pdf</a>, <a href="/format/2403.02076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunzhuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zien Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+B">Benxiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Sidan Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Video temporal grounding (VTG) aims to locate specific temporal segments from
an untrimmed video based on a linguistic query. Most existing VTG models are
trained on extensive annotated video-text pairs, a process that not only
introduces human biases from the queries but also incurs significant
computational costs. To tackle these challenges, we propose VTG-GPT, a
GPT-based method for zero-shot VTG without training or fine-tuning. To reduce
prejudice in the original query, we employ Baichuan2 to generate debiased
queries. To lessen redundant information in videos, we apply MiniGPT-v2 to
transform visual content into more precise captions. Finally, we devise the
proposal generator and post-processing to produce accurate segments from
debiased queries and image captions. Extensive experiments demonstrate that
VTG-GPT significantly outperforms SOTA methods in zero-shot settings and
surpasses unsupervised approaches. More notably, it achieves competitive
performance comparable to supervised methods. The code is available on
https://github.com/YoucanBaby/VTG-GPT
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02078" title="Abstract">arXiv:2403.02078</a> [<a href="/pdf/2403.02078" title="Download PDF">pdf</a>, <a href="/format/2403.02078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Generation of Multiple-Choice Cloze Questions for Assessing  English Vocabulary Using GPT-turbo 3.5
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+R">Ralph Rose</a>, 
<a href="/search/cs?searchtype=author&query=Orita%2C+N">Naho Orita</a>, 
<a href="/search/cs?searchtype=author&query=Sugawara%2C+A">Ayaka Sugawara</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mika H\"am\"al\"ainen, Emily \"Ohman, Flammie Pirinen, Khalid
  Alnajjar, So Miyagawa, Yuri Bizzoni, Niko Partanen, and Jack Rueter. 2023.
  Proc. of the Joint 3rd International Conference on NLP4DH and 8th IWCLUL.
  ACL, Tokyo, Japan, edition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A common way of assessing language learners' mastery of vocabulary is via
multiple-choice cloze (i.e., fill-in-the-blank) questions. But the creation of
test items can be laborious for individual teachers or in large-scale language
programs. In this paper, we evaluate a new method for automatically generating
these types of questions using large language models (LLM). The VocaTT
(vocabulary teaching and training) engine is written in Python and comprises
three basic steps: pre-processing target word lists, generating sentences and
candidate word options using GPT, and finally selecting suitable word options.
To test the efficiency of this system, 60 questions were generated targeting
academic words. The generated items were reviewed by expert reviewers who
judged the well-formedness of the sentences and word options, adding comments
to items judged not well-formed. Results showed a 75% rate of well-formedness
for sentences and 66.85% rate for suitable word options. This is a marked
improvement over the generator used earlier in our research which did not take
advantage of GPT's capabilities. Post-hoc qualitative analysis reveals several
points for improvement in future work including cross-referencing
part-of-speech tagging, better sentence validation, and improving GPT prompts.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02084" title="Abstract">arXiv:2403.02084</a> [<a href="/pdf/2403.02084" title="Download PDF">pdf</a>, <a href="/format/2403.02084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiaxiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiashi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuxi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huixia Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuefeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Min Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Lean Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancement in text-to-image models (e.g., Stable Diffusion) and
corresponding personalized technologies (e.g., DreamBooth and LoRA) enables
individuals to generate high-quality and imaginative images. However, they
often suffer from limitations when generating images with resolutions outside
of their trained domain. To overcome this limitation, we present the Resolution
Adapter (ResAdapter), a domain-consistent adapter designed for diffusion models
to generate images with unrestricted resolutions and aspect ratios. Unlike
other multi-resolution generation methods that process images of static
resolution with complex post-process operations, ResAdapter directly generates
images with the dynamical resolution. Especially, after learning a deep
understanding of pure resolution priors, ResAdapter trained on the general
dataset, generates resolution-free images with personalized diffusion models
while preserving their original style domain. Comprehensive experiments
demonstrate that ResAdapter with only 0.5M can process images with flexible
resolutions for arbitrary diffusion models. More extended experiments
demonstrate that ResAdapter is compatible with other modules (e.g., ControlNet,
IP-Adapter and LCM-LoRA) for image generation across a broad range of
resolutions, and can be integrated into other multi-resolution model (e.g.,
ElasticDiffusion) for efficiently generating higher-resolution images. Project
link is https://res-adapter.github.io
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02090" title="Abstract">arXiv:2403.02090</a> [<a href="/pdf/2403.02090" title="Download PDF">pdf</a>, <a href="/format/2403.02090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Multimodal Social Interactions: New Challenges and Baselines  with Densely Aligned Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+B">Bolin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+F">Fiona Ryan</a>, 
<a href="/search/cs?searchtype=author&query=Boote%2C+B">Bikram Boote</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding social interactions involving both verbal and non-verbal cues
is essential to effectively interpret social situations. However, most prior
works on multimodal social cues focus predominantly on single-person behaviors
or rely on holistic visual representations that are not densely aligned to
utterances in multi-party environments. They are limited in modeling the
intricate dynamics of multi-party interactions. In this paper, we introduce
three new challenging tasks to model the fine-grained dynamics between multiple
people: speaking target identification, pronoun coreference resolution, and
mentioned player prediction. We contribute extensive data annotations to curate
these new challenges in social deduction game settings. Furthermore, we propose
a novel multimodal baseline that leverages densely aligned language-visual
representations by synchronizing visual features with their corresponding
utterances. This facilitates concurrently capturing verbal and non-verbal cues
pertinent to social reasoning. Experiments demonstrate the effectiveness of the
proposed approach with densely aligned multimodal representations in modeling
social interactions. We will release our benchmarks and source code to
facilitate further research.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02093" title="Abstract">arXiv:2403.02093</a> [<a href="/pdf/2403.02093" title="Download PDF">pdf</a>, <a href="/format/2403.02093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Daedalus: Self-Adaptive Horizontal Autoscaling for Resource Efficiency  of Distributed Stream Processing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfister%2C+B+J+J">Benjamin J. J. Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Geldenhuys%2C+M+K">Morgan K. Geldenhuys</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Distributed Stream Processing (DSP) systems are capable of processing large
streams of unbounded data, offering high throughput and low latencies. To
maintain a stable Quality of Service (QoS), these systems require a sufficient
allocation of resources. At the same time, over-provisioning can result in
wasted energy and high operating costs. Therefore, to maximize resource
utilization, autoscaling methods have been proposed that aim to efficiently
match the resource allocation with the incoming workload. However, determining
when and by how much to scale remains a significant challenge. Given the
long-running nature of DSP jobs, scaling actions need to be executed at
runtime, and to maintain a good QoS, they should be both accurate and
infrequent. To address the challenges of autoscaling, the concept of
self-adaptive systems is particularly fitting. These systems monitor themselves
and their environment, adapting to changes with minimal need for expert
involvement.
<br />This paper introduces Daedalus, a self-adaptive manager for autoscaling in
DSP systems, which draws on the principles of self-adaption to address the
challenge of efficient autoscaling. Daedalus monitors a running DSP job and
builds performance models, aiming to predict the maximum processing capacity at
different scale-outs. When combined with time series forecasting to predict
future workloads, Daedalus proactively scales DSP jobs, optimizing for maximum
throughput and minimizing both latencies and resource usage. We conducted
experiments using Apache Flink and Kafka Streams to evaluate the performance of
Daedalus against two state-of-the-art approaches. Daedalus was able to achieve
comparable latencies while reducing resource usage by up to 71%.
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02107" title="Abstract">arXiv:2403.02107</a> [<a href="/pdf/2403.02107" title="Download PDF">pdf</a>, <a href="/format/2403.02107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterated $Q$-Network: Beyond the One-Step Bellman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vincent%2C+T">Th&#xe9;o Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Palenicek%2C+D">Daniel Palenicek</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+B">Boris Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Value-based Reinforcement Learning (RL) methods rely on the application of
the Bellman operator, which needs to be approximated from samples. Most
approaches consist of an iterative scheme alternating the application of the
Bellman operator and a subsequent projection step onto a considered function
space. However, we observe that these algorithms can be improved by considering
multiple iterations of the Bellman operator at once. Thus, we introduce
iterated $Q$-Networks (iQN), a novel approach that learns a sequence of
$Q$-function approximations where each $Q$-function serves as the target for
the next one in a chain of consecutive Bellman iterations. We demonstrate that
iQN is theoretically sound and show how it can be seamlessly used in
value-based and actor-critic methods. We empirically demonstrate its advantages
on Atari $2600$ games and in continuous-control MuJoCo environments.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02112" title="Abstract">arXiv:2403.02112</a> [<a href="/pdf/2403.02112" title="Download PDF">pdf</a>, <a href="/format/2403.02112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Perspective on Smiling and Laughter Detection: Intensity Levels  Matter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bohy%2C+H">Hugo Bohy</a>, 
<a href="/search/cs?searchtype=author&query=Haddad%2C+K+E">Kevin El Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Dutoit%2C+T">Thierry Dutoit</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In 2022 10th International Conference on Affective Computing and
  Intelligent Interaction (ACII) (pp. 1-8). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Smiles and laughs detection systems have attracted a lot of attention in the
past decade contributing to the improvement of human-agent interaction systems.
But very few considered these expressions as distinct, although no prior work
clearly proves them to belong to the same category or not. In this work, we
present a deep learning-based multimodal smile and laugh classification system,
considering them as two different entities. We compare the use of audio and
vision-based models as well as a fusion approach. We show that, as expected,
the fusion leads to a better generalization on unseen data. We also present an
in-depth analysis of the behavior of these models on the smiles and laughs
intensity levels. The analyses on the intensity levels show that the
relationship between smiles and laughs might not be as simple as a binary one
or even grouping them in a single category, and so, a more complex approach
should be taken when dealing with them. We also tackle the problem of limited
resources by showing that transfer learning allows the models to improve the
detection of confusing intensity levels.
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02116" title="Abstract">arXiv:2403.02116</a> [<a href="/pdf/2403.02116" title="Download PDF">pdf</a>, <a href="/format/2403.02116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inf2Guard: An Information-Theoretic Framework for Learning  Privacy-Preserving Representations against Inference Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noorbakhsh%2C+S+L">Sayedeh Leila Noorbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binghui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Usenix Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine learning (ML) is vulnerable to inference (e.g., membership inference,
property inference, and data reconstruction) attacks that aim to infer the
private information of training data or dataset. Existing defenses are only
designed for one specific type of attack and sacrifice significant utility or
are soon broken by adaptive attacks. We address these limitations by proposing
an information-theoretic defense framework, called Inf2Guard, against the three
major types of inference attacks. Our framework, inspired by the success of
representation learning, posits that learning shared representations not only
saves time/costs but also benefits numerous downstream tasks. Generally,
Inf2Guard involves two mutual information objectives, for privacy protection
and utility preservation, respectively. Inf2Guard exhibits many merits: it
facilitates the design of customized objectives against the specific inference
attack; it provides a general defense framework which can treat certain
existing defenses as special cases; and importantly, it aids in deriving
theoretical results, e.g., inherent utility-privacy tradeoff and guaranteed
privacy leakage. Extensive evaluations validate the effectiveness of Inf2Guard
for learning privacy-preserving representations against inference attacks and
demonstrate the superiority over the baselines.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02118" title="Abstract">arXiv:2403.02118</a> [<a href="/pdf/2403.02118" title="Download PDF">pdf</a>, <a href="/format/2403.02118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position Paper: Towards Implicit Prompt For Text-To-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yue Yang</a>, 
<a href="/search/cs?searchtype=author&query=lin%2C+Y">Yuqi lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+H">Hailong Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent text-to-image (T2I) models have had great success, and many benchmarks
have been proposed to evaluate their performance and safety. However, they only
consider explicit prompts while neglecting implicit prompts (hint at a target
without explicitly mentioning it). These prompts may get rid of safety
constraints and pose potential threats to the applications of these models.
This position paper highlights the current state of T2I models toward implicit
prompts. We present a benchmark named ImplicitBench and conduct an
investigation on the performance and impacts of implicit prompts with popular
T2I models. Specifically, we design and collect more than 2,000 implicit
prompts of three aspects: General Symbols, Celebrity Privacy, and
Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models'
capabilities under these implicit prompts. Experiment results show that (1) T2I
models are able to accurately create various target symbols indicated by
implicit prompts; (2) Implicit prompts bring potential risks of privacy leakage
for T2I models. (3) Constraints of NSFW in most of the evaluated T2I models can
be bypassed with implicit prompts. We call for increased attention to the
potential and risks of implicit prompts in the T2I community and further
investigation into the capabilities and impacts of implicit prompts, advocating
for a balanced approach that harnesses their benefits while mitigating their
risks.
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02121" title="Abstract">arXiv:2403.02121</a> [<a href="/pdf/2403.02121" title="Download PDF">pdf</a>, <a href="/format/2403.02121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed  Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+S">Sargam Yadav</a> (1), 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+A">Abhishek Kaushik</a> (1), 
<a href="/search/cs?searchtype=author&query=McDaid%2C+K">Kevin McDaid</a> (1) ((1) Dundalk Institute of Technology, Dundalk)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted in the 16th ISDSI-Global Conference 2023 <a href="https://isdsi2023.iimranchi.ac.in">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of Large Language Models (LLMs) has advanced the benchmark in
various Natural Language Processing (NLP) tasks. However, large amounts of
labelled training data are required to train LLMs. Furthermore, data annotation
and training are computationally expensive and time-consuming. Zero and
few-shot learning have recently emerged as viable options for labelling data
using large pre-trained models. Hate speech detection in mix-code low-resource
languages is an active problem area where the use of LLMs has proven
beneficial. In this study, we have compiled a dataset of 100 YouTube comments,
and weakly labelled them for coarse and fine-grained misogyny classification in
mix-code Hinglish. Weak annotation was applied due to the labor-intensive
annotation process. Zero-shot learning, one-shot learning, and few-shot
learning and prompting approaches have then been applied to assign labels to
the comments and compare them to human-assigned labels. Out of all the
approaches, zero-shot classification using the Bidirectional Auto-Regressive
Transformers (BART) large model and few-shot prompting using Generative
Pre-trained Transformer- 3 (ChatGPT-3) achieve the best results
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02127" title="Abstract">arXiv:2403.02127</a> [<a href="/pdf/2403.02127" title="Download PDF">pdf</a>, <a href="/format/2403.02127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOCR: Location-Guided Transformer for Optical Character Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongzhan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han-Sen Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Academic documents are packed with texts, equations, tables, and figures,
requiring comprehensive understanding for accurate Optical Character
Recognition (OCR). While end-to-end OCR methods offer improved accuracy over
layout-based approaches, they often grapple with significant repetition issues,
especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this
issue, we propose LOCR, a model that integrates location guiding into the
transformer architecture during autoregression. We train the model on a dataset
comprising over 77M text-location pairs from 125K academic document pages,
including bounding boxes for words, tables and mathematical symbols. LOCR
adeptly handles various formatting elements and generates content in Markdown
language. It outperforms all existing methods in our test set constructed from
arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also
reduces repetition frequency from 4.4% of pages to 0.5% in the arXiv dataset,
from 13.2% to 1.3% in OOD quantum physics documents and from 8.1% to 1.8% in
OOD marketing documents. Additionally, LOCR features an interactive OCR mode,
facilitating the generation of complex documents through a few location prompts
from human.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02129" title="Abstract">arXiv:2403.02129</a> [<a href="/pdf/2403.02129" title="Download PDF">pdf</a>, <a href="/format/2403.02129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demeter: Resource-Efficient Distributed Stream Processing under Dynamic  Loads with Multi-Configuration Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geldenhuys%2C+M">Morgan Geldenhuys</a>, 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 14 figures, published at ICPE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Distributed Stream Processing (DSP) focuses on the near real-time processing
of large streams of unbounded data. To increase processing capacities, DSP
systems are able to dynamically scale across a cluster of commodity nodes,
ensuring a good Quality of Service despite variable workloads. However,
selecting scaleout configurations which maximize resource utilization remains a
challenge. This is especially true in environments where workloads change over
time and node failures are all but inevitable. Furthermore, configuration
parameters such as memory allocation and checkpointing intervals impact
performance and resource usage as well. Sub-optimal configurations easily lead
to high operational costs, poor performance, or unacceptable loss of service.
<br />In this paper, we present Demeter, a method for dynamically optimizing key
DSP system configuration parameters for resource efficiency. Demeter uses Time
Series Forecasting to predict future workloads and Multi-Objective Bayesian
Optimization to model runtime behaviors in relation to parameter settings and
workload rates. Together, these techniques allow us to determine whether or not
enough is known about the predicted workload rate to proactively initiate
short-lived parallel profiling runs for data gathering. Once trained, the
models guide the adjustment of multiple, potentially dependent system
configuration parameters ensuring optimized performance and resource usage in
response to changing workload rates. Our experiments on a commodity cluster
using Apache Flink demonstrate that Demeter significantly improves the
operational efficiency of long-running benchmark jobs.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02130" title="Abstract">arXiv:2403.02130</a> [<a href="/pdf/2403.02130" title="Download PDF">pdf</a>, <a href="/format/2403.02130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using LLMs for the Extraction and Normalization of Product Attribute  Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+N">Nick Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Brinkmann%2C+A">Alexander Brinkmann</a>, 
<a href="/search/cs?searchtype=author&query=Bizer%2C+C">Christian Bizer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Product offers on e-commerce websites often consist of a textual product
title and a textual product description. In order to provide features such as
faceted product filtering or content-based product recommendation, the websites
need to extract attribute-value pairs from the unstructured product
descriptions. This paper explores the potential of using large language models
(LLMs), such as OpenAI's GPT-3.5 and GPT-4, to extract and normalize attribute
values from product titles and product descriptions. For our experiments, we
introduce the WDC Product Attribute-Value Extraction (WDC PAVE) dataset. WDC
PAVE consists of product offers from 87 websites that provide schema.org
annotations. The offers belong to five different categories, each featuring a
specific set of attributes. The dataset provides manually verified
attribute-value pairs in two forms: (i) directly extracted values and (ii)
normalized attribute values. The normalization of the attribute values requires
systems to perform the following types of operations: name expansion,
generalization, unit of measurement normalization, and string wrangling. Our
experiments demonstrate that GPT-4 outperforms PLM-based extraction methods by
10%, achieving an F1-Score of 91%. For the extraction and normalization of
product attribute values, GPT-4 achieves a similar performance to the
extraction scenario, while being particularly strong at string wrangling and
name expansion.
</p>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02131" title="Abstract">arXiv:2403.02131</a> [<a href="/pdf/2403.02131" title="Download PDF">pdf</a>, <a href="/format/2403.02131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Dynamic Algorithm Selection: A  Proof-of-Principle Study on Differential Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongshu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yining Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zeyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yue-Jiao Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Systems, Man, and Cybernetics: Systems at Thu, Feb 29, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Evolutionary algorithms, such as Differential Evolution, excel in solving
real-parameter optimization challenges. However, the effectiveness of a single
algorithm varies across different problem instances, necessitating considerable
efforts in algorithm selection or configuration. This paper aims to address the
limitation by leveraging the complementary strengths of a group of algorithms
and dynamically scheduling them throughout the optimization progress for
specific problems. We propose a deep reinforcement learning-based dynamic
algorithm selection framework to accomplish this task. Our approach models the
dynamic algorithm selection a Markov Decision Process, training an agent in a
policy gradient manner to select the most suitable algorithm according to the
features observed during the optimization process. To empower the agent with
the necessary information, our framework incorporates a thoughtful design of
landscape and algorithmic features. Meanwhile, we employ a sophisticated deep
neural network model to infer the optimal action, ensuring informed algorithm
selections. Additionally, an algorithm context restoration mechanism is
embedded to facilitate smooth switching among different algorithms. These
mechanisms together enable our framework to seamlessly select and switch
algorithms in a dynamic online fashion. Notably, the proposed framework is
simple and generic, offering potential improvements across a broad spectrum of
evolutionary algorithms. As a proof-of-principle study, we apply this framework
to a group of Differential Evolution algorithms. The experimental results
showcase the remarkable effectiveness of the proposed framework, not only
enhancing the overall optimization performance but also demonstrating favorable
generalization ability across different problem classes.
</p>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02132" title="Abstract">arXiv:2403.02132</a> [<a href="/pdf/2403.02132" title="Download PDF">pdf</a>, <a href="/format/2403.02132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UB-FineNet: Urban Building Fine-grained Classification Network for  Open-access Satellite Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiyi He</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Puzuo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fine classification of city-scale buildings from satellite remote sensing
imagery is a crucial research area with significant implications for urban
planning, infrastructure development, and population distribution analysis.
However, the task faces big challenges due to low-resolution overhead images
acquired from high altitude space-borne platforms and the long-tail sample
distribution of fine-grained urban building categories, leading to severe class
imbalance problem. To address these issues, we propose a deep network approach
to fine-grained classification of urban buildings using open-access satellite
images. A Denoising Diffusion Probabilistic Model (DDPM) based super-resolution
method is first introduced to enhance the spatial resolution of satellite
images, which benefits from domain-adaptive knowledge distillation. Then, a new
fine-grained classification network with Category Information Balancing Module
(CIBM) and Contrastive Supervision (CS) technique is proposed to mitigate the
problem of class imbalance and improve the classification robustness and
accuracy. Experiments on Hong Kong data set with 11 fine building types
revealed promising classification results with a mean Top-1 accuracy of
60.45\%, which is on par with street-view image based approaches. Extensive
ablation study shows that CIBM and CS improve Top-1 accuracy by 2.6\% and 3.5\%
compared to the baseline method, respectively. And both modules can be easily
inserted into other classification networks and similar enhancements have been
achieved. Our research contributes to the field of urban analysis by providing
a practical solution for fine classification of buildings in challenging mega
city scenarios solely using open-access satellite images. The proposed method
can serve as a valuable tool for urban planners, aiding in the understanding of
economic, industrial, and population distribution.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02135" title="Abstract">arXiv:2403.02135</a> [<a href="/pdf/2403.02135" title="Download PDF">pdf</a>, <a href="/format/2403.02135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memoro: Using Large Language Models to Realize a Concise Interface for  Real-Time Memory Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zulfikar%2C+W">Wazeer Zulfikar</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Samantha Chan</a>, 
<a href="/search/cs?searchtype=author&query=Maes%2C+P">Pattie Maes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures, project page at <a href="https://www.media.mit.edu/projects/memoro/overview">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the CHI Conference on Human Factors in Computing
  Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">People have to remember an ever-expanding volume of information. Wearables
that use information capture and retrieval for memory augmentation can help but
can be disruptive and cumbersome in real-world tasks, such as in social
settings. To address this, we developed Memoro, a wearable audio-based memory
assistant with a concise user interface. Memoro uses a large language model
(LLM) to infer the user's memory needs in a conversational context,
semantically search memories, and present minimal suggestions. The assistant
has two interaction modes: Query Mode for voicing queries and Queryless Mode
for on-demand predictive assistance, without explicit query. Our study of
(N=20) participants engaged in a real-time conversation demonstrated that using
Memoro reduced device interaction time and increased recall confidence while
preserving conversational quality. We report quantitative results and discuss
the preferences and experiences of users. This work contributes towards
utilizing LLMs to design wearable memory augmentation systems that are
minimally disruptive.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02136" title="Abstract">arXiv:2403.02136</a> [<a href="/pdf/2403.02136" title="Download PDF">pdf</a>, <a href="/format/2403.02136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point2Building: Reconstructing Buildings from Airborne LiDAR Point  Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Obukhov%2C+A">Anton Obukhov</a>, 
<a href="/search/cs?searchtype=author&query=Wegner%2C+J+D">Jan Dirk Wegner</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a learning-based approach to reconstruct buildings as 3D polygonal
meshes from airborne LiDAR point clouds. What makes 3D building reconstruction
from airborne LiDAR hard is the large diversity of building designs and
especially roof shapes, the low and varying point density across the scene, and
the often incomplete coverage of building facades due to occlusions by
vegetation or to the viewing angle of the sensor. To cope with the diversity of
shapes and inhomogeneous and incomplete object coverage, we introduce a
generative model that directly predicts 3D polygonal meshes from input point
clouds. Our autoregressive model, called Point2Building, iteratively builds up
the mesh by generating sequences of vertices and faces. This approach enables
our model to adapt flexibly to diverse geometries and building structures.
Unlike many existing methods that rely heavily on pre-processing steps like
exhaustive plane detection, our model learns directly from the point cloud
data, thereby reducing error propagation and increasing the fidelity of the
reconstruction. We experimentally validate our method on a collection of
airborne LiDAR data of Zurich, Berlin and Tallinn. Our method shows good
generalization to diverse urban styles.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02138" title="Abstract">arXiv:2403.02138</a> [<a href="/pdf/2403.02138" title="Download PDF">pdf</a>, <a href="/format/2403.02138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Facial Representation Learning with Facial Region  Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Patras%2C+I">Ioannis Patras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised pre-training has been proved to be effective in learning
transferable representations that benefit various visual tasks. This paper asks
this question: can self-supervised pre-training learn general facial
representations for various facial analysis tasks? Recent efforts toward this
goal are limited to treating each face image as a whole, i.e., learning
consistent facial representations at the image-level, which overlooks the
consistency of local facial representations (i.e., facial regions like eyes,
nose, etc). In this work, we make a first attempt to propose a novel
self-supervised facial representation learning framework to learn consistent
global and local facial representations, Facial Region Awareness (FRA).
Specifically, we explicitly enforce the consistency of facial regions by
matching the local facial representations across views, which are extracted
with learned heatmaps highlighting the facial regions. Inspired by the mask
prediction in supervised semantic segmentation, we obtain the heatmaps via
cosine similarity between the per-pixel projection of feature maps and facial
mask embeddings computed from learnable positional embeddings, which leverage
the attention mechanism to globally look up the facial image for facial
regions. To learn such heatmaps, we formulate the learning of facial mask
embeddings as a deep clustering problem by assigning the pixel features from
the feature maps to them. The transfer learning results on facial
classification and regression tasks show that our FRA outperforms previous
pre-trained models and more importantly, using ResNet as the unified backbone
for various tasks, our FRA achieves comparable or even better performance
compared with SOTA methods in facial analysis tasks.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02139" title="Abstract">arXiv:2403.02139</a> [<a href="/pdf/2403.02139" title="Download PDF">pdf</a>, <a href="/ps/2403.02139" title="Download PostScript">ps</a>, <a href="/format/2403.02139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis on aggregation and block smoothers in multigrid methods for  block Toeplitz linear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bolten%2C+M">Matthias Bolten</a>, 
<a href="/search/math?searchtype=author&query=Donatelli%2C+M">Marco Donatelli</a>, 
<a href="/search/math?searchtype=author&query=Ferrari%2C+P">Paola Ferrari</a>, 
<a href="/search/math?searchtype=author&query=Furci%2C+I">Isabella Furci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present novel improvements in the context of symbol-based multigrid
procedures for solving large block structured linear systems. We study the
application of an aggregation-based grid transfer operator that transforms the
symbol of a block Toeplitz matrix from matrix-valued to scalar-valued at the
coarser level. Our convergence analysis of the Two-Grid Method (TGM) reveals
the connection between the features of the scalar-valued symbol at the coarser
level and the properties of the original matrix-valued one. This allows us to
prove the convergence of a V-cycle multigrid with standard grid transfer
operators for scalar Toeplitz systems at the coarser levels. Consequently, we
extend the class of suitable smoothers for block Toeplitz matrices, focusing on
the efficiency of block strategies, particularly the relaxed block Jacobi
method. General conditions on smoothing parameters are derived, with emphasis
on practical applications where these parameters can be calculated with
negligible computational cost. We test the proposed strategies on linear
systems stemming from the discretization of differential problems with
$\mathbb{Q}_{d} $ Lagrangian FEM or B-spline with non-maximal regularity. The
numerical results show in both cases computational advantages compared to
existing methods for block structured linear systems.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02140" title="Abstract">arXiv:2403.02140</a> [<a href="/pdf/2403.02140" title="Download PDF">pdf</a>, <a href="/format/2403.02140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Algorithms in the Sparse Stochastic Block Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandenberger%2C+A">Anna Brandenberger</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+B">Byron Chin</a>, 
<a href="/search/cs?searchtype=author&query=Sheffield%2C+N+S">Nathan S. Sheffield</a>, 
<a href="/search/cs?searchtype=author&query=Shyamal%2C+D">Divya Shyamal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The stochastic block model (SBM) is a generalization of the
Erd\H{o}s--R\'enyi model of random graphs that describes the interaction of a
finite number of distinct communities. In sparse Erd\H{o}s--R\'enyi graphs, it
is known that a linear-time algorithm of Karp and Sipser achieves near-optimal
matching sizes asymptotically almost surely, giving a law-of-large numbers for
the matching sizes of such graphs in terms of solutions to an ODE. We provide
an extension of this analysis, identifying broad ranges of stochastic block
model parameters for which the Karp--Sipser algorithm achieves near-optimal
matching sizes, but demonstrating that it cannot perform optimally on general
SBM instances.
<br />We also consider the problem of constructing a matching online, in which the
vertices of one half of a bipartite stochastic block model arrive
one-at-a-time, and must be matched as they arrive. We show that the competitive
ratio lower bound of 0.837 found by Mastin and Jaillet for the
Erd\H{o}s--R\'enyi case is tight whenever the expected degrees in all
communities are equal. We propose several linear-time algorithms for online
matching in the general stochastic block model, but prove that despite very
good experimental performance, none of these achieve online asymptotic
optimality.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02141" title="Abstract">arXiv:2403.02141</a> [<a href="/pdf/2403.02141" title="Download PDF">pdf</a>, <a href="/format/2403.02141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Derivative Runge-Kutta Flux Reconstruction for hyperbolic  conservation laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Babbar%2C+A">Arpit Babbar</a>, 
<a href="/search/math?searchtype=author&query=Chandrashekar%2C+P">Praveen Chandrashekar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We extend the fourth order, two stage Multi-Derivative Runge Kutta (MDRK)
scheme of Li and Du to the Flux Reconstruction (FR) framework by writing both
of the stages in terms of a time averaged flux and then use the approximate
Lax-Wendroff procedure. Numerical flux is computed in each stage using D2
dissipation and EA flux, enhancing Fourier CFL stability and accuracy
respectively. A subcell based blending limiter is developed for the MDRK
scheme, which ensures that the limited scheme is provably admissibility
preserving. Along with being admissibility preserving, the blending scheme is
constructed to minimize dissipation errors by using Gauss-Legendre solution
points and performing MUSCL-Hancock reconstruction on subcells. The accuracy
enhancement of the blending scheme is numerically verified on compressible
Euler's equations, with test cases involving shocks and small-scale structures.
</p>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02145" title="Abstract">arXiv:2403.02145</a> [<a href="/pdf/2403.02145" title="Download PDF">pdf</a>, <a href="/ps/2403.02145" title="Download PostScript">ps</a>, <a href="/format/2403.02145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#x27;SSL?! What on earth is that?&#x27;: Towards Designing Age-Inclusive Secure  Smartphone Browsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pakianathan%2C+P+V+S">Pavithren V. S. Pakianathan</a>, 
<a href="/search/cs?searchtype=author&query=Siddharth%2C+L">L. Siddharth</a>, 
<a href="/search/cs?searchtype=author&query=Raviselvam%2C+S">Sujithra Raviselvam</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+K+L">Kristin L. Wood</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyowon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Foong%2C+P+S">Pin Sym Foong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Perrault%2C+S+T">Simon Tangi Perrault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version was last submitted to EuroUSEC 2023 - European Symposium on Usable Security. It was later invited for poster submission at the same conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Owing to the increase in 'certified' phishing websites, there is a steady
increase in the number of phishing cases and general susceptibility to
phishing. Trust mechanisms (e.g., HTTPS Lock Indicators, SSL Certificates) that
help differentiate genuine and phishing websites should therefore be evaluated
for their effectiveness in preventing vulnerable users from accessing phishing
websites. In this article, we present a study involving 18 adults (male-6;
female-12) and 12 older adults (male-4; female-8) to understand the usability
of current trust mechanisms and preferred modalities in a conceptualized
mechanism. In the first part of the study, using Chrome browser on Android, we
asked the participants to browse a banking website and a government website for
digital particulars. We asked them to identify which one of the two was a
phishing website, rate the usability of both websites and provide qualitative
feedback on the trust mechanisms. In the second part, we conceptualized an
alternative trust mechanism, which allows seeking social, community and
AI-based support to make website trust-related decisions. Herein, we asked the
participants as to which modality (social, community or AI) they prefer to seek
support from and why it is preferred. Using the current trust mechanisms, none
of the participants were able to identify the phishing website. As the
participants rated the current mechanisms poorly in terms of usability, they
expressed various difficulties that largely did not differ between adults and
older adults. In the conceptualized mechanism, we observed a notable difference
in the preferred modalities, in that, older adults primarily preferred social
support. In addition to these overall findings, specific observations suggest
that future trust mechanisms should not only consider age-specific needs but
also incorporate substantial improvement in terms of usability.
</p>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02148" title="Abstract">arXiv:2403.02148</a> [<a href="/pdf/2403.02148" title="Download PDF">pdf</a>, <a href="/format/2403.02148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhentao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Q">Qi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first Mamba-based model for infrared small target detection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Thanks to the development of basic models, infrared small target detection
(ISTD) algorithms have made significant progress. Specifically, the structures
combining convolutional networks with transformers can well extract both local
and global features. At the same time, they also inherit defects from the basic
model, e.g., the quadratic computational complexity of transformers, which
impacts efficiency. Inspired by a recent basic model with linear complexity for
long-distance modeling, called Mamba, we explore the potential of this state
space model in ISTD in this paper. However, direct application is unsuitable
since local features, which are critical to detecting small targets, cannot be
fully exploited. Instead, we tailor a Mamba-in-Mamba (MiM-ISTD) structure for
efficient ISTD. For example, we treat the local patches as "visual sentences"
and further decompose them into sub-patches as "visual words" to further
explore the locality. The interactions among each word in a given visual
sentence will be calculated with negligible computational costs. By aggregating
the word and sentence features, the representation ability of MiM-ISTD can be
significantly bolstered. Experiments on NUAA-SIRST and IRSTD-1k prove the
superior accuracy and efficiency of our method. Specifically, MiM-ISTD is $10
\times$ faster than the SOTA and reduces GPU memory usage by 73.4$\%$ per $2048
\times 2048$ image during inference, overcoming the computation$\&amp;$memory
constraints on performing Mamba-based understanding on high-resolution infrared
images.Source code is available at https://github.com/txchen-USTC/MiM-ISTD.
</p>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02151" title="Abstract">arXiv:2403.02151</a> [<a href="/pdf/2403.02151" title="Download PDF">pdf</a>, <a href="/format/2403.02151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TripoSR: Fast 3D Object Reconstruction from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tochilkin%2C+D">Dmitry Tochilkin</a>, 
<a href="/search/cs?searchtype=author&query=Pankratz%2C+D">David Pankratz</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zexiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Letts%2C+A">Adam Letts</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Ding Liang</a>, 
<a href="/search/cs?searchtype=author&query=Laforte%2C+C">Christian Laforte</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Model: <a href="https://huggingface.co/stabilityai/TripoSR">this https URL</a> Code: <a href="https://github.com/VAST-AI-Research/TripoSR">this https URL</a> Demo: <a href="https://huggingface.co/spaces/stabilityai/TripoSR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This technical report introduces TripoSR, a 3D reconstruction model
leveraging transformer architecture for fast feed-forward 3D generation,
producing 3D mesh from a single image in under 0.5 seconds. Building upon the
LRM network architecture, TripoSR integrates substantial improvements in data
processing, model design, and training techniques. Evaluations on public
datasets show that TripoSR exhibits superior performance, both quantitatively
and qualitatively, compared to other open-source alternatives. Released under
the MIT license, TripoSR is intended to empower researchers, developers, and
creatives with the latest advancements in 3D generative AI.
</p>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02160" title="Abstract">arXiv:2403.02160</a> [<a href="/pdf/2403.02160" title="Download PDF">pdf</a>, <a href="/ps/2403.02160" title="Download PostScript">ps</a>, <a href="/format/2403.02160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the arithmetic complexity of computing Gr&#xf6;bner bases of comaximal  determinantal ideals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+S">Sriram Gopalakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC)

</div>
<p class="mathjax">Let $M$ be an $n\times n$ matrix of homogeneous linear forms over a field
$\Bbbk$. If the ideal $\mathcal{I}_{n-2}(M)$ generated by minors of size $n-1$
is Cohen-Macaulay, then the Gulliksen-Neg{\aa}rd complex is a free resolution
of $\mathcal{I}_{n-2}(M)$. It has recently been shown that by taking into
account the syzygy modules for $\mathcal{I}_{n-2}(M)$ which can be obtained
from this complex, one can derive a refined signature-based Gr\"obner basis
algorithm DetGB which avoids reductions to zero when computing a grevlex
Gr\"obner basis for $\mathcal{I}_{n-2}(M)$. In this paper, we establish sharp
complexity bounds on DetGB. To accomplish this, we prove several results on the
sizes of reduced grevlex Gr\"obner bases of reverse lexicographic ideals,
thanks to which we obtain two main complexity results which rely on conjectures
similar to that of Fr\"oberg. The first one states that, in the
zero-dimensional case, the size of the reduced grevlex Gr\"obner basis of
$\mathcal{I}_{n-2}(M)$ is bounded from below by $n^{6}$ asymptotically. The
second, also in the zero-dimensional case, states that the complexity of DetGB
is bounded from above by $n^{2\omega+3}$ asymptotically, where $2\le\omega\le
3$ is any complexity exponent for matrix multiplication over $\Bbbk$.
</p>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02161" title="Abstract">arXiv:2403.02161</a> [<a href="/pdf/2403.02161" title="Download PDF">pdf</a>, <a href="/ps/2403.02161" title="Download PostScript">ps</a>, <a href="/format/2403.02161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveRec: Prototyping Probes by Framing Debug Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%B6derlein%2C+J">Jean-Baptiste D&#xf6;derlein</a> (ENS Rennes, France), 
<a href="/search/cs?searchtype=author&query=van+Rozen%2C+R">Riemer van Rozen</a> (CWI, Netherlands), 
<a href="/search/cs?searchtype=author&query=van+der+Storm%2C+T">Tijs van der Storm</a> (CWI, Netherlands / University of Groningen, Netherlands)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 16
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Context: In the first part of his 2012 presentation "Inventing on Principle",
Bret Victor gives a demo of a live code editor for Javascript which shows the
dynamic history of values of variables in real time. This form of live
programming has become known as "probes". Probes provide the programmer with
permanent and continuous insight into the dynamic evolution of function or
method variables, thus improving feedback and developer experience.
<br />Inquiry: Although Victor shows a working prototype of live probes in the
context of Javascript, he does not discuss strategies for implementing them.
Later work provides an implementation approach, but this requires a programming
language to be implemented on top of the GraalVM runtime. In this paper we
present **LiveRec**, a generic approach for implementing probes which can be
applied in the context of many programming languages, without requiring the
modification of compilers or run-time systems.
<br />Approach: **LiveRec** is based on reusing existing debug protocols to
implement probes. Methods or functions are compiled after every code change and
executed inside the debugger. During execution the evolution of all local
variables in the current stack frame are recorded and communicated back to the
editor or IDE for display to the user.
<br />Knowledge: It turns out that mainstream debug protocols are rich enough for
implementing live probes. Step-wise execution, code hot swapping, and stack
frame inspection provide the right granularity and sufficient information to
realize live probes, without modifying compilers or language runtimes.
Furthermore, it turns out that the recently proposed Debugger Adapter Protocol
(DAP) provides an even more generic approach of implementing live probes, but,
in some cases, at the cost of a significant performance penalty.
<br />Grounding: We have applied **LiveRec** to implement probes using stack
recording natively for Java through the Java Debug Interface (JDI), and through
the DAP for Java, Python, C, and Javascript, all requiring just modest amounts
of configuration code. We evaluate the run-time performance of all four probes
prototypes, decomposed into: compile-after-change, hot swap, single step
overhead, and stack recording overhead. Our initial results show that live
probes on top of native debug APIs can be performant enough for interactive
use. In the case of DAP, however, it highly depends on characteristics of the
programming language implementation and its associated debugging
infrastructure.
<br />Importance: Live programming improves the programmer experience by providing
immediate feedback about a program's execution and eliminating disruptive
edit-compile-restart sequences. Probes are one way to shorten the programmer
feedback loop at the level of functions and methods. Although probes are not
new, and have been implemented in (prototype) systems, **LiveRec**'s approach
of building live probes on top of existing and generic debug protocols promises
a path towards probes for a host of mainstream programming languages, with
reasonable effort.
</p>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02164" title="Abstract">arXiv:2403.02164</a> [<a href="/pdf/2403.02164" title="Download PDF">pdf</a>, <a href="/ps/2403.02164" title="Download PostScript">ps</a>, <a href="/format/2403.02164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognition is All You Need - The Next Layer of AI Above Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spivack%2C+N">Nova Spivack</a>, 
<a href="/search/cs?searchtype=author&query=Douglas%2C+S">Sam Douglas</a>, 
<a href="/search/cs?searchtype=author&query=Crames%2C+M">Michelle Crames</a>, 
<a href="/search/cs?searchtype=author&query=Connors%2C+T">Tim Connors</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Recent studies of the applications of conversational AI tools, such as
chatbots powered by large language models, to complex real-world knowledge work
have shown limitations related to reasoning and multi-step problem solving.
Specifically, while existing chatbots simulate shallow reasoning and
understanding they are prone to errors as problem complexity increases. The
failure of these systems to address complex knowledge work is due to the fact
that they do not perform any actual cognition. In this position paper, we
present Cognitive AI, a higher-level framework for implementing
programmatically defined neuro-symbolic cognition above and outside of large
language models. Specifically, we propose a dual-layer functional architecture
for Cognitive AI that serves as a roadmap for AI systems that can perform
complex multi-step knowledge work. We propose that Cognitive AI is a necessary
precursor for the evolution of higher forms of AI, such as AGI, and
specifically claim that AGI cannot be achieved by probabilistic approaches on
their own. We conclude with a discussion of the implications for large language
models, adoption cycles in AI, and commercial Cognitive AI development.
</p>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02170" title="Abstract">arXiv:2403.02170</a> [<a href="/pdf/2403.02170" title="Download PDF">pdf</a>, <a href="/format/2403.02170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VITAMIN: A Compositional Framework for Model Checking of Multi-Agent  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrando%2C+A">Angelo Ferrando</a>, 
<a href="/search/cs?searchtype=author&query=Malvone%2C+V">Vadim Malvone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Logic in Computer Science (cs.LO); Software Engineering (cs.SE)

</div>
<p class="mathjax">The verification of Multi-Agent Systems (MAS) poses a significant challenge.
Various approaches and methodologies exist to address this challenge; however,
tools that support them are not always readily available. Even when such tools
are accessible, they tend to be hard-coded, lacking in compositionality, and
challenging to use due to a steep learning curve. In this paper, we introduce a
methodology designed for the formal verification of MAS in a modular and
versatile manner, along with an initial prototype, that we named VITAMIN.
Unlike existing verification methodologies and frameworks for MAS, VITAMIN is
constructed for easy extension to accommodate various logics (for specifying
the properties to verify) and models (for determining on what to verify such
properties).
</p>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02172" title="Abstract">arXiv:2403.02172</a> [<a href="/pdf/2403.02172" title="Download PDF">pdf</a>, <a href="/ps/2403.02172" title="Download PostScript">ps</a>, <a href="/format/2403.02172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirage: Defense against CrossPath Attacks in Software Defined Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murtuza%2C+S">Shariq Murtuza</a>, 
<a href="/search/cs?searchtype=author&query=Asawa%2C+K">Krishna Asawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Software-Defined Networks (SDNs) face persistent threats from various
adversaries that attack them using different methods to mount Denial of Service
attacks. These attackers have different motives and follow diverse tactics to
achieve their nefarious objectives. In this work, we focus on the impact of
CrossPath attacks in SDNs and introduce our framework, Mirage, which not only
detects but also mitigates this attack. Our framework, Mirage, detects SDN
switches that become unreachable due to being under attack, takes proactive
measures to prevent Adversarial Path Reconnaissance, and effectively mitigates
CrossPath attacks in SDNs. A CrossPath attack is a form of link flood attack
that indirectly attacks the control plane by overwhelming the shared links that
connect the data and control planes with data plane traffic. This attack is
exclusive to in band SDN, where the data and the control plane, both utilize
the same physical links for transmitting and receiving traffic. Our framework,
Mirage, prevents attackers from launching adversarial path reconnaissance to
identify shared links in a network, thereby thwarting their abuse and
preventing this attack. Mirage not only stops adversarial path reconnaissance
but also includes features to quickly counter ongoing attacks once detected.
Mirage uses path diversity to reroute network packet to prevent timing based
measurement. Mirage can also enforce short lived flow table rules to prevent
timing attacks. These measures are carefully designed to enhance the security
of the SDN environment. Moreover, we share the results of our experiments,
which clearly show Mirage's effectiveness in preventing path reconnaissance,
detecting CrossPath attacks, and mitigating ongoing threats. Our framework
successfully protects the network from these harmful activities, giving
valuable insights into SDN security.
</p>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02173" title="Abstract">arXiv:2403.02173</a> [<a href="/pdf/2403.02173" title="Download PDF">pdf</a>, <a href="/format/2403.02173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What has LeBenchmark Learnt about French Syntax?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dugonji%C4%87%2C+Z">Zdravko Dugonji&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Pupier%2C+A">Adrien Pupier</a>, 
<a href="/search/cs?searchtype=author&query=Lecouteux%2C+B">Benjamin Lecouteux</a>, 
<a href="/search/cs?searchtype=author&query=Coavoux%2C+M">Maximin Coavoux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The paper reports on a series of experiments aiming at probing LeBenchmark, a
pretrained acoustic model trained on 7k hours of spoken French, for syntactic
information. Pretrained acoustic models are increasingly used for downstream
speech tasks such as automatic speech recognition, speech translation, spoken
language understanding or speech parsing. They are trained on very low level
information (the raw speech signal), and do not have explicit lexical
knowledge. Despite that, they obtained reasonable results on tasks that
requires higher level linguistic knowledge. As a result, an emerging question
is whether these models encode syntactic information. We probe each
representation layer of LeBenchmark for syntax, using the Orf\'eo treebank, and
observe that it has learnt some syntactic information. Our results show that
syntactic information is more easily extractable from the middle layers of the
network, after which a very sharp decrease is observed.
</p>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02175" title="Abstract">arXiv:2403.02175</a> [<a href="/pdf/2403.02175" title="Download PDF">pdf</a>, <a href="/format/2403.02175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiSTA: Geometric Object-Based Change Detection in Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rowell%2C+J">Joseph Rowell</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lintong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fallon%2C+M">Maurice Fallon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6+n page limit for (accepted) ICRA 2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present LiSTA (LiDAR Spatio-Temporal Analysis), a system to detect
probabilistic object-level change over time using multi-mission SLAM. Many
applications require such a system, including construction, robotic navigation,
long-term autonomy, and environmental monitoring. We focus on the semi-static
scenario where objects are added, subtracted, or changed in position over weeks
or months. Our system combines multi-mission LiDAR SLAM, volumetric
differencing, object instance description, and correspondence grouping using
learned descriptors to keep track of an open set of objects. Object
correspondences between missions are determined by clustering the object's
learned descriptors. We demonstrate our approach using datasets collected in a
simulated environment and a real-world dataset captured using a LiDAR system
mounted on a quadruped robot monitoring an industrial facility containing
static, semi-static, and dynamic objects. Our method demonstrates superior
performance in detecting changes in semi-static environments compared to
existing methods.
</p>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02176" title="Abstract">arXiv:2403.02176</a> [<a href="/pdf/2403.02176" title="Download PDF">pdf</a>, <a href="/format/2403.02176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEE-QA: Exploring Effective and Efficient Question-Answer  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhanghao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yifu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pinzhen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Current approaches to question answering rely on pre-trained language models
(PLMs) like RoBERTa. This work challenges the existing question-answer encoding
convention and explores finer representations. We begin with testing various
pooling methods compared to using the begin-of-sentence token as a question
representation for better quality. Next, we explore opportunities to
simultaneously embed all answer candidates with the question. This enables
cross-reference between answer choices and improves inference throughput via
reduced memory usage. Despite their simplicity and effectiveness, these methods
have yet to be widely studied in current frameworks. We experiment with
different PLMs, and with and without the integration of knowledge graphs.
Results prove that the memory efficacy of the proposed techniques with little
sacrifice in performance. Practically, our work enhances 38-100% throughput
with 26-65% speedups on consumer-grade GPUs by allowing for considerably larger
batch sizes. Our work sends a message to the community with promising
directions in both representation quality and efficiency for the
question-answering task in natural language processing.
</p>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02177" title="Abstract">arXiv:2403.02177</a> [<a href="/pdf/2403.02177" title="Download PDF">pdf</a>, <a href="/format/2403.02177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProTrix: Building Models for Planning and Reasoning over Tables with  Sentence Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zirui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yansong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Tables play a crucial role in conveying information in various domains,
serving as indispensable tools for organizing and presenting data in a
structured manner. We propose a Plan-then-Reason framework to answer different
types of user queries over tables with sentence context. The framework first
plans the reasoning paths over the context, then assigns each step to
program-based or textual reasoning to reach the final answer. We construct an
instruction tuning set TrixInstruct following the framework. Our dataset cover
queries that are program-unsolvable or need combining information from tables
and sentences to obtain planning and reasoning abilities. We present ProTrix by
finetuning Llama-2-7B on TrixInstruct. Our experiments show that ProTrix
generalizes to diverse tabular tasks and achieves comparable performance to
GPT-3.5-turbo. We further demonstrate that ProTrix can generate accurate and
faithful explanations to answer complex free-form questions. Our work
underscores the importance of the planning and reasoning abilities towards a
model over tabular tasks with generalizability and interpretability. We will
release our dataset and model at https://github.com/WilliamZR/ProTrix.
</p>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02178" title="Abstract">arXiv:2403.02178</a> [<a href="/pdf/2403.02178" title="Download PDF">pdf</a>, <a href="/format/2403.02178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Thought: Simply Masking Partial Reasoning Steps Can Improve  Mathematical Reasoning Learning of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Ting-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+A">Ang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In reasoning tasks, even a minor error can cascade into inaccurate results,
leading to suboptimal performance of large language models in such domains.
Earlier fine-tuning approaches sought to mitigate this by leveraging more
precise supervisory signals from human labeling, larger models, or
self-sampling, although at a high cost. Conversely, we develop a method that
avoids external resources, relying instead on introducing perturbations to the
input. Our training approach randomly masks certain tokens within the chain of
thought, a technique we found to be particularly effective for reasoning tasks.
When applied to fine-tuning with GSM8K, this method achieved a 5% improvement
in accuracy over standard supervised fine-tuning with a few codes modified and
no additional labeling effort. Furthermore, it is complementary to existing
methods. When integrated with related data augmentation methods, it leads to an
average improvement of 3% improvement in GSM8K accuracy and 1% improvement in
MATH accuracy across five datasets of various quality and size, as well as two
base models. We further investigate the mechanisms behind this improvement
through case studies and quantitative analysis, suggesting that our approach
may provide superior support for the model in capturing long-distance
dependencies, especially those related to questions. This enhancement could
deepen understanding of premises in questions and prior steps. Our code is
available at Github.
</p>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02181" title="Abstract">arXiv:2403.02181</a> [<a href="/pdf/2403.02181" title="Download PDF">pdf</a>, <a href="/format/2403.02181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not all Layers of LLMs are Necessary during Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xuying Meng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Peng Han</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Shuo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Aixin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The inference phase of Large Language Models (LLMs) is very expensive. An
ideal inference stage of LLMs could utilize fewer computational resources while
still maintaining its capabilities (e.g., generalization and in-context
learning ability). In this paper, we try to answer the question, "During LLM
inference, can we use shallow layers for easy instances; and deep layers for
hard ones?" To answer this question, we first indicate that Not all Layers are
Necessary during Inference by statistically analyzing the activated layers
across tasks. Then, we propose a simple algorithm named AdaInfer to determine
the inference termination moment based on the input instance adaptively. More
importantly, AdaInfer does not alter LLM parameters and maintains
generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2
series and OPT) show that AdaInfer saves an average of 14.8% of computational
resources, even up to 50% on sentiment tasks, while maintaining comparable
performance. Additionally, this method is orthogonal to other model
acceleration techniques, potentially boosting inference efficiency further.
</p>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02183" title="Abstract">arXiv:2403.02183</a> [<a href="/pdf/2403.02183" title="Download PDF">pdf</a>, <a href="/ps/2403.02183" title="Download PostScript">ps</a>, <a href="/format/2403.02183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Allocator Abstraction to Control Object Spatial Locality in  C++
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hideshima%2C+T">Takato Hideshima</a> (University of Tokyo, Japan), 
<a href="/search/cs?searchtype=author&query=Sato%2C+S">Shigeyuki Sato</a> (University of Electro-Communications, Japan), 
<a href="/search/cs?searchtype=author&query=Ugawa%2C+T">Tomoharu Ugawa</a> (University of Tokyo, Japan)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 15
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Disaggregated memory is promising for improving memory utilization in
computer clusters in which memory demands significantly vary across computer
nodes under utilization. It allows applications with high memory demands to use
memory in other computer nodes.
<br />However, disaggregated memory is not easy to use for implementing data
structures in C++ because the C++ standard does not provide an adequate
abstraction to use it efficiently in a high-level, modular manner. Because
accessing remote memory involves high latency, disaggregated memory is often
used as a far-memory system, which forms a kind of swap memory where part of
local memory is used as a cache area, while the remaining memory is not subject
to swapping. To pursue performance, programmers have to be aware of this
nonuniform memory view and place data appropriately to minimize swapping.
<br />In this work, we model the address space of memory-disaggregated systems as
the far-memory model, present the collective allocator abstraction, which
enables us to specify object placement aware of memory address subspaces, and
apply it to programming aware of the far-memory model.
<br />The far-memory model provides a view of the nonuniform memory space while
hiding the details. In the model, the virtual address space is divided into two
subspaces; one is subject to swapping and the other is not. The swapping
subspace is further divided into even-sized pages, which are units of swapping.
The collective allocator abstraction forms an allocator as a collection of
sub-allocators, each of which owns a distinct subspace, where every allocation
is done via sub-allocators. It enables us to control object placement at
allocation time by selecting an appropriate sub-allocator according to
different criteria, such as subspace characteristics and object collocation. It
greatly facilitates implementing container data structures aware of the
far-memory model.
<br />We develop an allocator based on the collective allocator abstraction by
extending the C++ standard allocator for container data structures on the
far-memory model and experimentally demonstrate that it facilitates
implementing containers equipped with object placement strategies aware of
spatial locality under the far-memory model in a high-level, modular manner.
More specifically, we have successfully implemented B-trees and skip lists with
the combined use of two placement strategies. The modifications therein for the
original implementations are fairly modest: addition is mostly due to
specifying object placement; deletion and modification are at most 1.2 % and
3.2 % of lines of the original code, respectively. We have experimentally
confirmed that the modified implementations successfully have data layouts
suppressing swapping.
<br />We forecast that the collective allocator abstraction would be a key to
high-level integration with different memory hardware technologies because it
straightforwardly accommodates new interfaces for subspaces.
</p>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02185" title="Abstract">arXiv:2403.02185</a> [<a href="/pdf/2403.02185" title="Download PDF">pdf</a>, <a href="/format/2403.02185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilled ChatGPT Topic &amp; Sentiment Modeling with Applications in  Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandouet%2C+O">Olivier Gandouet</a>, 
<a href="/search/cs?searchtype=author&query=Belbahri%2C+M">Mouloud Belbahri</a>, 
<a href="/search/cs?searchtype=author&query=Jezequel%2C+A">Armelle Jezequel</a>, 
<a href="/search/cs?searchtype=author&query=Bodjov%2C+Y">Yuriy Bodjov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edge Intelligence Workshop at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL)

</div>
<p class="mathjax">In this study, ChatGPT is utilized to create streamlined models that generate
easily interpretable features. These features are then used to evaluate
financial outcomes from earnings calls. We detail a training approach that
merges knowledge distillation and transfer learning, resulting in lightweight
topic and sentiment classification models without significant loss in accuracy.
These models are assessed through a dataset annotated by experts. The paper
also delves into two practical case studies, highlighting how the generated
features can be effectively utilized in quantitative investing scenarios.
</p>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02187" title="Abstract">arXiv:2403.02187</a> [<a href="/pdf/2403.02187" title="Download PDF">pdf</a>, <a href="/ps/2403.02187" title="Download PostScript">ps</a>, <a href="/format/2403.02187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Information Estimation via Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butakov%2C+I">Ivan Butakov</a>, 
<a href="/search/cs?searchtype=author&query=Tolmachev%2C+A">Aleksander Tolmachev</a>, 
<a href="/search/cs?searchtype=author&query=Malanchuk%2C+S">Sofia Malanchuk</a>, 
<a href="/search/cs?searchtype=author&query=Neopryatnaya%2C+A">Anna Neopryatnaya</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+A">Alexey Frolov</a>, 
<a href="/search/cs?searchtype=author&query=Andreev%2C+K">Kirill Andreev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a novel approach to the problem of mutual information (MI)
estimation via introducing normalizing flows-based estimator. The estimator
maps original data to the target distribution with known closed-form expression
for MI. We demonstrate that our approach yields MI estimates for the original
data. Experiments with high-dimensional data are provided to show the
advantages of the proposed estimator.
</p>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02198" title="Abstract">arXiv:2403.02198</a> [<a href="/pdf/2403.02198" title="Download PDF">pdf</a>, <a href="/ps/2403.02198" title="Download PostScript">ps</a>, <a href="/format/2403.02198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Payment Scheduling in the Interval Debt Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedetzky%2C+T">Tom Friedetzky</a>, 
<a href="/search/cs?searchtype=author&query=Kutner%2C+D+C">David C. Kutner</a>, 
<a href="/search/cs?searchtype=author&query=Mertzios%2C+G+B">George B. Mertzios</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+I+A">Iain A. Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Trehan%2C+A">Amitabh Trehan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The network-based study of financial systems has received considerable
attention in recent years but has seldom explicitly incorporated the dynamic
aspects of such systems. We consider this problem setting from the temporal
point of view and introduce the Interval Debt Model (IDM) and some scheduling
problems based on it, namely: Bankruptcy Minimization/Maximization, in which
the aim is to produce a payment schedule with at most/at least a given number
of bankruptcies; Perfect Scheduling, the special case of the minimization
variant where the aim is to produce a schedule with no bankruptcies (that is, a
perfect schedule); and Bailout Minimization, in which a financial authority
must allocate a smallest possible bailout package to enable a perfect schedule.
We show that each of these problems is NP-complete, in many cases even on very
restricted input instances. On the positive side, we provide for Perfect
Scheduling a polynomial-time algorithm on (rooted) out-trees although in
contrast we prove NP-completeness on directed acyclic graphs, as well as on
instances with a constant number of nodes (and hence also constant treewidth).
When we allow non-integer payments, we show by a linear programming argument
that the problem Bailout Minimization can be solved in polynomial time.
</p>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02199" title="Abstract">arXiv:2403.02199</a> [<a href="/pdf/2403.02199" title="Download PDF">pdf</a>, <a href="/format/2403.02199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piet: Facilitating Color Authoring for Motion Graphics Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xinyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinghou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Motion graphic (MG) videos are effective and compelling for presenting
complex concepts through animated visuals; and colors are important to convey
desired emotions, maintain visual continuity, and signal narrative transitions.
However, current video color authoring workflows are fragmented, lacking
contextual previews, hindering rapid theme adjustments, and not aligning with
progressive authoring flows of designers. To bridge this gap, we introduce
Piet, the first tool tailored for MG video color authoring. Piet features an
interactive palette to visually represent color distributions, support
controllable focus levels, and enable quick theme probing via grouped color
shifts. We interviewed 6 domain experts to identify the frustrations in current
tools and inform the design of Piet. An in-lab user study with 13 expert
designers showed that Piet effectively simplified the MG video color authoring
and reduced the friction in creative color theme exploration.
</p>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02200" title="Abstract">arXiv:2403.02200</a> [<a href="/pdf/2403.02200" title="Download PDF">pdf</a>, <a href="/ps/2403.02200" title="Download PostScript">ps</a>, <a href="/format/2403.02200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduling Garbage Collection for Energy Efficiency on Asymmetric  Multicore Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimchenko%2C+M">Marina Shimchenko</a> (Uppsala University, Sweden), 
<a href="/search/cs?searchtype=author&query=%C3%96sterlund%2C+E">Erik &#xd6;sterlund</a> (Oracle, Sweden), 
<a href="/search/cs?searchtype=author&query=Wrigstad%2C+T">Tobias Wrigstad</a> (Uppsala University, Sweden)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The growing concern for energy efficiency in the Information and
Communication Technology (ICT) sector has prompted the exploration of resource
management techniques. While hardware architectures, such as single-ISA
asymmetric multicore processors (AMP), offer potential energy savings, there is
still untapped potential for software optimizations. This paper aims to bridge
this gap by investigating the scheduling of garbage collection (GC) activities
on a heterogeneous architecture with both performance cores ("p-cores") and
energy cores ("e-cores") to achieve energy savings.
<br />Our study focuses on the concurrent ZGC collector in the context of Java
Virtual Machines (JVM), as the energy aspect is not well studied in the context
of latency-sensitive Java workloads. By comparing the energy efficiency,
performance, latency, and memory utilization of executing GC on p-cores versus
e-cores, we present compelling findings.
<br />We demonstrate that scheduling GC work on e-cores overall leads to
approximately 3% energy savings without performance and mean latency
degradation while requiring no additional effort from developers. Overall
energy reduction can increase to 5.3$\pm$0.0225% by tuning the number of
e-cores (still not changing the program!).
<br />Our findings highlight the practicality and benefits of scheduling GC on
e-cores, showcasing the potential for energy savings in heterogeneous
architectures running Java workloads while meeting critical latency
requirements. Our research contributes to the ongoing efforts toward achieving
a more sustainable and efficient ICT sector.
</p>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02202" title="Abstract">arXiv:2403.02202</a> [<a href="/pdf/2403.02202" title="Download PDF">pdf</a>, <a href="/format/2403.02202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Interactive Color Palettes for Abstraction-Driven Exploratory  Image Colorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xinyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Neshati%2C+A">Ali Neshati</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R">Ryan Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Color design is essential in areas such as product, graphic, and fashion
design. However, current tools like Photoshop, with their concrete-driven color
manipulation approach, often stumble during early ideation, favoring polished
end results over initial exploration. We introduced Mondrian as a test-bed for
abstraction-driven approach using interactive color palettes for image
colorization. Through a formative study with six design experts, we selected
three design options for visual abstractions in color design and developed
Mondrian where humans work with abstractions and AI manages the concrete
aspects. We carried out a user study to understand the benefits and challenges
of each abstraction format and compare the Mondrian with Photoshop. A survey
involving 100 participants further examined the influence of each abstraction
format on color composition perceptions. Findings suggest that interactive
visual abstractions encourage a non-linear exploration workflow and an open
mindset during ideation, thus providing better creative affordance.
</p>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02210" title="Abstract">arXiv:2403.02210</a> [<a href="/pdf/2403.02210" title="Download PDF">pdf</a>, <a href="/ps/2403.02210" title="Download PostScript">ps</a>, <a href="/format/2403.02210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unknown Biases and Timing Constraints in Timed Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haase%2C+D">Darion Haase</a>, 
<a href="/search/cs?searchtype=author&query=Katoen%2C+J">Joost-Pieter Katoen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Timed automata are the formal model for real-time systems. Extensions with
discrete probabilistic branching have been considered in the literature and
successfully applied. Probabilistic timed automata (PTA) do require all
branching probabilities and clock constraints to be constants. This report
investigates PTA in which this constraint is relaxed: both branching
probabilities and clock constraints can be parametric. We formally define this
PTA variant and define its semantics by an uncountable parametric Markov
Decision Process (pMDP). We show that reachability probabilities in parametric
L/U-PTA can be reduced to considering PTA with only parametric branching
probabilities. This enables the usage of existing techniques from the
literature. Finally, we generalize the symbolic backward and digital clock
semantics of PTA to the setting with parametric probabilities and constraints.
</p>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02211" title="Abstract">arXiv:2403.02211</a> [<a href="/pdf/2403.02211" title="Download PDF">pdf</a>, <a href="/format/2403.02211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptive self-supervised learning network for noisy image watermark  removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chunwei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Menghua Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shichao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">David Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Popular methods usually use a degradation model in a supervised way to learn
a watermark removal model. However, it is true that reference images are
difficult to obtain in the real world, as well as collected images by cameras
suffer from noise. To overcome these drawbacks, we propose a perceptive
self-supervised learning network for noisy image watermark removal (PSLNet) in
this paper. PSLNet depends on a parallel network to remove noise and
watermarks. The upper network uses task decomposition ideas to remove noise and
watermarks in sequence. The lower network utilizes the degradation model idea
to simultaneously remove noise and watermarks. Specifically, mentioned paired
watermark images are obtained in a self supervised way, and paired noisy images
(i.e., noisy and reference images) are obtained in a supervised way. To enhance
the clarity of obtained images, interacting two sub-networks and fusing
obtained clean images are used to improve the effects of image watermark
removal in terms of structural information and pixel enhancement. Taking into
texture information account, a mixed loss uses obtained images and features to
achieve a robust model of noisy image watermark removal. Comprehensive
experiments show that our proposed method is very effective in comparison with
popular convolutional neural networks (CNNs) for noisy image watermark removal.
Codes can be obtained at https://github.com/hellloxiaotian/PSLNet.
</p>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02212" title="Abstract">arXiv:2403.02212</a> [<a href="/pdf/2403.02212" title="Download PDF">pdf</a>, <a href="/ps/2403.02212" title="Download PostScript">ps</a>, <a href="/format/2403.02212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint Satisfaction Problems with Advice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghoshal%2C+S">Suprovat Ghoshal</a>, 
<a href="/search/cs?searchtype=author&query=Makarychev%2C+K">Konstantin Makarychev</a>, 
<a href="/search/cs?searchtype=author&query=Makarychev%2C+Y">Yury Makarychev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We initiate the study of algorithms for constraint satisfaction problems with
ML oracle advice. We introduce two models of advice and then design an
approximation algorithm for Max Cut and Max 2-Lin in these models.
</p>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02215" title="Abstract">arXiv:2403.02215</a> [<a href="/pdf/2403.02215" title="Download PDF">pdf</a>, <a href="/format/2403.02215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Parameter and Parameterization Inference with Uncertainty  Quantification through Differentiable Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yongquan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Bhouri%2C+M+A">Mohamed Aziz Bhouri</a>, 
<a href="/search/cs?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Accurate representations of unknown and sub-grid physical processes through
parameterizations (or closure) in numerical simulations with quantified
uncertainty are critical for resolving the coarse-grained partial differential
equations that govern many problems ranging from weather and climate prediction
to turbulence simulations. Recent advances have seen machine learning (ML)
increasingly applied to model these subgrid processes, resulting in the
development of hybrid physics-ML models through the integration with numerical
solvers. In this work, we introduce a novel framework for the joint estimation
and uncertainty quantification of physical parameters and machine learning
parameterizations in tandem, leveraging differentiable programming. Achieved
through online training and efficient Bayesian inference within a
high-dimensional parameter space, this approach is enabled by the capabilities
of differentiable programming. This proof of concept underscores the
substantial potential of differentiable programming in synergistically
combining machine learning with differential equations, thereby enhancing the
capabilities of hybrid physics-ML modeling.
</p>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02217" title="Abstract">arXiv:2403.02217</a> [<a href="/pdf/2403.02217" title="Download PDF">pdf</a>, <a href="/format/2403.02217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DragTex: Generative Point-Based Texture Editing on 3D Mesh
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating 3D textured meshes using generative artificial intelligence has
garnered significant attention recently. While existing methods support
text-based generative texture generation or editing on 3D meshes, they often
struggle to precisely control pixels of texture images through more intuitive
interaction. While 2D images can be edited generatively using drag interaction,
applying this type of methods directly to 3D mesh textures still leads to
issues such as the lack of local consistency among multiple views, error
accumulation and long training times. To address these challenges, we propose a
generative point-based 3D mesh texture editing method called DragTex. This
method utilizes a diffusion model to blend locally inconsistent textures in the
region near the deformed silhouette between different views, enabling locally
consistent texture editing. Besides, we fine-tune a decoder to reduce
reconstruction errors in the non-drag region, thereby mitigating overall error
accumulation. Moreover, we train LoRA using multi-view images instead of
training each view individually, which significantly shortens the training
time. The experimental results show that our method effectively achieves
dragging textures on 3D meshes and generates plausible textures that align with
the desired intent of drag interaction.
</p>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02221" title="Abstract">arXiv:2403.02221</a> [<a href="/pdf/2403.02221" title="Download PDF">pdf</a>, <a href="/format/2403.02221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yilong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiyong Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic prediction constitutes a pivotal facet within the purview of
Intelligent Transportation Systems (ITS), and the attainment of highly precise
predictions holds profound significance for efficacious traffic management. The
precision of prevailing deep learning-driven traffic prediction models
typically sees an upward trend with a rise in the volume of training data.
However, the procurement of comprehensive spatiotemporal datasets for traffic
is often fraught with challenges, primarily stemming from the substantial costs
associated with data collection and retention. Consequently, developing a model
that can achieve accurate predictions and good generalization ability in areas
with limited historical traffic data is a challenging problem. It is noteworthy
that the rapidly advancing pretrained Large Language Models (LLMs) of recent
years have demonstrated exceptional proficiency in cross-modality knowledge
transfer and few-shot learning. Recognizing the sequential nature of traffic
data, similar to language, we introduce TPLLM, a novel traffic prediction
framework leveraging LLMs. In this framework, we construct a sequence embedding
layer based on Convolutional Neural Networks (CNNs) and a graph embedding layer
based on Graph Convolutional Networks (GCNs) to extract sequence features and
spatial features, respectively. These are subsequently integrated to form
inputs that are suitable for LLMs. A Low-Rank Adaptation (LoRA) fine-tuning
approach is applied to TPLLM, thereby facilitating efficient learning and
minimizing computational demands. Experiments on two real-world datasets
demonstrate that TPLLM exhibits commendable performance in both full-sample and
few-shot prediction scenarios, effectively supporting the development of ITS in
regions with scarce historical traffic data.
</p>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02225" title="Abstract">arXiv:2403.02225</a> [<a href="/pdf/2403.02225" title="Download PDF">pdf</a>, <a href="/format/2403.02225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Trust in Data for IoT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Margaria%2C+D">Davide Margaria</a>, 
<a href="/search/cs?searchtype=author&query=Carelli%2C+A">Alberto Carelli</a>, 
<a href="/search/cs?searchtype=author&query=Vesco%2C+A">Andrea Vesco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Nowadays, Internet of Things platforms are being deployed in a wide range of
application domains. Some of these include use cases with security
requirements, where the data generated by an IoT node is the basis for making
safety-critical or liability-critical decisions at system level. The challenge
is to develop a solution for data exchange while proving and verifying the
authenticity of the data from end-to-end. In line with this objective, this
paper proposes a novel solution with the proper protocols to provide Trust in
Data, making use of two Roots of Trust that are the IOTA Distributed Ledger
Technology and the Trusted Platform Module. The paper presents the design of
the proposed solution and discusses the key design aspects and relevant
trade-offs. The paper concludes with a Proof-of-Concept implementation and an
experimental evaluation to confirm its feasibility and to assess the achievable
performance.
</p>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02227" title="Abstract">arXiv:2403.02227</a> [<a href="/pdf/2403.02227" title="Download PDF">pdf</a>, <a href="/format/2403.02227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Space Response Oracles: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bighashdel%2C+A">Ariyan Bighashdel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=McAleer%2C+S">Stephen McAleer</a>, 
<a href="/search/cs?searchtype=author&query=Savani%2C+R">Rahul Savani</a>, 
<a href="/search/cs?searchtype=author&query=Oliehoek%2C+F+A">Frans A. Oliehoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ariyan Bighashdel and Yongzhao Wang contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In game theory, a game refers to a model of interaction among rational
decision-makers or players, making choices with the goal of achieving their
individual objectives. Understanding their behavior in games is often referred
to as game reasoning. This survey provides a comprehensive overview of a
fast-developing game-reasoning framework for large games, known as Policy Space
Response Oracles (PSRO). We first motivate PSRO, provide historical context,
and position PSRO within game-reasoning approaches. We then focus on the
strategy exploration issue for PSRO, the challenge of assembling an effective
strategy portfolio for modeling the underlying game with minimum computational
cost. We also survey current research directions for enhancing the efficiency
of PSRO, and explore the applications of PSRO across various domains. We
conclude by discussing open questions and future research.
</p>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02231" title="Abstract">arXiv:2403.02231</a> [<a href="/pdf/2403.02231" title="Download PDF">pdf</a>, <a href="/format/2403.02231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CODE-ACCORD: A Corpus of Building Regulatory Data for Rule Generation  towards Automatic Compliance Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hettiarachchi%2C+H">Hansi Hettiarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Dridi%2C+A">Amna Dridi</a>, 
<a href="/search/cs?searchtype=author&query=Gaber%2C+M+M">Mohamed Medhat Gaber</a>, 
<a href="/search/cs?searchtype=author&query=Parsafard%2C+P">Pouyan Parsafard</a>, 
<a href="/search/cs?searchtype=author&query=Bocaneala%2C+N">Nicoleta Bocaneala</a>, 
<a href="/search/cs?searchtype=author&query=Breitenfelder%2C+K">Katja Breitenfelder</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+G">Gon&#xe7;al Costa</a>, 
<a href="/search/cs?searchtype=author&query=Hedblom%2C+M">Maria Hedblom</a>, 
<a href="/search/cs?searchtype=author&query=Juganaru-Mathieu%2C+M">Mihaela Juganaru-Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Mecharnia%2C+T">Thamer Mecharnia</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sumee Park</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">He Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tawil%2C+A+H">Abdel-Rahman H. Tawil</a>, 
<a href="/search/cs?searchtype=author&query=Vakaj%2C+E">Edlira Vakaj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of an article submitted to the Data in Brief Journal, Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Automatic Compliance Checking (ACC) within the Architecture, Engineering, and
Construction (AEC) sector necessitates automating the interpretation of
building regulations to achieve its full potential. However, extracting
information from textual rules to convert them to a machine-readable format has
been a challenge due to the complexities associated with natural language and
the limited resources that can support advanced machine-learning techniques. To
address this challenge, we introduce CODE-ACCORD, a unique dataset compiled
under the EU Horizon ACCORD project. CODE-ACCORD comprises 862 self-contained
sentences extracted from the building regulations of England and Finland.
Aligned with our core objective of facilitating information extraction from
text for machine-readable rule generation, each sentence was annotated with
entities and relations. Entities represent specific components such as "window"
and "smoke detectors", while relations denote semantic associations between
these entities, collectively capturing the conveyed ideas in natural language.
We manually annotated all the sentences using a group of 12 annotators. Each
sentence underwent annotations by multiple annotators and subsequently careful
data curation to finalise annotations, ensuring their accuracy and reliability,
thereby establishing the dataset as a solid ground truth. CODE-ACCORD offers a
rich resource for diverse machine learning and natural language processing
(NLP) related tasks in ACC, including text classification, entity recognition
and relation extraction. To the best of our knowledge, this is the first entity
and relation-annotated dataset in compliance checking, which is also publicly
available.
</p>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02232" title="Abstract">arXiv:2403.02232</a> [<a href="/pdf/2403.02232" title="Download PDF">pdf</a>, <a href="/ps/2403.02232" title="Download PostScript">ps</a>, <a href="/format/2403.02232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive evaluation of Mal-API-2019 dataset by machine learning in  malware detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haibei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Houze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jintong Song</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qishuo Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study conducts a thorough examination of malware detection using machine
learning techniques, focusing on the evaluation of various classification
models using the Mal-API-2019 dataset. The aim is to advance cybersecurity
capabilities by identifying and mitigating threats more effectively. Both
ensemble and non-ensemble machine learning methods, such as Random Forest,
XGBoost, K Nearest Neighbor (KNN), and Neural Networks, are explored. Special
emphasis is placed on the importance of data pre-processing techniques,
particularly TF-IDF representation and Principal Component Analysis, in
improving model performance. Results indicate that ensemble methods,
particularly Random Forest and XGBoost, exhibit superior accuracy, precision,
and recall compared to others, highlighting their effectiveness in malware
detection. The paper also discusses limitations and potential future
directions, emphasizing the need for continuous adaptation to address the
evolving nature of malware. This research contributes to ongoing discussions in
cybersecurity and provides practical insights for developing more robust
malware detection systems in the digital era.
</p>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02233" title="Abstract">arXiv:2403.02233</a> [<a href="/pdf/2403.02233" title="Download PDF">pdf</a>, <a href="/format/2403.02233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers Provably Learn Feature-Position Correlations in Masked  Image Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zixin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingbin Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Masked image modeling (MIM), which predicts randomly masked patches from
unmasked ones, has emerged as a promising approach in self-supervised vision
pretraining. However, the theoretical understanding of MIM is rather limited,
especially with the foundational architecture of transformers. In this paper,
to the best of our knowledge, we provide the first end-to-end theory of
learning one-layer transformers with softmax attention in MIM self-supervised
pretraining. On the conceptual side, we posit a theoretical mechanism of how
transformers, pretrained with MIM, produce empirically observed local and
diverse attention patterns on data distributions with spatial structures that
highlight feature-position correlations. On the technical side, our end-to-end
analysis of the training dynamics of softmax-based transformers accommodates
both input and position embeddings simultaneously, which is developed based on
a novel approach to track the interplay between the attention of
feature-position and position-wise correlations.
</p>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02234" title="Abstract">arXiv:2403.02234</a> [<a href="/pdf/2403.02234" title="Download PDF">pdf</a>, <a href="/format/2403.02234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DTopia: Large Text-to-3D Generation Model with Hybrid Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Fangzhou Hong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Ziang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Min Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/3DTopia/3DTopia">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a two-stage text-to-3D generation system, namely 3DTopia, which
generates high-quality general 3D assets within 5 minutes using hybrid
diffusion priors. The first stage samples from a 3D diffusion prior directly
learned from 3D data. Specifically, it is powered by a text-conditioned
tri-plane latent diffusion model, which quickly generates coarse 3D samples for
fast prototyping. The second stage utilizes 2D diffusion priors to further
refine the texture of coarse 3D models from the first stage. The refinement
consists of both latent and pixel space optimization for high-quality texture
generation. To facilitate the training of the proposed system, we clean and
caption the largest open-source 3D dataset, Objaverse, by combining the power
of vision language models and large language models. Experiment results are
reported qualitatively and quantitatively to show the performance of the
proposed system. Our codes and models are available at
https://github.com/3DTopia/3DTopia
</p>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02235" title="Abstract">arXiv:2403.02235</a> [<a href="/pdf/2403.02235" title="Download PDF">pdf</a>, <a href="/format/2403.02235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure from WiFi (SfW): RSSI-based Geometric Mapping of Indoor  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junseo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zalat%2C+J+A">Jill Aghyourli Zalat</a>, 
<a href="/search/cs?searchtype=author&query=Bahoo%2C+Y">Yeganeh Bahoo</a>, 
<a href="/search/cs?searchtype=author&query=Saeedi%2C+S">Sajad Saeedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at American Control Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the rising prominence of WiFi in common spaces, efforts have been made
in the robotics community to take advantage of this fact by incorporating WiFi
signal measurements in indoor SLAM (Simultaneous Localization and Mapping)
systems. SLAM is essential in a wide range of applications, especially in the
control of autonomous robots. This paper describes recent work in the
development of WiFi-based localization and addresses the challenges currently
faced in achieving WiFi-based geometric mapping. Inspired by the field of
research into k-visibility, this paper presents the concept of inverse
k-visibility and proposes a novel algorithm that allows robots to build a map
of the free space of an unknown environment, essential for planning,
navigation, and avoiding obstacles. Experiments performed in simulated and
real-world environments demonstrate the effectiveness of the proposed
algorithm.
</p>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02238" title="Abstract">arXiv:2403.02238</a> [<a href="/pdf/2403.02238" title="Download PDF">pdf</a>, <a href="/format/2403.02238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Intent-Based Network Management: Large Language Models for  Intent Extraction in 5G Core Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manias%2C+D+M">Dimitrios Michael Manias</a>, 
<a href="/search/cs?searchtype=author&query=Chouman%2C+A">Ali Chouman</a>, 
<a href="/search/cs?searchtype=author&query=Shami%2C+A">Abdallah Shami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to: International Conference on the Design of Reliable Communication Networks 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The integration of Machine Learning and Artificial Intelligence (ML/AI) into
fifth-generation (5G) networks has made evident the limitations of network
intelligence with ever-increasing, strenuous requirements for current and
next-generation devices. This transition to ubiquitous intelligence demands
high connectivity, synchronicity, and end-to-end communication between users
and network operators, and will pave the way towards full network automation
without human intervention. Intent-based networking is a key factor in the
reduction of human actions, roles, and responsibilities while shifting towards
novel extraction and interpretation of automated network management. This paper
presents the development of a custom Large Language Model (LLM) for 5G and
next-generation intent-based networking and provides insights into future LLM
developments and integrations to realize end-to-end intent-based networking for
fully automated network intelligence.
</p>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02240" title="Abstract">arXiv:2403.02240</a> [<a href="/pdf/2403.02240" title="Download PDF">pdf</a>, <a href="/format/2403.02240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Computing: Vision and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gill%2C+S+S">Sukhpal Singh Gill</a>, 
<a href="/search/cs?searchtype=author&query=Cetinkaya%2C+O">Oktay Cetinkaya</a>, 
<a href="/search/cs?searchtype=author&query=Marrone%2C+S">Stefano Marrone</a>, 
<a href="/search/cs?searchtype=author&query=Combarro%2C+E+F">Elias F. Combarro</a>, 
<a href="/search/cs?searchtype=author&query=Claudino%2C+D">Daniel Claudino</a>, 
<a href="/search/cs?searchtype=author&query=Haunschild%2C+D">David Haunschild</a>, 
<a href="/search/cs?searchtype=author&query=Schlote%2C+L">Leon Schlote</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huaming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ottaviani%2C+C">Carlo Ottaviani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Machupalli%2C+S+P">Sree Pragna Machupalli</a>, 
<a href="/search/cs?searchtype=author&query=Kaur%2C+K">Kamalpreet Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+P">Priyansh Arora</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shamshad%2C+S">Salman Shamshad</a>, 
<a href="/search/cs?searchtype=author&query=Farouk%2C+A">Ahmed Farouk</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H+H">Houbing Herbert Song</a>, 
<a href="/search/cs?searchtype=author&query=Uhlig%2C+S">Steve Uhlig</a>, 
<a href="/search/cs?searchtype=author&query=Ramamohanarao%2C+K">Kotagiri Ramamohanarao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Elsevier Journal of Economy and Technology (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Emerging Technologies (cs.ET); Quantum Physics (quant-ph)

</div>
<p class="mathjax">The recent development of quantum computing, which makes use of entanglement,
superposition, and other quantum fundamental concepts, has the ability to
provide substantial processing advantages over traditional computing. These
quantum features help solve many hard problems that cannot be solved with
traditional computing methods. These problems are in areas like modeling
quantum mechanics, logistics, making chemical-based advances, designing drugs,
statistical science, sustainable energy, banking, reliable communication, and
quantum chemical engineering. The last few years have witnessed remarkable
advancements in quantum software and algorithm creation as well as quantum
hardware research, which have significantly advanced the prospect of the
realization of quantum computers. It would be helpful to have comprehensive
literature research on this area to grasp the current status and find
outstanding problems that require considerable attention from the research
community working in the quantum computing industry. To better understand
quantum computing, this paper examines the foundations and vision based on
current research in this area. We discuss cutting-edge developments in quantum
computer hardware advancement, and subsequent advances in quantum cryptography,
quantum software, and high-scalability quantum computers. Many potential
challenges and exciting new trends for quantum technology research and
development are highlighted in this paper for a wider debate.
</p>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02241" title="Abstract">arXiv:2403.02241</a> [<a href="/pdf/2403.02241" title="Download PDF">pdf</a>, <a href="/format/2403.02241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Redshift: Random Networks are not Random Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A">Armand Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+V">Valentin Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Our understanding of the generalization capabilities of neural networks (NNs)
is still incomplete. Prevailing explanations are based on implicit biases of
gradient descent (GD) but they cannot account for the capabilities of models
from gradient-free methods nor the simplicity bias recently observed in
untrained networks. This paper seeks other sources of generalization in NNs.
<br />Findings. To understand the inductive biases provided by architectures
independently from GD, we examine untrained, random-weight networks. Even
simple MLPs show strong inductive biases: uniform sampling in weight space
yields a very biased distribution of functions in terms of complexity. But
unlike common wisdom, NNs do not have an inherent "simplicity bias". This
property depends on components such as ReLUs, residual connections, and layer
normalizations. Alternative architectures can be built with a bias for any
level of complexity. Transformers also inherit all these properties from their
building blocks.
<br />Implications. We provide a fresh explanation for the success of deep learning
independent from gradient-based training. It points at promising avenues for
controlling the solutions implemented by trained models.
</p>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02243" title="Abstract">arXiv:2403.02243</a> [<a href="/pdf/2403.02243" title="Download PDF">pdf</a>, <a href="/format/2403.02243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Schedules for Low Precision Training of Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolfe%2C+C+R">Cameron R. Wolfe</a>, 
<a href="/search/cs?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures, 1 table, ACML 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Wolfe, Cameron R., and Anastasios Kyrillidis. "Better schedules
  for low precision training of deep neural networks." Machine Learning (2024):
  1-19
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Low precision training can significantly reduce the computational overhead of
training deep neural networks (DNNs). Though many such techniques exist, cyclic
precision training (CPT), which dynamically adjusts precision throughout train-
ing according to a cyclic schedule, achieves particularly impressive
improvements in training efficiency, while actually improving DNN performance.
Existing CPT implementations take common learning rate schedules (e.g.,
cyclical cosine sched- ules) and use them for low precision training without
adequate comparisons to alternative scheduling options. We define a diverse
suite of CPT schedules and analyze their performance across a variety of DNN
training regimes, some of which are unexplored in the low precision training
literature (e.g., node classification with graph neural networks). From these
experiments, we discover alternative CPT schedules that offer further
improvements in training efficiency and model performance, as well as derive a
set of best practices for choosing CPT schedules. Going further, we find that a
correlation exists between model performance and training cost, and that
changing the underlying CPT schedule can control the tradeoff between these two
variables. To explain the direct correlation between model performance and
training cost, we draw a connection between quantized training and critical
learning periods, suggesting that aggressive quantization is a form of learning
impairment that can permanently damage model performance.
</p>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02246" title="Abstract">arXiv:2403.02246</a> [<a href="/pdf/2403.02246" title="Download PDF">pdf</a>, <a href="/ps/2403.02246" title="Download PostScript">ps</a>, <a href="/format/2403.02246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+F+A">Fiona Anting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+G+C">Gerard Christopher Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fanyou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weijie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Jaidka%2C+K">Kokil Jaidka</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advances in large language models (LLMs) demonstrate that their
capabilities are comparable, or even superior, to humans in many tasks in
natural language processing. Despite this progress, LLMs are still inadequate
at social-cognitive reasoning, which humans are naturally good at. Drawing
inspiration from psychological research on the links between certain
personality traits and Theory-of-Mind (ToM) reasoning, and from prompt
engineering research on the hyper-sensitivity of prompts in affecting LLMs
capabilities, this study investigates how inducing personalities in LLMs using
prompts affects their ToM reasoning capabilities. Our findings show that
certain induced personalities can significantly affect the LLMs' reasoning
capabilities in three different ToM tasks. In particular, traits from the Dark
Triad have a larger variable effect on LLMs like GPT-3.5, Llama 2, and Mistral
across the different ToM tasks. We find that LLMs that exhibit a higher
variance across personality prompts in ToM also tends to be more controllable
in personality tests: personality traits in LLMs like GPT-3.5, Llama 2 and
Mistral can be controllably adjusted through our personality prompts. In
today's landscape where role-play is a common strategy when using LLMs, our
research highlights the need for caution, as models that adopt specific
personas with personalities potentially also alter their reasoning abilities in
an unexpected manner.
</p>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02247" title="Abstract">arXiv:2403.02247</a> [<a href="/pdf/2403.02247" title="Download PDF">pdf</a>, <a href="/ps/2403.02247" title="Download PostScript">ps</a>, <a href="/format/2403.02247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Birbal: An efficient 7B instruct-model fine-tuned with curated datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jindal%2C+A+K">Ashvini Kumar Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Rajpoot%2C+P+K">Pawan Kumar Rajpoot</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+A">Ankur Parikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">LLMOps incur significant costs due to hardware requirements, hindering their
widespread accessibility. Additionally, a lack of transparency in model
training methods and data contributes to the majority of models being
non-reproducible. To tackle these challenges, the LLM Efficiency Challenge was
introduced at NeurIPS Workshop, aiming to adapt foundation models on a diverse
set of tasks via fine-tuning on a single GPU (RTX 4090 or A100 with 40GB)
within a 24-hour timeframe. In this system description paper, we introduce
Birbal, our Mistral-7B based winning model, fine-tuned on a single RTX 4090 for
16 hours. Birbal's success lies in curating high-quality instructions covering
diverse tasks, resulting in a 35% performance improvement over second-best
Qwen-14B based submission.
</p>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02249" title="Abstract">arXiv:2403.02249</a> [<a href="/pdf/2403.02249" title="Download PDF">pdf</a>, <a href="/format/2403.02249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-autoregressive Sequence-to-Sequence Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kunyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Goncalves%2C+L">Luis Goncalves</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sequence-to-sequence vision-language models are showing promise, but their
applicability is limited by their inference latency due to their autoregressive
way of generating predictions. We propose a parallel decoding
sequence-to-sequence vision-language model, trained with a Query-CTC loss, that
marginalizes over multiple inference paths in the decoder. This allows us to
model the joint distribution of tokens, rather than restricting to conditional
distribution as in an autoregressive model. The resulting model, NARVL,
achieves performance on-par with its state-of-the-art autoregressive
counterpart, but is faster at inference time, reducing from the linear
complexity associated with the sequential generation of tokens to a paradigm of
constant time joint inference.
</p>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02253" title="Abstract">arXiv:2403.02253</a> [<a href="/pdf/2403.02253" title="Download PDF">pdf</a>, <a href="/format/2403.02253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for  Enhancing Reference-Based Phishing Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuexin Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lock%2C+M+L">Mei Lin Lock</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tri Cao</a>, 
<a href="/search/cs?searchtype=author&query=Oo%2C+N">Nay Oo</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H+W">Hoon Wei Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Phishing attacks have inflicted substantial losses on individuals and
businesses alike, necessitating the development of robust and efficient
automated phishing detection approaches. Reference-based phishing detectors
(RBPDs), which compare the logos on a target webpage to a known set of logos,
have emerged as the state-of-the-art approach. However, a major limitation of
existing RBPDs is that they rely on a manually constructed brand knowledge
base, making it infeasible to scale to a large number of brands, which results
in false negative errors due to the insufficient brand coverage of the
knowledge base. To address this issue, we propose an automated knowledge
collection pipeline, using which we collect and release a large-scale
multimodal brand knowledge base, KnowPhish, containing 20k brands with rich
information about each brand. KnowPhish can be used to boost the performance of
existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs
is that they solely rely on the image modality, ignoring useful textual
information present in the webpage HTML. To utilize this textual information,
we propose a Large Language Model (LLM)-based approach to extract brand
information of webpages from text. Our resulting multimodal phishing detection
approach, KnowPhish Detector (KPD), can detect phishing webpages with or
without logos. We evaluate KnowPhish and KPD on a manually validated dataset,
and on a field study under Singapore's local context, showing substantial
improvements in effectiveness and efficiency compared to state-of-the-art
baselines.
</p>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02254" title="Abstract">arXiv:2403.02254</a> [<a href="/pdf/2403.02254" title="Download PDF">pdf</a>, <a href="/format/2403.02254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Fault-Tolerant Robust Traffic Grooming in OTN-over-DWDM  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manias%2C+D+M">Dimitrios Michael Manias</a>, 
<a href="/search/cs?searchtype=author&query=Naoum-Sawaya%2C+J">Joe Naoum-Sawaya</a>, 
<a href="/search/cs?searchtype=author&query=Javadtalab%2C+A">Abbas Javadtalab</a>, 
<a href="/search/cs?searchtype=author&query=Shami%2C+A">Abdallah Shami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to: International Conference on the Design of Reliable Communication Networks 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The development of next-generation networks is revolutionizing network
operators' management and orchestration practices worldwide. The critical
services supported by these networks require increasingly stringent performance
requirements, especially when considering the aspect of network reliability.
This increase in reliability, coupled with the mass generation and consumption
of information stemming from the increasing complexity of the network and the
integration of artificial intelligence agents, affects transport networks,
which will be required to allow the feasibility of such services to
materialize. To this end, traditional recovery schemes are inadequate to ensure
the resilience requirements of next-generation critical services given the
increasingly dynamic nature of the network. The work presented in this paper
proposes a probabilistic and fault-tolerant robust traffic grooming model for
OTN-over-DWDM networks. The model's parameterization gives network operators
the ability to control the level of protection and reliability required to meet
their quality of service and service level agreement guarantees. The results
demonstrate that the robust solution can ensure fault tolerance even in the
face of demand uncertainty without service disruptions and the need for
reactive network maintenance.
</p>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02255" title="Abstract">arXiv:2403.02255</a> [<a href="/pdf/2403.02255" title="Download PDF">pdf</a>, <a href="/format/2403.02255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astronomy in Colombia: a bibliometric perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guevara-Montoya%2C+S">Sof&#xed;a Guevara-Montoya</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz-Ferreira%2C+F">Felipe Ortiz-Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Silva-Ar%C3%A9valo%2C+M+P">Mar&#xed;a Paula Silva-Ar&#xe9;valo</a>, 
<a href="/search/cs?searchtype=author&query=Ni%C3%B1o-Mu%C3%B1oz%2C+P+A">Paola A. Ni&#xf1;o-Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Forero-Romero%2C+J+E">Jaime E. Forero-Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, in Spanish language, 7 figures, 7 tables. Submitted to the Revista de la Academia Colombiana de Ciencias Exactas, F\'isicas y Naturales (ACCEFYN). Texto en espa\~nol
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM)

</div>
<p class="mathjax">In Colombia, astronomical research is experiencing accelerated growth. In
order to better understand its evolution and current state, we conducted a
bibliometric study using data from the Astrophysics Data System (ADS) and Web
of Science (WoS). In ADS, we identified 422 peer-reviewed publications from
1980, the year of the first publication, until 2023, which was the cutoff date
for our study. Among the 25 Colombian institutions identified as participants
in at least one publication, the contributions of four universities stand out:
Universidad de los Andes, Universidad Nacional de Colombia, Universidad
Industrial de Santander, and Universidad de Antioquia, with 104, 78, 68, and 67
publications, respectively. By cross-referencing information from ADS and WoS,
we found that the areas with the greatest impact in publications are threefold:
high-energy and fundamental physics, stars and stellar physics, and galaxies
and cosmology. Globally, according to WoS, Colombia ranks 52nd in the number of
peer-reviewed publications between 2019 and 2023, and fifth in Latin America.
Additionally, we identified three highly cited publications (top 1% worldwide)
belonging to the field of observational cosmology. When analyzing countries
with equal or greater bibliographic production, we estimate that Colombian
production is approximately four times lower than expected considering its
population and GDP.
</p>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02259" title="Abstract">arXiv:2403.02259</a> [<a href="/pdf/2403.02259" title="Download PDF">pdf</a>, <a href="/format/2403.02259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-AI Collaboration Increases Skill Tagging Speed but Degrades  Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Cheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pardos%2C+Z">Zachary Pardos</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">AI approaches are progressing besting humans at game-related tasks (e.g.
chess). The next stage is expected to be Human-AI collaboration; however, the
research on this subject has been mixed and is in need of additional data
points. We add to this nascent literature by studying Human-AI collaboration on
a common administrative educational task. Education is a special domain in its
relation to AI and has been slow to adopt AI approaches in practice, concerned
with the educational enterprise losing its humanistic touch and because
standard of quality is demanded because of the impact on a person's career and
developmental trajectory. In this study (N = 22), we design an experiment to
explore the effect of Human-AI collaboration on the task of tagging educational
content with skills from the US common core taxonomy. Our results show that the
experiment group (with AI recommendations) saved around 50% time (p &lt; 0.01) in
the execution of their tagging task but at the sacrifice of 7.7% recall (p =
0.267) and 35% accuracy (p= 0.1170) compared with the non-AI involved control
group, placing the AI+human group in between the AI alone (lowest performance)
and the human alone (highest performance). We further analyze log data from
this AI collaboration experiment to explore under what circumstances humans
still exercised their discernment when receiving recommendations. Finally, we
outline how this study can assist in implementing AI tools, like ChatGPT, in
education.
</p>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02265" title="Abstract">arXiv:2403.02265</a> [<a href="/pdf/2403.02265" title="Download PDF">pdf</a>, <a href="/format/2403.02265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DaReNeRF: Direction-aware Representation for Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Ange Lou</a>, 
<a href="/search/cs?searchtype=author&query=Planche%2C+B">Benjamin Planche</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhongpai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yamin Li</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+T">Tianyu Luan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Terrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Noble%2C+J">Jack Noble</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2024. Paper + supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Addressing the intricate challenge of modeling and re-rendering dynamic
scenes, most recent approaches have sought to simplify these complexities using
plane-based explicit representations, overcoming the slow training time issues
associated with methods like Neural Radiance Fields (NeRF) and implicit
representations. However, the straightforward decomposition of 4D dynamic
scenes into multiple 2D plane-based representations proves insufficient for
re-rendering high-fidelity scenes with complex motions. In response, we present
a novel direction-aware representation (DaRe) approach that captures scene
dynamics from six different directions. This learned representation undergoes
an inverse dual-tree complex wavelet transformation (DTCWT) to recover
plane-based information. DaReNeRF computes features for each space-time point
by fusing vectors from these recovered planes. Combining DaReNeRF with a tiny
MLP for color regression and leveraging volume rendering in training yield
state-of-the-art performance in novel view synthesis for complex dynamic
scenes. Notably, to address redundancy introduced by the six real and six
imaginary direction-aware wavelet coefficients, we introduce a trainable
masking approach, mitigating storage issues without significant performance
decline. Moreover, DaReNeRF maintains a 2x reduction in training time compared
to prior art while delivering superior performance.
</p>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02268" title="Abstract">arXiv:2403.02268</a> [<a href="/pdf/2403.02268" title="Download PDF">pdf</a>, <a href="/format/2403.02268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subjective $\textit{Isms}$? On the Danger of Conflating Hate and Offence  in Abusive Language Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Curry%2C+A+C">Amanda Cercas Curry</a>, 
<a href="/search/cs?searchtype=author&query=Abercrombie%2C+G">Gavin Abercrombie</a>, 
<a href="/search/cs?searchtype=author&query=Talat%2C+Z">Zeerak Talat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Natural language processing research has begun to embrace the notion of
annotator subjectivity, motivated by variations in labelling. This approach
understands each annotator's view as valid, which can be highly suitable for
tasks that embed subjectivity, e.g., sentiment analysis. However, this
construction may be inappropriate for tasks such as hate speech detection, as
it affords equal validity to all positions on e.g., sexism or racism. We argue
that the conflation of hate and offence can invalidate findings on hate speech,
and call for future work to be situated in theory, disentangling hate from its
orthogonal concept, offence.
</p>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02270" title="Abstract">arXiv:2403.02270</a> [<a href="/pdf/2403.02270" title="Download PDF">pdf</a>, <a href="/format/2403.02270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FENICE: Factuality Evaluation of summarization based on Natural language  Inference and Claim Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scir%C3%A8%2C+A">Alessandro Scir&#xe8;</a>, 
<a href="/search/cs?searchtype=author&query=Ghonim%2C+K">Karim Ghonim</a>, 
<a href="/search/cs?searchtype=author&query=Navigli%2C+R">Roberto Navigli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in text summarization, particularly with the advent of
Large Language Models (LLMs), have shown remarkable performance. However, a
notable challenge persists as a substantial number of automatically-generated
summaries exhibit factual inconsistencies, such as hallucinations. In response
to this issue, various approaches for the evaluation of consistency for
summarization have emerged. Yet, these newly-introduced metrics face several
limitations, including lack of interpretability, focus on short document
summaries (e.g., news articles), and computational impracticality, especially
for LLM-based metrics. To address these shortcomings, we propose Factuality
Evaluation of summarization based on Natural language Inference and Claim
Extraction (FENICE), a more interpretable and efficient factuality-oriented
metric. FENICE leverages an NLI-based alignment between information in the
source document and a set of atomic facts, referred to as claims, extracted
from the summary. Our metric sets a new state of the art on AGGREFACT, the
de-facto benchmark for factuality evaluation. Moreover, we extend our
evaluation to a more challenging setting by conducting a human annotation
process of long-form summarization.
</p>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02271" title="Abstract">arXiv:2403.02271</a> [<a href="/pdf/2403.02271" title="Download PDF">pdf</a>, <a href="/format/2403.02271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIFF: Learning to Rephrase Inputs for Few-shot Fine-tuning of Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Najafi%2C+S">Saeed Najafi</a>, 
<a href="/search/cs?searchtype=author&query=Fyshe%2C+A">Alona Fyshe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version Submitted to ACL2024. Review Discussion here: <a href="https://openreview.net/forum?id=_gFGBVMRN1">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained Language Models (PLMs) can be accurately fine-tuned for
downstream text processing tasks. Recently, researchers have introduced several
parameter-efficient fine-tuning methods that optimize input prompts or adjust a
small number of model parameters (e.g LoRA). In this study, we explore the
impact of altering the input text of the original task in conjunction with
parameter-efficient fine-tuning methods. To most effectively rewrite the input
text, we train a few-shot paraphrase model with a Maximum-Marginal Likelihood
objective. Using six few-shot text classification datasets, we show that
enriching data with paraphrases at train and test time enhances the performance
beyond what can be achieved with parameter-efficient fine-tuning alone.
</p>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02273" title="Abstract">arXiv:2403.02273</a> [<a href="/pdf/2403.02273" title="Download PDF">pdf</a>, <a href="/ps/2403.02273" title="Download PostScript">ps</a>, <a href="/format/2403.02273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let a Thousand Flowers Bloom: An Algebraic Representation for Edge  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liell-Cock%2C+J">Jack Liell-Cock</a> (University of Oxford, United Kingdom), 
<a href="/search/cs?searchtype=author&query=Schrijvers%2C+T">Tom Schrijvers</a> (KU Leuven, Belgium)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Context: Edge graphs are graphs whose edges are labelled with identifiers,
and nodes can have multiple edges between them. They are used to model a wide
range of systems, including networks with distances or degrees of connection
and complex relational data.
<br />Inquiry: Unfortunately, the homogeneity of this graph structure prevents an
effective representation in (functional) programs. Either their interface is
riddled with partial functions, or the representations are computationally
inefficient to process.
<br />Approach: We present a novel data type for edge graphs, based on total and
recursive definitions, that prevents usage errors from partial APIs and
promotes structurally recursive computations. We follow an algebraic approach
and provide a set of primitive constructors and combinators, along with
equational laws that identify semantically equivalent constructions.
<br />Knowledge: This algebra translates directly into an implementation using
algebraic data types, and its homomorphisms give rise to functions for
manipulating and transforming these edge graphs.
<br />Grounding: We exploit the fact that many common graph algorithms are such
homomorphisms to implement them in our framework.
<br />Importance: In giving a theoretical grounding for the edge graph data type,
we can formalise properties such as soundness and completeness of the
representation while also minimising usage errors and maximising re-usability.
</p>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02274" title="Abstract">arXiv:2403.02274</a> [<a href="/pdf/2403.02274" title="Download PDF">pdf</a>, <a href="/format/2403.02274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NatSGD: A Dataset with Speech, Gestures, and Demonstrations for Robot  Learning in Natural Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+S">Snehesh Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Y">Yantian Zha</a>, 
<a href="/search/cs?searchtype=author&query=Banagiri%2C+S">Saketh Banagiri</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/cs?searchtype=author&query=Aloimonos%2C+Y">Yiannis Aloimonos</a>, 
<a href="/search/cs?searchtype=author&query=Fermuller%2C+C">Cornelia Fermuller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in multimodal Human-Robot Interaction (HRI) datasets have
highlighted the fusion of speech and gesture, expanding robots' capabilities to
absorb explicit and implicit HRI insights. However, existing speech-gesture HRI
datasets often focus on elementary tasks, like object pointing and pushing,
revealing limitations in scaling to intricate domains and prioritizing human
command data over robot behavior records. To bridge these gaps, we introduce
NatSGD, a multimodal HRI dataset encompassing human commands through speech and
gestures that are natural, synchronized with robot behavior demonstrations.
NatSGD serves as a foundational resource at the intersection of machine
learning and HRI research, and we demonstrate its effectiveness in training
robots to understand tasks through multimodal human commands, emphasizing the
significance of jointly considering speech and gestures. We have released our
dataset, simulator, and code to facilitate future research in human-robot
interaction system learning; access these resources at
https://www.snehesh.com/natsgd/
</p>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02275" title="Abstract">arXiv:2403.02275</a> [<a href="/pdf/2403.02275" title="Download PDF">pdf</a>, <a href="/ps/2403.02275" title="Download PostScript">ps</a>, <a href="/format/2403.02275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded Depth Frege Lower Bounds for Random 3-CNFs via Deterministic  Restrictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gryaznov%2C+S">Svyatoslav Gryaznov</a>, 
<a href="/search/cs?searchtype=author&query=Talebanfard%2C+N">Navid Talebanfard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">A major open problem in proof complexity is to show that random 3-CNFs with
linear number of clauses require super-polynomial size refutations in bounded
depth Frege. We make a first step towards this question by showing a
super-linear lower bound: for every $k$, there exists $\epsilon &gt; 0$ such that
any depth-$k$ Frege refutation of a random $n$-variable 3-CNF with $\Theta(n)$
clauses has $\Omega(n^{1 + \epsilon})$ steps w.h.p. Our proof involves a novel
adaptation of the deterministic restriction technique of Chaudhuri and
Radhakrishnan (STOC'96).
</p>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02280" title="Abstract">arXiv:2403.02280</a> [<a href="/pdf/2403.02280" title="Download PDF">pdf</a>, <a href="/format/2403.02280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tightly-Coupled LiDAR-Visual-Inertial SLAM and Large-Scale Volumetric  Occupancy Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boche%2C+S">Simon Boche</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+S+B">Sebasti&#xe1;n Barbas Laina</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous navigation is one of the key requirements for every potential
application of mobile robots in the real-world. Besides high-accuracy state
estimation, a suitable and globally consistent representation of the 3D
environment is indispensable. We present a fully tightly-coupled
LiDAR-Visual-Inertial SLAM system and 3D mapping framework applying local
submapping strategies to achieve scalability to large-scale environments. A
novel and correspondence-free, inherently probabilistic, formulation of LiDAR
residuals is introduced, expressed only in terms of the occupancy fields and
its respective gradients. These residuals can be added to a factor graph
optimisation problem, either as frame-to-map factors for the live estimates or
as map-to-map factors aligning the submaps with respect to one another.
Experimental validation demonstrates that the approach achieves
state-of-the-art pose accuracy and furthermore produces globally consistent
volumetric occupancy submaps which can be directly used in downstream tasks
such as navigation or exploration.
</p>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02281" title="Abstract">arXiv:2403.02281</a> [<a href="/pdf/2403.02281" title="Download PDF">pdf</a>, <a href="/format/2403.02281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Granularity from Text: An Aggregate-Level Indicator of Mental  Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishnubhotla%2C+K">Krishnapriya Vishnubhotla</a>, 
<a href="/search/cs?searchtype=author&query=Teodorescu%2C+D">Daniela Teodorescu</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+M+J">Mallory J. Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Lindquist%2C+K+A">Kristen A. Lindquist</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+S+M">Saif M. Mohammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages plus appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We are united in how emotions are central to shaping our experiences; and
yet, individuals differ greatly in how we each identify, categorize, and
express emotions. In psychology, variation in the ability of individuals to
differentiate between emotion concepts is called emotion granularity
(determined through self-reports of one's emotions). High emotion granularity
has been linked with better mental and physical health; whereas low emotion
granularity has been linked with maladaptive emotion regulation strategies and
poor health outcomes. In this work, we propose computational measures of
emotion granularity derived from temporally-ordered speaker utterances in
social media (in lieu of self-reports that suffer from various biases). We then
investigate the effectiveness of such text-derived measures of emotion
granularity in functioning as markers of various mental health conditions
(MHCs). We establish baseline measures of emotion granularity derived from
textual utterances, and show that, at an aggregate level, emotion granularities
are significantly lower for people self-reporting as having an MHC than for the
control population. This paves the way towards a better understanding of the
MHCs, and specifically the role emotions play in our well-being.
</p>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02284" title="Abstract">arXiv:2403.02284</a> [<a href="/pdf/2403.02284" title="Download PDF">pdf</a>, <a href="/format/2403.02284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphical Quadratic Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+D">Dario Stein</a>, 
<a href="/search/cs?searchtype=author&query=Zanasi%2C+F">Fabio Zanasi</a>, 
<a href="/search/cs?searchtype=author&query=Samuelson%2C+R">Richard Samuelson</a>, 
<a href="/search/cs?searchtype=author&query=Piedeleu%2C+R">Robin Piedeleu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Optimization and Control (math.OC)

</div>
<p class="mathjax">We introduce Graphical Quadratic Algebra (GQA), a string diagrammatic
calculus extending the language of Graphical Affine Algebra with a new
generator characterised by invariance under rotation matrices. We show that GQA
is a sound and complete axiomatisation for three different models: quadratic
relations, which are a compositional formalism for least-squares problems,
Gaussian stochastic processes, and Gaussian stochastic processes extended with
non-determinisms. The equational theory of GQA sheds light on the connections
between these perspectives, giving an algebraic interpretation to the interplay
of stochastic behaviour, relational behaviour, non-determinism, and
conditioning. As applications, we discuss various case studies, including
linear regression, probabilistic programming, and electrical circuits with
realistic (noisy) components.
</p>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02285" title="Abstract">arXiv:2403.02285</a> [<a href="/pdf/2403.02285" title="Download PDF">pdf</a>, <a href="/format/2403.02285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Non-recorded Word Senses in English and Swedish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lautenschlager%2C+J">Jonathan Lautenschlager</a>, 
<a href="/search/cs?searchtype=author&query=Sk%C3%B6ldberg%2C+E">Emma Sk&#xf6;ldberg</a>, 
<a href="/search/cs?searchtype=author&query=Hengchen%2C+S">Simon Hengchen</a>, 
<a href="/search/cs?searchtype=author&query=Schlechtweg%2C+D">Dominik Schlechtweg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study addresses the task of Unknown Sense Detection in English and
Swedish. The primary objective of this task is to determine whether the meaning
of a particular word usage is documented in a dictionary or not. For this
purpose, sense entries are compared with word usages from modern and historical
corpora using a pre-trained Word-in-Context embedder that allows us to model
this task in a few-shot scenario. Additionally, we use human annotations to
adapt and evaluate our models. Compared to a random sample from a corpus, our
model is able to considerably increase the detected number of word usages with
non-recorded senses.
</p>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02286" title="Abstract">arXiv:2403.02286</a> [<a href="/pdf/2403.02286" title="Download PDF">pdf</a>, <a href="/format/2403.02286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stage: Query Execution Time Prediction in Amazon Redshift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziniu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Marcus%2C+R">Ryan Marcus</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengchun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Negi%2C+P">Parimarjan Negi</a>, 
<a href="/search/cs?searchtype=author&query=Nathan%2C+V">Vikram Nathan</a>, 
<a href="/search/cs?searchtype=author&query=Pfeil%2C+P">Pascal Pfeil</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+G">Gaurav Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mohammad Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Narayanaswamy%2C+B">Balakrishnan Narayanaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Kraska%2C+T">Tim Kraska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Query performance (e.g., execution time) prediction is a critical component
of modern DBMSes. As a pioneering cloud data warehouse, Amazon Redshift relies
on an accurate execution time prediction for many downstream tasks, ranging
from high-level optimizations, such as automatically creating materialized
views, to low-level tasks on the critical path of query execution, such as
admission, scheduling, and execution resource control. Unfortunately, many
existing execution time prediction techniques, including those used in
Redshift, suffer from cold start issues, inaccurate estimation, and are not
robust against workload/data changes.
<br />In this paper, we propose a novel hierarchical execution time predictor: the
Stage predictor. The Stage predictor is designed to leverage the unique
characteristics and challenges faced by Redshift. The Stage predictor consists
of three model states: an execution time cache, a lightweight local model
optimized for a specific DB instance with uncertainty measurement, and a
complex global model that is transferable across all instances in Redshift. We
design a systematic approach to use these models that best leverages optimality
(cache), instance-optimization (local model), and transferable knowledge about
Redshift (global model). Experimentally, we show that the Stage predictor makes
more accurate and robust predictions while maintaining a practical inference
latency and memory overhead. Overall, the Stage predictor can improve the
average query execution latency by $20\%$ on these instances compared to the
prior query performance predictor in Redshift.
</p>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02289" title="Abstract">arXiv:2403.02289</a> [<a href="/pdf/2403.02289" title="Download PDF">pdf</a>, <a href="/format/2403.02289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Networks with Skip Connections for Modeling and  Control of Gas-Lifted Oil Wells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kittelsen%2C+J+E">Jonas Ekeland Kittelsen</a>, 
<a href="/search/cs?searchtype=author&query=Antonelo%2C+E+A">Eric Aislan Antonelo</a>, 
<a href="/search/cs?searchtype=author&query=Camponogara%2C+E">Eduardo Camponogara</a>, 
<a href="/search/cs?searchtype=author&query=Imsland%2C+L+S">Lars Struen Imsland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural networks, while powerful, often lack interpretability.
Physics-Informed Neural Networks (PINNs) address this limitation by
incorporating physics laws into the loss function, making them applicable to
solving Ordinary Differential Equations (ODEs) and Partial Differential
Equations (PDEs). The recently introduced PINC framework extends PINNs to
control applications, allowing for open-ended long-range prediction and control
of dynamic systems. In this work, we enhance PINC for modeling highly nonlinear
systems such as gas-lifted oil wells. By introducing skip connections in the
PINC network and refining certain terms in the ODE, we achieve more accurate
gradients during training, resulting in an effective modeling process for the
oil well system. Our proposed improved PINC demonstrates superior performance,
reducing the validation prediction error by an average of 67% in the oil well
application and significantly enhancing gradient flow through the network
layers, increasing its magnitude by four orders of magnitude compared to the
original PINC. Furthermore, experiments showcase the efficacy of Model
Predictive Control (MPC) in regulating the bottom-hole pressure of the oil well
using the improved PINC model, even in the presence of noisy measurements.
</p>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02290" title="Abstract">arXiv:2403.02290</a> [<a href="/pdf/2403.02290" title="Download PDF">pdf</a>, <a href="/format/2403.02290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Koopman-Assisted Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozwood%2C+P">Preston Rozwood</a>, 
<a href="/search/cs?searchtype=author&query=Mehrez%2C+E">Edward Mehrez</a>, 
<a href="/search/cs?searchtype=author&query=Paehler%2C+L">Ludger Paehler</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Brunton%2C+S+L">Steven L. Brunton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman
(HJB) equation, are ubiquitous in reinforcement learning (RL) and control
theory. However, these equations quickly become intractable for systems with
high-dimensional states and nonlinearity. This paper explores the connection
between the data-driven Koopman operator and Markov Decision Processes (MDPs),
resulting in the development of two new RL algorithms to address these
limitations. We leverage Koopman operator techniques to lift a nonlinear system
into new coordinates where the dynamics become approximately linear, and where
HJB-based methods are more tractable. In particular, the Koopman operator is
able to capture the expectation of the time evolution of the value function of
a given system via linear dynamics in the lifted coordinates. By parameterizing
the Koopman operator with the control actions, we construct a ``Koopman
tensor'' that facilitates the estimation of the optimal value function. Then, a
transformation of Bellman's framework in terms of the Koopman tensor enables us
to reformulate two max-entropy RL algorithms: soft value iteration and soft
actor-critic (SAC). This highly flexible framework can be used for
deterministic or stochastic systems as well as for discrete or continuous-time
dynamics. Finally, we show that these Koopman Assisted Reinforcement Learning
(KARL) algorithms attain state-of-the-art (SOTA) performance with respect to
traditional neural network-based SAC and linear quadratic regulator (LQR)
baselines on four controlled dynamical systems: a linear state-space system,
the Lorenz system, fluid flow past a cylinder, and a double-well potential with
non-isotropic stochastic forcing.
</p>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02292" title="Abstract">arXiv:2403.02292</a> [<a href="/pdf/2403.02292" title="Download PDF">pdf</a>, <a href="/format/2403.02292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Decade of Privacy-Relevant Android App Reviews: Large Scale Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akgul%2C+O">Omer Akgul</a>, 
<a href="/search/cs?searchtype=author&query=Peddinti%2C+S+T">Sai Teja Peddinti</a>, 
<a href="/search/cs?searchtype=author&query=Taft%2C+N">Nina Taft</a>, 
<a href="/search/cs?searchtype=author&query=Mazurek%2C+M+L">Michelle L. Mazurek</a>, 
<a href="/search/cs?searchtype=author&query=Harkous%2C+H">Hamza Harkous</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Animesh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Seguin%2C+B">Benoit Seguin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We present an analysis of 12 million instances of privacy-relevant reviews
publicly visible on the Google Play Store that span a 10 year period. By
leveraging state of the art NLP techniques, we can examine what users have been
writing about privacy along multiple dimensions: time, countries, app types,
diverse privacy topics, and even across a spectrum of emotions. We find
consistent growth of privacy-relevant reviews, and explore topics that are
trending (such as Data Deletion and Data Theft), as well as those on the
decline (such as privacy-relevant reviews on sensitive permissions). We find
that although privacy reviews come from more than 200 countries, 33 countries
provide 90% of privacy reviews. We conduct a comparison across countries by
examining the distribution of privacy topics a country's users write about, and
find that geographic proximity is not a reliable indicator that nearby
countries have similar privacy perspectives. We uncover some countries with
unique patterns and explore those herein. Surprisingly, we uncover that it is
not uncommon for reviews that discuss privacy to be positive (32%); many users
express pleasure about privacy features within apps or privacy-focused apps. We
also uncover some unexpected behaviors, such as the use of reviews to deliver
privacy disclaimers to developers. Finally, we demonstrate the value of
analyzing app reviews with our approach as a complement to existing methods for
understanding users' perspectives about privacy.
</p>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02296" title="Abstract">arXiv:2403.02296</a> [<a href="/pdf/2403.02296" title="Download PDF">pdf</a>, <a href="/ps/2403.02296" title="Download PostScript">ps</a>, <a href="/format/2403.02296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reactive Programming without Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oeyen%2C+B">Bjarno Oeyen</a> (Vrije Universiteit Brussel, Belgium), 
<a href="/search/cs?searchtype=author&query=De+Koster%2C+J">Joeri De Koster</a> (Vrije Universiteit Brussel, Belgium), 
<a href="/search/cs?searchtype=author&query=De+Meuter%2C+W">Wolfgang De Meuter</a> (Vrije Universiteit Brussel, Belgium)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Art, Science, and Engineering of Programming, 2024, Vol. 8,
  Issue 3, Article 11
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Context: Reactive programming (RP) is a declarative programming paradigm
suitable for expressing the handling of events. It enables programmers to
create applications that react automatically to changes over time. Whenever a
time-varying signal changes -- e.g. in response to values produced by event
stream (e.g., sensor data, user input...) -- the program state is updated
automatically in tandem with that change. This makes RP well-suited for
building interactive applications and reactive (soft real-time) systems.
Inquiry: RP Language implementations are often built on top of an existing
(host) language as an Embedded Domain Specific Language (EDSL). This results in
application code in which reactive code and non-reactive code is inherently
entangled. Using a mechanism known as lifting, one usually has access to the
full feature set of the (non-reactive) host language in the RP program.
However, lifting is also dangerous. First, host code expressed in a
Turing-complete language may diverge, resulting in unresponsive programs: i.e.
reactive programs that are not actually reactive. Second, the bi-directional
integration of reactive and non-reactive code results in a paradigmatic
mismatch that, when unchecked, leads to faulty behaviour in programs. Approach:
We propose a new reactive programming language, that has been meticulously
designed to be reactive-only. We start with a simple (first-order) model for
reactivity, based on reactors (i.e. uninstantiated descriptions of signals and
their dependencies) and deployments (i.e. instances of reactors) that consist
of signals. The language does not have the notion of functions, and thus unlike
other RP languages there is no lifting either. We extend this simple model
incrementally with additional features found in other programming languages, RP
or otherwise. These features include stateful reactors (that allow for
time-based accumulation), signals with dynamic dependencies by means of
conditionals and polymorphic deployments, recursively-defined reactors, and
(anonymous) reactors with lexical scope. Knowledge: In our description of these
language features, we not only describe the syntax and semantics, but also how
each features compares to the problems that exist in (EDSL) RP languages. I.e.
by starting from a reactive-only model, we identify which reactive features
(that, in other RP languages are typically expressed in non-reactive code)
affect the reactive guarantees that can be enforced by the language. Grounding:
We base our arguments by analysing the effect that each feature has on our
language: e.g., by analysing how signals are updated, how they are created and
how dependencies between signals can be affected. When applicable, we draw
parallels with other languages: i.e. similarities shared with other RP
languages will be highlighted and thoroughly analysed, and where relevant the
same will also be done with non-reactive languages. Importance: Our language
shows how a purely reactive programming is able to express the same kinds of
programs as in other RP languages that require the use of (unchecked)
functions. By considering reactive programs as a collection of pure
(reactive-only) reactors, we aim to increase how reactive programming is
comprehended by both language designers and its users.
</p>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02297" title="Abstract">arXiv:2403.02297</a> [<a href="/pdf/2403.02297" title="Download PDF">pdf</a>, <a href="/format/2403.02297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Prediction and Application in Planning for Autonomous  Driving: Definitions, Methods, and Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenbo Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiahui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous driving systems face the formidable challenge of navigating
intricate and dynamic environments with uncertainty. This study presents a
unified prediction and planning framework that concurrently models short-term
aleatoric uncertainty (SAU), long-term aleatoric uncertainty (LAU), and
epistemic uncertainty (EU) to predict and establish a robust foundation for
planning in dynamic contexts. The framework uses Gaussian mixture models and
deep ensemble methods, to concurrently capture and assess SAU, LAU, and EU,
where traditional methods do not integrate these uncertainties simultaneously.
Additionally, uncertainty-aware planning is introduced, considering various
uncertainties. The study's contributions include comparisons of uncertainty
estimations, risk modeling, and planning methods in comparison to existing
approaches. The proposed methods were rigorously evaluated using the CommonRoad
benchmark and settings with limited perception. These experiments illuminated
the advantages and roles of different uncertainty factors in autonomous driving
processes. In addition, comparative assessments of various uncertainty modeling
strategies underscore the benefits of modeling multiple types of uncertainties,
thus enhancing planning accuracy and reliability. The proposed framework
facilitates the development of methods for UAP and surpasses existing
uncertainty-aware risk models, particularly when considering diverse traffic
scenarios. Project page: https://swb19.github.io/UAP/.
</p>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02300" title="Abstract">arXiv:2403.02300</a> [<a href="/pdf/2403.02300" title="Download PDF">pdf</a>, <a href="/format/2403.02300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Query Lower Bounds for Learning Truncated Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+D+M">Daniel M. Kane</a>, 
<a href="/search/cs?searchtype=author&query=Pittas%2C+T">Thanasis Pittas</a>, 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+N">Nikos Zarifis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problem of estimating the mean of an identity covariance
Gaussian in the truncated setting, in the regime when the truncation set comes
from a low-complexity family $\mathcal{C}$ of sets. Specifically, for a fixed
but unknown truncation set $S \subseteq \mathbb{R}^d$, we are given access to
samples from the distribution $\mathcal{N}(\boldsymbol{ \mu}, \mathbf{ I})$
truncated to the set $S$. The goal is to estimate $\boldsymbol\mu$ within
accuracy $\epsilon&gt;0$ in $\ell_2$-norm. Our main result is a Statistical Query
(SQ) lower bound suggesting a super-polynomial information-computation gap for
this task. In more detail, we show that the complexity of any SQ algorithm for
this problem is $d^{\mathrm{poly}(1/\epsilon)}$, even when the class
$\mathcal{C}$ is simple so that $\mathrm{poly}(d/\epsilon)$ samples
information-theoretically suffice. Concretely, our SQ lower bound applies when
$\mathcal{C}$ is a union of a bounded number of rectangles whose VC dimension
and Gaussian surface are small. As a corollary of our construction, it also
follows that the complexity of the previously known algorithm for this task is
qualitatively best possible.
</p>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02302" title="Abstract">arXiv:2403.02302</a> [<a href="/pdf/2403.02302" title="Download PDF">pdf</a>, <a href="/format/2403.02302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Specialization: Assessing the Capabilities of MLLMs in Age and  Gender Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuprashevich%2C+M">Maksim Kuprashevich</a>, 
<a href="/search/cs?searchtype=author&query=Alekseenko%2C+G">Grigorii Alekseenko</a>, 
<a href="/search/cs?searchtype=author&query=Tolstykh%2C+I">Irina Tolstykh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have recently gained immense
popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as
open-source ones such as LLaVA, are essentially general-purpose models and are
applied to solve a wide variety of tasks, including those in computer vision.
These neural networks possess such strong general knowledge and reasoning
abilities that they have proven capable of working even on tasks for which they
were not specifically trained. We compared the capabilities of the most
powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task
of age and gender estimation with our state-of-the-art specialized model,
MiVOLO. We also updated MiVOLO and provide details and new metrics in this
article. This comparison has yielded some interesting results and insights
about the strengths and weaknesses of the participating models. Furthermore, we
attempted various ways to fine-tune the ShareGPT4V model for this specific
task, aiming to achieve state-of-the-art results in this particular challenge.
Although such a model would not be practical in production, as it is incredibly
expensive compared to a specialized model like MiVOLO, it could be very useful
in some tasks, like data annotation.
</p>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02308" title="Abstract">arXiv:2403.02308</a> [<a href="/pdf/2403.02308" title="Download PDF">pdf</a>, <a href="/format/2403.02308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuchen Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have revolutionized computer vision and natural language
processing, but their high computational complexity limits their application in
high-resolution image processing and long-context analysis. This paper
introduces Vision-RWKV (VRWKV), a model adapted from the RWKV model used in the
NLP field with necessary modifications for vision tasks. Similar to the Vision
Transformer (ViT), our model is designed to efficiently handle sparse inputs
and demonstrate robust global processing capabilities, while also scaling up
effectively, accommodating both large-scale parameters and extensive datasets.
Its distinctive advantage lies in its reduced spatial aggregation complexity,
which renders it exceptionally adept at processing high-resolution images
seamlessly, eliminating the necessity for windowing operations. Our evaluations
in image classification demonstrate that VRWKV matches ViT's classification
performance with significantly faster speeds and lower memory usage. In dense
prediction tasks, it outperforms window-based models, maintaining comparable
speeds. These results highlight VRWKV's potential as a more efficient
alternative for visual perception tasks. Code is released at
\url{https://github.com/OpenGVLab/Vision-RWKV}.
</p>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02310" title="Abstract">arXiv:2403.02310</a> [<a href="/pdf/2403.02310" title="Download PDF">pdf</a>, <a href="/format/2403.02310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Amey Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Kedia%2C+N">Nitin Kedia</a>, 
<a href="/search/cs?searchtype=author&query=Panwar%2C+A">Ashish Panwar</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+J">Jayashree Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Kwatra%2C+N">Nipun Kwatra</a>, 
<a href="/search/cs?searchtype=author&query=Gulavani%2C+B+S">Bhargav S. Gulavani</a>, 
<a href="/search/cs?searchtype=author&query=Tumanov%2C+A">Alexey Tumanov</a>, 
<a href="/search/cs?searchtype=author&query=Ramjee%2C+R">Ramachandran Ramjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Each LLM serving request goes through two phases. The first is prefill which
processes the entire input prompt to produce one output token and the second is
decode which generates the rest of output tokens, one-at-a-time. Prefill
iterations have high latency but saturate GPU compute due to parallel
processing of the input prompt. In contrast, decode iterations have low latency
but also low compute utilization because a decode iteration processes only a
single token per request. This makes batching highly effective for decodes and
consequently for overall throughput. However, batching multiple requests leads
to an interleaving of prefill and decode iterations which makes it challenging
to achieve both high throughput and low latency.
<br />We introduce an efficient LLM inference scheduler Sarathi-Serve inspired by
the techniques we originally proposed for optimizing throughput in Sarathi.
Sarathi-Serve leverages chunked-prefills from Sarathi to create stall-free
schedules that can add new requests in a batch without pausing ongoing decodes.
Stall-free scheduling unlocks the opportunity to improve throughput with large
batch sizes while minimizing the effect of batching on latency. Our evaluation
shows that Sarathi-Serve improves serving throughput within desired latency
SLOs of Mistral-7B by up to 2.6x on a single A100 GPU and up to 6.9x for
Falcon-180B on 8 A100 GPUs over Orca and vLLM.
</p>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02316" title="Abstract">arXiv:2403.02316</a> [<a href="/pdf/2403.02316" title="Download PDF">pdf</a>, <a href="/format/2403.02316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Library of Skill-Agents for Hardware-Level Reusability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takamatsu%2C+J">Jun Takamatsu</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+D">Daichi Saito</a>, 
<a href="/search/cs?searchtype=author&query=Ikeuchi%2C+K">Katsushi Ikeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Kanehira%2C+A">Atsushi Kanehira</a>, 
<a href="/search/cs?searchtype=author&query=Sasabuchi%2C+K">Kazuhiro Sasabuchi</a>, 
<a href="/search/cs?searchtype=author&query=Wake%2C+N">Naoki Wake</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">To use new robot hardware in a new environment, it is necessary to develop a
control program tailored to that specific robot in that environment.
Considering the reusability of software among robots is crucial to minimize the
effort involved in this process and maximize software reuse across different
robots in different environments. This paper proposes a method to remedy this
process by considering hardware-level reusability, using
Learning-from-observation (LfO) paradigm with a pre-designed skill-agent
library. The LfO framework represents the required actions in
hardware-independent representations, referred to as task models, from
observing human demonstrations, capturing the necessary parameters for the
interaction between the environment and the robot. When executing the desired
actions from the task models, a set of skill agents is employed to convert the
representations into robot commands. This paper focuses on the latter part of
the LfO framework, utilizing the set to generate robot actions from the task
models, and explores a hardware-independent design approach for these skill
agents. These skill agents are described in a hardware-independent manner,
considering the relative relationship between the robot's hand position and the
environment. As a result, it is possible to execute these actions on robots
with different hardware configurations by simply swapping the inverse
kinematics solver. This paper, first, defines a necessary and sufficient
skill-agent set corresponding to cover all possible actions, and considers the
design principles for these skill agents in the library. We provide concrete
examples of such skill agents and demonstrate the practicality of using these
skill agents by showing that the same representations can be executed on two
different robots, Nextage and Fetch, using the proposed skill-agents set.
</p>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02317" title="Abstract">arXiv:2403.02317</a> [<a href="/pdf/2403.02317" title="Download PDF">pdf</a>, <a href="/ps/2403.02317" title="Download PostScript">ps</a>, <a href="/format/2403.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contract Design for Pandora&#x27;s Box
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoefer%2C+M">Martin Hoefer</a>, 
<a href="/search/cs?searchtype=author&query=Schecker%2C+C">Conrad Schecker</a>, 
<a href="/search/cs?searchtype=author&query=Schewior%2C+K">Kevin Schewior</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study a natural application of contract design to search problems with
probabilistic prior and exploration costs. These problems have a plethora of
applications and are expressed concisely within the Pandora's Box model. Its
optimal solution is the ingenious index policy proposed originally by Weitzman
in 1979.
<br />In our principal-agent setting, the search task is delegated to an agent. The
agent performs a sequential exploration of $n$ boxes, suffers the exploration
cost for each inspected box, and selects the content (called the prize) of one
inspected box as outcome. Agent and principal obtain an individual value based
on the selected prize. To influence the search, the principal a-priori designs
a contract with a non-negative payment to the agent for each potential prize.
The goal of the principal to maximize her expected reward, i.e., value minus
payment. We show how to compute optimal contracts for the principal in several
scenarios.
<br />A popular and important subclass are linear contracts, and we show how to
compute optimal linear contracts in polynomial time. For general contracts, we
consider the standard assumption that the agent suffers cost but obtains value
only from the transfers by the principal. Interestingly, a suitable adaptation
of the index policy results in an optimal contract here. More generally, for
general contracts with non-zero agent values for outcomes we show how to
compute an optimal contract in two cases: (1) when each box has only one prize
with non-zero value for principal and agent, (2) for i.i.d. boxes with a single
prize with positive value for the principal. These results show that optimal
contracts can be highly non-trivial, and their design goes significantly beyond
the application or re-interpretation of the index policy.
</p>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02325" title="Abstract">arXiv:2403.02325</a> [<a href="/pdf/2403.02325" title="Download PDF">pdf</a>, <a href="/format/2403.02325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Region Guidance: Improving Grounding in Vision-Language  Models without Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+D">David Wan</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaemin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Stengel-Eskin%2C+E">Elias Stengel-Eskin</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://contrastive-region-guidance.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Highlighting particularly relevant regions of an image can improve the
performance of vision-language models (VLMs) on various vision-language (VL)
tasks by guiding the model to attend more closely to these regions of interest.
For example, VLMs can be given a "visual prompt", where visual markers such as
bounding boxes delineate key image regions. However, current VLMs that can
incorporate visual guidance are either proprietary and expensive or require
costly training on curated data that includes visual prompts. We introduce
Contrastive Region Guidance (CRG), a training-free guidance method that enables
open-source VLMs to respond to visual prompts. CRG contrasts model outputs
produced with and without visual prompts, factoring out biases revealed by the
model when answering without the information required to produce a correct
answer (i.e., the model's prior). CRG achieves substantial improvements in a
wide variety of VL tasks: When region annotations are provided, CRG increases
absolute accuracy by up to 11.1% on ViP-Bench, a collection of six diverse
region-based tasks such as recognition, math, and object relationship
reasoning. We also show CRG's applicability to spatial reasoning, with 10%
improvement on What'sUp, as well as to compositional generalization --
improving accuracy by 11.5% and 7.5% on two challenging splits from SugarCrepe
-- and to image-text alignment for generated images, where we improve by up to
8.4 AUROC and 6.8 F1 points on SeeTRUE. When reference regions are absent, CRG
allows us to re-rank proposed regions in referring expression comprehension and
phrase grounding benchmarks like RefCOCO/+/g and Flickr30K Entities, with an
average gain of 3.2% in accuracy. Our analysis explores alternative masking
strategies for CRG, quantifies CRG's probability shift, and evaluates the role
of region guidance strength, empirically validating CRG's design choices.
</p>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02327" title="Abstract">arXiv:2403.02327</a> [<a href="/pdf/2403.02327" title="Download PDF">pdf</a>, <a href="/format/2403.02327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Lakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+K">Koyena Pal</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+R+J">Ren&#xe9;e J. Miller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given a set of deep learning models, it can be hard to find models
appropriate to a task, understand the models, and characterize how models are
different one from another. Currently, practitioners rely on manually-written
documentation to understand and choose models. However, not all models have
complete and reliable documentation. As the number of machine learning models
increases, this issue of finding, differentiating, and understanding models is
becoming more crucial. Inspired from research on data lakes, we introduce and
define the concept of model lakes. We discuss fundamental research challenges
in the management of large models. And we discuss what principled data
management techniques can be brought to bear on the study of large model
management.
</p>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02329" title="Abstract">arXiv:2403.02329</a> [<a href="/pdf/2403.02329" title="Download PDF">pdf</a>, <a href="/format/2403.02329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMMIT: Certifying Robustness of Multi-Sensor Fusion Systems against  Semantic Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zijian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wenda Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chejian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-sensor fusion systems (MSFs) play a vital role as the perception module
in modern autonomous vehicles (AVs). Therefore, ensuring their robustness
against common and realistic adversarial semantic transformations, such as
rotation and shifting in the physical world, is crucial for the safety of AVs.
While empirical evidence suggests that MSFs exhibit improved robustness
compared to single-modal models, they are still vulnerable to adversarial
semantic transformations. Despite the proposal of empirical defenses, several
works show that these defenses can be attacked again by new adaptive attacks.
So far, there is no certified defense proposed for MSFs. In this work, we
propose the first robustness certification framework COMMIT certify robustness
of multi-sensor fusion systems against semantic attacks. In particular, we
propose a practical anisotropic noise mechanism that leverages randomized
smoothing with multi-modal data and performs a grid-based splitting method to
characterize complex semantic transformations. We also propose efficient
algorithms to compute the certification in terms of object detection accuracy
and IoU for large-scale MSF models. Empirically, we evaluate the efficacy of
COMMIT in different settings and provide a comprehensive benchmark of certified
robustness for different MSF models using the CARLA simulation platform. We
show that the certification for MSF models is at most 48.39% higher than that
of single-modal models, which validates the advantages of MSF models. We
believe our certification framework and benchmark will contribute an important
step towards certifiably robust AVs in practice.
</p>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02330" title="Abstract">arXiv:2403.02330</a> [<a href="/pdf/2403.02330" title="Download PDF">pdf</a>, <a href="/format/2403.02330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RegionGPT: Towards Region Understanding Vision Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qiushan Guo</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello%2C+S">Shalini De Mello</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongxu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Byeon%2C+W">Wonmin Byeon</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+K+C">Ka Chun Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision language models (VLMs) have experienced rapid advancements through the
integration of large language models (LLMs) with image-text pairs, yet they
struggle with detailed regional visual understanding due to limited spatial
awareness of the vision encoder, and the use of coarse-grained training data
that lacks detailed, region-specific captions. To address this, we introduce
RegionGPT (short as RGPT), a novel framework designed for complex region-level
captioning and understanding. RGPT enhances the spatial awareness of regional
representation with simple yet effective modifications to existing visual
encoders in VLMs. We further improve performance on tasks requiring a specific
output scope by integrating task-guided instruction prompts during both
training and inference phases, while maintaining the model's versatility for
general-purpose tasks. Additionally, we develop an automated region caption
data generation pipeline, enriching the training set with detailed region-level
captions. We demonstrate that a universal RGPT model can be effectively applied
and significantly enhancing performance across a range of region-level tasks,
including but not limited to complex region descriptions, reasoning, object
classification, and referring expressions comprehension.
</p>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02331" title="Abstract">arXiv:2403.02331</a> [<a href="/pdf/2403.02331" title="Download PDF">pdf</a>, <a href="/ps/2403.02331" title="Download PostScript">ps</a>, <a href="/format/2403.02331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Neuromic Computing: Neurons as Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bull%2C+L">Larry Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The computational capabilities of dendrites have become increasingly clear.
This letter presents the idea that neural backpropagation is using dendritic
processing to enable individual neurons to perform autoencoding. Using a very
simple connection weight search heuristic and artificial neural network model,
the effects of interleaving autoencoding for each neuron in a hidden layer of a
feedforward network are explored. This is contrasted to the standard layered
approach to autoencoding. It is shown that such individualised processing is
not detrimental and can improve network learning.
</p>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02332" title="Abstract">arXiv:2403.02332</a> [<a href="/pdf/2403.02332" title="Download PDF">pdf</a>, <a href="/format/2403.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniCtrl: Improving the Spatiotemporal Consistency of Text-to-Video  Diffusion Models via Training-Free Unified Attention Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuweiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tian Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sihan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Diffusion Models have been developed for video generation, usually
integrating text and image conditioning to enhance control over the generated
content. Despite the progress, ensuring consistency across frames remains a
challenge, particularly when using text prompts as control conditions. To
address this problem, we introduce UniCtrl, a novel, plug-and-play method that
is universally applicable to improve the spatiotemporal consistency and motion
diversity of videos generated by text-to-video models without additional
training. UniCtrl ensures semantic consistency across different frames through
cross-frame self-attention control, and meanwhile, enhances the motion quality
and spatiotemporal consistency through motion injection and spatiotemporal
synchronization. Our experimental results demonstrate UniCtrl's efficacy in
enhancing various text-to-video models, confirming its effectiveness and
universality.
</p>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02333" title="Abstract">arXiv:2403.02333</a> [<a href="/pdf/2403.02333" title="Download PDF">pdf</a>, <a href="/format/2403.02333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Key-Point-Driven Data Synthesis with its Enhancement on Mathematical  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Gou%2C+Z">Zhibin Gou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yelong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown great potential in complex reasoning
tasks, yet their performance is often hampered by the scarcity of high-quality,
reasoning-focused training datasets. Addressing this challenge, we propose
Key-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that
synthesizes question-answer pairs by leveraging key points and exemplar pairs
from authentic data sources. KPDDS ensures the generation of novel questions
with rigorous quality control and substantial scalability. As a result, we
present KPMath, the most extensive synthetic dataset tailored for mathematical
reasoning to date, comprising over one million question-answer pairs. Utilizing
KPMath and augmenting it with additional reasoning-intensive corpora, we create
the comprehensive KPMath-Plus dataset. Fine-tuning the Mistral-7B model on
KPMath-Plus yields a zero-shot PASS@1 accuracy of 39.3% on the MATH test set, a
performance that not only outpaces other finetuned 7B models but also exceeds
that of certain 34B models. Our ablation studies further confirm the
substantial enhancement in mathematical reasoning across various subtopics,
marking a significant stride in LLMs' reasoning capabilities.
</p>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02334" title="Abstract">arXiv:2403.02334</a> [<a href="/pdf/2403.02334" title="Download PDF">pdf</a>, <a href="/format/2403.02334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Correlation Subspace Learning against Catastrophic Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubnov%2C+T">Tammuz Dubnov</a>, 
<a href="/search/cs?searchtype=author&query=Thengane%2C+V">Vishal Thengane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures; Code will be available here: <a href="https://github.com/vgthengane/GCSL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Efficient continual learning techniques have been a topic of significant
research over the last few years. A fundamental problem with such learning is
severe degradation of performance on previously learned tasks, known also as
catastrophic forgetting. This paper introduces a novel method to reduce
catastrophic forgetting in the context of incremental class learning called
Gradient Correlation Subspace Learning (GCSL). The method detects a subspace of
the weights that is least affected by previous tasks and projects the weights
to train for the new task into said subspace. The method can be applied to one
or more layers of a given network architectures and the size of the subspace
used can be altered from layer to layer and task to task. Code will be
available at
\href{https://github.com/vgthengane/GCSL}{https://github.com/vgthengane/GCSL}
</p>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02336" title="Abstract">arXiv:2403.02336</a> [<a href="/pdf/2403.02336" title="Download PDF">pdf</a>, <a href="/format/2403.02336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brand Visibility in Packaging: A Deep Learning Approach for Logo  Detection, Saliency-Map Prediction, and Logo Placement Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+A">Alireza Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Hooshanfar%2C+K">Kiana Hooshanfar</a>, 
<a href="/search/cs?searchtype=author&query=Omrani%2C+P">Pouria Omrani</a>, 
<a href="/search/cs?searchtype=author&query=Toosi%2C+R">Reza Toosi</a>, 
<a href="/search/cs?searchtype=author&query=Toosi%2C+R">Ramin Toosi</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimian%2C+Z">Zahra Ebrahimian</a>, 
<a href="/search/cs?searchtype=author&query=Akhaee%2C+M+A">Mohammad Ali Akhaee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the highly competitive area of product marketing, the visibility of brand
logos on packaging plays a crucial role in shaping consumer perception,
directly influencing the success of the product. This paper introduces a
comprehensive framework to measure the brand logo's attention on a packaging
design. The proposed method consists of three steps. The first step leverages
YOLOv8 for precise logo detection across prominent datasets, FoodLogoDet-1500
and LogoDet-3K. The second step involves modeling the user's visual attention
with a novel saliency prediction model tailored for the packaging context. The
proposed saliency model combines the visual elements with text maps employing a
transformers-based architecture to predict user attention maps. In the third
step, by integrating logo detection with a saliency map generation, the
framework provides a comprehensive brand attention score. The effectiveness of
the proposed method is assessed module by module, ensuring a thorough
evaluation of each component. Comparing logo detection and saliency map
prediction with state-of-the-art models shows the superiority of the proposed
methods. To investigate the robustness of the proposed brand attention score,
we collected a unique dataset to examine previous psychophysical hypotheses
related to brand visibility. the results show that the brand attention score is
in line with all previous studies. Also, we introduced seven new hypotheses to
check the impact of position, orientation, presence of person, and other visual
elements on brand attention. This research marks a significant stride in the
intersection of cognitive psychology, computer vision, and marketing, paving
the way for advanced, consumer-centric packaging designs.
</p>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02338" title="Abstract">arXiv:2403.02338</a> [<a href="/pdf/2403.02338" title="Download PDF">pdf</a>, <a href="/format/2403.02338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twisting Lids Off with Two Hands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Toru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhao-Heng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Haozhi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page can be found at <a href="https://toruowo.github.io/bimanual-twist">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Manipulating objects with two multi-fingered hands has been a long-standing
challenge in robotics, attributed to the contact-rich nature of many
manipulation tasks and the complexity inherent in coordinating a
high-dimensional bimanual system. In this work, we consider the problem of
twisting lids of various bottle-like objects with two hands, and demonstrate
that policies trained in simulation using deep reinforcement learning can be
effectively transferred to the real world. With novel engineering insights into
physical modeling, real-time perception, and reward design, the policy
demonstrates generalization capabilities across a diverse set of unseen
objects, showcasing dynamic and dexterous behaviors. Our findings serve as
compelling evidence that deep reinforcement learning combined with sim-to-real
transfer remains a promising approach for addressing manipulation problems of
unprecedented complexity.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue,  5 Mar 24</h3>
<dl>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00770" title="Abstract">arXiv:2403.00770</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00770" title="Download PDF">pdf</a>, <a href="/format/2403.00770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain Metrics and Indicators in Cryptocurrency Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=King%2C+J+C">Juan C. King</a>, 
<a href="/search/q-fin?searchtype=author&query=Dale%2C+R">Roberto Dale</a>, 
<a href="/search/q-fin?searchtype=author&query=Amig%C3%B3%2C+J+M">Jos&#xe9; M. Amig&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages; 14 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J.C. King, R. Dale, J.M. Amig\'o, Solitons &amp; Fractals, 178, 114305
  (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The objective of this paper is the construction of new indicators that can be
useful to operate in the cryptocurrency market. These indicators are based on
public data obtained from the blockchain network, specifically from the nodes
that make up Bitcoin mining. Therefore, our analysis is unique to that network.
The results obtained with numerical simulations of algorithmic trading and
prediction via statistical models and Machine Learning demonstrate the
importance of variables such as the hash rate, the difficulty of mining or the
cost per transaction when it comes to trade Bitcoin assets or predict the
direction of price. Variables obtained from the blockchain network will be
called here blockchain metrics. The corresponding indicators (inspired by the
"Hash Ribbon") perform well in locating buy signals. From our results, we
conclude that such blockchain indicators allow obtaining information with a
statistical advantage in the highly volatile cryptocurrency market.
</p>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00771" title="Abstract">arXiv:2403.00771</a> (cross-list from eess.IV) [<a href="/pdf/2403.00771" title="Download PDF">pdf</a>, <a href="/ps/2403.00771" title="Download PostScript">ps</a>, <a href="/format/2403.00771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XProspeCT: CT Volume Generation from Paired X-Rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paulson%2C+B">Benjamin Paulson</a>, 
<a href="/search/eess?searchtype=author&query=Goldshteyn%2C+J">Joshua Goldshteyn</a>, 
<a href="/search/eess?searchtype=author&query=Balboni%2C+S">Sydney Balboni</a>, 
<a href="/search/eess?searchtype=author&query=Cisler%2C+J">John Cisler</a>, 
<a href="/search/eess?searchtype=author&query=Crisler%2C+A">Andrew Crisler</a>, 
<a href="/search/eess?searchtype=author&query=Bukowski%2C+N">Natalia Bukowski</a>, 
<a href="/search/eess?searchtype=author&query=Kalish%2C+J">Julia Kalish</a>, 
<a href="/search/eess?searchtype=author&query=Colwell%2C+T">Theodore Colwell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Originally submitted as part of the MICS 2023 Undergraduate Paper Competition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Computed tomography (CT) is a beneficial imaging tool for diagnostic
purposes. CT scans provide detailed information concerning the internal
anatomic structures of a patient, but present higher radiation dose and costs
compared to X-ray imaging. In this paper, we build on previous research to
convert orthogonal X-ray images into simulated CT volumes by exploring larger
datasets and various model structures. Significant model variations include
UNet architectures, custom connections, activation functions, loss functions,
optimizers, and a novel back projection approach.
</p>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00772" title="Abstract">arXiv:2403.00772</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00772" title="Download PDF">pdf</a>, <a href="/format/2403.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Weibo platform experts perform better at predicting stock market?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Ma%2C+Z">Ziyuan Ma</a>, 
<a href="/search/q-fin?searchtype=author&query=Ryan%2C+C">Conor Ryan</a>, 
<a href="/search/q-fin?searchtype=author&query=Buckley%2C+J">Jim Buckley</a>, 
<a href="/search/q-fin?searchtype=author&query=Chochlov%2C+M">Muslim Chochlov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2021, 22nd Engineering Applications of Neural Networks Conference
  (EANN 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Sentiment analysis can be used for stock market prediction. However, existing
research has not studied the impact of a user's financial background on
sentiment-based forecasting of the stock market using artificial neural
networks. In this work, a novel combination of neural networks is used for the
assessment of sentiment-based stock market prediction, based on the financial
background of the population that generated the sentiment. The state-of-the-art
language processing model Bidirectional Encoder Representations from
Transformers (BERT) is used to classify the sentiment and a Long-Short Term
Memory (LSTM) model is used for time-series based stock market prediction. For
evaluation, the Weibo social networking platform is used as a sentiment data
collection source. Weibo users (and their comments respectively) are divided
into Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor
(UFA) groups according to their background information, as collected by Weibo.
The Hong Kong Hang Seng index is used to extract historical stock market change
data. The results indicate that stock market prediction learned from the AFA
group users is 39.67% more precise than that learned from the UFA group users
and shows the highest accuracy (87%) when compared to existing approaches.
</p>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00774" title="Abstract">arXiv:2403.00774</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00774" title="Download PDF">pdf</a>, <a href="/ps/2403.00774" title="Download PostScript">ps</a>, <a href="/format/2403.00774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regional inflation analysis using social network data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Karpov%2C+V+C+I">Vasilii Chsherbakov Ilia Karpov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Inflation is one of the most important macroeconomic indicators that have a
great impact on the population of any country and region. Inflation is
influenced by range of factors, one of which is inflation expectations. Many
central banks take this factor into consideration while implementing monetary
policy within the inflation targeting regime. Nowadays, a lot of people are
active users of the Internet, especially social networks. There is a hypothesis
that people search, read, and discuss mainly only those issues that are of
particular interest to them. It is logical to assume that the dynamics of
prices may also be in the focus of user discussions. So, such discussions could
be regarded as an alternative source of more rapid information about inflation
expectations. This study is based on unstructured data from Vkontakte social
network to analyze upward and downward inflationary trends (on the example of
the Omsk region). The sample of more than 8.5 million posts was collected
between January 2010 and May 2022. The authors used BERT neural networks to
solve the problem. These models demonstrated better results than the benchmarks
(e.g., logistic regression, decision tree classifier, etc.). It makes possible
to define pro-inflationary and disinflationary types of keywords in different
contexts and get their visualization with SHAP method. This analysis provides
additional operational information about inflationary processes at the regional
level The proposed approach can be scaled for other regions. At the same time
the limitation of the work is the time and power costs for the initial training
of similar models for all regions of Russia.
</p>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00775" title="Abstract">arXiv:2403.00775</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00775" title="Download PDF">pdf</a>, <a href="/ps/2403.00775" title="Download PostScript">ps</a>, <a href="/format/2403.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Anomalous Events in Object-centric Business Processes via  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Niro%2C+A">Alessandro Niro</a>, 
<a href="/search/q-fin?searchtype=author&query=Werner%2C+M">Michael Werner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, to appear in the ICPM 2023 Workshops Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">Detecting anomalies is important for identifying inefficiencies, errors, or
fraud in business processes. Traditional process mining approaches focus on
analyzing 'flattened', sequential, event logs based on a single case notion.
However, many real-world process executions exhibit a graph-like structure,
where events can be associated with multiple cases. Flattening event logs
requires selecting a single case identifier which creates a gap with the real
event data and artificially introduces anomalies in the event logs.
Object-centric process mining avoids these limitations by allowing events to be
related to different cases. This study proposes a novel framework for anomaly
detection in business processes that exploits graph neural networks and the
enhanced information offered by object-centric process mining. We first
reconstruct and represent the process dependencies of the object-centric event
logs as attributed graphs and then employ a graph convolutional autoencoder
architecture to detect anomalous events. Our results show that our approach
provides promising performance in detecting anomalies at the activity type and
attributes level, although it struggles to detect anomalies in the temporal
order of events.
</p>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00777" title="Abstract">arXiv:2403.00777</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00777" title="Download PDF">pdf</a>, <a href="/ps/2403.00777" title="Download PostScript">ps</a>, <a href="/format/2403.00777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating Financial Crimes with Unsupervised Learning Techniques:  Clustering and Dimensionality Reduction for Anti-Money Laundering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Bakry%2C+A+N">Ahmed N. Bakry</a>, 
<a href="/search/q-fin?searchtype=author&query=Alsharkawy%2C+A+S">Almohammady S. Alsharkawy</a>, 
<a href="/search/q-fin?searchtype=author&query=Farag%2C+M+S">Mohamed S. Farag</a>, 
<a href="/search/q-fin?searchtype=author&query=Raslan%2C+K+R">Kamal R. Raslan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Anti-Money Laundering (AML) is a crucial task in ensuring the integrity of
financial systems. One keychallenge in AML is identifying high-risk groups
based on their behavior. Unsupervised learning, particularly clustering, is a
promising solution for this task. However, the use of hundreds of features
todescribe behavior results in a highdimensional dataset that negatively
impacts clustering performance.In this paper, we investigate the effectiveness
of combining clustering method agglomerative hierarchicalclustering with four
dimensionality reduction techniques -Independent Component Analysis (ICA),
andKernel Principal Component Analysis (KPCA), Singular Value Decomposition
(SVD), Locality Preserving Projections (LPP)- to overcome the issue of
high-dimensionality in AML data and improve clusteringresults. This study aims
to provide insights into the most effective way of reducing the dimensionality
ofAML data and enhance the accuracy of clustering-based AML systems. The
experimental results demonstrate that KPCA outperforms other dimension
reduction techniques when combined with agglomerativehierarchical clustering.
This superiority is observed in the majority of situations, as confirmed by
threedistinct validation indices.
</p>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00782" title="Abstract">arXiv:2403.00782</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00782" title="Download PDF">pdf</a>, <a href="/format/2403.00782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ploutos: Towards interpretable stock movement prediction with financial  large language model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Tong%2C+H">Hanshuang Tong</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/q-fin?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have opened new pathways
for many domains. However, the full potential of LLMs in financial investments
remains largely untapped. There are two main challenges for typical deep
learning-based methods for quantitative finance. First, they struggle to fuse
textual and numerical information flexibly for stock movement prediction.
Second, traditional methods lack clarity and interpretability, which impedes
their application in scenarios where the justification for predictions is
essential. To solve the above challenges, we propose Ploutos, a novel financial
LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen
contains multiple primary experts that can analyze different modal data, such
as text and numbers, and provide quantitative strategies from different
perspectives. Then PloutosGPT combines their insights and predictions and
generates interpretable rationales. To generate accurate and faithful
rationales, the training strategy of PloutosGPT leverage rearview-mirror
prompting mechanism to guide GPT-4 to generate rationales, and a dynamic token
weighting mechanism to finetune LLM by increasing key tokens weight. Extensive
experiments show our framework outperforms the state-of-the-art methods on both
prediction accuracy and interpretability.
</p>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00785" title="Abstract">arXiv:2403.00785</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00785" title="Download PDF">pdf</a>, <a href="/ps/2403.00785" title="Download PostScript">ps</a>, <a href="/format/2403.00785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying News and Media Sentiment Analysis for Generating Forex Trading  Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Olaiyapo%2C+O+F">Oluwafemi F Olaiyapo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Olaiyapo O.F. Applying News and Media Sentiment Analysis for
  Generating Forex Trading Signals. Review of Business and Economics Studies.
  2023;11(4):84-94
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The objective of this research is to examine how sentiment analysis can be
employed to generate trading signals for the Foreign Exchange (Forex) market.
The author assessed sentiment in social media posts and news articles
pertaining to the United States Dollar (USD) using a combination of methods:
lexicon-based analysis and the Naive Bayes machine learning algorithm. The
findings indicate that sentiment analysis proves valuable in forecasting market
movements and devising trading signals. Notably, its effectiveness is
consistent across different market conditions. The author concludes that by
analyzing sentiment expressed in news and social media, traders can glean
insights into prevailing market sentiments towards the USD and other pertinent
countries, thereby aiding trading decision-making. This study underscores the
importance of weaving sentiment analysis into trading strategies as a pivotal
tool for predicting market dynamics.
</p>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00796" title="Abstract">arXiv:2403.00796</a> (cross-list from q-fin.ST) [<a href="/pdf/2403.00796" title="Download PDF">pdf</a>, <a href="/ps/2403.00796" title="Download PostScript">ps</a>, <a href="/format/2403.00796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes:  Functional and Augmented Data Structures in Financial Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Tondapu%2C+N">Narayan Tondapu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we explore the application of Gaussian Processes (GPs) for
predicting mean-reverting time series with an underlying structure, using
relatively unexplored functional and augmented data structures. While many
conventional forecasting methods concentrate on the short-term dynamics of time
series data, GPs offer the potential to forecast not just the average
prediction but the entire probability distribution over a future trajectory.
This is particularly beneficial in financial contexts, where accurate
predictions alone may not suffice if incorrect volatility assessments lead to
capital losses. Moreover, in trade selection, GPs allow for the forecasting of
multiple Sharpe ratios adjusted for transaction costs, aiding in
decision-making. The functional data representation utilized in this study
enables longer-term predictions by leveraging information from previous years,
even as the forecast moves away from the current year's training data.
Additionally, the augmented representation enriches the training set by
incorporating multiple targets for future points in time, facilitating
long-term predictions. Our implementation closely aligns with the methodology
outlined in, which assessed effectiveness on commodity futures. However, our
testing methodology differs. Instead of real data, we employ simulated data
with similar characteristics. We construct a testing environment to evaluate
both data representations and models under conditions of increasing noise, fat
tails, and inappropriate kernels-conditions commonly encountered in practice.
By simulating data, we can compare our forecast distribution over time against
a full simulation of the actual distribution of our test set, thereby reducing
the inherent uncertainty in testing time series models on real data. We enable
feature prediction through augmentation and employ sub-sampling to ensure the
feasibility of GPs.
</p>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00838" title="Abstract">arXiv:2403.00838</a> (cross-list from math.AP) [<a href="/pdf/2403.00838" title="Download PDF">pdf</a>, <a href="/format/2403.00838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp-interface limits for brittle fracture via the inverse-deformation  formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Healey%2C+T+J">Timothy J. Healey</a>, 
<a href="/search/math?searchtype=author&query=Paroni%2C+R">Roberto Paroni</a>, 
<a href="/search/math?searchtype=author&query=Rosakis%2C+P">Phoebus Rosakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We derive sharp-interface models for one-dimensional brittle fracture via the
inverse-deformation approach. Methods of Gamma-convergence are employed to
obtain the singular limits of previously proposed models. The latter feature a
local, non-convex stored energy of inverse strain, augmented by small
interfacial energy, formulated in terms of the inverse-strain gradient. They
predict spontaneous fracture with exact crack-opening discontinuities, without
the use of damage (phase) fields or pre-existing cracks; crack faces are
endowed with a thin layer of surface energy. The models obtained herewith
inherit the same properties, except that surface energy is now concentrated at
the crack faces. Accordingly, we construct energy-minimizing configurations.
For a composite bar with a breakable layer, our results predict a pattern of
equally spaced cracks whose number is given as an increasing function of
applied load.
</p>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00854" title="Abstract">arXiv:2403.00854</a> (cross-list from q-bio.NC) [<a href="/pdf/2403.00854" title="Download PDF">pdf</a>, <a href="/format/2403.00854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker-Independent Dysarthria Severity Classification using  Self-Supervised Transformers and Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Stumpf%2C+L">Lauren Stumpf</a>, 
<a href="/search/q-bio?searchtype=author&query=Kadirvelu%2C+B">Balasundaram Kadirvelu</a>, 
<a href="/search/q-bio?searchtype=author&query=Waibel%2C+S">Sigourney Waibel</a>, 
<a href="/search/q-bio?searchtype=author&query=Faisal%2C+A+A">A. Aldo Faisal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 tables, 4 main figures, 2 supplemental figures, prepared for journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Dysarthria, a condition resulting from impaired control of the speech muscles
due to neurological disorders, significantly impacts the communication and
quality of life of patients. The condition's complexity, human scoring and
varied presentations make its assessment and management challenging. This study
presents a transformer-based framework for automatically assessing dysarthria
severity from raw speech data. It can offer an objective, repeatable,
accessible, standardised and cost-effective and compared to traditional methods
requiring human expert assessors. We develop a transformer framework, called
Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task
learning objective and contrastive learning for speaker-independent multi-class
dysarthria severity classification. The multi-task framework is designed to
reduce reliance on speaker-specific characteristics and address the intrinsic
intra-class variability of dysarthric speech. We evaluated on the Universal
Access Speech dataset using leave-one-speaker-out cross-validation, our model
demonstrated superior performance over traditional machine learning approaches,
with an accuracy of $70.48\%$ and an F1 score of $59.23\%$. Our SALR model also
exceeded the previous benchmark for AI-based classification, which used support
vector machines, by $16.58\%$. We open the black box of our model by
visualising the latent space where we can observe how the model substantially
reduces speaker-specific cues and amplifies task-specific ones, thereby showing
its robustness. In conclusion, SALR establishes a new benchmark in
speaker-independent multi-class dysarthria severity classification using
generative AI. The potential implications of our findings for broader clinical
applications in automated dysarthria severity assessments.
</p>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00874" title="Abstract">arXiv:2403.00874</a> (cross-list from math.AP) [<a href="/pdf/2403.00874" title="Download PDF">pdf</a>, <a href="/format/2403.00874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On complex algebraic singularities of some genuinely nonlinear PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dutykh%2C+D">Denys Dutykh</a>, 
<a href="/search/math?searchtype=author&query=Leichtnam%2C+%C3%89">&#xc9;ric Leichtnam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 85 pages, 15 figures, 52 references, 5 appendices, and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Complex Variables (math.CV); Numerical Analysis (math.NA); Exactly Solvable and Integrable Systems (nlin.SI)

</div>
<p class="mathjax">In this manuscript, we highlight a new phenomenon of complex algebraic
singularity formation for solutions of a large class of genuinely nonlinear
partial differential equations (PDEs). We start from a unique Cauchy datum,
which is holomorphic ramified around the smooth locus and is sufficiently
singular. Then, we expect the existence of a solution which should be
holomorphic ramified around the singular locus S defined by the vanishing of
the discriminant of an algebraic equation. Notice, moreover, that the monodromy
of the Cauchy datum is Abelian, whereas one of the solutions is non-Abelian.
Moreover, the singular locus S depends on the Cauchy datum in contrast to the
Leray principle (stated for linear problems only). This phenomenon is due to
the fact that the PDE is genuinely nonlinear and that the Cauchy datum is
sufficiently singular. First, we investigate the case of the inviscid Burgers
equation. Later, we state a general conjecture that describes the expected
phenomenon. We view this Conjecture as a working programme allowing us to
develop interesting new Mathematics. We also state another Conjecture 2, which
is a particular case of the general Conjecture but keeps all the flavour and
difficulty of the subject. Then, we propose a new algorithm with a map F such
that a fixed point of F would give a solution to the problem associated with
Conjecture 2. Then, we perform convincing, elaborate numerical tests that
suggest that a Banach norm should exist for which the mapping F should be a
contraction so that the solution (with the above specific algebraic structure)
should be unique. This work is a continuation of Leichtnam (1993).
</p>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00875" title="Abstract">arXiv:2403.00875</a> (cross-list from q-bio.QM) [<a href="/pdf/2403.00875" title="Download PDF">pdf</a>, <a href="/format/2403.00875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Protein Predictive Models via Proteins Data Augmentation: A  Benchmark and New Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Lin%2C+H">Haitao Lin</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+Y">Yufei Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Augmentation is an effective alternative to utilize the small amount of
labeled protein data. However, most of the existing work focuses on design-ing
new architectures or pre-training tasks, and relatively little work has studied
data augmentation for proteins. This paper extends data augmentation techniques
previously used for images and texts to proteins and then benchmarks these
techniques on a variety of protein-related tasks, providing the first
comprehensive evaluation of protein augmentation. Furthermore, we propose two
novel semantic-level protein augmentation methods, namely Integrated Gradients
Substitution and Back Translation Substitution, which enable protein
semantic-aware augmentation through saliency detection and biological
knowledge. Finally, we integrate extended and proposed augmentations into an
augmentation pool and propose a simple but effective framework, namely
Automated Protein Augmentation (APA), which can adaptively select the most
suitable augmentation combinations for different tasks. Extensive experiments
have shown that APA enhances the performance of five protein related tasks by
an average of 10.55% across three architectures compared to vanilla
implementations without augmentation, highlighting its potential to make a
great impact on the field.
</p>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00885" title="Abstract">arXiv:2403.00885</a> (cross-list from physics.ed-ph) [<a href="/pdf/2403.00885" title="Download PDF">pdf</a>, <a href="/format/2403.00885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Computer Scientists for the Challenges of Hybrid  Quantum-Classical Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=De+Maio%2C+V">Vincenzo De Maio</a>, 
<a href="/search/physics?searchtype=author&query=Kanatbekova%2C+M">Meerzhan Kanatbekova</a>, 
<a href="/search/physics?searchtype=author&query=Zilk%2C+F">Felix Zilk</a>, 
<a href="/search/physics?searchtype=author&query=Friis%2C+N">Nicolai Friis</a>, 
<a href="/search/physics?searchtype=author&query=Guggemos%2C+T">Tobias Guggemos</a>, 
<a href="/search/physics?searchtype=author&query=Brandic%2C+I">Ivona Brandic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET); Quantum Physics (quant-ph)

</div>
<p class="mathjax">As we enter the post-Moore era, we experience the rise of various
non-von-Neumann-architectures to address the increasing computational demand
for modern applications, with quantum computing being among the most prominent
and promising technologies. However, this development creates a gap in current
computer science curricula since most quantum computing lectures are strongly
physics-oriented and have little intersection with the remaining curriculum of
computer science. This fact makes designing an appealing course very difficult,
in particular for non-physicists. Furthermore, in the academic community, there
is consensus that quantum computers are going to be used only for specific
computational tasks (e.g., in computational science), where hybrid systems -
combined classical and quantum computers - facilitate the execution of an
application on both quantum and classical computing resources. A hybrid system
thus executes only certain suitable parts of an application on the quantum
machine, while other parts are executed on the classical components of the
system. To fully exploit the capabilities of hybrid systems and to meet future
requirements in this emerging field, we need to prepare a new generation of
computer scientists with skills in both distributed computing and quantum
computing. To bridge this existing gap in standard computer science curricula,
we designed a new lecture and exercise series on Hybrid Quantum-Classical
Systems, where students learn how to decompose applications and implement
computational tasks on a hybrid quantum-classical computational continuum.
While learning the inherent concepts underlying quantum systems, students are
obligated to apply techniques and methods they are already familiar with,
making the entrance to the field of quantum computing comprehensive yet
appealing and accessible to students of computer science.
</p>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00887" title="Abstract">arXiv:2403.00887</a> (cross-list from eess.AS) [<a href="/pdf/2403.00887" title="Download PDF">pdf</a>, <a href="/format/2403.00887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in  Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=R%2C+A">Aron R</a>, 
<a href="/search/eess?searchtype=author&query=Sigicharla%2C+I">Indra Sigicharla</a>, 
<a href="/search/eess?searchtype=author&query=Periwal%2C+C">Chirag Periwal</a>, 
<a href="/search/eess?searchtype=author&query=K%2C+M">Mohanaprasad K</a>, 
<a href="/search/eess?searchtype=author&query=S%2C+N+D+P">Nithya Darisini P S</a>, 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+S">Sourabh Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Arora%2C+S">Shivani Arora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">The interpretation of human voices holds importance across various
applications. This study ventures into predicting age, gender, and emotion from
vocal cues, a field with vast applications. Voice analysis tech advancements
span domains, from improving customer interactions to enhancing healthcare and
retail experiences. Discerning emotions aids mental health, while age and
gender detection are vital in various contexts. Exploring deep learning models
for these predictions involves comparing single, multi-output, and sequential
models highlighted in this paper. Sourcing suitable data posed challenges,
resulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work
showed promise in individual predictions, but limited research considered all
three variables simultaneously. This paper identifies flaws in an individual
model approach and advocates for our novel multi-output learning architecture
Speech-based Emotion Gender and Age Analysis (SEGAA) model. The experiments
suggest that Multi-output models perform comparably to individual models,
efficiently capturing the intricate relationships between variables and speech
inputs, all while achieving improved runtime.
</p>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00897" title="Abstract">arXiv:2403.00897</a> (cross-list from eess.IV) [<a href="/pdf/2403.00897" title="Download PDF">pdf</a>, <a href="/format/2403.00897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisRec: A Semi-Supervised Approach to Radio Interferometric Data  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ruoqi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haitao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Q">Qiong Luo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Hejun Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Astrophysics of Galaxies (astro-ph.GA); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Radio telescopes produce visibility data about celestial objects, but these
data are sparse and noisy. As a result, images created on raw visibility data
are of low quality. Recent studies have used deep learning models to
reconstruct visibility data to get cleaner images. However, these methods rely
on a substantial amount of labeled training data, which requires significant
labeling effort from radio astronomers. Addressing this challenge, we propose
VisRec, a model-agnostic semi-supervised learning approach to the
reconstruction of visibility data. Specifically, VisRec consists of both a
supervised learning module and an unsupervised learning module. In the
supervised learning module, we introduce a set of data augmentation functions
to produce diverse training examples. In comparison, the unsupervised learning
module in VisRec augments unlabeled data and uses reconstructions from
non-augmented visibility data as pseudo-labels for training. This hybrid
approach allows VisRec to effectively leverage both labeled and unlabeled data.
This way, VisRec performs well even when labeled data is scarce. Our evaluation
results show that VisRec outperforms all baseline methods in reconstruction
quality, robustness against common observation perturbation, and
generalizability to different telescope configurations.
</p>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00961" title="Abstract">arXiv:2403.00961</a> (cross-list from physics.ed-ph) [<a href="/pdf/2403.00961" title="Download PDF">pdf</a>, <a href="/format/2403.00961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Science Education in Undergraduate Physics: Lessons Learned from a  Community of Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shah%2C+K">Karan Shah</a>, 
<a href="/search/physics?searchtype=author&query=Butler%2C+J">Julie Butler</a>, 
<a href="/search/physics?searchtype=author&query=Knaub%2C+A">Alexis Knaub</a>, 
<a href="/search/physics?searchtype=author&query=Zengino%C4%9Flu%2C+A">An&#x131;l Zengino&#x11f;lu</a>, 
<a href="/search/physics?searchtype=author&query=Ratcliff%2C+W">William Ratcliff</a>, 
<a href="/search/physics?searchtype=author&query=Soltanieh-ha%2C+M">Mohammad Soltanieh-ha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures, 2 tables. The associated GItHub repository can be found at <a href="https://github.com/GDS-Education-Community-of-Practice/DSECOP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">With the increasing availability of diverse datasets, ranging from
small-scale experimental data points to large and complex data repositories and
powerful data analysis tools, it is increasingly important that physics
educators equip their students with the skills to work with data effectively.
However, many educators may lack the necessary training and expertise in data
science to teach these skills. To address this gap, we created the Data Science
Education Community of Practice (DSECOP), bringing together graduate students
and physics educators from different institutions and backgrounds to share best
practices and lessons learned in integrating data science into undergraduate
physics education. In this article, we present insights and experiences from
this community of practice, highlighting key strategies and challenges in
incorporating data science into the introductory physics curriculum. Our goal
is to provide guidance and inspiration to educators who seek to integrate data
science into their teaching, helping to prepare the next generation of
physicists for a data-driven world.
</p>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00965" title="Abstract">arXiv:2403.00965</a> (cross-list from stat.AP) [<a href="/pdf/2403.00965" title="Download PDF">pdf</a>, <a href="/ps/2403.00965" title="Download PostScript">ps</a>, <a href="/format/2403.00965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to  Advance ML-based Clinical Decision Support Systems for Early Prediction of  Dialysis Among CKD Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Khosravi%2C+H">Hamed Khosravi</a>, 
<a href="/search/stat?searchtype=author&query=Das%2C+S">Srinjoy Das</a>, 
<a href="/search/stat?searchtype=author&query=Al-Mamun%2C+A">Abdullah Al-Mamun</a>, 
<a href="/search/stat?searchtype=author&query=Ahmed%2C+I">Imtiaz Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Center for Disease Control estimates that over 37 million US adults
suffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals
are unaware of their condition due to the absence of symptoms in the early
stages. It has a significant impact on patients' quality of life, particularly
when it progresses to the need for dialysis. Early prediction of dialysis is
crucial as it can significantly improve patient outcomes and assist healthcare
providers in making timely and informed decisions. However, developing an
effective machine learning (ML)-based Clinical Decision Support System (CDSS)
for early dialysis prediction poses a key challenge due to the imbalanced
nature of data. To address this challenge, this study evaluates various data
augmentation techniques to understand their effectiveness on real-world
datasets. We propose a new approach named Binary Gaussian Copula Synthesis
(BGCS). BGCS is tailored for binary medical datasets and excels in generating
synthetic minority data that mirrors the distribution of the original data.
BGCS enhances early dialysis prediction by outperforming traditional methods in
detecting dialysis patients. For the best ML model, Random Forest, BCGS
achieved a 72% improvement, surpassing the state-of-the-art augmentation
approaches. Also, we present a ML-based CDSS, designed to aid clinicians in
making informed decisions. CDSS, which utilizes decision tree models, is
developed to improve patient outcomes, identify critical variables, and thereby
enable clinicians to make proactive decisions, and strategize treatment plans
effectively for CKD patients who are more likely to require dialysis in the
near future. Through comprehensive feature analysis and meticulous data
preparation, we ensure that the CDSS's dialysis predictions are not only
accurate but also actionable, providing a valuable tool in the management and
treatment of CKD.
</p>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00971" title="Abstract">arXiv:2403.00971</a> (cross-list from math.AP) [<a href="/pdf/2403.00971" title="Download PDF">pdf</a>, <a href="/ps/2403.00971" title="Download PostScript">ps</a>, <a href="/format/2403.00971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The sequence of pseudo-equilibria describes the long-time behaviour of  the NNLIF model with large delay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=C%C3%A1ceres%2C+M+J">Mar&#xed;a J. C&#xe1;ceres</a>, 
<a href="/search/math?searchtype=author&query=Ca%C3%B1izo%2C+J+A">Jos&#xe9; A. Ca&#xf1;izo</a>, 
<a href="/search/math?searchtype=author&query=Ramos-Lora%2C+A">Alejandro Ramos-Lora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">There is a wide range of mathematical models that describe populations of
large numbers of neurons. In this article, we focus on nonlinear noisy leaky
integrate and fire (NNLIF) models that describe neuronal activity at the level
of the membrane potential of neurons. We introduce a set of novel states, which
we call "pseudo-equilibria", and give evidence of their defining role in the
behaviour of the NNLIF system when a significant synaptic delay is considered.
The advantage is that these states are determined solely by the system's
parameters and are derived from a sequence of firing rates that result from
solving a recurrence equation. We propose a new strategy to show convergence to
an equilibrium for a weakly connected system with large transmission delay,
based on following the sequence of pseudo-equilibria. Unlike with the direct
entropy dissipation method, this technique allows us to see how a large delay
favours convergence. We also present a detailed numerical study to support our
results. This study explores the overall behaviour of the NNLIF system and
helps us understand, among other phenomena, periodic solutions in strongly
inhibitory networks.
</p>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01066" title="Abstract">arXiv:2403.01066</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.01066" title="Download PDF">pdf</a>, <a href="/format/2403.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An &quot;Opinion Reproduction Number&quot; for Infodemics in a Bounded-Confidence  Content-Spreading Process on Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Brooks%2C+H+Z">Heather Z. Brooks</a>, 
<a href="/search/physics?searchtype=author&query=Porter%2C+M+A">Mason A. Porter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages; submitted to \emph{Chaos} for the special issue for the 80th birthday of David Campbell. (Happy birthday, David!)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We study the spreading dynamics of content on networks. To do this, we use a
model in which content spreads through a bounded-confidence mechanism. In a
bounded-confidence model (BCM) of opinion dynamics, the agents of a network
have continuous-valued opinions, which they adjust when they interact with
agents whose opinions are sufficiently close to theirs. The employed
content-spread model introduces a twist into BCMs by using bounded confidence
for the content spread itself. To study the spread of content, we define an
analogue of the basic reproduction number from disease dynamics that we call an
\emph{opinion reproduction number}. A critical value of the opinion
reproduction number indicates whether or not there is an ``infodemic'' (i.e., a
large content-spreading cascade) of content that reflects a particular opinion.
By determining this critical value, one can determine whether or not an opinion
will die off or propagate widely as a cascade in a population of agents. Using
configuration-model networks, we quantify the size and shape of content
dissemination using a variety of summary statistics, and we illustrate how
network structure and spreading model parameters affect these statistics. We
find that content spreads most widely when the agents have large expected mean
degree or large receptiveness to content. When the amount of content spread
only slightly exceeds the critical opinion reproduction number (i.e., the
infodemic threshold), there can be longer dissemination trees than when the
expected mean degree or receptiveness is larger, even though the total number
of content shares is smaller.
</p>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01098" title="Abstract">arXiv:2403.01098</a> (cross-list from eess.SP) [<a href="/pdf/2403.01098" title="Download PDF">pdf</a>, <a href="/format/2403.01098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Complexity Deep Learning Augmented Wireless Channel Estimation for  Pilot-Based OFDM on Zynq System on Chip
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+A">Animesh Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Haq%2C+S+A+U">Syed Asrar Ul Haq</a>, 
<a href="/search/eess?searchtype=author&query=Darak%2C+S+J">Sumit J. Darak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Channel estimation (CE) is one of the critical signal-processing tasks of the
wireless physical layer (PHY). Recent deep learning (DL) based CE have
outperformed statistical approaches such as least-square-based CE (LS) and
linear minimum mean square error-based CE (LMMSE). However, existing CE
approaches have not yet been realized on system-on-chip (SoC). The first
contribution of this paper is to efficiently implement the existing
state-of-the-art CE algorithms on Zynq SoC (ZSoC), comprising of ARM processor
and field programmable gate array (FPGA), via hardware-software co-design and
fixed point analysis. We validate the superiority of DL-based CE and LMMSE over
LS for various signal-to-noise ratios (SNR) and wireless channels in terms of
mean square error (MSE) and bit error rate (BER). We also highlight the high
complexity, execution time, and power consumption of DL-based CE and LMMSE
approaches. To address this, we propose a novel compute-efficient LS-augmented
interpolated deep neural network (LSiDNN) based CE algorithm and realize it on
ZSoC. The proposed LSiDNN offers 88-90% lower execution time and 38-85% lower
resource utilization than state-of-the-art DL-based CE for identical MSE and
BER. LSiDNN offers significantly lower MSE and BER than LMMSE, and the gain
improves with increased mobility between transceivers. It offers 75% lower
execution time and 90-94% lower resource utilization than LMMSE.
</p>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01131" title="Abstract">arXiv:2403.01131</a> (cross-list from math.OC) [<a href="/pdf/2403.01131" title="Download PDF">pdf</a>, <a href="/format/2403.01131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMoCo: Instruction Tuning of Large Language Models for Optimization  Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ma%2C+Z">Zeyuan Ma</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hongshu Guo</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+G">Guojun Peng</a>, 
<a href="/search/math?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Y">Yining Ma</a>, 
<a href="/search/math?searchtype=author&query=Gong%2C+Y">Yue-Jiao Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE)

</div>
<p class="mathjax">Recent research explores optimization using large language models (LLMs) by
either iteratively seeking next-step solutions from LLMs or directly prompting
LLMs for an optimizer. However, these approaches exhibit inherent limitations,
including low operational efficiency, high sensitivity to prompt design, and a
lack of domain-specific knowledge. We introduce LLaMoCo, the first
instruction-tuning framework designed to adapt LLMs for solving optimization
problems in a code-to-code manner. Specifically, we establish a comprehensive
instruction set containing well-described problem prompts and effective
optimization codes. We then develop a novel two-phase learning strategy that
incorporates a contrastive learning-based warm-up procedure before the
instruction-tuning phase to enhance the convergence behavior during model
fine-tuning. The experiment results demonstrate that a CodeGen (350M) model
fine-tuned by our LLaMoCo achieves superior optimization performance compared
to GPT-4 Turbo and the other competitors across both synthetic and realistic
problem sets. The fine-tuned model and the usage instructions are available at
https://anonymous.4open.science/r/LLaMoCo-722A.
</p>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01150" title="Abstract">arXiv:2403.01150</a> (cross-list from stat.ME) [<a href="/pdf/2403.01150" title="Download PDF">pdf</a>, <a href="/ps/2403.01150" title="Download PostScript">ps</a>, <a href="/format/2403.01150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Analysis of a Simple Quaternion Estimator: the Gaussian Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Peng%2C+C">Caitong Peng</a>, 
<a href="/search/stat?searchtype=author&query=Choukroun%2C+D">Daniel Choukroun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Reference [1] introduces a novel closed-form quaternion estimator from two
vector observations. The simplicity of the estimator enables clear physical
insights and a closed-form expression for the bias as a function of the
quaternion error covariance matrix. The latter could be approximated up to
second order with respect to the underlying measurement noise assuming
arbitrary probability distribution. The current note relaxes the second-order
assumption and provides an expression for the error covariance that is exact to
the fourth order, under the assumption of Gaussian distribution. This not only
provides increased accuracy but also alleviates issues related to singularity.
This technical note presents a comprehensive derivation of the individual
components of the quaternion additive error covariance matrix.
</p>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01158" title="Abstract">arXiv:2403.01158</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2403.01158" title="Download PDF">pdf</a>, <a href="/ps/2403.01158" title="Download PostScript">ps</a>, <a href="/format/2403.01158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Committee Machine Potential for Oxygen-containing Organic  Compounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Kim%2C+S">Seungwon Kim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yang%2C+D+C">D. ChangMo Yang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Willow%2C+S+Y">Soohaeng Yoo Willow</a>, 
<a href="/search/cond-mat?searchtype=author&query=Myung%2C+C+W">Chang Woo Myung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding the pivotal role of oxygen-containing organic compounds in
serving as an energy source for living organisms and contributing to protein
formation is crucial in the field of biochemistry. This study addresses the
challenge of comprehending protein-protein interactions (PPI) and developing
predicitive models for proteins and organic compounds, with a specific focus on
quantifying their binding affinity. Here, we introduce the active Bayesian
Committee Machine (BCM) potential, specifically designed to predict
oxygen-containing organic compounds within eight groups of CHO. The BCM
potential adopts a committee-based approach to tackle scalability issues
associated with kernel regressors, particularly when dealing with large
datasets. Its adaptable structure allows for efficient and cost-effective
expansion, maintaing both transferability and scalability. Through systematic
benchmarking, we position the sparse BCM potential as a promising contender in
the pursuit of a universal machine learning potential.
</p>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01192" title="Abstract">arXiv:2403.01192</a> (cross-list from math.OC) [<a href="/pdf/2403.01192" title="Download PDF">pdf</a>, <a href="/format/2403.01192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Composite Decomposition Method for Large-Scale Global Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tian%2C+M">Maojiang Tian</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+M">Minyang Chen</a>, 
<a href="/search/math?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+Y">Yang Tang</a>, 
<a href="/search/math?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>, 
<a href="/search/math?searchtype=author&query=Yen%2C+G+G">Gary G. Yen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer
strategy, have emerged as the predominant approach to solving large-scale
global optimization (LSGO) problems. The efficiency and accuracy of the
grouping stage significantly impact the performance of the optimization
process. While the general separability grouping (GSG) method has overcome the
limitation of previous differential grouping (DG) methods by enabling the
decomposition of non-additively separable functions, it suffers from high
computational complexity. To address this challenge, this article proposes a
composite separability grouping (CSG) method, seamlessly integrating DG and GSG
into a problem decomposition framework to utilize the strengths of both
approaches. CSG introduces a step-by-step decomposition framework that
accurately decomposes various problem types using fewer computational
resources. By sequentially identifying additively, multiplicatively and
generally separable variables, CSG progressively groups non-separable variables
by recursively considering the interactions between each non-separable variable
and the formed non-separable groups. Furthermore, to enhance the efficiency and
accuracy of CSG, we introduce two innovative methods: a multiplicatively
separable variable detection method and a non-separable variable grouping
method. These two methods are designed to effectively detect multiplicatively
separable variables and efficiently group non-separable variables,
respectively. Extensive experimental results demonstrate that CSG achieves more
accurate variable grouping with lower computational complexity compared to GSG
and state-of-the-art DG series designs.
</p>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01206" title="Abstract">arXiv:2403.01206</a> (cross-list from quant-ph) [<a href="/pdf/2403.01206" title="Download PDF">pdf</a>, <a href="/format/2403.01206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting the Efficiency of Quantum Divider through Effective Design  Space Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+S">Siyi Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lim%2C+E">Eugene Lim</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chattopadhyay%2C+A">Anupam Chattopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is accepted for publication in ISCAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Rapid progress in the design of scalable, robust quantum computing
necessitates efficient quantum circuit implementation for algorithms with
practical relevance. For several algorithms, arithmetic kernels, in particular,
division plays an important role. In this manuscript, we focus on enhancing the
performance of quantum slow dividers by exploring the design choices of its
sub-blocks, such as, adders. Through comprehensive design space exploration of
state-of-the-art quantum addition building blocks, our work have resulted in an
impressive achievement: a reduction in Toffoli Depth of up to 94.06%,
accompanied by substantial reductions in both Toffoli and Qubit Count of up to
91.98% and 99.37%, respectively. This paper offers crucial perspectives on
efficient design of quantum dividers, and emphasizes the importance of adopting
a systematic design space exploration approach.
</p>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01260" title="Abstract">arXiv:2403.01260</a> (cross-list from math.OC) [<a href="/pdf/2403.01260" title="Download PDF">pdf</a>, <a href="/ps/2403.01260" title="Download PostScript">ps</a>, <a href="/format/2403.01260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Implicit Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Valenzuela%2C+L+F">Lucas Fuentes Valenzuela</a>, 
<a href="/search/math?searchtype=author&query=Brown%2C+R">Robin Brown</a>, 
<a href="/search/math?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The ability to differentiate through optimization problems has unlocked
numerous applications, from optimization-based layers in machine learning
models to complex design problems formulated as bilevel programs. It has been
shown that exploiting problem structure can yield significant computation gains
for optimization and, in some cases, enable distributed computation. One should
expect that this structure can be similarly exploited for gradient computation.
In this work, we discuss a decentralized framework for computing gradients of
constraint-coupled optimization problems. First, we show that this framework
results in significant computational gains, especially for large systems, and
provide sufficient conditions for its validity. Second, we leverage exponential
decay of sensitivities in graph-structured problems towards building a fully
distributed algorithm with convergence guarantees. Finally, we use the
methodology to rigorously estimate marginal emissions rates in power systems
models. Specifically, we demonstrate how the distributed scheme allows for
accurate and efficient estimation of these important emissions metrics on large
dynamic power system models.
</p>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01269" title="Abstract">arXiv:2403.01269</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.01269" title="Download PDF">pdf</a>, <a href="/format/2403.01269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network analysis using Krylov subspace trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Frost%2C+H+R">H. Robert Frost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We describe a set of network analysis methods based on the rows of the Krylov
subspace matrix computed from a network adjacency matrix via power iteration
using a non-random initial vector. We refer to these node-specific row vectors
as Krylov subspace trajectories. While power iteration using a random initial
starting vector is commonly applied to the network adjacency matrix to compute
eigenvector centrality values, this application only uses the final vector
generated after numerical convergence. Importantly, use of a random initial
vector means that the intermediate results of power iteration are also random
and lack a clear interpretation. To the best of our knowledge, use of
intermediate power iteration results for network analysis has been limited to
techniques that leverage just a single pre-convergence solution, e.g., Power
Iteration Clustering. In this paper, we explore methods that apply power
iteration with a non-random inital vector to the network adjacency matrix to
generate Krylov subspace trajectories for each node. These non-random
trajectories provide important information regarding network structure, node
importance, and response to perturbations. We have created this short preprint
in part to generate feedback from others in the network analysis community who
might be aware of similar existing work.
</p>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01318" title="Abstract">arXiv:2403.01318</a> (cross-list from stat.ML) [<a href="/pdf/2403.01318" title="Download PDF">pdf</a>, <a href="/format/2403.01318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Dimensional Tail Index Regression: with An Application to Text  Analyses of Viral Posts in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sasaki%2C+Y">Yuya Sasaki</a>, 
<a href="/search/stat?searchtype=author&query=Tao%2C+J">Jing Tao</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y">Yulong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
<p class="mathjax">Motivated by the empirical power law of the distributions of credits (e.g.,
the number of "likes") of viral posts in social media, we introduce the
high-dimensional tail index regression and methods of estimation and inference
for its parameters. We propose a regularized estimator, establish its
consistency, and derive its convergence rate. To conduct inference, we propose
to debias the regularized estimate, and establish the asymptotic normality of
the debiased estimator. Simulation studies support our theory. These methods
are applied to text analyses of viral posts in X (formerly Twitter) concerning
LGBTQ+.
</p>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01331" title="Abstract">arXiv:2403.01331</a> (cross-list from math.HO) [<a href="/pdf/2403.01331" title="Download PDF">pdf</a>, <a href="/ps/2403.01331" title="Download PostScript">ps</a>, <a href="/format/2403.01331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The legacy of Bletchley Park on UK mathematics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shiu%2C+D">Daniel Shiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The second world war saw a major influx of mathematical talent into the areas
of cryptanalysis and cryptography. This was particularly true at the UK's
Government Codes and Cypher School (GCCS) at Bletchley Park. The success of
introducing mathematical thinking into activities previously dominated by
linguists is well-studied, but the reciprocal question of how the cryptologic
effort affected the field of mathematics has been less investigated. Although
their cryptologic achievements are not as celebrated as those of Turing, Tutte
and Welchman, Bletchley Park's effort was supplemented by more eminent
mathematicians, and those who would achieve eminence and provide leadership and
direction for mathematical research in the United Kingdom. Amongst their number
were Ian Cassels, Sandy Green, Philip Hall, Max Newman and Henry Whitehead.
This paper considers how the experience of these and other mathematicians at
Bletchley Park may have informed and influenced the mathematics that was
produced in their post-war careers.
</p>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01332" title="Abstract">arXiv:2403.01332</a> (cross-list from q-bio.QM) [<a href="/pdf/2403.01332" title="Download PDF">pdf</a>, <a href="/format/2403.01332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chaining thoughts and LLMs to learn DNA structural biophysics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ross%2C+T+D">Tyler D. Ross</a>, 
<a href="/search/q-bio?searchtype=author&query=Gopinath%2C+A">Ashwin Gopinath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The future development of an AI scientist, a tool that is capable of
integrating a variety of experimental data and generating testable hypotheses,
holds immense potential. So far, bespoke machine learning models have been
created to specialize in singular scientific tasks, but otherwise lack the
flexibility of a general purpose model. Here, we show that a general purpose
large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the
structural biophysics of DNA. We find that both fine-tuning models to return
chain-of-thought responses and chaining together models fine-tuned for subtasks
have an enhanced ability to analyze and design DNA sequences and their
structures.
</p>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01353" title="Abstract">arXiv:2403.01353</a> (cross-list from quant-ph) [<a href="/pdf/2403.01353" title="Download PDF">pdf</a>, <a href="/format/2403.01353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially parallel decoding for multi-qubit lattice surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+S+F">Sophia Fuhui Lin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Peterson%2C+E+C">Eric C. Peterson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sankar%2C+K">Krishanu Sankar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sivarajah%2C+P">Prasahnt Sivarajah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Running quantum algorithms protected by quantum error correction requires a
real time, classical decoder. To prevent the accumulation of a backlog, this
decoder must process syndromes from the quantum device at a faster rate than
they are generated. Most prior work on real time decoding has focused on an
isolated logical qubit encoded in the surface code. However, for surface code,
quantum programs of utility will require multi-qubit interactions performed via
lattice surgery. A large merged patch can arise during lattice surgery --
possibly as large as the entire device. This puts a significant strain on a
real time decoder, which must decode errors on this merged patch and maintain
the level of fault-tolerance that it achieves on isolated logical qubits.
<br />These requirements are relaxed by using spatially parallel decoding, which
can be accomplished by dividing the physical qubits on the device into multiple
overlapping groups and assigning a decoder module to each. We refer to this
approach as spatially parallel windows. While previous work has explored
similar ideas, none have addressed system-specific considerations pertinent to
the task or the constraints from using hardware accelerators. In this work, we
demonstrate how to configure spatially parallel windows, so that the scheme (1)
is compatible with hardware accelerators, (2) supports general lattice surgery
operations, (3) maintains the fidelity of the logical qubits, and (4) meets the
throughput requirement for real time decoding. Furthermore, our results reveal
the importance of optimally choosing the buffer width to achieve a balance
between accuracy and throughput -- a decision that should be influenced by the
device's physical noise.
</p>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01355" title="Abstract">arXiv:2403.01355</a> (cross-list from eess.AS) [<a href="/pdf/2403.01355" title="Download PDF">pdf</a>, <a href="/ps/2403.01355" title="Download PostScript">ps</a>, <a href="/format/2403.01355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> a-DCF: an architecture agnostic metric with application to  spoofing-robust speaker verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shim%2C+H">Hye-jin Shim</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="/search/eess?searchtype=author&query=Kinnunen%2C+T">Tomi Kinnunen</a>, 
<a href="/search/eess?searchtype=author&query=Evans%2C+N">Nicholas Evans</a>, 
<a href="/search/eess?searchtype=author&query=Bonastre%2C+J">Jean-Francois Bonastre</a>, 
<a href="/search/eess?searchtype=author&query=Lapidot%2C+I">Itshak Lapidot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, submitted to Speaker Odyssey 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spoofing detection is today a mainstream research topic. Standard metrics can
be applied to evaluate the performance of isolated spoofing detection solutions
and others have been proposed to support their evaluation when they are
combined with speaker detection. These either have well-known deficiencies or
restrict the architectural approach to combine speaker and spoof detectors. In
this paper, we propose an architecture-agnostic detection cost function
(a-DCF). A generalisation of the original DCF used widely for the assessment of
automatic speaker verification (ASV), the a-DCF is designed for the evaluation
of spoofing-robust ASV. Like the DCF, the a-DCF reflects the cost of decisions
in a Bayes risk sense, with explicitly defined class priors and detection cost
model. We demonstrate the merit of the a-DCF through the benchmarking
evaluation of architecturally-heterogeneous spoofing-robust ASV solutions.
</p>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01362" title="Abstract">arXiv:2403.01362</a> (cross-list from eess.IV) [<a href="/pdf/2403.01362" title="Download PDF">pdf</a>, <a href="/ps/2403.01362" title="Download PostScript">ps</a>, <a href="/format/2403.01362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Retinal Vascular Structure Segmentation in Images With a Novel  Design Two-Path Interactive Fusion Module Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shunpu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Precision in identifying and differentiating micro and macro blood vessels in
the retina is crucial for the diagnosis of retinal diseases, although it poses
a significant challenge. Current autoencoding-based segmentation approaches
encounter limitations as they are constrained by the encoder and undergo a
reduction in resolution during the encoding stage. The inability to recover
lost information in the decoding phase further impedes these approaches.
Consequently, their capacity to extract the retinal microvascular structure is
restricted. To address this issue, we introduce Swin-Res-Net, a specialized
module designed to enhance the precision of retinal vessel segmentation.
Swin-Res-Net utilizes the Swin transformer which uses shifted windows with
displacement for partitioning, to reduce network complexity and accelerate
model convergence. Additionally, the model incorporates interactive fusion with
a functional module in the Res2Net architecture. The Res2Net leverages
multi-scale techniques to enlarge the receptive field of the convolutional
kernel, enabling the extraction of additional semantic information from the
image. This combination creates a new module that enhances the localization and
separation of micro vessels in the retina. To improve the efficiency of
processing vascular information, we've added a module to eliminate redundant
information between the encoding and decoding steps.
<br />Our proposed architecture produces outstanding results, either meeting or
surpassing those of other published models. The AUC reflects significant
enhancements, achieving values of 0.9956, 0.9931, and 0.9946 in pixel-wise
segmentation of retinal vessels across three widely utilized datasets:
CHASE-DB1, DRIVE, and STARE, respectively. Moreover, Swin-Res-Net outperforms
alternative architectures, demonstrating superior performance in both IOU and
F1 measure metrics.
</p>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01369" title="Abstract">arXiv:2403.01369</a> (cross-list from eess.AS) [<a href="/pdf/2403.01369" title="Download PDF">pdf</a>, <a href="/format/2403.01369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shankar%2C+R">Ravi Shankar</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+K">Ke Tan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+B">Buye Xu</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+A">Anurag Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages; Shorter form accepted in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised learned models have been found to be very effective for
certain speech tasks such as automatic speech recognition, speaker
identification, keyword spotting and others. While the features are undeniably
useful in speech recognition and associated tasks, their utility in speech
enhancement systems is yet to be firmly established, and perhaps not properly
understood. In this paper, we investigate the uses of SSL representations for
single-channel speech enhancement in challenging conditions and find that they
add very little value for the enhancement task. Our constraints are designed
around on-device real-time speech enhancement -- model is causal, the compute
footprint is small. Additionally, we focus on low SNR conditions where such
models struggle to provide good enhancement. In order to systematically examine
how SSL representations impact performance of such enhancement models, we
propose a variety of techniques to utilize these embeddings which include
different forms of knowledge-distillation and pre-training.
</p>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01371" title="Abstract">arXiv:2403.01371</a> (cross-list from stat.ML) [<a href="/pdf/2403.01371" title="Download PDF">pdf</a>, <a href="/format/2403.01371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale variational Gaussian state-space models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dowling%2C+M">Matthew Dowling</a>, 
<a href="/search/stat?searchtype=author&query=Zhao%2C+Y">Yuan Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Park%2C+I+M">Il Memming Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce an amortized variational inference algorithm and structured
variational approximation for state-space models with nonlinear dynamics driven
by Gaussian noise. Importantly, the proposed framework allows for efficient
evaluation of the ELBO and low-variance stochastic gradient estimates without
resorting to diagonal Gaussian approximations by exploiting (i) the low-rank
structure of Monte-Carlo approximations to marginalize the latent state through
the dynamics (ii) an inference network that approximates the update step with
low-rank precision matrix updates (iii) encoding current and future
observations into pseudo observations -- transforming the approximate smoothing
problem into an (easier) approximate filtering problem. Overall, the necessary
statistics and ELBO can be computed in $O(TL(Sr + S^2 + r^2))$ time where $T$
is the series length, $L$ is the state-space dimensionality, $S$ are the number
of samples used to approximate the predict step statistics, and $r$ is the rank
of the approximate precision matrix update in the update step (which can be
made of much lower dimension than $L$).
</p>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01435" title="Abstract">arXiv:2403.01435</a> (cross-list from math.OC) [<a href="/pdf/2403.01435" title="Download PDF">pdf</a>, <a href="/ps/2403.01435" title="Download PostScript">ps</a>, <a href="/format/2403.01435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Least-Squares Optimization Solvers with Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+W">Weijia Liu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+F">Fanghong Guo</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Z">Zhengguang Wu</a>, 
<a href="/search/math?searchtype=author&query=Su%2C+H">Hongye Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper studies the distributed least-squares optimization problem with
differential privacy requirement of local cost functions, for which two
differentially private distributed solvers are proposed. The first is
established on the distributed gradient tracking algorithm, by appropriately
perturbing the initial values and parameters that contain the privacy-sensitive
data with Gaussian and truncated Laplacian noises, respectively. Rigorous
proofs are established to show the achievable trade-off between the
({\epsilon}, {\delta})-differential privacy and the computation accuracy. The
second solver is established on the combination of the distributed shuffling
mechanism and the average consensus algorithm, which enables each agent to
obtain a noisy version of parameters characterizing the global gradient. As a
result, the least-squares optimization problem can be eventually solved by each
agent locally in such a way that any given ({\epsilon}, {\delta})-differential
privacy requirement can be preserved while the solution may be computed with
the accuracy independent of the network size, which makes the latter more
suitable for large-scale distributed least-squares problems. Numerical
simulations are presented to show the effectiveness of both solvers.
</p>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01442" title="Abstract">arXiv:2403.01442</a> (cross-list from econ.TH) [<a href="/pdf/2403.01442" title="Download PDF">pdf</a>, <a href="/ps/2403.01442" title="Download PostScript">ps</a>, <a href="/format/2403.01442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic and pessimistic approaches for cooperative games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Atay%2C+A">Ata Atay</a>, 
<a href="/search/econ?searchtype=author&query=Trudeau%2C+C">Christian Trudeau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Cooperative game theory aims to study how to divide a joint value created by
a set of players. These games are often studied through the characteristic
function form with transferable utility, which represents the value obtainable
by each coalition. In the presence of externalities, there are many ways to
define this value. Various models that account for different levels of player
cooperation and the influence of external players on coalition value have been
studied. Although there are different approaches, typically, the optimistic and
pessimistic approaches provide sufficient insights into strategic interactions.
This paper clarifies the interpretation of these approaches by providing a
unified framework. We show that making sure that no coalition receives more
than their (optimistic) upper bounds is always at least as difficult as
guaranteeing their (pessimistic) lower bounds. We also show that if
externalities are negative, providing these guarantees is always feasible.
Then, we explore applications and show how our findings can be applied to
derive results from the existing literature.
</p>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01478" title="Abstract">arXiv:2403.01478</a> (cross-list from math.OC) [<a href="/pdf/2403.01478" title="Download PDF">pdf</a>, <a href="/format/2403.01478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Discrete-time Dynamic Outer Approximation of the  Intersection of Ellipsoids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sebasti%C3%A1n%2C+E">Eduardo Sebasti&#xe1;n</a>, 
<a href="/search/math?searchtype=author&query=Aldana-L%C3%B3pez%2C+R">Rodrigo Aldana-L&#xf3;pez</a>, 
<a href="/search/math?searchtype=author&query=Arag%C3%BC%C3%A9s%2C+R">Rosario Arag&#xfc;&#xe9;s</a>, 
<a href="/search/math?searchtype=author&query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="/search/math?searchtype=author&query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sag&#xfc;&#xe9;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents the first discrete-time distributed algorithm to track
the tightest ellipsoids that outer approximates the global dynamic intersection
of ellipsoids. The ellipsoids are defined as time-varying positive definite
matrices. On the other hand, given an undirected network, each node is equipped
with one of these ellipsoids. The solution is based on a novel distributed
reformulation of the original centralized semi-definite outer L\"owner-John
program, characterized by a non-separable objective function and global
constraints. We prove finite-time convergence to the global minima of the
centralized problem in the static case and finite-time bounded tracking error
in the dynamic case. Moreover, we prove boundedness of estimation in the
tracking of the global optimum and robustness in the estimation against
time-varying inputs. As a by-product, the proposed algorithm extends min/max
dynamic consensus algorithms to positive definite matrices. We illustrate the
properties of the algorithm with different simulated examples, including a
distributed estimation showcase where our proposal is integrated into a
distributed Kalman filter to surpass the state-of-the-art in mean square error
performance.
</p>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01485" title="Abstract">arXiv:2403.01485</a> (cross-list from stat.ML) [<a href="/pdf/2403.01485" title="Download PDF">pdf</a>, <a href="/format/2403.01485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximations to the Fisher Information Metric of Deep Generative  Models for Out-Of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dauncey%2C+S">Sam Dauncey</a>, 
<a href="/search/stat?searchtype=author&query=Holmes%2C+C">Chris Holmes</a>, 
<a href="/search/stat?searchtype=author&query=Williams%2C+C">Christopher Williams</a>, 
<a href="/search/stat?searchtype=author&query=Falck%2C+F">Fabian Falck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Likelihood-based deep generative models such as score-based diffusion models
and variational autoencoders are state-of-the-art machine learning models
approximating high-dimensional distributions of data such as images, text, or
audio. One of many downstream tasks they can be naturally applied to is
out-of-distribution (OOD) detection. However, seminal work by Nalisnick et al.
which we reproduce showed that deep generative models consistently infer higher
log-likelihoods for OOD data than data they were trained on, marking an open
problem. In this work, we analyse using the gradient of a data point with
respect to the parameters of the deep generative model for OOD detection, based
on the simple intuition that OOD data should have larger gradient norms than
training data. We formalise measuring the size of the gradient as approximating
the Fisher information metric. We show that the Fisher information matrix (FIM)
has large absolute diagonal values, motivating the use of chi-square
distributed, layer-wise gradient norms as features. We combine these features
to make a simple, model-agnostic and hyperparameter-free method for OOD
detection which estimates the joint density of the layer-wise gradient norms
for a given data point. We find that these layer-wise gradient norms are weakly
correlated, rendering their combined usage informative, and prove that the
layer-wise gradient norms satisfy the principle of (data representation)
invariance. Our empirical results indicate that this method outperforms the
Typicality test for most deep generative models and image dataset pairings.
</p>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01494" title="Abstract">arXiv:2403.01494</a> (cross-list from eess.AS) [<a href="/pdf/2403.01494" title="Download PDF">pdf</a>, <a href="/format/2403.01494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAVITS: Exploring Prosody-aware VITS for End-to-End Emotional Voice  Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qi%2C+T">Tianhua Qi</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+W">Wenming Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zong%2C+Y">Yuan Zong</a>, 
<a href="/search/eess?searchtype=author&query=Lian%2C+H">Hailun Lian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we propose Prosody-aware VITS (PAVITS) for emotional voice
conversion (EVC), aiming to achieve two major objectives of EVC: high content
naturalness and high emotional naturalness, which are crucial for meeting the
demands of human perception. To improve the content naturalness of converted
audio, we have developed an end-to-end EVC architecture inspired by the high
audio quality of VITS. By seamlessly integrating an acoustic converter and
vocoder, we effectively address the common issue of mismatch between emotional
prosody training and run-time conversion that is prevalent in existing EVC
models. To further enhance the emotional naturalness, we introduce an emotion
descriptor to model the subtle prosody variations of different speech emotions.
Additionally, we propose a prosody predictor, which predicts prosody features
from text based on the provided emotion label. Notably, we introduce a prosody
alignment loss to establish a connection between latent prosody features from
two distinct modalities, ensuring effective training. Experimental results show
that the performance of PAVITS is superior to the state-of-the-art EVC methods.
Speech Samples are available at https://jeremychee4.github.io/pavits4EVC/ .
</p>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01496" title="Abstract">arXiv:2403.01496</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2403.01496" title="Download PDF">pdf</a>, <a href="/format/2403.01496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A face-centred finite volume method for laminar and turbulent  incompressible flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Vieira%2C+L+M">Luan M. Vieira</a>, 
<a href="/search/physics?searchtype=author&query=Giacomini%2C+M">Matteo Giacomini</a>, 
<a href="/search/physics?searchtype=author&query=Sevilla%2C+R">Ruben Sevilla</a>, 
<a href="/search/physics?searchtype=author&query=Huerta%2C+A">Antonio Huerta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 23 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work develops, for the first time, a face-centred finite volume (FCFV)
solver for the simulation of laminar and turbulent viscous incompressible
flows. The formulation relies on the Reynolds-averaged Navier-Stokes (RANS)
equations coupled with the negative Spalart-Allmaras (SA) model and three novel
convective stabilisations, inspired by Riemann solvers, are derived and
compared numerically. The resulting method achieves first-order convergence of
the velocity, the velocity-gradient tensor and the pressure. FCFV accurately
predicts engineering quantities of interest, such as drag and lift, on
unstructured meshes and, by avoiding gradient reconstruction, the method is
insensitive to mesh quality, even in the presence of highly distorted and
stretched cells. A monolithic and a staggered solution strategies for the
RANS-SA system are derived and compared numerically. Numerical benchmarks,
involving laminar and turbulent, steady and transient cases are used to assess
the performance, accuracy and robustness of the proposed FCFV method.
</p>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01506" title="Abstract">arXiv:2403.01506</a> (cross-list from math.CO) [<a href="/pdf/2403.01506" title="Download PDF">pdf</a>, <a href="/ps/2403.01506" title="Download PostScript">ps</a>, <a href="/format/2403.01506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new family of $2$-scattered subspaces and related MRD codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartoli%2C+D">Daniele Bartoli</a>, 
<a href="/search/math?searchtype=author&query=Ghiandoni%2C+F">Francesco Ghiandoni</a>, 
<a href="/search/math?searchtype=author&query=Giannoni%2C+A">Alessandro Giannoni</a>, 
<a href="/search/math?searchtype=author&query=Marino%2C+G">Giuseppe Marino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Scattered subspaces and $h$-scattered subspaces have been extensively studied
in recent decades for both theoretical purposes and their connections to
various applications. While numerous constructions of scattered subspaces
exist, relatively few are known about $h$-scattered subspaces with $h\geq2$. In
this paper, we establish the existence of maximum $2$-scattered
$\F_q$-subspaces in $V(r,q^6)$ whenever $r\geq 3$, $r\ne 5$, and $q$ is an odd
power of $2$. Additionally, we explore the corresponding MRD codes.
</p>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01513" title="Abstract">arXiv:2403.01513</a> (cross-list from eess.IV) [<a href="/pdf/2403.01513" title="Download PDF">pdf</a>, <a href="/ps/2403.01513" title="Download PostScript">ps</a>, <a href="/format/2403.01513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDSE-UNet: Enhancing COVID-19 CT Image Segmentation with Canny Edge  Detection and Dual-Path SENet Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ding%2C+J">Jiao Ding</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+J">Jie Chang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+R">Renrui Han</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+L">Li Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate segmentation of COVID-19 CT images is crucial for reducing the
severity and mortality rates associated with COVID-19 infections. In response
to blurred boundaries and high variability characteristic of lesion areas in
COVID-19 CT images, we introduce CDSE-UNet: a novel UNet-based segmentation
model that integrates Canny operator edge detection and a dual-path SENet
feature fusion mechanism. This model enhances the standard UNet architecture by
employing the Canny operator for edge detection in sample images, paralleling
this with a similar network structure for semantic feature extraction. A key
innovation is the Double SENet Feature Fusion Block, applied across
corresponding network layers to effectively combine features from both image
paths. Moreover, we have developed a Multiscale Convolution approach, replacing
the standard Convolution in UNet, to adapt to the varied lesion sizes and
shapes. This addition not only aids in accurately classifying lesion edge
pixels but also significantly improves channel differentiation and expands the
capacity of the model. Our evaluations on public datasets demonstrate
CDSE-UNet's superior performance over other leading models, particularly in
segmenting large and small lesion areas, accurately delineating lesion edges,
and effectively suppressing noise
</p>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01523" title="Abstract">arXiv:2403.01523</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2403.01523" title="Download PDF">pdf</a>, <a href="/ps/2403.01523" title="Download PostScript">ps</a>, <a href="/format/2403.01523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven local operator finding for reduced-order modelling of plasma  systems: I. Concept and verifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Faraji%2C+F">Farbod Faraji</a>, 
<a href="/search/physics?searchtype=author&query=Reza%2C+M">Maryam Reza</a>, 
<a href="/search/physics?searchtype=author&query=Knoll%2C+A">Aaron Knoll</a>, 
<a href="/search/physics?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Reduced-order plasma models that can efficiently predict plasma behavior
across various settings and configurations are highly sought after yet elusive.
The demand for such models has surged in the past decade due to their potential
to facilitate scientific research and expedite the development of plasma
technologies. In line with the advancements in computational power and
data-driven methods, we introduce the "Phi Method" in this two-part article.
Part I presents this novel algorithm, which employs constrained regression on a
candidate term library informed by numerical discretization schemes to discover
discretized systems of differential equations. We demonstrate Phi Method's
efficacy in deriving reliable and robust reduced-order models (ROMs) for three
test cases: the Lorenz attractor, flow past a cylinder, and a 1D
Hall-thruster-representative plasma. Part II will delve into the method's
application for parametric dynamics discovery. Our results show that ROMs
derived from the Phi Method provide remarkably accurate predictions of systems'
behavior, whether derived from steady-state or transient-state data. This
underscores the method's potential for transforming plasma system modeling.
</p>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01532" title="Abstract">arXiv:2403.01532</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2403.01532" title="Download PDF">pdf</a>, <a href="/ps/2403.01532" title="Download PostScript">ps</a>, <a href="/format/2403.01532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven local operator finding for reduced-order modelling of plasma  systems: II. Application to parametric dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Faraji%2C+F">Farbod Faraji</a>, 
<a href="/search/physics?searchtype=author&query=Reza%2C+M">Maryam Reza</a>, 
<a href="/search/physics?searchtype=author&query=Knoll%2C+A">Aaron Knoll</a>, 
<a href="/search/physics?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Real-world systems often exhibit dynamics influenced by various parameters,
either inherent or externally controllable, necessitating models capable of
reliably capturing these parametric behaviors. Plasma technologies exemplify
such systems. For example, phenomena governing global dynamics in Hall
thrusters (a spacecraft propulsion technology) vary with various parameters,
such as the "self-sustained electric field". In this Part II, following on the
introduction of our novel data-driven local operator finding algorithm, Phi
Method, in Part I, we showcase the method's effectiveness in learning
parametric dynamics to predict system behavior across unseen parameter spaces.
We present two adaptations: the "parametric Phi Method" and the "ensemble Phi
Method", which are demonstrated through 2D fluid-flow-past-a-cylinder and 1D
Hall-thruster-plasma-discharge problems. Comparative evaluation against
parametric OPT-DMD in the fluid case demonstrates superior predictive
performance of the parametric Phi Method. Across both test cases, parametric
and ensemble Phi Method reliably recover governing parametric PDEs and offer
accurate predictions over test parameters. Ensemble ROM analysis underscores
Phi Method's robust learning of dominant dynamic coefficients with high
confidence.
</p>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01550" title="Abstract">arXiv:2403.01550</a> (cross-list from math.CO) [<a href="/pdf/2403.01550" title="Download PDF">pdf</a>, <a href="/format/2403.01550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral antisymmetry of twisted graph adjacency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+Y">Ye Luo</a>, 
<a href="/search/math?searchtype=author&query=Roy%2C+A">Arindam Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Number Theory (math.NT); Spectral Theory (math.SP)

</div>
<p class="mathjax">We address a prime counting problem across the homology classes of a graph,
presenting a graph-theoretical Dirichlet-type analogue of the prime number
theorem. The main machinery we have developed and employed is a spectral
antisymmetry theorem, revealing that the spectra of the twisted graph adjacency
matrices have an antisymmetric distribution over the character group of the
graph. Additionally, we derive some trace formulas based on the twisted
adjacency matrices as part of our analysis.
</p>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01571" title="Abstract">arXiv:2403.01571</a> (cross-list from stat.ML) [<a href="/pdf/2403.01571" title="Download PDF">pdf</a>, <a href="/format/2403.01571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limits to classification performance by relating Kullback-Leibler  divergence to Cohen&#x27;s Kappa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Crow%2C+L">L. Crow</a>, 
<a href="/search/stat?searchtype=author&query=Watts%2C+S+J">S. J. Watts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the American Statistical Association Symposium on Data Science and Statistics, St. Louis, USA, May 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">The performance of machine learning classification algorithms are evaluated
by estimating metrics, often from the confusion matrix, using training data and
cross-validation. However, these do not prove that the best possible
performance has been achieved. Fundamental limits to error rates can be
estimated using information distance measures. To this end, the confusion
matrix has been formulated to comply with the Chernoff-Stein Lemma. This links
the error rates to the Kullback-Leibler divergences between the probability
density functions describing the two classes. This leads to a key result that
relates Cohen's Kappa to the Resistor Average Distance which is the parallel
resistor combination of the two Kullback-Leibler divergences. The Resistor
Average Distance has units of bits and is estimated from the same training data
used by the classification algorithm, using kNN estimates of the
KullBack-Leibler divergences. The classification algorithm gives the confusion
matrix and Kappa. Theory and methods are discussed in detail and then applied
to Monte Carlo data and real datasets. Four very different real datasets -
Breast Cancer, Coronary Heart Disease, Bankruptcy, and Particle Identification
- are analysed, with both continuous and discrete values, and their
classification performance compared to the expected theoretical limit. In all
cases this analysis shows that the algorithms could not have performed any
better due to the underlying probability density functions for the two classes.
Important lessons are learnt on how to predict the performance of algorithms
for imbalanced data using training datasets that are approximately balanced.
Machine learning is very powerful but classification performance ultimately
depends on the quality of the data and the relevance of the variables to the
problem.
</p>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01598" title="Abstract">arXiv:2403.01598</a> (cross-list from eess.IV) [<a href="/pdf/2403.01598" title="Download PDF">pdf</a>, <a href="/format/2403.01598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APISR: Anime Production Inspired Real-World Anime Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Boyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+F">Fengyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xihang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H">Hanbin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While real-world anime super-resolution (SR) has gained increasing attention
in the SR community, existing methods still adopt techniques from the
photorealistic domain. In this paper, we analyze the anime production workflow
and rethink how to use characteristics of it for the sake of the real-world
anime SR. First, we argue that video networks and datasets are not necessary
for anime SR due to the repetition use of hand-drawing frames. Instead, we
propose an anime image collection pipeline by choosing the least compressed and
the most informative frames from the video sources. Based on this pipeline, we
introduce the Anime Production-oriented Image (API) dataset. In addition, we
identify two anime-specific challenges of distorted and faint hand-drawn lines
and unwanted color artifacts. We address the first issue by introducing a
prediction-oriented compression module in the image degradation model and a
pseudo-ground truth preparation with enhanced hand-drawn lines. In addition, we
introduce the balanced twin perceptual loss combining both anime and
photorealistic high-level features to mitigate unwanted color artifacts and
increase visual clarity. We evaluate our method through extensive experiments
on the public benchmark, showing our method outperforms state-of-the-art
approaches by a large margin.
</p>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01635" title="Abstract">arXiv:2403.01635</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2403.01635" title="Download PDF">pdf</a>, <a href="/format/2403.01635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Neural Ordinary Differential Equations for Tokamak Plasma  Dynamics Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+Z">Zefang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Stacey%2C+W+M">Weston M. Stacey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the quest for controlled thermonuclear fusion, tokamaks present complex
challenges in understanding burning plasma dynamics. This study introduces a
multi-region multi-timescale transport model, employing Neural Ordinary
Differential Equations (Neural ODEs) to simulate the intricate energy transfer
processes within tokamaks. Our methodology leverages Neural ODEs for the
numerical derivation of diffusivity parameters from DIII-D tokamak experimental
data, enabling the precise modeling of energy interactions between electrons
and ions across various regions, including the core, edge, and scrape-off
layer. These regions are conceptualized as distinct nodes, capturing the
critical timescales of radiation and transport processes essential for
efficient tokamak operation. Validation against DIII-D plasmas under various
auxiliary heating conditions demonstrates the model's effectiveness, ultimately
shedding light on ways to enhance tokamak performance with deep learning.
</p>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01636" title="Abstract">arXiv:2403.01636</a> (cross-list from stat.ML) [<a href="/pdf/2403.01636" title="Download PDF">pdf</a>, <a href="/format/2403.01636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Efficient Myopic Exploration Through Multitask Reinforcement  Learning with Diverse Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+Z">Ziping Xu</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+Z">Zifan Xu</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+R">Runxuan Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/stat?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multitask Reinforcement Learning (MTRL) approaches have gained increasing
attention for its wide applications in many important Reinforcement Learning
(RL) tasks. However, while recent advancements in MTRL theory have focused on
the improved statistical efficiency by assuming a shared structure across
tasks, exploration--a crucial aspect of RL--has been largely overlooked. This
paper addresses this gap by showing that when an agent is trained on a
sufficiently diverse set of tasks, a generic policy-sharing algorithm with
myopic exploration design like $\epsilon$-greedy that are inefficient in
general can be sample-efficient for MTRL. To the best of our knowledge, this is
the first theoretical demonstration of the "exploration benefits" of MTRL. It
may also shed light on the enigmatic success of the wide applications of myopic
exploration in practice. To validate the role of diversity, we conduct
experiments on synthetic robotic control environments, where the diverse task
set aligns with the task selection by automatic curriculum learning, which is
empirically shown to improve sample-efficiency.
</p>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01657" title="Abstract">arXiv:2403.01657</a> (cross-list from math.OC) [<a href="/pdf/2403.01657" title="Download PDF">pdf</a>, <a href="/ps/2403.01657" title="Download PostScript">ps</a>, <a href="/format/2403.01657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized pair-wise logit dynamic and its connection to a mean field  game: theoretical and computational investigations focusing on resource  management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yoshioka%2C+H">Hidekazu Yoshioka</a>, 
<a href="/search/math?searchtype=author&query=Tsujimura%2C+M">Motoh Tsujimura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Logit dynamics are evolution equations that describe transitions to
equilibria of actions among many players. We formulate a pair-wise logit
dynamic in a continuous action space with a generalized exponential function,
which we call a generalized pair-wise logit dynamic, depicted by a new
evolution equation nonlocal in space. We prove the well-posedness and
approximability of the generalized pair-wise logit dynamic to show that it is
computationally implementable. We also show that this dynamic has an explicit
connection to a mean field game of a controlled pure-jump process, with which
the two different mathematical models can be understood in a unified way.
Particularly, we show that the generalized pair-wise logit dynamic is derived
as a myopic version of the corresponding mean field game, and that the
conditions to guarantee the existence of unique solutions are different from
each other. The key in this procedure is to find the objective function to be
optimized in the mean field game based on the logit function. The monotonicity
of the utility is unnecessary for the generalized pair-wise logit dynamic but
crucial for the mean field game. Finally, we present applications of the two
approaches to fisheries management problems with collected data.
</p>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01658" title="Abstract">arXiv:2403.01658</a> (cross-list from math.PR) [<a href="/pdf/2403.01658" title="Download PDF">pdf</a>, <a href="/ps/2403.01658" title="Download PostScript">ps</a>, <a href="/format/2403.01658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise sensitivity and stability on groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tanaka%2C+R">Ryokichi Tanaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We provide finitely generated infinite groups on which natural random walks
are noise sensitive in total variation as well as ones on which natural random
walks are noise stable in total variation.
</p>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01670" title="Abstract">arXiv:2403.01670</a> (cross-list from eess.AS) [<a href="/pdf/2403.01670" title="Download PDF">pdf</a>, <a href="/format/2403.01670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6DoF SELD: Sound Event Localization and Detection Using Microphones and  Motion Tracking Sensors on self-motioning human
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yasuda%2C+M">Masahiro Yasuda</a>, 
<a href="/search/eess?searchtype=author&query=Saito%2C+S">Shoichiro Saito</a>, 
<a href="/search/eess?searchtype=author&query=Nakayama%2C+A">Akira Nakayama</a>, 
<a href="/search/eess?searchtype=author&query=Harada%2C+N">Noboru Harada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">We aim to perform sound event localization and detection (SELD) using
wearable equipment for a moving human, such as a pedestrian. Conventional SELD
tasks have dealt only with microphone arrays located in static positions.
However, self-motion with three rotational and three translational degrees of
freedom (6DoF) shall be considered for wearable microphone arrays. A system
trained only with a dataset using microphone arrays in a fixed position would
be unable to adapt to the fast relative motion of sound events associated with
self-motion, resulting in the degradation of SELD performance. To address this,
we designed 6DoF SELD Dataset for wearable systems, the first SELD dataset
considering the self-motion of microphones. Furthermore, we proposed a
multi-modal SELD system that jointly utilizes audio and motion tracking sensor
signals. These sensor signals are expected to help the system find useful
acoustic cues for SELD on the basis of the current self-motion state.
Experimental results on our dataset show that the proposed method effectively
improves SELD performance with a mechanism to extract acoustic features
conditioned by sensor signals.
</p>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01673" title="Abstract">arXiv:2403.01673</a> (cross-list from stat.ML) [<a href="/pdf/2403.01673" title="Download PDF">pdf</a>, <a href="/format/2403.01673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATS: Enhancing Multivariate Time Series Forecasting by Constructing  Auxiliary Time Series as Exogenous Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lu%2C+J">Jiecheng Lu</a>, 
<a href="/search/stat?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+Y">Yan Sun</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+S">Shihao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">For Multivariate Time Series Forecasting (MTSF), recent deep learning
applications show that univariate models frequently outperform multivariate
ones. To address the difficiency in multivariate models, we introduce a method
to Construct Auxiliary Time Series (CATS) that functions like a 2D
temporal-contextual attention mechanism, which generates Auxiliary Time Series
(ATS) from Original Time Series (OTS) to effectively represent and incorporate
inter-series relationships for forecasting. Key principles of ATS - continuity,
sparsity, and variability - are identified and implemented through different
modules. Even with a basic 2-layer MLP as core predictor, CATS achieves
state-of-the-art, significantly reducing complexity and parameters compared to
previous multivariate models, marking it an efficient and transferable MTSF
solution.
</p>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01692" title="Abstract">arXiv:2403.01692</a> (cross-list from astro-ph.IM) [<a href="/pdf/2403.01692" title="Download PDF">pdf</a>, <a href="/format/2403.01692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PI-AstroDeconv: A Physics-Informed Unsupervised Learning Method for  Astronomical Image Deconvolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Ni%2C+S">Shulei Ni</a>, 
<a href="/search/astro-ph?searchtype=author&query=Qiu%2C+Y">Yisheng Qiu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chen%2C+Y">Yunchun Chen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Song%2C+Z">Zihao Song</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jiang%2C+X">Xuejian Jiang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chen%2C+H">Huaxi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Astrophysics of Galaxies (astro-ph.GA); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In the imaging process of an astronomical telescope, the deconvolution of its
beam or Point Spread Function (PSF) is a crucial task. However, deconvolution
presents a classical and challenging inverse computation problem. In scenarios
where the beam or PSF is complex or inaccurately measured, such as in
interferometric arrays and certain radio telescopes, the resultant blurry
images are often challenging to interpret visually or analyze using traditional
physical detection methods. We argue that traditional methods frequently lack
specific prior knowledge, thereby leading to suboptimal performance. To address
this issue and achieve image deconvolution and reconstruction, we propose an
unsupervised network architecture that incorporates prior physical information.
The network adopts an encoder-decoder structure while leveraging the
telescope's PSF as prior knowledge. During network training, we introduced
accelerated Fast Fourier Transform (FFT) convolution to enable efficient
processing of high-resolution input images and PSFs. We explored various
classic regression networks, including autoencoder (AE) and U-Net, and
conducted a comprehensive performance evaluation through comparative analysis.
</p>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01717" title="Abstract">arXiv:2403.01717</a> (cross-list from stat.ML) [<a href="/pdf/2403.01717" title="Download PDF">pdf</a>, <a href="/format/2403.01717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft-constrained Schrodinger Bridge: a Stochastic Control Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Garg%2C+J">Jhanvi Garg</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+X">Xianyang Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 7 figures. Accepted by AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Computation (stat.CO)

</div>
<p class="mathjax">Schr\"{o}dinger bridge can be viewed as a continuous-time stochastic control
problem where the goal is to find an optimally controlled diffusion process
with a pre-specified terminal distribution $\mu_T$. We propose to generalize
this stochastic control problem by allowing the terminal distribution to differ
from $\mu_T$ but penalizing the Kullback-Leibler divergence between the two
distributions. We call this new control problem soft-constrained
Schr\"{o}dinger bridge (SSB). The main contribution of this work is a
theoretical derivation of the solution to SSB, which shows that the terminal
distribution of the optimally controlled process is a geometric mixture of
$\mu_T$ and some other distribution. This result is further extended to a time
series setting. One application of SSB is the development of robust generative
diffusion models. We propose a score matching-based algorithm for sampling from
geometric mixtures and showcase its use via a numerical example for the MNIST
data set.
</p>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01723" title="Abstract">arXiv:2403.01723</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2403.01723" title="Download PDF">pdf</a>, <a href="/format/2403.01723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Mechanics of Dynamical System Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Klishin%2C+A+A">Andrei A. Klishin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bakarji%2C+J">Joseph Bakarji</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kutz%2C+J+N">J. Nathan Kutz</a>, 
<a href="/search/cond-mat?searchtype=author&query=Manohar%2C+K">Krithika Manohar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 RevTeX page, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Recovering dynamical equations from observed noisy data is the central
challenge of system identification. We develop a statistical mechanical
approach to analyze sparse equation discovery algorithms, which typically
balance data fit and parsimony through a trial-and-error selection of
hyperparameters. In this framework, statistical mechanics offers tools to
analyze the interplay between complexity and fitness, in analogy to that done
between entropy and energy. To establish this analogy, we define the
optimization procedure as a two-level Bayesian inference problem that separates
variable selection from coefficient values and enables the computation of the
posterior parameter distribution in closed form. A key advantage of employing
statistical mechanical concepts, such as free energy and the partition
function, is in the quantification of uncertainty, especially in in the
low-data limit; frequently encountered in real-world applications. As the data
volume increases, our approach mirrors the thermodynamic limit, leading to
distinct sparsity- and noise-induced phase transitions that delineate correct
from incorrect identification. This perspective of sparse equation discovery,
is versatile and can be adapted to various other equation discovery algorithms.
</p>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01758" title="Abstract">arXiv:2403.01758</a> (cross-list from eess.IV) [<a href="/pdf/2403.01758" title="Download PDF">pdf</a>, <a href="/format/2403.01758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFBT GAN: enhanced explainability and diagnostic performance for  cognitive decline by counterfactual generative adversarial network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+X">Xiongri Shen</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zhenxi Song</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhiguo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Existing explanation results of functional connectivity (FC) are normally
generated by using classification result labels and correlation analysis
methods such as Pearson's correlation or gradient backward. However, the
diagnostic model is still trained on the black box model and might lack the
attention of FCs in important regions during the training. To enhance the
explainability and improve diagnostic performance, providing prior knowledge on
neurodegeneration-related regions when healthy subjects (HC) develop into
subject cognitive decline (SCD) and mild cognitive impairment (MCI) for the
diagnostic model is a key step. To better determine the
neurodegeneration-related regions, we employ counterfactual reasoning to
generate the target label FC matrices derived from source label FC and then
subtract source label FC with target label FC. The counterfactual reasoning
architecture is constructed by adaptive forward and backward transformer
generative adversarial network (AFBT GAN), which is specifically designed by
network property in FC and inverse patch embedding operation in the
transformer. The specific design can make the model focus more on the current
network correlation and employ the global insight of the transformer to
reconstruct FC, which both help the generation of high-quality target label FC.
The validation experiments are conducted on both clinical and public datasets,
the generated attention map are both vital correlated to cognitive function and
the diagnostic performance is also significant. The code is available at
https://github.com/SXR3015/AFBT-GAN.
</p>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01771" title="Abstract">arXiv:2403.01771</a> (cross-list from math.CO) [<a href="/pdf/2403.01771" title="Download PDF">pdf</a>, <a href="/format/2403.01771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly modular graphs with diamond condition, the interval function and  axiomatic characterizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kamalolbhavan-Sheela%2C+L+K">Lekshmi Kamal Kamalolbhavan-Sheela</a>, 
<a href="/search/math?searchtype=author&query=Jacob%2C+J">Jeny Jacob</a>, 
<a href="/search/math?searchtype=author&query=Changat%2C+M">Manoj Changat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Weakly modular graphs are defined as the class of graphs that satisfy the
\emph{triangle condition ($TC$)} and the \emph{quadrangle condition ($QC$)}. We
study an interesting subclass of weakly modular graphs that satisfies a
stronger version of the triangle condition, known as the \emph{triangle diamond
condition ($TDC$)}. and term this subclass of weakly modular graphs as the
\emph{diamond-weakly modular graphs}. It is observed that this class contains
the class of bridged graphs and the class of weakly bridged graphs.
<br />The interval function $I_G$ of a connected graph $G$ with vertex set $V$ is
an important concept in metric graph theory and is one of the prime example of
a transit function; a set function defined on the Cartesian product $V\times V$
to the power set of $V$ satisfying the expansive, symmetric and idempotent
axioms.
<br />In this paper, we derive an interesting axiom denoted as $(J0')$, obtained
from a well-known axiom introduced by Marlow Sholander in 1952, denoted as
$(J0)$. It is proved that the axiom $(J0')$ is a characterizing axiom of the
diamond-weakly modular graphs. We propose certain types of independent
first-order betweenness axioms on an arbitrary transit function $R$ and prove
that an arbitrary transit function becomes the interval function of a
diamond-weakly modular graph if and only if $R$ satisfies these betweenness
axioms. Similar characterizations are obtained for the interval function of
bridged graphs and weakly bridged graphs.
</p>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01776" title="Abstract">arXiv:2403.01776</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2403.01776" title="Download PDF">pdf</a>, <a href="/format/2403.01776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid data-driven and physics-informed regularized learning of cyclic  plasticity with Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Hildebrand%2C+S">Stefan Hildebrand</a>, 
<a href="/search/cond-mat?searchtype=author&query=Klinge%2C+S">Sandra Klinge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Adaptation and Self-Organizing Systems (nlin.AO); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">An extendable, efficient and explainable Machine Learning approach is
proposed to represent cyclic plasticity and replace conventional material
models based on the Radial Return Mapping algorithm. High accuracy and
stability by means of a limited amount of training data is achieved by
implementing physics-informed regularizations and the back stress information.
The off-loading of the Neural Network is applied to the maximal extent. The
proposed model architecture is simpler and more efficient compared to existing
solutions from the literature, while representing a complete three-dimensional
material model. The validation of the approach is carried out by means of
surrogate data obtained with the Armstrong-Frederick kinematic hardening model.
The Mean Squared Error is assumed as the loss function which stipulates several
restrictions: deviatoric character of internal variables, compliance with the
flow rule, the differentiation of elastic and plastic steps and the
associativity of the flow rule. The latter, however, has a minor impact on the
accuracy, which implies the generalizability of the model for a broad spectrum
of evolution laws for internal variables. Numerical tests simulating several
load cases are shown in detail and validated for accuracy and stability.
</p>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01805" title="Abstract">arXiv:2403.01805</a> (cross-list from math.OC) [<a href="/pdf/2403.01805" title="Download PDF">pdf</a>, <a href="/format/2403.01805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tsallis Entropy Regularization for Linearly Solvable MDP and Linear  Quadratic Regulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hashizume%2C+Y">Yota Hashizume</a>, 
<a href="/search/math?searchtype=author&query=Oishi%2C+K">Koshi Oishi</a>, 
<a href="/search/math?searchtype=author&query=Kashima%2C+K">Kenji Kashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Shannon entropy regularization is widely adopted in optimal control due to
its ability to promote exploration and enhance robustness, e.g., maximum
entropy reinforcement learning known as Soft Actor-Critic. In this paper,
Tsallis entropy, which is a one-parameter extension of Shannon entropy, is used
for the regularization of linearly solvable MDP and linear quadratic
regulators. We derive the solution for these problems and demonstrate its
usefulness in balancing between exploration and sparsity of the obtained
control law.
</p>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01865" title="Abstract">arXiv:2403.01865</a> (cross-list from stat.ML) [<a href="/pdf/2403.01865" title="Download PDF">pdf</a>, <a href="/format/2403.01865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving generalisation via anchor multivariate analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Durand%2C+H">Homer Durand</a>, 
<a href="/search/stat?searchtype=author&query=Varando%2C+G">Gherardo Varando</a>, 
<a href="/search/stat?searchtype=author&query=Camps-Valls%2C+G">Gustau Camps-Valls</a>, 
<a href="/search/stat?searchtype=author&query=Mankovich%2C+N">Nathan Mankovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">We introduce a causal regularisation extension to anchor regression (AR) for
improved out-of-distribution (OOD) generalisation. We present anchor-compatible
losses, aligning with the anchor framework to ensure robustness against
distribution shifts. Various multivariate analysis (MVA) algorithms, such as
(Orthonormalized) PLS, RRR, and MLR, fall within the anchor framework. We
observe that simple regularisation enhances robustness in OOD settings.
Estimators for selected algorithms are provided, showcasing consistency and
efficacy in synthetic and real-world climate science problems. The empirical
validation highlights the versatility of anchor regularisation, emphasizing its
compatibility with MVA approaches and its role in enhancing replicability while
guarding against distribution shifts. The extended AR framework advances causal
inference methodologies, addressing the need for reliable OOD generalisation.
</p>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01868" title="Abstract">arXiv:2403.01868</a> (cross-list from eess.IV) [<a href="/pdf/2403.01868" title="Download PDF">pdf</a>, <a href="/format/2403.01868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Map-aided annotation for pole base detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Missaoui%2C+B">Benjamin Missaoui</a> (Heudiasyc), 
<a href="/search/eess?searchtype=author&query=Noizet%2C+M">Maxime Noizet</a> (Heudiasyc), 
<a href="/search/eess?searchtype=author&query=Xu%2C+P">Philippe Xu</a> (Heudiasyc)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 35th IEEE Intelligent Vehicles Symposium (IV 2023), Jun 2023,
  Anchorage, AK, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">For autonomous navigation, high definition maps are a widely used source of
information. Pole-like features encoded in HD maps such as traffic signs,
traffic lights or street lights can be used as landmarks for localization. For
this purpose, they first need to be detected by the vehicle using its embedded
sensors. While geometric models can be used to process 3D point clouds
retrieved by lidar sensors, modern image-based approaches rely on deep neural
network and therefore heavily depend on annotated training data. In this paper,
a 2D HD map is used to automatically annotate pole-like features in images. In
the absence of height information, the map features are represented as pole
bases at the ground level. We show how an additional lidar sensor can be used
to filter out occluded features and refine the ground projection. We also
demonstrate how an object detector can be trained to detect a pole base. To
evaluate our methodology, it is first validated with data manually annotated
from semantic segmentation and then compared to our own automatically generated
annotated data recorded in the city of Compi{\`e}gne, France. Erratum: In the
original version [1], an error occurred in the accuracy evaluation of the
different models studied and the evaluation method applied on the detection
results was not clearly defined. In this revision, we offer a rectification to
this segment, presenting updated results, especially in terms of Mean Absolute
Errors (MAE).
</p>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01892" title="Abstract">arXiv:2403.01892</a> (cross-list from math.ST) [<a href="/pdf/2403.01892" title="Download PDF">pdf</a>, <a href="/format/2403.01892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Lower Bounds for Robust Mean Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Degenne%2C+R">R&#xe9;my Degenne</a>, 
<a href="/search/math?searchtype=author&query=Mathieu%2C+T">Timoth&#xe9;e Mathieu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We prove lower bounds on the error of any estimator for the mean of a real
probability distribution under the knowledge that the distribution belongs to a
given set. We apply these lower bounds both to parametric and nonparametric
estimation. In the nonparametric case, we apply our results to the question of
sub-Gaussian estimation for distributions with finite variance to obtain new
lower bounds in the small error probability regime, and present an optimal
estimator in that regime. In the (semi-)parametric case, we use the Fisher
information to provide distribution-dependent lower bounds that are
constant-tight asymptotically, of order $\sqrt{2\log(1/\delta)/(nI)}$ where $I$
is the Fisher information of the distribution. We use known minimizers of the
Fisher information on some nonparametric set of distributions to give lower
bounds in cases such as corrupted distributions, or bounded/semi-bounded
distributions.
</p>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01907" title="Abstract">arXiv:2403.01907</a> (cross-list from stat.ML) [<a href="/pdf/2403.01907" title="Download PDF">pdf</a>, <a href="/ps/2403.01907" title="Download PostScript">ps</a>, <a href="/format/2403.01907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity of the Hebbian-Hopfield network associative memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Information Theory (cs.IT); Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">In \cite{Hop82}, Hopfield introduced a \emph{Hebbian} learning rule based
neural network model and suggested how it can efficiently operate as an
associative memory. Studying random binary patterns, he also uncovered that, if
a small fraction of errors is tolerated in the stored patterns retrieval, the
capacity of the network (maximal number of memorized patterns, $m$) scales
linearly with each pattern's size, $n$. Moreover, he famously predicted
$\alpha_c=\lim_{n\rightarrow\infty}\frac{m}{n}\approx 0.14$. We study this very
same scenario with two famous pattern's basins of attraction:
\textbf{\emph{(i)}} The AGS one from \cite{AmiGutSom85}; and
\textbf{\emph{(ii)}} The NLT one from
\cite{Newman88,Louk94,Louk94a,Louk97,Tal98}. Relying on the \emph{fully lifted
random duality theory} (fl RDT) from \cite{Stojnicflrdt23}, we obtain the
following explicit capacity characterizations on the first level of lifting:
<br />\begin{equation}
<br />\alpha_c^{(AGS,1)} = \left ( \max_{\delta\in \left ( 0,\frac{1}{2}\right )
}\frac{1-2\delta}{\sqrt{2} \mbox{erfinv} \left ( 1-2\delta\right )} -
\frac{2}{\sqrt{2\pi}} e^{-\left ( \mbox{erfinv}\left ( 1-2\delta \right )\right
)^2}\right )^2 \approx \mathbf{0.137906} \end{equation}
<br />\begin{equation}
<br />\alpha_c^{(NLT,1)} = \frac{\mbox{erf}(x)^2}{2x^2}-1+\mbox{erf}(x)^2 \approx
\mathbf{0.129490}, \quad 1-\mbox{erf}(x)^2-
\frac{2\mbox{erf}(x)e^{-x^2}}{\sqrt{\pi}x}+\frac{2e^{-2x^2}}{\pi}=0.
\end{equation}
<br />A substantial numerical work gives on the second level of lifting
$\alpha_c^{(AGS,2)} \approx \mathbf{0.138186}$ and $\alpha_c^{(NLT,2)} \approx
\mathbf{0.12979}$, effectively uncovering a remarkably fast lifting
convergence. Moreover, the obtained AGS characterizations exactly match the
replica symmetry based ones of \cite{AmiGutSom85} and the corresponding
symmetry breaking ones of \cite{SteKuh94}.
</p>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01927" title="Abstract">arXiv:2403.01927</a> (cross-list from q-bio.GN) [<a href="/pdf/2403.01927" title="Download PDF">pdf</a>, <a href="/format/2403.01927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Gene Selection in Oncology: A Fusion of Deep Learning and  Sparsity for Precision Gene Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Krishna%2C+A">Akhila Krishna</a>, 
<a href="/search/q-bio?searchtype=author&query=Gupta%2C+R+K">Ravi Kant Gupta</a>, 
<a href="/search/q-bio?searchtype=author&query=Jeevan%2C+P">Pranav Jeevan</a>, 
<a href="/search/q-bio?searchtype=author&query=Sethi%2C+A">Amit Sethi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Gene selection plays a pivotal role in oncology research for improving
outcome prediction accuracy and facilitating cost-effective genomic profiling
for cancer patients. This paper introduces two gene selection strategies for
deep learning-based survival prediction models. The first strategy uses a
sparsity-inducing method while the second one uses importance based gene
selection for identifying relevant genes. Our overall approach leverages the
power of deep learning to model complex biological data structures, while
sparsity-inducing methods ensure the selection process focuses on the most
informative genes, minimizing noise and redundancy. Through comprehensive
experimentation on diverse genomic and survival datasets, we demonstrate that
our strategy not only identifies gene signatures with high predictive power for
survival outcomes but can also streamlines the process for low-cost genomic
profiling. The implications of this research are profound as it offers a
scalable and effective tool for advancing personalized medicine and targeted
cancer therapies. By pushing the boundaries of gene selection methodologies,
our work contributes significantly to the ongoing efforts in cancer genomics,
promising improved diagnostic and prognostic capabilities in clinical settings.
</p>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01939" title="Abstract">arXiv:2403.01939</a> (cross-list from math.CT) [<a href="/pdf/2403.01939" title="Download PDF">pdf</a>, <a href="/format/2403.01939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Type Theory with a Tiny Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Riley%2C+M">Mitchell Riley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Programming Languages (cs.PL); Logic (math.LO)

</div>
<p class="mathjax">We present an extension of Martin-L\"of Type Theory that contains a tiny
object; a type for which there is a right adjoint to the formation of function
types as well as the expected left adjoint. We demonstrate the practicality of
this type theory by proving various properties related to tininess internally
and suggest a few potential applications.
</p>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01947" title="Abstract">arXiv:2403.01947</a> (cross-list from math.CO) [<a href="/pdf/2403.01947" title="Download PDF">pdf</a>, <a href="/format/2403.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterization of Chordal Circular-arc Graphs: I. Split Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/math?searchtype=author&query=Derbisz%2C+J">Jan Derbisz</a>, 
<a href="/search/math?searchtype=author&query=Krawczyk%2C+T">Tomasz Krawczyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The most elusive problem around the class of circular-arc graphs is
identifying all minimal graphs that are not in this class. The main obstacle is
the lack of a systematic way of enumerating these minimal graphs. McConnell
[FOCS 2001] presented a transformation from circular-arc graphs to interval
graphs with certain patterns of representations. We fully characterize these
interval patterns for circular-arc graphs that are split graphs, thereby
building a connection between minimal split graphs that are not circular-arc
graphs and minimal non-interval graphs. This connection enables us to identify
all minimal split graphs that are not circular-arc graphs. As a byproduct, we
develop a linear-time certifying recognition algorithm for circular-arc graphs
when the input is a split graph.
</p>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01948" title="Abstract">arXiv:2403.01948</a> (cross-list from stat.ME) [<a href="/pdf/2403.01948" title="Download PDF">pdf</a>, <a href="/format/2403.01948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Fractional Moment Estimation from Polynomial Chaos Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nov%C3%A1k%2C+L">Luk&#xe1;&#x161; Nov&#xe1;k</a>, 
<a href="/search/stat?searchtype=author&query=Valdebenito%2C+M">Marcos Valdebenito</a>, 
<a href="/search/stat?searchtype=author&query=Faes%2C+M">Matthias Faes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fractional statistical moments are utilized for various tasks of uncertainty
quantification, including the estimation of probability distributions. However,
an estimation of fractional statistical moments of costly mathematical models
by statistical sampling is challenging since it is typically not possible to
create a large experimental design due to limitations in computing capacity.
This paper presents a novel approach for the analytical estimation of
fractional moments, directly from polynomial chaos expansions. Specifically,
the first four statistical moments obtained from the deterministic PCE
coefficients are used for an estimation of arbitrary fractional moments via
H\"{o}lder's inequality. The proposed approach is utilized for an estimation of
statistical moments and probability distributions in three numerical examples
of increasing complexity. Obtained results show that the proposed approach
achieves a superior performance in estimating the distribution of the response,
in comparison to a standard Latin hypercube sampling in the presented examples.
</p>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01964" title="Abstract">arXiv:2403.01964</a> (cross-list from econ.GN) [<a href="/pdf/2403.01964" title="Download PDF">pdf</a>, <a href="/format/2403.01964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Heterogeneous Productivity Effects of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Kreitmeir%2C+D">David Kreitmeir</a>, 
<a href="/search/econ?searchtype=author&query=Raschky%2C+P+A">Paul A. Raschky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We analyse the individual productivity effects of Italy's ban on ChatGPT, a
generative pretrained transformer chatbot. We compile data on the daily coding
output quantity and quality of over 36,000 GitHub users in Italy and other
European countries and combine these data with the sudden announcement of the
ban in a difference-in-differences framework. Among the affected users in
Italy, we find a short-term increase in output quantity and quality for less
experienced users and a decrease in productivity on more routine tasks for
experienced users.
</p>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02011" title="Abstract">arXiv:2403.02011</a> (cross-list from stat.ML) [<a href="/pdf/2403.02011" title="Download PDF">pdf</a>, <a href="/format/2403.02011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bipartite Graph Variational Auto-Encoder with Fair Latent Representation  to Account for Sampling Bias in Ecological Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Anakok%2C+E">Emre Anakok</a>, 
<a href="/search/stat?searchtype=author&query=Barbillon%2C+P">Pierre Barbillon</a>, 
<a href="/search/stat?searchtype=author&query=Fontaine%2C+C">Colin Fontaine</a>, 
<a href="/search/stat?searchtype=author&query=Thebault%2C+E">Elisa Thebault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We propose a method to represent bipartite networks using graph embeddings
tailored to tackle the challenges of studying ecological networks, such as the
ones linking plants and pollinators, where many covariates need to be accounted
for, in particular to control for sampling bias. We adapt the variational graph
auto-encoder approach to the bipartite case, which enables us to generate
embeddings in a latent space where the two sets of nodes are positioned based
on their probability of connection. We translate the fairness framework
commonly considered in sociology in order to address sampling bias in ecology.
By incorporating the Hilbert-Schmidt independence criterion (HSIC) as an
additional penalty term in the loss we optimize, we ensure that the structure
of the latent space is independent of continuous variables, which are related
to the sampling process. Finally, we show how our approach can change our
understanding of ecological networks when applied to the Spipoll data set, a
citizen science monitoring program of plant-pollinator interactions to which
many observers contribute, making it prone to sampling bias.
</p>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02043" title="Abstract">arXiv:2403.02043</a> (cross-list from eess.IV) [<a href="/pdf/2403.02043" title="Download PDF">pdf</a>, <a href="/format/2403.02043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Occlusion-Aware Light Field Depth Estimation using 4D  Geometrical Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Louren%C3%A7o%2C+R">Rui Louren&#xe7;o</a>, 
<a href="/search/eess?searchtype=author&query=Thomaz%2C+L">Lucas Thomaz</a>, 
<a href="/search/eess?searchtype=author&query=Silva%2C+E+A+B">Eduardo A. B. Silva</a>, 
<a href="/search/eess?searchtype=author&query=Faria%2C+S+M+M">Sergio M. M. Faria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Light field cameras and multi-camera arrays have emerged as promising
solutions for accurately estimating depth by passively capturing light
information. This is possible because the 3D information of a scene is embedded
in the 4D light field geometry. Commonly, depth estimation methods extract this
information relying on gradient information, heuristic-based optimisation
models, or learning-based approaches. This paper focuses mainly on explicitly
understanding and exploiting 4D geometrical cues for light field depth
estimation. Thus, a novel method is proposed, based on a non-learning-based
optimisation approach for depth estimation that explicitly considers surface
normal accuracy and occlusion regions by utilising a fully explainable 4D
geometric model of the light field. The 4D model performs depth/disparity
estimation by determining the orientations and analysing the intersections of
key 2D planes in 4D space, which are the images of 3D-space points in the 4D
light field. Experimental results show that the proposed method outperforms
both learning-based and non-learning-based state-of-the-art methods in terms of
surface normal angle accuracy, achieving a Median Angle Error on planar
surfaces, on average, 26.3\% lower than the state-of-the-art, and still being
competitive with state-of-the-art methods in terms of Mean Squared Error
$\vc{\times}$ 100 and Badpix 0.07.
</p>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02051" title="Abstract">arXiv:2403.02051</a> (cross-list from stat.ML) [<a href="/pdf/2403.02051" title="Download PDF">pdf</a>, <a href="/format/2403.02051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Privacy of Noisy (S)GD under Heavy-Tailed Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=%C5%9Eim%C5%9Fekli%2C+U">Umut &#x15e;im&#x15f;ekli</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%BCrb%C3%BCzbalaban%2C+M">Mert G&#xfc;rb&#xfc;zbalaban</a>, 
<a href="/search/stat?searchtype=author&query=Y%C4%B1ld%C4%B1r%C4%B1m%2C+S">Sinan Y&#x131;ld&#x131;r&#x131;m</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+L">Lingjiong Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">Injecting heavy-tailed noise to the iterates of stochastic gradient descent
(SGD) has received increasing attention over the past few years. While various
theoretical properties of the resulting algorithm have been analyzed mainly
from learning theory and optimization perspectives, their privacy preservation
properties have not yet been established. Aiming to bridge this gap, we provide
differential privacy (DP) guarantees for noisy SGD, when the injected noise
follows an $\alpha$-stable distribution, which includes a spectrum of
heavy-tailed distributions (with infinite variance) as well as the Gaussian
distribution. Considering the $(\epsilon, \delta)$-DP framework, we show that
SGD with heavy-tailed perturbations achieves $(0, \tilde{\mathcal{O}}(1/n))$-DP
for a broad class of loss functions which can be non-convex, where $n$ is the
number of data points. As a remarkable byproduct, contrary to prior work that
necessitates bounded sensitivity for the gradients or clipping the iterates,
our theory reveals that under mild assumptions, such a projection step is not
actually necessary. We illustrate that the heavy-tailed noising mechanism
achieves similar DP guarantees compared to the Gaussian case, which suggests
that it can be a viable alternative to its light-tailed counterparts.
</p>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02080" title="Abstract">arXiv:2403.02080</a> (cross-list from quant-ph) [<a href="/pdf/2403.02080" title="Download PDF">pdf</a>, <a href="/format/2403.02080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Quantum Neural Network Advantage for Radar-Based Drone Detection  and Classification in Low Signal-to-Noise Ratio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Malarvanan%2C+A+S">Aiswariya Sweety Malarvanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">In this paper, we investigate the performance of a Hybrid Quantum Neural
Network (HQNN) and a comparable classical Convolution Neural Network (CNN) for
detection and classification problem using a radar. Specifically, we take a
fairly complex radar time-series model derived from electromagnetic theory,
namely the Martin-Mulgrew model, that is used to simulate radar returns of
objects with rotating blades, such as drones. We find that when that
signal-to-noise ratio (SNR) is high, CNN outperforms the HQNN for detection and
classification. However, in the low SNR regime (which is of greatest interest
in practice) the performance of HQNN is found to be superior to that of the CNN
of a similar architecture.
</p>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02095" title="Abstract">arXiv:2403.02095</a> (cross-list from math.OC) [<a href="/pdf/2403.02095" title="Download PDF">pdf</a>, <a href="/format/2403.02095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homotopy Methods for Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klingler%2C+A">Andreas Klingler</a>, 
<a href="/search/math?searchtype=author&query=Netzer%2C+T">Tim Netzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Algebraic Geometry (math.AG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Convex optimization encompasses a wide range of optimization problems,
containing many efficiently solvable subclasses. Interior point methods are
currently the state-of-the-art approach for solving such problems, particularly
effective for classes like semidefinite programming, quadratic programming, and
geometric programming. However, their success hinges on the construction of
self-concordant barrier functions for the feasible sets. In this work, we
introduce an alternative method for tackling convex optimization problems,
employing a homotopy. With this technique, the feasible set of a trivial
optimization problem is continuously transformed into the target one, while
tracking the solutions. We conduct an analysis of this approach, focusing on
its application to semidefinite programs, hyperbolic programs, and convex
optimization problems with a single convexity constraint. Moreover, we
demonstrate that our approach numerically outperforms state-of-the-art methods
in several interesting cases.
</p>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02150" title="Abstract">arXiv:2403.02150</a> (cross-list from stat.ML) [<a href="/pdf/2403.02150" title="Download PDF">pdf</a>, <a href="/format/2403.02150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recency-Weighted Temporally-Segmented Ensemble for Time-Series Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Johnsen%2C+P+V">P&#xe5;l V. Johnsen</a>, 
<a href="/search/stat?searchtype=author&query=B%C3%B8hn%2C+E">Eivind B&#xf8;hn</a>, 
<a href="/search/stat?searchtype=author&query=Eidnes%2C+S">S&#xf8;lve Eidnes</a>, 
<a href="/search/stat?searchtype=author&query=Remonato%2C+F">Filippo Remonato</a>, 
<a href="/search/stat?searchtype=author&query=Riemer-S%C3%B8rensen%2C+S">Signe Riemer-S&#xf8;rensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main article with 23 pages including 12 figures and 4 tables. Supplementary File with 11 pages including 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Time-series modeling in process industries faces the challenge of dealing
with complex, multi-faceted, and evolving data characteristics. Conventional
single model approaches often struggle to capture the interplay of diverse
dynamics, resulting in suboptimal forecasts. Addressing this, we introduce the
Recency-Weighted Temporally-Segmented (ReWTS, pronounced `roots') ensemble
model, a novel chunk-based approach for multi-step forecasting. The key
characteristics of the ReWTS model are twofold: 1) It facilitates
specialization of models into different dynamics by segmenting the training
data into `chunks' of data and training one model per chunk. 2) During
inference, an optimization procedure assesses each model on the recent past and
selects the active models, such that the appropriate mixture of previously
learned dynamics can be recalled to forecast the future. This method not only
captures the nuances of each period, but also adapts more effectively to
changes over time compared to conventional `global' models trained on all data
in one go. We present a comparative analysis, utilizing two years of data from
a wastewater treatment plant and a drinking water treatment plant in Norway,
demonstrating the ReWTS ensemble's superiority. It consistently outperforms the
global model in terms of mean squared forecasting error across various model
architectures by 10-70\% on both datasets, notably exhibiting greater
resilience to outliers. This approach shows promise in developing automatic,
adaptable forecasting models for decision-making and control systems in process
industries and other complex systems.
</p>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02163" title="Abstract">arXiv:2403.02163</a> (cross-list from eess.IV) [<a href="/pdf/2403.02163" title="Download PDF">pdf</a>, <a href="/format/2403.02163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REAL-Colon: A dataset for developing real-world AI applications in  colonoscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Biffi%2C+C">Carlo Biffi</a>, 
<a href="/search/eess?searchtype=author&query=Antonelli%2C+G">Giulio Antonelli</a>, 
<a href="/search/eess?searchtype=author&query=Bernhofer%2C+S">Sebastian Bernhofer</a>, 
<a href="/search/eess?searchtype=author&query=Hassan%2C+C">Cesare Hassan</a>, 
<a href="/search/eess?searchtype=author&query=Hirata%2C+D">Daizen Hirata</a>, 
<a href="/search/eess?searchtype=author&query=Iwatate%2C+M">Mineo Iwatate</a>, 
<a href="/search/eess?searchtype=author&query=Maieron%2C+A">Andreas Maieron</a>, 
<a href="/search/eess?searchtype=author&query=Salvagnini%2C+P">Pietro Salvagnini</a>, 
<a href="/search/eess?searchtype=author&query=Cherubini%2C+A">Andrea Cherubini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 tables, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Detection and diagnosis of colon polyps are key to preventing colorectal
cancer. Recent evidence suggests that AI-based computer-aided detection (CADe)
and computer-aided diagnosis (CADx) systems can enhance endoscopists'
performance and boost colonoscopy effectiveness. However, most available public
datasets primarily consist of still images or video clips, often at a
down-sampled resolution, and do not accurately represent real-world colonoscopy
procedures. We introduce the REAL-Colon (Real-world multi-center Endoscopy
Annotated video Library) dataset: a compilation of 2.7M native video frames
from sixty full-resolution, real-world colonoscopy recordings across multiple
centers. The dataset contains 350k bounding-box annotations, each created under
the supervision of expert gastroenterologists. Comprehensive patient clinical
data, colonoscopy acquisition information, and polyp histopathological
information are also included in each video. With its unprecedented size,
quality, and heterogeneity, the REAL-Colon dataset is a unique resource for
researchers and developers aiming to advance AI research in colonoscopy. Its
openness and transparency facilitate rigorous and reproducible research,
fostering the development and benchmarking of more accurate and reliable
colonoscopy-related algorithms and models.
</p>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02167" title="Abstract">arXiv:2403.02167</a> (cross-list from eess.AS) [<a href="/pdf/2403.02167" title="Download PDF">pdf</a>, <a href="/format/2403.02167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech emotion recognition from voice messages recorded in the wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=G%C3%B3mez-Zaragoz%C3%A1%2C+L">Luc&#xed;a G&#xf3;mez-Zaragoz&#xe1;</a>, 
<a href="/search/eess?searchtype=author&query=Valls%2C+%C3%93">&#xd3;scar Valls</a>, 
<a href="/search/eess?searchtype=author&query=del+Amor%2C+R">Roc&#xed;o del Amor</a>, 
<a href="/search/eess?searchtype=author&query=Castro-Bleda%2C+M+J">Mar&#xed;a Jos&#xe9; Castro-Bleda</a>, 
<a href="/search/eess?searchtype=author&query=Naranjo%2C+V">Valery Naranjo</a>, 
<a href="/search/eess?searchtype=author&query=Raya%2C+M+A">Mariano Alca&#xf1;iz Raya</a>, 
<a href="/search/eess?searchtype=author&query=Mar%C3%ADn-Morales%2C+J">Javier Mar&#xed;n-Morales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Emotion datasets used for Speech Emotion Recognition (SER) often contain
acted or elicited speech, limiting their applicability in real-world scenarios.
In this work, we used the Emotional Voice Messages (EMOVOME) database,
including spontaneous voice messages from conversations of 100 Spanish speakers
on a messaging app, labeled in continuous and discrete emotions by expert and
non-expert annotators. We created speaker-independent SER models using the
eGeMAPS features, transformer-based models and their combination. We compared
the results with reference databases and analyzed the influence of annotators
and gender fairness. The pre-trained Unispeech-L model and its combination with
eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted
Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10%
improvement over baseline models. For the emotion categories, 42.58% UA was
obtained. EMOVOME performed lower than the acted RAVDESS database. The elicited
IEMOCAP database also outperformed EMOVOME in the prediction of emotion
categories, while similar results were obtained in valence and arousal.
Additionally, EMOVOME outcomes varied with annotator labels, showing superior
results and better fairness when combining expert and non-expert annotations.
This study significantly contributes to the evaluation of SER models in
real-life situations, advancing in the development of applications for
analyzing spontaneous voice messages.
</p>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02171" title="Abstract">arXiv:2403.02171</a> (cross-list from astro-ph.CO) [<a href="/pdf/2403.02171" title="Download PDF">pdf</a>, <a href="/format/2403.02171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting large scale cosmological structure evolution with GAN-based  autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Ullmo%2C+M">Marion Ullmo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Aghnim%2C+N">Nabila Aghnim</a>, 
<a href="/search/astro-ph?searchtype=author&query=Decelle%2C+A">Aur&#xe9;lien Decelle</a>, 
<a href="/search/astro-ph?searchtype=author&query=Aragon-Calvo%2C+M">Miguel Aragon-Calvo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cosmological simulations play a key role in the prediction and understanding
of large scale structure formation from initial conditions. We make use of
GAN-based Autoencoders (AEs) in an attempt to predict structure evolution
within simulations. The AEs are trained on images and cubes issued from
respectively 2D and 3D N-body simulations describing the evolution of the dark
matter (DM) field. We find that while the AEs can predict structure evolution
for 2D simulations of DM fields well, using only the density fields as input,
they perform significantly more poorly in similar conditions for 3D
simulations. However, additionally providing velocity fields as inputs greatly
improves results, with similar predictions regardless of time-difference
between input and target.
</p>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02192" title="Abstract">arXiv:2403.02192</a> (cross-list from eess.IV) [<a href="/pdf/2403.02192" title="Download PDF">pdf</a>, <a href="/format/2403.02192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain adaptation, Explainability &amp; Fairness in AI for Medical Image  Analysis: Diagnosis of COVID-19 based on 3-D Chest CT-scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kollias%2C+D">Dimitrios Kollias</a>, 
<a href="/search/eess?searchtype=author&query=Arsenos%2C+A">Anastasios Arsenos</a>, 
<a href="/search/eess?searchtype=author&query=Kollias%2C+S">Stefanos Kollias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The paper presents the DEF-AI-MIA COV19D Competition, which is organized in
the framework of the 'Domain adaptation, Explainability, Fairness in AI for
Medical Image Analysis (DEF-AI-MIA)' Workshop of the 2024 Computer Vision and
Pattern Recognition (CVPR) Conference. The Competition is the 4th in the
series, following the first three Competitions held in the framework of ICCV
2021, ECCV 2022 and ICASSP 2023 International Conferences respectively. It
includes two Challenges on: i) Covid-19 Detection and ii) Covid-19 Domain
Adaptation. The Competition use data from COV19-CT-DB database, which is
described in the paper and includes a large number of chest CT scan series.
Each chest CT scan series consists of a sequence of 2-D CT slices, the number
of which is between 50 and 700. Training, validation and test datasets have
been extracted from COV19-CT-DB and provided to the participants in both
Challenges. The paper presents the baseline models used in the Challenges and
the performance which was obtained respectively.
</p>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02220" title="Abstract">arXiv:2403.02220</a> (cross-list from math.PR) [<a href="/pdf/2403.02220" title="Download PDF">pdf</a>, <a href="/format/2403.02220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Multivariate Extremes in Multilayer Inhomogeneous Random  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cirkovic%2C+D">Daniel Cirkovic</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+T">Tiandong Wang</a>, 
<a href="/search/math?searchtype=author&query=Cline%2C+D+B+H">Daren B.H. Cline</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Social and Information Networks (cs.SI); Statistics Theory (math.ST); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">In this paper, we propose a multilayer inhomogeneous random graph model
(MIRG), whose layers may consist of both single-edge and multi-edge graphs. In
the single layer case, it has been shown that the regular variation of the
weight distribution underlying the inhomogeneous random graph implies the
regular variation of the typical degree distribution. We extend this
correspondence to the multilayer case by showing that the multivariate regular
variation of the weight distribution implies the multivariate regular variation
of the asymptotic degree distribution. Furthermore, in certain circumstances,
the extremal dependence structure present in the weight distribution will be
adopted by the asymptotic degree distribution. By considering the asymptotic
degree distribution, a wider class of Chung-Lu and Norros-Reittu graphs may be
incorporated into the MIRG layers. Additionally, we prove consistency of the
Hill estimator when applied to degrees of the MIRG that have a tail index
greater than 1. Simulation results indicate that, in practice, hidden regular
variation may be consistently detected from an observed MIRG.
</p>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02236" title="Abstract">arXiv:2403.02236</a> (cross-list from eess.IV) [<a href="/pdf/2403.02236" title="Download PDF">pdf</a>, <a href="/format/2403.02236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Models for Detecting and Monitoring Elevated Intracranial  Pressure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hannan%2C+D">Darryl Hannan</a>, 
<a href="/search/eess?searchtype=author&query=Nesbit%2C+S+C">Steven C. Nesbit</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+X">Ximing Wen</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+G">Glen Smith</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qiao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Goffi%2C+A">Alberto Goffi</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+V">Vincent Chan</a>, 
<a href="/search/eess?searchtype=author&query=Morris%2C+M+J">Michael J. Morris</a>, 
<a href="/search/eess?searchtype=author&query=Hunninghake%2C+J+C">John C. Hunninghake</a>, 
<a href="/search/eess?searchtype=author&query=Villalobos%2C+N+E">Nicholas E. Villalobos</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+E">Edward Kim</a>, 
<a href="/search/eess?searchtype=author&query=Weber%2C+R+O">Rosina O. Weber</a>, 
<a href="/search/eess?searchtype=author&query=MacLellan%2C+C+J">Christopher J. MacLellan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Detecting elevated intracranial pressure (ICP) is crucial in diagnosing and
managing various neurological conditions. These fluctuations in pressure are
transmitted to the optic nerve sheath (ONS), resulting in changes to its
diameter, which can then be detected using ultrasound imaging devices. However,
interpreting sonographic images of the ONS can be challenging. In this work, we
propose two systems that actively monitor the ONS diameter throughout an
ultrasound video and make a final prediction as to whether ICP is elevated. To
construct our systems, we leverage subject matter expert (SME) guidance,
structuring our processing pipeline according to their collection procedure,
while also prioritizing interpretability and computational efficiency. We
conduct a number of experiments, demonstrating that our proposed systems are
able to outperform various baselines. One of our SMEs then manually validates
our top system's performance, lending further credibility to our approach while
demonstrating its potential utility in a clinical setting.
</p>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02237" title="Abstract">arXiv:2403.02237</a> (cross-list from hep-ph) [<a href="/pdf/2403.02237" title="Download PDF">pdf</a>, <a href="/format/2403.02237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytic continuations and numerical evaluation of the Appell $F_1$,  $F_3$, Lauricella $F_D^{(3)}$ and Lauricella-Saran $F_S^{(3)}$ and their  Application to Feynman Integrals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Bera%2C+S">Souvik Bera</a>, 
<a href="/search/hep-ph?searchtype=author&query=Pathak%2C+T">Tanay Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 1 figure, Repository see <a href="https://github.com/souvik5151/Appell_Lauricella_Saran_functions">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Mathematical Software (cs.MS); High Energy Physics - Theory (hep-th); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We present our investigation of the study of two variable hypergeometric
series, namely Appell $F_{1}$ and $F_{3}$ series, and obtain a comprehensive
list of its analytic continuations enough to cover the whole real $(x,y)$
plane, except on their singular loci. We also derive analytic continuations of
their 3-variable generalization, the Lauricella $F_{D}^{(3)}$ series and the
Lauricella-Saran $F_{S}^{(3)}$ series, leveraging the analytic continuations of
$F_{1}$ and $F_{3}$, which ensures that the whole real $(x,y,z)$ space is
covered, except on the singular loci of these functions. While these studies
are motivated by the frequent occurrence of these multivariable hypergeometric
functions in Feynman integral evaluation, they can also be used whenever they
appear in other branches of mathematical physics. To facilitate their practical
use, we provide four packages: $\texttt{AppellF1.wl}$, $\texttt{AppellF3.wl}$,
$\texttt{LauricellaFD.wl}$, and $\texttt{LauricellaSaranFS.wl}$ in
$\textit{MATHEMATICA}$. These packages are applicable for generic as well as
non-generic values of parameters, keeping in mind their utilities in the
evaluation of the Feynman integrals. We explicitly present various physical
applications of these packages in the context of Feynman integral evaluation
and compare the results using other means as well. Various
$\textit{MATHEMATICA}$ notebooks demonstrating different numerical results are
also provided along with this paper.
</p>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02251" title="Abstract">arXiv:2403.02251</a> (cross-list from stat.ML) [<a href="/pdf/2403.02251" title="Download PDF">pdf</a>, <a href="/format/2403.02251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A prediction rigidity formalism for low-cost uncertainties in trained  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bigi%2C+F">Filippo Bigi</a>, 
<a href="/search/stat?searchtype=author&query=Chong%2C+S">Sanggyu Chong</a>, 
<a href="/search/stat?searchtype=author&query=Ceriotti%2C+M">Michele Ceriotti</a>, 
<a href="/search/stat?searchtype=author&query=Grasselli%2C+F">Federico Grasselli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Regression methods are fundamental for scientific and technological
applications. However, fitted models can be highly unreliable outside of their
training domain, and hence the quantification of their uncertainty is crucial
in many of their applications. Based on the solution of a constrained
optimization problem, we propose "prediction rigidities" as a method to obtain
uncertainties of arbitrary pre-trained regressors. We establish a strong
connection between our framework and Bayesian inference, and we develop a
last-layer approximation that allows the new method to be applied to neural
networks. This extension affords cheap uncertainties without any modification
to the neural network itself or its training procedure. We show the
effectiveness of our method on a wide range of regression tasks, ranging from
simple toy models to applications in chemistry and meteorology.
</p>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02298" title="Abstract">arXiv:2403.02298</a> (cross-list from math.CO) [<a href="/pdf/2403.02298" title="Download PDF">pdf</a>, <a href="/format/2403.02298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum acyclic number and maximum dichromatic number of oriented  triangle-free graphs of a given order
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aboulker%2C+P">Pierre Aboulker</a>, 
<a href="/search/math?searchtype=author&query=Havet%2C+F">Fr&#xe9;d&#xe9;ric Havet</a>, 
<a href="/search/math?searchtype=author&query=Pirot%2C+F">Fran&#xe7;ois Pirot</a>, 
<a href="/search/math?searchtype=author&query=Schabanel%2C+J">Juliette Schabanel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Let $D$ be a digraph. Its acyclic number $\vec{\alpha}(D)$ is the maximum
order of an acyclic induced subdigraph and its dichromatic number
$\vec{\chi}(D)$ is the least integer $k$ such that $V(D)$ can be partitioned
into $k$ subsets inducing acyclic subdigraphs. We study ${\vec a}(n)$ and $\vec
t(n)$ which are the minimum of $\vec\alpha(D)$ and the maximum of
$\vec{\chi}(D)$, respectively, over all oriented triangle-free graphs of order
$n$. For every $\epsilon&gt;0$ and $n$ large enough, we show $(1/\sqrt{2} -
\epsilon) \sqrt{n\log n} \leq \vec{a}(n) \leq \frac{107}{8} \sqrt n \log n$ and
$\frac{8}{107} \sqrt n/\log n \leq \vec{t}(n) \leq (\sqrt 2 + \epsilon)
\sqrt{n/\log n}$. We also construct an oriented triangle-free graph on 25
vertices with dichromatic number~3, and show that every oriented triangle-free
graph of order at most 17 has dichromatic number at most 2.
</p>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02307" title="Abstract">arXiv:2403.02307</a> (cross-list from eess.IV) [<a href="/pdf/2403.02307" title="Download PDF">pdf</a>, <a href="/format/2403.02307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Intra-group Variations Via a Population-Level Context for  Pathology Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Githinji%2C+P+B">P. Bilha Githinji</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+X">Xi Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhenglin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Gul%2C+I">Ijaz Gul</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+D">Dingqi Shang</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+W">Wen Liang</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+J">Jianming Deng</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+D">Dan Zeng</a>, 
<a href="/search/eess?searchtype=author&query=yu%2C+D">Dongmei yu</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+C">Chenggang Yan</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+P">Peiwu Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Realizing sufficient separability between the distributions of healthy and
pathological samples is a critical obstacle for pathology detection
convolutional models. Moreover, these models exhibit a bias for contrast-based
images, with diminished performance on texture-based medical images. This study
introduces the notion of a population-level context for pathology detection and
employs a graph theoretic approach to model and incorporate it into the latent
code of an autoencoder via a refinement module we term PopuSense. PopuSense
seeks to capture additional intra-group variations inherent in biomedical data
that a local or global context of the convolutional model might miss or smooth
out. Experiments on contrast-based and texture-based images, with minimal
adaptation, encounter the existing preference for intensity-based input.
Nevertheless, PopuSense demonstrates improved separability in contrast-based
images, presenting an additional avenue for refining representations learned by
a model.
</p>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02311" title="Abstract">arXiv:2403.02311</a> (cross-list from eess.IV) [<a href="/pdf/2403.02311" title="Download PDF">pdf</a>, <a href="/format/2403.02311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Uncertainty Estimation by Hamiltonian Monte Carlo: Applications  to Cardiac MRI Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yidong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Tourais%2C+J">Joao Tourais</a>, 
<a href="/search/eess?searchtype=author&query=Pierce%2C+I">Iain Pierce</a>, 
<a href="/search/eess?searchtype=author&query=Nitsche%2C+C">Christian Nitsche</a>, 
<a href="/search/eess?searchtype=author&query=Treibel%2C+T+A">Thomas A. Treibel</a>, 
<a href="/search/eess?searchtype=author&query=Weing%C3%A4rtner%2C+S">Sebastian Weing&#xe4;rtner</a>, 
<a href="/search/eess?searchtype=author&query=Schweidtmann%2C+A+M">Artur M. Schweidtmann</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+Q">Qian Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning (DL)-based methods have achieved state-of-the-art performance
for a wide range of medical image segmentation tasks. Nevertheless, recent
studies show that deep neural networks (DNNs) can be miscalibrated and
overconfident, leading to "silent failures" that are risky} for clinical
applications. Bayesian statistics provide an intuitive approach to DL failure
detection, based on posterior probability estimation. However, Bayesian DL, and
in particular the posterior estimation, is intractable for large medical image
segmentation DNNs. To tackle this challenge, we propose a Bayesian learning
framework by Hamiltonian Monte Carlo (HMC), tempered by cold posterior (CP) to
accommodate medical data augmentation, named HMC-CP. For HMC computation, we
further propose a cyclical annealing strategy, which captures both local and
global geometries of the posterior distribution, enabling highly efficient
Bayesian DNN training with the same computational budget requirements as
training a single DNN. The resulting Bayesian DNN outputs an ensemble
segmentation along with the segmentation uncertainty. We evaluate the proposed
HMC-CP extensively on cardiac magnetic resonance image (MRI) segmentation,
using in-domain steady-state free precession (SSFP) cine images as well as
out-of-domain datasets of quantitative $T_1$ and $T_2$ mapping.
</p>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02324" title="Abstract">arXiv:2403.02324</a> (cross-list from eess.SP) [<a href="/pdf/2403.02324" title="Download PDF">pdf</a>, <a href="/format/2403.02324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Smart Grid Integrity: A Differential Privacy Framework for  Secure Detection of False Data Injection Attacks in the Smart Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ravi%2C+N">Nikhil Ravi</a>, 
<a href="/search/eess?searchtype=author&query=Scaglione%2C+A">Anna Scaglione</a>, 
<a href="/search/eess?searchtype=author&query=Peisert%2C+S">Sean Peisert</a>, 
<a href="/search/eess?searchtype=author&query=Pradhan%2C+P">Parth Pradhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this paper, we present a framework based on differential privacy (DP) for
querying electric power measurements to detect system anomalies or bad data
caused by false data injections (FDIs). Our DP approach conceals consumption
and system matrix data, while simultaneously enabling an untrusted third party
to test hypotheses of anomalies, such as an FDI attack, by releasing a
randomized sufficient statistic for hypothesis-testing. We consider a
measurement model corrupted by Gaussian noise and a sparse noise vector
representing the attack, and we observe that the optimal test statistic is a
chi-square random variable. To detect possible attacks, we propose a novel DP
chi-square noise mechanism that ensures the test does not reveal private
information about power injections or the system matrix. The proposed framework
provides a robust solution for detecting FDIs while preserving the privacy of
sensitive power system data.
</p>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02339" title="Abstract">arXiv:2403.02339</a> (cross-list from math.AP) [<a href="/pdf/2403.02339" title="Download PDF">pdf</a>, <a href="/format/2403.02339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Well-Posedness and Asymptotic Behavior in an  Advection-Diffusion-Reaction (ADR) Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Elghandouri%2C+M">Mohammed Elghandouri</a>, 
<a href="/search/math?searchtype=author&query=Ezzinbi%2C+K">Khalil Ezzinbi</a>, 
<a href="/search/math?searchtype=author&query=Saidi%2C+L">Lamiae Saidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, the existence, uniqueness, and positivity of solutions, as
well as the asymptotic behavior through a finite fractal dimensional global
attractor for a general Advection-Diffusion-Reaction (ADR) equation, are
investigated. Our findings are innovative, as we employ semigroups and global
attractors theories to achieve these results. Also, an analytical solution of a
two-dimensional Advection-Diffusion Equation is presented. And finally, two
Explicit Finite Difference schemes are used to simulate solutions in the two-
and three-dimensional cases. The numerical simulations are conducted with
predefined initial and Dirichlet boundary conditions.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue,  5 Mar 24</h3>
<dl>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1803.06488" title="Abstract">arXiv:1803.06488</a> (replaced) [<a href="/pdf/1803.06488" title="Download PDF">pdf</a>, <a href="/format/1803.06488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An extended type system with lambda-typed lambda-expressions (extended  version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Matthias Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 246 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.01743" title="Abstract">arXiv:1907.01743</a> (replaced) [<a href="/pdf/1907.01743" title="Download PDF">pdf</a>, <a href="/format/1907.01743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Attentive Features for Prostate Segmentation in 3D Transrectal  Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dou%2C+H">Haoran Dou</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xiaowei Hu</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+J">Jing Qin</a>, 
<a href="/search/eess?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tianfu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+D">Dong Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures, 2 tables. Accepted by IEEE transactions on Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.04331" title="Abstract">arXiv:1910.04331</a> (replaced) [<a href="/pdf/1910.04331" title="Download PDF">pdf</a>, <a href="/format/1910.04331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent with Warm Start and Active Termination for Plane Localization in  3D Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dou%2C+H">Haoran Dou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+J">Jikuan Qian</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+W">Wufeng Xue</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+H">Hao Qin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+L">Lequan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shujun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+Y">Yi Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+D">Dong Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 1 table. Accepted by MICCAI 2019 (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.04935" title="Abstract">arXiv:1910.04935</a> (replaced) [<a href="/pdf/1910.04935" title="Download PDF">pdf</a>, <a href="/format/1910.04935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FetusMap: Fetal Pose Estimation in 3D Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenlong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+H">Haoran Dou</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jikuan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wufeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengli Li</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, 2 tables. Accepted by MICCAI 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.09038" title="Abstract">arXiv:2003.09038</a> (replaced) [<a href="/pdf/2003.09038" title="Download PDF">pdf</a>, <a href="/format/2003.09038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine-Resilient Distributed Optimization of Multi-Dimensional  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kuwaranancharoen%2C+K">Kananart Kuwaranancharoen</a>, 
<a href="/search/math?searchtype=author&query=Xin%2C+L">Lei Xin</a>, 
<a href="/search/math?searchtype=author&query=Sundaram%2C+S">Shreyas Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure; Proceedings of the 2020 American Control Conference, 1-3 July 2020, Denver, CO, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.06202" title="Abstract">arXiv:2102.06202</a> (replaced) [<a href="/pdf/2102.06202" title="Download PDF">pdf</a>, <a href="/format/2102.06202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Prediction Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+A+N">Anastasios N. Angelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bates%2C+S">Stephen Bates</a>, 
<a href="/search/cs?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/aangelopoulos/private_prediction_sets">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Harvard Data Science Review, 4(2). 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.09407" title="Abstract">arXiv:2102.09407</a> (replaced) [<a href="/pdf/2102.09407" title="Download PDF">pdf</a>, <a href="/format/2102.09407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Rational Activations to Boost Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delfosse%2C+Q">Quentin Delfosse</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Mundt%2C+M">Martin Mundt</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+A">Alejandro Molina</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main paper: 9 pages, References: 4 pages, Appendix: 11 pages. Main paper: 5 figures, Appendix: 6 figures, 6 tables. Rational Activation Functions repository: <a href="https://github.com/k4ntz/activation-functions">this https URL</a> Rational Reinforcement Learning: <a href="https://github.com/ml-research/rational_rl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.12468" title="Abstract">arXiv:2103.12468</a> (replaced) [<a href="/pdf/2103.12468" title="Download PDF">pdf</a>, <a href="/ps/2103.12468" title="Download PostScript">ps</a>, <a href="/format/2103.12468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximately Counting Answers to Conjunctive Queries with Disequalities  and Negations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Focke%2C+J">Jacob Focke</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+L+A">Leslie Ann Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+M">Marc Roth</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDivn%C3%BD%2C+S">Stanislav &#x17d;ivn&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended abstract of this work appeared in the proceedings of PODS22. 30 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.05377" title="Abstract">arXiv:2105.05377</a> (replaced) [<a href="/pdf/2105.05377" title="Download PDF">pdf</a>, <a href="/ps/2105.05377" title="Download PostScript">ps</a>, <a href="/format/2105.05377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identity Concealment Games: How I Learned to Stop Revealing and Love the  Coincidences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karabag%2C+M+O">Mustafa O. Karabag</a>, 
<a href="/search/cs?searchtype=author&query=Ornik%2C+M">Melkior Ornik</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Karabag, Mustafa O., Melkior Ornik, and Ufuk Topcu. "Identity
  concealment games: How I learned to stop revealing and love the
  coincidences." Automatica 161 (2024): 111482
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.13937" title="Abstract">arXiv:2105.13937</a> (replaced) [<a href="/pdf/2105.13937" title="Download PDF">pdf</a>, <a href="/format/2105.13937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient  adaptive algorithms for neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+D">Dong-Young Lim</a>, 
<a href="/search/cs?searchtype=author&query=Sabanis%2C+S">Sotirios Sabanis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.14490" title="Abstract">arXiv:2106.14490</a> (replaced) [<a href="/pdf/2106.14490" title="Download PDF">pdf</a>, <a href="/format/2106.14490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Images Real Again: A Comprehensive Survey on Deep Image  Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+W">Wenyan Cong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.04252" title="Abstract">arXiv:2107.04252</a> (replaced) [<a href="/pdf/2107.04252" title="Download PDF">pdf</a>, <a href="/format/2107.04252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tight Max-Flow Min-Cut Duality Theorem for Non-Linear Multicommodity  Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Broussard%2C+M">Matthew Broussard</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+B">Bala Krishnamoorthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor revisions; to appear in the Journal of Combinatorial Optimization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Algebraic Topology (math.AT)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.04771" title="Abstract">arXiv:2107.04771</a> (replaced) [<a href="/pdf/2107.04771" title="Download PDF">pdf</a>, <a href="/format/2107.04771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similar Cases Recommendation using Legal Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhani%2C+J+S">Jaspreet Singh Dhani</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+R">Ruchika Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+B">Balaji Ganesan</a>, 
<a href="/search/cs?searchtype=author&query=Sirohi%2C+P">Parikshet Sirohi</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+V">Vasudha Bhatnagar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. 6 figures. 3rd Symposium on Artificial Intelligence and Law. SAIL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.11977" title="Abstract">arXiv:2107.11977</a> (replaced) [<a href="/pdf/2107.11977" title="Download PDF">pdf</a>, <a href="/format/2107.11977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategyproof Facility Location in Perturbation Stable Instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fotakis%2C+D">Dimitris Fotakis</a>, 
<a href="/search/cs?searchtype=author&query=Patsilinakos%2C+P">Panagiotis Patsilinakos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.09307" title="Abstract">arXiv:2109.09307</a> (replaced) [<a href="/pdf/2109.09307" title="Download PDF">pdf</a>, <a href="/format/2109.09307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assisted Learning for Organizations with Limited Imbalanced Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiaying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jie Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (TMLR) (05/2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> C. Chen, J. Zhou, J. Ding, and Y. Zhou, "Assisted Learning for
  Organizations with Limited Imbalanced Data," Transactions on Machine Learning
  Research (TMLR), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.12586" title="Abstract">arXiv:2109.12586</a> (replaced) [<a href="/pdf/2109.12586" title="Download PDF">pdf</a>, <a href="/format/2109.12586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Simulation of Quantum Measurements via the Likelihood POVMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Padakandla%2C+A">Arun Padakandla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.15478" title="Abstract">arXiv:2111.15478</a> (replaced) [<a href="/pdf/2111.15478" title="Download PDF">pdf</a>, <a href="/ps/2111.15478" title="Download PostScript">ps</a>, <a href="/format/2111.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new near-linear time algorithm for k-nearest neighbor search using a  compressed cover tree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkin%2C+Y">Yury Elkin</a>, 
<a href="/search/cs?searchtype=author&query=Kurlin%2C+V">Vitaliy Kurlin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.11967" title="Abstract">arXiv:2201.11967</a> (replaced) [<a href="/pdf/2201.11967" title="Download PDF">pdf</a>, <a href="/format/2201.11967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Differential Neural Operator: Generalized Fourier Neural Operator  for Learning Solution Operators of Partial Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+J+Y">Jin Young Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Yong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H+J">Hyung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06191" title="Abstract">arXiv:2202.06191</a> (replaced) [<a href="/pdf/2202.06191" title="Download PDF">pdf</a>, <a href="/format/2202.06191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration and Incentivizing Participation in Clinical Trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingkai Li</a>, 
<a href="/search/cs?searchtype=author&query=Slivkins%2C+A">Aleksandrs Slivkins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09210" title="Abstract">arXiv:2202.09210</a> (replaced) [<a href="/pdf/2202.09210" title="Download PDF">pdf</a>, <a href="/format/2202.09210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hedonic Diversity Games: A Complexity Picture with More than Two Colors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Hamm%2C+T">Thekla Hamm</a>, 
<a href="/search/cs?searchtype=author&query=Knop%2C+D">Du&#x161;an Knop</a>, 
<a href="/search/cs?searchtype=author&query=Schierreich%2C+%C5%A0">&#x160;imon Schierreich</a>, 
<a href="/search/cs?searchtype=author&query=Such%C3%BD%2C+O">Ond&#x159;ej Such&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version appeared in AAAI '22
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Artificial Intelligence 325 (2023) 104017:1-20
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00465" title="Abstract">arXiv:2203.00465</a> (replaced) [<a href="/pdf/2203.00465" title="Download PDF">pdf</a>, <a href="/ps/2203.00465" title="Download PostScript">ps</a>, <a href="/format/2203.00465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient User-Centric Privacy-Friendly and Flexible Wearable Data  Aggregation and Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jastaniah%2C+K">Khlood Jastaniah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+M+A">Mustafa A. Mustafa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.05888" title="Abstract">arXiv:2203.05888</a> (replaced) [<a href="/pdf/2203.05888" title="Download PDF">pdf</a>, <a href="/format/2203.05888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moser-Tardos Algorithm with small number of random bits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cs%C3%B3ka%2C+E">Endre Cs&#xf3;ka</a>, 
<a href="/search/math?searchtype=author&query=Grabowski%2C+%C5%81">&#x141;ukasz Grabowski</a>, 
<a href="/search/math?searchtype=author&query=M%C3%A1th%C3%A9%2C+A">Andr&#xe1;s M&#xe1;th&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Pikhurko%2C+O">Oleg Pikhurko</a>, 
<a href="/search/math?searchtype=author&query=Tyros%2C+K">Konstantinos Tyros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages; minor corrections and changes; note that the required bound on the failure probabilities in Theorems 2.5 and 3.28 is slightly stronger than in Version 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.15149" title="Abstract">arXiv:2203.15149</a> (replaced) [<a href="/pdf/2203.15149" title="Download PDF">pdf</a>, <a href="/format/2203.15149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMGAN: Conformer-based Metric GAN for Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+R">Ruizhe Cao</a>, 
<a href="/search/cs?searchtype=author&query=Abdulatif%2C+S">Sherif Abdulatif</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, 2 tables, published in INTERSPEECH 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.00961" title="Abstract">arXiv:2204.00961</a> (replaced) [<a href="/pdf/2204.00961" title="Download PDF">pdf</a>, <a href="/ps/2204.00961" title="Download PostScript">ps</a>, <a href="/format/2204.00961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Digital Health Services: A Machine Learning Approach to  Personalized Exercise Goal Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Ji Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+V+C">Vincent CS Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Hao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiyan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05275" title="Abstract">arXiv:2204.05275</a> (replaced) [<a href="/pdf/2204.05275" title="Download PDF">pdf</a>, <a href="/format/2204.05275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Settling the Sample Complexity of Model-Based Offline Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+L">Laixi Shi</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/stat?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>, 
<a href="/search/stat?searchtype=author&query=Wei%2C+Y">Yuting Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to the Annals of Statistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Systems and Control (eess.SY); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05798" title="Abstract">arXiv:2204.05798</a> (replaced) [<a href="/pdf/2204.05798" title="Download PDF">pdf</a>, <a href="/format/2204.05798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Hypercomplex Learning for Breast Cancer Screening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopez%2C+E">Eleonora Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Grassucci%2C+E">Eleonora Grassucci</a>, 
<a href="/search/cs?searchtype=author&query=Valleriani%2C+M">Martina Valleriani</a>, 
<a href="/search/cs?searchtype=author&query=Comminiello%2C+D">Danilo Comminiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00224" title="Abstract">arXiv:2206.00224</a> (replaced) [<a href="/pdf/2206.00224" title="Download PDF">pdf</a>, <a href="/format/2206.00224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated first-order methods for a class of semidefinite programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+A+L">Alex L. Wang</a>, 
<a href="/search/math?searchtype=author&query=Kilinc-Karzan%2C+F">Fatma Kilinc-Karzan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12733" title="Abstract">arXiv:2206.12733</a> (replaced) [<a href="/pdf/2206.12733" title="Download PDF">pdf</a>, <a href="/format/2206.12733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiMa: Effective and Efficient Matching Across Data Silos Using Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koutras%2C+C">Christos Koutras</a>, 
<a href="/search/cs?searchtype=author&query=Hai%2C+R">Rihan Hai</a>, 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+K">Kyriakos Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Fragkoulis%2C+M">Marios Fragkoulis</a>, 
<a href="/search/cs?searchtype=author&query=Katsifodimos%2C+A">Asterios Katsifodimos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01227" title="Abstract">arXiv:2207.01227</a> (replaced) [<a href="/pdf/2207.01227" title="Download PDF">pdf</a>, <a href="/ps/2207.01227" title="Download PostScript">ps</a>, <a href="/format/2207.01227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity: Past, Present and Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Shahid Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Author's copy of the book published under ISBN: 978-620-4-74421-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03512" title="Abstract">arXiv:2207.03512</a> (replaced) [<a href="/pdf/2207.03512" title="Download PDF">pdf</a>, <a href="/ps/2207.03512" title="Download PostScript">ps</a>, <a href="/format/2207.03512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of smooth parametrizations on nonconvex optimization  landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Levin%2C+E">Eitan Levin</a>, 
<a href="/search/math?searchtype=author&query=Kileel%2C+J">Joe Kileel</a>, 
<a href="/search/math?searchtype=author&query=Boumal%2C+N">Nicolas Boumal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Math. Program. (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05868" title="Abstract">arXiv:2207.05868</a> (replaced) [<a href="/pdf/2207.05868" title="Download PDF">pdf</a>, <a href="/format/2207.05868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation algorithms for job scheduling with block-type conflict  graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Furma%C5%84czyk%2C+H">Hanna Furma&#x144;czyk</a>, 
<a href="/search/cs?searchtype=author&query=Pikies%2C+T">Tytus Pikies</a>, 
<a href="/search/cs?searchtype=author&query=Soko%C5%82owska%2C+I">Inka Soko&#x142;owska</a>, 
<a href="/search/cs?searchtype=author&query=Turowski%2C+K">Krzysztof Turowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 6 figures, 9 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06492" title="Abstract">arXiv:2207.06492</a> (replaced) [<a href="/pdf/2207.06492" title="Download PDF">pdf</a>, <a href="/format/2207.06492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Nash Equilibrium Learning for n-Player Markov Games in  Dynamic Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Larkin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07827" title="Abstract">arXiv:2207.07827</a> (replaced) [<a href="/pdf/2207.07827" title="Download PDF">pdf</a>, <a href="/format/2207.07827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLMFormer: Mitigating Data Redundancy to Revitalize Transformer-based  Long-Term Time Series Forecasting System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangsi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingfei Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changling Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.09286" title="Abstract">arXiv:2207.09286</a> (replaced) [<a href="/pdf/2207.09286" title="Download PDF">pdf</a>, <a href="/format/2207.09286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Online Micro-targeting Practices of Small, Medium, and  Large Businesses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chouaki%2C+S">Salim Chouaki</a> (1, 2, 3, 4), 
<a href="/search/cs?searchtype=author&query=Bouzenia%2C+I">Islem Bouzenia</a> (1, 2, 3, 4), 
<a href="/search/cs?searchtype=author&query=Goga%2C+O">Oana Goga</a> (1, 2, 3, 4), 
<a href="/search/cs?searchtype=author&query=Roussillon%2C+B">Beatrice Roussillon</a> (1, 5) ((1) Univ. Grenoble Alpes, (2) CNRS, (3) Grenoble INP, (4) LIG, (5) GAEL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12993" title="Abstract">arXiv:2207.12993</a> (replaced) [<a href="/pdf/2207.12993" title="Download PDF">pdf</a>, <a href="/ps/2207.12993" title="Download PostScript">ps</a>, <a href="/format/2207.12993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Stability of Electromechanical Switching Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramirez-Laboreo%2C+E">Edgar Ramirez-Laboreo</a> (1), 
<a href="/search/eess?searchtype=author&query=Sagues%2C+C">Carlos Sagues</a> (1), 
<a href="/search/eess?searchtype=author&query=Moya-Lasheras%2C+E">Eduardo Moya-Lasheras</a> (1), 
<a href="/search/eess?searchtype=author&query=Serrano-Seco%2C+E">Eloy Serrano-Seco</a> (1) ((1) Universidad de Zaragoza)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures. Revised version submitted for consideration to the IEEE/ASME Transactions on Mechatronics after first round of peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00463" title="Abstract">arXiv:2208.00463</a> (replaced) [<a href="/pdf/2208.00463" title="Download PDF">pdf</a>, <a href="/format/2208.00463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mismatching-Aware Unsupervised Translation Quality Estimation For  Low-Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azadi%2C+F">Fatemeh Azadi</a>, 
<a href="/search/cs?searchtype=author&query=Faili%2C+H">Heshaam Faili</a>, 
<a href="/search/cs?searchtype=author&query=Dousti%2C+M+J">Mohammad Javad Dousti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Language Resources and Evaluation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09500" title="Abstract">arXiv:2208.09500</a> (replaced) [<a href="/pdf/2208.09500" title="Download PDF">pdf</a>, <a href="/format/2208.09500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality-Inspired Taxonomy for Explainable Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neto%2C+P+C">Pedro C. Neto</a>, 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+T">Tiago Gon&#xe7;alves</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+J+R">Jo&#xe3;o Ribeiro Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+W">Wilson Silva</a>, 
<a href="/search/cs?searchtype=author&query=Sequeira%2C+A+F">Ana F. Sequeira</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+A">Arun Ross</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J+S">Jaime S. Cardoso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06177" title="Abstract">arXiv:2209.06177</a> (replaced) [<a href="/pdf/2209.06177" title="Download PDF">pdf</a>, <a href="/format/2209.06177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Graph Datasets for Node Classification:  Homophily-Heterophily Dichotomy and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Platonov%2C+O">Oleg Platonov</a>, 
<a href="/search/cs?searchtype=author&query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
<a href="/search/cs?searchtype=author&query=Babenko%2C+A">Artem Babenko</a>, 
<a href="/search/cs?searchtype=author&query=Prokhorenkova%2C+L">Liudmila Prokhorenkova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06356" title="Abstract">arXiv:2209.06356</a> (replaced) [<a href="/pdf/2209.06356" title="Download PDF">pdf</a>, <a href="/format/2209.06356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Forwards-Backwards Models to Approximate MDP Homomorphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mavor-Parker%2C+A+N">Augustine N. Mavor-Parker</a>, 
<a href="/search/cs?searchtype=author&query=Sargent%2C+M+J">Matthew J. Sargent</a>, 
<a href="/search/cs?searchtype=author&query=Pehle%2C+C">Christian Pehle</a>, 
<a href="/search/cs?searchtype=author&query=Banino%2C+A">Andrea Banino</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+L+D">Lewis D. Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Barry%2C+C">Caswell Barry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Previously Presented at the Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM) 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13099" title="Abstract">arXiv:2209.13099</a> (replaced) [<a href="/pdf/2209.13099" title="Download PDF">pdf</a>, <a href="/format/2209.13099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Mechanism Design for Blockchain Transaction Fee Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Simchi-Levi%2C+D">David Simchi-Levi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zishuo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, CESC 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01598" title="Abstract">arXiv:2210.01598</a> (replaced) [<a href="/pdf/2210.01598" title="Download PDF">pdf</a>, <a href="/format/2210.01598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the hull and interval numbers of oriented graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Araujo%2C+J">J. Araujo</a>, 
<a href="/search/math?searchtype=author&query=Maia%2C+A+K">A. K. Maia</a>, 
<a href="/search/math?searchtype=author&query=Medeiros%2C+P+P">P. P. Medeiros</a>, 
<a href="/search/math?searchtype=author&query=Penso%2C+L">L. Penso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01607" title="Abstract">arXiv:2210.01607</a> (replaced) [<a href="/pdf/2210.01607" title="Download PDF">pdf</a>, <a href="/format/2210.01607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Shape Compositional Framework to Synthesise Populations of  Virtual Chimaeras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dou%2C+H">Haoran Dou</a>, 
<a href="/search/eess?searchtype=author&query=Virtanen%2C+S">Seppo Virtanen</a>, 
<a href="/search/eess?searchtype=author&query=Ravikumar%2C+N">Nishant Ravikumar</a>, 
<a href="/search/eess?searchtype=author&query=Frangi%2C+A+F">Alejandro F. Frangi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, 4 tables. Accepted by IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02419" title="Abstract">arXiv:2210.02419</a> (replaced) [<a href="/pdf/2210.02419" title="Download PDF">pdf</a>, <a href="/format/2210.02419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary-Aware Uncertainty for Feature Attribution Explainers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hill%2C+D">Davin Hill</a>, 
<a href="/search/cs?searchtype=author&query=Masoomi%2C+A">Aria Masoomi</a>, 
<a href="/search/cs?searchtype=author&query=Torop%2C+M">Max Torop</a>, 
<a href="/search/cs?searchtype=author&query=Ghimire%2C+S">Sandesh Ghimire</a>, 
<a href="/search/cs?searchtype=author&query=Dy%2C+J">Jennifer Dy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 27th International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04870" title="Abstract">arXiv:2210.04870</a> (replaced) [<a href="/pdf/2210.04870" title="Download PDF">pdf</a>, <a href="/format/2210.04870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge  Graph Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+M">Miao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Ben Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+M">Min Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09475" title="Abstract">arXiv:2210.09475</a> (replaced) [<a href="/pdf/2210.09475" title="Download PDF">pdf</a>, <a href="/format/2210.09475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIMP: Foundation Model-Informed Message Passing for Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+A">Syed Asad Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Haoran Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+B">Benjamin Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Caro%2C+J+O">Josue Ortega Caro</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+A+H+O">Antonio H. O. Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Zappala%2C+E">Emanuele Zappala</a>, 
<a href="/search/cs?searchtype=author&query=Bagherian%2C+M">Maryam Bagherian</a>, 
<a href="/search/cs?searchtype=author&query=Averill%2C+C">Christopher Averill</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+C+G">Chadi G. Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Karbasi%2C+A">Amin Karbasi</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=Brbic%2C+M">Maria Brbic</a>, 
<a href="/search/cs?searchtype=author&query=Dhodapkar%2C+R+M">Rahul Madhav Dhodapkar</a>, 
<a href="/search/cs?searchtype=author&query=van+Dijk%2C+D">David van Dijk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages (11 + 5 pages appendix). 5 figures and 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00617" title="Abstract">arXiv:2211.00617</a> (replaced) [<a href="/pdf/2211.00617" title="Download PDF">pdf</a>, <a href="/format/2211.00617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of policy gradient methods for finite-horizon exploratory  linear-quadratic control problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Giegrich%2C+M">Michael Giegrich</a>, 
<a href="/search/math?searchtype=author&query=Reisinger%2C+C">Christoph Reisinger</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yufei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in SIAM Journal on Control and Optimization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01412" title="Abstract">arXiv:2211.01412</a> (replaced) [<a href="/pdf/2211.01412" title="Download PDF">pdf</a>, <a href="/format/2211.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMANet: Class Activation Map Guided Attention Network for Radiology  Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bhalerao%2C+A">Abhir Bhalerao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+T">Terry Yin</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+S">Simon See</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Journal of Biomedical and Health Informatics (IJBHI). 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07160" title="Abstract">arXiv:2211.07160</a> (replaced) [<a href="/pdf/2211.07160" title="Download PDF">pdf</a>, <a href="/format/2211.07160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedTracker: Furnishing Ownership Verification and Traceability for  Federated Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuo Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10209" title="Abstract">arXiv:2211.10209</a> (replaced) [<a href="/pdf/2211.10209" title="Download PDF">pdf</a>, <a href="/format/2211.10209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Algorithmic Fairness to Mitigate Blackbox Attribute Inference  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aalmoes%2C+J">Jan Aalmoes</a>, 
<a href="/search/cs?searchtype=author&query=Duddu%2C+V">Vasisht Duddu</a>, 
<a href="/search/cs?searchtype=author&query=Boutet%2C+A">Antoine Boutet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.02242">arXiv:2202.02242</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14298" title="Abstract">arXiv:2211.14298</a> (replaced) [<a href="/pdf/2211.14298" title="Download PDF">pdf</a>, <a href="/format/2211.14298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIP: Positional-encoding Image Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shabtay%2C+N">Nimrod Shabtay</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+E">Eli Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16943" title="Abstract">arXiv:2211.16943</a> (replaced) [<a href="/pdf/2211.16943" title="Download PDF">pdf</a>, <a href="/format/2211.16943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Properties of Quantum Systems with Conditional Generative  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Haoxiang Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Weber%2C+M">Maurice Weber</a>, 
<a href="/search/quant-ph?searchtype=author&query=Izaac%2C+J">Josh Izaac</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+C+Y">Cedric Yen-Yu Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 14 figures, 5 pages appendix. Open-source code is available at <a href="https://github.com/PennyLaneAI/generative-quantum-states">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03827" title="Abstract">arXiv:2212.03827</a> (replaced) [<a href="/pdf/2212.03827" title="Download PDF">pdf</a>, <a href="/format/2212.03827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Latent Knowledge in Language Models Without Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burns%2C+C">Collin Burns</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haotian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04672" title="Abstract">arXiv:2212.04672</a> (replaced) [<a href="/pdf/2212.04672" title="Download PDF">pdf</a>, <a href="/format/2212.04672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primal Dual Alternating Proximal Gradient Algorithms for Nonsmooth  Nonconvex Minimax Problems with Coupled Linear Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+H">Huiling Zhang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+J">Junlin Wang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Z">Zi Xu</a>, 
<a href="/search/math?searchtype=author&query=Dai%2C+Y">Yu-Hong Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11756" title="Abstract">arXiv:2212.11756</a> (replaced) [<a href="/pdf/2212.11756" title="Download PDF">pdf</a>, <a href="/ps/2212.11756" title="Download PostScript">ps</a>, <a href="/format/2212.11756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSS-o-SAGE: Direction-Scan Sounding-Oriented SAGE Algorithm for Channel  Parameter Estimation in mmWave and THz Bands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chong Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xuefeng Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13619" title="Abstract">arXiv:2212.13619</a> (replaced) [<a href="/pdf/2212.13619" title="Download PDF">pdf</a>, <a href="/ps/2212.13619" title="Download PostScript">ps</a>, <a href="/format/2212.13619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost-Bayesian Quadratic Persuasion (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Massicot%2C+O">Olivier Massicot</a>, 
<a href="/search/cs?searchtype=author&query=Langbort%2C+C">C&#xe9;dric Langbort</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version extends the article submitted to the IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13992" title="Abstract">arXiv:2212.13992</a> (replaced) [<a href="/pdf/2212.13992" title="Download PDF">pdf</a>, <a href="/format/2212.13992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social-Aware Clustered Federated Learning with Customized Privacy  Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhou Su</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yanghe Pan</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+T+H">Tom H Luan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruidong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shui Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE/ACM Transactions on Networking in March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09308" title="Abstract">arXiv:2301.09308</a> (replaced) [<a href="/pdf/2301.09308" title="Download PDF">pdf</a>, <a href="/format/2301.09308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Expressive Power of Geometric Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+C+K">Chaitanya K. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Bodnar%2C+C">Cristian Bodnar</a>, 
<a href="/search/cs?searchtype=author&query=Mathis%2C+S+V">Simon V. Mathis</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+T">Taco Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:15330-15355, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Group Theory (math.GR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10812" title="Abstract">arXiv:2301.10812</a> (replaced) [<a href="/pdf/2301.10812" title="Download PDF">pdf</a>, <a href="/ps/2301.10812" title="Download PostScript">ps</a>, <a href="/format/2301.10812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multisets and Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kozen%2C+D">Dexter Kozen</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Alexandra Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12318" title="Abstract">arXiv:2301.12318</a> (replaced) [<a href="/pdf/2301.12318" title="Download PDF">pdf</a>, <a href="/format/2301.12318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Di Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guanhong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shiqing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haixu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13755" title="Abstract">arXiv:2301.13755</a> (replaced) [<a href="/pdf/2301.13755" title="Download PDF">pdf</a>, <a href="/format/2301.13755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrosynthetic Planning with Dual Value Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guoqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+D">Di Xue</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shufang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tripp%2C+A">Austin Tripp</a>, 
<a href="/search/cs?searchtype=author&query=Maziarz%2C+K">Krzysztof Maziarz</a>, 
<a href="/search/cs?searchtype=author&query=Segler%2C+M">Marwin Segler</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zongzhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00556" title="Abstract">arXiv:2302.00556</a> (replaced) [<a href="/pdf/2302.00556" title="Download PDF">pdf</a>, <a href="/format/2302.00556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correspondence-free online human motion retargeting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rekik%2C+R">Rim Rekik</a>, 
<a href="/search/cs?searchtype=author&query=Marsot%2C+M">Mathieu Marsot</a>, 
<a href="/search/cs?searchtype=author&query=Olivier%2C+A">Anne-H&#xe9;l&#xe8;ne Olivier</a>, 
<a href="/search/cs?searchtype=author&query=Franco%2C+J">Jean-S&#xe9;bastien Franco</a>, 
<a href="/search/cs?searchtype=author&query=Wuhrer%2C+S">Stefanie Wuhrer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in International Conference on 3D Vision (3DV), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01203" title="Abstract">arXiv:2302.01203</a> (replaced) [<a href="/pdf/2302.01203" title="Download PDF">pdf</a>, <a href="/ps/2302.01203" title="Download PostScript">ps</a>, <a href="/format/2302.01203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning under Budget and ROI Constraints via Weak Adaptivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castiglioni%2C+M">Matteo Castiglioni</a>, 
<a href="/search/cs?searchtype=author&query=Celli%2C+A">Andrea Celli</a>, 
<a href="/search/cs?searchtype=author&query=Kroer%2C+C">Christian Kroer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02803" title="Abstract">arXiv:2302.02803</a> (replaced) [<a href="/pdf/2302.02803" title="Download PDF">pdf</a>, <a href="/format/2302.02803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never Skip Leg Day Again: Training the Lower Body with Vertical Jumps in  a Virtual Reality Exergame
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Karaosmanoglu%2C+S">Sukran Karaosmanoglu</a>, 
<a href="/search/cs?searchtype=author&query=Nacke%2C+L">Lennart Nacke</a>, 
<a href="/search/cs?searchtype=author&query=Steinicke%2C+F">Frank Steinicke</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04947" title="Abstract">arXiv:2302.04947</a> (replaced) [<a href="/pdf/2302.04947" title="Download PDF">pdf</a>, <a href="/format/2302.04947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Process-Gated Hierarchical Mixtures of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ajirak%2C+M">Marzieh Ajirak</a>, 
<a href="/search/cs?searchtype=author&query=Djuric%2C+P">Petar Djuric</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09597" title="Abstract">arXiv:2302.09597</a> (replaced) [<a href="/e-print/2302.09597" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Differential-Algebraic Equations in Power System Dynamic  Analysis with Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+H+T+T">Huynh Trung Thanh Tran</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+H+T">Hieu T.Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Vu%2C+L+T">Long T. Vu</a>, 
<a href="/search/eess?searchtype=author&query=Ojetola%2C+S+T">Samuel T. Ojetola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version was uploaded as an incorrect replacement, and was intended as a replacement of <a href="/abs/2306.01961">arXiv:2306.01961</a>. I need to withdraw this paper to upload it as a replacement of the correct paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energy Conversion and Economics, Volume 5, Issue 1, Feb 2024,
  pages 40-53
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10970" title="Abstract">arXiv:2302.10970</a> (replaced) [<a href="/pdf/2302.10970" title="Download PDF">pdf</a>, <a href="/format/2302.10970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Rendering with Reparameterized Volume Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morozov%2C+N">Nikita Morozov</a>, 
<a href="/search/cs?searchtype=author&query=Rakitin%2C+D">Denis Rakitin</a>, 
<a href="/search/cs?searchtype=author&query=Desheulin%2C+O">Oleg Desheulin</a>, 
<a href="/search/cs?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>, 
<a href="/search/cs?searchtype=author&query=Struminsky%2C+K">Kirill Struminsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024. Short version of this paper appeared in ICLR 2023 Neural Fields workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11517" title="Abstract">arXiv:2302.11517</a> (replaced) [<a href="/pdf/2302.11517" title="Download PDF">pdf</a>, <a href="/format/2302.11517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Global and Patch-wise Contrastive Loss for Accurate Automated Exudate  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+K">Kangning Cui</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+R+H">Raymond H. Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 2 tables. To appear in ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11640" title="Abstract">arXiv:2302.11640</a> (replaced) [<a href="/pdf/2302.11640" title="Download PDF">pdf</a>, <a href="/ps/2302.11640" title="Download PostScript">ps</a>, <a href="/format/2302.11640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A critical look at the evaluation of GNNs under heterophily: Are we  really making progress?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Platonov%2C+O">Oleg Platonov</a>, 
<a href="/search/cs?searchtype=author&query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
<a href="/search/cs?searchtype=author&query=Diskin%2C+M">Michael Diskin</a>, 
<a href="/search/cs?searchtype=author&query=Babenko%2C+A">Artem Babenko</a>, 
<a href="/search/cs?searchtype=author&query=Prokhorenkova%2C+L">Liudmila Prokhorenkova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12415" title="Abstract">arXiv:2302.12415</a> (replaced) [<a href="/pdf/2302.12415" title="Download PDF">pdf</a>, <a href="/ps/2302.12415" title="Download PostScript">ps</a>, <a href="/format/2302.12415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Speed and Accuracy of Machine Learning to Advance  Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+K">Khatoon Mohammed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14186" title="Abstract">arXiv:2302.14186</a> (replaced) [<a href="/pdf/2302.14186" title="Download PDF">pdf</a>, <a href="/format/2302.14186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximately optimal domain adaptation with Fisher&#x27;s Linear  Discriminant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Helm%2C+H+S">Hayden S. Helm</a>, 
<a href="/search/eess?searchtype=author&query=De+Silva%2C+A">Ashwin De Silva</a>, 
<a href="/search/eess?searchtype=author&query=Vogelstein%2C+J+T">Joshua T. Vogelstein</a>, 
<a href="/search/eess?searchtype=author&query=Priebe%2C+C+E">Carey E. Priebe</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+W">Weiwei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Applications (stat.AP); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03156" title="Abstract">arXiv:2303.03156</a> (replaced) [<a href="/pdf/2303.03156" title="Download PDF">pdf</a>, <a href="/ps/2303.03156" title="Download PostScript">ps</a>, <a href="/format/2303.03156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parallel Monte-Carlo Tree Search-Based Metaheuristic For Optimal Fleet  Composition Considering Vehicle Routing Using Branch &amp; Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baltussen%2C+T+M+J+T">T.M.J.T. Baltussen</a>, 
<a href="/search/eess?searchtype=author&query=Goutham%2C+M">M. Goutham</a>, 
<a href="/search/eess?searchtype=author&query=Menon%2C+M">M. Menon</a>, 
<a href="/search/eess?searchtype=author&query=Garrow%2C+S+G">S.G. Garrow</a>, 
<a href="/search/eess?searchtype=author&query=Santillo%2C+M">M. Santillo</a>, 
<a href="/search/eess?searchtype=author&query=Stockar%2C+S">S. Stockar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DOI Included in manuscript
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Intelligent Vehicles Symposium (IV)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05328" title="Abstract">arXiv:2303.05328</a> (replaced) [<a href="/pdf/2303.05328" title="Download PDF">pdf</a>, <a href="/format/2303.05328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-based, Finite-sample Inference for Privatized Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Awan%2C+J">Jordan Awan</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages before references and appendices, 42 pages total, 10 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Cryptography and Security (cs.CR); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07196" title="Abstract">arXiv:2303.07196</a> (replaced) [<a href="/pdf/2303.07196" title="Download PDF">pdf</a>, <a href="/format/2303.07196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Empirical Evaluation of Existing Word Embedding  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaland%2C+O">Obaidullah Zaland</a>, 
<a href="/search/cs?searchtype=author&query=Abulaish%2C+M">Muhammad Abulaish</a>, 
<a href="/search/cs?searchtype=author&query=Fazil%2C+M">Mohd. Fazil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures and 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09105" title="Abstract">arXiv:2303.09105</a> (replaced) [<a href="/pdf/2303.09105" title="Download PDF">pdf</a>, <a href="/format/2303.09105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Model Ensemble in Transfer-based Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12194" title="Abstract">arXiv:2303.12194</a> (replaced) [<a href="/pdf/2303.12194" title="Download PDF">pdf</a>, <a href="/format/2303.12194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDARFormer: A Unified Transformer-based Multi-task Network for LiDAR  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dongqiangzi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yufei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Panqu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Foroosh%2C+H">Hassan Foroosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15495" title="Abstract">arXiv:2303.15495</a> (replaced) [<a href="/pdf/2303.15495" title="Download PDF">pdf</a>, <a href="/format/2303.15495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Bus Arrival Prediction: A Deep Learning Approach for Enhanced  Urban Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashvand%2C+N">Narges Rashvand</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+S+S">Sanaz Sadat Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Azarbayjani%2C+M">Mona Azarbayjani</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15610" title="Abstract">arXiv:2303.15610</a> (replaced) [<a href="/pdf/2303.15610" title="Download PDF">pdf</a>, <a href="/format/2303.15610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Crossing-Free Hamiltonian Cycles in Simple Drawings of Complete  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aichholzer%2C+O">Oswin Aichholzer</a>, 
<a href="/search/math?searchtype=author&query=Orthaber%2C+J">Joachim Orthaber</a>, 
<a href="/search/math?searchtype=author&query=Vogtenhuber%2C+B">Birgit Vogtenhuber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version as published in the journal Computing in Geometry and Topology. (30 pages, 22 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17386" title="Abstract">arXiv:2303.17386</a> (replaced) [<a href="/pdf/2303.17386" title="Download PDF">pdf</a>, <a href="/format/2303.17386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complementary Random Masking for RGB-Thermal Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+U">Ukcheol Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyunghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kweon%2C+I+S">In So Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jean Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024, Our source code is available at <a href="https://github.com/UkcheolShin/CRM_RGBTSeg">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01915" title="Abstract">arXiv:2304.01915</a> (replaced) [<a href="/pdf/2304.01915" title="Download PDF">pdf</a>, <a href="/format/2304.01915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fog Device-as-a-Service (FDaaS): A Framework for Service Deployment in  Public Fog Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Battula%2C+S+K">Sudheer Kumar Battula</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Saurabh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Montgomery%2C+J">James Montgomery</a>, 
<a href="/search/cs?searchtype=author&query=Naha%2C+R">Ranesh Naha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 13 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02313" title="Abstract">arXiv:2304.02313</a> (replaced) [<a href="/pdf/2304.02313" title="Download PDF">pdf</a>, <a href="/format/2304.02313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personality-aware Human-centric Multimodal Reasoning: A New Task,  Dataset and Baselines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiangqing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Rui Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02867" title="Abstract">arXiv:2304.02867</a> (replaced) [<a href="/pdf/2304.02867" title="Download PDF">pdf</a>, <a href="/format/2304.02867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voxel or Pillar: Exploring Efficient Point Cloud Representation for 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sanping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06155" title="Abstract">arXiv:2304.06155</a> (replaced) [<a href="/pdf/2304.06155" title="Download PDF">pdf</a>, <a href="/format/2304.06155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skyline Operators for Document Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amarilli%2C+A">Antoine Amarilli</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>, 
<a href="/search/cs?searchtype=author&query=Labb%C3%A9%2C+S">S&#xe9;bastien Labb&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Mengel%2C+S">Stefan Mengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages. This is the full version of the ICDT'24 publication, which includes all reviewer feedback; the main body is identical to the ICDT'24 article up to minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06607" title="Abstract">arXiv:2304.06607</a> (replaced) [<a href="/pdf/2304.06607" title="Download PDF">pdf</a>, <a href="/format/2304.06607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Claims against Model Ownership Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Szyller%2C+S">Sebastian Szyller</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13pages,3 figures. To appear in the 33rd USENIX Security Symposium (USENIX Security '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08718" title="Abstract">arXiv:2304.08718</a> (replaced) [<a href="/pdf/2304.08718" title="Download PDF">pdf</a>, <a href="/format/2304.08718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Implicit Factorization Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yansong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Nitaj%2C+A">Abderrahmane Nitaj</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yanbin Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09485" title="Abstract">arXiv:2304.09485</a> (replaced) [<a href="/pdf/2304.09485" title="Download PDF">pdf</a>, <a href="/ps/2304.09485" title="Download PostScript">ps</a>, <a href="/format/2304.09485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit high-order gas-kinetic schemes for compressible flows on  three-dimensional unstructured meshes I: steady flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yaqing Yang</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+K">Kun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2203.09047">arXiv:2203.09047</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10921" title="Abstract">arXiv:2304.10921</a> (replaced) [<a href="/pdf/2304.10921" title="Download PDF">pdf</a>, <a href="/format/2304.10921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-Based Distributed Controller Design Over Directed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+Y">Yuto Watanabe</a>, 
<a href="/search/eess?searchtype=author&query=Sakurama%2C+K">Kazunori Sakurama</a>, 
<a href="/search/eess?searchtype=author&query=Ahn%2C+H">Hyo-Sung Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. <a href="https://ieeexplore.ieee.org/document/10453999">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14614" title="Abstract">arXiv:2304.14614</a> (replaced) [<a href="/pdf/2304.14614" title="Download PDF">pdf</a>, <a href="/format/2304.14614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusion is Not Enough: Single Modal Attacks on Fusion Models for 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hongjun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">James Liang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shiwei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guanhong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongfang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zuzak%2C+M">Michael Zuzak</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14701" title="Abstract">arXiv:2304.14701</a> (replaced) [<a href="/pdf/2304.14701" title="Download PDF">pdf</a>, <a href="/ps/2304.14701" title="Download PostScript">ps</a>, <a href="/format/2304.14701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permissionless Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewis-Pye%2C+A">Andrew Lewis-Pye</a>, 
<a href="/search/cs?searchtype=author&query=Roughgarden%2C+T">Tim Roughgarden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a journal version of the paper that subsumes earlier (conference) versions "Byzantine Generals in the Permissionless Setting" and "Resource Pools and the CAP Theorem"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02483" title="Abstract">arXiv:2305.02483</a> (replaced) [<a href="/pdf/2305.02483" title="Download PDF">pdf</a>, <a href="/format/2305.02483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Abstractive Summarization by Tri-agent Generation Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yujia Xie</a>, 
<a href="/search/cs?searchtype=author&query=Carenini%2C+G">Giuseppe Carenini</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EACL 2024 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04104" title="Abstract">arXiv:2305.04104</a> (replaced) [<a href="/pdf/2305.04104" title="Download PDF">pdf</a>, <a href="/format/2305.04104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Feedback for Affine Nonlinear Systems with Application to Global  Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Miaomiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figues
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Automatic Control (2024) 1-8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04440" title="Abstract">arXiv:2305.04440</a> (replaced) [<a href="/pdf/2305.04440" title="Download PDF">pdf</a>, <a href="/format/2305.04440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Transformer Off-the-Shelf: A Surprising Baseline for Few-Shot  Class-Agnostic Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Liwen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07912" title="Abstract">arXiv:2305.07912</a> (replaced) [<a href="/pdf/2305.07912" title="Download PDF">pdf</a>, <a href="/format/2305.07912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Language Model with Prompts for Temporal Knowledge Graph  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Ben Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+M">Miao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xu Jia</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+M">Min Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09181" title="Abstract">arXiv:2305.09181</a> (replaced) [<a href="/pdf/2305.09181" title="Download PDF">pdf</a>, <a href="/format/2305.09181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Rectified Version) Push-LSVRG-UP: Distributed Stochastic Optimization  over Unbalanced Directed Networks with Uncoordinated Triggered Probabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jinhui Hu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huaqing Li</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+Z">Zixiang Shen</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+W">Weidong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 30 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE TRANSACTIONS ON NETWORK SCIENCE AND ENGINEERING, VOL. 10, NO.
  2, 2023, PP. 934-950
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10738" title="Abstract">arXiv:2305.10738</a> (replaced) [<a href="/pdf/2305.10738" title="Download PDF">pdf</a>, <a href="/format/2305.10738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Temporal Graph Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+W">Wenxuan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11468" title="Abstract">arXiv:2305.11468</a> (replaced) [<a href="/pdf/2305.11468" title="Download PDF">pdf</a>, <a href="/format/2305.11468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Topology Agnosticism: Enhancing Skeleton-Based Action  Recognition through Redefined Skeletal Topology Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11577" title="Abstract">arXiv:2305.11577</a> (replaced) [<a href="/pdf/2305.11577" title="Download PDF">pdf</a>, <a href="/format/2305.11577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeftRefill: Filling Right Canvas based on Left Reference through  Generalized Text-to-Image Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chenjie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yunuo Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiaole Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024. Codes and models are released at <a href="https://github.com/ewrfcas/LeftRefill">this https URL</a>, Project page: <a href="https://ewrfcas.github.io/LeftRefill">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13318" title="Abstract">arXiv:2305.13318</a> (replaced) [<a href="/pdf/2305.13318" title="Download PDF">pdf</a>, <a href="/format/2305.13318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stable deep adversarial learning approach for geological facies  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bhavsar%2C+F">Ferdinand Bhavsar</a>, 
<a href="/search/physics?searchtype=author&query=Desassis%2C+N">Nicolas Desassis</a>, 
<a href="/search/physics?searchtype=author&query=Ors%2C+F">Fabien Ors</a>, 
<a href="/search/physics?searchtype=author&query=Romary%2C+T">Thomas Romary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13655" title="Abstract">arXiv:2305.13655</a> (replaced) [<a href="/pdf/2305.13655" title="Download PDF">pdf</a>, <a href="/format/2305.13655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image  Diffusion Models with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+L">Long Lian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yala%2C+A">Adam Yala</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research (TMLR) 2024, with Featured Certification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15086" title="Abstract">arXiv:2305.15086</a> (replaced) [<a href="/pdf/2305.15086" title="Download PDF">pdf</a>, <a href="/format/2305.15086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unpaired Image-to-Image Translation via Neural Schr&#xf6;dinger Bridge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+G">Gihyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kwanyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16147" title="Abstract">arXiv:2305.16147</a> (replaced) [<a href="/pdf/2305.16147" title="Download PDF">pdf</a>, <a href="/format/2305.16147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Safety Constraints from Demonstrations with Unknown Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindner%2C+D">David Lindner</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tschiatschek%2C+S">Sebastian Tschiatschek</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+K">Katja Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the International Conference on Artificial Intelligence and Statistics (AISTATS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17583" title="Abstract">arXiv:2305.17583</a> (replaced) [<a href="/pdf/2305.17583" title="Download PDF">pdf</a>, <a href="/format/2305.17583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Neural Networks as Infinite Tree-Structured Probabilistic Graphical  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+B">Boyao Li</a>, 
<a href="/search/stat?searchtype=author&query=Thomson%2C+A+J">Alexandar J. Thomson</a>, 
<a href="/search/stat?searchtype=author&query=Engelhard%2C+M+M">Matthew M. Engelhard</a>, 
<a href="/search/stat?searchtype=author&query=Page%2C+D">David Page</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18352" title="Abstract">arXiv:2305.18352</a> (replaced) [<a href="/pdf/2305.18352" title="Download PDF">pdf</a>, <a href="/format/2305.18352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Genetic Algorithm for Multi-View Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imani%2C+V">Vandad Imani</a>, 
<a href="/search/cs?searchtype=author&query=Sevilla-Salcedo%2C+C">Carlos Sevilla-Salcedo</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+E">Elaheh Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Fortino%2C+V">Vittorio Fortino</a>, 
<a href="/search/cs?searchtype=author&query=Tohka%2C+J">Jussi Tohka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18436" title="Abstract">arXiv:2305.18436</a> (replaced) [<a href="/pdf/2305.18436" title="Download PDF">pdf</a>, <a href="/format/2305.18436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistically Optimal K-means Clustering via Nonnegative Low-rank  Semidefinite Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhuang%2C+Y">Yubo Zhuang</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+Y">Yun Yang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+R+Y">Richard Y. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00603" title="Abstract">arXiv:2306.00603</a> (replaced) [<a href="/pdf/2306.00603" title="Download PDF">pdf</a>, <a href="/format/2306.00603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Offline Reinforcement Learning with Real-Time Budget Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shangqin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianlong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingxing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We propose a method to handle the constraint problem with dynamically determined safety budgets under the offline setting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00973" title="Abstract">arXiv:2306.00973</a> (replaced) [<a href="/pdf/2306.00973" title="Download PDF">pdf</a>, <a href="/format/2306.00973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yujie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024. Project Page: <a href="https://haoningwu3639.github.io/StoryGen_Webpage/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01517" title="Abstract">arXiv:2306.01517</a> (replaced) [<a href="/pdf/2306.01517" title="Download PDF">pdf</a>, <a href="/ps/2306.01517" title="Download PostScript">ps</a>, <a href="/format/2306.01517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Broadcast Networks with Registers: from NP to the  Frontiers of Decidability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guillou%2C+L">Lucie Guillou</a>, 
<a href="/search/cs?searchtype=author&query=Mascle%2C+C">Corto Mascle</a>, 
<a href="/search/cs?searchtype=author&query=Waldburger%2C+N">Nicolas Waldburger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long version of a paper published at FoSSaCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01597" title="Abstract">arXiv:2306.01597</a> (replaced) [<a href="/pdf/2306.01597" title="Download PDF">pdf</a>, <a href="/ps/2306.01597" title="Download PostScript">ps</a>, <a href="/format/2306.01597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Un)Solvable Loop Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amrollahi%2C+D">Daneshvar Amrollahi</a>, 
<a href="/search/cs?searchtype=author&query=Bartocci%2C+E">Ezio Bartocci</a>, 
<a href="/search/cs?searchtype=author&query=Kenison%2C+G">George Kenison</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Moosbrugger%2C+M">Marcel Moosbrugger</a>, 
<a href="/search/cs?searchtype=author&query=Stankovi%C4%8D%2C+M">Miroslav Stankovi&#x10d;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the conference paper `Solving Invariant Generation for Unsolvable Loops' published at SAS 2022 (see also the preprint <a href="/abs/2206.06943">arXiv:2206.06943</a>). We extended both the text and results. 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02010" title="Abstract">arXiv:2306.02010</a> (replaced) [<a href="/pdf/2306.02010" title="Download PDF">pdf</a>, <a href="/format/2306.02010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memorization Capacity of Multi-Head Attention in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+S">Sadegh Mahdavi</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+R">Renjie Liao</a>, 
<a href="/search/cs?searchtype=author&query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03424" title="Abstract">arXiv:2306.03424</a> (replaced) [<a href="/pdf/2306.03424" title="Download PDF">pdf</a>, <a href="/format/2306.03424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCD-DDPM: A Generative Change Detection Model Based on  Difference-Feature Guided DDPM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yihan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+M">Man-On Pun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03604" title="Abstract">arXiv:2306.03604</a> (replaced) [<a href="/pdf/2306.03604" title="Download PDF">pdf</a>, <a href="/format/2306.03604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Intelligent Interactions between an Agent and an LLM: A  Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuanhang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03928" title="Abstract">arXiv:2306.03928</a> (replaced) [<a href="/pdf/2306.03928" title="Download PDF">pdf</a>, <a href="/format/2306.03928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Decision Support Systems Using Counterfactual Prediction Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straitouri%2C+E">Eleni Straitouri</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+M+G">Manuel Gomez Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best paper award in the ICML 2023 AI&amp;HCI Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04815" title="Abstract">arXiv:2306.04815</a> (replaced) [<a href="/pdf/2306.04815" title="Download PDF">pdf</a>, <a href="/format/2306.04815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catapults in SGD: spikes in the training loss and their impact on  generalization through feature learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Libin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chaoyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+A">Adityanarayanan Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Belkin%2C+M">Mikhail Belkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05499" title="Abstract">arXiv:2306.05499</a> (replaced) [<a href="/pdf/2306.05499" title="Download PDF">pdf</a>, <a href="/format/2306.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Injection attack against LLM-integrated Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+G">Gelei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuekang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yepang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06022" title="Abstract">arXiv:2306.06022</a> (replaced) [<a href="/pdf/2306.06022" title="Download PDF">pdf</a>, <a href="/ps/2306.06022" title="Download PostScript">ps</a>, <a href="/format/2306.06022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Partial Computation Offloading for the Metaverse in In-Network  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliyu%2C+I">Ibrahim Aliyu</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Seungmin Oh</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+N">Namseok Ko</a>, 
<a href="/search/cs?searchtype=author&query=Um%2C+T">Tai-Won Um</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinsul Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06458" title="Abstract">arXiv:2306.06458</a> (replaced) [<a href="/pdf/2306.06458" title="Download PDF">pdf</a>, <a href="/ps/2306.06458" title="Download PostScript">ps</a>, <a href="/format/2306.06458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Splitting Multiple Access for Simultaneous Multi-User Communication  and Multi-Target Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kexin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Longfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengcheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yang Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07490" title="Abstract">arXiv:2306.07490</a> (replaced) [<a href="/pdf/2306.07490" title="Download PDF">pdf</a>, <a href="/format/2306.07490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-Down Framework for Weakly-supervised Grounded Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Chen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+K">Kim-hui Yap</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08018" title="Abstract">arXiv:2306.08018</a> (replaced) [<a href="/pdf/2306.08018" title="Download PDF">pdf</a>, <a href="/format/2306.08018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+Y">Yin Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liang%2C+X">Xiaozhuan Liang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+K">Kangwei Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+R">Rui Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Fan%2C+X">Xiaohui Fan</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Project homepage: <a href="https://github.com/zjunlp/Mol-Instructions">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08069" title="Abstract">arXiv:2306.08069</a> (replaced) [<a href="/pdf/2306.08069" title="Download PDF">pdf</a>, <a href="/ps/2306.08069" title="Download PostScript">ps</a>, <a href="/format/2306.08069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $(n,m)$-chromatic numbers of graphs having bounded sparsity  parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Das%2C+S">Sandip Das</a>, 
<a href="/search/math?searchtype=author&query=Lahiri%2C+A">Abhiruk Lahiri</a>, 
<a href="/search/math?searchtype=author&query=Nandi%2C+S">Soumen Nandi</a>, 
<a href="/search/math?searchtype=author&query=Sen%2C+S">Sagnik Sen</a>, 
<a href="/search/math?searchtype=author&query=Taruni%2C+S">S Taruni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08175" title="Abstract">arXiv:2306.08175</a> (replaced) [<a href="/pdf/2306.08175" title="Download PDF">pdf</a>, <a href="/format/2306.08175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCTX-Conformer: Dynamic context carry-over for low latency unified  streaming and non-streaming Conformer ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huybrechts%2C+G">Goeric Huybrechts</a>, 
<a href="/search/eess?searchtype=author&query=Ronanki%2C+S">Srikanth Ronanki</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xilai Li</a>, 
<a href="/search/eess?searchtype=author&query=Nosrati%2C+H">Hadis Nosrati</a>, 
<a href="/search/eess?searchtype=author&query=Bodapati%2C+S">Sravan Bodapati</a>, 
<a href="/search/eess?searchtype=author&query=Kirchhoff%2C+K">Katrin Kirchhoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08625" title="Abstract">arXiv:2306.08625</a> (replaced) [<a href="/pdf/2306.08625" title="Download PDF">pdf</a>, <a href="/format/2306.08625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RRSIS: Referring Remote Sensing Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhenghang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+L">Lichao Mou</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yuansheng Hua</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08823" title="Abstract">arXiv:2306.08823</a> (replaced) [<a href="/pdf/2306.08823" title="Download PDF">pdf</a>, <a href="/format/2306.08823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-in Hybrid Electric Vehicle Energy Management with Clutch Engagement  Control via Continuous-Discrete Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gong%2C+C">Changfu Gong</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jinming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09348" title="Abstract">arXiv:2306.09348</a> (replaced) [<a href="/pdf/2306.09348" title="Download PDF">pdf</a>, <a href="/format/2306.09348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing the World through Your Eyes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alzayer%2C+H">Hadi Alzayer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kevin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+B">Brandon Feng</a>, 
<a href="/search/cs?searchtype=author&query=Metzler%2C+C">Christopher Metzler</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. First two authors contributed equally. Project page: <a href="https://world-from-eyes.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09910" title="Abstract">arXiv:2306.09910</a> (replaced) [<a href="/pdf/2306.09910" title="Download PDF">pdf</a>, <a href="/format/2306.09910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LabelBench: A Comprehensive Framework for Benchmarking Adaptive  Label-Efficient Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Canal%2C+G">Gregory Canal</a>, 
<a href="/search/cs?searchtype=author&query=Mussmann%2C+S">Stephen Mussmann</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav M. Das</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yinglun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeffrey Bilmes</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon Shaolei Du</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+R+D">Robert D Nowak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10356" title="Abstract">arXiv:2306.10356</a> (replaced) [<a href="/pdf/2306.10356" title="Download PDF">pdf</a>, <a href="/format/2306.10356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MATNet: Multi-Level Fusion Transformer-Based Model for Day-Ahead PV  Generation Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tortora%2C+M">Matteo Tortora</a>, 
<a href="/search/cs?searchtype=author&query=Conte%2C+F">Francesco Conte</a>, 
<a href="/search/cs?searchtype=author&query=Natrella%2C+G">Gianluca Natrella</a>, 
<a href="/search/cs?searchtype=author&query=Soda%2C+P">Paolo Soda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12508" title="Abstract">arXiv:2306.12508</a> (replaced) [<a href="/pdf/2306.12508" title="Download PDF">pdf</a>, <a href="/format/2306.12508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Logical Zonotopes: A Set Representation for Reachability  Analysis of Logical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alanwar%2C+A">Amr Alanwar</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F+J">Frank J. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12525" title="Abstract">arXiv:2306.12525</a> (replaced) [<a href="/pdf/2306.12525" title="Download PDF">pdf</a>, <a href="/format/2306.12525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LPFormer: LiDAR Pose Estimation Transformer with Multi-Task Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dongqiangzi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yufei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+L">Lingting Ge</a>, 
<a href="/search/cs?searchtype=author&query=Foroosh%2C+H">Hassan Foroosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024. Top solution for the Waymo Open Dataset Challenges 2023 - Pose Estimation. CVPR 2023 Workshop on Autonomous Driving
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12682" title="Abstract">arXiv:2306.12682</a> (replaced) [<a href="/pdf/2306.12682" title="Download PDF">pdf</a>, <a href="/format/2306.12682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting occurrences of patterns in permutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Conway%2C+A+R">Andrew R Conway</a>, 
<a href="/search/math?searchtype=author&query=Guttmann%2C+A+J">Anthony J Guttmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages. Updated references from previous version. Removal on earlier discussion of Stieltjes sequences, which was incomplete and confusing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12803" title="Abstract">arXiv:2306.12803</a> (replaced) [<a href="/pdf/2306.12803" title="Download PDF">pdf</a>, <a href="/format/2306.12803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Statistical Comparison of Random Variables with Locally Varying  Scale of Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jansen%2C+C">Christoph Jansen</a>, 
<a href="/search/stat?searchtype=author&query=Schollmeyer%2C+G">Georg Schollmeyer</a>, 
<a href="/search/stat?searchtype=author&query=Blocher%2C+H">Hannah Blocher</a>, 
<a href="/search/stat?searchtype=author&query=Rodemann%2C+J">Julian Rodemann</a>, 
<a href="/search/stat?searchtype=author&query=Augustin%2C+T">Thomas Augustin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 39th Conference on Uncertainty in Artificial Intelligence (UAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14137" title="Abstract">arXiv:2306.14137</a> (replaced) [<a href="/pdf/2306.14137" title="Download PDF">pdf</a>, <a href="/ps/2306.14137" title="Download PostScript">ps</a>, <a href="/format/2306.14137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BotanicGarden: A High-Quality Dataset for Robot Navigation in  Unstructured Natural Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yujia Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Minghui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yufeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baoxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fengdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Goossens%2C+B">Bart Goossens</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P+Z+H">Poly Z.H. Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15924" title="Abstract">arXiv:2306.15924</a> (replaced) [<a href="/pdf/2306.15924" title="Download PDF">pdf</a>, <a href="/ps/2306.15924" title="Download PostScript">ps</a>, <a href="/format/2306.15924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Parametric Complexity of Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanthaler%2C+S">Samuel Lanthaler</a>, 
<a href="/search/cs?searchtype=author&query=Stuart%2C+A+M">Andrew M. Stuart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17494" title="Abstract">arXiv:2306.17494</a> (replaced) [<a href="/pdf/2306.17494" title="Download PDF">pdf</a>, <a href="/format/2306.17494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ontological Approach to Compliance Verification of the NIS 2  Directive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castiglione%2C+G">Gianpietro Castiglione</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria%2C+D+F">Daniele Francesco Santamaria</a>, 
<a href="/search/cs?searchtype=author&query=Bella%2C+G">Giampaolo Bella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00212" title="Abstract">arXiv:2307.00212</a> (replaced) [<a href="/pdf/2307.00212" title="Download PDF">pdf</a>, <a href="/format/2307.00212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internal-External Boundary Attention Fusion for Glass Surface  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongshen Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungkyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Heechan Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyukmin Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyun-Cheol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+H">Hyon-Gon Choo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00494" title="Abstract">arXiv:2307.00494</a> (replaced) [<a href="/pdf/2307.00494" title="Download PDF">pdf</a>, <a href="/format/2307.00494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Protein Optimization with Smoothed Fitness Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kirjner%2C+A">Andrew Kirjner</a>, 
<a href="/search/q-bio?searchtype=author&query=Yim%2C+J">Jason Yim</a>, 
<a href="/search/q-bio?searchtype=author&query=Samusevich%2C+R">Raman Samusevich</a>, 
<a href="/search/q-bio?searchtype=author&query=Bracha%2C+S">Shahar Bracha</a>, 
<a href="/search/q-bio?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>, 
<a href="/search/q-bio?searchtype=author&query=Barzilay%2C+R">Regina Barzilay</a>, 
<a href="/search/q-bio?searchtype=author&query=Fiete%2C+I">Ila Fiete</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Code: <a href="https://github.com/kirjner/GGS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02799" title="Abstract">arXiv:2307.02799</a> (replaced) [<a href="/pdf/2307.02799" title="Download PDF">pdf</a>, <a href="/format/2307.02799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Personalized Saliency Prediction Based on Inter-personnel Gaze  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moroto%2C+Y">Yuya Moroto</a>, 
<a href="/search/eess?searchtype=author&query=Maeda%2C+K">Keisuke Maeda</a>, 
<a href="/search/eess?searchtype=author&query=Ogawa%2C+T">Takahiro Ogawa</a>, 
<a href="/search/eess?searchtype=author&query=Haseyama%2C+M">Miki Haseyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02932" title="Abstract">arXiv:2307.02932</a> (replaced) [<a href="/pdf/2307.02932" title="Download PDF">pdf</a>, <a href="/format/2307.02932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When No-Rejection Learning is Consistent for Regression with Rejection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaocheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chunlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04644" title="Abstract">arXiv:2307.04644</a> (replaced) [<a href="/pdf/2307.04644" title="Download PDF">pdf</a>, <a href="/format/2307.04644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness and Diversity in Recommender Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+C">Charu Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05435" title="Abstract">arXiv:2307.05435</a> (replaced) [<a href="/pdf/2307.05435" title="Download PDF">pdf</a>, <a href="/format/2307.05435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Versus-Others Attention: Scalable Multimodal Integration for  Clinical Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golovanevsky%2C+M">Michal Golovanevsky</a>, 
<a href="/search/cs?searchtype=author&query=Schiller%2C+E">Eva Schiller</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+A">Akira Nair</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Ritambhara Singh</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+C">Carsten Eickhoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07221" title="Abstract">arXiv:2307.07221</a> (replaced) [<a href="/pdf/2307.07221" title="Download PDF">pdf</a>, <a href="/format/2307.07221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Testing with Large Language Models: Survey, Landscape, and  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuchao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Software Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07932" title="Abstract">arXiv:2307.07932</a> (replaced) [<a href="/pdf/2307.07932" title="Download PDF">pdf</a>, <a href="/format/2307.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Truncated Norm Regularization Method for Multi-channel Color  Image Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shan%2C+Y">Yiwen Shan</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+D">Dong Hu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11543" title="Abstract">arXiv:2307.11543</a> (replaced) [<a href="/pdf/2307.11543" title="Download PDF">pdf</a>, <a href="/format/2307.11543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donadi%2C+I">Ivano Donadi</a>, 
<a href="/search/cs?searchtype=author&query=Pretto%2C+A">Alberto Pretto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 9, no. 4, pp.
  3498-3505, April 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12306" title="Abstract">arXiv:2307.12306</a> (replaced) [<a href="/pdf/2307.12306" title="Download PDF">pdf</a>, <a href="/format/2307.12306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling the Curse of Dimensionality with Physics-Informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+K">Khemraj Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12936" title="Abstract">arXiv:2307.12936</a> (replaced) [<a href="/pdf/2307.12936" title="Download PDF">pdf</a>, <a href="/format/2307.12936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timely Target Tracking: Distributed Updating in Cognitive Radar Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Howard%2C+W+W">William W. Howard</a>, 
<a href="/search/eess?searchtype=author&query=Martone%2C+A+F">Anthony F. Martone</a>, 
<a href="/search/eess?searchtype=author&query=Buehrer%2C+R+M">R. Michael Buehrer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, double column, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13586" title="Abstract">arXiv:2307.13586</a> (replaced) [<a href="/pdf/2307.13586" title="Download PDF">pdf</a>, <a href="/ps/2307.13586" title="Download PostScript">ps</a>, <a href="/format/2307.13586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Settling the Sample Complexity of Online Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14288" title="Abstract">arXiv:2307.14288</a> (replaced) [<a href="/pdf/2307.14288" title="Download PDF">pdf</a>, <a href="/format/2307.14288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> US \&amp; MRI Image Fusion Based on Markerless Skin Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paccini%2C+M">Martina Paccini</a>, 
<a href="/search/cs?searchtype=author&query=Paschina%2C+G">Giacomo Paschina</a>, 
<a href="/search/cs?searchtype=author&query=De+Beni%2C+S">Stefano De Beni</a>, 
<a href="/search/cs?searchtype=author&query=Stefanov%2C+A">Andrei Stefanov</a>, 
<a href="/search/cs?searchtype=author&query=Kolev%2C+V">Velizar Kolev</a>, 
<a href="/search/cs?searchtype=author&query=Patan%C3%A8%2C+G">Giuseppe Patan&#xe8;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15337" title="Abstract">arXiv:2307.15337</a> (replaced) [<a href="/pdf/2307.15337" title="Download PDF">pdf</a>, <a href="/format/2307.15337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuefei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In ICLR'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16446" title="Abstract">arXiv:2307.16446</a> (replaced) [<a href="/pdf/2307.16446" title="Download PDF">pdf</a>, <a href="/format/2307.16446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Transfer between Two Antenna Arrays in the Near Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+K+K">Krishan Kumar Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16640" title="Abstract">arXiv:2307.16640</a> (replaced) [<a href="/pdf/2307.16640" title="Download PDF">pdf</a>, <a href="/format/2307.16640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multilevel Monte Carlo algorithm for SDEs driven by countably  dimensional Wiener process and Poisson random measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sobieraj%2C+M">Micha&#x142; Sobieraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures, 2 code listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03812" title="Abstract">arXiv:2308.03812</a> (replaced) [<a href="/pdf/2308.03812" title="Download PDF">pdf</a>, <a href="/format/2308.03812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noncompact uniform universal approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Nuland%2C+T+D+H">Teun D. H. van Nuland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA); Operator Algebras (math.OA)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05576" title="Abstract">arXiv:2308.05576</a> (replaced) [<a href="/pdf/2308.05576" title="Download PDF">pdf</a>, <a href="/format/2308.05576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Language Models&#x27; Words Refer?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandelkern%2C+M">Matthew Mandelkern</a>, 
<a href="/search/cs?searchtype=author&query=Linzen%2C+T">Tal Linzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07231" title="Abstract">arXiv:2308.07231</a> (replaced) [<a href="/pdf/2308.07231" title="Download PDF">pdf</a>, <a href="/format/2308.07231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale environment mapping and immersive human-robot interaction  for agricultural mobile robot teleoperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+B">Baohua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+Q">Qianqiu Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07233" title="Abstract">arXiv:2308.07233</a> (replaced) [<a href="/pdf/2308.07233" title="Download PDF">pdf</a>, <a href="/format/2308.07233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unifying Generator Loss Function for Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veiner%2C+J">Justin Veiner</a>, 
<a href="/search/cs?searchtype=author&query=Alajaji%2C+F">Fady Alajaji</a>, 
<a href="/search/cs?searchtype=author&query=Gharesifard%2C+B">Bahman Gharesifard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09071" title="Abstract">arXiv:2308.09071</a> (replaced) [<a href="/pdf/2308.09071" title="Download PDF">pdf</a>, <a href="/ps/2308.09071" title="Download PostScript">ps</a>, <a href="/format/2308.09071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pattern recognition using spiking antiferromagnetic neurons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bradley%2C+H">Hannah Bradley</a> (1), 
<a href="/search/cs?searchtype=author&query=Louis%2C+S">Steven Louis</a> (2), 
<a href="/search/cs?searchtype=author&query=Slavin%2C+A">Andrei Slavin</a> (1), 
<a href="/search/cs?searchtype=author&query=Tyberkevych%2C+V">Vasyl Tyberkevych</a> (1) ((1) Department of Physics, Oakland University, (2) Department of Electrical Engineering, Oakland University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09729" title="Abstract">arXiv:2308.09729</a> (replaced) [<a href="/pdf/2308.09729" title="Download PDF">pdf</a>, <a href="/format/2308.09729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yilin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10316" title="Abstract">arXiv:2308.10316</a> (replaced) [<a href="/pdf/2308.10316" title="Download PDF">pdf</a>, <a href="/ps/2308.10316" title="Download PostScript">ps</a>, <a href="/format/2308.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Tight Bounds for Differentially Private Densest Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinitz%2C+M">Michael Dinitz</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+S">Satyen Kale</a>, 
<a href="/search/cs?searchtype=author&query=Lattanzi%2C+S">Silvio Lattanzi</a>, 
<a href="/search/cs?searchtype=author&query=Vassilvitskii%2C+S">Sergei Vassilvitskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved bounds over original version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11863" title="Abstract">arXiv:2308.11863</a> (replaced) [<a href="/pdf/2308.11863" title="Download PDF">pdf</a>, <a href="/format/2308.11863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KinSPEAK: Improving speech recognition for Kinyarwanda via  semi-supervised learning methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nzeyimana%2C+A">Antoine Nzeyimana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13888" title="Abstract">arXiv:2308.13888</a> (replaced) [<a href="/pdf/2308.13888" title="Download PDF">pdf</a>, <a href="/format/2308.13888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Implicit Morphing of Face Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schardong%2C+G">Guilherme Schardong</a>, 
<a href="/search/cs?searchtype=author&query=Novello%2C+T">Tiago Novello</a>, 
<a href="/search/cs?searchtype=author&query=Paz%2C+H">Hallison Paz</a>, 
<a href="/search/cs?searchtype=author&query=Medvedev%2C+I">Iurii Medvedev</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+V">Vin&#xed;cius da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Velho%2C+L">Luiz Velho</a>, 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+N">Nuno Gon&#xe7;alves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14490" title="Abstract">arXiv:2308.14490</a> (replaced) [<a href="/pdf/2308.14490" title="Download PDF">pdf</a>, <a href="/format/2308.14490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient least squares approximation and collocation methods using  radial basis functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+Y">Yiqing Zhou</a>, 
<a href="/search/math?searchtype=author&query=Huybrechs%2C+D">Daan Huybrechs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15109" title="Abstract">arXiv:2308.15109</a> (replaced) [<a href="/pdf/2308.15109" title="Download PDF">pdf</a>, <a href="/format/2308.15109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionVMR: Diffusion Model for Joint Video Moment Retrieval and  Highlight Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Henghao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K+Q">Kevin Qinghong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zechao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00125" title="Abstract">arXiv:2309.00125</a> (replaced) [<a href="/pdf/2309.00125" title="Download PDF">pdf</a>, <a href="/format/2309.00125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pure Differential Privacy for Functional Summaries via a Laplace-like  Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lin%2C+H">Haotian Lin</a>, 
<a href="/search/stat?searchtype=author&query=Reimherr%2C+M">Matthew Reimherr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00255" title="Abstract">arXiv:2309.00255</a> (replaced) [<a href="/pdf/2309.00255" title="Download PDF">pdf</a>, <a href="/format/2309.00255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SortedNet, a Place for Every Network and Every Network in its Place:  Towards a Generalized Solution for Training Many-in-One Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valipour%2C+M">Mojtaba Valipour</a>, 
<a href="/search/cs?searchtype=author&query=Rezagholizadeh%2C+M">Mehdi Rezagholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Rajabzadeh%2C+H">Hossein Rajabzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Kavehzadeh%2C+P">Parsa Kavehzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Tahaei%2C+M">Marzieh Tahaei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+A">Ali Ghodsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00517" title="Abstract">arXiv:2309.00517</a> (replaced) [<a href="/pdf/2309.00517" title="Download PDF">pdf</a>, <a href="/format/2309.00517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative, Small-Signal L2 Stability Analysis of Nonlinear Constrained  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lavaei%2C+R">Reza Lavaei</a>, 
<a href="/search/eess?searchtype=author&query=Bridgeman%2C+L+J">Leila J. Bridgeman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01829" title="Abstract">arXiv:2309.01829</a> (replaced) [<a href="/pdf/2309.01829" title="Download PDF">pdf</a>, <a href="/format/2309.01829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Post-Training Approach for Mitigating Overfitting in Quantum  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shinde%2C+A+R">Aakash Ravindra Shinde</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jain%2C+C">Charu Jain</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kalev%2C+A">Amir Kalev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 14 images, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02561" title="Abstract">arXiv:2309.02561</a> (replaced) [<a href="/pdf/2309.02561" title="Download PDF">pdf</a>, <a href="/format/2309.02561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physically Grounded Vision-Language Models for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jensen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+B">Bidipta Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03078" title="Abstract">arXiv:2309.03078</a> (replaced) [<a href="/pdf/2309.03078" title="Download PDF">pdf</a>, <a href="/format/2309.03078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Political Context of the European Vaccine Debate on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paoletti%2C+G">Giordano Paoletti</a>, 
<a href="/search/cs?searchtype=author&query=Dall%27Amico%2C+L">Lorenzo Dall&#x27;Amico</a>, 
<a href="/search/cs?searchtype=author&query=Kalimeri%2C+K">Kyriaki Kalimeri</a>, 
<a href="/search/cs?searchtype=author&query=Lenti%2C+J">Jacopo Lenti</a>, 
<a href="/search/cs?searchtype=author&query=Mejova%2C+Y">Yelena Mejova</a>, 
<a href="/search/cs?searchtype=author&query=Paolotti%2C+D">Daniela Paolotti</a>, 
<a href="/search/cs?searchtype=author&query=Starnini%2C+M">Michele Starnini</a>, 
<a href="/search/cs?searchtype=author&query=Tizzani%2C+M">Michele Tizzani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published version in Sci Rep
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Rep 14, 4397 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03720" title="Abstract">arXiv:2309.03720</a> (replaced) [<a href="/pdf/2309.03720" title="Download PDF">pdf</a>, <a href="/format/2309.03720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Natural Gas Consumption Forecasting System for Continual Learning  Scenarios based on Hoeffding Trees with Change Point Detection Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+R">Radek Svoboda</a>, 
<a href="/search/cs?searchtype=author&query=Basterrech%2C+S">Sebastian Basterrech</a>, 
<a href="/search/cs?searchtype=author&query=Kozal%2C+J">J&#x119;drzej Kozal</a>, 
<a href="/search/cs?searchtype=author&query=Plato%C5%A1%2C+J">Jan Plato&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Wo%C5%BAniak%2C+M">Micha&#x142; Wo&#x17a;niak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03750" title="Abstract">arXiv:2309.03750</a> (replaced) [<a href="/pdf/2309.03750" title="Download PDF">pdf</a>, <a href="/format/2309.03750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PBP: Path-based Trajectory Prediction for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afshar%2C+S">Sepideh Afshar</a>, 
<a href="/search/cs?searchtype=author&query=Deo%2C+N">Nachiket Deo</a>, 
<a href="/search/cs?searchtype=author&query=Bhagat%2C+A">Akshay Bhagat</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Titas Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yunming Shao</a>, 
<a href="/search/cs?searchtype=author&query=Buddharaju%2C+B+R">Balarama Raju Buddharaju</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Adwait Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Henggang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICRA 2024; Sepideh Afshar and Nachiket Deo contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03891" title="Abstract">arXiv:2309.03891</a> (replaced) [<a href="/pdf/2309.03891" title="Download PDF">pdf</a>, <a href="/format/2309.03891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArtiGrasp: Physically Plausible Synthesis of Bi-Manual Dexterous  Grasping and Articulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Christen%2C+S">Sammy Christen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zicong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Luocheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hwangbo%2C+J">Jemin Hwangbo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3DV-2024 camera ready. Project page: <a href="https://eth-ait.github.io/artigrasp/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04550" title="Abstract">arXiv:2309.04550</a> (replaced) [<a href="/pdf/2309.04550" title="Download PDF">pdf</a>, <a href="/format/2309.04550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+H">Hiba Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=McInerney%2C+D+J">Denis Jered McInerney</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Potter%2C+C">Christopher Potter</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+G">Geoffrey Young</a>, 
<a href="/search/cs?searchtype=author&query=Amir%2C+S">Silvio Amir</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04739" title="Abstract">arXiv:2309.04739</a> (replaced) [<a href="/pdf/2309.04739" title="Download PDF">pdf</a>, <a href="/ps/2309.04739" title="Download PostScript">ps</a>, <a href="/format/2309.04739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Conversational AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soudani%2C+H">Heydar Soudani</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+E">Evangelos Kanoulas</a>, 
<a href="/search/cs?searchtype=author&query=Hasibi%2C+F">Faegheh Hasibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04823" title="Abstract">arXiv:2309.04823</a> (replaced) [<a href="/pdf/2309.04823" title="Download PDF">pdf</a>, <a href="/format/2309.04823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaNS: a Facet-based Narrative Similarity Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+M">Mousumi Akter</a>, 
<a href="/search/cs?searchtype=author&query=Santu%2C+S+K+K">Shubhra Kanti Karmaker Santu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05019" title="Abstract">arXiv:2309.05019</a> (replaced) [<a href="/pdf/2309.05019" title="Download PDF">pdf</a>, <a href="/format/2309.05019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Shuchen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+M">Mingyang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weijian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiacheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05334" title="Abstract">arXiv:2309.05334</a> (replaced) [<a href="/pdf/2309.05334" title="Download PDF">pdf</a>, <a href="/format/2309.05334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultIOD: Rehearsal-free Multihead Incremental Object Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belouadah%2C+E">Eden Belouadah</a>, 
<a href="/search/cs?searchtype=author&query=Dapogny%2C+A">Arnaud Dapogny</a>, 
<a href="/search/cs?searchtype=author&query=Bailly%2C+K">Kevin Bailly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at the Workshop on Continual Learning in Computer Vision (CVPR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06427" title="Abstract">arXiv:2309.06427</a> (replaced) [<a href="/pdf/2309.06427" title="Download PDF">pdf</a>, <a href="/format/2309.06427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetric Stair Preconditioning of Linear Systems for Parallel  Trajectory Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bu%2C+X">Xueyi Bu</a>, 
<a href="/search/math?searchtype=author&query=Plancher%2C+B">Brian Plancher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024, 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06634" title="Abstract">arXiv:2309.06634</a> (replaced) [<a href="/pdf/2309.06634" title="Download PDF">pdf</a>, <a href="/format/2309.06634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $G$-Mapper: Learning a Cover in the Mapper Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+E">Enrique Alvarado</a>, 
<a href="/search/cs?searchtype=author&query=Belton%2C+R">Robin Belton</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+E">Emily Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-Ju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Palande%2C+S">Sourabh Palande</a>, 
<a href="/search/cs?searchtype=author&query=Percival%2C+S">Sarah Percival</a>, 
<a href="/search/cs?searchtype=author&query=Purvine%2C+E">Emilie Purvine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06635" title="Abstract">arXiv:2309.06635</a> (replaced) [<a href="/pdf/2309.06635" title="Download PDF">pdf</a>, <a href="/format/2309.06635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Dynamic 3D Scene Graphs for Automated Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greve%2C+E">Elias Greve</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchner%2C+M">Martin B&#xfc;chner</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6disch%2C+N">Niclas V&#xf6;disch</a>, 
<a href="/search/cs?searchtype=author&query=Burgard%2C+W">Wolfram Burgard</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for "IEEE International Conference on Robotics and Automation (ICRA) 2024"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06747" title="Abstract">arXiv:2309.06747</a> (replaced) [<a href="/pdf/2309.06747" title="Download PDF">pdf</a>, <a href="/ps/2309.06747" title="Download PostScript">ps</a>, <a href="/format/2309.06747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tengyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiangtao Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 2 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07514" title="Abstract">arXiv:2309.07514</a> (replaced) [<a href="/pdf/2309.07514" title="Download PDF">pdf</a>, <a href="/ps/2309.07514" title="Download PostScript">ps</a>, <a href="/format/2309.07514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $k$-Contraction in a Generalized Lurie System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ofir%2C+R">Ron Ofir</a>, 
<a href="/search/eess?searchtype=author&query=Slotine%2C+J">Jean-Jacques Slotine</a>, 
<a href="/search/eess?searchtype=author&query=Margaliot%2C+M">Michael Margaliot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07932" title="Abstract">arXiv:2309.07932</a> (replaced) [<a href="/pdf/2309.07932" title="Download PDF">pdf</a>, <a href="/ps/2309.07932" title="Download PostScript">ps</a>, <a href="/format/2309.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flat origami is Turing Complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hull%2C+T+C">Thomas C. Hull</a>, 
<a href="/search/math?searchtype=author&query=Zakharevich%2C+I">Inna Zakharevich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08079" title="Abstract">arXiv:2309.08079</a> (replaced) [<a href="/pdf/2309.08079" title="Download PDF">pdf</a>, <a href="/format/2309.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPCGPU: Real-Time Nonlinear Model Predictive Control through  Preconditioned Conjugate Gradient on the GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adabag%2C+E">Emre Adabag</a>, 
<a href="/search/cs?searchtype=author&query=Atal%2C+M">Miloni Atal</a>, 
<a href="/search/cs?searchtype=author&query=Gerard%2C+W">William Gerard</a>, 
<a href="/search/cs?searchtype=author&query=Plancher%2C+B">Brian Plancher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024, 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08095" title="Abstract">arXiv:2309.08095</a> (replaced) [<a href="/pdf/2309.08095" title="Download PDF">pdf</a>, <a href="/format/2309.08095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RELAX: Reinforcement Learning Enabled 2D-LiDAR Autonomous System for  Parsimonious UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuokai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yutao He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08133" title="Abstract">arXiv:2309.08133</a> (replaced) [<a href="/pdf/2309.08133" title="Download PDF">pdf</a>, <a href="/ps/2309.08133" title="Download PostScript">ps</a>, <a href="/format/2309.08133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talkin&#x27; &#x27;Bout AI Generation: Copyright and the Generative-AI Supply  Chain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Grimmelmann%2C+J">James Grimmelmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Forthcoming, Journal of the Copyright Society of the USA '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08214" title="Abstract">arXiv:2309.08214</a> (replaced) [<a href="/pdf/2309.08214" title="Download PDF">pdf</a>, <a href="/format/2309.08214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTG: Mapless Trajectory Generator with Traversability Coverage for  Outdoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M+C">Ming C. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08399" title="Abstract">arXiv:2309.08399</a> (replaced) [<a href="/pdf/2309.08399" title="Download PDF">pdf</a>, <a href="/format/2309.08399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Modular Robot Composition: A Lexicographic Genetic Algorithm  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BClz%2C+J">Jonathan K&#xfc;lz</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09256" title="Abstract">arXiv:2309.09256</a> (replaced) [<a href="/pdf/2309.09256" title="Download PDF">pdf</a>, <a href="/format/2309.09256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR Data Synthesis with Denoising Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+K">Kazuto Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Kurazume%2C+R">Ryo Kurazume</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09502" title="Abstract">arXiv:2309.09502</a> (replaced) [<a href="/pdf/2309.09502" title="Download PDF">pdf</a>, <a href="/format/2309.09502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RenderOcc: Vision-Centric 3D Occupancy Prediction with 2D Rendering  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Mingjie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peixiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hongwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09682" title="Abstract">arXiv:2309.09682</a> (replaced) [<a href="/pdf/2309.09682" title="Download PDF">pdf</a>, <a href="/format/2309.09682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Stage Learning of Highly Dynamic Motions with Rigid and Articulated  Soft Quadrupeds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vezzi%2C+F">Francecso Vezzi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiatao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, Accepated by ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10108" title="Abstract">arXiv:2309.10108</a> (replaced) [<a href="/pdf/2309.10108" title="Download PDF">pdf</a>, <a href="/format/2309.10108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Do Data Analysts Respond to AI Assistance? A Wizard-of-Oz Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+K">Ken Gu</a>, 
<a href="/search/cs?searchtype=author&query=Grunde-McLaughlin%2C+M">Madeleine Grunde-McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=McNutt%2C+A+M">Andrew M. McNutt</a>, 
<a href="/search/cs?searchtype=author&query=Heer%2C+J">Jeffrey Heer</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+T">Tim Althoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10216" title="Abstract">arXiv:2309.10216</a> (replaced) [<a href="/pdf/2309.10216" title="Download PDF">pdf</a>, <a href="/format/2309.10216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe POMDP Online Planning via Shielding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+S">Shili Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Parker%2C+D">David Parker</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lu Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10314" title="Abstract">arXiv:2309.10314</a> (replaced) [<a href="/pdf/2309.10314" title="Download PDF">pdf</a>, <a href="/format/2309.10314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dive Deeper into Rectifying Homography for Stereo Camera Online  Self-Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10947" title="Abstract">arXiv:2309.10947</a> (replaced) [<a href="/pdf/2309.10947" title="Download PDF">pdf</a>, <a href="/format/2309.10947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Do Analysts Understand and Verify AI-Assisted Data Analyses?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+K">Ken Gu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+R">Ruoxi Shang</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+T">Tim Althoff</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Drucker%2C+S+M">Steven M. Drucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11852" title="Abstract">arXiv:2309.11852</a> (replaced) [<a href="/pdf/2309.11852" title="Download PDF">pdf</a>, <a href="/format/2309.11852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Sanitization of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishibashi%2C+Y">Yoichi Ishibashi</a>, 
<a href="/search/cs?searchtype=author&query=Shimodaira%2C+H">Hidetoshi Shimodaira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12005" title="Abstract">arXiv:2309.12005</a> (replaced) [<a href="/pdf/2309.12005" title="Download PDF">pdf</a>, <a href="/format/2309.12005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPS-VIO Fusion with Online Rotational Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Junlin Song</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez-Cuevas%2C+P+J">Pedro J. Sanchez-Cuevas</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+A">Antoine Richard</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+R+T">Raj Thilak Rajan</a>, 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M">Miguel Olivares-Mendez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13150" title="Abstract">arXiv:2309.13150</a> (replaced) [<a href="/pdf/2309.13150" title="Download PDF">pdf</a>, <a href="/format/2309.13150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel-wise Smoothing for Certified Robustness against Camera Motion  Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanjiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiacheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version of AISTATS 2024, 30 pages, 5 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13515" title="Abstract">arXiv:2309.13515</a> (replaced) [<a href="/pdf/2309.13515" title="Download PDF">pdf</a>, <a href="/format/2309.13515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-based Inverse Perception Contracts and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dawei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B+C">Benjamin C. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Sayan Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13957" title="Abstract">arXiv:2309.13957</a> (replaced) [<a href="/pdf/2309.13957" title="Download PDF">pdf</a>, <a href="/format/2309.13957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beam Enumeration: Probabilistic Explainability For Sample Efficient  Self-conditioned Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Guo%2C+J">Jeff Guo</a>, 
<a href="/search/q-bio?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14504" title="Abstract">arXiv:2309.14504</a> (replaced) [<a href="/pdf/2309.14504" title="Download PDF">pdf</a>, <a href="/format/2309.14504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> People&#x27;s Perceptions Toward Bias and Related Concepts in Large Language  Models: A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Max Song</a>, 
<a href="/search/cs?searchtype=author&query=Rezapour%2C+R">Rezvaneh Rezapour</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+B+C">Bum Chul Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Huh-Yoo%2C+J">Jina Huh-Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15135" title="Abstract">arXiv:2309.15135</a> (replaced) [<a href="/pdf/2309.15135" title="Download PDF">pdf</a>, <a href="/format/2309.15135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Continual Multi-view Clustering with Filtered Structural  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xinhang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhibin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15459" title="Abstract">arXiv:2309.15459</a> (replaced) [<a href="/pdf/2309.15459" title="Download PDF">pdf</a>, <a href="/format/2309.15459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAMMA: Graspability-Aware Mobile MAnipulation Policy Learning based on  Online Grasping Pose Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiazhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gireesh%2C+N">Nandiraju Gireesh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiaomeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chaoyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Liu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15790" title="Abstract">arXiv:2309.15790</a> (replaced) [<a href="/pdf/2309.15790" title="Download PDF">pdf</a>, <a href="/format/2309.15790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private, Efficient, and Optimal K-Norm and Elliptic Gaussian Noise For  Sum, Count, and Vote
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joseph%2C+M">Matthew Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Alexander Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version adds count and elliptic Gaussian material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16098" title="Abstract">arXiv:2309.16098</a> (replaced) [<a href="/pdf/2309.16098" title="Download PDF">pdf</a>, <a href="/format/2309.16098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg Game-Theoretic Trajectory Guidance for Multi-Robot Systems  with Koopman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16739" title="Abstract">arXiv:2309.16739</a> (replaced) [<a href="/pdf/2309.16739" title="Download PDF">pdf</a>, <a href="/format/2309.16739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Large Language Models to the 6G Edge: Vision, Challenges, and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Guanqiao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaibin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17187" title="Abstract">arXiv:2309.17187</a> (replaced) [<a href="/pdf/2309.17187" title="Download PDF">pdf</a>, <a href="/format/2309.17187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TBD Pedestrian Data Collection: Towards Rich, Portable, and Large-Scale  Natural Pedestrian Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Allan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+D">Daisuke Sato</a>, 
<a href="/search/cs?searchtype=author&query=Corzo%2C+Y">Yasser Corzo</a>, 
<a href="/search/cs?searchtype=author&query=Simkin%2C+S">Sonya Simkin</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Abhijat Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Steinfeld%2C+A">Aaron Steinfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by IEEE ICRA 2024. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with <a href="/abs/2203.01974">arXiv:2203.01974</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00078" title="Abstract">arXiv:2310.00078</a> (replaced) [<a href="/pdf/2310.00078" title="Download PDF">pdf</a>, <a href="/ps/2310.00078" title="Download PostScript">ps</a>, <a href="/format/2310.00078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Semantic Ambiguity of the Materials Science Ontologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McClellan%2C+S">Scott McClellan</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yuan An</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xintong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+J">Jane Greenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, International Society for Knowledge Organization (ISKO) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00433" title="Abstract">arXiv:2310.00433</a> (replaced) [<a href="/pdf/2310.00433" title="Download PDF">pdf</a>, <a href="/format/2310.00433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active-Perceptive Motion Generation for Mobile Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jauhri%2C+S">Snehal Jauhri</a>, 
<a href="/search/cs?searchtype=author&query=Lueth%2C+S">Sophie Lueth</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024. Project page: <a href="https://sites.google.com/view/actpermoma">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01287" title="Abstract">arXiv:2310.01287</a> (replaced) [<a href="/pdf/2310.01287" title="Download PDF">pdf</a>, <a href="/format/2310.01287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenQuery: Supporting Expressive Visual Search with Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+K">Kihoon Son</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">DaEun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T+S">Tae Soo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Young-Ho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages and 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01690" title="Abstract">arXiv:2310.01690</a> (replaced) [<a href="/pdf/2310.01690" title="Download PDF">pdf</a>, <a href="/format/2310.01690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Tropical Cyclones with Cascaded Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Nath%2C+P">Pritthijit Nath</a>, 
<a href="/search/physics?searchtype=author&query=Shukla%2C+P">Pancham Shukla</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/physics?searchtype=author&query=Quilodr%C3%A1n-Casas%2C+C">C&#xe9;sar Quilodr&#xe1;n-Casas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for poster presentation at the ICLR 2024 workshop on Tackling Climate Change with Machine Learning. 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02207" title="Abstract">arXiv:2310.02207</a> (replaced) [<a href="/pdf/2310.02207" title="Download PDF">pdf</a>, <a href="/format/2310.02207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models Represent Space and Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurnee%2C+W">Wes Gurnee</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02432" title="Abstract">arXiv:2310.02432</a> (replaced) [<a href="/pdf/2310.02432" title="Download PDF">pdf</a>, <a href="/format/2310.02432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Dark Patterns: A Concept-Based Framework for Ethical Software  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caragay%2C+E">Evan Caragay</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Katherine Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+J">Jonathan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+D">Daniel Jackson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02954" title="Abstract">arXiv:2310.02954</a> (replaced) [<a href="/pdf/2310.02954" title="Download PDF">pdf</a>, <a href="/format/2310.02954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for  In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jing Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhijiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yichun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qingxing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiongwei Han</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengming Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03234" title="Abstract">arXiv:2310.03234</a> (replaced) [<a href="/pdf/2310.03234" title="Download PDF">pdf</a>, <a href="/format/2310.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+Q">Quanqi Hu</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+D">Dixian Zhu</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03637" title="Abstract">arXiv:2310.03637</a> (replaced) [<a href="/pdf/2310.03637" title="Download PDF">pdf</a>, <a href="/ps/2310.03637" title="Download PostScript">ps</a>, <a href="/format/2310.03637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Degree Bounds For Iterated Polynomial Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steiner%2C+M+J">Matthias Johann Steiner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IACR Trans. Symm. Cryptol. 2024(1) 357-411
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04418" title="Abstract">arXiv:2310.04418</a> (replaced) [<a href="/pdf/2310.04418" title="Download PDF">pdf</a>, <a href="/format/2310.04418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Interpolation for Relative Positions Improves Long Context  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanda Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chong You</a>, 
<a href="/search/cs?searchtype=author&query=Guruganesh%2C+G">Guru Guruganesh</a>, 
<a href="/search/cs?searchtype=author&query=Ainslie%2C+J">Joshua Ainslie</a>, 
<a href="/search/cs?searchtype=author&query=Ontanon%2C+S">Santiago Ontanon</a>, 
<a href="/search/cs?searchtype=author&query=Zaheer%2C+M">Manzil Zaheer</a>, 
<a href="/search/cs?searchtype=author&query=Sanghai%2C+S">Sumit Sanghai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bhojanapalli%2C+S">Srinadh Bhojanapalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages; ICLR 2024 camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05207" title="Abstract">arXiv:2310.05207</a> (replaced) [<a href="/pdf/2310.05207" title="Download PDF">pdf</a>, <a href="/format/2310.05207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Facial Action Unit Detection Through Jointly Learning Facial  Landmark Detection and Domain Separation and Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Ziqiao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Li Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05245" title="Abstract">arXiv:2310.05245</a> (replaced) [<a href="/pdf/2310.05245" title="Download PDF">pdf</a>, <a href="/format/2310.05245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence of Camera-LiDAR Configuration on 3D Object Detection for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanjiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaonan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05670" title="Abstract">arXiv:2310.05670</a> (replaced) [<a href="/pdf/2310.05670" title="Download PDF">pdf</a>, <a href="/format/2310.05670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement learning for freeform robot design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Muhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+D">David Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Kriegman%2C+S">Sam Kriegman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05696" title="Abstract">arXiv:2310.05696</a> (replaced) [<a href="/pdf/2310.05696" title="Download PDF">pdf</a>, <a href="/format/2310.05696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protecting Sensitive Data through Federated Co-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abourayya%2C+A">Amr Abourayya</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kanishka Rao</a>, 
<a href="/search/cs?searchtype=author&query=Ayday%2C+E">Erman Ayday</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+B">Bharat Rao</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G">Geoff Webb</a>, 
<a href="/search/cs?searchtype=author&query=Kamp%2C+M">Michael Kamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05808" title="Abstract">arXiv:2310.05808</a> (replaced) [<a href="/pdf/2310.05808" title="Download PDF">pdf</a>, <a href="/format/2310.05808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Open-Loop Baseline for Reinforcement Learning Locomotion Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Albu-Sch%C3%A4ffer%2C+A">Alin Albu-Sch&#xe4;ffer</a>, 
<a href="/search/cs?searchtype=author&query=Silv%C3%A9rio%2C+J">Jo&#xe3;o Silv&#xe9;rio</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+F">Freek Stulp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> video: <a href="https://b2drop.eudat.eu/s/ykDPMM7F9KFyLgi">this https URL</a> minimal code: <a href="https://gist.github.com/araffin/1fb77a8f290ac248b2e76e01164f21e0">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06185" title="Abstract">arXiv:2310.06185</a> (replaced) [<a href="/pdf/2310.06185" title="Download PDF">pdf</a>, <a href="/format/2310.06185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Bounds for the Maximum Distance Over a Polytope to a Given Point
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Costandin%2C+M">Marius Costandin</a>, 
<a href="/search/math?searchtype=author&query=Costandin%2C+B">Beniamin Costandin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.15054">arXiv:2308.15054</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06474" title="Abstract">arXiv:2310.06474</a> (replaced) [<a href="/pdf/2310.06474" title="Download PDF">pdf</a>, <a href="/format/2310.06474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Jailbreak Challenges in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S+J">Sinno Jialin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06543" title="Abstract">arXiv:2310.06543</a> (replaced) [<a href="/pdf/2310.06543" title="Download PDF">pdf</a>, <a href="/format/2310.06543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Edge-Aware Graph Autoencoder Trained on Scale-Imbalanced Data for  Traveling Salesman Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xueming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 7 figures. Accepted by Knowledge-based Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06836" title="Abstract">arXiv:2310.06836</a> (replaced) [<a href="/pdf/2310.06836" title="Download PDF">pdf</a>, <a href="/format/2310.06836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Does Stable Diffusion Know about the 3D Scene?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+G">Guanqi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanxia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07171" title="Abstract">arXiv:2310.07171</a> (replaced) [<a href="/pdf/2310.07171" title="Download PDF">pdf</a>, <a href="/format/2310.07171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advocating for the Silent: Enhancing Federated Generalization for  Non-Participating Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheshun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07855" title="Abstract">arXiv:2310.07855</a> (replaced) [<a href="/pdf/2310.07855" title="Download PDF">pdf</a>, <a href="/format/2310.07855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrIBo: Self-Supervised Learning via Cross-Image Object-Level  Bootstrapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lebailly%2C+T">Tim Lebailly</a>, 
<a href="/search/cs?searchtype=author&query=Stegm%C3%BCller%2C+T">Thomas Stegm&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Bozorgtabar%2C+B">Behzad Bozorgtabar</a>, 
<a href="/search/cs?searchtype=author&query=Thiran%2C+J">Jean-Philippe Thiran</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 (spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07898" title="Abstract">arXiv:2310.07898</a> (replaced) [<a href="/pdf/2310.07898" title="Download PDF">pdf</a>, <a href="/format/2310.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlorDB: Multiversion Hindsight Logging for Continuous Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+R">Rolando Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Dandamudi%2C+A">Anusha Dandamudi</a>, 
<a href="/search/cs?searchtype=author&query=Matute%2C+G">Gabriel Matute</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Lehan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J">Joseph Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Hellerstein%2C+J+M">Joseph M. Hellerstein</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+K">Koushik Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1071">[1071]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07902" title="Abstract">arXiv:2310.07902</a> (replaced) [<a href="/pdf/2310.07902" title="Download PDF">pdf</a>, <a href="/format/2310.07902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Single Tangent Space Fallacy: An Analysis and  Clarification for Applying Riemannian Geometry in Robot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaquier%2C+N">No&#xe9;mie Jaquier</a>, 
<a href="/search/cs?searchtype=author&query=Rozo%2C+L">Leonel Rozo</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in ICRA'24. 8 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1072">[1072]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08031" title="Abstract">arXiv:2310.08031</a> (replaced) [<a href="/pdf/2310.08031" title="Download PDF">pdf</a>, <a href="/format/2310.08031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Graph Clustering with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Luca%2C+A+B">Artur Back de Luca</a>, 
<a href="/search/cs?searchtype=author&query=Fountoulakis%2C+K">Kimon Fountoulakis</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shenghao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures, 18 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1073">[1073]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08224" title="Abstract">arXiv:2310.08224</a> (replaced) [<a href="/pdf/2310.08224" title="Download PDF">pdf</a>, <a href="/format/2310.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Latent Binary Encoding in Deep Neural Network Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sbail%C3%B2%2C+L">Luigi Sbail&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Ghiringhelli%2C+L">Luca Ghiringhelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1074">[1074]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08929" title="Abstract">arXiv:2310.08929</a> (replaced) [<a href="/pdf/2310.08929" title="Download PDF">pdf</a>, <a href="/format/2310.08929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Image Augmentation for Object Manipulation: Towards  Interpretable Controllability in Object-Centric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Janghyuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaehyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Ho-Jin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Seon Joo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1075">[1075]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09463" title="Abstract">arXiv:2310.09463</a> (replaced) [<a href="/pdf/2310.09463" title="Download PDF">pdf</a>, <a href="/format/2310.09463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIO-SDF: Hierarchical Incremental Online Signed Distance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasilopoulos%2C+V">Vasileios Vasilopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Suveer Garg</a>, 
<a href="/search/cs?searchtype=author&query=Huh%2C+J">Jinwook Huh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bhoram Lee</a>, 
<a href="/search/cs?searchtype=author&query=Isler%2C+V">Volkan Isler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Robotics and Automation (ICRA 2024) - 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1076">[1076]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09680" title="Abstract">arXiv:2310.09680</a> (replaced) [<a href="/pdf/2310.09680" title="Download PDF">pdf</a>, <a href="/format/2310.09680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Contextual Recognition In Automatic Speech Recognition Systems  By Semantic Lattice Rescoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudarshan%2C+A">Ankitha Sudarshan</a>, 
<a href="/search/cs?searchtype=author&query=Samuel%2C+V">Vinay Samuel</a>, 
<a href="/search/cs?searchtype=author&query=Patwa%2C+P">Parth Patwa</a>, 
<a href="/search/cs?searchtype=author&query=Amara%2C+I">Ibtihel Amara</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1077">[1077]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09893" title="Abstract">arXiv:2310.09893</a> (replaced) [<a href="/pdf/2310.09893" title="Download PDF">pdf</a>, <a href="/format/2310.09893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Contact-Implicit Model Predictive Control with Online Residual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei-Cheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Aydinoglu%2C+A">Alp Aydinoglu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wanxin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Posa%2C+M">Michael Posa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Wei-Cheng Huang and Alp Aydinoglu contributed equally to this work. ICRA 2024 Final Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1078">[1078]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10012" title="Abstract">arXiv:2310.10012</a> (replaced) [<a href="/pdf/2310.10012" title="Download PDF">pdf</a>, <a href="/format/2310.10012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ring-A-Bell! How Reliable are Concept Removal Methods for Diffusion  Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yu-Lin Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chia-Yi Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chih-Hsun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jia-You Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chia-Mu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chun-Ying Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has already been accepted by ICLR 2024. This version is the camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1079">[1079]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10023" title="Abstract">arXiv:2310.10023</a> (replaced) [<a href="/pdf/2310.10023" title="Download PDF">pdf</a>, <a href="/format/2310.10023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-BBS: Global Localization for 3D Point Cloud Scan Matching Using  Branch-and-Bound Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aoki%2C+K">Koki Aoki</a>, 
<a href="/search/cs?searchtype=author&query=Koide%2C+K">Kenji Koide</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+S">Shuji Oishi</a>, 
<a href="/search/cs?searchtype=author&query=Yokozuka%2C+M">Masashi Yokozuka</a>, 
<a href="/search/cs?searchtype=author&query=Banno%2C+A">Atsuhiko Banno</a>, 
<a href="/search/cs?searchtype=author&query=Meguro%2C+J">Junichi Meguro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1080">[1080]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10207" title="Abstract">arXiv:2310.10207</a> (replaced) [<a href="/pdf/2310.10207" title="Download PDF">pdf</a>, <a href="/format/2310.10207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bongard-OpenWorld: Few-Shot Reasoning for Free-form Visual Concepts in  the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rujie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1081">[1081]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11053" title="Abstract">arXiv:2310.11053</a> (replaced) [<a href="/pdf/2310.11053" title="Download PDF">pdf</a>, <a href="/format/2310.11053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denevil: Towards Deciphering and Navigating the Ethical Values of Large  Language Models via Instruction Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shitong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1082">[1082]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11142" title="Abstract">arXiv:2310.11142</a> (replaced) [<a href="/pdf/2310.11142" title="Download PDF">pdf</a>, <a href="/format/2310.11142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BayesDiff: Estimating Pixel-wise Uncertainty in Diffusion via Bayesian  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kou%2C+S">Siqi Kou</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+L">Lei Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1083">[1083]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11534" title="Abstract">arXiv:2310.11534</a> (replaced) [<a href="/pdf/2310.11534" title="Download PDF">pdf</a>, <a href="/format/2310.11534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HMN: Generalization of Heterogeneous and Multi-layered Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S+K">Shraban Kumar Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Suman Kundu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1084">[1084]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11684" title="Abstract">arXiv:2310.11684</a> (replaced) [<a href="/pdf/2310.11684" title="Download PDF">pdf</a>, <a href="/format/2310.11684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Speedups in Regret Analysis of Infinite Horizon Average-Reward  Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+B">Bhargav Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item1085">[1085]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11837" title="Abstract">arXiv:2310.11837</a> (replaced) [<a href="/pdf/2310.11837" title="Download PDF">pdf</a>, <a href="/format/2310.11837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising Distributions with Natural Gradient Surrogates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=So%2C+J">Jonathan So</a>, 
<a href="/search/stat?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1086">[1086]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11984" title="Abstract">arXiv:2310.11984</a> (replaced) [<a href="/pdf/2310.11984" title="Download PDF">pdf</a>, <a href="/format/2310.11984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Interpolation to Extrapolation: Complete Length Generalization for  Arithmetic Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shaoxiong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yining Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1087">[1087]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12574" title="Abstract">arXiv:2310.12574</a> (replaced) [<a href="/pdf/2310.12574" title="Download PDF">pdf</a>, <a href="/ps/2310.12574" title="Download PostScript">ps</a>, <a href="/format/2310.12574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A reproducible 3D convolutional neural network with dual attention  module (3D-DAM) for Alzheimer&#x27;s disease classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vu%2C+T+P">Thanh Phuong Vu</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T+N">Tien Nhat Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+N+M+N">N. Minh Nhat Hoang</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+G+M">Gia Minh Hoang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1088">[1088]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12828" title="Abstract">arXiv:2310.12828</a> (replaced) [<a href="/pdf/2310.12828" title="Download PDF">pdf</a>, <a href="/format/2310.12828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Informed Trees (FIT*): Adaptive Batch-Size Approach in Informed  Sampling-Based Path Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liding Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kuanqi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Krumbholz%2C+P">Peter Krumbholz</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhilin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1089">[1089]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13104" title="Abstract">arXiv:2310.13104</a> (replaced) [<a href="/pdf/2310.13104" title="Download PDF">pdf</a>, <a href="/format/2310.13104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Differential Privacy Easier to Use for Data Controllers and Data  Analysts using a Privacy Risk Indicator and an Escrow-Based Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+R+C">Raul Castro Fernandez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1090">[1090]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13266" title="Abstract">arXiv:2310.13266</a> (replaced) [<a href="/pdf/2310.13266" title="Download PDF">pdf</a>, <a href="/ps/2310.13266" title="Download PostScript">ps</a>, <a href="/format/2310.13266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measurement-Based Small-Scale Channel Model for Sub-6 GHz RIS-Assisted  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jian Sang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jifeng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Boning Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1091">[1091]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13822" title="Abstract">arXiv:2310.13822</a> (replaced) [<a href="/pdf/2310.13822" title="Download PDF">pdf</a>, <a href="/format/2310.13822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks on Fairness of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binchi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yushun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yada Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1092">[1092]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15516" title="Abstract">arXiv:2310.15516</a> (replaced) [<a href="/pdf/2310.15516" title="Download PDF">pdf</a>, <a href="/format/2310.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Attention-based Deep Reinforcement Learning for solving the  Chinese Postman Problem with Load-dependent costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hy%2C+T+S">Truong Son Hy</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C+D">Cong Dao Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1093">[1093]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17844" title="Abstract">arXiv:2310.17844</a> (replaced) [<a href="/pdf/2310.17844" title="Download PDF">pdf</a>, <a href="/format/2310.17844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive operator learning for infinite-dimensional Bayesian inverse  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+Z">Zhiwei Gao</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+L">Liang Yan</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1094">[1094]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18681" title="Abstract">arXiv:2310.18681</a> (replaced) [<a href="/pdf/2310.18681" title="Download PDF">pdf</a>, <a href="/format/2310.18681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mesinovic%2C+M">Munib Mesinovic</a>, 
<a href="/search/cs?searchtype=author&query=Watkinson%2C+P">Peter Watkinson</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tingting Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1095">[1095]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19450" title="Abstract">arXiv:2310.19450</a> (replaced) [<a href="/pdf/2310.19450" title="Download PDF">pdf</a>, <a href="/format/2310.19450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hodge-Compositional Edge Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yang%2C+M">Maosheng Yang</a>, 
<a href="/search/stat?searchtype=author&query=Borovitskiy%2C+V">Viacheslav Borovitskiy</a>, 
<a href="/search/stat?searchtype=author&query=Isufi%2C+E">Elvin Isufi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1096">[1096]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19527" title="Abstract">arXiv:2310.19527</a> (replaced) [<a href="/pdf/2310.19527" title="Download PDF">pdf</a>, <a href="/format/2310.19527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Theory of Risk-Aware Agents: Bridging Actor-Critic and Economics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nauman%2C+M">Michal Nauman</a>, 
<a href="/search/cs?searchtype=author&query=Cygan%2C+M">Marek Cygan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1097">[1097]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00123" title="Abstract">arXiv:2311.00123</a> (replaced) [<a href="/pdf/2311.00123" title="Download PDF">pdf</a>, <a href="/format/2311.00123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Learning for Stochastic Control under General Information Structures  and Non-Markovian Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kara%2C+A+D">Ali Devran Kara</a>, 
<a href="/search/math?searchtype=author&query=Yuksel%2C+S">Serdar Yuksel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1098">[1098]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00187" title="Abstract">arXiv:2311.00187</a> (replaced) [<a href="/pdf/2311.00187" title="Download PDF">pdf</a>, <a href="/format/2311.00187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decodable and Sample Invariant Continuous Object Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Dehao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ferm%C3%BCller%2C+C">Cornelia Ferm&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Aloimonos%2C+Y">Yiannis Aloimonos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1099">[1099]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00453" title="Abstract">arXiv:2311.00453</a> (replaced) [<a href="/pdf/2311.00453" title="Download PDF">pdf</a>, <a href="/format/2311.00453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-AD: A Language-Guided Staged Dual-Path Model for Zero-shot Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+G">Guanzhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyang He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1100">[1100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00968" title="Abstract">arXiv:2311.00968</a> (replaced) [<a href="/pdf/2311.00968" title="Download PDF">pdf</a>, <a href="/format/2311.00968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video2Music: Suitable Music Generation from Videos using an Affective  Multimodal Transformer model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaeyong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>, 
<a href="/search/cs?searchtype=author&query=Herremans%2C+D">Dorien Herremans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1101">[1101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01047" title="Abstract">arXiv:2311.01047</a> (replaced) [<a href="/pdf/2311.01047" title="Download PDF">pdf</a>, <a href="/format/2311.01047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Robustness via Tilted Exponential Layer: A  Communication-Theoretic Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puranik%2C+B">Bhagyashree Puranik</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Madhow%2C+U">Upamanyu Madhow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27th International Conference on Artificial Intelligence and Statistics (AISTATS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1102">[1102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01092" title="Abstract">arXiv:2311.01092</a> (replaced) [<a href="/pdf/2311.01092" title="Download PDF">pdf</a>, <a href="/format/2311.01092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning A Multi-Task Transformer Via Unified And Customized Instruction  Tuning For Chest Radiograph Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lijian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Ziyu Ni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinglong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1103">[1103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02786" title="Abstract">arXiv:2311.02786</a> (replaced) [<a href="/pdf/2311.02786" title="Download PDF">pdf</a>, <a href="/ps/2311.02786" title="Download PostScript">ps</a>, <a href="/format/2311.02786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobility as a Resource (MaaR) for resilient human-centric automation: a  vision paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Waller%2C+S+T">S. Travis Waller</a>, 
<a href="/search/eess?searchtype=author&query=Polydoropoulou%2C+A">Amalia Polydoropoulou</a>, 
<a href="/search/eess?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>, 
<a href="/search/eess?searchtype=author&query=Ziliaskopoulos%2C+A">Athanasios Ziliaskopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Jian%2C+S">Sisi Jian</a>, 
<a href="/search/eess?searchtype=author&query=Wagenknecht%2C+S">Susann Wagenknecht</a>, 
<a href="/search/eess?searchtype=author&query=Hirte%2C+G">Georg Hirte</a>, 
<a href="/search/eess?searchtype=author&query=Ukkusuri%2C+S">Satish Ukkusuri</a>, 
<a href="/search/eess?searchtype=author&query=Ramadurai%2C+G">Gitakrishnan Ramadurai</a>, 
<a href="/search/eess?searchtype=author&query=Bednarz%2C+T">Tomasz Bednarz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1104">[1104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03758" title="Abstract">arXiv:2311.03758</a> (replaced) [<a href="/pdf/2311.03758" title="Download PDF">pdf</a>, <a href="/format/2311.03758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model based Long-tail Query Rewriting in Taobao Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wenjun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+D">Dan Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaoyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Derong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW Industry
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1105">[1105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03764" title="Abstract">arXiv:2311.03764</a> (replaced) [<a href="/pdf/2311.03764" title="Download PDF">pdf</a>, <a href="/format/2311.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-GPT: Towards A Foundation Model for EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wenhui Cui</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+W">Woojae Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Th%C3%B6lke%2C+P">Philipp Th&#xf6;lke</a>, 
<a href="/search/cs?searchtype=author&query=Medani%2C+T">Takfarinas Medani</a>, 
<a href="/search/cs?searchtype=author&query=Jerbi%2C+K">Karim Jerbi</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A+A">Anand A. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+R+M">Richard M. Leahy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted by the 2024 IEEE International Symposium on Biomedical Imaging (ISBI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1106">[1106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04194" title="Abstract">arXiv:2311.04194</a> (replaced) [<a href="/pdf/2311.04194" title="Download PDF">pdf</a>, <a href="/format/2311.04194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantization-aware Neural Architectural Search for Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+R+Y">Rabin Yu Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Jeune%2C+L+L">Laurens Le Jeune</a>, 
<a href="/search/cs?searchtype=author&query=Mentens%2C+N">Nele Mentens</a>, 
<a href="/search/cs?searchtype=author&query=Ganji%2C+F">Fatemeh Ganji</a>, 
<a href="/search/cs?searchtype=author&query=Forte%2C+D">Domenic Forte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1107">[1107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05112" title="Abstract">arXiv:2311.05112</a> (replaced) [<a href="/pdf/2311.05112" title="Download PDF">pdf</a>, <a href="/format/2311.05112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Large Language Models in Medicine: Progress, Application,  and Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongjian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fenglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Boyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xinyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinfa Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinge Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiru Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S+S">Sam S. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yining Hua</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengfeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chenyu You</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+L">Lei Clifton</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Version 4. 7 figures; 13 tables; 49 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1108">[1108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05818" title="Abstract">arXiv:2311.05818</a> (replaced) [<a href="/pdf/2311.05818" title="Download PDF">pdf</a>, <a href="/format/2311.05818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Agile Bipedal Motions on a Quadrupedal Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1109">[1109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06534" title="Abstract">arXiv:2311.06534</a> (replaced) [<a href="/pdf/2311.06534" title="Download PDF">pdf</a>, <a href="/format/2311.06534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Translating Legalese: Enhancing Public Understanding of Court Opinions  with Legal Summarizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ash%2C+E">Elliott Ash</a>, 
<a href="/search/cs?searchtype=author&query=Kesari%2C+A">Aniket Kesari</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+S">Suresh Naidu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lena Song</a>, 
<a href="/search/cs?searchtype=author&query=Stammbach%2C+D">Dominik Stammbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in proceedings of CSLAW 2024: Symposium on Computer Science and Law
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1110">[1110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07346" title="Abstract">arXiv:2311.07346</a> (replaced) [<a href="/pdf/2311.07346" title="Download PDF">pdf</a>, <a href="/format/2311.07346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-oriented Estimation of Multiple Markov Sources in  Resource-constrained Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+J">Jiping Luo</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1111">[1111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07434" title="Abstract">arXiv:2311.07434</a> (replaced) [<a href="/pdf/2311.07434" title="Download PDF">pdf</a>, <a href="/format/2311.07434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Users&#x27; Dissatisfaction with ChatGPT Responses: Types,  Resolving Tactics, and the Effect of Knowledge Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoonsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jueon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seoyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehyuk Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1112">[1112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07548" title="Abstract">arXiv:2311.07548</a> (replaced) [<a href="/pdf/2311.07548" title="Download PDF">pdf</a>, <a href="/format/2311.07548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Fine-Tuning for Graph Neural Network Surrogate Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barwey%2C+S">Shivam Barwey</a>, 
<a href="/search/cs?searchtype=author&query=Maulik%2C+R">Romit Maulik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item1113">[1113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08919" title="Abstract">arXiv:2311.08919</a> (replaced) [<a href="/pdf/2311.08919" title="Download PDF">pdf</a>, <a href="/format/2311.08919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FCS-HGNN: Flexible Multi-type Community Search in Heterogeneous  Information Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fangda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Peiying Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing Work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1114">[1114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09033" title="Abstract">arXiv:2311.09033</a> (replaced) [<a href="/pdf/2311.09033" title="Download PDF">pdf</a>, <a href="/format/2311.09033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MELA: Multilingual Evaluation of Linguistic Acceptability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yikang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weifang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Junyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hai Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1115">[1115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09563" title="Abstract">arXiv:2311.09563</a> (replaced) [<a href="/pdf/2311.09563" title="Download PDF">pdf</a>, <a href="/format/2311.09563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Transmission Expansion: An Offshore Wind Power  Integration Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khanal%2C+S">Saroj Khanal</a>, 
<a href="/search/eess?searchtype=author&query=Graf%2C+C">Christoph Graf</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+Z">Zhirui Liang</a>, 
<a href="/search/eess?searchtype=author&query=Dvorkin%2C+Y">Yury Dvorkin</a>, 
<a href="/search/eess?searchtype=author&query=%C3%9Cnel%2C+B">Bur&#xe7;in &#xdc;nel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1116">[1116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09800" title="Abstract">arXiv:2311.09800</a> (replaced) [<a href="/pdf/2311.09800" title="Download PDF">pdf</a>, <a href="/format/2311.09800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\textit{Dial BeInfo for Faithfulness}$: Improving Factuality of  Information-Seeking Dialogue via Behavioural Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razumovskaia%2C+E">Evgeniia Razumovskaia</a>, 
<a href="/search/cs?searchtype=author&query=Vuli%C4%87%2C+I">Ivan Vuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Markovi%C4%87%2C+P">Pavle Markovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cichy%2C+T">Tomasz Cichy</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+T">Tsung-Hsien Wen</a>, 
<a href="/search/cs?searchtype=author&query=Budzianowski%2C+P">Pawe&#x142; Budzianowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1117">[1117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10329" title="Abstract">arXiv:2311.10329</a> (replaced) [<a href="/pdf/2311.10329" title="Download PDF">pdf</a>, <a href="/format/2311.10329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-fidelity Person-centric Subject-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jianwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1118">[1118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12075" title="Abstract">arXiv:2311.12075</a> (replaced) [<a href="/pdf/2311.12075" title="Download PDF">pdf</a>, <a href="/format/2311.12075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingli Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aishan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ee-Chien Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper lacks some work that needs to be cited
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1119">[1119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13033" title="Abstract">arXiv:2311.13033</a> (replaced) [<a href="/pdf/2311.13033" title="Download PDF">pdf</a>, <a href="/ps/2311.13033" title="Download PostScript">ps</a>, <a href="/format/2311.13033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Computation of Invariance Proximity: Closed-Form Error Bounds  for Finite-Dimensional Koopman-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haseli%2C+M">Masih Haseli</a>, 
<a href="/search/math?searchtype=author&query=Cort%C3%A9s%2C+J">Jorge Cort&#xe9;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item1120">[1120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13602" title="Abstract">arXiv:2311.13602</a> (replaced) [<a href="/pdf/2311.13602" title="Download PDF">pdf</a>, <a href="/format/2311.13602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Layout Transformer for Content-Aware Layout  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horita%2C+D">Daichi Horita</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+N">Naoto Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Kikuchi%2C+K">Kotaro Kikuchi</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+K">Kota Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024, Project website: <a href="https://udonda.github.io/RALF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1121">[1121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15767" title="Abstract">arXiv:2311.15767</a> (replaced) [<a href="/pdf/2311.15767" title="Download PDF">pdf</a>, <a href="/format/2311.15767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogeneous algorithms and solvable problems on cones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krieg%2C+D">David Krieg</a>, 
<a href="/search/math?searchtype=author&query=Kritzer%2C+P">Peter Kritzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1122">[1122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15836" title="Abstract">arXiv:2311.15836</a> (replaced) [<a href="/pdf/2311.15836" title="Download PDF">pdf</a>, <a href="/format/2311.15836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syn3DWound: A Synthetic Dataset for 3D Wound Bed Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lebrat%2C+L">L&#xe9;o Lebrat</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+R+S">Rodrigo Santa Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Chierchia%2C+R">Remi Chierchia</a>, 
<a href="/search/cs?searchtype=author&query=Arzhaeva%2C+Y">Yulia Arzhaeva</a>, 
<a href="/search/cs?searchtype=author&query=Armin%2C+M+A">Mohammad Ali Armin</a>, 
<a href="/search/cs?searchtype=author&query=Goldsmith%2C+J">Joshua Goldsmith</a>, 
<a href="/search/cs?searchtype=author&query=Oorloff%2C+J">Jeremy Oorloff</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+P">Prithvi Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Chuong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>, 
<a href="/search/cs?searchtype=author&query=Barakat-Johnson%2C+M">Michelle Barakat-Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Luscombe%2C+G">Georgina Luscombe</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Salvado%2C+O">Olivier Salvado</a>, 
<a href="/search/cs?searchtype=author&query=Ahmedt-Aristizabal%2C+D">David Ahmedt-Aristizabal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the IEEE International Symposium on Biomedical Imaging (ISBI) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1123">[1123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16119" title="Abstract">arXiv:2311.16119</a> (replaced) [<a href="/pdf/2311.16119" title="Download PDF">pdf</a>, <a href="/format/2311.16119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of  LLMs through a Global Scale Prompt Hacking Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schulhoff%2C+S">Sander Schulhoff</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+J">Jeremy Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Anaum Khan</a>, 
<a href="/search/cs?searchtype=author&query=Bouchard%2C+L">Louis-Fran&#xe7;ois Bouchard</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenglei Si</a>, 
<a href="/search/cs?searchtype=author&query=Anati%2C+S">Svetlina Anati</a>, 
<a href="/search/cs?searchtype=author&query=Tagliabue%2C+V">Valen Tagliabue</a>, 
<a href="/search/cs?searchtype=author&query=Kost%2C+A+L">Anson Liu Kost</a>, 
<a href="/search/cs?searchtype=author&query=Carnahan%2C+C">Christopher Carnahan</a>, 
<a href="/search/cs?searchtype=author&query=Boyd-Graber%2C+J">Jordan Boyd-Graber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 8 figures Codebase: <a href="https://github.com/PromptLabs/hackaprompt">this https URL</a> Dataset: <a href="https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset/blob/main/README.md">this https URL</a> Playground: <a href="https://huggingface.co/spaces/hackaprompt/playground">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1124">[1124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17119" title="Abstract">arXiv:2311.17119</a> (replaced) [<a href="/pdf/2311.17119" title="Download PDF">pdf</a>, <a href="/format/2311.17119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Pose for Monocular Cameras in Neural Implicit Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1125">[1125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18274" title="Abstract">arXiv:2311.18274</a> (replaced) [<a href="/pdf/2311.18274" title="Download PDF">pdf</a>, <a href="/format/2311.18274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semiparametric Efficient Inference in Adaptive Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cook%2C+T">Thomas Cook</a>, 
<a href="/search/stat?searchtype=author&query=Mishler%2C+A">Alan Mishler</a>, 
<a href="/search/stat?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures. To appear at CLeaR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1126">[1126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18528" title="Abstract">arXiv:2311.18528</a> (replaced) [<a href="/pdf/2311.18528" title="Download PDF">pdf</a>, <a href="/format/2311.18528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bottom-up computation using trees of sublists (Functional Pearl)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Shin-Cheng Mu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Functional Programming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item1127">[1127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00038" title="Abstract">arXiv:2312.00038</a> (replaced) [<a href="/pdf/2312.00038" title="Download PDF">pdf</a>, <a href="/format/2312.00038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Posteriori Evaluation of a Physics-Constrained Neural Ordinary  Differential Equations Approach Coupled with CFD Solver for Modeling Stiff  Chemical Kinetics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+T">Tadbhagya Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Kumar%2C+A">Anuj Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Pal%2C+P">Pinaki Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item1128">[1128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00786" title="Abstract">arXiv:2312.00786</a> (replaced) [<a href="/pdf/2312.00786" title="Download PDF">pdf</a>, <a href="/format/2312.00786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Optical Tracking: Connecting the Dots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moing%2C+G+L">Guillaume Le Moing</a>, 
<a href="/search/cs?searchtype=author&query=Ponce%2C+J">Jean Ponce</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1129">[1129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00925" title="Abstract">arXiv:2312.00925</a> (replaced) [<a href="/pdf/2312.00925" title="Download PDF">pdf</a>, <a href="/ps/2312.00925" title="Download PostScript">ps</a>, <a href="/format/2312.00925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Describing Globally Distributed Software Architectures for Tax  Compliance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorner%2C+M">Michael Dorner</a>, 
<a href="/search/cs?searchtype=author&query=Treidler%2C+O">Oliver Treidler</a>, 
<a href="/search/cs?searchtype=author&query=Kunz%2C+T">Tom-Eric Kunz</a>, 
<a href="/search/cs?searchtype=author&query=Zabardast%2C+E">Ehsan Zabardast</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0mite%2C+D">Darja &#x160;mite</a>, 
<a href="/search/cs?searchtype=author&query=Capraro%2C+M">Maximilian Capraro</a>, 
<a href="/search/cs?searchtype=author&query=Wnuk%2C+K">Krzysztof Wnuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to TOSEM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1130">[1130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01050" title="Abstract">arXiv:2312.01050</a> (replaced) [<a href="/pdf/2312.01050" title="Download PDF">pdf</a>, <a href="/format/2312.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and Analysis of Stress-Related Posts in Reddit Acamedic  Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oryngozha%2C+N">Nazzere Oryngozha</a>, 
<a href="/search/cs?searchtype=author&query=Shamoi%2C+P">Pakizar Shamoi</a>, 
<a href="/search/cs?searchtype=author&query=Igali%2C+A">Ayan Igali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 12, pp. 14932-14948, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1131">[1131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01133" title="Abstract">arXiv:2312.01133</a> (replaced) [<a href="/pdf/2312.01133" title="Download PDF">pdf</a>, <a href="/format/2312.01133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $t^3$-Variational Autoencoder: Learning Heavy-tailed Data with Student&#x27;s  t and Power Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+J">Juno Kim</a>, 
<a href="/search/stat?searchtype=author&query=Kwon%2C+J">Jaehyuk Kwon</a>, 
<a href="/search/stat?searchtype=author&query=Cho%2C+M">Mincheol Cho</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+H">Hyunjong Lee</a>, 
<a href="/search/stat?searchtype=author&query=Won%2C+J">Joong-Ho Won</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024; 27 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1132">[1132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01714" title="Abstract">arXiv:2312.01714</a> (replaced) [<a href="/pdf/2312.01714" title="Download PDF">pdf</a>, <a href="/format/2312.01714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingshuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+Z">Zijun Min</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1133">[1133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02170" title="Abstract">arXiv:2312.02170</a> (replaced) [<a href="/pdf/2312.02170" title="Download PDF">pdf</a>, <a href="/format/2312.02170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 5G DMRS-based Signal for Integrated Sensing and Communication System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kaifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1134">[1134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02436" title="Abstract">arXiv:2312.02436</a> (replaced) [<a href="/pdf/2312.02436" title="Download PDF">pdf</a>, <a href="/format/2312.02436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUFFIN: Curating Multi-Faceted Instructions for Improving  Instruction-Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+R">Renze Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Janice Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanzi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Data, model, and code are available at: <a href="https://renzelou.github.io/Muffin/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1135">[1135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04265" title="Abstract">arXiv:2312.04265</a> (replaced) [<a href="/pdf/2312.04265" title="Download PDF">pdf</a>, <a href="/format/2312.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger, Fewer, &amp; Superior: Harnessing Vision Foundation Models for  Domain Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhixiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianle Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+P">Pengyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinjin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1136">[1136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04819" title="Abstract">arXiv:2312.04819</a> (replaced) [<a href="/pdf/2312.04819" title="Download PDF">pdf</a>, <a href="/format/2312.04819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Guided Contrastive Role Representations for Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zican Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zongzhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hongyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item1137">[1137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05476" title="Abstract">arXiv:2312.05476</a> (replaced) [<a href="/pdf/2312.05476" title="Download PDF">pdf</a>, <a href="/format/2312.05476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Naturalness of AI-Generated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhongpeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fengyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jui%2C+S">Shangling Jui</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1138">[1138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05490" title="Abstract">arXiv:2312.05490</a> (replaced) [<a href="/pdf/2312.05490" title="Download PDF">pdf</a>, <a href="/format/2312.05490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shapley Values-enabled Progressive Pseudo Bag Augmentation for Whole  Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Renao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiehe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yonghong He</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tian Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE TRANSACTIONS ON MEDICAL IMAGING
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1139">[1139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05588" title="Abstract">arXiv:2312.05588</a> (replaced) [<a href="/pdf/2312.05588" title="Download PDF">pdf</a>, <a href="/format/2312.05588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-assisted Vision Model Debugger: A Sample-Free Approach to  Finding and Fixing Bugs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaoquan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+J">Jitao Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1140">[1140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05772" title="Abstract">arXiv:2312.05772</a> (replaced) [<a href="/pdf/2312.05772" title="Download PDF">pdf</a>, <a href="/format/2312.05772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A^3-CodGen: A Repository-Level Code Generation Framework for Code Reuse  with Local-Aware, Global-Aware, and Third-Party-Library-Aware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Dianshu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoxue Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Huan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinying Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1141">[1141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06893" title="Abstract">arXiv:2312.06893</a> (replaced) [<a href="/pdf/2312.06893" title="Download PDF">pdf</a>, <a href="/format/2312.06893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Styx: Transactional Stateful Functions on Streaming Dataflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+K">Kyriakos Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Siachamis%2C+G">George Siachamis</a>, 
<a href="/search/cs?searchtype=author&query=Christodoulou%2C+G">George Christodoulou</a>, 
<a href="/search/cs?searchtype=author&query=Fragkoulis%2C+M">Marios Fragkoulis</a>, 
<a href="/search/cs?searchtype=author&query=Katsifodimos%2C+A">Asterios Katsifodimos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1142">[1142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07358" title="Abstract">arXiv:2312.07358</a> (replaced) [<a href="/pdf/2312.07358" title="Download PDF">pdf</a>, <a href="/format/2312.07358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Bellman Operators over Mean Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wenliang%2C+L+K">Li Kevin Wenliang</a>, 
<a href="/search/stat?searchtype=author&query=Del%C3%A9tang%2C+G">Gr&#xe9;goire Del&#xe9;tang</a>, 
<a href="/search/stat?searchtype=author&query=Aitchison%2C+M">Matthew Aitchison</a>, 
<a href="/search/stat?searchtype=author&query=Hutter%2C+M">Marcus Hutter</a>, 
<a href="/search/stat?searchtype=author&query=Ruoss%2C+A">Anian Ruoss</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>, 
<a href="/search/stat?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1143">[1143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07472" title="Abstract">arXiv:2312.07472</a> (replaced) [<a href="/pdf/2312.07472" title="Download PDF">pdf</a>, <a href="/format/2312.07472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yiran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enshen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qichang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1144">[1144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07806" title="Abstract">arXiv:2312.07806</a> (replaced) [<a href="/pdf/2312.07806" title="Download PDF">pdf</a>, <a href="/format/2312.07806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextually Affinitive Neighborhood Refinery for Deep Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chunlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1145">[1145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08519" title="Abstract">arXiv:2312.08519</a> (replaced) [<a href="/pdf/2312.08519" title="Download PDF">pdf</a>, <a href="/ps/2312.08519" title="Download PostScript">ps</a>, <a href="/format/2312.08519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconciling Shared versus Context-Specific Information in a Neural  Network Model of Latent Causes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+Q">Qihong Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Nguyen%2C+T+T">Tan T. Nguyen</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Q">Qiong Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Hasson%2C+U">Uri Hasson</a>, 
<a href="/search/q-bio?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/q-bio?searchtype=author&query=Zacks%2C+J+M">Jeffrey M. Zacks</a>, 
<a href="/search/q-bio?searchtype=author&query=Gershman%2C+S+J">Samuel J. Gershman</a>, 
<a href="/search/q-bio?searchtype=author&query=Norman%2C+K+A">Kenneth A. Norman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1146">[1146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08664" title="Abstract">arXiv:2312.08664</a> (replaced) [<a href="/pdf/2312.08664" title="Download PDF">pdf</a>, <a href="/format/2312.08664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEAL: Skeletal Prior Embedded Attention Learning for Cross-Source Point  Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Kezheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Maoji Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingshan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chenglu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Siqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1147">[1147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08799" title="Abstract">arXiv:2312.08799</a> (replaced) [<a href="/pdf/2312.08799" title="Download PDF">pdf</a>, <a href="/ps/2312.08799" title="Download PostScript">ps</a>, <a href="/format/2312.08799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Characterizations of Approval-based Committee Scoring Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chris Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lederer%2C+P">Patrick Lederer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item1148">[1148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08886" title="Abstract">arXiv:2312.08886</a> (replaced) [<a href="/pdf/2312.08886" title="Download PDF">pdf</a>, <a href="/format/2312.08886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Blind Text Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhouxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Luwei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongqing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+L">Liheng Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1149">[1149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09854" title="Abstract">arXiv:2312.09854</a> (replaced) [<a href="/pdf/2312.09854" title="Download PDF">pdf</a>, <a href="/ps/2312.09854" title="Download PostScript">ps</a>, <a href="/format/2312.09854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Segment: Segmenting Images In-Sensor for Vessel-Based Medical  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bonazzi%2C+P">Pietro Bonazzi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+S">Sizhen Bian</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1150">[1150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10930" title="Abstract">arXiv:2312.10930</a> (replaced) [<a href="/pdf/2312.10930" title="Download PDF">pdf</a>, <a href="/format/2312.10930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Approaches for Seizure Video Analysis: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmedt-Aristizabal%2C+D">David Ahmedt-Aristizabal</a>, 
<a href="/search/cs?searchtype=author&query=Armin%2C+M+A">Mohammad Ali Armin</a>, 
<a href="/search/cs?searchtype=author&query=Hayder%2C+Z">Zeeshan Hayder</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Cairasco%2C+N">Norberto Garcia-Cairasco</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Denman%2C+S">Simon Denman</a>, 
<a href="/search/cs?searchtype=author&query=McGonigal%2C+A">Aileen McGonigal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Epilepsy &amp; Behavior
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1151">[1151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11361" title="Abstract">arXiv:2312.11361</a> (replaced) [<a href="/pdf/2312.11361" title="Download PDF">pdf</a>, <a href="/format/2312.11361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoMIRACL: Knowing When You Don&#x27;t Know for Robust Multilingual  Retrieval-Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+N">Nandan Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Bonifacio%2C+L">Luiz Bonifacio</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ogundepo%2C+O">Odunayo Ogundepo</a>, 
<a href="/search/cs?searchtype=author&query=Kamalloo%2C+E">Ehsan Kamalloo</a>, 
<a href="/search/cs?searchtype=author&query=Alfonso-Hermelo%2C+D">David Alfonso-Hermelo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rezagholizadeh%2C+M">Mehdi Rezagholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1152">[1152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11436" title="Abstract">arXiv:2312.11436</a> (replaced) [<a href="/pdf/2312.11436" title="Download PDF">pdf</a>, <a href="/format/2312.11436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layerwise complexity-matched learning yields an improved model of  cortical area V2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Parthasarathy%2C+N">Nikhil Parthasarathy</a>, 
<a href="/search/q-bio?searchtype=author&query=H%C3%A9naff%2C+O+J">Olivier J. H&#xe9;naff</a>, 
<a href="/search/q-bio?searchtype=author&query=Simoncelli%2C+E+P">Eero P. Simoncelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1153">[1153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11954" title="Abstract">arXiv:2312.11954</a> (replaced) [<a href="/pdf/2312.11954" title="Download PDF">pdf</a>, <a href="/format/2312.11954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial AutoMixup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huafeng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=El-Yacoubi%2C+M+A">Mounim A. El-Yacoubi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Camera Ready.(19 pages) with the source code at <a href="https://github.com/JinXins/Adversarial-AutoMixup">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1154">[1154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13004" title="Abstract">arXiv:2312.13004</a> (replaced) [<a href="/pdf/2312.13004" title="Download PDF">pdf</a>, <a href="/format/2312.13004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Surface-Aided Near-field Communications for  6G: Opportunities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, this paper was accepted for publication in IEEE Vehicular Technology Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1155">[1155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13064" title="Abstract">arXiv:2312.13064</a> (replaced) [<a href="/pdf/2312.13064" title="Download PDF">pdf</a>, <a href="/format/2312.13064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LPR: Large Language Models-Aided Program Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yongqiang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiwen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S+H">Shin Hwei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chengnian Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1156">[1156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13103" title="Abstract">arXiv:2312.13103</a> (replaced) [<a href="/pdf/2312.13103" title="Download PDF">pdf</a>, <a href="/ps/2312.13103" title="Download PostScript">ps</a>, <a href="/format/2312.13103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multimodal Large Language Models for Radiology Report  Error-checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinge Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+E+C">Eva C. Keller</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+J">Jamie Chow</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+A+P">Adam P. Levine</a>, 
<a href="/search/cs?searchtype=author&query=Pontikos%2C+N">Nikolas Pontikos</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+Z">Zina Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+P">Paul Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+M+C">Michelle C. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Honghan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1157">[1157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14404" title="Abstract">arXiv:2312.14404</a> (replaced) [<a href="/pdf/2312.14404" title="Download PDF">pdf</a>, <a href="/format/2312.14404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Covariate Gait Recognition: A Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shinan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jianbo Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chuanfu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1158">[1158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14499" title="Abstract">arXiv:2312.14499</a> (replaced) [<a href="/pdf/2312.14499" title="Download PDF">pdf</a>, <a href="/format/2312.14499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hutchinson Trace Estimation for High-Dimensional and High-Order  Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zekun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Computer Methods in Applied Mechanics and Engineering
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering, Volume 424,
  1 May 2024, 116883
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1159">[1159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15068" title="Abstract">arXiv:2312.15068</a> (replaced) [<a href="/pdf/2312.15068" title="Download PDF">pdf</a>, <a href="/format/2312.15068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining GPT-3 Embeddings with a Siamese Structure for Technical Post  Duplicate Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yoshioka%2C+N">Nobukazu Yoshioka</a>, 
<a href="/search/cs?searchtype=author&query=Washizaki%2C+H">Hironori Washizaki</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SANER 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1160">[1160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15285" title="Abstract">arXiv:2312.15285</a> (replaced) [<a href="/pdf/2312.15285" title="Download PDF">pdf</a>, <a href="/ps/2312.15285" title="Download PostScript">ps</a>, <a href="/format/2312.15285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandom and Pseudoentangled States from Subset States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jeronimo%2C+F+G">Fernando Granha Jeronimo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magrafta%2C+N">Nir Magrafta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+P">Pei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages; add a minimum background on pseudoentanglement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1161">[1161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15954" title="Abstract">arXiv:2312.15954</a> (replaced) [<a href="/pdf/2312.15954" title="Download PDF">pdf</a>, <a href="/ps/2312.15954" title="Download PostScript">ps</a>, <a href="/format/2312.15954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On two-dimensional minimal linear codes over the rings  $\mathbb{Z}_{p^n}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+B">Biplab Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+R+K">Ratnesh Kumar Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item1162">[1162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17242" title="Abstract">arXiv:2312.17242</a> (replaced) [<a href="/pdf/2312.17242" title="Download PDF">pdf</a>, <a href="/format/2312.17242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Text in Arbitrary Writing Styles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aleem Khan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Andrew Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hager%2C+S">Sophia Hager</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+N">Nicholas Andrews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1163">[1163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00283" title="Abstract">arXiv:2401.00283</a> (replaced) [<a href="/pdf/2401.00283" title="Download PDF">pdf</a>, <a href="/format/2401.00283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Space Communications: the Last Piece of 6G Space-Air-Ground-Sea  Integrated Network Puzzle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+T">Tianqi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+K">Keke Ying</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Li Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+R">Rui Na</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yikun Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+G">Guanghui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghuai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dezhi Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1164">[1164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00873" title="Abstract">arXiv:2401.00873</a> (replaced) [<a href="/pdf/2401.00873" title="Download PDF">pdf</a>, <a href="/format/2401.00873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Unification of Self-Supervised Clustering and Energy-Based  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sansone%2C+E">Emanuele Sansone</a>, 
<a href="/search/cs?searchtype=author&query=Manhaeve%2C+R">Robin Manhaeve</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Changes from previous version: added mean and standard deviations in experiments. Integral version of workshop paper <a href="/abs/2309.15420">arXiv:2309.15420</a>. Improved GEDI version (from two stages to single stage training) arxiv:<a href="/abs/2212.13425">2212.13425</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1165">[1165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01749" title="Abstract">arXiv:2401.01749</a> (replaced) [<a href="/pdf/2401.01749" title="Download PDF">pdf</a>, <a href="/format/2401.01749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Image Generation via Information Transfer from the Built  Geodesic Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuexing Han</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+L">Liheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1166">[1166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02116" title="Abstract">arXiv:2401.02116</a> (replaced) [<a href="/pdf/2401.02116" title="Download PDF">pdf</a>, <a href="/format/2401.02116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Starling: An I/O-Efficient Disk-Resident Graph Index Framework for  High-Dimensional Vector Similarity Search on Data Segment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weizhi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaomeng Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Songlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhangyang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+X">Xiangyu Ke</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Rentong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Charles Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1167">[1167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02597" title="Abstract">arXiv:2401.02597</a> (replaced) [<a href="/pdf/2401.02597" title="Download PDF">pdf</a>, <a href="/format/2401.02597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Spectral Efficiency with Data-Carrying Reference Signals on the  Grassmann Manifold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Endo%2C+N">Naoki Endo</a>, 
<a href="/search/eess?searchtype=author&query=Iimori%2C+H">Hiroki Iimori</a>, 
<a href="/search/eess?searchtype=author&query=Pradhan%2C+C">Chandan Pradhan</a>, 
<a href="/search/eess?searchtype=author&query=Malomsoky%2C+S">Szabolcs Malomsoky</a>, 
<a href="/search/eess?searchtype=author&query=Ishikawa%2C+N">Naoki Ishikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Wireless Communications, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item1168">[1168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03790" title="Abstract">arXiv:2401.03790</a> (replaced) [<a href="/pdf/2401.03790" title="Download PDF">pdf</a>, <a href="/format/2401.03790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Properties of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Dat Nguyen</a> (1), 
<a href="/search/cs?searchtype=author&query=Vu%2C+H+M">Hieu M. Vu</a> (2), 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cong-Thanh Le</a> (1), 
<a href="/search/cs?searchtype=author&query=Le%2C+B">Bach Le</a> (1), 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a> (3), 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">ThanhVu Nguyen</a> (4)
<a href="/search/cs?searchtype=author&query=Pasareanu%2C+C">Corina Pasareanu</a> (5) ((1) University of Melbourne, (2) Independent Researcher, (3) Singapore Management University, (4) George Mason University, (5) Carnegie Mellon University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages main paper, 10 pages for appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1169">[1169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04330" title="Abstract">arXiv:2401.04330</a> (replaced) [<a href="/pdf/2401.04330" title="Download PDF">pdf</a>, <a href="/format/2401.04330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method  guided by multi-scale feature information aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yonghui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaolong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yishu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+J">Jinquan Ai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1170">[1170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04331" title="Abstract">arXiv:2401.04331</a> (replaced) [<a href="/pdf/2401.04331" title="Download PDF">pdf</a>, <a href="/format/2401.04331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupling Graph Neural Networks with Fractional Order Continuous  Dynamics: A Robustness Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qiyu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yihang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+R">Rui She</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Proc. AAAI Conference on Artificial Intelligence, Vancouver, Canada, Feb. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1171">[1171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04837" title="Abstract">arXiv:2401.04837</a> (replaced) [<a href="/pdf/2401.04837" title="Download PDF">pdf</a>, <a href="/format/2401.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-PRIME: Transformer-based Protocol Identification for Machine-learning  at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belgiovine%2C+M">Mauro Belgiovine</a>, 
<a href="/search/cs?searchtype=author&query=Groen%2C+J">Joshua Groen</a>, 
<a href="/search/cs?searchtype=author&query=Sirera%2C+M">Miquel Sirera</a>, 
<a href="/search/cs?searchtype=author&query=Tassie%2C+C">Chinenye Tassie</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+A+Y">Ayberk Yark&#x131;n Y&#x131;ld&#x131;z</a>, 
<a href="/search/cs?searchtype=author&query=Trudeau%2C+S">Sage Trudeau</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S">Stratis Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+K">Kaushik Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the extended version of the IEEE INFOCOM 2024 paper with the same title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1172">[1172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05531" title="Abstract">arXiv:2401.05531</a> (replaced) [<a href="/pdf/2401.05531" title="Download PDF">pdf</a>, <a href="/ps/2401.05531" title="Download PostScript">ps</a>, <a href="/format/2401.05531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational  Inference for Improved Generalization in Audio Pattern Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+J">John Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Orescanin%2C+M">Marko Orescanin</a>, 
<a href="/search/cs?searchtype=author&query=Eckstrand%2C+E">Eric Eckstrand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Access
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1173">[1173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05603" title="Abstract">arXiv:2401.05603</a> (replaced) [<a href="/pdf/2401.05603" title="Download PDF">pdf</a>, <a href="/ps/2401.05603" title="Download PostScript">ps</a>, <a href="/format/2401.05603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personal Moderation Configurations on Facebook: Exploring the Role of  FoMO, Social Media Addiction, Norms, and Platform Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jhaver%2C+S">Shagun Jhaver</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1174">[1174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05638" title="Abstract">arXiv:2401.05638</a> (replaced) [<a href="/pdf/2401.05638" title="Download PDF">pdf</a>, <a href="/format/2401.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatSAM: Efficient Extraction of Microstructures of Materials via Visual  Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+X">Xiaojuan Ban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures, and 5 tables. Updated with revision and code repository
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1175">[1175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05744" title="Abstract">arXiv:2401.05744</a> (replaced) [<a href="/pdf/2401.05744" title="Download PDF">pdf</a>, <a href="/format/2401.05744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Is Not the Only Choice: Counterfactual Reasoning for  Path-Based Explainable Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yicong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sixiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by TKDE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1176">[1176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06040" title="Abstract">arXiv:2401.06040</a> (replaced) [<a href="/pdf/2401.06040" title="Download PDF">pdf</a>, <a href="/format/2401.06040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet-Inspired Multiscale Graph Convolutional Recurrent Network for  Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qipeng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+T">Tanwi Mallick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1177">[1177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06182" title="Abstract">arXiv:2401.06182</a> (replaced) [<a href="/pdf/2401.06182" title="Download PDF">pdf</a>, <a href="/format/2401.06182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Cellular Identities from Trajectory and Cell Fate  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Dai%2C+B">Baiyang Dai</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+J">Jiamin Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Shroff%2C+H">Hari Shroff</a>, 
<a href="/search/q-bio?searchtype=author&query=La+Riviere%2C+P">Patrick La Riviere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1178">[1178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06509" title="Abstract">arXiv:2401.06509</a> (replaced) [<a href="/pdf/2401.06509" title="Download PDF">pdf</a>, <a href="/format/2401.06509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntEval: Quantitatively Evaluating Informativeness and Expressiveness of  Agent Social Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuanzhi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version of an ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1179">[1179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06755" title="Abstract">arXiv:2401.06755</a> (replaced) [<a href="/pdf/2401.06755" title="Download PDF">pdf</a>, <a href="/format/2401.06755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the Discretised Multiphase Flow Equations with Interface  Capturing on Structured Grids Using Machine Learning Libraries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+B">Boyang Chen</a>, 
<a href="/search/physics?searchtype=author&query=Heaney%2C+C+E">Claire E. Heaney</a>, 
<a href="/search/physics?searchtype=author&query=Gomes%2C+J+L+M+A">Jefferson L. M. A. Gomes</a>, 
<a href="/search/physics?searchtype=author&query=Matar%2C+O+K">Omar K. Matar</a>, 
<a href="/search/physics?searchtype=author&query=Pain%2C+C+C">Christopher C. Pain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 18 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1180">[1180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06915" title="Abstract">arXiv:2401.06915</a> (replaced) [<a href="/pdf/2401.06915" title="Download PDF">pdf</a>, <a href="/format/2401.06915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocFinQA: A Long-Context Financial Reasoning Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+V">Varshini Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Koncel-Kedziorski%2C+R">Rik Koncel-Kedziorski</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V+D">Viet Dac Lai</a>, 
<a href="/search/cs?searchtype=author&query=Krumdick%2C+M">Michael Krumdick</a>, 
<a href="/search/cs?searchtype=author&query=Lovering%2C+C">Charles Lovering</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+C">Chris Tanner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1181">[1181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07768" title="Abstract">arXiv:2401.07768</a> (replaced) [<a href="/pdf/2401.07768" title="Download PDF">pdf</a>, <a href="/ps/2401.07768" title="Download PostScript">ps</a>, <a href="/format/2401.07768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Hilbert-Poincar&#xe9; series of affine semi-regular polynomial  sequences and related Gr&#xf6;bner bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudo%2C+M">Momonari Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+K">Kazuhiro Yokoyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, Comments are welcome!
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematical Foundations for Post-Quantum Cryptography (T. Takagi
  et al. eds), Mathematics for Industry, Springer, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item1182">[1182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08037" title="Abstract">arXiv:2401.08037</a> (replaced) [<a href="/pdf/2401.08037" title="Download PDF">pdf</a>, <a href="/format/2401.08037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding factors behind IoT privacy -- A user&#x27;s perspective on RF  sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+D">Akash Deep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Brian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+L">Luis Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M">Mani Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1183">[1183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08536" title="Abstract">arXiv:2401.08536</a> (replaced) [<a href="/pdf/2401.08536" title="Download PDF">pdf</a>, <a href="/format/2401.08536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Loop Robust Control of Biased Koopman Operator Model by Noisy Data  of Nonlinear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+T">Tianyi He</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anuj Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1184">[1184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09630" title="Abstract">arXiv:2401.09630</a> (replaced) [<a href="/pdf/2401.09630" title="Download PDF">pdf</a>, <a href="/format/2401.09630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CT Liver Segmentation via PVT-based Encoding and Refined Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/eess?searchtype=author&query=Tomar%2C+N+K">Nikhil Kumar Tomar</a>, 
<a href="/search/eess?searchtype=author&query=Biswas%2C+K">Koushik Biswas</a>, 
<a href="/search/eess?searchtype=author&query=Durak%2C+G">Gorkem Durak</a>, 
<a href="/search/eess?searchtype=author&query=Medetalibeyoglu%2C+A">Alpay Medetalibeyoglu</a>, 
<a href="/search/eess?searchtype=author&query=Antalek%2C+M">Matthew Antalek</a>, 
<a href="/search/eess?searchtype=author&query=Velichko%2C+Y">Yury Velichko</a>, 
<a href="/search/eess?searchtype=author&query=Ladner%2C+D">Daniela Ladner</a>, 
<a href="/search/eess?searchtype=author&query=Borhani%2C+A">Amir Borhani</a>, 
<a href="/search/eess?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1185">[1185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09851" title="Abstract">arXiv:2401.09851</a> (replaced) [<a href="/pdf/2401.09851" title="Download PDF">pdf</a>, <a href="/format/2401.09851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sophisticated Behavioral Simulation: A Possible Solution to Problems of  Organized Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Shirong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+R">Ronghui Ning</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1186">[1186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10652" title="Abstract">arXiv:2401.10652</a> (replaced) [<a href="/pdf/2401.10652" title="Download PDF">pdf</a>, <a href="/format/2401.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuanlei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shenggan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiarui Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haotian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Bin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1187">[1187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10731" title="Abstract">arXiv:2401.10731</a> (replaced) [<a href="/pdf/2401.10731" title="Download PDF">pdf</a>, <a href="/format/2401.10731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removal and Selection: Improving RGB-Infrared Object Detection via  Coarse-to-Fine Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Maoxun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9pages, 7figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1188">[1188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11202" title="Abstract">arXiv:2401.11202</a> (replaced) [<a href="/pdf/2401.11202" title="Download PDF">pdf</a>, <a href="/format/2401.11202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PartIR: Composing SPMD Partitioning Strategies for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabed%2C+S">Sami Alabed</a>, 
<a href="/search/cs?searchtype=author&query=Belov%2C+D">Daniel Belov</a>, 
<a href="/search/cs?searchtype=author&query=Chrzaszcz%2C+B">Bart Chrzaszcz</a>, 
<a href="/search/cs?searchtype=author&query=Franco%2C+J">Juliana Franco</a>, 
<a href="/search/cs?searchtype=author&query=Grewe%2C+D">Dominik Grewe</a>, 
<a href="/search/cs?searchtype=author&query=Maclaurin%2C+D">Dougal Maclaurin</a>, 
<a href="/search/cs?searchtype=author&query=Molloy%2C+J">James Molloy</a>, 
<a href="/search/cs?searchtype=author&query=Natan%2C+T">Tom Natan</a>, 
<a href="/search/cs?searchtype=author&query=Norman%2C+T">Tamara Norman</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaoyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Paszke%2C+A">Adam Paszke</a>, 
<a href="/search/cs?searchtype=author&query=Rink%2C+N+A">Norman A. Rink</a>, 
<a href="/search/cs?searchtype=author&query=Schaarschmidt%2C+M">Michael Schaarschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Sitdikov%2C+T">Timur Sitdikov</a>, 
<a href="/search/cs?searchtype=author&query=Swietlik%2C+A">Agnieszka Swietlik</a>, 
<a href="/search/cs?searchtype=author&query=Vytiniotis%2C+D">Dimitrios Vytiniotis</a>, 
<a href="/search/cs?searchtype=author&query=Wee%2C+J">Joel Wee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1189">[1189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11667" title="Abstract">arXiv:2401.11667</a> (replaced) [<a href="/pdf/2401.11667" title="Download PDF">pdf</a>, <a href="/format/2401.11667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INCPrompt: Task-Aware incremental Prompting for Rehearsal-Free  Class-incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoyang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bokui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 49th IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1190">[1190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11977" title="Abstract">arXiv:2401.11977</a> (replaced) [<a href="/pdf/2401.11977" title="Download PDF">pdf</a>, <a href="/format/2401.11977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Motion Planning for Multi-fingered Functional Grasp via Force  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+D">Dongying Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiangbo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yi Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1191">[1191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12624" title="Abstract">arXiv:2401.12624</a> (replaced) [<a href="/pdf/2401.12624" title="Download PDF">pdf</a>, <a href="/format/2401.12624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation from Language-Oriented to Emergent Communication  for Multi-Agent Remote Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Sejin Seo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jihong Park</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seong-Lyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Junil Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1192">[1192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12768" title="Abstract">arXiv:2401.12768</a> (replaced) [<a href="/pdf/2401.12768" title="Download PDF">pdf</a>, <a href="/format/2401.12768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Can Self-Admitted Technical Debt Tell Us About Security? A  Mixed-Methods Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreyra%2C+N+E+D">Nicol&#xe1;s E. D&#xed;az Ferreyra</a>, 
<a href="/search/cs?searchtype=author&query=Shahin%2C+M">Mojtaba Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mansooreh Zahedi</a>, 
<a href="/search/cs?searchtype=author&query=Quadri%2C+S">Sodiq Quadri</a>, 
<a href="/search/cs?searchtype=author&query=Scandariato%2C+R">Ricardo Scandariato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 21th International Conference on Mining Software Repositories (MSR '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1193">[1193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12938" title="Abstract">arXiv:2401.12938</a> (replaced) [<a href="/pdf/2401.12938" title="Download PDF">pdf</a>, <a href="/format/2401.12938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural deformation fields for template-based reconstruction of cortical  surfaces from MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bongratz%2C+F">Fabian Bongratz</a>, 
<a href="/search/eess?searchtype=author&query=Rickmann%2C+A">Anne-Marie Rickmann</a>, 
<a href="/search/eess?searchtype=author&query=Wachinger%2C+C">Christian Wachinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1194">[1194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13782" title="Abstract">arXiv:2401.13782</a> (replaced) [<a href="/pdf/2401.13782" title="Download PDF">pdf</a>, <a href="/format/2401.13782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tweets to Citations: Unveiling the Impact of Social Media Influencers on  AI Research Visibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weissburg%2C+I+X">Iain Xie Weissburg</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+M">Mehir Arora</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 14 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1195">[1195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14028" title="Abstract">arXiv:2401.14028</a> (replaced) [<a href="/pdf/2401.14028" title="Download PDF">pdf</a>, <a href="/format/2401.14028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of modularity-based approaches for nodes clustering in  hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poda%2C+V">Veronica Poda</a>, 
<a href="/search/cs?searchtype=author&query=Matias%2C+C">Catherine Matias</a> (LPSM (UMR\_8001))
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Combinatorics (math.CO); Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1196">[1196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14112" title="Abstract">arXiv:2401.14112</a> (replaced) [<a href="/pdf/2401.14112" title="Download PDF">pdf</a>, <a href="/format/2401.14112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric  Algorithm-System Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haojun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+S">Stephen Youn</a>, 
<a href="/search/cs?searchtype=author&query=Bakhtiari%2C+A">Arash Bakhtiari</a>, 
<a href="/search/cs?searchtype=author&query=Wyatt%2C+M">Michael Wyatt</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+D">Donglin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhongzhu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ruwase%2C+O">Olatunji Ruwase</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S+L">Shuaiwen Leon Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Adding URL link of the source code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item1197">[1197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14304" title="Abstract">arXiv:2401.14304</a> (replaced) [<a href="/pdf/2401.14304" title="Download PDF">pdf</a>, <a href="/format/2401.14304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint-Aware Mesh Refinement Method by Reachability Set Envelope of  Curvature Bounded Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bae%2C+J">Juho Bae</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+J+H">Ji Hoon Bai</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+B">Byung-Yoon Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jun-Yong Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1198">[1198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15030" title="Abstract">arXiv:2401.15030</a> (replaced) [<a href="/pdf/2401.15030" title="Download PDF">pdf</a>, <a href="/format/2401.15030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the generalization capacity of neural networks during generic  multimodal reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ito%2C+T">Takuya Ito</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+S">Soham Dan</a>, 
<a href="/search/cs?searchtype=author&query=Rigotti%2C+M">Mattia Rigotti</a>, 
<a href="/search/cs?searchtype=author&query=Kozloski%2C+J">James Kozloski</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+M">Murray Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1199">[1199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15380" title="Abstract">arXiv:2401.15380</a> (replaced) [<a href="/pdf/2401.15380" title="Download PDF">pdf</a>, <a href="/format/2401.15380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-RadVLAD: Fast and Robust Radar Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadd%2C+M">Matthew Gadd</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+P">Paul Newman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at 2024 IEEE Radar Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1200">[1200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15422" title="Abstract">arXiv:2401.15422</a> (replaced) [<a href="/pdf/2401.15422" title="Download PDF">pdf</a>, <a href="/format/2401.15422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Data Augmentation in Large Model Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chenlu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages; <a href="https://github.com/MLGroup-JLU/LLM-data-aug-survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1201">[1201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16193" title="Abstract">arXiv:2401.16193</a> (replaced) [<a href="/pdf/2401.16193" title="Download PDF">pdf</a>, <a href="/format/2401.16193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contributing Dimension Structure of Deep Feature for Coreset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhijing Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+S">Shin&#x27;ichi Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,11 figures, to be published in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1202">[1202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16337" title="Abstract">arXiv:2401.16337</a> (replaced) [<a href="/pdf/2401.16337" title="Download PDF">pdf</a>, <a href="/format/2401.16337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum-Based Reinforcement Learning for Quadrupedal Jumping: A  Reference-free Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atanassov%2C+V">Vassil Atanassov</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiatao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Havoutis%2C+I">Ioannis Havoutis</a>, 
<a href="/search/cs?searchtype=author&query=Della+Santina%2C+C">Cosimo Della Santina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 10 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1203">[1203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16549" title="Abstract">arXiv:2401.16549</a> (replaced) [<a href="/pdf/2401.16549" title="Download PDF">pdf</a>, <a href="/ps/2401.16549" title="Download PostScript">ps</a>, <a href="/format/2401.16549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Multi-Label Learning: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarekegn%2C+A+N">Adane Nega Tarekegn</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+M">Mohib Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Cheikh%2C+F+A">Faouzi Alaya Cheikh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 12 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1204">[1204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17644" title="Abstract">arXiv:2401.17644</a> (replaced) [<a href="/pdf/2401.17644" title="Download PDF">pdf</a>, <a href="/format/2401.17644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Reliable LLM Serving: A Real-World Workload Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhenheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Rui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A+C">Amelie Chi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiaowen Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item1205">[1205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.18018" title="Abstract">arXiv:2401.18018</a> (replaced) [<a href="/pdf/2401.18018" title="Download PDF">pdf</a>, <a href="/format/2401.18018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Prompt-Driven Safeguarding for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chujie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1206">[1206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.18030" title="Abstract">arXiv:2401.18030</a> (replaced) [<a href="/pdf/2401.18030" title="Download PDF">pdf</a>, <a href="/ps/2401.18030" title="Download PostScript">ps</a>, <a href="/format/2401.18030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed fixed-point algorithms for dynamic convex optimization over  decentralized and unbalanced wireless networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Agrawal%2C+N">Navneet Agrawal</a>, 
<a href="/search/math?searchtype=author&query=Cavalcante%2C+R+L+G">Renato L.G. Cavalcante</a>, 
<a href="/search/math?searchtype=author&query=Sta%C5%84czak%2C+S">S&#x142;awomir Sta&#x144;czak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at: 27th International Workshop on Smart Antennas (WSA) 2024, Dresden, Germany. Copyright: IEEE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1207">[1207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00321" title="Abstract">arXiv:2402.00321</a> (replaced) [<a href="/pdf/2402.00321" title="Download PDF">pdf</a>, <a href="/format/2402.00321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartCooper: Vehicular Collaborative Perception with Adaptive Fusion and  Judger Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Haonan An</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhengru Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1208">[1208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00330" title="Abstract">arXiv:2402.00330</a> (replaced) [<a href="/pdf/2402.00330" title="Download PDF">pdf</a>, <a href="/format/2402.00330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Night-Rider: Nocturnal Vision-aided Localization in Streetlight Maps  Using Invariant Extended Kalman Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tianxiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mingle Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+H">Hui Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1209">[1209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00712" title="Abstract">arXiv:2402.00712</a> (replaced) [<a href="/pdf/2402.00712" title="Download PDF">pdf</a>, <a href="/format/2402.00712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChaosBench: A Multi-Channel, Physics-Based Benchmark for  Subseasonal-to-Seasonal Climate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nathaniel%2C+J">Juan Nathaniel</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yongquan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sungduk Yu</a>, 
<a href="/search/cs?searchtype=author&query=Busecke%2C+J">Julius Busecke</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>, 
<a href="/search/cs?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 39 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1210">[1210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00924" title="Abstract">arXiv:2402.00924</a> (replaced) [<a href="/pdf/2402.00924" title="Download PDF">pdf</a>, <a href="/format/2402.00924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fragile Nature of Road Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+L">Linghang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Axenie%2C+C">Cristian Axenie</a>, 
<a href="/search/eess?searchtype=author&query=Grossi%2C+M">Margherita Grossi</a>, 
<a href="/search/eess?searchtype=author&query=Kouvelas%2C+A">Anastasios Kouvelas</a>, 
<a href="/search/eess?searchtype=author&query=Makridis%2C+M+A">Michail A. Makridis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1211">[1211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01244" title="Abstract">arXiv:2402.01244</a> (replaced) [<a href="/pdf/2402.01244" title="Download PDF">pdf</a>, <a href="/format/2402.01244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short Systematic Codes for Correcting Random Edit Errors in DNA Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanna%2C+S+K">Serge Kas Hanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor text edits and additional simulation results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1212">[1212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01440" title="Abstract">arXiv:2402.01440</a> (replaced) [<a href="/pdf/2402.01440" title="Download PDF">pdf</a>, <a href="/format/2402.01440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Learning on Graphs: from Meta-learning to Pre-training and  Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+J">Jianyuan Bo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hoi%2C+S+C+H">Steven C.H. Hoi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1213">[1213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01499" title="Abstract">arXiv:2402.01499</a> (replaced) [<a href="/pdf/2402.01499" title="Download PDF">pdf</a>, <a href="/format/2402.01499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing and Evaluating a Design Method for Positive Artificial  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Maden%2C+W">Willem van der Maden</a>, 
<a href="/search/cs?searchtype=author&query=Lomas%2C+D">Derek Lomas</a>, 
<a href="/search/cs?searchtype=author&query=Hekkert%2C+P">Paul Hekkert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1214">[1214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02042" title="Abstract">arXiv:2402.02042</a> (replaced) [<a href="/pdf/2402.02042" title="Download PDF">pdf</a>, <a href="/ps/2402.02042" title="Download PostScript">ps</a>, <a href="/format/2402.02042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning General Parameterized Policies for Infinite Horizon Average  Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Q">Qinbo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+W+U">Washim Uddin Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We fixed Lemma 6 in v2 which changed the final result
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1215">[1215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02446" title="Abstract">arXiv:2402.02446</a> (replaced) [<a href="/pdf/2402.02446" title="Download PDF">pdf</a>, <a href="/format/2402.02446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LQER: Low-Rank Quantization Error Reconstruction for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jianyi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1216">[1216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02564" title="Abstract">arXiv:2402.02564</a> (replaced) [<a href="/pdf/2402.02564" title="Download PDF">pdf</a>, <a href="/format/2402.02564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Truly Joint Neural Architecture for Segmentation and Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levi%2C+D+Y">Danit Yshaayahu Levi</a>, 
<a href="/search/cs?searchtype=author&query=Tsarfaty%2C+R">Reut Tsarfaty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1217">[1217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02606" title="Abstract">arXiv:2402.02606</a> (replaced) [<a href="/pdf/2402.02606" title="Download PDF">pdf</a>, <a href="/format/2402.02606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nelson algebras, residuated lattices and rough sets: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=J%C3%A4rvinen%2C+J">Jouni J&#xe4;rvinen</a>, 
<a href="/search/math?searchtype=author&query=Radeleczki%2C+S">S&#xe1;ndor Radeleczki</a>, 
<a href="/search/math?searchtype=author&query=Rivieccio%2C+U">Umberto Rivieccio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Journal of Applied Non-Classical Logics. In this version of the manuscript, certain typographical errors have been rectified
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1218">[1218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02733" title="Abstract">arXiv:2402.02733</a> (replaced) [<a href="/pdf/2402.02733" title="Download PDF">pdf</a>, <a href="/format/2402.02733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Bumsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Muqeet%2C+A">Abdul Muqeet</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyuchul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Sanghyun Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1219">[1219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03181" title="Abstract">arXiv:2402.03181</a> (replaced) [<a href="/pdf/2402.03181" title="Download PDF">pdf</a>, <a href="/format/2402.03181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-RAG: Certified Generation Risks for Retrieval-Augmented Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mintong Kang</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrel%2C+N+M">Nezihe Merve G&#xfc;rel</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1220">[1220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03223" title="Abstract">arXiv:2402.03223</a> (replaced) [<a href="/pdf/2402.03223" title="Download PDF">pdf</a>, <a href="/format/2402.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barrei%C3%9F%2C+P">Patrick Barrei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Klinger%2C+R">Roman Klinger</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+J">Jeremy Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to the PromptEng workshop at The Web Conf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1221">[1221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03246" title="Abstract">arXiv:2402.03246</a> (replaced) [<a href="/pdf/2402.03246" title="Download PDF">pdf</a>, <a href="/format/2402.03246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Heng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guohao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Na Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1222">[1222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03496" title="Abstract">arXiv:2402.03496</a> (replaced) [<a href="/pdf/2402.03496" title="Download PDF">pdf</a>, <a href="/format/2402.03496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Remove the Square-Root in Adaptive Gradient Methods? A  Second-Order Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dangel%2C+F">Felix Dangel</a>, 
<a href="/search/cs?searchtype=author&query=Eschenhagen%2C+R">Runa Eschenhagen</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Juhan Bae</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Makhzani%2C+A">Alireza Makhzani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated Sec. 3 &amp; 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1223">[1223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03681" title="Abstract">arXiv:2402.03681</a> (replaced) [<a href="/pdf/2402.03681" title="Download PDF">pdf</a>, <a href="/format/2402.03681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhanyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jesse Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Z">Zhou Xian</a>, 
<a href="/search/cs?searchtype=author&query=Biyik%2C+E">Erdem Biyik</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1224">[1224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04584" title="Abstract">arXiv:2402.04584</a> (replaced) [<a href="/pdf/2402.04584" title="Download PDF">pdf</a>, <a href="/format/2402.04584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Troublemaker Learning for Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+Y">Yinghao Song</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Z">Zhiyuan Cao</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+W">Wanhong Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Long%2C+S">Sifan Long</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+H">Hongwei Ge</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+Y">Yanchun Liang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chunguo Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1225">[1225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04921" title="Abstract">arXiv:2402.04921</a> (replaced) [<a href="/pdf/2402.04921" title="Download PDF">pdf</a>, <a href="/format/2402.04921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Two-shot All You Need? A Label-efficient Approach for Video  Segmentation in Breast Ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeng%2C+J">Jiajun Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+D">Dong Ni</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+R">Ruobing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figure, 2 tables, accepted by ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1226">[1226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05011" title="Abstract">arXiv:2402.05011</a> (replaced) [<a href="/pdf/2402.05011" title="Download PDF">pdf</a>, <a href="/format/2402.05011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Complexity: Toward Lossless Graph Condensation via Expanding  Window Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wei Jin</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lossless graph condensation method
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1227">[1227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05044" title="Abstract">arXiv:2402.05044</a> (replaced) [<a href="/pdf/2402.05044" title="Download PDF">pdf</a>, <a href="/format/2402.05044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bowen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuhao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> fix institution typo
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1228">[1228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05300" title="Abstract">arXiv:2402.05300</a> (replaced) [<a href="/pdf/2402.05300" title="Download PDF">pdf</a>, <a href="/ps/2402.05300" title="Download PostScript">ps</a>, <a href="/format/2402.05300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Player Resource-Sharing Games with Fair Reward Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wijewardena%2C+M">Mevan Wijewardena</a>, 
<a href="/search/cs?searchtype=author&query=Neely%2C+M+J">Michael. J Neely</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1229">[1229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05423" title="Abstract">arXiv:2402.05423</a> (replaced) [<a href="/pdf/2402.05423" title="Download PDF">pdf</a>, <a href="/format/2402.05423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTSA-SNN: A Multi-modal Time Series Analysis Model Based on Spiking  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zihong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, published to International Conference on Computer Supported Cooperative Work in Design
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Computer Supported Cooperative Work in
  Design 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1230">[1230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05448" title="Abstract">arXiv:2402.05448</a> (replaced) [<a href="/pdf/2402.05448" title="Download PDF">pdf</a>, <a href="/format/2402.05448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minecraft-ify: Minecraft Style Image Generation with Text-guided Image  Editing for In-Game Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Bumsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+S">Sanghyun Byun</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+Y">Yonghoon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonseop Shin</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+S+U">Sareer UI Amin</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Sanghyun Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 2 figures. Accepted as Spotlight to NeurIPS 2023 Workshop on Machine Learning for Creativity and Design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1231">[1231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05663" title="Abstract">arXiv:2402.05663</a> (replaced) [<a href="/pdf/2402.05663" title="Download PDF">pdf</a>, <a href="/format/2402.05663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chekroun%2C+R">Raphael Chekroun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jonathan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Toromanoff%2C+M">Marin Toromanoff</a>, 
<a href="/search/cs?searchtype=author&query=Hornauer%2C+S">Sascha Hornauer</a>, 
<a href="/search/cs?searchtype=author&query=Moutarde%2C+F">Fabien Moutarde</a>, 
<a href="/search/cs?searchtype=author&query=Monache%2C+M+L+D">Maria Laura Delle Monache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1232">[1232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05967" title="Abstract">arXiv:2402.05967</a> (replaced) [<a href="/pdf/2402.05967" title="Download PDF">pdf</a>, <a href="/format/2402.05967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The last Dance : Robust backdoor attack via diffusion models and  bayesian approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mengara%2C+O">Orson Mengara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint: audio backdoor attack on Hugging Face's Transformer pre-trained models. This attack incorporates state-of-the-art Bayesian techniques, a modified Fokker-Planck equation, and a diffusion model approach. To alert the community to this danger!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1233">[1233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06104" title="Abstract">arXiv:2402.06104</a> (replaced) [<a href="/pdf/2402.06104" title="Download PDF">pdf</a>, <a href="/format/2402.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function Aligned Regression: A Method Explicitly Learns Functional  Derivatives from Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dixian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jerby%2C+L">Livnat Jerby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages excluding references, 12 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1234">[1234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06649" title="Abstract">arXiv:2402.06649</a> (replaced) [<a href="/pdf/2402.06649" title="Download PDF">pdf</a>, <a href="/ps/2402.06649" title="Download PostScript">ps</a>, <a href="/format/2402.06649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replacing CAPTCHA with XNO micropayments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiruvayipati%2C+S">Sujanavan Tiruvayipati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1235">[1235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07234" title="Abstract">arXiv:2402.07234</a> (replaced) [<a href="/pdf/2402.07234" title="Download PDF">pdf</a>, <a href="/format/2402.07234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for  Chinese Public Security Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Bo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Ting Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Q">Qiang Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1236">[1236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07388" title="Abstract">arXiv:2402.07388</a> (replaced) [<a href="/pdf/2402.07388" title="Download PDF">pdf</a>, <a href="/ps/2402.07388" title="Download PostScript">ps</a>, <a href="/format/2402.07388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Limits of Assumption-free Tests for Algorithm Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+Y">Yuetian Luo</a>, 
<a href="/search/math?searchtype=author&query=Barber%2C+R+F">Rina Foygel Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1237">[1237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07787" title="Abstract">arXiv:2402.07787</a> (replaced) [<a href="/pdf/2402.07787" title="Download PDF">pdf</a>, <a href="/format/2402.07787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaowei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiujuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1238">[1238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08128" title="Abstract">arXiv:2402.08128</a> (replaced) [<a href="/pdf/2402.08128" title="Download PDF">pdf</a>, <a href="/format/2402.08128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Joint Simulation in Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kovarik%2C+V">Vojtech Kovarik</a>, 
<a href="/search/cs?searchtype=author&query=Oesterheld%2C+C">Caspar Oesterheld</a>, 
<a href="/search/cs?searchtype=author&query=Conitzer%2C+V">Vincent Conitzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item1239">[1239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08640" title="Abstract">arXiv:2402.08640</a> (replaced) [<a href="/pdf/2402.08640" title="Download PDF">pdf</a>, <a href="/format/2402.08640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting high-impact research topics via machine learning on evolving  knowledge graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xuemei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Krenn%2C+M">Mario Krenn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1240">[1240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08939" title="Abstract">arXiv:2402.08939</a> (replaced) [<a href="/pdf/2402.08939" title="Download PDF">pdf</a>, <a href="/format/2402.08939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Premise Order Matters in Reasoning with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+R+A">Ryan A. Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Xinyun and Ryan contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1241">[1241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09099" title="Abstract">arXiv:2402.09099</a> (replaced) [<a href="/pdf/2402.09099" title="Download PDF">pdf</a>, <a href="/format/2402.09099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Neuron Interactions and Emergence in LLMs: From the  Multifractal Analysis Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+H">Heng Ping</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Defu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaxing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yizhuo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1242">[1242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09108" title="Abstract">arXiv:2402.09108</a> (replaced) [<a href="/pdf/2402.09108" title="Download PDF">pdf</a>, <a href="/format/2402.09108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Web 3.0 and Quantum Security: Long-Distance Free-Space QSDC for Global  Web 3.0 Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wong%2C+Y+K">Yew Kee Wong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+X">Xinlin Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liang%2C+Y+S">Yan Shing Liang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z+Y">Zi Yan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1243">[1243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09282" title="Abstract">arXiv:2402.09282</a> (replaced) [<a href="/pdf/2402.09282" title="Download PDF">pdf</a>, <a href="/format/2402.09282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Large Language Models into Tiny Models for Named Entity  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yining Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1244">[1244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09702" title="Abstract">arXiv:2402.09702</a> (replaced) [<a href="/pdf/2402.09702" title="Download PDF">pdf</a>, <a href="/format/2402.09702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse and Faithful Explanations Without Sparse Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Orlandi%2C+V">Vittorio Orlandi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1245">[1245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09782" title="Abstract">arXiv:2402.09782</a> (replaced) [<a href="/pdf/2402.09782" title="Download PDF">pdf</a>, <a href="/format/2402.09782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MC-DBN: A Deep Belief Network-Based Model for Modality Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zihong Luo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kexin He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zheng Tao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Computer Supported Cooperative Work in
  Design 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1246">[1246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09963" title="Abstract">arXiv:2402.09963</a> (replaced) [<a href="/pdf/2402.09963" title="Download PDF">pdf</a>, <a href="/format/2402.09963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why are Sensitive Functions Hard for Transformers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hahn%2C+M">Michael Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Rofin%2C+M">Mark Rofin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed various errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1247">[1247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10991" title="Abstract">arXiv:2402.10991</a> (replaced) [<a href="/pdf/2402.10991" title="Download PDF">pdf</a>, <a href="/ps/2402.10991" title="Download PostScript">ps</a>, <a href="/format/2402.10991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Convergence in Federated Learning: A Contribution-Aware  Asynchronous Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yuxin Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+F">Fanghao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jize Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1248">[1248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11027" title="Abstract">arXiv:2402.11027</a> (replaced) [<a href="/pdf/2402.11027" title="Download PDF">pdf</a>, <a href="/format/2402.11027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MITS: A Quantum Sorcerer Stone For Designing Surface Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chatterjee%2C+A">Avimita Chatterjee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+D">Debarshi Kundu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ghosh%2C+S">Swaroop Ghosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item1249">[1249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11094" title="Abstract">arXiv:2402.11094</a> (replaced) [<a href="/pdf/2402.11094" title="Download PDF">pdf</a>, <a href="/format/2402.11094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Embeddings Revisited: Do LLMs Offer Something New?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freestone%2C+M">Matthew Freestone</a>, 
<a href="/search/cs?searchtype=author&query=Santu%2C+S+K+K">Shubhra Kanti Karmaker Santu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1250">[1250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11127" title="Abstract">arXiv:2402.11127</a> (replaced) [<a href="/pdf/2402.11127" title="Download PDF">pdf</a>, <a href="/format/2402.11127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Embroidery: A Study on Weaving Quantum Error Correction into the  Fabric of Quantum Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chatterjee%2C+A">Avimita Chatterjee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+D">Debarshi Kundu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ghosh%2C+S">Swaroop Ghosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item1251">[1251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11253" title="Abstract">arXiv:2402.11253</a> (replaced) [<a href="/pdf/2402.11253" title="Download PDF">pdf</a>, <a href="/format/2402.11253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Large Language Models by On-Policy Self-Judgment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangkyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungdong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yousefpour%2C+A">Ashkan Yousefpour</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+K+M">Kang Min Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1252">[1252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11403" title="Abstract">arXiv:2402.11403</a> (replaced) [<a href="/pdf/2402.11403" title="Download PDF">pdf</a>, <a href="/format/2402.11403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Neural and Neuro-symbolic Approaches to  Real-time Multimodal Complex Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Liying Han</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M+B">Mani B. Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1253">[1253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11567" title="Abstract">arXiv:2402.11567</a> (replaced) [<a href="/pdf/2402.11567" title="Download PDF">pdf</a>, <a href="/ps/2402.11567" title="Download PostScript">ps</a>, <a href="/format/2402.11567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturability of the Quantum Cram&#xe9;r-Rao Bound in Multiparameter  Quantum Estimation at the Single-Copy Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nurdin%2C+H+I">Hendra I. Nurdin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, no figures. Filled in a gap in the proof of the main theorem (Theorem 6), removed Lemma 7 (not needed) and replaced with Remark 7, added references and fixed some typos. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1254">[1254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11837" title="Abstract">arXiv:2402.11837</a> (replaced) [<a href="/pdf/2402.11837" title="Download PDF">pdf</a>, <a href="/format/2402.11837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Guided Robust Graph Structure Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=In%2C+Y">Yeonjun In</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+K">Kanghoon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibum Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kijung Shin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by TheWebConf 2024 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1255">[1255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11871" title="Abstract">arXiv:2402.11871</a> (replaced) [<a href="/pdf/2402.11871" title="Download PDF">pdf</a>, <a href="/format/2402.11871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions,  and Models for Planning from Raw Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Naman Shah</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+J">Jayesh Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+P">Pulkit Verma</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Siddharth Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1256">[1256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11924" title="Abstract">arXiv:2402.11924</a> (replaced) [<a href="/pdf/2402.11924" title="Download PDF">pdf</a>, <a href="/format/2402.11924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Okumura%2C+M">Manabu Okumura</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1257">[1257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12151" title="Abstract">arXiv:2402.12151</a> (replaced) [<a href="/pdf/2402.12151" title="Download PDF">pdf</a>, <a href="/format/2402.12151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Causal Language Models Perform Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added new experimental results and fixed some errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1258">[1258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12694" title="Abstract">arXiv:2402.12694</a> (replaced) [<a href="/pdf/2402.12694" title="Download PDF">pdf</a>, <a href="/format/2402.12694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revitalizing Multivariate Time Series Forecasting: Learnable  Decomposition with Inter-Series Dependencies and Intra-Series Variations  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaowei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I. Aviles-Rivero</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shujun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1259">[1259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12721" title="Abstract">arXiv:2402.12721</a> (replaced) [<a href="/pdf/2402.12721" title="Download PDF">pdf</a>, <a href="/format/2402.12721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for  Recognizing Low-Quality Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+J">Jinsung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hyundong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jonghyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sanghyun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1260">[1260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12728" title="Abstract">arXiv:2402.12728</a> (replaced) [<a href="/pdf/2402.12728" title="Download PDF">pdf</a>, <a href="/format/2402.12728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality-Aware Integration with Large Language Models for  Knowledge-based Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junnan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huachi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Pai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,3 figures and 1 page appendix; The processed graphs and codes will be avalibale
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1261">[1261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13172" title="Abstract">arXiv:2402.13172</a> (replaced) [<a href="/pdf/2402.13172" title="Download PDF">pdf</a>, <a href="/format/2402.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Kinematics Estimation from Video with a Biomechanical Model and  Synthetic Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhi-Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+B">Bofan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+J+C">Judith Cueto Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Kruk%2C+E">Eline van der Kruk</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Ajay Seth</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xucong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1262">[1262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13226" title="Abstract">arXiv:2402.13226</a> (replaced) [<a href="/pdf/2402.13226" title="Download PDF">pdf</a>, <a href="/format/2402.13226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF Solves Undersampled MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jang%2C+T+J">Tae Jun Jang</a>, 
<a href="/search/eess?searchtype=author&query=Hyun%2C+C+M">Chang Min Hyun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1263">[1263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13711" title="Abstract">arXiv:2402.13711</a> (replaced) [<a href="/pdf/2402.13711" title="Download PDF">pdf</a>, <a href="/format/2402.13711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based  Graph Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seungyoon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Wonjoong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=In%2C+Y">Yeonjun In</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sein Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM TheWebConf 2024 (WWW 2024) (Oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1264">[1264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13809" title="Abstract">arXiv:2402.13809</a> (replaced) [<a href="/e-print/2402.13809" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual  Feature Guided Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Badong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The implementation error lead to incorrect results in experiment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1265">[1265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13929" title="Abstract">arXiv:2402.13929</a> (replaced) [<a href="/pdf/2402.13929" title="Download PDF">pdf</a>, <a href="/format/2402.13929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDXL-Lightning: Progressive Adversarial Diffusion Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Anran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1266">[1266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14041" title="Abstract">arXiv:2402.14041</a> (replaced) [<a href="/pdf/2402.14041" title="Download PDF">pdf</a>, <a href="/ps/2402.14041" title="Download PostScript">ps</a>, <a href="/format/2402.14041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2USD: Efficient-yet-effective Unsupervised State Detection for  Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhichen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dalin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weizhu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The Web Conference 2024 (WWW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1267">[1267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14139" title="Abstract">arXiv:2402.14139</a> (replaced) [<a href="/pdf/2402.14139" title="Download PDF">pdf</a>, <a href="/format/2402.14139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroFlux: Memory-Efficient CNN Training Using Adaptive Local Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saikumar%2C+D">Dhananjay Saikumar</a>, 
<a href="/search/cs?searchtype=author&query=Varghese%2C+B">Blesson Varghese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EuroSys 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1268">[1268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14264" title="Abstract">arXiv:2402.14264</a> (replaced) [<a href="/pdf/2402.14264" title="Download PDF">pdf</a>, <a href="/ps/2402.14264" title="Download PostScript">ps</a>, <a href="/format/2402.14264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-agnostic Optimality of Doubly Robust Learning for Treatment  Effect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jin%2C+J">Jikai Jin</a>, 
<a href="/search/stat?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1269">[1269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14498" title="Abstract">arXiv:2402.14498</a> (replaced) [<a href="/pdf/2402.14498" title="Download PDF">pdf</a>, <a href="/format/2402.14498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Collision-Aware Cable Grasping Method in Cluttered Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+K">Kaixin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaopeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1270">[1270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14547" title="Abstract">arXiv:2402.14547</a> (replaced) [<a href="/pdf/2402.14547" title="Download PDF">pdf</a>, <a href="/format/2402.14547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniPred: Language Models as Universal Regressors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xingyou Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+O">Oscar Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chansoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bangding Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Daiyi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Perel%2C+S">Sagi Perel</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yutian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures. Code can be found in <a href="https://github.com/google-research/optformer/tree/main/optformer/omnipred">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1271">[1271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14795" title="Abstract">arXiv:2402.14795</a> (replaced) [<a href="/pdf/2402.14795" title="Download PDF">pdf</a>, <a href="/format/2402.14795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CyberDemo: Augmenting Simulated Human Demonstration for Real-World  Dexterous Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kaiming Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Korkmaz%2C+Y">Yigit Korkmaz</a>, 
<a href="/search/cs?searchtype=author&query=Gurumoorthy%2C+A">Akhilan Gurumoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1272">[1272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14994" title="Abstract">arXiv:2402.14994</a> (replaced) [<a href="/pdf/2402.14994" title="Download PDF">pdf</a>, <a href="/format/2402.14994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Active Element Selection in RIS-aided Massive MIMO  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Souza%2C+W">Wilson Souza Jr</a>, 
<a href="/search/cs?searchtype=author&query=Marinello%2C+J+C">Jos&#xe9; Carlos Marinello</a>, 
<a href="/search/cs?searchtype=author&query=Abr%C3%A3o%2C+T">Taufik Abr&#xe3;o</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 52 references, 2 tables, and 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1273">[1273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15140" title="Abstract">arXiv:2402.15140</a> (replaced) [<a href="/pdf/2402.15140" title="Download PDF">pdf</a>, <a href="/format/2402.15140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Relation-Interactive Approach for Message Passing in Hyper-relational  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yonglin Jing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1274">[1274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15302" title="Abstract">arXiv:2402.15302</a> (replaced) [<a href="/pdf/2402.15302" title="Download PDF">pdf</a>, <a href="/format/2402.15302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How (un)ethical are instruction-centric responses of LLMs? Unveiling the  vulnerabilities of safety guardrails to harmful queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. {<a href="https://huggingface.co/datasets/SoftMINER-Group/TechHazardQA">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1275">[1275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15708" title="Abstract">arXiv:2402.15708</a> (replaced) [<a href="/pdf/2402.15708" title="Download PDF">pdf</a>, <a href="/format/2402.15708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query Augmentation by Decoding Semantics from Brain Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jingtao Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>, 
<a href="/search/cs?searchtype=author&query=Lioma%2C+C">Christina Lioma</a>, 
<a href="/search/cs?searchtype=author&query=Ruotsalo%2C+T">Tuukka Ruotsalo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1276">[1276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15727" title="Abstract">arXiv:2402.15727</a> (replaced) [<a href="/pdf/2402.15727" title="Download PDF">pdf</a>, <a href="/format/2402.15727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A  Vision Paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Daoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed the bibliography reference issue in our LLM jailbreak defense vision paper submitted on 24 Feb 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1277">[1277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15837" title="Abstract">arXiv:2402.15837</a> (replaced) [<a href="/pdf/2402.15837" title="Download PDF">pdf</a>, <a href="/format/2402.15837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An $O(n \log n)$-Time Approximation Scheme for Geometric Many-to-Many  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandyapadhyay%2C+S">Sayan Bandyapadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jie Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SoCG'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item1278">[1278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15883" title="Abstract">arXiv:2402.15883</a> (replaced) [<a href="/pdf/2402.15883" title="Download PDF">pdf</a>, <a href="/format/2402.15883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusion Encoder Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasteris%2C+S">Stephen Pasteris</a>, 
<a href="/search/cs?searchtype=author&query=Hicks%2C+C">Chris Hicks</a>, 
<a href="/search/cs?searchtype=author&query=Mavroudis%2C+V">Vasilios Mavroudis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1279">[1279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15943" title="Abstract">arXiv:2402.15943</a> (replaced) [<a href="/pdf/2402.15943" title="Download PDF">pdf</a>, <a href="/ps/2402.15943" title="Download PostScript">ps</a>, <a href="/format/2402.15943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Software Engineering in the Foundation Model Era: A Curated  Catalogue of Challenges in the Development of Trustworthy FMware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A+E">Ahmed E. Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dayi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajbahadur%2C+G+K">Gopi Krishnan Rajbahadur</a>, 
<a href="/search/cs?searchtype=author&query=Gallaba%2C+K">Keheliya Gallaba</a>, 
<a href="/search/cs?searchtype=author&query=Cogo%2C+F+R">Filipe R. Cogo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Thangarajah%2C+K">Kishanthan Thangarajah</a>, 
<a href="/search/cs?searchtype=author&query=Oliva%2C+G+A">Gustavo Ansaldi Oliva</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiahuei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+W+M">Wali Mohammad Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z+M">Zhen Ming Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1280">[1280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16061" title="Abstract">arXiv:2402.16061</a> (replaced) [<a href="/pdf/2402.16061" title="Download PDF">pdf</a>, <a href="/format/2402.16061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Large Language Models Encode Context Knowledge? A Layer-Wise Probing  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+T">Tianjie Ju</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xinwei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024 (Long Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1281">[1281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16063" title="Abstract">arXiv:2402.16063</a> (replaced) [<a href="/pdf/2402.16063" title="Download PDF">pdf</a>, <a href="/format/2402.16063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citation-Enhanced Generation for LLM-based Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weitao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junkai Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weizhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1282">[1282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16107" title="Abstract">arXiv:2402.16107</a> (replaced) [<a href="/pdf/2402.16107" title="Download PDF">pdf</a>, <a href="/format/2402.16107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FuseChat: Knowledge Fusion of Chat Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Longguang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1283">[1283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16338" title="Abstract">arXiv:2402.16338</a> (replaced) [<a href="/pdf/2402.16338" title="Download PDF">pdf</a>, <a href="/format/2402.16338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLO-SAM: Bi-level Optimization Based Overfitting-Preventing Finetuning  of SAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengtao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1284">[1284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16379" title="Abstract">arXiv:2402.16379</a> (replaced) [<a href="/pdf/2402.16379" title="Download PDF">pdf</a>, <a href="/format/2402.16379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving LLM-based Machine Translation with Systematic Self-Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhaopeng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+J">Jun Lang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1285">[1285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16388" title="Abstract">arXiv:2402.16388</a> (replaced) [<a href="/pdf/2402.16388" title="Download PDF">pdf</a>, <a href="/format/2402.16388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Anomaly Detection with Cross-Conformal  $p$-Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hennh%C3%B6fer%2C+O">Oliver Hennh&#xf6;fer</a>, 
<a href="/search/stat?searchtype=author&query=Preisach%2C+C">Christine Preisach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure, 3 tables (added code reference, typos)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1286">[1286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16627" title="Abstract">arXiv:2402.16627</a> (replaced) [<a href="/pdf/2402.16627" title="Download PDF">pdf</a>, <a href="/format/2402.16627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Contextualized Diffusion Models for Text-Guided Visual  Generation and Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Ling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaochen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Project: <a href="https://github.com/YangLing0818/ContextDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1287">[1287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16641" title="Abstract">arXiv:2402.16641</a> (replaced) [<a href="/pdf/2402.16641" title="Download PDF">pdf</a>, <a href="/format/2402.16641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open-ended Visual Quality Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1288">[1288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16906" title="Abstract">arXiv:2402.16906</a> (replaced) [<a href="/pdf/2402.16906" title="Download PDF">pdf</a>, <a href="/format/2402.16906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDB: A Large Language Model Debugger via Verifying Runtime Execution  Step-by-step
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Li Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1289">[1289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16991" title="Abstract">arXiv:2402.16991</a> (replaced) [<a href="/pdf/2402.16991" title="Download PDF">pdf</a>, <a href="/format/2402.16991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Phase Transition in Diffusion Models Reveals the Hierarchical Nature  of Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sclocchi%2C+A">Antonio Sclocchi</a>, 
<a href="/search/stat?searchtype=author&query=Favero%2C+A">Alessandro Favero</a>, 
<a href="/search/stat?searchtype=author&query=Wyart%2C+M">Matthieu Wyart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1290">[1290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17113" title="Abstract">arXiv:2402.17113</a> (replaced) [<a href="/pdf/2402.17113" title="Download PDF">pdf</a>, <a href="/format/2402.17113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparent Image Layer Diffusion using Latent Transparency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lvmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 37 figures, github.com/layerdiffusion/LayerDiffuse
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1291">[1291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17188" title="Abstract">arXiv:2402.17188</a> (replaced) [<a href="/pdf/2402.17188" title="Download PDF">pdf</a>, <a href="/format/2402.17188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptMM: Multi-Modal Knowledge Distillation for Recommendation with  Prompt-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiabin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangqin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1292">[1292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17204" title="Abstract">arXiv:2402.17204</a> (replaced) [<a href="/pdf/2402.17204" title="Download PDF">pdf</a>, <a href="/format/2402.17204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Generative Model Evaluation: A Novel Algorithm for Realistic  Image Synthesis and Comparison in OCR System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Memari%2C+M">Majid Memari</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+K+R">Khaled R. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+S">Shahram Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Golilarz%2C+N+A">Noorbakhsh Amiri Golilarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript was submitted to IEEE Access on 29-Jan-2024 and is currently under review for publication in IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1293">[1293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17256" title="Abstract">arXiv:2402.17256</a> (replaced) [<a href="/pdf/2402.17256" title="Download PDF">pdf</a>, <a href="/format/2402.17256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pei Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Keqing He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yejie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoshuai Song</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+Y">Yutao Mou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yunsen Xian</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xunliang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiran Xu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1294">[1294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17411" title="Abstract">arXiv:2402.17411</a> (replaced) [<a href="/e-print/2402.17411" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Matters: Explore LLMs Consistency From a Black-Box  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fufangchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Guoqiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Fei Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is not ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1295">[1295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17512" title="Abstract">arXiv:2402.17512</a> (replaced) [<a href="/pdf/2402.17512" title="Download PDF">pdf</a>, <a href="/format/2402.17512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Attention for Linear Time Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dolga%2C+R">Rares Dolga</a>, 
<a href="/search/cs?searchtype=author&query=Cobzarenco%2C+M">Marius Cobzarenco</a>, 
<a href="/search/cs?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1296">[1296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17563" title="Abstract">arXiv:2402.17563</a> (replaced) [<a href="/pdf/2402.17563" title="Download PDF">pdf</a>, <a href="/format/2402.17563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Guided Adversarial Training of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Ling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Haotian Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1297">[1297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17664" title="Abstract">arXiv:2402.17664</a> (replaced) [<a href="/pdf/2402.17664" title="Download PDF">pdf</a>, <a href="/format/2402.17664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Differentiable Physics for Cloth Digitalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Deshan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+N">Ningtao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, to be published in CVPR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1298">[1298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17747" title="Abstract">arXiv:2402.17747</a> (replaced) [<a href="/pdf/2402.17747" title="Download PDF">pdf</a>, <a href="/format/2402.17747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Your AIs Deceive You: Challenges with Partial Observability of  Human Evaluators in Reward Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lang%2C+L">Leon Lang</a>, 
<a href="/search/cs?searchtype=author&query=Foote%2C+D">Davis Foote</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>, 
<a href="/search/cs?searchtype=author&query=Jenner%2C+E">Erik Jenner</a>, 
<a href="/search/cs?searchtype=author&query=Emmons%2C+S">Scott Emmons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1299">[1299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17759" title="Abstract">arXiv:2402.17759</a> (replaced) [<a href="/pdf/2402.17759" title="Download PDF">pdf</a>, <a href="/format/2402.17759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Learning of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuxian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yaru Hao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qingxiu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1300">[1300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17797" title="Abstract">arXiv:2402.17797</a> (replaced) [<a href="/pdf/2402.17797" title="Download PDF">pdf</a>, <a href="/format/2402.17797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Radiance Fields in Medical Imaging: Challenges and Next Steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+H">Hongtu Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1301">[1301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17846" title="Abstract">arXiv:2402.17846</a> (replaced) [<a href="/pdf/2402.17846" title="Download PDF">pdf</a>, <a href="/format/2402.17846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Parameterized Complexity of Motion Planning for Rectangular  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>, 
<a href="/search/cs?searchtype=author&query=Parsa%2C+S">Salman Parsa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item1302">[1302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17862" title="Abstract">arXiv:2402.17862</a> (replaced) [<a href="/pdf/2402.17862" title="Download PDF">pdf</a>, <a href="/format/2402.17862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REPrune: Channel Pruning via Kernel Representative Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+M">Mincheol Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Cheonjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Yuna Park</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+G+E">Gyeong Eun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+W+W">Won Woo Ro</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Suhyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1303">[1303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17887" title="Abstract">arXiv:2402.17887</a> (replaced) [<a href="/pdf/2402.17887" title="Download PDF">pdf</a>, <a href="/format/2402.17887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning  and Professional Question Answering Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1304">[1304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17897" title="Abstract">arXiv:2402.17897</a> (replaced) [<a href="/pdf/2402.17897" title="Download PDF">pdf</a>, <a href="/format/2402.17897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language Model based Framework for New Concept Placement in Ontologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuan He</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yongsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures, accepted for ESWC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1305">[1305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17926" title="Abstract">arXiv:2402.17926</a> (replaced) [<a href="/pdf/2402.17926" title="Download PDF">pdf</a>, <a href="/format/2402.17926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certain and Approximately Certain Models for Statistical Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhen%2C+C">Cheng Zhen</a>, 
<a href="/search/stat?searchtype=author&query=Aryal%2C+N">Nischal Aryal</a>, 
<a href="/search/stat?searchtype=author&query=Termehchy%2C+A">Arash Termehchy</a>, 
<a href="/search/stat?searchtype=author&query=Aghasi%2C+A">Alireza Aghasi</a>, 
<a href="/search/stat?searchtype=author&query=Chabada%2C+A+S">Amandeep Singh Chabada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A technical report for a paper to appear at SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1306">[1306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18007" title="Abstract">arXiv:2402.18007</a> (replaced) [<a href="/pdf/2402.18007" title="Download PDF">pdf</a>, <a href="/format/2402.18007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixer is more than just a model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qingfeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Letong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1307">[1307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18028" title="Abstract">arXiv:2402.18028</a> (replaced) [<a href="/pdf/2402.18028" title="Download PDF">pdf</a>, <a href="/format/2402.18028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenMEDLab: An Open-source Platform for Multi-modality Foundation Models  in Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guotai Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junjun He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhongyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Liang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Q">Qicheng Lao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+T">Tong Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yukun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lifeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Visit <a href="https://github.com/openmedlab">this https URL</a> for more details
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1308">[1308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18064" title="Abstract">arXiv:2402.18064</a> (replaced) [<a href="/pdf/2402.18064" title="Download PDF">pdf</a>, <a href="/format/2402.18064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Testing of Spatially-Dependent Environmental Hypotheses  through Active Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harrison%2C+N">Nicholas Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+N">Nathan Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Sukkarieh%2C+S">Salah Sukkarieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication and presentation at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1309">[1309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18086" title="Abstract">arXiv:2402.18086</a> (replaced) [<a href="/pdf/2402.18086" title="Download PDF">pdf</a>, <a href="/format/2402.18086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Two-Branch Framework for Image Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaobin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruixuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures,accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1310">[1310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18122" title="Abstract">arXiv:2402.18122</a> (replaced) [<a href="/pdf/2402.18122" title="Download PDF">pdf</a>, <a href="/format/2402.18122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G4G:A Generic Framework for High Fidelity Talking Face Generation with  Fine-grained Intra-modal Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+T">Tangquan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1311">[1311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18123" title="Abstract">arXiv:2402.18123</a> (replaced) [<a href="/pdf/2402.18123" title="Download PDF">pdf</a>, <a href="/format/2402.18123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixture calibration with guaranteed bounds from a few  correspondence-free surface points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haugaard%2C+R+L">Rasmus Laurvig Haugaard</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yitaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Iversen%2C+T+M">Thorbj&#xf8;rn Mosekj&#xe6;r Iversen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1312">[1312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18180" title="Abstract">arXiv:2402.18180</a> (replaced) [<a href="/pdf/2402.18180" title="Download PDF">pdf</a>, <a href="/format/2402.18180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Simulacra: A Step toward the Personification of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiuejie Xie</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingqiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuejie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Rui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item1313">[1313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18205" title="Abstract">arXiv:2402.18205</a> (replaced) [<a href="/pdf/2402.18205" title="Download PDF">pdf</a>, <a href="/format/2402.18205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+A">Anjie Le</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tieqiao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+R">Runqiang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liangfan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1314">[1314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18243" title="Abstract">arXiv:2402.18243</a> (replaced) [<a href="/pdf/2402.18243" title="Download PDF">pdf</a>, <a href="/format/2402.18243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning or Self-aligning? Rethinking Instruction Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Boxi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Ke Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Guanglu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xunliang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1315">[1315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18284" title="Abstract">arXiv:2402.18284</a> (replaced) [<a href="/pdf/2402.18284" title="Download PDF">pdf</a>, <a href="/format/2402.18284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of  Pre-trained Language Models with Proximal Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1316">[1316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18351" title="Abstract">arXiv:2402.18351</a> (replaced) [<a href="/pdf/2402.18351" title="Download PDF">pdf</a>, <a href="/format/2402.18351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatentSwap: An Efficient Latent Code Mapping Framework for Face Swapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Changho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junhyeok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hyoung-Kyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Younggeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1317">[1317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18445" title="Abstract">arXiv:2402.18445</a> (replaced) [<a href="/pdf/2402.18445" title="Download PDF">pdf</a>, <a href="/format/2402.18445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperFedNet: Communication-Efficient Personalized Federated Learning Via  Hypernetwork
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhenzhen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Junjie Pang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item1318">[1318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18590" title="Abstract">arXiv:2402.18590</a> (replaced) [<a href="/pdf/2402.18590" title="Download PDF">pdf</a>, <a href="/ps/2402.18590" title="Download PostScript">ps</a>, <a href="/format/2402.18590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Large Language Models on Recommender Systems: An  Extensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+A">Arpita Vats</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+R">Rahul Raja</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1319">[1319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18607" title="Abstract">arXiv:2402.18607</a> (replaced) [<a href="/pdf/2402.18607" title="Download PDF">pdf</a>, <a href="/format/2402.18607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An  Adversarial Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xinjian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangfan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1320">[1320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18679" title="Abstract">arXiv:2402.18679</a> (replaced) [<a href="/pdf/2402.18679" title="Download PDF">pdf</a>, <a href="/format/2402.18679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Interpreter: An LLM Agent For Data Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sirui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yizhang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bangbang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuge%2C+M">Mingchen Zhuge</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Taicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tuo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiangtao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinbing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Y">Yaying Fei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zongze Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenglin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1321">[1321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18775" title="Abstract">arXiv:2402.18775</a> (replaced) [<a href="/e-print/2402.18775" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Evaluate Human-likeness of Interaction-aware Driver Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jemin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+C">Changsun Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper could benefit from further refinement to enhance the significance of its results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1322">[1322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18781" title="Abstract">arXiv:2402.18781</a> (replaced) [<a href="/pdf/2402.18781" title="Download PDF">pdf</a>, <a href="/ps/2402.18781" title="Download PostScript">ps</a>, <a href="/format/2402.18781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conjectural Online Learning with First-order Beliefs in Asymmetric  Information Stochastic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hammar%2C+K">Kim Hammar</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+R">Rolf Stadler</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1323">[1323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18839" title="Abstract">arXiv:2402.18839</a> (replaced) [<a href="/pdf/2402.18839" title="Download PDF">pdf</a>, <a href="/format/2402.18839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Flow Matching: a Method of Conditional Generation with  Generalized Continuity Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isobe%2C+N">Noboru Isobe</a>, 
<a href="/search/cs?searchtype=author&query=Koyama%2C+M">Masanori Koyama</a>, 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+K">Kohei Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Fukumizu%2C+K">Kenji Fukumizu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Functional Analysis (math.FA); Optimization and Control (math.OC); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1324">[1324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18919" title="Abstract">arXiv:2402.18919</a> (replaced) [<a href="/pdf/2402.18919" title="Download PDF">pdf</a>, <a href="/format/2402.18919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decompose-and-Compose: A Compositional Approach to Mitigating Spurious  Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noohdani%2C+F+H">Fahimeh Hosseini Noohdani</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+P">Parsa Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Parast%2C+A+Y">Aryan Yazdan Parast</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+H+Y">Hamidreza Yaghoubi Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Baghshah%2C+M+S">Mahdieh Soleymani Baghshah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1325">[1325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18920" title="Abstract">arXiv:2402.18920</a> (replaced) [<a href="/pdf/2402.18920" title="Download PDF">pdf</a>, <a href="/format/2402.18920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Dongliang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Eisenberger%2C+M">Marvin Eisenberger</a>, 
<a href="/search/cs?searchtype=author&query=Amrani%2C+N+E">Nafie El Amrani</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item1326">[1326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19047" title="Abstract">arXiv:2402.19047</a> (replaced) [<a href="/pdf/2402.19047" title="Download PDF">pdf</a>, <a href="/format/2402.19047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Foundations of Deep Selective State-Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cirone%2C+N+M">Nicola Muca Cirone</a>, 
<a href="/search/cs?searchtype=author&query=Orvieto%2C+A">Antonio Orvieto</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+B">Benjamin Walker</a>, 
<a href="/search/cs?searchtype=author&query=Salvi%2C+C">Cristopher Salvi</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item1327">[1327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19080" title="Abstract">arXiv:2402.19080</a> (replaced) [<a href="/pdf/2402.19080" title="Download PDF">pdf</a>, <a href="/format/2402.19080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput,  Energy-Efficient and Programmer-Transparent Multiple-Instruction  Multiple-Data Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fl%C4%B1k%C3%A7%C4%B1%2C+A+G">Abdullah Giray Ya&#x11f;l&#x131;k&#xe7;&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Bostanc%C4%B1%2C+F+N">F. Nisa Bostanc&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Luna%2C+J">Juan G&#xf3;mez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Ghose%2C+S">Saugata Ghose</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of HPCA 2024 paper. arXiv admin note: text overlap with <a href="/abs/2109.05881">arXiv:2109.05881</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item1328">[1328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19116" title="Abstract">arXiv:2402.19116</a> (replaced) [<a href="/pdf/2402.19116" title="Download PDF">pdf</a>, <a href="/format/2402.19116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Understand &quot;Support&quot;? An Implicit-enhanced Causal Inference  Approach for Weakly-supervised Phrase Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiamin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guodong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1329">[1329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19248" title="Abstract">arXiv:2402.19248</a> (replaced) [<a href="/pdf/2402.19248" title="Download PDF">pdf</a>, <a href="/format/2402.19248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question  Answering Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhikun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ruixue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenlian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1330">[1330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19282" title="Abstract">arXiv:2402.19282</a> (replaced) [<a href="/pdf/2402.19282" title="Download PDF">pdf</a>, <a href="/format/2402.19282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiantao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Haijun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenjiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+W">Wenchang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">ChaoBin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P">Pei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lindong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Runyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huanze Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhikai Lei</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiawei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhaoye Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruiliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhongyin Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1331">[1331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19341" title="Abstract">arXiv:2402.19341</a> (replaced) [<a href="/pdf/2402.19341" title="Download PDF">pdf</a>, <a href="/format/2402.19341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoadRunner - Learning Traversability Estimation for Autonomous Off-road  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frey%2C+J">Jonas Frey</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+S">Shehryar Khattak</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Manthan Patel</a>, 
<a href="/search/cs?searchtype=author&query=Atha%2C+D">Deegan Atha</a>, 
<a href="/search/cs?searchtype=author&query=Nubert%2C+J">Julian Nubert</a>, 
<a href="/search/cs?searchtype=author&query=Padgett%2C+C">Curtis Padgett</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Spieler%2C+P">Patrick Spieler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review for Field Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1332">[1332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19405" title="Abstract">arXiv:2402.19405</a> (replaced) [<a href="/pdf/2402.19405" title="Download PDF">pdf</a>, <a href="/format/2402.19405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Hallucinations for Reasoning of Unintentional Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grover%2C+S">Shresth Grover</a>, 
<a href="/search/cs?searchtype=author&query=Vineet%2C+V">Vibhav Vineet</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+Y+S">Yogesh S Rawat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1333">[1333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19406" title="Abstract">arXiv:2402.19406</a> (replaced) [<a href="/pdf/2402.19406" title="Download PDF">pdf</a>, <a href="/format/2402.19406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Scaling Laws of Geographical Representation in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godey%2C+N">Nathan Godey</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Clergerie%2C+%C3%89">&#xc9;ric de la Clergerie</a>, 
<a href="/search/cs?searchtype=author&query=Sagot%2C+B">Beno&#xee;t Sagot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1334">[1334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00033" title="Abstract">arXiv:2403.00033</a> (replaced) [<a href="/pdf/2403.00033" title="Download PDF">pdf</a>, <a href="/format/2403.00033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Craving Maps among Marijuana Users via Analysis of  Functional Brain Networks with High-Order Attention Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+J">Jun-En Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+S">Shihao Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zilverstand%2C+A">Anna Zilverstand</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+F">Feng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1335">[1335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00049" title="Abstract">arXiv:2403.00049</a> (replaced) [<a href="/pdf/2403.00049" title="Download PDF">pdf</a>, <a href="/format/2403.00049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEXterity - Tactile Extrinsic deXterity: Simultaneous Tactile Estimation  and Control for Extrinsic Dexterity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangwoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bronars%2C+A">Antonia Bronars</a>, 
<a href="/search/cs?searchtype=author&query=Patre%2C+P">Parag Patre</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+A">Alberto Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project website: <a href="https://sites.google.com/view/texterity.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2401.10230">arXiv:2401.10230</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1336">[1336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00106" title="Abstract">arXiv:2403.00106</a> (replaced) [<a href="/pdf/2403.00106" title="Download PDF">pdf</a>, <a href="/format/2403.00106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Umwelt: Accessible Structured Editing of Multimodal Data Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+J">Jonathan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Pineros%2C+I+P">Isabella Pedraza Pineros</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M+K">Mengzhu Katie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hajas%2C+D">Daniel Hajas</a>, 
<a href="/search/cs?searchtype=author&query=Satyanarayan%2C+A">Arvind Satyanarayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1337">[1337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00231" title="Abstract">arXiv:2403.00231</a> (replaced) [<a href="/pdf/2403.00231" title="Download PDF">pdf</a>, <a href="/format/2403.00231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of  Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiachong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://mm-arxiv.github.io">this https URL</a> Fix typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1338">[1338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00246" title="Abstract">arXiv:2403.00246</a> (replaced) [<a href="/pdf/2403.00246" title="Download PDF">pdf</a>, <a href="/ps/2403.00246" title="Download PostScript">ps</a>, <a href="/format/2403.00246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Phylogeny Tracking Algorithms for Serial and Multiprocess  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreno%2C+M+A">Matthew Andres Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Papa%2C+S+R">Santiago Rodriguez Papa</a>, 
<a href="/search/cs?searchtype=author&query=Dolson%2C+E">Emily Dolson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item1339">[1339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00326" title="Abstract">arXiv:2403.00326</a> (replaced) [<a href="/pdf/2403.00326" title="Download PDF">pdf</a>, <a href="/format/2403.00326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAMS-DETR: Dynamic Adaptive Multispectral Detection Transformer with  Competitive Query Selection and Adaptive Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junjie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chenqiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangcen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1340">[1340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00459" title="Abstract">arXiv:2403.00459</a> (replaced) [<a href="/pdf/2403.00459" title="Download PDF">pdf</a>, <a href="/format/2403.00459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable One-shot Face Stylization via DINO Semantic Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zichong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024. Project page: <a href="https://github.com/zichongc/DoesFS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1341">[1341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00510" title="Abstract">arXiv:2403.00510</a> (replaced) [<a href="/pdf/2403.00510" title="Download PDF">pdf</a>, <a href="/format/2403.00510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROME: Memorization Insights from Text, Probability and Hidden State in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinghua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ACL, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1342">[1342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00692" title="Abstract">arXiv:2403.00692</a> (replaced) [<a href="/pdf/2403.00692" title="Download PDF">pdf</a>, <a href="/format/2403.00692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Autonomous Cooperation in Heterogeneous Nanosatellite  Constellations Using Dynamic Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Casadesus-Vila%2C+G">Guillem Casadesus-Vila</a>, 
<a href="/search/eess?searchtype=author&query=Ruiz-de-Azua%2C+J">Joan-Adria Ruiz-de-Azua</a>, 
<a href="/search/eess?searchtype=author&query=Alarcon%2C+E">Eduard Alarcon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item757">Cross-lists</a></li>
<li><a href="#item847">Replacements</a></li>
</ul>
<small>[ total of 1342 entries:  <b>1-1342</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2403">2403</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
