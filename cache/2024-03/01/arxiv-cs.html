<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 28 Feb 24  to  Thu 29 Feb 24, announced Fri,  1 Mar 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item381">Cross-lists</a></li>
<li><a href="#item428">Replacements</a></li>
</ul>
<small>[ total of 689 entries:  <b>1-689</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri,  1 Mar 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18576" title="Abstract">arXiv:2402.18576</a> [<a href="/pdf/2402.18576" title="Download PDF">pdf</a>, <a href="/ps/2402.18576" title="Download PostScript">ps</a>, <a href="/format/2402.18576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aribe%2C+S">Sales Aribe Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, Published with International Journal of Engineering Trends and Technology (IJETT)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Engineering Trends and Technology, vol.
  72, no. 1, pp. 11-19, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Decision making and planning have long relied heavily on AI-driven forecasts.
The government and the general public are working to minimize the risks while
maximizing benefits in the face of potential future public health
uncertainties. This study used an improved method of forecasting utilizing the
Random Descending Velocity Inertia Weight (RDV IW) technique to improve the
convergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial
Neural Network (ANN). The IW technique, inspired by the motions of a golf ball,
modified the particles' velocities as they approached the solution point to a
parabolically descending structure. Simulation results revealed that the
proposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump
exhibits a 6.36% improvement in position error and 11.75% improvement in
computational time compared to the old model, thus, improving its convergence.
It reached the optimum level at minimal steps with 12.50% improvement as
against the old model since it provides better velocity averages when speed
stabilization occurs at the 24th iteration. Meanwhile, the computed p-values
for NRMSE (0.04889174), MAE (0.02829063), MAPE (0.02226053), WAPE (0.01701545),
and R2 (0.00000021) of the proposed algorithm are less than the set 0.05 level
of significance, thus the values indicated a significant result in terms of
accuracy performance. Applying the modified ANN-PSO using RDV IW technique
greatly improved the new HIV/AIDS forecasting model compared with the two
models.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18577" title="Abstract">arXiv:2402.18577</a> [<a href="/pdf/2402.18577" title="Download PDF">pdf</a>, <a href="/format/2402.18577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Guided Token Compression for Efficient Masked Video Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yukun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tan Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent developments in Transformers have achieved notable strides in
enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity
associated with attention mechanisms presents substantial computational hurdles
when dealing with the high dimensionality of videos. This challenge becomes
particularly pronounced when striving to increase the frames per second (FPS)
to enhance the motion capturing capabilities. Such a pursuit is likely to
introduce redundancy and exacerbate the existing computational limitations. In
this paper, we initiate by showcasing the enhanced performance achieved through
an escalation in the FPS rate. Additionally, we present a novel approach,
Motion Guided Token Compression (MGTC), to empower Transformer models to
utilize a smaller yet more representative set of tokens for comprehensive video
representation. Consequently, this yields substantial reductions in
computational burden and remains seamlessly adaptable to increased FPS rates.
Specifically, we draw inspiration from video compression algorithms and
scrutinize the variance between patches in consecutive video frames across the
temporal dimension. The tokens exhibiting a disparity below a predetermined
threshold are then masked. Notably, this masking strategy effectively addresses
video redundancy while conserving essential information. Our experiments,
conducted on widely examined video recognition datasets, Kinetics-400, UCF101
and HMDB51, demonstrate that elevating the FPS rate results in a significant
top-1 accuracy score improvement of over 1.6, 1.6 and 4.0. By implementing MGTC
with the masking ratio of 25\%, we further augment accuracy by 0.1 and
simultaneously reduce computational costs by over 31\% on Kinetics-400. Even
within a fixed computational budget, higher FPS rates paired with MGTC sustain
performance gains when compared to lower FPS settings.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18579" title="Abstract">arXiv:2402.18579</a> [<a href="/pdf/2402.18579" title="Download PDF">pdf</a>, <a href="/ps/2402.18579" title="Download PostScript">ps</a>, <a href="/format/2402.18579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangwei Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Applications (stat.AP)

</div>
<p class="mathjax">The parametric constant false alarm rate (CFAR) detection algorithms which
are based on various statistical distributions, such as Gaussian, Gamma,
Weibull, log-normal, G0 distribution, alpha-stable distribution, etc, are most
widely used to detect the ship targets in SAR image at present. However, the
clutter background in SAR images is complicated and variable. When the actual
clutter background deviates from the assumed statistical distribution, the
performance of the parametric CFAR detector will deteriorate. In addition to
the parametric CFAR schemes, there is another class of nonparametric CFAR
detectors which can maintain a constant false alarm rate for the target
detection without the assumption of a known clutter distribution. In this work,
the Wilcoxon nonparametric CFAR scheme for ship detection in SAR image is
proposed and analyzed, and a closed form of the false alarm rate for the
Wilcoxon nonparametric detector to determine the decision threshold is
presented. By comparison with several typical parametric CFAR schemes on
Radarsat-2, ICEYE-X6 and Gaofen-3 SAR images, the robustness of the Wilcoxon
nonparametric detector to maintain a good false alarm performance in different
detection backgrounds is revealed, and its detection performance for the weak
ship in rough sea surface is improved to some extent. Moreover, the Wilcoxon
nonparametric detector can suppress the false alarms resulting from the
sidelobes at some degree and its detection speed is fast.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18581" title="Abstract">arXiv:2402.18581</a> [<a href="/pdf/2402.18581" title="Download PDF">pdf</a>, <a href="/format/2402.18581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-objective Optimal Roadside Units Deployment in Urban Vehicular  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zecheng Kang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript has been submitted to the journal of IEEE Transactions on Vehicular Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The significance of transportation efficiency, safety, and related services
is increasing in urban vehicular networks. Within such networks, roadside units
(RSUs) serve as intermediates in facilitating communication. Therefore, the
deployment of RSUs is of utmost importance in ensuring the quality of
communication services. However, the optimization objectives, such as time
delay and deployment cost, are commonly developed from diverse perspectives. As
a result, it is possible that conflicts may arise among the objectives.
Furthermore, in urban environments, the presence of various obstacles, such as
buildings, gardens, lakes, and other infrastructure, poses challenges for the
deployment of RSUs. Hence, the deployment encounters significant difficulties
due to the existence of multiple objectives, constraints imposed by obstacles,
and the necessity to explore a large-scale optimization space. To address this
issue, two versions of multi-objective optimization algorithms are proposed in
this paper. By utilizing a multi-population strategy and an adaptive
exploration technique, the methods efficiently explore a large-scale
decision-variable space. In order to mitigate the issue of an overcrowded
deployment of RSUs, a calibrating mechanism is adopted to adjust RSU density
during the optimization procedures. The proposed methods also take care of data
offloading between vehicles and RSUs by setting up an iterative best response
sequence game (IBRSG). By comparing the proposed algorithms with several
state-of-the-art algorithms, the results demonstrate that our strategies
perform better in both high-density and low-density urban scenarios. The
results also indicate that the proposed solutions substantially improve the
efficiency of vehicular networks.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18582" title="Abstract">arXiv:2402.18582</a> [<a href="/pdf/2402.18582" title="Download PDF">pdf</a>, <a href="/ps/2402.18582" title="Download PostScript">ps</a>, <a href="/format/2402.18582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streamlining the Selection Phase of Systematic Literature Reviews (SLRs)  Using AI-Enabled GPT-4 Assistant API
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jafari%2C+S+M+A">Seyed Mohammad Ali Jafari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The escalating volume of academic literature presents a formidable challenge
in staying updated with the newest research developments. Addressing this, this
study introduces a pioneering AI-based tool, configured specifically to
streamline the efficiency of the article selection phase in Systematic
Literature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4
Assistant API, the tool successfully homogenizes the article selection process
across a broad array of academic disciplines. Implemented through a tripartite
approach consisting of data preparation, AI-mediated article assessment, and
structured result presentation, this tool significantly accelerates the
time-consuming task of literature reviews. Importantly, this tool could be
highly beneficial in fields such as management and economics, where the SLR
process involves substantial human judgment. The adoption of a standard GPT
model can substantially reduce potential biases and enhance the speed and
precision of the SLR selection phase. This not only amplifies researcher
productivity and accuracy but also denotes a considerable stride forward in the
way academic research is conducted amidst the surging body of scholarly
publications.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18584" title="Abstract">arXiv:2402.18584</a> [<a href="/pdf/2402.18584" title="Download PDF">pdf</a>, <a href="/format/2402.18584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjusting Dynamics of Hopfield Neural Network via Time-variant Stimulus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xuenan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yicheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chun-Lai Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">As a paradigmatic model for nonlinear dynamics studies, the Hopfield Neural
Network (HNN) demonstrates a high susceptibility to external disturbances owing
to its intricate structure. This paper delves into the challenge of modulating
HNN dynamics through time-variant stimuli. The effects of adjustments using two
distinct types of time-variant stimuli, namely the Weight Matrix Stimulus (WMS)
and the State Variable Stimulus (SVS), along with a Constant Stimulus (CS) are
reported. The findings reveal that deploying four WMSs enables the HNN to
generate either a four-scroll or a coexisting two-scroll attractor. When
combined with one SVS, four WMSs can lead to the formation of an eight-scroll
or four-scroll attractor, while the integration of four WMSs and multiple SVSs
can induce grid-multi-scroll attractors. Moreover, the introduction of a CS and
an SVS can significantly disrupt the dynamic behavior of the HNN. Consequently,
suitable adjustment methods are crucial for enhancing the network's dynamics,
whereas inappropriate applications can lead to the loss of its chaotic
characteristics. To empirically validate these enhancement effects, the study
employs an FPGA hardware platform. Subsequently, an image encryption scheme is
designed to demonstrate the practical application benefits of the dynamically
adjusted HNN in secure multimedia communication. This exploration into the
dynamic modulation of HNN via time-variant stimuli offers insightful
contributions to the advancement of secure communication technologies.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18587" title="Abstract">arXiv:2402.18587</a> [<a href="/pdf/2402.18587" title="Download PDF">pdf</a>, <a href="/format/2402.18587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers  in 6G Wireless Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celik%2C+A">Abdulkadir Celik</a>, 
<a href="/search/cs?searchtype=author&query=Eltawil%2C+A+M">Ahmed M. Eltawil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The majority of data-driven wireless research leans heavily on discriminative
AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI
(GenAI) pertains to generative models (GMs) capable of discerning the
underlying data distribution, patterns, and features of the input data. This
makes GenAI a crucial asset in wireless domain wherein real-world data is often
scarce, incomplete, costly to acquire, and hard to model or comprehend. With
these appealing attributes, GenAI can replace or supplement DAI methods in
various capacities. Accordingly, this combined tutorial-survey paper commences
with preliminaries of 6G and wireless intelligence by outlining candidate 6G
applications and services, presenting a taxonomy of state-of-the-art DAI
models, exemplifying prominent DAI use cases, and elucidating the multifaceted
ways through which GenAI enhances DAI. Subsequently, we present a tutorial on
GMs by spotlighting seminal examples such as generative adversarial networks,
variational autoencoders, flow-based GMs, diffusion-based GMs, generative
transformers, large language models, to name a few. Contrary to the prevailing
belief that GenAI is a nascent trend, our exhaustive review of approximately
120 technical papers demonstrates the scope of research across core wireless
research areas, including physical layer design; network optimization,
organization, and management; network traffic analytics; cross-layer network
security; and localization &amp; positioning. Furthermore, we outline the central
role of GMs in pioneering areas of 6G network research, including
semantic/THz/near-field communications, ISAC, extremely large antenna arrays,
digital twins, AI-generated content services, mobile edge computing and edge
AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the
multifarious challenges ahead, suggesting potential strategies and promising
remedies.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18589" title="Abstract">arXiv:2402.18589</a> [<a href="/pdf/2402.18589" title="Download PDF">pdf</a>, <a href="/format/2402.18589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verif.ai: Towards an Open-Source Scientific Generative  Question-Answering System with Referenced and Verifiable Answers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%C5%A1prdi%C4%87%2C+M">Milo&#x161; Ko&#x161;prdi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Ljaji%C4%87%2C+A">Adela Ljaji&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Ba%C5%A1aragin%2C+B">Bojana Ba&#x161;aragin</a>, 
<a href="/search/cs?searchtype=author&query=Medvecki%2C+D">Darija Medvecki</a>, 
<a href="/search/cs?searchtype=author&query=Milo%C5%A1evi%C4%87%2C+N">Nikola Milo&#x161;evi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a short paper at The Sixteenth International Conference on Evolving Internet (INTERNET 2024)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Sixteenth International Conference on Evolving Internet
  (INTERNET 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we present the current progress of the project Verif.ai, an
open-source scientific generative question-answering system with referenced and
verified answers. The components of the system are (1) an information retrieval
system combining semantic and lexical search techniques over scientific papers
(PubMed), (2) a fine-tuned generative model (Mistral 7B) taking top answers and
generating answers with references to the papers from which the claim was
derived, and (3) a verification engine that cross-checks the generated claim
and the abstract or paper from which the claim was derived, verifying whether
there may have been any hallucinations in generating the claim. We are
reinforcing the generative model by providing the abstract in context, but in
addition, an independent set of methods and models are verifying the answer and
checking for hallucinations. Therefore, we believe that by using our method, we
can make scientists more productive, while building trust in the use of
generative language models in scientific environments, where hallucinations and
misinformation cannot be tolerated.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18590" title="Abstract">arXiv:2402.18590</a> [<a href="/pdf/2402.18590" title="Download PDF">pdf</a>, <a href="/ps/2402.18590" title="Download PostScript">ps</a>, <a href="/format/2402.18590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Large Language Models on Recommender Systems: An  Extensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+A">Arpita Vats</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+R">Rahul Raja</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The paper underscores the significance of Large Language Models (LLMs) in
reshaping recommender systems, attributing their value to unique reasoning
abilities absent in traditional recommenders. Unlike conventional systems
lacking direct user interaction data, LLMs exhibit exceptional proficiency in
recommending items, showcasing their adeptness in comprehending intricacies of
language. This marks a fundamental paradigm shift in the realm of
recommendations. Amidst the dynamic research landscape, researchers actively
harness the language comprehension and generation capabilities of LLMs to
redefine the foundations of recommendation tasks. The investigation thoroughly
explores the inherent strengths of LLMs within recommendation frameworks,
encompassing nuanced contextual comprehension, seamless transitions across
diverse domains, adoption of unified approaches, holistic learning strategies
leveraging shared data reservoirs, transparent decision-making, and iterative
improvements. Despite their transformative potential, challenges persist,
including sensitivity to input prompts, occasional misinterpretations, and
unforeseen recommendations, necessitating continuous refinement and evolution
in LLM-driven recommender systems.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18591" title="Abstract">arXiv:2402.18591</a> [<a href="/pdf/2402.18591" title="Download PDF">pdf</a>, <a href="/ps/2402.18591" title="Download PostScript">ps</a>, <a href="/format/2402.18591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic contextual bandits with graph feedback: from independence  number to MAS number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuxiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yanjun Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Statistics Theory (math.ST)

</div>
<p class="mathjax">We consider contextual bandits with graph feedback, a class of interactive
learning problems with richer structures than vanilla contextual bandits, where
taking an action reveals the rewards for all neighboring actions in the
feedback graph under all contexts. Unlike the multi-armed bandits setting where
a growing literature has painted a near-complete understanding of graph
feedback, much remains unexplored in the contextual bandits counterpart. In
this paper, we make inroads into this inquiry by establishing a regret lower
bound $\Omega(\sqrt{\beta_M(G) T})$, where $M$ is the number of contexts, $G$
is the feedback graph, and $\beta_M(G)$ is our proposed graph-theoretical
quantity that characterizes the fundamental learning limit for this class of
problems. Interestingly, $\beta_M(G)$ interpolates between $\alpha(G)$ (the
independence number of the graph) and $\mathsf{m}(G)$ (the maximum acyclic
subgraph (MAS) number of the graph) as the number of contexts $M$ varies. We
also provide algorithms that achieve near-optimal regrets for important classes
of context sequences and/or feedback graphs, such as transitively closed graphs
that find applications in auctions and inventory control. In particular, with
many contexts, our results show that the MAS number completely characterizes
the statistical complexity for contextual bandits, as opposed to the
independence number in multi-armed bandits.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18592" title="Abstract">arXiv:2402.18592</a> [<a href="/pdf/2402.18592" title="Download PDF">pdf</a>, <a href="/format/2402.18592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A$^3$PIM: An Automated, Analytic and Accurate Processing-in-Memory  Offloader
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qingcai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shaojie Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junshi Chen</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Hong An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, accepted for presentation at Design, Automation and Test in Europe Conference | The European Event for Electronic System Design &amp; Test (DATE 2024), conference to be held in March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The performance gap between memory and processor has grown rapidly.
Consequently, the energy and wall-clock time costs associated with moving data
between the CPU and main memory predominate the overall computational cost. The
Processing-in-Memory (PIM) paradigm emerges as a promising architecture that
mitigates the need for extensive data movements by strategically positioning
computing units proximate to the memory. Despite the abundant efforts devoted
to building a robust and highly-available PIM system, identifying PIM-friendly
segments of applications poses significant challenges due to the lack of a
comprehensive tool to evaluate the intrinsic memory access pattern of the
segment.
<br />To tackle this challenge, we propose A$^3$PIM: an Automated, Analytic and
Accurate Processing-in-Memory offloader. We systematically consider the
cross-segment data movement and the intrinsic memory access pattern of each
code segment via static code analyzer. We evaluate A$^3$PIM across a wide range
of real-world workloads including GAP and PrIM benchmarks and achieve an
average speedup of 2.63x and 4.45x (up to 7.14x and 10.64x) when compared to
CPU-only and PIM-only executions, respectively.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18593" title="Abstract">arXiv:2402.18593</a> [<a href="/pdf/2402.18593" title="Download PDF">pdf</a>, <a href="/format/2402.18593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Samsi%2C+S">Siddharth Samsi</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+J">Joseph McDonald</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baolin Li</a>, 
<a href="/search/cs?searchtype=author&query=Bestor%2C+D">David Bestor</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Michael Jones</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+D">Devesh Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Gadepally%2C+V">Vijay Gadepally</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">As research and deployment of AI grows, the computational burden to support
and sustain its progress inevitably does too. To train or fine-tune
state-of-the-art models in NLP, computer vision, etc., some form of AI hardware
acceleration is virtually a requirement. Recent large language models require
considerable resources to train and deploy, resulting in significant energy
usage, potential carbon emissions, and massive demand for GPUs and other
hardware accelerators. However, this surge carries large implications for
energy sustainability at the HPC/datacenter level. In this paper, we study the
aggregate effect of power-capping GPUs on GPU temperature and power draw at a
research supercomputing center. With the right amount of power-capping, we show
significant decreases in both temperature and power draw, reducing power
consumption and potentially improving hardware life-span with minimal impact on
job performance. While power-capping reduces power draw by design, the
aggregate system-wide effect on overall energy consumption is less clear; for
instance, if users notice job performance degradation from GPU power-caps, they
may request additional GPU-jobs to compensate, negating any energy savings or
even worsening energy consumption. To our knowledge, our work is the first to
conduct and make available a detailed analysis of the effects of GPU
power-capping at the supercomputing scale. We hope our work will inspire
HPCs/datacenters to further explore, evaluate, and communicate the impact of
power-capping AI hardware accelerators for more sustainable AI.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18595" title="Abstract">arXiv:2402.18595</a> [<a href="/pdf/2402.18595" title="Download PDF">pdf</a>, <a href="/format/2402.18595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EncodingNet: A Novel Encoding-based MAC Design for Efficient Neural  Network Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G+L">Grace Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Schlichtmann%2C+U">Ulf Schlichtmann</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural networks (DNNs) have achieved great breakthroughs in many fields
such as image classification and natural language processing. However, the
execution of DNNs needs to conduct massive numbers of multiply-accumulate (MAC)
operations on hardware and thus incurs a large power consumption. To address
this challenge, we propose a novel digital MAC design based on encoding. In
this new design, the multipliers are replaced by simple logic gates to project
the results onto a wide bit representation. These bits carry individual
position weights, which can be trained for specific neural networks to enhance
inference accuracy. The outputs of the new multipliers are added by bit-wise
weighted accumulation and the accumulation results are compatible with existing
computing platforms accelerating neural networks with either uniform or
non-uniform quantization. Since the multiplication function is replaced by
simple logic projection, the critical paths in the resulting circuits become
much shorter. Correspondingly, pipelining stages in the MAC array can be
reduced, leading to a significantly smaller area as well as a better power
efficiency. The proposed design has been synthesized and verified by
ResNet18-Cifar10, ResNet20-Cifar100 and ResNet50-ImageNet. The experimental
results confirmed the reduction of circuit area by up to 79.63% and the
reduction of power consumption of executing DNNs by up to 70.18%, while the
accuracy of the neural networks can still be well maintained.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18596" title="Abstract">arXiv:2402.18596</a> [<a href="/pdf/2402.18596" title="Download PDF">pdf</a>, <a href="/format/2402.18596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-To-Mesh Conversion for Biomedical Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drakopoulos%2C+F">Fotis Drakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Garner%2C+K">Kevin Garner</a>, 
<a href="/search/cs?searchtype=author&query=Rector%2C+C">Christopher Rector</a>, 
<a href="/search/cs?searchtype=author&query=Chrisochoides%2C+N">Nikos Chrisochoides</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Converting a three-dimensional medical image into a 3D mesh that satisfies
both the quality and fidelity constraints of predictive simulations and
image-guided surgical procedures remains a critical problem. Presented is an
image-to-mesh conversion method called CBC3D. It first discretizes a segmented
image by generating an adaptive Body-Centered Cubic (BCC) mesh of high-quality
elements. Next, the tetrahedral mesh is converted into a mixed-element mesh of
tetrahedra, pentahedra, and hexahedra to decrease element count while
maintaining quality. Finally, the mesh surfaces are deformed to their
corresponding physical image boundaries, improving the mesh's fidelity. The
deformation scheme builds upon the ITK open-source library and is based on the
concept of energy minimization, relying on a multi-material point-based
registration. It uses non-connectivity patterns to implicitly control the
number of extracted feature points needed for the registration and, thus,
adjusts the trade-off between the achieved mesh fidelity and the deformation
speed. We compare CBC3D with four widely used and state-of-the-art homegrown
image-to-mesh conversion methods from industry and academia. Results indicate
that the CBC3D meshes (i) achieve high fidelity, (ii) keep the element count
reasonably low, and (iii) exhibit good element quality.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18599" title="Abstract">arXiv:2402.18599</a> [<a href="/pdf/2402.18599" title="Download PDF">pdf</a>, <a href="/format/2402.18599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Tasks: An alternative view on Meta-Learning Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>, 
<a href="/search/cs?searchtype=author&query=Faysal%2C+A">Atik Faysal</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+A">Avimanyu Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Antle%2C+R">Ryan Antle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Few-shot learning (FSL) is a challenging machine learning problem due to a
scarcity of labeled data. The ability to generalize effectively on both novel
and training tasks is a significant barrier to FSL. This paper proposes a novel
solution that can generalize to both training and novel tasks while also
utilizing unlabeled samples. The method refines the embedding model before
updating the outer loop using unsupervised techniques as ``meta-tasks''. The
experimental results show that our proposed method performs well on novel and
training tasks, with faster and better convergence, lower generalization, and
standard deviation error, indicating its potential for practical applications
in FSL. The experimental results show that the proposed method outperforms
prototypical networks by 3.9%.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18603" title="Abstract">arXiv:2402.18603</a> [<a href="/pdf/2402.18603" title="Download PDF">pdf</a>, <a href="/format/2402.18603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMSR: Symbolic Regression is a Multimodal Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lina Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+M">Meilan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Su Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yusong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 page
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Mathematical formulas are the crystallization of human wisdom in exploring
the laws of nature for thousands of years. Describing the complex laws of
nature with a concise mathematical formula is a constant pursuit of scientists
and a great challenge for artificial intelligence. This field is called
symbolic regression. Symbolic regression was originally formulated as a
combinatorial optimization problem, and GP and reinforcement learning
algorithms were used to solve it. However, GP is sensitive to hyperparameters,
and these two types of algorithms are inefficient. To solve this problem,
researchers treat the mapping from data to expressions as a translation
problem. And the corresponding large-scale pre-trained model is introduced.
However, the data and expression skeletons do not have very clear word
correspondences as the two languages do. Instead, they are more like two
modalities (e.g., image and text). Therefore, in this paper, we proposed MMSR.
The SR problem is solved as a pure multimodal problem, and contrastive learning
is also introduced in the training process for modal alignment to facilitate
later modal feature fusion. It is worth noting that in order to better promote
the modal feature fusion, we adopt the strategy of training contrastive
learning loss and other losses at the same time, which only needs one-step
training, instead of training contrastive learning loss first and then training
other losses. Because our experiments prove training together can make the
feature extraction module and feature fusion module running-in better.
Experimental results show that compared with multiple large-scale pre-training
baselines, MMSR achieves the most advanced results on multiple mainstream
datasets including SRBench.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18605" title="Abstract">arXiv:2402.18605</a> [<a href="/pdf/2402.18605" title="Download PDF">pdf</a>, <a href="/format/2402.18605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FORML: A Riemannian Hessian-free Method for Meta-learning with  Orthogonality Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabealhojeh%2C+H">Hadi Tabealhojeh</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Soumava Kumar Roy</a>, 
<a href="/search/cs?searchtype=author&query=Adibi%2C+P">Peyman Adibi</a>, 
<a href="/search/cs?searchtype=author&query=Karshenas%2C+H">Hossein Karshenas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Meta-learning problem is usually formulated as a bi-level optimization in
which the task-specific and the meta-parameters are updated in the inner and
outer loops of optimization, respectively. However, performing the optimization
in the Riemannian space, where the parameters and meta-parameters are located
on Riemannian manifolds is computationally intensive. Unlike the Euclidean
methods, the Riemannian backpropagation needs computing the second-order
derivatives that include backward computations through the Riemannian operators
such as retraction and orthogonal projection. This paper introduces a
Hessian-free approach that uses a first-order approximation of derivatives on
the Stiefel manifold. Our method significantly reduces the computational load
and memory footprint. We show how using a Stiefel fully-connected layer that
enforces orthogonality constraint on the parameters of the last classification
layer as the head of the backbone network, strengthens the representation reuse
of the gradient-based meta-learning methods. Our experimental results across
various few-shot learning datasets, demonstrate the superiority of our proposed
method compared to the state-of-the-art methods, especially MAML, its Euclidean
counterpart.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18606" title="Abstract">arXiv:2402.18606</a> [<a href="/pdf/2402.18606" title="Download PDF">pdf</a>, <a href="/format/2402.18606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of network topology on the performance of Decentralized Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palmieri%2C+L">Luigi Palmieri</a>, 
<a href="/search/cs?searchtype=author&query=Boldrini%2C+C">Chiara Boldrini</a>, 
<a href="/search/cs?searchtype=author&query=Valerio%2C+L">Lorenzo Valerio</a>, 
<a href="/search/cs?searchtype=author&query=Passarella%2C+A">Andrea Passarella</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Marco Conti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Funding: H2020 HumaneAI Net (Grant N. 952026), CHIST-ERA SAI (CHIST-ERA-19-XAI010), PNRR FAIR (PE00000013), PNRR RESTART (PE00000001). arXiv admin note: text overlap with <a href="/abs/2307.15947">arXiv:2307.15947</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Fully decentralized learning is gaining momentum for training AI models at
the Internet's edge, addressing infrastructure challenges and privacy concerns.
In a decentralized machine learning system, data is distributed across multiple
nodes, with each node training a local model based on its respective dataset.
The local models are then shared and combined to form a global model capable of
making accurate predictions on new data. Our exploration focuses on how
different types of network structures influence the spreading of knowledge -
the process by which nodes incorporate insights gained from learning patterns
in data available on other nodes across the network. Specifically, this study
investigates the intricate interplay between network structure and learning
performance using three network topologies and six data distribution methods.
These methods consider different vertex properties, including degree
centrality, betweenness centrality, and clustering coefficient, along with
whether nodes exhibit high or low values of these metrics. Our findings
underscore the significance of global centrality metrics (degree, betweenness)
in correlating with learning performance, while local clustering proves less
predictive. We highlight the challenges in transferring knowledge from
peripheral to central nodes, attributed to a dilution effect during model
aggregation. Additionally, we observe that central nodes exert a pull effect,
facilitating the spread of knowledge. In examining degree distribution, hubs in
Barabasi-Albert networks positively impact learning for central nodes but
exacerbate dilution when knowledge originates from peripheral nodes. Finally,
we demonstrate the formidable challenge of knowledge circulation outside of
segregated communities.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18607" title="Abstract">arXiv:2402.18607</a> [<a href="/pdf/2402.18607" title="Download PDF">pdf</a>, <a href="/format/2402.18607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An  Adversarial Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xinjian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangfan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Diffusion models have recently gained significant attention in both academia
and industry due to their impressive generative performance in terms of both
sampling quality and distribution coverage. Accordingly, proposals are made for
sharing pre-trained diffusion models across different organizations, as a way
of improving data utilization while enhancing privacy protection by avoiding
sharing private data directly. However, the potential risks associated with
such an approach have not been comprehensively examined.
<br />In this paper, we take an adversarial perspective to investigate the
potential privacy and fairness risks associated with the sharing of diffusion
models. Specifically, we investigate the circumstances in which one party (the
sharer) trains a diffusion model using private data and provides another party
(the receiver) black-box access to the pre-trained model for downstream tasks.
We demonstrate that the sharer can execute fairness poisoning attacks to
undermine the receiver's downstream models by manipulating the training data
distribution of the diffusion model. Meanwhile, the receiver can perform
property inference attacks to reveal the distribution of sensitive features in
the sharer's dataset. Our experiments conducted on real-world datasets
demonstrate remarkable attack performance on different types of diffusion
models, which highlights the critical importance of robust data auditing and
privacy protection protocols in pertinent applications.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18609" title="Abstract">arXiv:2402.18609</a> [<a href="/pdf/2402.18609" title="Download PDF">pdf</a>, <a href="/format/2402.18609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICE-SEARCH: A Language Model-Driven Feature Selection Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tianze">Tianze</a> (Tom)
<a href="/search/cs?searchtype=author&query=Yang">Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tianyi">Tianyi</a> (Tim)
<a href="/search/cs?searchtype=author&query=Yang">Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaoshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lvu%2C+F">Fuyuan Lvu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method,
the first work that melds language models (LMs) with evolutionary algorithms
for feature selection (FS) tasks and demonstrates its effectiveness in Medical
Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and
mutation capabilities inherent in LMs within an evolutionary framework,
significantly improving FS through the model's comprehensive world knowledge
and its adaptability to a variety of roles. Our evaluation of this methodology
spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes,
where ICE-SEARCH outperforms traditional FS methods in pinpointing essential
features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA)
performance in stroke prediction and diabetes prediction; the
Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease
prediction. Our results not only demonstrate the efficacy of ICE-SEARCH in
medical FS but also underscore the versatility, efficiency, and scalability of
integrating LMs in FS tasks. The study emphasizes the critical role of
incorporating domain-specific insights, illustrating ICE-SEARCH's robustness,
generalizability, and swift convergence. This opens avenues for further
research into comprehensive and intricate FS landscapes, marking a significant
stride in the application of artificial intelligence in medical predictive
analytics.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18610" title="Abstract">arXiv:2402.18610</a> [<a href="/pdf/2402.18610" title="Download PDF">pdf</a>, <a href="/format/2402.18610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Attention Graphs Are All We Need: Pioneering Hierarchical  Classification of Hematologic Cell Populations with LeukoGraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mojarrad%2C+F+N">Fatemeh Nassajian Mojarrad</a>, 
<a href="/search/cs?searchtype=author&query=Bini%2C+L">Lorenzo Bini</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+T">Thomas Matthes</a>, 
<a href="/search/cs?searchtype=author&query=Marchand-Maillet%2C+S">St&#xe9;phane Marchand-Maillet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">In the complex landscape of hematologic samples such as peripheral blood or
bone marrow, cell classification, delineating diverse populations into a
hierarchical structure, presents profound challenges. This study presents
LeukoGraph, a recently developed framework designed explicitly for this purpose
employing graph attention networks (GATs) to navigate hierarchical
classification (HC) complexities. Notably, LeukoGraph stands as a pioneering
effort, marking the application of graph neural networks (GNNs) for
hierarchical inference on graphs, accommodating up to one million nodes and
millions of edges, all derived from flow cytometry data. LeukoGraph intricately
addresses a classification paradigm where for example four different cell
populations undergo flat categorization, while a fifth diverges into two
distinct child branches, exemplifying the nuanced hierarchical structure
inherent in complex datasets. The technique is more general than this example.
A hallmark achievement of LeukoGraph is its F-score of 98%, significantly
outclassing prevailing state-of-the-art methodologies. Crucially, LeukoGraph's
prowess extends beyond theoretical innovation, showcasing remarkable precision
in predicting both flat and hierarchical cell types across flow cytometry
datasets from 30 distinct patients. This precision is further underscored by
LeukoGraph's ability to maintain a correct label ratio, despite the inherent
challenges posed by hierarchical classifications.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18614" title="Abstract">arXiv:2402.18614</a> [<a href="/pdf/2402.18614" title="Download PDF">pdf</a>, <a href="/format/2402.18614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Models Trained With A Fixed Random Classifier  Transfer Better Across Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+H+T">Hafiz Tiomoko Ali</a>, 
<a href="/search/cs?searchtype=author&query=Michieli%2C+U">Umberto Michieli</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+J+J">Ji Joong Moon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daehyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+M">Mete Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024. Copyright 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The recently discovered Neural collapse (NC) phenomenon states that the
last-layer weights of Deep Neural Networks (DNN), converge to the so-called
Equiangular Tight Frame (ETF) simplex, at the terminal phase of their training.
This ETF geometry is equivalent to vanishing within-class variability of the
last layer activations. Inspired by NC properties, we explore in this paper the
transferability of DNN models trained with their last layer weight fixed
according to ETF. This enforces class separation by eliminating class
covariance information, effectively providing implicit regularization. We show
that DNN models trained with such a fixed classifier significantly improve
transfer performance, particularly on out-of-domain datasets. On a broad range
of fine-grained image classification datasets, our approach outperforms i)
baseline methods that do not perform any covariance regularization (up to 22%),
as well as ii) methods that explicitly whiten covariance of activations
throughout training (up to 19%). Our findings suggest that DNNs trained with
fixed ETF classifiers offer a powerful mechanism for improving transfer
learning across domains.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18616" title="Abstract">arXiv:2402.18616</a> [<a href="/pdf/2402.18616" title="Download PDF">pdf</a>, <a href="/ps/2402.18616" title="Download PostScript">ps</a>, <a href="/format/2402.18616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JCLEC-MO: a Java suite for solving many-objective optimization  engineering problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez%2C+A">Aurora Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+R">Jos&#xe9; Ra&#xfa;l Romero</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Mart%C3%ADnez%2C+C">Carlos Garc&#xed;a-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Ventura%2C+S">Sebasti&#xe1;n Ventura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 5 figures, journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Engineering Applications of Artificial Intelligence, Volume 81,
  May 2019, Pages 14-28
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although metaheuristics have been widely recognized as efficient techniques
to solve real-world optimization problems, implementing them from scratch
remains difficult for domain-specific experts without programming skills. In
this scenario, metaheuristic optimization frameworks are a practical
alternative as they provide a variety of algorithms composed of customized
elements, as well as experimental support. Recently, many engineering problems
require to optimize multiple or even many objectives, increasing the interest
in appropriate metaheuristic algorithms and frameworks that might integrate new
specific requirements while maintaining the generality and reusability
principles they were conceived for. Based on this idea, this paper introduces
JCLEC-MO, a Java framework for both multi- and many-objective optimization that
enables engineers to apply, or adapt, a great number of multi-objective
algorithms with little coding effort. A case study is developed and explained
to show how JCLEC-MO can be used to address many-objective engineering
problems, often requiring the inclusion of domain-specific elements, and to
analyze experimental outcomes by means of conveniently connected R utilities.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18617" title="Abstract">arXiv:2402.18617</a> [<a href="/pdf/2402.18617" title="Download PDF">pdf</a>, <a href="/format/2402.18617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shiqi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kanghoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Offline learning has become widely used due to its ability to derive
effective policies from offline datasets gathered by expert demonstrators
without interacting with the environment directly. Recent research has explored
various ways to enhance offline learning efficiency by considering the
characteristics (e.g., expertise level or multiple demonstrators) of the
dataset. However, a different approach is necessary in the context of zero-sum
games, where outcomes vary significantly based on the strategy of the opponent.
In this study, we introduce a novel approach that uses unsupervised learning
techniques to estimate the exploited level of each trajectory from the offline
dataset of zero-sum games made by diverse demonstrators. Subsequently, we
incorporate the estimated exploited level into the offline learning to maximize
the influence of the dominant strategy. Our method enables interpretable
exploited level estimation in multiple zero-sum games and effectively
identifies dominant strategy data. Also, our exploited level augmented offline
learning significantly enhances the original offline learning algorithms
including imitation learning and offline reinforcement learning for zero-sum
games.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18618" title="Abstract">arXiv:2402.18618</a> [<a href="/pdf/2402.18618" title="Download PDF">pdf</a>, <a href="/ps/2402.18618" title="Download PostScript">ps</a>, <a href="/format/2402.18618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Urban Green Index estimation based on data collected by remote sensing  for Romanian cities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Necula%2C+M">Marian Necula</a>, 
<a href="/search/cs?searchtype=author&query=Andrei%2C+T">Tudorel Andrei</a>, 
<a href="/search/cs?searchtype=author&query=Oancea%2C+B">Bogdan Oancea</a>, 
<a href="/search/cs?searchtype=author&query=P%C4%83un%2C+M">Mihaela P&#x103;un</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Romanian Statistical Review nr. 4 / 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
<p class="mathjax">The modernization of offi cial statistics involves the use of new data
sources, such as data collected through remote sensing. The document contains a
description of how an urban green index, derived from the SDG 11.7 objective,
was obtained for Romania's 41 county seat cities based on free data sets
collected by remote sensing from the European and North American space
agencies. The main result is represented by an estimate of the areas of
surfaces covered with vegetation for the 40 county seat towns and the
municipality of Bucharest, relative to the total surface. To estimate the area
covered with vegetation, we used two data sets obtained by remote sensing,
namely data provided by the MODIS mission, the TERRA satellite, and data
provided by the Sentinel 2 mission from the Copernicus space program. Based on
the results obtained, namely the surface area covered with vegetation,
estimated in square kilometers, and the percentage of the total surface area or
urban green index, we have created a national top of the county seat cities
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18621" title="Abstract">arXiv:2402.18621</a> [<a href="/pdf/2402.18621" title="Download PDF">pdf</a>, <a href="/format/2402.18621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling News Publishers Trustworthiness Through Social Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pratelli%2C+M">Manuel Pratelli</a>, 
<a href="/search/cs?searchtype=author&query=Saracco%2C+F">Fabio Saracco</a>, 
<a href="/search/cs?searchtype=author&query=Petrocchi%2C+M">Marinella Petrocchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A pre-final version of the paper accepted at WebSci'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">With the primary goal of raising readers' awareness of misinformation
phenomena, extensive efforts have been made by both academic institutions and
independent organizations to develop methodologies for assessing the
trustworthiness of online news publishers. Unfortunately, existing approaches
are costly and face critical scalability challenges. This study presents a
novel framework for assessing the trustworthiness of online news publishers
using user interactions on social media platforms. The proposed methodology
provides a versatile solution that serves the dual purpose of i) identifying
verifiable online publishers and ii) automatically performing an initial
estimation of the trustworthiness of previously unclassified online news
outlets.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18630" title="Abstract">arXiv:2402.18630</a> [<a href="/pdf/2402.18630" title="Download PDF">pdf</a>, <a href="/format/2402.18630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNSS Positioning using Cost Function Regulated Multilateration and Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalalirad%2C+A">Amir Jalalirad</a>, 
<a href="/search/cs?searchtype=author&query=Belli%2C+D">Davide Belli</a>, 
<a href="/search/cs?searchtype=author&query=Major%2C+B">Bence Major</a>, 
<a href="/search/cs?searchtype=author&query=Jee%2C+S">Songwon Jee</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Himanshu Shah</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+W">Will Morrison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in The Proceedings of the Institute of Navigation GNSS+ 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In urban environments, where line-of-sight signals from GNSS satellites are
frequently blocked by high-rise objects, GNSS receivers are subject to large
errors in measuring satellite ranges. Heuristic methods are commonly used to
estimate these errors and reduce the impact of noisy measurements on
localization accuracy. In our work, we replace these error estimation
heuristics with a deep learning model based on Graph Neural Networks.
Additionally, by analyzing the cost function of the multilateration process, we
derive an optimal method to utilize the estimated errors. Our approach
guarantees that the multilateration converges to the receiver's location as the
error estimation accuracy increases. We evaluate our solution on a real-world
dataset containing more than 100k GNSS epochs, collected from multiple cities
with diverse characteristics. The empirical results show improvements from 40%
to 80% in the horizontal localization error against recent deep learning
baselines as well as classical localization approaches.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18649" title="Abstract">arXiv:2402.18649</a> [<a href="/pdf/2402.18649" title="Download PDF">pdf</a>, <a href="/format/2402.18649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Era in LLM Security: Exploring Security Concerns in Real-World  LLM-based Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangzhou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Somesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=McDaniel%2C+P">Patrick McDaniel</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Model (LLM) systems are inherently compositional, with
individual LLM serving as the core foundation with additional layers of objects
such as plugins, sandbox, and so on. Along with the great potential, there are
also increasing concerns over the security of such probabilistic intelligent
systems. However, existing studies on LLM security often focus on individual
LLM, but without examining the ecosystem through the lens of LLM systems with
other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we
systematically analyze the security of LLM systems, instead of focusing on the
individual LLMs. To do so, we build on top of the information flow and
formulate the security of LLM systems as constraints on the alignment of the
information flow within LLM and between LLM and other objects. Based on this
construction and the unique probabilistic nature of LLM, the attack surface of
the LLM system can be decomposed into three key components: (1) multi-layer
security analysis, (2) analysis of the existence of constraints, and (3)
analysis of the robustness of these constraints. To ground this new attack
surface, we propose a multi-layer and multi-step approach and apply it to the
state-of-art LLM system, OpenAI GPT4. Our investigation exposes several
security issues, not just within the LLM model itself but also in its
integration with other components. We found that although the OpenAI GPT4 has
designed numerous safety constraints to improve its safety features, these
safety constraints are still vulnerable to attackers. To further demonstrate
the real-world threats of our discovered vulnerabilities, we construct an
end-to-end attack where an adversary can illicitly acquire the user's chat
history, all without the need to manipulate the user's input or gain direct
access to OpenAI GPT4. Our demo is in the link:
https://fzwark.github.io/LLM-System-Attack-Demo/
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18650" title="Abstract">arXiv:2402.18650</a> [<a href="/pdf/2402.18650" title="Download PDF">pdf</a>, <a href="/format/2402.18650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Grasp Reset Mechanism: An Automated Apparatus for Conducting  Grasping Trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DuFrene%2C+K">Kyle DuFrene</a>, 
<a href="/search/cs?searchtype=author&query=Nave%2C+K">Keegan Nave</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+J">Joshua Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+R">Ravi Balasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Grimm%2C+C">Cindy Grimm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Advancing robotic grasping and manipulation requires the ability to test
algorithms and/or train learning models on large numbers of grasps. Towards the
goal of more advanced grasping, we present the Grasp Reset Mechanism (GRM), a
fully automated apparatus for conducting large-scale grasping trials. The GRM
automates the process of resetting a grasping environment, repeatably placing
an object in a fixed location and controllable 1-D orientation. It also
collects data and swaps between multiple objects enabling robust dataset
collection with no human intervention. We also present a standardized state
machine interface for control, which allows for integration of most
manipulators with minimal effort. In addition to the physical design and
corresponding software, we include a dataset of 1,020 grasps. The grasps were
created with a Kinova Gen3 robot arm and Robotiq 2F-85 Adaptive Gripper to
enable training of learning models and to demonstrate the capabilities of the
GRM. The dataset includes ranges of grasps conducted across four objects and a
variety of orientations. Manipulator states, object pose, video, and grasp
success data are provided for every trial.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18651" title="Abstract">arXiv:2402.18651</a> [<a href="/pdf/2402.18651" title="Download PDF">pdf</a>, <a href="/format/2402.18651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Human Priors over Social and Navigation Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bravo-Hermsdorff%2C+G">Gecia Bravo-Hermsdorff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on Proceedings of the 40th International Conference on Machine Learning (ICML), PMLR 202:3063-3105, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph); Neurons and Cognition (q-bio.NC); Methodology (stat.ME)

</div>
<p class="mathjax">Human knowledge is largely implicit and relational -- do we have a friend in
common? can I walk from here to there? In this work, we leverage the
combinatorial structure of graphs to quantify human priors over such relational
data. Our experiments focus on two domains that have been continuously relevant
over evolutionary timescales: social interaction and spatial navigation. We
find that some features of the inferred priors are remarkably consistent, such
as the tendency for sparsity as a function of graph size. Other features are
domain-specific, such as the propensity for triadic closure in social
interactions. More broadly, our work demonstrates how nonclassical statistical
analysis of indirect behavioral experiments can be used to efficiently model
latent biases in the data.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18652" title="Abstract">arXiv:2402.18652</a> [<a href="/pdf/2402.18652" title="Download PDF">pdf</a>, <a href="/format/2402.18652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Variation-Aware Read Disturbance Defenses: Experimental Analysis  of Real DRAM Chips and Implications on Future Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fl%C4%B1k%C3%A7%C4%B1%2C+A+G">Abdullah Giray Ya&#x11f;l&#x131;k&#xe7;&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Tu%C4%9Frul%2C+Y+C">Yahya Can Tu&#x11f;rul</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Y%C3%BCksel%2C+%C4%B0+E">&#x130;smail Emir Y&#xfc;ksel</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shorter version of this work is to appear at the 30th IEEE International Symposium on High-Performance Computer Architecture (HPCA-30), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Read disturbance in modern DRAM chips is a widespread phenomenon and is
reliably used for breaking memory isolation, a fundamental building block for
building robust systems. RowHammer and RowPress are two examples of read
disturbance in DRAM where repeatedly accessing (hammering) or keeping active
(pressing) a memory location induces bitflips in other memory locations.
Unfortunately, shrinking technology node size exacerbates read disturbance in
DRAM chips over generations. As a result, existing defense mechanisms suffer
from significant performance and energy overheads, limited effectiveness, or
prohibitively high hardware complexity.
<br />In this paper, we tackle these shortcomings by leveraging the spatial
variation in read disturbance across different memory locations in real DRAM
chips. To do so, we 1) present the first rigorous real DRAM chip
characterization study of spatial variation of read disturbance and 2) propose
Sv\"ard, a new mechanism that dynamically adapts the aggressiveness of existing
solutions based on the row-level read disturbance profile. Our experimental
characterization on 144 real DDR4 DRAM chips representing 10 chip designs
demonstrates a large variation in read disturbance vulnerability across
different memory locations: in the part of memory with the worst read
disturbance vulnerability, 1) up to 2x the number of bitflips can occur and 2)
bitflips can occur at an order of magnitude fewer accesses, compared to the
memory locations with the least vulnerability to read disturbance. Sv\"ard
leverages this variation to reduce the overheads of five state-of-the-art read
disturbance solutions, and thus significantly increases system performance.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18659" title="Abstract">arXiv:2402.18659</a> [<a href="/pdf/2402.18659" title="Download PDF">pdf</a>, <a href="/format/2402.18659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models and Games: A Survey and Roadmap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallotta%2C+R">Roberto Gallotta</a>, 
<a href="/search/cs?searchtype=author&query=Todd%2C+G">Graham Todd</a>, 
<a href="/search/cs?searchtype=author&query=Zammit%2C+M">Marvin Zammit</a>, 
<a href="/search/cs?searchtype=author&query=Earle%2C+S">Sam Earle</a>, 
<a href="/search/cs?searchtype=author&query=Liapis%2C+A">Antonios Liapis</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>, 
<a href="/search/cs?searchtype=author&query=Yannakakis%2C+G+N">Georgios N. Yannakakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Recent years have seen an explosive increase in research on large language
models (LLMs), and accompanying public engagement on the topic. While starting
as a niche area within natural language processing, LLMs have shown remarkable
potential across a broad range of applications and domains, including games.
This paper surveys the current state of the art across the various applications
of LLMs in and for games, and identifies the different roles LLMs can take
within a game. Importantly, we discuss underexplored areas and promising
directions for future uses of LLMs in games and we reconcile the potential and
limitations of LLMs within the games domain. As the first comprehensive survey
and roadmap at the intersection of LLMs and games, we are hopeful that this
paper will serve as the basis for groundbreaking research and innovation in
this exciting new field.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18660" title="Abstract">arXiv:2402.18660</a> [<a href="/pdf/2402.18660" title="Download PDF">pdf</a>, <a href="/format/2402.18660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Versatile mixed methods for compressible flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miller%2C+E+A">Edward A. Miller</a>, 
<a href="/search/math?searchtype=author&query=Williams%2C+D+M">David M. Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Versatile mixed finite element methods were originally developed by Chen and
Williams for isothermal incompressible flows in "Versatile mixed methods for
the incompressible Navier-Stokes equations," Computers &amp; Mathematics with
Applications, Volume 80, 2020. Thereafter, these methods were extended by
Miller, Chen, and Williams to non-isothermal incompressible flows in "Versatile
mixed methods for non-isothermal incompressible flows," Computers &amp; Mathematics
with Applications, Volume 125, 2022. The main advantage of these methods lies
in their flexibility. Unlike traditional mixed methods, they retain the
divergence terms in the momentum and temperature equations. As a result, the
favorable properties of the schemes are maintained even in the presence of
non-zero divergence. This makes them an ideal candidate for an extension to
compressible flows, in which the divergence does not generally vanish. In the
present article, we finally construct the fully-compressible extension of the
methods. In addition, we demonstrate the excellent performance of the resulting
methods for weakly-compressible flows that arise near the incompressible limit,
as well as more strongly-compressible flows that arise near Mach 0.5.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18664" title="Abstract">arXiv:2402.18664</a> [<a href="/pdf/2402.18664" title="Download PDF">pdf</a>, <a href="/format/2402.18664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online disinformation in the 2020 U.S. Election: swing vs. safe states
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pratelli%2C+M">Manuel Pratelli</a>, 
<a href="/search/cs?searchtype=author&query=Petrocchi%2C+M">Marinella Petrocchi</a>, 
<a href="/search/cs?searchtype=author&query=Saracco%2C+F">Fabio Saracco</a>, 
<a href="/search/cs?searchtype=author&query=De+Nicola%2C+R">Rocco De Nicola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.12474">arXiv:2303.12474</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">For U.S. presidential elections, most states use the so-called
winner-take-all system, in which the state's presidential electors are awarded
to the winning political party in the state after a popular vote phase,
regardless of the actual margin of victory. Therefore, election campaigns are
especially intense in states where there is no clear direction on which party
will be the winning party. These states are often referred to as swing states.
To measure the impact of such an election law on the campaigns, we analyze the
Twitter activity surrounding the 2020 US preelection debate, with a particular
focus on the spread of disinformation. We find that about 88\% of the online
traffic was associated with swing states. In addition, the sharing of links to
unreliable news sources is significantly more prevalent in tweets associated
with swing states: in this case, untrustworthy tweets are predominantly
generated by automated accounts. Furthermore, we observe that the debate is
mostly led by two main communities, one with a predominantly Republican
affiliation and the other with accounts of different political orientations.
Most of the disinformation comes from the former.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18667" title="Abstract">arXiv:2402.18667</a> [<a href="/pdf/2402.18667" title="Download PDF">pdf</a>, <a href="/format/2402.18667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOFO: A Benchmark to Evaluate LLMs&#x27; Format-Following Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+C">Congying Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiangshu Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yihao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents FoFo, a pioneering benchmark for evaluating large
language models' (LLMs) ability to follow complex, domain-specific formats, a
crucial yet underexamined capability for their application as AI agents.
Despite LLMs' advancements, existing benchmarks fail to assess their
format-following proficiency adequately. FoFo fills this gap with a diverse
range of real-world formats and instructions, developed through an AI-Human
collaborative method. Our evaluation across both open-source (e.g., Llama 2,
WizardLM) and closed-source (e.g., GPT-4, PALM2, Gemini) LLMs highlights three
key findings: open-source models significantly lag behind closed-source ones in
format adherence; LLMs' format-following performance is independent of their
content generation quality; and LLMs' format proficiency varies across
different domains. These insights suggest the need for specialized tuning for
format-following skills and highlight FoFo's role in guiding the selection of
domain-specific AI agents. FoFo is released here at
https://github.com/SalesforceAIResearch/FoFo.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18668" title="Abstract">arXiv:2402.18668</a> [<a href="/pdf/2402.18668" title="Download PDF">pdf</a>, <a href="/format/2402.18668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple linear attention language models balance the recall-throughput  tradeoff
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Simran Arora</a>, 
<a href="/search/cs?searchtype=author&query=Eyuboglu%2C+S">Sabri Eyuboglu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Michael Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Timalsina%2C+A">Aman Timalsina</a>, 
<a href="/search/cs?searchtype=author&query=Alberti%2C+S">Silas Alberti</a>, 
<a href="/search/cs?searchtype=author&query=Zinsley%2C+D">Dylan Zinsley</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Rudra%2C+A">Atri Rudra</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work has shown that attention-based language models excel at recall,
the ability to ground generations in tokens previously seen in context.
However, the efficiency of attention-based models is bottle-necked during
inference by the KV-cache's aggressive memory consumption. In this work, we
explore whether we can improve language model efficiency (e.g. by reducing
memory consumption) without compromising on recall. By applying experiments and
theory to a broad set of architectures, we identify a key tradeoff between a
model's state size and recall ability. We show that efficient alternatives to
attention (e.g. H3, Mamba, RWKV) maintain a fixed-size recurrent state, but
struggle at recall. We propose BASED a simple architecture combining linear and
sliding window attention. By varying BASED window size and linear attention
feature dimension, we can dial the state size and traverse the pareto frontier
of the recall-memory tradeoff curve, recovering the full quality of attention
on one end and the small state size of attention-alternatives on the other. We
train language models up to 1.3b parameters and show that BASED matches the
strongest sub-quadratic models (e.g. Mamba) in perplexity and outperforms them
on real-world recall-intensive tasks by 6.22 accuracy points. Implementations
of linear attention are often less efficient than optimized standard attention
implementations. To make BASED competitive, we develop IO-aware algorithms that
enable 24x higher throughput on language generation than FlashAttention-2, when
generating 1024 tokens using 1.3b parameter models. Code for this work is
provided at: https://github.com/HazyResearch/based.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18673" title="Abstract">arXiv:2402.18673</a> [<a href="/pdf/2402.18673" title="Download PDF">pdf</a>, <a href="/format/2402.18673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trends, Applications, and Challenges in Human Attention Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cartella%2C+G">Giuseppe Cartella</a>, 
<a href="/search/cs?searchtype=author&query=Cornia%2C+M">Marcella Cornia</a>, 
<a href="/search/cs?searchtype=author&query=Cuculo%2C+V">Vittorio Cuculo</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amelio%2C+A">Alessandro D&#x27;Amelio</a>, 
<a href="/search/cs?searchtype=author&query=Zanca%2C+D">Dario Zanca</a>, 
<a href="/search/cs?searchtype=author&query=Boccignone%2C+G">Giuseppe Boccignone</a>, 
<a href="/search/cs?searchtype=author&query=Cucchiara%2C+R">Rita Cucchiara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub repository: <a href="https://github.com/aimagelab/awesome-human-visual-attention">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human attention modelling has proven, in recent years, to be particularly
useful not only for understanding the cognitive processes underlying visual
exploration, but also for providing support to artificial intelligence models
that aim to solve problems in various domains, including image and video
processing, vision-and-language applications, and language modelling. This
survey offers a reasoned overview of recent efforts to integrate human
attention mechanisms into contemporary deep learning models and discusses
future research directions and challenges. For a comprehensive overview on the
ongoing research refer to our dedicated repository available at
https://github.com/aimagelab/awesome-human-visual-attention.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18675" title="Abstract">arXiv:2402.18675</a> [<a href="/pdf/2402.18675" title="Download PDF">pdf</a>, <a href="/format/2402.18675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robot Body Schema Learning from Full-body Extero/Proprioception Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinkun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lawson Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">For a robot, its body structure is an a-prior knowledge when it is designed.
However, when such information is not available, can a robot recognize it by
itself? In this paper, we aim to grant a robot such ability to learn its body
structure from exteroception and proprioception data collected from on-body
sensors. By a novel machine learning method, the robot can learn a binary
Heterogeneous Dependency Matrix from its sensor readings. We showed such matrix
is equivalent to a Heterogeneous out-tree structure which can uniquely
represent the robot body topology. We explored the properties of such matrix
and the out-tree, and proposed a remedy to fix them when they are contaminated
by partial observability or data noise. We ran our algorithm on 6 different
robots with different body structures in simulation and 1 real robot. Our
algorithm correctly recognized their body structures with only on-body sensor
readings but no topology prior knowledge.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18677" title="Abstract">arXiv:2402.18677</a> [<a href="/pdf/2402.18677" title="Download PDF">pdf</a>, <a href="/format/2402.18677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Tolerant Neural Control Barrier Functions for Robotic Systems  under Sensor Faults and Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongchao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Luyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+A">Andrew Clark</a>, 
<a href="/search/cs?searchtype=author&query=Poovendran%2C+R">Radha Poovendran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Safety is a fundamental requirement of many robotic systems. Control barrier
function (CBF)-based approaches have been proposed to guarantee the safety of
robotic systems. However, the effectiveness of these approaches highly relies
on the choice of CBFs. Inspired by the universal approximation power of neural
networks, there is a growing trend toward representing CBFs using neural
networks, leading to the notion of neural CBFs (NCBFs). Current NCBFs, however,
are trained and deployed in benign environments, making them ineffective for
scenarios where robotic systems experience sensor faults and attacks. In this
paper, we study safety-critical control synthesis for robotic systems under
sensor faults and attacks. Our main contribution is the development and
synthesis of a new class of CBFs that we term fault tolerant neural control
barrier function (FT-NCBF). We derive the necessary and sufficient conditions
for FT-NCBFs to guarantee safety, and develop a data-driven method to learn
FT-NCBFs by minimizing a loss function constructed using the derived
conditions. Using the learned FT-NCBF, we synthesize a control input and
formally prove the safety guarantee provided by our approach. We demonstrate
our proposed approach using two case studies: obstacle avoidance problem for an
autonomous mobile robot and spacecraft rendezvous problem, with code available
via https://github.com/HongchaoZhang-HZ/FTNCBF.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18678" title="Abstract">arXiv:2402.18678</a> [<a href="/pdf/2402.18678" title="Download PDF">pdf</a>, <a href="/format/2402.18678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RORA: Robust Free-Text Rationale Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengping Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yining Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anqi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Free-text rationales play a pivotal role in explainable NLP, bridging the
knowledge and reasoning gaps behind a model's decision-making. However, due to
the diversity of potential reasoning paths and a corresponding lack of
definitive ground truth, their evaluation remains a challenge. Existing
evaluation metrics rely on the degree to which a rationale supports a target
label, but we find these fall short in evaluating rationales that inadvertently
leak the labels. To address this problem, we propose RORA, a Robust free-text
Rationale evaluation against label leakage. RORA quantifies the new information
supplied by a rationale to justify the label. This is achieved by assessing the
conditional V-information \citep{hewitt-etal-2021-conditional} with a
predictive family robust against leaky features that can be exploited by a
small model. RORA consistently outperforms existing approaches in evaluating
human-written, synthetic, or model-generated rationales, particularly
demonstrating robustness against label leakage. We also show that RORA aligns
well with human judgment, providing a more reliable and accurate measurement
across diverse free-text rationales.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18679" title="Abstract">arXiv:2402.18679</a> [<a href="/pdf/2402.18679" title="Download PDF">pdf</a>, <a href="/format/2402.18679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Interpreter: An LLM Agent For Data Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sirui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yizhang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bangbang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuge%2C+M">Mingchen Zhuge</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Taicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tuo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiangtao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinbing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Y">Yaying Fei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zongze Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenglin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Model (LLM)-based agents have demonstrated remarkable
effectiveness. However, their performance can be compromised in data science
scenarios that require real-time data adjustment, expertise in optimization due
to complex dependencies among various tasks, and the ability to identify
logical errors for precise reasoning. In this study, we introduce the Data
Interpreter, a solution designed to solve with code that emphasizes three
pivotal techniques to augment problem-solving in data science: 1) dynamic
planning with hierarchical graph structures for real-time data adaptability;2)
tool integration dynamically to enhance code proficiency during execution,
enriching the requisite expertise;3) logical inconsistency identification in
feedback, and efficiency enhancement through experience recording. We evaluate
the Data Interpreter on various data science and real-world tasks. Compared to
open-source baselines, it demonstrated superior performance, exhibiting
significant improvements in machine learning tasks, increasing from 0.86 to
0.95. Additionally, it showed a 26% increase in the MATH dataset and a
remarkable 112% improvement in open-ended tasks. The solution will be released
at https://github.com/geekan/MetaGPT.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18682" title="Abstract">arXiv:2402.18682</a> [<a href="/pdf/2402.18682" title="Download PDF">pdf</a>, <a href="/format/2402.18682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic tactile sensing for mobile robot wheels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mason%2C+W">Wilfred Mason</a>, 
<a href="/search/cs?searchtype=author&query=Brenken%2C+D">David Brenken</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+F+Z">Falcon Z. Dai</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+R+G+C">Ricardo Gonzalo Cruz Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Cormier%2C+O+S">Olivier St-Martin Cormier</a>, 
<a href="/search/cs?searchtype=author&query=Sedal%2C+A">Audrey Sedal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Tactile sensing in mobile robots remains under-explored, mainly due to
challenges related to sensor integration and the complexities of distributed
sensing. In this work, we present a tactile sensing architecture for mobile
robots based on wheel-mounted acoustic waveguides. Our sensor architecture
enables tactile sensing along the entire circumference of a wheel with a single
active component: an off-the-shelf acoustic rangefinder. We present findings
showing that our sensor, mounted on the wheel of a mobile robot, is capable of
discriminating between different terrains, detecting and classifying obstacles
with different geometries, and performing collision detection via contact
localization. We also present a comparison between our sensor and sensors
traditionally used in mobile robots, and point to the potential for sensor
fusion approaches that leverage the unique capabilities of our tactile sensing
architecture. Our findings demonstrate that autonomous mobile robots can
further leverage our sensor architecture for diverse mapping tasks requiring
knowledge of terrain material, surface topology, and underlying structure.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18683" title="Abstract">arXiv:2402.18683</a> [<a href="/pdf/2402.18683" title="Download PDF">pdf</a>, <a href="/format/2402.18683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication Meets Smart Propagation  Engineering: Opportunities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+K">Kaitao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Masouros%2C+C">Christos Masouros</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Petropulu%2C+A+P">Athina P. Petropulu</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, submitted to IEEE journal for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Both smart propagation engineering as well as integrated sensing and
communication (ISAC) constitute promising candidates for next-generation (NG)
mobile networks. We provide a synergistic view of these technologies, and
explore their mutual benefits. First, moving beyond just intelligent surfaces,
we provide a holistic view of the engineering aspects of smart propagation
environments. By delving into the fundamental characteristics of intelligent
surfaces, fluid antennas, and unmanned aerial vehicles, we reveal that more
efficient control of the pathloss and fading can be achieved, thus facilitating
intrinsic integration and mutual assistance between sensing and communication
functionalities. In turn, with the exploitation of the sensing capabilities of
ISAC to orchestrate the efficient configuration of radio environments, both the
computational effort and signaling overheads can be reduced. We present
indicative simulation results, which verify that cooperative smart propagation
environment design significantly enhances the ISAC performance. Finally, some
promising directions are outlined for combining ISAC with smart propagation
engineering.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18688" title="Abstract">arXiv:2402.18688</a> [<a href="/pdf/2402.18688" title="Download PDF">pdf</a>, <a href="/format/2402.18688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring AI Problem Formulation with Children via Teachable Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+U">Utkarsh Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed-Ali%2C+S">Salma Elsayed-Ali</a>, 
<a href="/search/cs?searchtype=author&query=Bonsignore%2C+E">Elizabeth Bonsignore</a>, 
<a href="/search/cs?searchtype=author&query=Kacorri%2C+H">Hernisa Kacorri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Emphasizing problem formulation in AI literacy activities with children is
vital, yet we lack empirical studies on their structure and affordances. We
propose that participatory design involving teachable machines facilitates
problem formulation activities. To test this, we integrated problem reduction
heuristics into storyboarding and invited a university-based intergenerational
design team of 10 children (ages 8-13) and 9 adults to co-design a teachable
machine. We find that children draw from personal experiences when formulating
AI problems; they assume voice and video capabilities, explore diverse machine
learning approaches, and plan for error handling. Their ideas promote human
involvement in AI, though some are drawn to more autonomous systems. Their
designs prioritize values like capability, logic, helpfulness, responsibility,
and obedience, and a preference for a comfortable life, family security, inner
harmony, and excitement as end-states. We conclude by discussing how these
results can inform the design of future participatory AI activities.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18689" title="Abstract">arXiv:2402.18689</a> [<a href="/pdf/2402.18689" title="Download PDF">pdf</a>, <a href="/format/2402.18689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The VOROS: Lifting ROC curves to 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratigan%2C+C">Christopher Ratigan</a>, 
<a href="/search/cs?searchtype=author&query=Cowen%2C+L">Lenore Cowen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Metric Geometry (math.MG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
<p class="mathjax">The area under the ROC curve is a common measure that is often used to rank
the relative performance of different binary classifiers. However, as has been
also previously noted, it can be a measure that ill-captures the benefits of
different classifiers when either the true class values or misclassification
costs are highly unbalanced between the two classes. We introduce a third
dimension to capture these costs, and lift the ROC curve to a ROC surface in a
natural way. We study both this surface and introduce the VOROS, the volume
over this ROC surface, as a 3D generalization of the 2D area under the ROC
curve. For problems where there are only bounds on the expected costs or class
imbalances, we restrict consideration to the volume of the appropriate
subregion of the ROC surface. We show how the VOROS can better capture the
costs of different classifiers on both a classical and a modern example
dataset.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18695" title="Abstract">arXiv:2402.18695</a> [<a href="/pdf/2402.18695" title="Download PDF">pdf</a>, <a href="/format/2402.18695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Language Models for Visual Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zilin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Cascante-Bonilla%2C+P">Paola Cascante-Bonilla</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+V">Vicente Ordonez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce AutoVER, an Autoregressive model for Visual Entity Recognition.
Our model extends an autoregressive Multi-modal Large Language Model by
employing retrieval augmented constrained generation. It mitigates low
performance on out-of-domain entities while excelling in queries that require
visually-situated reasoning. Our method learns to distinguish similar entities
within a vast label space by contrastively training on hard negative pairs in
parallel with a sequence-to-sequence objective without an external retriever.
During inference, a list of retrieved candidate answers explicitly guides
language generation by removing invalid decoding paths. The proposed method
achieves significant improvements across different dataset splits in the
recently proposed Oven-Wiki benchmark. Accuracy on the Entity seen split rises
from 32.7% to 61.5%. It also demonstrates superior performance on the unseen
and query splits by a substantial double-digit margin.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18698" title="Abstract">arXiv:2402.18698</a> [<a href="/pdf/2402.18698" title="Download PDF">pdf</a>, <a href="/ps/2402.18698" title="Download PostScript">ps</a>, <a href="/format/2402.18698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Coherence Loss for Salient and Camouflaged Object Detection and  Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Choy%2C+K">Kevin Choy</a>, 
<a href="/search/cs?searchtype=author&query=Farsiu%2C+S">Sina Farsiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generic object detection is a category-independent task that relies on
accurate modeling of objectness. Most relevant CNN-based models of objectness
utilize loss functions (e.g., binary cross entropy) that focus on the
single-response, i.e., the loss response of a single pixel. Inspired by the
human visual system, which first discerns the boundaries of ambiguous regions
(i.e., hard regions) before delving into the semantic meaning, we propose a
novel loss function, Spatial Coherence Loss (SCLoss), that uses the mutual
response between adjacent pixels to suppress or emphasize the single-response
of pixels. We demonstrate that the proposed SCLoss can gradually learn the hard
regions by detecting and emphasizing their boundaries. Through comprehensive
experiments, we demonstrate that replacing popular loss functions with SCLoss
can improve the performance of current state-of-the-art (SOTA) salient or
camouflaged object detection (SOD or COD) models. We also demonstrate that
combining SCLoss with other loss functions can further improve performance and
result in the SOTA outcomes for different applications. Finally, as a
demonstrative example of the potential uses for other related tasks, we show an
application of SCLoss for semantic segmentation.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18699" title="Abstract">arXiv:2402.18699</a> [<a href="/pdf/2402.18699" title="Download PDF">pdf</a>, <a href="/format/2402.18699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Articulated Object Manipulation with Coarse-to-fine Affordance for  Mitigating the Effect of Point Cloud Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Suhan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shiguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuzheng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">3D articulated objects are inherently challenging for manipulation due to the
varied geometries and intricate functionalities associated with articulated
objects.Point-level affordance, which predicts the per-point actionable score
and thus proposes the best point to interact with, has demonstrated excellent
performance and generalization capabilities in articulated object manipulation.
However, a significant challenge remains: while previous works use perfect
point cloud generated in simulation, the models cannot directly apply to the
noisy point cloud in the real-world.To tackle this challenge, we leverage the
property of real-world scanned point cloud that, the point cloud becomes less
noisy when the camera is closer to the object. Therefore, we propose a novel
coarse-to-fine affordance learning pipeline to mitigate the effect of point
cloud noise in two stages. In the first stage, we learn the affordance on the
noisy far point cloud which includes the whole object to propose the
approximated place to manipulate. Then, we move the camera in front of the
approximated place, scan a less noisy point cloud containing precise local
geometries for manipulation, and learn affordance on such point cloud to
propose fine-grained final actions. The proposed method is thoroughly evaluated
both using large-scale simulated noisy point clouds mimicking real-world scans,
and in the real world scenarios, with superiority over existing methods,
demonstrating the effectiveness in tackling the noisy real-world point cloud
problem.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18700" title="Abstract">arXiv:2402.18700</a> [<a href="/pdf/2402.18700" title="Download PDF">pdf</a>, <a href="/format/2402.18700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Compress Prompt in Natural Language Formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yu-Neng Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+T">Tianwei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chia-Yuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are great at processing multiple natural
language processing tasks, but their abilities are constrained by inferior
performance with long context, slow inference speed, and the high cost of
computing the results. Deploying LLMs with precise and informative context
helps users process large-scale datasets more effectively and cost-efficiently.
Existing works rely on compressing long prompt contexts into soft prompts.
However, soft prompt compression encounters limitations in transferability
across different LLMs, especially API-based LLMs. To this end, this work aims
to compress lengthy prompts in the form of natural language with LLM
transferability. This poses two challenges: (i) Natural Language (NL) prompts
are incompatible with back-propagation, and (ii) NL prompts lack flexibility in
imposing length constraints. In this work, we propose a Natural Language Prompt
Encapsulation (Nano-Capsulator) framework compressing original prompts into NL
formatted Capsule Prompt while maintaining the prompt utility and
transferability. Specifically, to tackle the first challenge, the
Nano-Capsulator is optimized by a reward function that interacts with the
proposed semantics preserving loss. To address the second question, the
Nano-Capsulator is optimized by a reward function featuring length constraints.
Experimental results demonstrate that the Capsule Prompt can reduce 81.4% of
the original length, decrease inference latency up to 4.5x, and save 80.1% of
budget overheads while providing transferability across diverse LLMs and
different datasets.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18702" title="Abstract">arXiv:2402.18702</a> [<a href="/pdf/2402.18702" title="Download PDF">pdf</a>, <a href="/ps/2402.18702" title="Download PostScript">ps</a>, <a href="/format/2402.18702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Multimedia Information Environment through Multi-modal  Clustering of YouTube Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousefi%2C+N">Niloofar Yousefi</a>, 
<a href="/search/cs?searchtype=author&query=Shaik%2C+M">Mainuddin Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Nitin Agarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, In the 4th International Conference on SMART MULTIMEDIA, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">This study aims to investigate the comprehensive characterization of
information content in multimedia (videos), particularly on YouTube. The
research presents a multi-method framework for characterizing multimedia
content by clustering signals from various modalities, such as audio, video,
and text. With a focus on South China Sea videos as a case study, this approach
aims to enhance our understanding of online content, especially on YouTube. The
dataset includes 160 videos, and our findings offer insights into content
themes and patterns within different modalities of a video based on clusters.
Text modality analysis revealed topical themes related to geopolitical
countries, strategies, and global security, while video and audio modality
analysis identified distinct patterns of signals related to diverse sets of
videos, including news analysis/reporting, educational content, and interviews.
Furthermore, our findings uncover instances of content repurposing within video
clusters, which were identified using the barcode technique and audio
similarity assessments. These findings indicate potential content amplification
techniques. In conclusion, this study uniquely enhances our current
understanding of multimedia content information based on modality clustering
techniques.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18705" title="Abstract">arXiv:2402.18705</a> [<a href="/pdf/2402.18705" title="Download PDF">pdf</a>, <a href="/ps/2402.18705" title="Download PostScript">ps</a>, <a href="/format/2402.18705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Platform Exchange and Safeguards Matter: The Case of Sexual Risk in  Airbnb and Couchsurfing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Skyler Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Recent work in CHI and CSCW has devoted increasing attention to how the
design of network hospitality platforms shapes user experiences and relational
outcomes. In this article, I interrogate how different risk factors emerge
based on the type of exchanges these platforms facilitate. To do so, I
juxtapose two prominent network hospitality platforms: one facilitating
negotiated exchange (i.e., Airbnb) with another facilitating reciprocal
exchange (i.e., Couchsurfing) between users. Homing in on sexual risk, an
underexplored form of platform danger, and drawing on interviews with 40 female
dual-platform users, I argue that the provision of binding negotiated exchange
and institutional safeguards by Airbnb reduces risk through three mechanisms:
casting initial guest-host relation into a buyer-seller arrangement,
stabilizing interactional scripts, and formalizing sexual violence recourse.
Conversely, Couchsurfing's reciprocal exchange and lack of safeguards increase
sexual precarity for users both on- and off-platform. This study demonstrates
how platforms with strong prosocial motivations can jeopardize sociality and
concludes with implications for designs that better protect vulnerable user
populations.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18707" title="Abstract">arXiv:2402.18707</a> [<a href="/pdf/2402.18707" title="Download PDF">pdf</a>, <a href="/format/2402.18707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embodied Supervision: Haptic Display of Automation Command to Improve  Supervisory Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+A">Alia Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+S">Sachit Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Gillespie%2C+R+B">R. Brent Gillespie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Haptics Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">A human operator using a manual control interface has ready access to their
own command signal, both by efference copy and proprioception. In contrast, a
human supervisor typically relies on visual information alone. We propose
supplying a supervisor with a copy of the operators command signal,
hypothesizing improved performance, especially when that copy is provided
through haptic display. We experimentally compared haptic with visual access to
the command signal, quantifying the performance of N equals 10 participants
attempting to determine which of three reference signals was being tracked by
an operator. Results indicate an improved accuracy in identifying the tracked
target when haptic display was available relative to visual display alone. We
conjecture the benefit follows from the relationship of haptics to the
supervisor's own experience, perhaps muscle memory, as an operator.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18708" title="Abstract">arXiv:2402.18708</a> [<a href="/pdf/2402.18708" title="Download PDF">pdf</a>, <a href="/format/2402.18708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bluebell: An Alliance of Relational Lifting and Independence For  Probabilistic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jialu Bao</a>, 
<a href="/search/cs?searchtype=author&query=D%27Osualdo%2C+E">Emanuele D&#x27;Osualdo</a>, 
<a href="/search/cs?searchtype=author&query=Farzan%2C+A">Azadeh Farzan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages + 53 pages of appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We present Bluebell, a program logic for reasoning about probabilistic
programs where unary and relational styles of reasoning come together to create
new reasoning tools. Unary-style reasoning is very expressive and is powered by
foundational mechanisms to reason about probabilistic behaviour like
independence and conditioning. The relational style of reasoning, on the other
hand, naturally shines when the properties of interest compare the behaviour of
similar programs (e.g. when proving differential privacy) managing to avoid
having to characterize the output distributions of the individual programs. So
far, the two styles of reasoning have largely remained separate in the many
program logics designed for the deductive verification of probabilistic
programs. In Bluebell, we unify these styles of reasoning through the
introduction of a new modality called "joint conditioning" that can encode and
illuminate the rich interaction between conditional independence and relational
liftings; the two powerhouses from the two styles of reasoning.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18709" title="Abstract">arXiv:2402.18709</a> [<a href="/pdf/2402.18709" title="Download PDF">pdf</a>, <a href="/format/2402.18709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear identification algorithm for online and offline study of  pulmonary mechanical ventilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Riva%2C+D+A">Diego A. Riva</a>, 
<a href="/search/eess?searchtype=author&query=Evangelista%2C+C+A">Carolina A. Evangelista</a>, 
<a href="/search/eess?searchtype=author&query=Puleston%2C+P+F">Paul F. Puleston</a>, 
<a href="/search/eess?searchtype=author&query=Corsiglia%2C+L">Luis Corsiglia</a>, 
<a href="/search/eess?searchtype=author&query=Dargains%2C+N">Nahuel Dargains</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Medical Physics (physics.med-ph)

</div>
<p class="mathjax">This work presents an algorithm for determining the parameters of a nonlinear
dynamic model of the respiratory system in patients undergoing assisted
ventilation. Using the pressure and flow signals measured at the mouth, the
model's quadratic pressure-volume characteristic is fit to this data in each
respiratory cycle by appropriate estimates of the model parameters. Parameter
changes during ventilation can thus also be detected. The algorithm is first
refined and assessed using data derived from simulated patients represented
through a sigmoidal pressure-volume characteristic with hysteresis. As
satisfactory results are achieved with the simulated data, the algorithm is
evaluated with real data obtained from actual patients undergoing assisted
ventilation. The proposed nonlinear dynamic model and associated parameter
estimation algorithm yield closer fits than the static linear models computed
by respiratory machines, with only a minor increase in computation. They also
provide more information to the physician, such as the pressure-volume (P-V)
curvature and the condition of the lung (whether normal, under-inflated, or
over-inflated). This information can be used to provide safer ventilation for
patients, for instance by ventilating them in the linear region of the
respiratory system.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18710" title="Abstract">arXiv:2402.18710</a> [<a href="/pdf/2402.18710" title="Download PDF">pdf</a>, <a href="/format/2402.18710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hefty: A Modular Reconfigurable Robot for Advancing Robot Manipulation  in Agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guri%2C+D">Dominic Guri</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moonyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kroemer%2C+O">Oliver Kroemer</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+G">George Kantor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a modular, reconfigurable robot platform for robot
manipulation in agriculture. While robot manipulation promises great
advancements in automating challenging, complex tasks that are currently best
left to humans, it is also an expensive capital investment for researchers and
users because it demands significantly varying robot configurations depending
on the task. Modular robots provide a way to obtain multiple configurations and
reduce costs by enabling incremental acquisition of only the necessary modules.
The robot we present, Hefty, is designed to be modular and reconfigurable. It
is designed for both researchers and end-users as a means to improve technology
transfer from research to real-world application. This paper provides a
detailed design and integration process, outlining the critical design
decisions that enable modularity in the mobility of the robot as well as its
sensor payload, power systems, computing, and fixture mounting. We demonstrate
the utility of the robot by presenting five configurations used in multiple
real-world agricultural robotics applications.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18715" title="Abstract">arXiv:2402.18715</a> [<a href="/pdf/2402.18715" title="Download PDF">pdf</a>, <a href="/format/2402.18715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commonsense Ontology Micropatterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eells%2C+A">Andrew Eells</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+B">Brandon Dave</a>, 
<a href="/search/cs?searchtype=author&query=Hitzler%2C+P">Pascal Hitzler</a>, 
<a href="/search/cs?searchtype=author&query=Shimizu%2C+C">Cogan Shimizu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The previously introduced Modular Ontology Modeling methodology (MOMo)
attempts to mimic the human analogical process by using modular patterns to
assemble more complex concepts. To support this, MOMo organizes organizes
ontology design patterns into design libraries, which are programmatically
queryable, to support accelerated ontology development, for both human and
automated processes. However, a major bottleneck to large-scale deployment of
MOMo is the (to-date) limited availability of ready-to-use ontology design
patterns. At the same time, Large Language Models have quickly become a source
of common knowledge and, in some cases, replacing search engines for questions.
In this paper, we thus present a collection of 104 ontology design patterns
representing often occurring nouns, curated from the common-sense knowledge
available in LLMs, organized into a fully-annotated modular ontology design
library ready for use with MOMo.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18718" title="Abstract">arXiv:2402.18718</a> [<a href="/pdf/2402.18718" title="Download PDF">pdf</a>, <a href="/format/2402.18718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Pairing Using Embedding Translation for Backdoor Attack Detection  on Open-Set Classification Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unnervik%2C+A">Alexander Unnervik</a>, 
<a href="/search/cs?searchtype=author&query=Shahreza%2C+H+O">Hatef Otroshi Shahreza</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+A">Anjith George</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">S&#xe9;bastien Marcel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Backdoor attacks allow an attacker to embed a specific vulnerability in a
machine learning algorithm, activated when an attacker-chosen pattern is
presented, causing a specific misprediction. The need to identify backdoors in
biometric scenarios has led us to propose a novel technique with different
trade-offs. In this paper we propose to use model pairs on open-set
classification tasks for detecting backdoors. Using a simple linear operation
to project embeddings from a probe model's embedding space to a reference
model's embedding space, we can compare both embeddings and compute a
similarity score. We show that this score, can be an indicator for the presence
of a backdoor despite models being of different architectures, having been
trained independently and on different datasets. Additionally, we show that
backdoors can be detected even when both models are backdoored. The source code
is made available for reproducibility purposes.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18719" title="Abstract">arXiv:2402.18719</a> [<a href="/pdf/2402.18719" title="Download PDF">pdf</a>, <a href="/format/2402.18719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaxCUCL: Max-Consensus with Deterministic Convergence in Networks with  Unreliable Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rikos%2C+A+I">Apostolos I. Rikos</a>, 
<a href="/search/eess?searchtype=author&query=Charalambous%2C+T">Themistoklis Charalambous</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we present a novel distributed algorithm (herein called
MaxCUCL) designed to guarantee that max-consensus is reached in networks
characterized by unreliable communication links (i.e., links suffering from
packet drops). Our proposed algorithm is the first algorithm that achieves
max-consensus in a deterministic manner (i.e., nodes always calculate the
maximum of their states regardless of the nature of the probability
distribution of the packet drops). Furthermore, it allows nodes to determine
whether convergence has been achieved (enabling them to transition to
subsequent tasks). The operation of MaxCUCL relies on the deployment of
narrowband error-free feedback channels used for acknowledging whether a packet
transmission between nodes was successful. We analyze the operation of our
algorithm and show that it converges after a finite number of time steps.
Finally, we demonstrate our algorithm's effectiveness and practical
applicability by applying it to a sensor network deployed for environmental
monitoring.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18721" title="Abstract">arXiv:2402.18721</a> [<a href="/pdf/2402.18721" title="Download PDF">pdf</a>, <a href="/format/2402.18721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A collocation method for nonlinear tensor differential equations on  low-rank manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dektor%2C+A">Alec Dektor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We present a new method to compute the solution to a nonlinear tensor
differential equation with dynamical low-rank approximation. The idea of
dynamical low-rank approximation is to project the differential equation onto
the tangent space of a low-rank tensor manifold at each time. Traditionally, an
orthogonal projection onto the tangent space is employed, which is challenging
to compute for nonlinear differential equations. We introduce a novel
interpolatory projection onto the tangent space that is easily computed for
many nonlinear differential equations and satisfies the differential equation
at a set of carefully selected indices. To select these indices, we devise a
new algorithm based on the discrete empirical interpolation method (DEIM) that
parameterizes any tensor train and its tangent space with tensor cross
interpolants. We demonstrate the proposed method with applications to tensor
differential equations arising from the discretization of partial differential
equations.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18724" title="Abstract">arXiv:2402.18724</a> [<a href="/pdf/2402.18724" title="Download PDF">pdf</a>, <a href="/format/2402.18724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Associative Memories with Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabannes%2C+V">Vivien Cabannes</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+B">Berfin Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Bietti%2C+A">Alberto Bietti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This work focuses on the training dynamics of one associative memory module
storing outer products of token embeddings. We reduce this problem to the study
of a system of particles, which interact according to properties of the data
distribution and correlations between embeddings. Through theory and
experiments, we provide several insights. In overparameterized regimes, we
obtain logarithmic growth of the ``classification margins.'' Yet, we show that
imbalance in token frequencies and memory interferences due to correlated
embeddings lead to oscillatory transitory regimes. The oscillations are more
pronounced with large step sizes, which can create benign loss spikes, although
these learning rates speed up the dynamics and accelerate the asymptotic
convergence. In underparameterized regimes, we illustrate how the cross-entropy
loss can lead to suboptimal memorization schemes. Finally, we assess the
validity of our findings on small Transformer models.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18726" title="Abstract">arXiv:2402.18726</a> [<a href="/pdf/2402.18726" title="Download PDF">pdf</a>, <a href="/format/2402.18726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Privacy, Memorization, and Input Curvature Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+D">Deepak Ravikumar</a>, 
<a href="/search/cs?searchtype=author&query=Soufleri%2C+E">Efstathia Soufleri</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+A">Abolfazl Hashemi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep Neural Nets (DNNs) have become a pervasive tool for solving many
emerging problems. However, they tend to overfit to and memorize the training
set. Memorization is of keen interest since it is closely related to several
concepts such as generalization, noisy learning, and privacy. To study
memorization, Feldman (2019) proposed a formal score, however its computational
requirements limit its practical use. Recent research has shown empirical
evidence linking input loss curvature (measured by the trace of the loss
Hessian w.r.t inputs) and memorization. It was shown to be ~3 orders of
magnitude more efficient than calculating the memorization score. However,
there is a lack of theoretical understanding linking memorization with input
loss curvature. In this paper, we not only investigate this connection but also
extend our analysis to establish theoretical links between differential
privacy, memorization, and input loss curvature. First, we derive an upper
bound on memorization characterized by both differential privacy and input loss
curvature. Second, we present a novel insight showing that input loss curvature
is upper-bounded by the differential privacy parameter. Our theoretical
findings are further empirically validated using deep models on CIFAR and
ImageNet datasets, showing a strong correlation between our theoretical
predictions and results observed in practice.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18728" title="Abstract">arXiv:2402.18728</a> [<a href="/pdf/2402.18728" title="Download PDF">pdf</a>, <a href="/format/2402.18728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All the Same: Understanding and Informing Similarity Estimation in  Tile-Based Video Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berns%2C+S">Sebastian Berns</a>, 
<a href="/search/cs?searchtype=author&query=Volz%2C+V">Vanessa Volz</a>, 
<a href="/search/cs?searchtype=author&query=Tokarchuk%2C+L">Laurissa Tokarchuk</a>, 
<a href="/search/cs?searchtype=author&query=Snodgrass%2C+S">Sam Snodgrass</a>, 
<a href="/search/cs?searchtype=author&query=Guckelsberger%2C+C">Christian Guckelsberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24), 11-16 May 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Similarity estimation is essential for many game AI applications, from the
procedural generation of distinct assets to automated exploration with
game-playing agents. While similarity metrics often substitute human
evaluation, their alignment with our judgement is unclear. Consequently, the
result of their application can fail human expectations, leading to e.g.
unappreciated content or unbelievable agent behaviour. We alleviate this gap
through a multi-factorial study of two tile-based games in two representations,
where participants (N=456) judged the similarity of level triplets. Based on
this data, we construct domain-specific perceptual spaces, encoding
similarity-relevant attributes. We compare 12 metrics to these spaces and
evaluate their approximation quality through several quantitative lenses.
Moreover, we conduct a qualitative labelling study to identify the features
underlying the human similarity judgement in this popular genre. Our findings
inform the selection of existing metrics and highlight requirements for the
design of new similarity metrics benefiting game development and research.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18732" title="Abstract">arXiv:2402.18732</a> [<a href="/pdf/2402.18732" title="Download PDF">pdf</a>, <a href="/format/2402.18732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAIA: Categorical Foundations of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahadevan%2C+S">Sridhar Mahadevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages. arXiv admin note: text overlap with <a href="/abs/2212.08981">arXiv:2212.08981</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we propose GAIA, a generative AI architecture based on
category theory. GAIA is based on a hierarchical model where modules are
organized as a simplicial complex. Each simplicial complex updates its internal
parameters biased on information it receives from its superior simplices and in
turn relays updates to its subordinate sub-simplices. Parameter updates are
formulated in terms of lifting diagrams over simplicial sets, where inner and
outer horn extensions correspond to different types of learning problems.
Backpropagation is modeled as an endofunctor over the category of parameters,
leading to a coalgebraic formulation of deep learning.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18734" title="Abstract">arXiv:2402.18734</a> [<a href="/pdf/2402.18734" title="Download PDF">pdf</a>, <a href="/format/2402.18734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Priority Sampling of Large Language Models for Compilers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grubisic%2C+D">Dejan Grubisic</a>, 
<a href="/search/cs?searchtype=author&query=Cummins%2C+C">Chris Cummins</a>, 
<a href="/search/cs?searchtype=author&query=Seeker%2C+V">Volker Seeker</a>, 
<a href="/search/cs?searchtype=author&query=Leather%2C+H">Hugh Leather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Performance (cs.PF)

</div>
<p class="mathjax">Large language models show great potential in generating and optimizing code.
Widely used sampling methods such as Nucleus Sampling increase the diversity of
generation but often produce repeated samples for low temperatures and
incoherent samples for high temperatures. Furthermore, the temperature
coefficient has to be tuned for each task, limiting its usability. We present
Priority Sampling, a simple and deterministic sampling technique that produces
unique samples ordered by the model's confidence. Each new sample expands the
unexpanded token with the highest probability in the augmented search tree.
Additionally, Priority Sampling supports generation based on regular expression
that provides a controllable and structured exploration process. Priority
Sampling outperforms Nucleus Sampling for any number of samples, boosting the
performance of the original model from 2.87% to 5% improvement over -Oz.
Moreover, it outperforms the autotuner used for the generation of labels for
the training of the original model in just 30 samples.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18736" title="Abstract">arXiv:2402.18736</a> [<a href="/pdf/2402.18736" title="Download PDF">pdf</a>, <a href="/format/2402.18736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functionally-Complete Boolean Logic in Real DRAM Chips: Experimental  Characterization and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuksel%2C+I+E">Ismail Emir Yuksel</a>, 
<a href="/search/cs?searchtype=author&query=Tugrul%2C+Y+C">Yahya Can Tugrul</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+F+N">F. Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">A. Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Luna%2C+J">Juan G&#xf3;mez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at HPCA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Processing-using-DRAM (PuD) is an emerging paradigm that leverages the analog
operational properties of DRAM circuitry to enable massively parallel in-DRAM
computation. PuD has the potential to significantly reduce or eliminate costly
data movement between processing elements and main memory. Prior works
experimentally demonstrate three-input MAJ (i.e., MAJ3) and two-input AND and
OR operations in commercial off-the-shelf (COTS) DRAM chips. Yet,
demonstrations on COTS DRAM chips do not provide a functionally complete set of
operations (e.g., NAND or AND and NOT).
<br />We experimentally demonstrate that COTS DRAM chips are capable of performing
1) functionally-complete Boolean operations: NOT, NAND, and NOR and 2)
many-input (i.e., more than two-input) AND and OR operations. We present an
extensive characterization of new bulk bitwise operations in 256 off-the-shelf
modern DDR4 DRAM chips. We evaluate the reliability of these operations using a
metric called success rate: the fraction of correctly performed bitwise
operations. Among our 19 new observations, we highlight four major results.
First, we can perform the NOT operation on COTS DRAM chips with a 98.37%
success rate on average. Second, we can perform up to 16-input NAND, NOR, AND,
and OR operations on COTS DRAM chips with high reliability (e.g., 16-input
NAND, NOR, AND, and OR with an average success rate of 94.94%, 95.87%, 94.94%,
and 95.85%, respectively). Third, data pattern only slightly affects bitwise
operations. Our results show that executing NAND, NOR, AND, and OR operations
with random data patterns decreases the success rate compared to all
logic-1/logic-0 patterns by 1.39%, 1.97%, 1.43%, and 1.98%, respectively.
Fourth, bitwise operations are highly resilient to temperature changes, with
small success rate fluctuations of at most 1.66% among all the tested
operations when the temperature is increased from 50C to 95C.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18740" title="Abstract">arXiv:2402.18740</a> [<a href="/pdf/2402.18740" title="Download PDF">pdf</a>, <a href="/format/2402.18740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sixth-order parabolic equation on an interval: Eigenfunction expansion,  Green&#x27;s function, and intermediate asymptotics for a finite thin film with  elastic resistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Papanicolaou%2C+N+C">Nectarios C. Papanicolaou</a>, 
<a href="/search/math?searchtype=author&query=Christov%2C+I+C">Ivan C. Christov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">A linear sixth-order partial differential equation (PDE) of ``parabolic''
type describes the dynamics of thin liquid films beneath surfaces with elastic
bending resistance when deflections from the equilibrium film height are small.
On a finite domain, the associated sixth-order Sturm--Liouville eigenvalue
value problem is self-adjoint for the boundary conditions corresponding to a
thin film in a closed trough, and the eigenfunctions form a complete
orthonormal set. Using these eigenfunctions, we derive the Green's function for
the governing sixth-order PDE on a finite interval and compare it to the known
infinite-line solution. Further, we propose a Galerkin spectral method based on
the constructed sixth-order eigenfunctions and their derivative expansions. The
system of ordinary differential equations for the time-dependent expansion
coefficients is solved by standard numerical methods. The numerical approach is
applied to versions of the governing PDE with a second-order derivative (in
addition to the sixth-order one), which arises from gravity acting on the film.
In the absence of gravity, we demonstrate the self-similar intermediate
asymptotics of initially localized disturbances on the film surface, at least
until the disturbances ``feel'' the finite boundaries, and show that the
derived Green's function is the global attractor for such solutions. In the
presence of gravity, we use the proposed spectral numerical method to
demonstrate that self-similar behavior persists, albeit for shortened intervals
of time, even for large values of the gravity-to-bending ratio.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18742" title="Abstract">arXiv:2402.18742</a> [<a href="/pdf/2402.18742" title="Download PDF">pdf</a>, <a href="/format/2402.18742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Importance Sampling Based Methods for Mitigating the Effect of  Class Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panigrahi%2C+I">Indu Panigrahi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Richard Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most state-of-the-art computer vision models heavily depend on data. However,
many datasets exhibit extreme class imbalance which has been shown to
negatively impact model performance. Among the training-time and
data-generation solutions that have been explored, one subset that leverages
existing data is importance sampling. A good deal of this work focuses
primarily on the CIFAR-10 and CIFAR-100 datasets which fail to be
representative of the scale, composition, and complexity of current
state-of-the-art datasets. In this work, we explore and compare three
techniques that derive from importance sampling: loss reweighting,
undersampling, and oversampling. Specifically, we compare the effect of these
techniques on the performance of two encoders on an impactful satellite imagery
dataset, Planet's Amazon Rainforest dataset, in preparation for another work.
Furthermore, we perform supplemental experimentation on a scene classification
dataset, ADE20K, to test on a contrasting domain and clarify our results.
Across both types of encoders, we find that up-weighting the loss for and
undersampling has a negigible effect on the performance on underrepresented
classes. Additionally, our results suggest oversampling generally improves
performance for the same underrepresented classes. Interestingly, our findings
also indicate that there may exist some redundancy in data in the Planet
dataset. Our work aims to provide a foundation for further work on the Planet
dataset and similar domain-specific datasets. We open-source our code at
https://github.com/RichardZhu123/514-class-imbalance for future work on other
satellite imagery datasets as well.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18743" title="Abstract">arXiv:2402.18743</a> [<a href="/pdf/2402.18743" title="Download PDF">pdf</a>, <a href="/format/2402.18743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A revision on Multi-Criteria Decision Making methods for Multi-UAV  Mission Planning Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez-Atencia%2C+C">Cristian Ramirez-Atencia</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Fernandez%2C+V">Victor Rodriguez-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted and acepted in Expert Systems with Applications
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 160, 2020, 113708
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Over the last decade, Unmanned Aerial Vehicles (UAVs) have been extensively
used in many commercial applications due to their manageability and risk
avoidance. One of the main problems considered is the Mission Planning for
multiple UAVs, where a solution plan must be found satisfying the different
constraints of the problem. This problem has multiple variables that must be
optimized simultaneously, such as the makespan, the cost of the mission or the
risk. Therefore, the problem has a lot of possible optimal solutions, and the
operator must select the final solution to be executed among them. In order to
reduce the workload of the operator in this decision process, a Decision
Support System (DSS) becomes necessary. In this work, a DSS consisting of
ranking and filtering systems, which order and reduce the optimal solutions,
has been designed. With regard to the ranking system, a wide range of
Multi-Criteria Decision Making (MCDM) methods, including some fuzzy MCDM, are
compared on a multi-UAV mission planning scenario, in order to study which
method could fit better in a multi-UAV decision support system. Expert
operators have evaluated the solutions returned, and the results show, on the
one hand, that fuzzy methods generally achieve better average scores, and on
the other, that all of the tested methods perform better when the preferences
of the operators are biased towards a specific variable, and worse when their
preferences are balanced. For the filtering system, a similarity function based
on the proximity of the solutions has been designed, and on top of that, a
threshold is tuned empirically to decide how to filter solutions without losing
much of the hypervolume of the space of solutions.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18744" title="Abstract">arXiv:2402.18744</a> [<a href="/pdf/2402.18744" title="Download PDF">pdf</a>, <a href="/ps/2402.18744" title="Download PostScript">ps</a>, <a href="/format/2402.18744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timer-Based Coverage Control for Mobile Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zegers%2C+F+M">Federico M. Zegers</a>, 
<a href="/search/eess?searchtype=author&query=Phillips%2C+S">Sean Phillips</a>, 
<a href="/search/eess?searchtype=author&query=Hicks%2C+G+P">Gregory P. Hicks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work studies the coverage control problem over a static, bounded, and
convex workspace and develops a hybrid extension of the continuous-time Lloyd
algorithm. Each agent in a multi-agent system (MAS) is equipped with a timer
that generates intermittent sampling events, which may occur asynchronously
between agents. At each sampling event, the corresponding agents update their
controllers, which are otherwise held constant. These controllers are shown to
drive the MAS into a neighborhood of the configurations corresponding to a
centroidal Voronoi tessellation, that is, a local minimizer of the standard
locational cost. The result is a distributed control strategy that leverages
intermittent and asynchronous position measurements to disperse the agents
within the workspace. The combination of continuous-time dynamics with
intermittently updated control inputs is modeled as a hybrid system. The
coverage control objective is posed as a set stabilization problem for hybrid
systems, where an invariance based convergence analysis yields sufficient
conditions that ensure all maximal solutions of the hybrid system
asymptotically converge to a desired set. A brief simulation example is
included to showcase the result.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18746" title="Abstract">arXiv:2402.18746</a> [<a href="/pdf/2402.18746" title="Download PDF">pdf</a>, <a href="/format/2402.18746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Computer Architecture Simulation through Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+W">Wajid Ali</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+A">Ayaz Akram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents our approach to accelerate computer architecture
simulation by leveraging machine learning techniques. Traditional computer
architecture simulations are time-consuming, making it challenging to explore
different design choices efficiently. Our proposed model utilizes a combination
of application features and micro-architectural features to predict the
performance of an application. These features are derived from simulations of a
small portion of the application. We demonstrate the effectiveness of our
approach by building and evaluating a machine learning model that offers
significant speedup in architectural exploration. This model demonstrates the
ability to predict IPC values for the testing data with a root mean square
error of less than 0.1.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18747" title="Abstract">arXiv:2402.18747</a> [<a href="/pdf/2402.18747" title="Download PDF">pdf</a>, <a href="/format/2402.18747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuoyang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Currey%2C+A">Anna Currey</a>, 
<a href="/search/cs?searchtype=author&query=Badeka%2C+T">Tatyana Badeka</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jenyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+B">Brian Thompson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce a new, extensive multidimensional quality metrics (MQM)
annotated dataset covering 11 language pairs in the biomedical domain. We use
this dataset to investigate whether machine translation (MT) metrics which are
fine-tuned on human-generated MT quality judgements are robust to domain shifts
between training and inference. We find that fine-tuned metrics exhibit a
substantial performance drop in the unseen domain scenario relative to metrics
that rely on the surface form, as well as pre-trained metrics which are not
fine-tuned on MT quality judgments.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18749" title="Abstract">arXiv:2402.18749</a> [<a href="/pdf/2402.18749" title="Download PDF">pdf</a>, <a href="/format/2402.18749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted strategies to guide a multi-objective evolutionary algorithm  for multi-UAV mission planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez-Atencia%2C+C">Cristian Ramirez-Atencia</a>, 
<a href="/search/cs?searchtype=author&query=Del+Ser%2C+J">Javier Del Ser</a>, 
<a href="/search/cs?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted and accepted in Swarm and Evolutionary Computation
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cristian Ramirez Atencia, Javier Del Ser, David Camacho: Weighted
  strategies to guide a multi-objective evolutionary algorithm for multi-UAV
  mission planning. Swarm and Evolutionary Computation, Volume 44, Pages
  480-495, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Management and mission planning over a swarm of unmanned aerial vehicle (UAV)
remains to date as a challenging research trend in what regards to this
particular type of aircrafts. These vehicles are controlled by a number of
ground control station (GCS), from which they are commanded to cooperatively
perform different tasks in specific geographic areas of interest.
Mathematically the problem of coordinating and assigning tasks to a swarm of
UAV can be modeled as a constraint satisfaction problem, whose complexity and
multiple conflicting criteria has hitherto motivated the adoption of
multi-objective solvers such as multi-objective evolutionary algorithm (MOEA).
The encoding approach consists of different alleles representing the decision
variables, whereas the fitness function checks that all constraints are
fulfilled, minimizing the optimization criteria of the problem. In problems of
high complexity involving several tasks, UAV and GCS, where the space of search
is huge compared to the space of valid solutions, the convergence rate of the
algorithm increases significantly. To overcome this issue, this work proposes a
weighted random generator for the creation and mutation of new individuals. The
main objective of this work is to reduce the convergence rate of the MOEA
solver for multi-UAV mission planning using weighted random strategies that
focus the search on potentially better regions of the solution space. Extensive
experimental results over a diverse range of scenarios evince the benefits of
the proposed approach, which notably improves this convergence rate with
respect to a na\"ive MOEA approach.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18751" title="Abstract">arXiv:2402.18751</a> [<a href="/pdf/2402.18751" title="Download PDF">pdf</a>, <a href="/format/2402.18751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Sensor and Multi-temporal High-Throughput Phenotyping for  Monitoring and Early Detection of Water-Limiting Stress in Soybean
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jones%2C+S+E">Sarah E. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Ayanlade%2C+T">Timilehin Ayanlade</a>, 
<a href="/search/cs?searchtype=author&query=Fallen%2C+B">Benjamin Fallen</a>, 
<a href="/search/cs?searchtype=author&query=Jubery%2C+T+Z">Talukder Z. Jubery</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Arti Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ganapathysubramanian%2C+B">Baskar Ganapathysubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumik Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Asheesh K. Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Soybean production is susceptible to biotic and abiotic stresses, exacerbated
by extreme weather events. Water limiting stress, i.e. drought, emerges as a
significant risk for soybean production, underscoring the need for advancements
in stress monitoring for crop breeding and production. This project combines
multi-modal information to identify the most effective and efficient automated
methods to investigate drought response. We investigated a set of diverse
soybean accessions using multiple sensors in a time series high-throughput
phenotyping manner to: (1) develop a pipeline for rapid classification of
soybean drought stress symptoms, and (2) investigate methods for early
detection of drought stress. We utilized high-throughput time-series
phenotyping using UAVs and sensors in conjunction with machine learning (ML)
analytics, which offered a swift and efficient means of phenotyping. The
red-edge and green bands were most effective to classify canopy wilting stress.
The Red-Edge Chlorophyll Vegetation Index (RECI) successfully differentiated
susceptible and tolerant soybean accessions prior to visual symptom
development. We report pre-visual detection of soybean wilting using a
combination of different vegetation indices. These results can contribute to
early stress detection methodologies and rapid classification of drought
responses in screening nurseries for breeding and production applications.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18752" title="Abstract">arXiv:2402.18752</a> [<a href="/pdf/2402.18752" title="Download PDF">pdf</a>, <a href="/format/2402.18752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training Differentially Private Models with Limited Public Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bu%2C+Z">Zhiqi Bu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+S">Sheng Zha</a>, 
<a href="/search/cs?searchtype=author&query=Karypis%2C+G">George Karypis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The superior performance of large foundation models relies on the use of
massive amounts of high-quality data, which often contain sensitive, private
and copyrighted material that requires formal protection. While differential
privacy (DP) is a prominent method to gauge the degree of security provided to
the models, its application is commonly limited to the model fine-tuning stage,
due to the performance degradation when applying DP during the pre-training
stage. Consequently, DP is yet not capable of protecting a substantial portion
of the data used during the initial pre-training process.
<br />In this work, we first provide a theoretical understanding of the efficacy of
DP training by analyzing the per-iteration loss improvement. We make a key
observation that DP optimizers' performance degradation can be significantly
mitigated by the use of limited public data, which leads to a novel DP
continual pre-training strategy. Empirically, using only 10\% of public data,
our strategy can achieve DP accuracy of 41.5\% on ImageNet-21k (with
$\epsilon=8$), as well as non-DP accuracy of 55.7\% and and 60.0\% on
downstream tasks Places365 and iNaturalist-2021, respectively, on par with
state-of-the-art standard pre-training and substantially outperforming existing
DP pre-trained models.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18753" title="Abstract">arXiv:2402.18753</a> [<a href="/pdf/2402.18753" title="Download PDF">pdf</a>, <a href="/ps/2402.18753" title="Download PostScript">ps</a>, <a href="/format/2402.18753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Like-minded, like-bodied: How users (18-26) trust online eating and  health information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rachel Xu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Nhu Le</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+R">Rebekah Park</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+L">Laura Murray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper investigates the relationship between social media and eating
practices amongst 42 internet users aged 18-26. We conducted an ethnography in
the US and India to observe how they navigated eating and health information
online. We found that participants portrayed themselves online through a
vocabulary we have labeled "the good life": performing holistic health by
displaying a socially-ideal body. In doing so, participants unconsciously
engaged in behaviors of disordered eating while actively eschewing them. They
also valued personal testimonies, and readily tested tips from content creators
who shared similar beliefs and bodies to them. In doing so, they discarded
probabilistic thinking and opened themselves to harm. Our study found that
their social media feeds did not unidirectionally influence participants - they
also reflected participants' internalized views of health, in an intertwined,
non-linear journey. Reducing the online spread of disordered eating practices
requires addressing it within young people's social context.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18754" title="Abstract">arXiv:2402.18754</a> [<a href="/pdf/2402.18754" title="Download PDF">pdf</a>, <a href="/format/2402.18754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending QGroundControl for Automated Mission Planning of UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez-Atencia%2C+C">Cristian Ramirez-Atencia</a>, 
<a href="/search/cs?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted and accepted in Sensors
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 18, no. 7: 2339 (2018)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Unmanned Aerial Vehicle (UAVs) have become very popular in the last decade
due to some advantages such as strong terrain adaptation, low cost, zero
casualties, and so on. One of the most interesting advances in this field is
the automation of mission planning (task allocation) and real-time replanning,
which are highly useful to increase the autonomy of the vehicle and reduce the
operator workload. These automated mission planning and replanning systems
require a Human Computer Interface (HCI) that facilitates the visualization and
selection of plans that will be executed by the vehicles. In addition, most
missions should be assessed before their real-life execution. This paper
extends QGroundControl, an open-source simulation environment for flight
control of multiple vehicles, by adding a mission designer that permits the
operator to build complex missions with tasks and other scenario items; an
interface for automated mission planning and replanning, which works as a test
bed for different algorithms, and a Decision Support System (DSS) that helps
the operator in the selection of the plan. In this work, a complete guide of
these systems and some practical use cases are provided.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18755" title="Abstract">arXiv:2402.18755</a> [<a href="/pdf/2402.18755" title="Download PDF">pdf</a>, <a href="/format/2402.18755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Defeating Graph Analysis of Anonymous Transactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Egger%2C+C">Christoph Egger</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+R+W+F">Russell W. F. Lai</a>, 
<a href="/search/cs?searchtype=author&query=Ronge%2C+V">Viktoria Ronge</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+I+K+Y">Ivy K. Y. Woo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H+H+F">Hoover H. F. Yin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings on Privacy Enhancing Technologies (PoPETs), Vol. 2022,
  Issue 3, Pages 538-557
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In a ring-signature-based anonymous cryptocurrency, signers of a transaction
are hidden among a set of potential signers, called a ring, whose size is much
smaller than the number of all users. The ring-membership relations specified
by the sets of transactions thus induce bipartite transaction graphs, whose
distribution is in turn induced by the ring sampler underlying the
cryptocurrency.
<br />Since efficient graph analysis could be performed on transaction graphs to
potentially deanonymise signers, it is crucial to understand the resistance of
(the transaction graphs induced by) a ring sampler against graph analysis. Of
particular interest is the class of partitioning ring samplers. Although
previous works showed that they provide almost optimal local anonymity, their
resistance against global, e.g. graph-based, attacks were unclear.
<br />In this work, we analyse transaction graphs induced by partitioning ring
samplers. Specifically, we show (partly analytically and partly empirically)
that, somewhat surprisingly, by setting the ring size to be at least
logarithmic in the number of users, a graph-analysing adversary is no better
than the one that performs random guessing in deanonymisation up to constant
factor of 2.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18756" title="Abstract">arXiv:2402.18756</a> [<a href="/pdf/2402.18756" title="Download PDF">pdf</a>, <a href="/format/2402.18756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Much Annotation is Needed to Compare Summarization Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaib%2C+C">Chantal Shaib</a>, 
<a href="/search/cs?searchtype=author&query=Barrow%2C+J">Joe Barrow</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+A+F">Alexa F. Siu</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+B+C">Byron C. Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Nenkova%2C+A">Ani Nenkova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Modern instruction-tuned models have become highly capable in text generation
tasks such as summarization, and are expected to be released at a steady pace.
In practice one may now wish to choose confidently, but with minimal effort,
the best performing summarization model when applied to a new domain or
purpose. In this work, we empirically investigate the test sample size
necessary to select a preferred model in the context of news summarization.
Empirical results reveal that comparative evaluation converges quickly for both
automatic and human evaluation, with clear preferences for a system emerging
from under 100 examples. The human preference data allows us to quantify how
well automatic scores can reproduce preference rankings across a variety of
downstream summarization tasks. We find that, while automatic metrics are
stable at smaller sample sizes, only some automatic metrics are able to
moderately predict model win rates according to human preference.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18759" title="Abstract">arXiv:2402.18759</a> [<a href="/pdf/2402.18759" title="Download PDF">pdf</a>, <a href="/format/2402.18759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Language-Guided State Abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+A">Andi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sucholutsky%2C+I">Ilia Sucholutsky</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B+Z">Belinda Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Sumers%2C+T+R">Theodore R. Sumers</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+J+A">Julie A. Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We describe a framework for using natural language to design state
abstractions for imitation learning. Generalizable policy learning in
high-dimensional observation spaces is facilitated by well-designed state
representations, which can surface important features of an environment and
hide irrelevant ones. These state representations are typically manually
specified, or derived from other labor-intensive labeling procedures. Our
method, LGA (language-guided abstraction), uses a combination of natural
language supervision and background knowledge from language models (LMs) to
automatically build state representations tailored to unseen tasks. In LGA, a
user first provides a (possibly incomplete) description of a target task in
natural language; next, a pre-trained LM translates this task description into
a state abstraction function that masks out irrelevant features; finally, an
imitation policy is trained using a small number of demonstrations and
LGA-generated abstract states. Experiments on simulated robotic tasks show that
LGA yields state abstractions similar to those designed by humans, but in a
fraction of the time, and that these abstractions improve generalization and
robustness in the presence of spurious correlations and ambiguous
specifications. We illustrate the utility of the learned abstractions on mobile
manipulation tasks with a Spot robot.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18762" title="Abstract">arXiv:2402.18762</a> [<a href="/pdf/2402.18762" title="Download PDF">pdf</a>, <a href="/format/2402.18762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling the Causes of Plasticity Loss in Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyle%2C+C">Clare Lyle</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zeyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Khetarpal%2C+K">Khimya Khetarpal</a>, 
<a href="/search/cs?searchtype=author&query=van+Hasselt%2C+H">Hado van Hasselt</a>, 
<a href="/search/cs?searchtype=author&query=Pascanu%2C+R">Razvan Pascanu</a>, 
<a href="/search/cs?searchtype=author&query=Martens%2C+J">James Martens</a>, 
<a href="/search/cs?searchtype=author&query=Dabney%2C+W">Will Dabney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Underpinning the past decades of work on the design, initialization, and
optimization of neural networks is a seemingly innocuous assumption: that the
network is trained on a \textit{stationary} data distribution. In settings
where this assumption is violated, e.g.\ deep reinforcement learning, learning
algorithms become unstable and brittle with respect to hyperparameters and even
random seeds. One factor driving this instability is the loss of plasticity,
meaning that updating the network's predictions in response to new information
becomes more difficult as training progresses. While many recent works provide
analyses and partial solutions to this phenomenon, a fundamental question
remains unanswered: to what extent do known mechanisms of plasticity loss
overlap, and how can mitigation strategies be combined to best maintain the
trainability of a network? This paper addresses these questions, showing that
loss of plasticity can be decomposed into multiple independent mechanisms and
that, while intervening on any single mechanism is insufficient to avoid the
loss of plasticity in all cases, intervening on multiple mechanisms in
conjunction results in highly robust learning algorithms. We show that a
combination of layer normalization and weight decay is highly effective at
maintaining plasticity in a variety of synthetic nonstationary learning tasks,
and further demonstrate its effectiveness on naturally arising
nonstationarities, including reinforcement learning in the Arcade Learning
Environment.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18766" title="Abstract">arXiv:2402.18766</a> [<a href="/pdf/2402.18766" title="Download PDF">pdf</a>, <a href="/ps/2402.18766" title="Download PostScript">ps</a>, <a href="/format/2402.18766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Generative AI for Portuguese with Open Decoder Gerv&#xe1;sio PT*
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+R">Rodrigo Santos</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J">Jo&#xe3;o Silva</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+L">Lu&#xed;s Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+J">Jo&#xe3;o Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Branco%2C+A">Ant&#xf3;nio Branco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To advance the neural decoding of Portuguese, in this paper we present a
fully open Transformer-based, instruction-tuned decoder model that sets a new
state of the art in this respect. To develop this decoder, which we named
Gerv\'asio PT*, a strong LLaMA~2 7B model was used as a starting point, and its
further improvement through additional training was done over language
resources that include new instruction data sets of Portuguese prepared for
this purpose, which are also contributed in this paper. All versions of
Gerv\'asio are open source and distributed for free under an open license,
including for either research or commercial usage, and can be run on
consumer-grade hardware, thus seeking to contribute to the advancement of
research and innovation in language technology for Portuguese.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18769" title="Abstract">arXiv:2402.18769</a> [<a href="/pdf/2402.18769" title="Download PDF">pdf</a>, <a href="/format/2402.18769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoMeT: Count-Min-Sketch-based Row Tracking to Mitigate RowHammer at Low  Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+F+N">F. Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Yuksel%2C+I+E">Ismail Emir Yuksel</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+K">Konstantinos Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tugrul%2C+Y+C">Yahya Can Tugrul</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">A. Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at HPCA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">We propose a new RowHammer mitigation mechanism, CoMeT, that prevents
RowHammer bitflips with low area, performance, and energy costs in DRAM-based
systems at very low RowHammer thresholds. The key idea of CoMeT is to use
low-cost and scalable hash-based counters to track DRAM row activations. CoMeT
uses the Count-Min Sketch technique that maps each DRAM row to a group of
counters, as uniquely as possible, using multiple hash functions. When a DRAM
row is activated, CoMeT increments the counters mapped to that DRAM row.
Because the mapping from DRAM rows to counters is not completely unique,
activating one row can increment one or more counters mapped to another row.
Thus, CoMeT may overestimate, but never underestimates, a DRAM row's activation
count. This property of CoMeT allows it to securely prevent RowHammer bitflips
while properly configuring its hash functions reduces overestimations. As a
result, CoMeT 1) implements substantially fewer counters than the number of
DRAM rows in a DRAM bank and 2) does not significantly overestimate a DRAM
row's activation count.
<br />Our comprehensive evaluations show that CoMeT prevents RowHammer bitflips
with an average performance overhead of only 4.01% across 61 benign single-core
workloads for a very low RowHammer threshold of 125, normalized to a system
with no RowHammer mitigation. CoMeT achieves a good trade-off between
performance, energy, and area overheads. Compared to the best-performing
state-of-the-art mitigation, CoMeT requires 74.2x less area overhead at the
RowHammer threshold 125 and incurs a small performance overhead on average for
all RowHammer thresholds. Compared to the best-performing low-area-cost
mechanism, at a very low RowHammer threshold of 125, CoMeT improves performance
by up to 39.1% while incurring a similar area overhead. CoMeT is openly and
freely available at https://github.com/CMU-SAFARI/CoMeT.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18771" title="Abstract">arXiv:2402.18771</a> [<a href="/pdf/2402.18771" title="Download PDF">pdf</a>, <a href="/format/2402.18771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NARUTO: Neural Active Reconstruction from Uncertain Target Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Ziyue Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Huangying Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qingan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Changjiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qilun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024. Revised version and code will be released after camera-ready deadline
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present NARUTO, a neural active reconstruction system that combines a
hybrid neural representation with uncertainty learning, enabling high-fidelity
surface reconstruction. Our approach leverages a multi-resolution hash-grid as
the mapping backbone, chosen for its exceptional convergence speed and capacity
to capture high-frequency local features.The centerpiece of our work is the
incorporation of an uncertainty learning module that dynamically quantifies
reconstruction uncertainty while actively reconstructing the environment. By
harnessing learned uncertainty, we propose a novel uncertainty aggregation
strategy for goal searching and efficient path planning. Our system
autonomously explores by targeting uncertain observations and reconstructs
environments with remarkable completeness and fidelity. We also demonstrate the
utility of this uncertainty-aware approach by enhancing SOTA neural SLAM
systems through an active ray sampling strategy. Extensive evaluations of
NARUTO in various environments, using an indoor scene simulator, confirm its
superior performance and state-of-the-art status in active reconstruction, as
evidenced by its impressive results on benchmark datasets like Replica and
MP3D.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18774" title="Abstract">arXiv:2402.18774</a> [<a href="/pdf/2402.18774" title="Download PDF">pdf</a>, <a href="/format/2402.18774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Situate AI Guidebook: Co-Designing a Toolkit to Support  Multi-Stakeholder Early-stage Deliberations Around Public Sector AI Proposals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawakami%2C+A">Anna Kawakami</a>, 
<a href="/search/cs?searchtype=author&query=Coston%2C+A">Amanda Coston</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haiyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+H">Hoda Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Holstein%2C+K">Kenneth Holstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Public sector agencies are rapidly deploying AI systems to augment or
automate critical decisions in real-world contexts like child welfare, criminal
justice, and public health. A growing body of work documents how these AI
systems often fail to improve services in practice. These failures can often be
traced to decisions made during the early stages of AI ideation and design,
such as problem formulation. However, today, we lack systematic processes to
support effective, early-stage decision-making about whether and under what
conditions to move forward with a proposed AI project. To understand how to
scaffold such processes in real-world settings, we worked with public sector
agency leaders, AI developers, frontline workers, and community advocates
across four public sector agencies and three community advocacy groups in the
United States. Through an iterative co-design process, we created the Situate
AI Guidebook: a structured process centered around a set of deliberation
questions to scaffold conversations around (1) goals and intended use or a
proposed AI system, (2) societal and legal considerations, (3) data and
modeling constraints, and (4) organizational governance factors. We discuss how
the guidebook's design is informed by participants' challenges, needs, and
desires for improved deliberation processes. We further elaborate on
implications for designing responsible AI toolkits in collaboration with public
sector agency stakeholders and opportunities for future work to expand upon the
guidebook. This design approach can be more broadly adopted to support the
co-creation of responsible AI toolkits that scaffold key decision-making
processes surrounding the use of AI in the public sector and beyond.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18775" title="Abstract">arXiv:2402.18775</a> [<a href="/pdf/2402.18775" title="Download PDF">pdf</a>, <a href="/ps/2402.18775" title="Download PostScript">ps</a>, <a href="/format/2402.18775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Evaluate Human-likeness of Interaction-aware Driver Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jemin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+C">Changsun Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This study proposes a method for qualitatively evaluating and designing
human-like driver models for autonomous vehicles. While most existing research
on human-likeness has been focused on quantitative evaluation, it is crucial to
consider qualitative measures to accurately capture human perception. To this
end, we conducted surveys utilizing both video study and human experience-based
study. The findings of this research can significantly contribute to the
development of naturalistic and human-like driver models for autonomous
vehicles, enabling them to safely and efficiently coexist with human-driven
vehicles in diverse driving scenarios.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18778" title="Abstract">arXiv:2402.18778</a> [<a href="/pdf/2402.18778" title="Download PDF">pdf</a>, <a href="/format/2402.18778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-ResQ: Reverse Annealing for Quantum MIMO Detection with Flexible  Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Abhishek Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Venturelli%2C+D">Davide Venturelli</a>, 
<a href="/search/cs?searchtype=author&query=Kaewell%2C+J">John Kaewell</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kyle Jamieson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum Annealing (QA)-accelerated MIMO detection is an emerging research
approach in the context of NextG wireless networks. The opportunity is to
enable large MIMO systems and thus improve wireless performance. The approach
aims to leverage QA to expedite the computation required for theoretically
optimal but computationally-demanding Maximum Likelihood detection to overcome
the limitations of the currently deployed linear detectors. This paper presents
\textbf{X-ResQ}, a QA-based MIMO detector system featuring fine-grained quantum
task parallelism that is uniquely enabled by the Reverse Annealing (RA)
protocol. Unlike prior designs, X-ResQ has many desirable system properties for
a parallel QA detector and has effectively improved detection performance as
more qubits are assigned. In our evaluations on a state-of-the-art quantum
annealer, fully parallel X-ResQ achieves near-optimal throughput (over 10
bits/s/Hz) for $4\times6$ MIMO with 16-QAM using six levels of parallelism with
240 qubits and $220~\mu$s QA compute time, achieving 2.5--5$\times$ gains
compared against other tested detectors. For more comprehensive evaluations, we
implement and evaluate X-ResQ in the non-quantum digital setting. This
non-quantum X-ResQ demonstration showcases the potential to realize ultra-large
$1024\times1024$ MIMO, significantly outperforming other MIMO detectors,
including the state-of-the-art RA detector classically implemented in the same
way.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18780" title="Abstract">arXiv:2402.18780</a> [<a href="/pdf/2402.18780" title="Download PDF">pdf</a>, <a href="/format/2402.18780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantitative Evaluation of Score Distillation Sampling Based  Text-to-3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+X">Xiaohan Fei</a>, 
<a href="/search/cs?searchtype=author&query=Parameshwara%2C+C">Chethan Parameshwara</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+J">Jiawei Mo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaolong Li</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Ashwin Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C">CJ Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+P">Paolo Favaro</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of generative models that create 3D content from a text
prompt has made considerable strides thanks to the use of the score
distillation sampling (SDS) method on pre-trained diffusion models for image
generation. However, the SDS method is also the source of several artifacts,
such as the Janus problem, the misalignment between the text prompt and the
generated 3D model, and 3D model inaccuracies. While existing methods heavily
rely on the qualitative assessment of these artifacts through visual inspection
of a limited set of samples, in this work we propose more objective
quantitative evaluation metrics, which we cross-validate via human ratings, and
show analysis of the failure cases of the SDS technique. We demonstrate the
effectiveness of this analysis by designing a novel computationally efficient
baseline model that achieves state-of-the-art performance on the proposed
metrics while addressing all the above-mentioned artifacts.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18781" title="Abstract">arXiv:2402.18781</a> [<a href="/pdf/2402.18781" title="Download PDF">pdf</a>, <a href="/ps/2402.18781" title="Download PostScript">ps</a>, <a href="/format/2402.18781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conjectural Online Learning with First-order Beliefs in Asymmetric  Information Stochastic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hammar%2C+K">Kim Hammar</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+R">Rolf Stadler</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Stochastic games arise in many complex socio-technical systems, such as
cyber-physical systems and IT infrastructures, where information asymmetry
presents challenges for decision-making entities (players). Existing
computational methods for asymmetric information stochastic games (AISG) are
primarily offline, targeting special classes of AISGs to avoid belief
hierarchies, and lack online adaptability to deviations from equilibrium. To
address this limitation, we propose a conjectural online learning (COL), a
learning scheme for generic AISGs. COL, structured as a forecaster-actor-critic
(FAC) architecture, utilizes first-order beliefs over the hidden states and
subjective forecasts of the opponent's strategies. Against the conjectured
opponent, COL updates strategies in an actor-critic approach using online
rollout and calibrates conjectures through Bayesian learning. We prove that
conjecture in COL is asymptotically consistent with the information feedback in
the sense of a relaxed Bayesian consistency. The resulting empirical strategy
profile converges to the Berk-Nash equilibrium, a solution concept
characterizing rationality under subjectivity. Experimental results from an
intrusion response use case demonstrate COL's superiority over state-of-the-art
reinforcement learning methods against nonstationary attacks.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18784" title="Abstract">arXiv:2402.18784</a> [<a href="/pdf/2402.18784" title="Download PDF">pdf</a>, <a href="/format/2402.18784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-inspired and Self-based Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+E">Enmeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuoya Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jihang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qingqun Kong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yinqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wenxuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiang He</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+A">Aorigele Bao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The question "Can machines think?" and the Turing Test to assess whether
machines could achieve human-level intelligence is one of the roots of AI. With
the philosophical argument "I think, therefore I am", this paper challenge the
idea of a "thinking machine" supported by current AIs since there is no sense
of self in them. Current artificial intelligence is only seemingly intelligent
information processing and does not truly understand or be subjectively aware
of oneself and perceive the world with the self as human intelligence does. In
this paper, we introduce a Brain-inspired and Self-based Artificial
Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to
coordinating various cognitive functions and learning strategies in a
self-organized manner to build human-level AI models and robotic applications.
Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the
future AI, rooted with a practical hierarchical Self framework, including
Perception and Learning, Bodily Self, Autonomous Self, Social Self, and
Conceptual Self. The hierarchical framework of the Self highlights self-based
environment perception, self-bodily modeling, autonomous interaction with the
environment, social interaction and collaboration with others, and even more
abstract understanding of the Self. Furthermore, the positive mutual promotion
and support among multiple levels of Self, as well as between Self and
learning, enhance the BriSe AI's conscious understanding of information and
flexible adaptation to complex environments, serving as a driving force
propelling BriSe AI towards real Artificial General Intelligence.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18786" title="Abstract">arXiv:2402.18786</a> [<a href="/pdf/2402.18786" title="Download PDF">pdf</a>, <a href="/format/2402.18786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpticalDR: A Deep Optical Imaging Model for Privacy-Protective  Depression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Keyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depression Recognition (DR) poses a considerable challenge, especially in the
context of the growing concerns surrounding privacy. Traditional automatic
diagnosis of DR technology necessitates the use of facial images, undoubtedly
expose the patient identity features and poses privacy risks. In order to
mitigate the potential risks associated with the inappropriate disclosure of
patient facial images, we design a new imaging system to erase the identity
information of captured facial images while retain disease-relevant features.
It is irreversible for identity information recovery while preserving essential
disease-related characteristics necessary for accurate DR. More specifically,
we try to record a de-identified facial image (erasing the identifiable
features as much as possible) by a learnable lens, which is optimized in
conjunction with the following DR task as well as a range of face analysis
related auxiliary tasks in an end-to-end manner. These aforementioned
strategies form our final Optical deep Depression Recognition network
(OpticalDR). Experiments on CelebA, AVEC 2013, and AVEC 2014 datasets
demonstrate that our OpticalDR has achieved state-of-the-art privacy protection
performance with an average AUC of 0.51 on popular facial recognition models,
and competitive results for DR with MAE/RMSE of 7.53/8.48 on AVEC 2013 and
7.89/8.82 on AVEC 2014, respectively.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18787" title="Abstract">arXiv:2402.18787</a> [<a href="/pdf/2402.18787" title="Download PDF">pdf</a>, <a href="/format/2402.18787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the &quot;Immunity&quot; of Mixture-of-Experts Networks for Adversarial  Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qiao Han</a>, 
<a href="/search/cs?searchtype=author&query=huang%2C+y">yong huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+x">xinling Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yiteng Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recent studies have revealed the vulnerability of Deep Neural Networks (DNNs)
to adversarial examples, which can easily fool DNNs into making incorrect
predictions. To mitigate this deficiency, we propose a novel adversarial
defense method called "Immunity" (Innovative MoE with MUtual information \&amp;
positioN stabilITY) based on a modified Mixture-of-Experts (MoE) architecture
in this work. The key enhancements to the standard MoE are two-fold: 1)
integrating of Random Switch Gates (RSGs) to obtain diverse network structures
via random permutation of RSG parameters at evaluation time, despite of RSGs
being determined after one-time training; 2) devising innovative Mutual
Information (MI)-based and Position Stability-based loss functions by
capitalizing on Grad-CAM's explanatory power to increase the diversity and the
causality of expert networks. Notably, our MI-based loss operates directly on
the heatmaps, thereby inducing subtler negative impacts on the classification
performance when compared to other losses of the same type, theoretically.
Extensive evaluation validates the efficacy of the proposed approach in
improving adversarial robustness against a wide range of attacks.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18789" title="Abstract">arXiv:2402.18789</a> [<a href="/pdf/2402.18789" title="Download PDF">pdf</a>, <a href="/format/2402.18789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexLLM: A System for Co-Serving Large Language Model Inference and  Parameter-Efficient Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Oliaro%2C+G">Gabriele Oliaro</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengdi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Unger%2C+C">Colin Unger</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Parameter-efficient finetuning (PEFT) is a widely used technique to adapt
large language models for different tasks. Service providers typically create
separate systems for users to perform PEFT model finetuning and inference
tasks. This is because existing systems cannot handle workloads that include a
mix of inference and PEFT finetuning requests. As a result, shared GPU
resources are underutilized, leading to inefficiencies. To address this
problem, we present FlexLLM, the first system that can serve inference and
parameter-efficient finetuning requests in the same iteration. Our system
leverages the complementary nature of these two tasks and utilizes shared GPU
resources to run them jointly, using a method called co-serving. To achieve
this, FlexLLM introduces a novel token-level finetuning mechanism, which breaks
down the finetuning computation of a sequence into smaller token-level
computations and uses dependent parallelization and graph pruning, two static
compilation optimizations, to minimize the memory overhead and latency for
co-serving. Compared to existing systems, FlexLLM's co-serving approach reduces
the activation GPU memory overhead by up to 8x, and the end-to-end GPU memory
requirement of finetuning by up to 36% while maintaining a low inference
latency and improving finetuning throughput. For example, under a heavy
inference workload, FlexLLM can still preserve more than 80% of the peak
finetuning throughput, whereas existing systems cannot make any progress with
finetuning. The source code of FlexLLM is publicly available at
https://github.com/flexflow/FlexFlow.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18792" title="Abstract">arXiv:2402.18792</a> [<a href="/pdf/2402.18792" title="Download PDF">pdf</a>, <a href="/format/2402.18792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPAT: Building Robust Deep Neural Networks against Textual Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fangyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huichi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuangjiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongtao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks have been proven to be vulnerable to adversarial
examples and various methods have been proposed to defend against adversarial
attacks for natural language processing tasks. However, previous defense
methods have limitations in maintaining effective defense while ensuring the
performance of the original task. In this paper, we propose a malicious
perturbation based adversarial training method (MPAT) for building robust deep
neural networks against textual adversarial attacks. Specifically, we construct
a multi-level malicious example generation strategy to generate adversarial
examples with malicious perturbations, which are used instead of original
inputs for model training. Additionally, we employ a novel training objective
function to ensure achieving the defense goal without compromising the
performance on the original task. We conduct comprehensive experiments to
evaluate our defense method by attacking five victim models on three benchmark
datasets. The result demonstrates that our method is more effective against
malicious adversarial attacks compared with previous defense methods while
maintaining or further improving the performance on the original task.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18793" title="Abstract">arXiv:2402.18793</a> [<a href="/pdf/2402.18793" title="Download PDF">pdf</a>, <a href="/format/2402.18793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Orthogonal Basis Method for Computing Multiple Solutions of  Differential Equations with polynomial nonlinearities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+Y">Yangyi Ye</a>, 
<a href="/search/math?searchtype=author&query=Hao%2C+W">Wenrui Hao</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huiyuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents an innovative approach, the Adaptive Orthogonal Basis
Method, tailored for computing multiple solutions to differential equations
characterized by polynomial nonlinearities. Departing from conventional
practices of predefining candidate basis pools, our novel method adaptively
computes bases, considering the equation's nature and structural
characteristics of the solution. It further leverages companion matrix
techniques to generate initial guesses for subsequent computations. Thus this
approach not only yields numerous initial guesses for solving such equations
but also adapts orthogonal basis functions to effectively address discretized
nonlinear systems. Through a series of numerical experiments, this paper
demonstrates the method's effectiveness and robustness. By reducing
computational costs in various applications, this novel approach opens new
avenues for uncovering multiple solutions to differential equations with
polynomial nonlinearities.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18796" title="Abstract">arXiv:2402.18796</a> [<a href="/pdf/2402.18796" title="Download PDF">pdf</a>, <a href="/format/2402.18796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOSAIC: A Modular System for Assistive and Interactive Cooking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaxiaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kedia%2C+K">Kushal Kedia</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Juntao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+R">Rahma Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+A">Atiksh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+A">Angela Chao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K+Y">Kelly Y Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+N">Nathaniel Chin</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+P">Prithwish Dan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xinyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Pumariega%2C+G">Gonzalo Gonzalez-Pumariega</a>, 
<a href="/search/cs?searchtype=author&query=Kompella%2C+A">Aditya Kompella</a>, 
<a href="/search/cs?searchtype=author&query=Pace%2C+M+A">Maximus Adrian Pace</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+Y">Yash Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangwan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sunkara%2C+N">Neha Sunkara</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present MOSAIC, a modular architecture for home robots to perform complex
collaborative tasks, such as cooking with everyday users. MOSAIC tightly
collaborates with humans, interacts with users using natural language,
coordinates multiple robots, and manages an open vocabulary of everyday
objects. At its core, MOSAIC employs modularity: it leverages multiple
large-scale pre-trained models for general tasks like language and image
recognition, while using streamlined modules designed for task-specific
control. We extensively evaluate MOSAIC on 60 end-to-end trials where two
robots collaborate with a human user to cook a combination of 6 recipes. We
also extensively test individual modules with 180 episodes of visuomotor
picking, 60 episodes of human motion forecasting, and 46 online user
evaluations of the task planner. We show that MOSAIC is able to efficiently
collaborate with humans by running the overall system end-to-end with a real
human user, completing 68.3% (41/60) collaborative cooking trials of 6
different recipes with a subtask completion rate of 91.6%. Finally, we discuss
the limitations of the current system and exciting open challenges in this
domain. The project's website is at https://portal-cornell.github.io/MOSAIC/
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18797" title="Abstract">arXiv:2402.18797</a> [<a href="/pdf/2402.18797" title="Download PDF">pdf</a>, <a href="/format/2402.18797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARTiST: Automated Text Simplification for Task Guidance in Augmented  Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guande Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Castelo%2C+S">Sonia Castelo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rulff%2C+J">Joao Rulff</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+C">Claudio Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally accepted by CHI '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Text presented in augmented reality provides in-situ, real-time information
for users. However, this content can be challenging to apprehend quickly when
engaging in cognitively demanding AR tasks, especially when it is presented on
a head-mounted display. We propose ARTiST, an automatic text simplification
system that uses a few-shot prompt and GPT-3 models to specifically optimize
the text length and semantic content for augmented reality. Developed out of a
formative study that included seven users and three experts, our system
combines a customized error calibration model with a few-shot prompt to
integrate the syntactic, lexical, elaborative, and content simplification
techniques, and generate simplified AR text for head-worn displays. Results
from a 16-user empirical study showed that ARTiST lightens the cognitive load
and improves performance significantly over both unmodified text and text
modified via traditional methods. Our work constitutes a step towards
automating the optimization of batch text data for readability and performance
in augmented reality.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18800" title="Abstract">arXiv:2402.18800</a> [<a href="/pdf/2402.18800" title="Download PDF">pdf</a>, <a href="/format/2402.18800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise  Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yiteng Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Block-wise missing data poses significant challenges in real-world data
imputation tasks. Compared to scattered missing data, block-wise gaps
exacerbate adverse effects on subsequent analytic and machine learning tasks,
as the lack of local neighboring elements significantly reduces the
interpolation capability and predictive power. However, this issue has not
received adequate attention. Most SOTA matrix completion methods appeared less
effective, primarily due to overreliance on neighboring elements for
predictions. We systematically analyze the issue and propose a novel matrix
completion method ``BlockEcho" for a more comprehensive solution. This method
creatively integrates Matrix Factorization (MF) within Generative Adversarial
Networks (GAN) to explicitly retain long-distance inter-element relationships
in the original matrix. Besides, we incorporate an additional discriminator for
GAN, comparing the generator's intermediate progress with pre-trained MF
results to constrain high-order feature distributions. Subsequently, we
evaluate BlockEcho on public datasets across three domains. Results demonstrate
superior performance over both traditional and SOTA methods when imputing
block-wise missing data, especially at higher missing rates. The advantage also
holds for scattered missing data at high missing rates. We also contribute on
the analyses in providing theoretical justification on the optimality and
convergence of fusing MF and GAN for missing block data.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18803" title="Abstract">arXiv:2402.18803</a> [<a href="/pdf/2402.18803" title="Download PDF">pdf</a>, <a href="/format/2402.18803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair  Training on Shared Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cousins%2C+C">Cyrus Cousins</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+I+E">I. Elizabeth Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Venkatasubramanian%2C+S">Suresh Venkatasubramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In fair machine learning, one source of performance disparities between
groups is over-fitting to groups with relatively few training samples. We
derive group-specific bounds on the generalization error of welfare-centric
fair machine learning that benefit from the larger sample size of the majority
group. We do this by considering group-specific Rademacher averages over a
restricted hypothesis class, which contains the family of models likely to
perform well with respect to a fair learning objective (e.g., a power-mean).
Our simulations demonstrate these bounds improve over a naive method, as
expected by theory, with particularly significant improvement for smaller group
sizes.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18805" title="Abstract">arXiv:2402.18805</a> [<a href="/pdf/2402.18805" title="Download PDF">pdf</a>, <a href="/format/2402.18805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braun%2C+G">Guillaume Braun</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Social networks are often associated with rich side information, such as
texts and images. While numerous methods have been developed to identify
communities from pairwise interactions, they usually ignore such side
information. In this work, we study an extension of the Stochastic Block Model
(SBM), a widely used statistical framework for community detection, that
integrates vectorial edges covariates: the Vectorial Edges Covariates
Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on
iterative refinement techniques and show that it optimally recovers the latent
communities under the VEC-SBM. Furthermore, we rigorously assess the added
value of leveraging edge's side information in the community detection process.
We complement our theoretical results with numerical experiments on synthetic
and semi-synthetic data.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18807" title="Abstract">arXiv:2402.18807</a> [<a href="/pdf/2402.18807" title="Download PDF">pdf</a>, <a href="/format/2402.18807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Decision-Making Abilities in Role-Playing using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chenglei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guofu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) are now increasingly utilized for role-playing
tasks, especially in impersonating domain-specific experts, primarily through
role-playing prompts. When interacting in real-world scenarios, the
decision-making abilities of a role significantly shape its behavioral
patterns. In this paper, we concentrate on evaluating the decision-making
abilities of LLMs post role-playing thereby validating the efficacy of
role-playing. Our goal is to provide metrics and guidance for enhancing the
decision-making abilities of LLMs in role-playing tasks. Specifically, we first
use LLMs to generate virtual role descriptions corresponding to the 16
personality types of Myers-Briggs Type Indicator (abbreviated as MBTI)
representing a segmentation of the population. Then we design specific
quantitative operations to evaluate the decision-making abilities of LLMs post
role-playing from four aspects: adaptability, exploration$\&amp;$exploitation
trade-off ability, reasoning ability, and safety. Finally, we analyze the
association between the performance of decision-making and the corresponding
MBTI types through GPT-4. Extensive experiments demonstrate stable differences
in the four aspects of decision-making abilities across distinct roles,
signifying a robust correlation between decision-making abilities and the roles
emulated by LLMs. These results underscore that LLMs can effectively
impersonate varied roles while embodying their genuine sociological
characteristics.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18811" title="Abstract">arXiv:2402.18811</a> [<a href="/pdf/2402.18811" title="Download PDF">pdf</a>, <a href="/format/2402.18811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BFRFormer: Transformer-based generator for Real-World Blind Face  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+G">Guojing Ge</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qi Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guibo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinglu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+M">Miao Xin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Blind face restoration is a challenging task due to the unknown and complex
degradation. Although face prior-based methods and reference-based methods have
recently demonstrated high-quality results, the restored images tend to contain
over-smoothed results and lose identity-preserved details when the degradation
is severe. It is observed that this is attributed to short-range dependencies,
the intrinsic limitation of convolutional neural networks. To model long-range
dependencies, we propose a Transformer-based blind face restoration method,
named BFRFormer, to reconstruct images with more identity-preserved details in
an end-to-end manner. In BFRFormer, to remove blocking artifacts, the wavelet
discriminator and aggregated attention module are developed, and spectral
normalization and balanced consistency regulation are adaptively applied to
address the training instability and over-fitting problem, respectively.
Extensive experiments show that our method outperforms state-of-the-art methods
on a synthetic dataset and four real-world datasets. The source code,
Casia-Test dataset, and pre-trained models are released at
https://github.com/s8Znk/BFRFormer.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18813" title="Abstract">arXiv:2402.18813</a> [<a href="/pdf/2402.18813" title="Download PDF">pdf</a>, <a href="/format/2402.18813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protein Multimer Structure Prediction via Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Ziqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zijing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Understanding the 3D structures of protein multimers is crucial, as they play
a vital role in regulating various cellular processes. It has been empirically
confirmed that the multimer structure prediction~(MSP) can be well handled in a
step-wise assembly fashion using provided dimer structures and predicted
protein-protein interactions~(PPIs). However, due to the biological gap in the
formation of dimers and larger multimers, directly applying PPI prediction
techniques can often cause a \textit{poor generalization} to the MSP task. To
address this challenge, we aim to extend the PPI knowledge to multimers of
different scales~(i.e., chain numbers). Specifically, we propose
\textbf{\textsc{PromptMSP}}, a pre-training and \textbf{Prompt} tuning
framework for \textbf{M}ultimer \textbf{S}tructure \textbf{P}rediction. First,
we tailor the source and target tasks for effective PPI knowledge learning and
efficient inference, respectively. We design PPI-inspired prompt learning to
narrow the gaps of two task formats and generalize the PPI knowledge to
multimers of different scales. We provide a meta-learning strategy to learn a
reliable initialization of the prompt model, enabling our prompting framework
to effectively adapt to limited data for large-scale multimers. Empirically, we
achieve both significant accuracy (RMSD and TM-Score) and efficiency
improvements compared to advanced MSP models. The code, data and checkpoints
are released at \url{https://github.com/zqgao22/PromptMSP}.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18814" title="Abstract">arXiv:2402.18814</a> [<a href="/pdf/2402.18814" title="Download PDF">pdf</a>, <a href="/format/2402.18814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New topological subsystem codes from semi-regular tessellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+E+B">Eduardo Brandani da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Brizola%2C+E+M">Evandro Mazetto Brizola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this work, we present new constructions for topological subsystem codes
using semi-regular Euclidean and hyperbolic tessellations. They give us new
families of codes, and we also provide a new family of codes obtained through
an already existing construction, due to Sarvepalli and Brown. We also prove
new results that allow us to obtain the parameters of these new codes.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18815" title="Abstract">arXiv:2402.18815</a> [<a href="/pdf/2402.18815" title="Download PDF">pdf</a>, <a href="/format/2402.18815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do Large Language Models Handle Multilingualism?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guizhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) demonstrate remarkable performance across a
spectrum of languages. In this work, we delve into the question: How do LLMs
handle multilingualism? We introduce a framework that depicts LLMs' processing
of multilingual inputs: In the first several layers, LLMs understand the
question, converting multilingual inputs into English to facilitate the
task-solving phase. In the intermediate layers, LLMs engage in problem-solving
by thinking in English and incorporating multilingual knowledge to obtain
factual content, leveraging the self-attention and feed-forward structures,
respectively. In the last several layers, LLMs generate responses that align
with the original language of the query. In addition, we investigate the
existence of language-specific neurons when processing a certain language. To
detect neurons activated by the input language, even without labels, we
innovatively design a Parallel Language specific Neuron Detection
($\texttt{PLND}$) method that effectively measures the significance of neurons
when handling multilingual inputs. By comprehensive ablation analysis through
deactivating neurons of different layers and structures, we verify the
framework that we propose. Additionally, we demonstrate that we can utilize
such a framework to effectively enhance the multilingual ability with much less
training effort.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18817" title="Abstract">arXiv:2402.18817</a> [<a href="/pdf/2402.18817" title="Download PDF">pdf</a>, <a href="/format/2402.18817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Alignment for Cross-Domain Face Anti-Spoofing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+B+M">Binh M. Le</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in domain generalization (DG) for face anti-spoofing
(FAS) have garnered considerable attention. Traditional methods have focused on
designing learning objectives and additional modules to isolate domain-specific
features while retaining domain-invariant characteristics in their
representations. However, such approaches often lack guarantees of consistent
maintenance of domain-invariant features or the complete removal of
domain-specific features. Furthermore, most prior works of DG for FAS do not
ensure convergence to a local flat minimum, which has been shown to be
advantageous for DG. In this paper, we introduce GAC-FAS, a novel learning
objective that encourages the model to converge towards an optimal flat minimum
without necessitating additional learning modules. Unlike conventional
sharpness-aware minimizers, GAC-FAS identifies ascending points for each domain
and regulates the generalization gradient updates at these points to align
coherently with empirical risk minimization (ERM) gradient updates. This unique
approach specifically guides the model to be robust against domain shifts. We
demonstrate the efficacy of GAC-FAS through rigorous testing on challenging
cross-domain FAS datasets, where it establishes state-of-the-art performance.
The code is available at https://github.com/leminhbinh0209/CVPR24-FAS.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18818" title="Abstract">arXiv:2402.18818</a> [<a href="/pdf/2402.18818" title="Download PDF">pdf</a>, <a href="/format/2402.18818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CEBin: A Cost-Effective Framework for Large-Scale Binary Code Similarity  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zeyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xi Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Binary code similarity detection (BCSD) is a fundamental technique for
various application. Many BCSD solutions have been proposed recently, which
mostly are embedding-based, but have shown limited accuracy and efficiency
especially when the volume of target binaries to search is large. To address
this issue, we propose a cost-effective BCSD framework, CEBin, which fuses
embedding-based and comparison-based approaches to significantly improve
accuracy while minimizing overheads. Specifically, CEBin utilizes a refined
embedding-based approach to extract features of target code, which efficiently
narrows down the scope of candidate similar code and boosts performance. Then,
it utilizes a comparison-based approach that performs a pairwise comparison on
the candidates to capture more nuanced and complex relationships, which greatly
improves the accuracy of similarity detection. By bridging the gap between
embedding-based and comparison-based approaches, CEBin is able to provide an
effective and efficient solution for detecting similar code (including
vulnerable ones) in large-scale software ecosystems. Experimental results on
three well-known datasets demonstrate the superiority of CEBin over existing
state-of-the-art (SOTA) baselines. To further evaluate the usefulness of BCSD
in real world, we construct a large-scale benchmark of vulnerability, offering
the first precise evaluation scheme to assess BCSD methods for the 1-day
vulnerability detection task. CEBin could identify the similar function from
millions of candidate functions in just a few seconds and achieves an
impressive recall rate of $85.46\%$ on this more practical but challenging
task, which are several order of magnitudes faster and $4.07\times$ better than
the best SOTA baseline. Our code is available at
https://github.com/Hustcw/CEBin.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18819" title="Abstract">arXiv:2402.18819</a> [<a href="/pdf/2402.18819" title="Download PDF">pdf</a>, <a href="/format/2402.18819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Operating Modes of In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Ziqian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kangwook Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In-context learning (ICL) exhibits dual operating modes: task learning, i.e.,
acquiring a new skill from in-context samples, and task retrieval, i.e.,
locating and activating a relevant pretrained skill. Recent theoretical work
investigates various mathematical models to analyze ICL, but existing models
explain only one operating mode at a time. We introduce a probabilistic model,
with which one can explain the dual operating modes of ICL simultaneously.
Focusing on in-context learning of linear functions, we extend existing models
for pretraining data by introducing multiple task groups and task-dependent
input distributions. We then analyze the behavior of the optimally pretrained
model under the squared loss, i.e., the MMSE estimator of the label given
in-context examples. Regarding pretraining task distribution as prior and
in-context examples as the observation, we derive the closed-form expression of
the task posterior distribution. With the closed-form expression, we obtain a
quantitative understanding of the two operating modes of ICL. Furthermore, we
shed light on an unexplained phenomenon observed in practice: under certain
settings, the ICL risk initially increases and then decreases with more
in-context examples. Our model offers a plausible explanation for this "early
ascent" phenomenon: a limited number of in-context samples may lead to the
retrieval of an incorrect skill, thereby increasing the risk, which will
eventually diminish as task learning takes effect with more in-context samples.
We also theoretically analyze ICL with biased labels, e.g., zero-shot ICL,
where in-context examples are assigned random labels. Lastly, we validate our
findings and predictions via experiments involving Transformers and large
language models.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18821" title="Abstract">arXiv:2402.18821</a> [<a href="/pdf/2402.18821" title="Download PDF">pdf</a>, <a href="/format/2402.18821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiased Novel Category Discovering and Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Juexiao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yanchun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yandong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuchen Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuwei He</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liuyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, object detection in deep learning has experienced rapid
development. However, most existing object detection models perform well only
on closed-set datasets, ignoring a large number of potential objects whose
categories are not defined in the training set. These objects are often
identified as background or incorrectly classified as pre-defined categories by
the detectors. In this paper, we focus on the challenging problem of Novel
Class Discovery and Localization (NCDL), aiming to train detectors that can
detect the categories present in the training data, while also actively
discover, localize, and cluster new categories. We analyze existing NCDL
methods and identify the core issue: object detectors tend to be biased towards
seen objects, and this leads to the neglect of unseen targets. To address this
issue, we first propose an Debiased Region Mining (DRM) approach that combines
class-agnostic Region Proposal Network (RPN) and class-aware RPN in a
complementary manner. Additionally, we suggest to improve the representation
network through semi-supervised contrastive learning by leveraging unlabeled
data. Finally, we adopt a simple and efficient mini-batch K-means clustering
method for novel class discovery. We conduct extensive experiments on the NCDL
benchmark, and the results demonstrate that the proposed DRM approach
significantly outperforms previous methods, establishing a new
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18824" title="Abstract">arXiv:2402.18824</a> [<a href="/pdf/2402.18824" title="Download PDF">pdf</a>, <a href="/format/2402.18824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch size invariant Adam
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aitchison%2C+L">Laurence Aitchison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a batch size invariant version of Adam, for use in large-scale,
distributed settings, in which the mini-batch is divided into micro-batches
which are distributed among worker nodes. For the v term, standard Adam first
computes the average over micro-batch gradients, then squares, while in the
batch size invariant Adam proposed here, we first square the micro-batch
gradients, then average. Previous work (e.g. Malladi et al. 2022) used an
alternative approach that involved a square-root scaling of the learning rate,
but this approach requires strong assumptions to work; in particular that the
gradient variance dominates the square of the expected gradient. In contrast,
the approach proposed here gives batch size invariance without this assumption.
We confirm that in practice our scheme gives batch size invariance in a much
larger range of scenarios than the previous approach.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18825" title="Abstract">arXiv:2402.18825</a> [<a href="/pdf/2402.18825" title="Download PDF">pdf</a>, <a href="/format/2402.18825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Local Hierarchy with Adversarial Training for Hierarchical  Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Houfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Hierarchical text classification (HTC) is a challenging subtask of
multi-label classification due to its complex taxonomic structure. Nearly all
recent HTC works focus on how the labels are structured but ignore the
sub-structure of ground-truth labels according to each input text which
contains fruitful label co-occurrence information. In this work, we introduce
this local hierarchy with an adversarial framework. We propose a HiAdv
framework that can fit in nearly all HTC models and optimize them with the
local hierarchy as auxiliary information. We test on two typical HTC models and
find that HiAdv is effective in all scenarios and is adept at dealing with
complex taxonomic hierarchies. Further experiments demonstrate that the
promotion of our framework indeed comes from the local hierarchy and the local
hierarchy is beneficial for rare classes which have insufficient training data.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18826" title="Abstract">arXiv:2402.18826</a> [<a href="/pdf/2402.18826" title="Download PDF">pdf</a>, <a href="/ps/2402.18826" title="Download PostScript">ps</a>, <a href="/format/2402.18826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Machine Can&#x27;t Replace the Human Heart
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Baihan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">What is the true heart of mental healthcare -- innovation or humanity? Can
virtual therapy ever replicate the profound human bonds where healing arises?
As artificial intelligence and immersive technologies promise expanded access,
safeguards must ensure technologies remain supplementary tools guided by
providers' wisdom. Implementation requires nuance balancing efficiency and
empathy. If conscious of ethical risks, perhaps AI could restore humanity by
automating tasks, giving providers more time to listen. Yet no algorithm can
replicate the seat of dignity within. We must ask ourselves: What future has
people at its core? One where AI thoughtfully plays a collaborative role? Or
where pursuit of progress leaves vulnerability behind? This commentary argues
for a balanced approach thoughtfully integrating technology while retaining
care's irreplaceable human essence, at the heart of this profoundly human
profession. Ultimately, by nurturing innovation and humanity together, perhaps
we reach new heights of empathy previously unimaginable.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18835" title="Abstract">arXiv:2402.18835</a> [<a href="/pdf/2402.18835" title="Download PDF">pdf</a>, <a href="/ps/2402.18835" title="Download PostScript">ps</a>, <a href="/format/2402.18835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Envisioning the Applications and Implications of Generative AI for News  Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishal%2C+S">Sachita Nishal</a>, 
<a href="/search/cs?searchtype=author&query=Diakopoulos%2C+N">Nicholas Diakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2023 Workshop on Generative AI and HCI; 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This article considers the increasing use of algorithmic decision-support
systems and synthetic media in the newsroom, and explores how generative models
can help reporters and editors across a range of tasks from the conception of a
news story to its distribution. Specifically, we draw from a taxonomy of tasks
associated with news production, and discuss where generative models could
appropriately support reporters, the journalistic and ethical values that must
be preserved within these interactions, and the resulting implications for
design contributions in this area in the future. Our essay is relevant to
practitioners and researchers as they consider using generative AI systems to
support different tasks and workflows.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18836" title="Abstract">arXiv:2402.18836</a> [<a href="/pdf/2402.18836" title="Download PDF">pdf</a>, <a href="/ps/2402.18836" title="Download PostScript">ps</a>, <a href="/format/2402.18836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Model-Based Approach for Improving Reinforcement Learning Efficiency  Leveraging Expert Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozcan%2C+E+C">Erhan Can Ozcan</a>, 
<a href="/search/cs?searchtype=author&query=Giammarino%2C+V">Vittorio Giammarino</a>, 
<a href="/search/cs?searchtype=author&query=Queeney%2C+J">James Queeney</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidis%2C+I+C">Ioannis Ch. Paschalidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper investigates how to incorporate expert observations (without
explicit information on expert actions) into a deep reinforcement learning
setting to improve sample efficiency. First, we formulate an augmented policy
loss combining a maximum entropy reinforcement learning objective with a
behavioral cloning loss that leverages a forward dynamics model. Then, we
propose an algorithm that automatically adjusts the weights of each component
in the augmented loss function. Experiments on a variety of continuous control
tasks demonstrate that the proposed algorithm outperforms various benchmarks by
effectively utilizing available expert observations.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18838" title="Abstract">arXiv:2402.18838</a> [<a href="/pdf/2402.18838" title="Download PDF">pdf</a>, <a href="/format/2402.18838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When does word order matter and when doesn&#x27;t it?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanda Chen</a>, 
<a href="/search/cs?searchtype=author&query=O%27Donnell%2C+T">Timothy O&#x27;Donnell</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models (LMs) may appear insensitive to word order changes in natural
language understanding (NLU) tasks. In this paper, we propose that linguistic
redundancy can explain this phenomenon, whereby word order and other linguistic
cues such as case markers provide overlapping and thus redundant information.
Our hypothesis is that models exhibit insensitivity to word order when the
order provides redundant information, and the degree of insensitivity varies
across tasks. We quantify how informative word order is using mutual
information (MI) between unscrambled and scrambled sentences. Our results show
the effect that the less informative word order is, the more consistent the
model's predictions are between unscrambled and scrambled sentences. We also
find that the effect varies across tasks: for some tasks, like SST-2, LMs'
prediction is almost always consistent with the original one even if the
Pointwise-MI (PMI) changes, while for others, like RTE, the consistency is near
random when the PMI gets lower, i.e., word order is really important.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18839" title="Abstract">arXiv:2402.18839</a> [<a href="/pdf/2402.18839" title="Download PDF">pdf</a>, <a href="/format/2402.18839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Flow Matching: a Method of Conditional Generation with  Generalized Continuity Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isobe%2C+N">Noboru Isobe</a>, 
<a href="/search/cs?searchtype=author&query=Koyama%2C+M">Masanori Koyama</a>, 
<a href="/search/cs?searchtype=author&query=Hayashi%2C+K">Kohei Hayashi</a>, 
<a href="/search/cs?searchtype=author&query=Fukumizu%2C+K">Kenji Fukumizu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Functional Analysis (math.FA); Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">The task of conditional generation is one of the most important applications
of generative models, and numerous methods have been developed to date based on
the celebrated diffusion models, with the guidance-based classifier-free method
taking the lead. However, the theory of the guidance-based method not only
requires the user to fine-tune the "guidance strength," but its target vector
field does not necessarily correspond to the conditional distribution used in
training. In this paper, we develop the theory of conditional generation based
on Flow Matching, a current strong contender of diffusion methods. Motivated by
the interpretation of a probability path as a distribution on path space, we
establish a novel theory of flow-based generation of conditional distribution
by employing the mathematical framework of generalized continuity equation
instead of the continuity equation in flow matching. This theory naturally
derives a method that aims to match the matrix field as opposed to the vector
field. Our framework ensures the continuity of the generated conditional
distribution through the existence of flow between conditional distributions.
We will present our theory through experiments and mathematical results.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18842" title="Abstract">arXiv:2402.18842</a> [<a href="/pdf/2402.18842" title="Download PDF">pdf</a>, <a href="/format/2402.18842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViewFusion: Towards Multi-View Consistency via Interpolated Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xianghui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Ramasinghe%2C+S">Sameera Ramasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Bazzani%2C+L">Loris Bazzani</a>, 
<a href="/search/cs?searchtype=author&query=Avraham%2C+G">Gil Avraham</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024,homepage:<a href="https://wi-sc.github.io/ViewFusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Novel-view synthesis through diffusion models has demonstrated remarkable
potential for generating diverse and high-quality images. Yet, the independent
process of image generation in these prevailing methods leads to challenges in
maintaining multiple-view consistency. To address this, we introduce
ViewFusion, a novel, training-free algorithm that can be seamlessly integrated
into existing pre-trained diffusion models. Our approach adopts an
auto-regressive method that implicitly leverages previously generated views as
context for the next view generation, ensuring robust multi-view consistency
during the novel-view generation process. Through a diffusion process that
fuses known-view information via interpolated denoising, our framework
successfully extends single-view conditioned models to work in multiple-view
conditional settings without any additional fine-tuning. Extensive experimental
results demonstrate the effectiveness of ViewFusion in generating consistent
and detailed novel views.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18844" title="Abstract">arXiv:2402.18844</a> [<a href="/pdf/2402.18844" title="Download PDF">pdf</a>, <a href="/format/2402.18844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for 3D Human Pose Estimation and Mesh Recovery: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+C">Changzhen Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">3D human pose estimation and mesh recovery have attracted widespread research
interest in many areas, such as computer vision, autonomous driving, and
robotics. Deep learning on 3D human pose estimation and mesh recovery has
recently thrived, with numerous methods proposed to address different problems
in this area. In this paper, to stimulate future research, we present a
comprehensive review of recent progress over the past five years in deep
learning methods for this area by delving into over 200 references. To the best
of our knowledge, this survey is arguably the first to comprehensively cover
deep learning methods for 3D human pose estimation, including both
single-person and multi-person approaches, as well as human mesh recovery,
encompassing methods based on explicit models and implicit representations. We
also present comparative results on several publicly available datasets,
together with insightful observations and inspiring future research directions.
A regularly updated project page can be found at
https://github.com/liuyangme/SOTA-3DHPE-HMR.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18846" title="Abstract">arXiv:2402.18846</a> [<a href="/pdf/2402.18846" title="Download PDF">pdf</a>, <a href="/format/2402.18846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Fidelity Residual Neural Processes for Scalable Surrogate Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+R">Ruijia Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kai Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi-An Ma</a>, 
<a href="/search/cs?searchtype=author&query=Watson-Parris%2C+D">Duncan Watson-Parris</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A novel probabilistic inference approach for scalable multi-fidelity surrogate modeling
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-fidelity surrogate modeling aims to learn an accurate surrogate at the
highest fidelity level by combining data from multiple sources. Traditional
methods relying on Gaussian processes can hardly scale to high-dimensional
data. Deep learning approaches utilize neural network based encoders and
decoders to improve scalability. These approaches share encoded representations
across fidelities without including corresponding decoder parameters. At the
highest fidelity, the representations are decoded with different parameters,
making the shared information inherently inaccurate. This hinders inference
performance, especially in out-of-distribution scenarios when the highest
fidelity data has limited domain coverage. To address these limitations, we
propose Multi-fidelity Residual Neural Processes (MFRNP), a novel
multi-fidelity surrogate modeling framework. MFRNP optimizes lower fidelity
decoders for accurate information sharing by aggregating lower fidelity
surrogate outputs and models residual between the aggregation and ground truth
on the highest fidelity. We show that MFRNP significantly outperforms current
state-of-the-art in learning partial differential equations and a real-world
climate modeling task.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18847" title="Abstract">arXiv:2402.18847</a> [<a href="/pdf/2402.18847" title="Download PDF">pdf</a>, <a href="/format/2402.18847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Precoding for Multi-User Movable Antenna Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+W">Wanting Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+B">Boyu Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongpei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This letter rethinks traditional precoding in multi-user wireless
communications with movable antennas (MAs). Utilizing MAs for optimal antenna
positioning, we introduce a sparse optimization (SO)-based approach focusing on
regularized zero-forcing (RZF). This framework targets the optimization of
antenna positions and the precoding matrix to minimize inter-user interference
and transmit power. We propose an off-grid regularized least squares-based
orthogonal matching pursuit (RLS-OMP) method for this purpose. Moreover, we
provide deeper insights into antenna position optimization using RLS-OMP,
viewed from a subspace projection angle. Overall, our proposed flexible
precoding scheme demonstrates a sum rate that exceeds more than twice that of
fixed antenna positions.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18848" title="Abstract">arXiv:2402.18848</a> [<a href="/pdf/2402.18848" title="Download PDF">pdf</a>, <a href="/format/2402.18848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwitchLight: Co-design of Physics-driven Architecture and Pre-training  Framework for Human Portrait Relighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+M">Minje Jang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+W">Wonjun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jisoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Donghyun Na</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sanghyun Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024. Live demos available at <a href="https://www.beeble.ai/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a co-designed approach for human portrait relighting that
combines a physics-guided architecture with a pre-training framework. Drawing
on the Cook-Torrance reflectance model, we have meticulously configured the
architecture design to precisely simulate light-surface interactions.
Furthermore, to overcome the limitation of scarce high-quality lightstage data,
we have developed a self-supervised pre-training strategy. This novel
combination of accurate physical modeling and expanded training dataset
establishes a new benchmark in relighting realism.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18849" title="Abstract">arXiv:2402.18849</a> [<a href="/pdf/2402.18849" title="Download PDF">pdf</a>, <a href="/ps/2402.18849" title="Download PostScript">ps</a>, <a href="/format/2402.18849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP  Models on Accuracy and Semantic Coherence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Maoqin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Pengsihua%2C+H">Han Pengsihua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This study discusses a new method combining image steganography technology
with Natural Language Processing (NLP) large models, aimed at improving the
accuracy and robustness of extracting steganographic text. Traditional Least
Significant Bit (LSB) steganography techniques face challenges in accuracy and
robustness of information extraction when dealing with complex character
encoding, such as Chinese characters. To address this issue, this study
proposes an innovative LSB-NLP hybrid framework. This framework integrates the
advanced capabilities of NLP large models, such as error detection, correction,
and semantic consistency analysis, as well as information reconstruction
techniques, thereby significantly enhancing the robustness of steganographic
text extraction. Experimental results show that the LSB-NLP hybrid framework
excels in improving the extraction accuracy of steganographic text, especially
in handling Chinese characters. The findings of this study not only confirm the
effectiveness of combining image steganography technology and NLP large models
but also propose new ideas for research and application in the field of
information hiding. The successful implementation of this interdisciplinary
approach demonstrates the great potential of integrating image steganography
technology with natural language processing technology in solving complex
information processing problems.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18851" title="Abstract">arXiv:2402.18851</a> [<a href="/pdf/2402.18851" title="Download PDF">pdf</a>, <a href="/format/2402.18851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of 0-1 Neural Networks in Prescription and Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+V">Vrishabh Patil</a>, 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+K">Kara Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Mintz%2C+Y">Yonatan Mintz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">A key challenge in medical decision making is learning treatment policies for
patients with limited observational data. This challenge is particularly
evident in personalized healthcare decision-making, where models need to take
into account the intricate relationships between patient characteristics,
treatment options, and health outcomes. To address this, we introduce
prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed
integer programming that can be used with counterfactual estimation to optimize
policies in medium data settings. These models offer greater interpretability
than deep neural networks and can encode more complex policies than common
models such as decision trees. We show that PNNs can outperform existing
methods in both synthetic data experiments and in a case study of assigning
treatments for postpartum hypertension. In particular, PNNs are shown to
produce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02)
over existing clinical practice, and by 2 mm Hg (p=0.01) over the next best
prescriptive modeling technique. Moreover PNNs were more likely than all other
models to correctly identify clinically significant features while existing
models relied on potentially dangerous features such as patient insurance
information and race that could lead to bias in treatment.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18853" title="Abstract">arXiv:2402.18853</a> [<a href="/pdf/2402.18853" title="Download PDF">pdf</a>, <a href="/format/2402.18853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Multi-domain Generalization with A General Learning Objective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhaorui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-domain generalization (mDG) is universally aimed to minimize the
discrepancy between training and testing distributions to enhance
marginal-to-label distribution mapping. However, existing mDG literature lacks
a general learning objective paradigm and often imposes constraints on static
target marginal distributions. In this paper, we propose to leverage a
$Y$-mapping to relax the constraint. We rethink the learning objective for mDG
and design a new \textbf{general learning objective} to interpret and analyze
most existing mDG wisdom. This general objective is bifurcated into two
synergistic amis: learning domain-independent conditional features and
maximizing a posterior. Explorations also extend to two effective
regularization terms that incorporate prior information and suppress invalid
causality, alleviating the issues that come with relaxed constraints. We
theoretically contribute an upper bound for the domain alignment of
domain-independent conditional features, disclosing that many previous mDG
endeavors actually \textbf{optimize partially the objective} and thus lead to
limited performance. As such, our study distills a general learning objective
into four practical components, providing a general, robust, and flexible
mechanism to handle complex domain shifts. Extensive empirical results indicate
that the proposed objective with $Y$-mapping leads to substantially better mDG
performance in various downstream tasks, including regression, segmentation,
and classification.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18859" title="Abstract">arXiv:2402.18859</a> [<a href="/pdf/2402.18859" title="Download PDF">pdf</a>, <a href="/format/2402.18859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking Second-life Batteries from Exhausted to Empowered using  Experiments, Data Analysis, and Health Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiaofan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Muhammad Aadil Khan</a>, 
<a href="/search/cs?searchtype=author&query=Pozzato%2C+G">Gabriele Pozzato</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Surinder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Ratnesh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Onori%2C+S">Simona Onori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The reuse of retired electric vehicle (EV) batteries in electric grid energy
storage emerges as a promising strategy to address environmental concerns and
boost economic value. This study concentrates on devising health monitoring
algorithms for retired batteries (BMS$_2$) deployed in grid storage
applications. Over 15 months of testing, we compile, analyze, and publicly
share a dataset of second-life (SL) batteries, implementing a cycling protocol
simulating grid energy storage load profiles within a 3 V-4 V voltage window.
Four machine learning-based health estimation models, relying on BMS$_2$
features and initial capacity, are developed and compared, with the selected
model achieving a Mean Absolute Percentage Error (MAPE) below 2.3% on test
data. Additionally, an adaptive online health estimation algorithm is proposed
by integrating a clustering-based method, limiting estimation errors during
online deployment. These results constitute an initial proof of concept,
showcasing the feasibility of repurposing retired batteries for second-life
applications. Based on obtained data and representative power demand, these SL
batteries exhibit the potential, under specific conditions, for over a decade
of grid energy storage use.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18860" title="Abstract">arXiv:2402.18860</a> [<a href="/pdf/2402.18860" title="Download PDF">pdf</a>, <a href="/ps/2402.18860" title="Download PostScript">ps</a>, <a href="/format/2402.18860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimation for finite element method on meshes that contain thin  elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kobayashi%2C+K">Kenta Kobayashi</a>, 
<a href="/search/math?searchtype=author&query=Tsuchiya%2C+T">Takuya Tsuchiya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In an error estimation of finite element solutions to the Poisson equation,
we usually impose the shape regularity assumption on the meshes to be used. In
this paper, we show that even if the shape regularity condition is violated,
the standard error estimation can be obtained if "bad" elements (elements that
violate the shape regularity or maximum angle condition) are covered virtually
by "good" simplices. A numerical experiment confirms the theoretical result.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18863" title="Abstract">arXiv:2402.18863</a> [<a href="/pdf/2402.18863" title="Download PDF">pdf</a>, <a href="/format/2402.18863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Lipschitzness and the Stable Rank for Comparing  Explanation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simpson%2C+L">Lachlan Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Millar%2C+K">Kyle Millar</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">Adriel Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+C">Cheng-Chew Lim</a>, 
<a href="/search/cs?searchtype=author&query=Chew%2C+H+G">Hong Gunn Chew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Explainability models are now prevalent within machine learning to address
the black-box nature of neural networks. The question now is which
explainability model is most effective. Probabilistic Lipschitzness has
demonstrated that the smoothness of a neural network is fundamentally linked to
the quality of post hoc explanations. In this work, we prove theoretical lower
bounds on the probabilistic Lipschitzness of Integrated Gradients, LIME and
SmoothGrad. We propose a novel metric using probabilistic Lipschitzness,
normalised astuteness, to compare the robustness of explainability models.
Further, we prove a link between the local Lipschitz constant of a neural
network and its stable rank. We then demonstrate that the stable rank of a
neural network provides a heuristic for the robustness of explainability
models.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18865" title="Abstract">arXiv:2402.18865</a> [<a href="/pdf/2402.18865" title="Download PDF">pdf</a>, <a href="/format/2402.18865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weijieying Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+W">Wei Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Existing research has shown that large language models (LLMs) exhibit
remarkable performance in language understanding and generation. However, when
LLMs are continuously fine-tuned on complex and diverse domain-specific
downstream tasks, the inference performance on historical tasks decreases
dramatically, which is known as a catastrophic forgetting problem. A trade-off
needs to be kept between learning plasticity and memory stability. Plenty of
existing works have explored strategies like memory replay, regularization and
parameter isolation, but little is known about the geometric connection of
various adjacent minima in the continual LLMs fine-tuning scenarios. In this
work, we investigate the geometric connections of different minima through the
lens of mode connectivity, which means different minima can be connected by a
low-loss valley. Through extensive experiments, we uncover the mode
connectivity phenomenon in the LLMs continual learning scenario and find that
it can strike a balance between plasticity and stability. Building upon these
findings, we propose a simple yet effective method called Interpolation-based
LoRA (I-LoRA), which constructs a dual-memory experience replay framework based
on LoRA parameter interpolations. Extensive experiments and analysis on eight
domain-specific CL benchmarks demonstrate that I-LoRA consistently show
significant improvement over the previous state-of-the-art approaches with up
to $11\%$ performance gains, providing a strong baseline and insights for
future research on the large language model continual learning problem. Our
code is available at \url{https://github.com/which47/LLMCL}.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18866" title="Abstract">arXiv:2402.18866</a> [<a href="/pdf/2402.18866" title="Download PDF">pdf</a>, <a href="/format/2402.18866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamed%2C+H">Hany Hamed</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Subin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaesik Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungjin Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Model-based reinforcement learning (MBRL) has been a primary approach to
ameliorating the sample efficiency issue as well as to make a generalist agent.
However, there has not been much effort toward enhancing the strategy of
dreaming itself. Therefore, it is a question whether and how an agent can
"dream better" in a more structured and strategic way. In this paper, inspired
by the observation from cognitive science suggesting that humans use a spatial
divide-and-conquer strategy in planning, we propose a new MBRL agent, called
Dr. Strategy, which is equipped with a novel Dreaming Strategy. The proposed
agent realizes a version of divide-and-conquer-like strategy in dreaming. This
is achieved by learning a set of latent landmarks and then utilizing these to
learn a landmark-conditioned highway policy. With the highway policy, the agent
can first learn in the dream to move to a landmark, and from there it tackles
the exploration and achievement task in a more focused way. In experiments, we
show that the proposed model outperforms prior pixel-based MBRL methods in
various visually complex and partially observable navigation tasks. The source
code will be available at https://github.com/ahn-ml/drstrategy
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18869" title="Abstract">arXiv:2402.18869</a> [<a href="/pdf/2402.18869" title="Download PDF">pdf</a>, <a href="/format/2402.18869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Gilbert-Varshamov Bound for Constrained Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+K">Keshav Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Kiah%2C+H+M">Han Mao Kiah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 Pages, 5 figures, submitted to Entropy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We revisit the well-known Gilbert-Varshamov (GV) bound for constrained
systems. In 1991, Kolesnik and Krachkovsky showed that GV bound can be
determined via the solution of some optimization problem. Later, Marcus and
Roth (1992) modified the optimization problem and improved the GV bound in many
instances. In this work, we provide explicit numerical procedures to solve
these two optimization problems and hence, compute the bounds. We then show the
procedures can be further simplified when we plot the respective curves. In the
case where the graph presentation comprise a single state, we provide explicit
formulas for both bounds.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18873" title="Abstract">arXiv:2402.18873</a> [<a href="/pdf/2402.18873" title="Download PDF">pdf</a>, <a href="/format/2402.18873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Hallucinations in Entity Abstract Summarization with  Facts-Template Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Entity abstract summarization aims to generate a coherent description of a
given entity based on a set of relevant Internet documents. Pretrained language
models (PLMs) have achieved significant success in this task, but they may
suffer from hallucinations, i.e. generating non-factual information about the
entity. To address this issue, we decompose the summary into two components:
Facts that represent the factual information about the given entity, which PLMs
are prone to fabricate; and Template that comprises generic content with
designated slots for facts, which PLMs can generate competently. Based on the
facts-template decomposition, we propose SlotSum, an explainable framework for
entity abstract summarization. SlotSum first creates the template and then
predicts the fact for each template slot based on the input documents.
Benefiting from our facts-template decomposition, SlotSum can easily locate
errors and further rectify hallucinated predictions with external knowledge. We
construct a new dataset WikiFactSum to evaluate the performance of SlotSum.
Experimental results demonstrate that SlotSum could generate summaries that are
significantly more factual with credible external knowledge.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18875" title="Abstract">arXiv:2402.18875</a> [<a href="/pdf/2402.18875" title="Download PDF">pdf</a>, <a href="/format/2402.18875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss-aware Curriculum Learning for Heterogeneous Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+Z+H">Zhen Hao Wong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hansi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaoyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Quanming Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Heterogeneous Graph Neural Networks (HGNNs) are a class of deep learning
models designed specifically for heterogeneous graphs, which are graphs that
contain different types of nodes and edges. This paper investigates the
application of curriculum learning techniques to improve the performance and
robustness of Heterogeneous Graph Neural Networks (GNNs). To better classify
the quality of the data, we design a loss-aware training schedule, named LTS
that measures the quality of every nodes of the data and incorporate the
training dataset into the model in a progressive manner that increases
difficulty step by step. LTS can be seamlessly integrated into various
frameworks, effectively reducing bias and variance, mitigating the impact of
noisy data, and enhancing overall accuracy. Our findings demonstrate the
efficacy of curriculum learning in enhancing HGNNs capabilities for analyzing
complex graph-structured data. The code is public at https:
//github.com/LARS-research/CLGNN/.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18877" title="Abstract">arXiv:2402.18877</a> [<a href="/pdf/2402.18877" title="Download PDF">pdf</a>, <a href="/format/2402.18877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principal Component Analysis as a Sanity Check for Bayesian  Phylolinguistic Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murawaki%2C+Y">Yugo Murawaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Bayesian approaches to reconstructing the evolutionary history of languages
rely on the tree model, which assumes that these languages descended from a
common ancestor and underwent modifications over time. However, this assumption
can be violated to different extents due to contact and other factors.
Understanding the degree to which this assumption is violated is crucial for
validating the accuracy of phylolinguistic inference. In this paper, we propose
a simple sanity check: projecting a reconstructed tree onto a space generated
by principal component analysis. By using both synthetic and real data, we
demonstrate that our method effectively visualizes anomalies, particularly in
the form of jogging.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18879" title="Abstract">arXiv:2402.18879</a> [<a href="/pdf/2402.18879" title="Download PDF">pdf</a>, <a href="/ps/2402.18879" title="Download PostScript">ps</a>, <a href="/format/2402.18879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dose Prediction Driven Radiotherapy Paramters Regression via Intra- and  Inter-Relation Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaqi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jianghong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Y">Yuchen Fei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiliu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xingcheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning has facilitated the automation of radiotherapy by predicting
accurate dose distribution maps. However, existing methods fail to derive the
desirable radiotherapy parameters that can be directly input into the treatment
planning system (TPS), impeding the full automation of radiotherapy. To enable
more thorough automatic radiotherapy, in this paper, we propose a novel
two-stage framework to directly regress the radiotherapy parameters, including
a dose map prediction stage and a radiotherapy parameters regression stage. In
stage one, we combine transformer and convolutional neural network (CNN) to
predict realistic dose maps with rich global and local information, providing
accurate dosimetric knowledge for the subsequent parameters regression. In
stage two, two elaborate modules, i.e., an intra-relation modeling (Intra-RM)
module and an inter-relation modeling (Inter-RM) module, are designed to
exploit the organ-specific and organ-shared features for precise parameters
regression. Experimental results on a rectal cancer dataset demonstrate the
effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18883" title="Abstract">arXiv:2402.18883</a> [<a href="/pdf/2402.18883" title="Download PDF">pdf</a>, <a href="/format/2402.18883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Processing of Subsequent Densest Subgraph Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hung%2C+C">Chia-Yang Hung</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chih-Ya Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Dense subgraph extraction is a fundamental problem in graph analysis and data
mining, aimed at identifying cohesive and densely connected substructures
within a given graph. It plays a crucial role in various domains, including
social network analysis, biological network analysis, recommendation systems,
and community detection. However, extracting a subgraph with the highest node
similarity is a lack of exploration. To address this problem, we studied the
Member Selection Problem and extended it with a dynamic constraint variant. By
incorporating dynamic constraints, our algorithm can adapt to changing
conditions or requirements, allowing for more flexible and personalized
subgraph extraction. This approach enables the algorithm to provide tailored
solutions that meet specific needs, even in scenarios where constraints may
vary over time. We also provide the theoretical analysis to show that our
algorithm is 1/3-approximation. Eventually, the experiments show that our
algorithm is effective and efficient in tackling the member selection problem
with dynamic constraints.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18884" title="Abstract">arXiv:2402.18884</a> [<a href="/pdf/2402.18884" title="Download PDF">pdf</a>, <a href="/ps/2402.18884" title="Download PostScript">ps</a>, <a href="/format/2402.18884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Contrastive Representation Learning: Landscape Analysis with  Unconstrained Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behnia%2C+T">Tina Behnia</a>, 
<a href="/search/cs?searchtype=author&query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent findings reveal that over-parameterized deep neural networks, trained
beyond zero training-error, exhibit a distinctive structural pattern at the
final layer, termed as Neural-collapse (NC). These results indicate that the
final hidden-layer outputs in such networks display minimal within-class
variations over the training set. While existing research extensively
investigates this phenomenon under cross-entropy loss, there are fewer studies
focusing on its contrastive counterpart, supervised contrastive (SC) loss.
Through the lens of NC, this paper employs an analytical approach to study the
solutions derived from optimizing the SC loss. We adopt the unconstrained
features model (UFM) as a representative proxy for unveiling NC-related
phenomena in sufficiently over-parameterized deep networks. We show that,
despite the non-convexity of SC loss minimization, all local minima are global
minima. Furthermore, the minimizer is unique (up to a rotation). We prove our
results by formalizing a tight convex relaxation of the UFM. Finally, through
this convex formulation, we delve deeper into characterizing the properties of
global solutions under label-imbalanced training data.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18886" title="Abstract">arXiv:2402.18886</a> [<a href="/pdf/2402.18886" title="Download PDF">pdf</a>, <a href="/format/2402.18886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BP-DeepONet: A new method for cuffless blood pressure estimation using  the physcis-informed DeepONet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+X">Xue-Cheng Tai</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R">Raymond Chan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Cardiovascular diseases (CVDs) are the leading cause of death worldwide, with
blood pressure serving as a crucial indicator. Arterial blood pressure (ABP)
waveforms provide continuous pressure measurements throughout the cardiac cycle
and offer valuable diagnostic insights. Consequently, there is a significant
demand for non-invasive and cuff-less methods to measure ABP waveforms
continuously. Accurate prediction of ABP waveforms can also improve the
estimation of mean blood pressure, an essential cardiovascular health
characteristic.
<br />This study proposes a novel framework based on the physics-informed DeepONet
approach to predict ABP waveforms. Unlike previous methods, our approach
requires the predicted ABP waveforms to satisfy the Navier-Stokes equation with
a time-periodic condition and a Windkessel boundary condition. Notably, our
framework is the first to predict ABP waveforms continuously, both with
location and time, within the part of the artery that is being simulated.
Furthermore, our method only requires ground truth data at the outlet boundary
and can handle periodic conditions with varying periods. Incorporating the
Windkessel boundary condition in our solution allows for generating natural
physical reflection waves, which closely resemble measurements observed in
real-world cases. Moreover, accurately estimating the hyper-parameters in the
Navier-Stokes equation for our simulations poses a significant challenge. To
overcome this obstacle, we introduce the concept of meta-learning, enabling the
neural networks to learn these parameters during the training process.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18888" title="Abstract">arXiv:2402.18888</a> [<a href="/pdf/2402.18888" title="Download PDF">pdf</a>, <a href="/format/2402.18888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Based Extensible Codebook for Discrete Federated Learning in  Heterogeneous Data Silos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dianbo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL), aimed at leveraging vast distributed datasets,
confronts a crucial challenge: the heterogeneity of data across different
silos. While previous studies have explored discrete representations to enhance
model generalization across minor distributional shifts, these approaches often
struggle to adapt to new data silos with significantly divergent distributions.
In response, we have identified that models derived from FL exhibit markedly
increased uncertainty when applied to data silos with unfamiliar distributions.
Consequently, we propose an innovative yet straightforward iterative framework,
termed Uncertainty-Based Extensible-Codebook Federated Learning (UEFL). This
framework dynamically maps latent features to trainable discrete vectors,
assesses the uncertainty, and specifically extends the discretization
dictionary or codebook for silos exhibiting high uncertainty. Our approach aims
to simultaneously enhance accuracy and reduce uncertainty by explicitly
addressing the diversity of data distributions, all while maintaining minimal
computational overhead in environments characterized by heterogeneous data
silos. Through experiments conducted on five datasets, our method has
demonstrated its superiority, achieving significant improvements in accuracy
(by 3%--22.1%) and uncertainty reduction (by 38.83%--96.24%), thereby
outperforming contemporary state-of-the-art methods. The source code is
available at https://github.com/destiny301/uefl.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18892" title="Abstract">arXiv:2402.18892</a> [<a href="/pdf/2402.18892" title="Download PDF">pdf</a>, <a href="/format/2402.18892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Knowledge Graph with Visual Perception for Object-goal  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Mengjie Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheyuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wei Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jason Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Object-goal navigation is a challenging task that requires guiding an agent
to specific objects based on first-person visual observations. The ability of
agent to comprehend its surroundings plays a crucial role in achieving
successful object finding. However, existing knowledge-graph-based navigators
often rely on discrete categorical one-hot vectors and vote counting strategy
to construct graph representation of the scenes, which results in misalignment
with visual images. To provide more accurate and coherent scene descriptions
and address this misalignment issue, we propose the Aligning Knowledge Graph
with Visual Perception (AKGVP) method for object-goal navigation. Technically,
our approach introduces continuous modeling of the hierarchical scene
architecture and leverages visual-language pre-training to align natural
language description with visual perception. The integration of a continuous
knowledge graph architecture and multimodal feature alignment empowers the
navigator with a remarkable zero-shot navigation capability. We extensively
evaluate our method using the AI2-THOR simulator and conduct a series of
experiments to demonstrate the effectiveness and efficiency of our navigator.
Code available: https://github.com/nuoxu/AKGVP.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18896" title="Abstract">arXiv:2402.18896</a> [<a href="/pdf/2402.18896" title="Download PDF">pdf</a>, <a href="/format/2402.18896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the maximum size of variable-length non-overlapping codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Geyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Non-overlapping codes are a set of codewords such that the prefix of each
codeword is not a suffix of any codeword in the set, including itself. If the
lengths of the codewords are variable, it is additionally required that every
codeword is not contained in any other codeword as a subword. Let $C(n,q)$ be
the maximum size of $q$-ary fixed-length non-overlapping codes of length $n$.
The upper bound on $C(n,q)$ has been well studied. However, the nontrivial
upper bound on the maximum size of variable-length non-overlapping codes of
length at most $n$ remains open. In this paper, by establishing a link between
variable-length non-overlapping codes and fixed-length ones, we are able to
show that the size of a $q$-ary variable-length non-overlapping code is upper
bounded by $C(n,q)$. Furthermore, we prove that the average length of the
codewords in a $q$-ary variable-length non-overlapping codes is lower bounded
by $\lceil \log_q \tilde{C} \rceil$, and is asymptotically no shorter than
$n-2$ as $q$ approaches $\infty$, where $\tilde{C}$ denotes the cardinality of
$q$-ary variable-length non-overlapping codes of length up to $n$.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18897" title="Abstract">arXiv:2402.18897</a> [<a href="/pdf/2402.18897" title="Download PDF">pdf</a>, <a href="/format/2402.18897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contact-Implicit Model Predictive Control for Dexterous In-hand  Manipulation: A Long-Horizon and Robust Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yongpeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mingrui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, submitted to IROS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Dexterous in-hand manipulation is an essential skill of production and life.
Nevertheless, the highly stiff and mutable features of contacts cause
limitations to real-time contact discovery and inference, which degrades the
performance of model-based methods. Inspired by recent advancements in
contact-rich locomotion and manipulation, this paper proposes a novel
model-based approach to control dexterous in-hand manipulation and overcome the
current limitations. The proposed approach has the attractive feature, which
allows the robot to robustly execute long-horizon in-hand manipulation without
pre-defined contact sequences or separated planning procedures. Specifically,
we design a contact-implicit model predictive controller at high-level to
generate real-time contact plans, which are executed by the low-level tracking
controller. Compared with other model-based methods, such a long-horizon
feature enables replanning and robust execution of contact-rich motions to
achieve large-displacement in-hand tasks more efficiently; Compared with
existing learning-based methods, the proposed approach achieves the dexterity
and also generalizes to different objects without any pre-training. Detailed
simulations and ablation studies demonstrate the efficiency and effectiveness
of our method. It runs at 20Hz on the 23-degree-of-freedom long-horizon in-hand
object rotation task.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18899" title="Abstract">arXiv:2402.18899</a> [<a href="/pdf/2402.18899" title="Download PDF">pdf</a>, <a href="/format/2402.18899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Language Models for Versatile Text-based Item Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yuxuan Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jianxun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages,1 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper addresses the gap between general-purpose text embeddings and the
specific demands of item retrieval tasks. We demonstrate the shortcomings of
existing models in capturing the nuances necessary for zero-shot performance on
item retrieval tasks. To overcome these limitations, we propose generate
in-domain dataset from ten tasks tailored to unlocking models' representation
ability for item retrieval. Our empirical studies demonstrate that fine-tuning
embedding models on the dataset leads to remarkable improvements in a variety
of retrieval tasks. We also illustrate the practical application of our refined
model in a conversational setting, where it enhances the capabilities of
LLM-based Recommender Agents like Chat-Rec. Our code is available at
https://github.com/microsoft/RecAI.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18905" title="Abstract">arXiv:2402.18905</a> [<a href="/pdf/2402.18905" title="Download PDF">pdf</a>, <a href="/format/2402.18905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of Differentially-Private Fine-tuning: To Linearly  Probe or to Fully Fine-tune?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ke%2C+S">Shuqi Ke</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Charlie Hou</a>, 
<a href="/search/cs?searchtype=author&query=Fanti%2C+G">Giulia Fanti</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sewoong Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Optimization and Control (math.OC)

</div>
<p class="mathjax">Differentially private (DP) machine learning pipelines typically involve a
two-phase process: non-private pre-training on a public dataset, followed by
fine-tuning on private data using DP optimization techniques. In the DP
setting, it has been observed that full fine-tuning may not always yield the
best test accuracy, even for in-distribution data. This paper (1) analyzes the
training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2)
explores the phenomenon of sequential fine-tuning, starting with linear probing
and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We
provide theoretical insights into the convergence of DP fine-tuning within an
overparameterized neural network and establish a utility curve that determines
the allocation of privacy budget between linear probing and full fine-tuning.
The theoretical results are supported by empirical evaluations on various
benchmarks and models. The findings reveal the complex nature of DP fine-tuning
methods. These results contribute to a deeper understanding of DP machine
learning and highlight the importance of considering the allocation of privacy
budget in the fine-tuning process.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18908" title="Abstract">arXiv:2402.18908</a> [<a href="/pdf/2402.18908" title="Download PDF">pdf</a>, <a href="/ps/2402.18908" title="Download PostScript">ps</a>, <a href="/format/2402.18908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facility Location Games with Scaling Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yu He</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+A">Alexander Lam</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minming Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We take the classic facility location problem and consider a variation, in
which each agent's individual cost function is equal to their distance from the
facility multiplied by a scaling factor which is determined by the facility
placement. In addition to the general class of continuous scaling functions, we
also provide results for piecewise linear scaling functions which can
effectively approximate or model the scaling of many real world scenarios. We
focus on the objectives of total and maximum cost, describing the computation
of the optimal solution. We then move to the approximate mechanism design
setting, observing that the agents' preferences may no longer be single-peaked.
Consequently, we characterize the conditions on scaling functions which ensure
that agents have single-peaked preferences. Under these conditions, we find
results on the total and maximum cost approximation ratios achievable by
strategyproof and anonymous mechanisms.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18909" title="Abstract">arXiv:2402.18909</a> [<a href="/pdf/2402.18909" title="Download PDF">pdf</a>, <a href="/format/2402.18909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Updating Language Models with Unstructured Facts: Towards Practical  Knowledge Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge editing aims to inject knowledge updates into language models to
keep them correct and up-to-date. However, its current evaluation strategies
are notably impractical: they solely update with well-curated structured facts
(triplets with subjects, relations, and objects), whereas real-world knowledge
updates commonly emerge in unstructured texts like news articles. In this
paper, we propose a new benchmark, Unstructured Knowledge Editing (UKE). It
evaluates editing performance directly using unstructured texts as knowledge
updates, termed unstructured facts. Hence UKE avoids the laborious construction
of structured facts and enables efficient and responsive knowledge editing,
becoming a more practical benchmark. We conduct extensive experiments on newly
built datasets and demonstrate that UKE poses a significant challenge to
state-of-the-art knowledge editing methods, resulting in their critical
performance declines. We further show that this challenge persists even if we
extract triplets as structured facts. Our analysis discloses key insights to
motivate future research in UKE for more practical knowledge editing.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18910" title="Abstract">arXiv:2402.18910</a> [<a href="/pdf/2402.18910" title="Download PDF">pdf</a>, <a href="/format/2402.18910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIGIC: Domain Generalizable Imitation Learning by Causal Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Causality has been combined with machine learning to produce robust
representations for domain generalization. Most existing methods of this type
require massive data from multiple domains to identify causal features by
cross-domain variations, which can be expensive or even infeasible and may lead
to misidentification in some cases. In this work, we make a different attempt
by leveraging the demonstration data distribution to discover the causal
features for a domain generalizable policy. We design a novel framework, called
DIGIC, to identify the causal features by finding the direct cause of the
expert action from the demonstration data distribution via causal discovery.
Our framework can achieve domain generalizable imitation learning with only
single-domain data and serve as a complement for cross-domain variation-based
methods under non-structural assumptions on the underlying causal models. Our
empirical study in various control tasks shows that the proposed framework
evidently improves the domain generalization performance and has comparable
performance to the expert in the original domain simultaneously.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18913" title="Abstract">arXiv:2402.18913</a> [<a href="/pdf/2402.18913" title="Download PDF">pdf</a>, <a href="/format/2402.18913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaMergeX: Cross-Lingual Transfer with Large Language Models via  Adaptive Adapter Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As an effective alternative to the direct fine-tuning on target tasks in
specific languages, cross-lingual transfer addresses the challenges of limited
training data by decoupling ''task ability'' and ''language ability'' by
fine-tuning on the target task in the source language and another selected task
in the target language, respectively. However, they fail to fully separate the
task ability from the source language or the language ability from the chosen
task. In this paper, we acknowledge the mutual reliance between task ability
and language ability and direct our attention toward the gap between the target
language and the source language on tasks. As the gap removes the impact of
tasks, we assume that it remains consistent across tasks. Based on this
assumption, we propose a new cross-lingual transfer method called
$\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a
reference task, we can determine that the divergence of adapters fine-tuned on
the reference task in both languages follows the same distribution as the
divergence of adapters fine-tuned on the target task in both languages. Hence,
we can obtain target adapters by combining the other three adapters.
Furthermore, we propose a structure-adaptive adapter merging method. Our
empirical results demonstrate that our approach yields new and effective
cross-lingual transfer, outperforming existing methods across all settings.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18917" title="Abstract">arXiv:2402.18917</a> [<a href="/pdf/2402.18917" title="Download PDF">pdf</a>, <a href="/format/2402.18917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stop Relying on No-Choice and Do not Repeat the Moves: Optimal,  Efficient and Practical Algorithms for Assortment Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aadirupa Saha</a>, 
<a href="/search/cs?searchtype=author&query=Gaillard%2C+P">Pierre Gaillard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">We address the problem of active online assortment optimization problem with
preference feedback, which is a framework for modeling user choices and
subsetwise utility maximization. The framework is useful in various real-world
applications including ad placement, online retail, recommender systems,
fine-tuning language models, amongst many. The problem, although has been
studied in the past, lacks an intuitive and practical solution approach with
simultaneously efficient algorithm and optimal regret guarantee. E.g.,
popularly used assortment selection algorithms often require the presence of a
`strong reference' which is always included in the choice sets, further they
are also designed to offer the same assortments repeatedly until the reference
item gets selected -- all such requirements are quite unrealistic for practical
applications. In this paper, we designed efficient algorithms for the problem
of regret minimization in assortment selection with \emph{Plackett Luce} (PL)
based user choices. We designed a novel concentration guarantee for estimating
the score parameters of the PL model using `\emph{Pairwise Rank-Breaking}',
which builds the foundation of our proposed algorithms. Moreover, our methods
are practical, provably optimal, and devoid of the aforementioned limitations
of the existing methods. Empirical evaluations corroborate our findings and
outperform the existing baselines.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18918" title="Abstract">arXiv:2402.18918</a> [<a href="/pdf/2402.18918" title="Download PDF">pdf</a>, <a href="/format/2402.18918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SNE-RoadSegV2: Advancing Heterogeneous Feature Fusion and Fallibility  Awareness for Freespace Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pitas%2C+I">Ioannis Pitas</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Feature-fusion networks with duplex encoders have proven to be an effective
technique to solve the freespace detection problem. However, despite the
compelling results achieved by previous research efforts, the exploration of
adequate and discriminative heterogeneous feature fusion, as well as the
development of fallibility-aware loss functions remains relatively scarce. This
paper makes several significant contributions to address these limitations: (1)
It presents a novel heterogeneous feature fusion block, comprising a holistic
attention module, a heterogeneous feature contrast descriptor, and an
affinity-weighted feature recalibrator, enabling a more in-depth exploitation
of the inherent characteristics of the extracted features, (2) it incorporates
both inter-scale and intra-scale skip connections into the decoder architecture
while eliminating redundant ones, leading to both improved accuracy and
computational efficiency, and (3) it introduces two fallibility-aware loss
functions that separately focus on semantic-transition and depth-inconsistent
regions, collectively contributing to greater supervision during model
training. Our proposed heterogeneous feature fusion network (SNE-RoadSegV2),
which incorporates all these innovative components, demonstrates superior
performance in comparison to all other freespace detection algorithms across
multiple public datasets. Notably, it ranks the 1st on the official KITTI Road
benchmark.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18919" title="Abstract">arXiv:2402.18919</a> [<a href="/pdf/2402.18919" title="Download PDF">pdf</a>, <a href="/format/2402.18919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decompose-and-Compose: A Compositional Approach to Mitigating Spurious  Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noohdani%2C+F+H">Fahimeh Hosseini Noohdani</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+P">Parsa Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Parast%2C+A+Y">Arian Yazdan Parast</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+H+Y">Hamidreza Yaghoubi Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Baghshah%2C+M+S">Mahdieh Soleymani Baghshah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While standard Empirical Risk Minimization (ERM) training is proven effective
for image classification on in-distribution data, it fails to perform well on
out-of-distribution samples. One of the main sources of distribution shift for
image classification is the compositional nature of images. Specifically, in
addition to the main object or component(s) determining the label, some other
image components usually exist, which may lead to the shift of input
distribution between train and test environments. More importantly, these
components may have spurious correlations with the label. To address this
issue, we propose Decompose-and-Compose (DaC), which improves robustness to
correlation shift by a compositional approach based on combining elements of
images. Based on our observations, models trained with ERM usually highly
attend to either the causal components or the components having a high spurious
correlation with the label (especially in datapoints on which models have a
high confidence). In fact, according to the amount of spurious correlation and
the easiness of classification based on the causal or non-causal components,
the model usually attends to one of these more (on samples with high
confidence). Following this, we first try to identify the causal components of
images using class activation maps of models trained with ERM. Afterward, we
intervene on images by combining them and retraining the model on the augmented
data, including the counterfactual ones. Along with its high interpretability,
this work proposes a group-balancing method by intervening on images without
requiring group labels or information regarding the spurious features during
training. The method has an overall better worst group accuracy compared to
previous methods with the same amount of supervision on the group labels in
correlation shift.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18920" title="Abstract">arXiv:2402.18920</a> [<a href="/pdf/2402.18920" title="Download PDF">pdf</a>, <a href="/format/2402.18920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Dongliang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Eisenberger%2C+M">Marvin Eisenberger</a>, 
<a href="/search/cs?searchtype=author&query=Amrani%2C+N+E">Nafie El Amrani</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">Although 3D shape matching and interpolation are highly interrelated, they
are often studied separately and applied sequentially to relate different 3D
shapes, thus resulting in sub-optimal performance. In this work we present a
unified framework to predict both point-wise correspondences and shape
interpolation between 3D shapes. To this end, we combine the deep functional
map framework with classical surface deformation models to map shapes in both
spectral and spatial domains. On the one hand, by incorporating spatial maps,
our method obtains more accurate and smooth point-wise correspondences compared
to previous functional map methods for shape matching. On the other hand, by
introducing spectral maps, our method gets rid of commonly used but
computationally expensive geodesic distance constraints that are only valid for
near-isometric shape deformations. Furthermore, we propose a novel test-time
adaptation scheme to capture both pose-dominant and shape-dominant
deformations. Using different challenging datasets, we demonstrate that our
method outperforms previous state-of-the-art methods for both shape matching
and interpolation, even compared to supervised approaches.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18922" title="Abstract">arXiv:2402.18922</a> [<a href="/pdf/2402.18922" title="Download PDF">pdf</a>, <a href="/format/2402.18922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple yet Effective Network based on Vision Transformer for  Camouflaged Object and Salient Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Chao Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zitong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE TIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camouflaged object detection (COD) and salient object detection (SOD) are two
distinct yet closely-related computer vision tasks widely studied during the
past decades. Though sharing the same purpose of segmenting an image into
binary foreground and background regions, their distinction lies in the fact
that COD focuses on concealed objects hidden in the image, while SOD
concentrates on the most prominent objects in the image. Previous works
achieved good performance by stacking various hand-designed modules and
multi-scale features. However, these carefully-designed complex networks often
performed well on one task but not on another. In this work, we propose a
simple yet effective network (SENet) based on vision Transformer (ViT), by
employing a simple design of an asymmetric ViT-based encoder-decoder structure,
we yield competitive results on both tasks, exhibiting greater versatility than
meticulously crafted ones. Furthermore, to enhance the Transformer's ability to
model local information, which is important for pixel-level binary segmentation
tasks, we propose a local information capture module (LICM). We also propose a
dynamic weighted loss (DW loss) based on Binary Cross-Entropy (BCE) and
Intersection over Union (IoU) loss, which guides the network to pay more
attention to those smaller and more difficult-to-find target objects according
to their size. Moreover, we explore the issue of joint training of SOD and COD,
and propose a preliminary solution to the conflict in joint training, further
improving the performance of SOD. Extensive experiments on multiple benchmark
datasets demonstrate the effectiveness of our method. The code is available at
https://github.com/linuxsino/SENet.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18923" title="Abstract">arXiv:2402.18923</a> [<a href="/pdf/2402.18923" title="Download PDF">pdf</a>, <a href="/format/2402.18923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jeehyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yerin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tae-Jin Song</a>, 
<a href="/search/cs?searchtype=author&query=Koo%2C+M">Myoung-Wan Koo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Dysarthria, a common issue among stroke patients, severely impacts speech
intelligibility. Inappropriate pauses are crucial indicators in severity
assessment and speech-language therapy. We propose to extend a large-scale
speech recognition model for inappropriate pause detection in dysarthric
speech. To this end, we propose task design, labeling strategy, and a speech
recognition model with an inappropriate pause prediction layer. First, we treat
pause detection as speech recognition, using an automatic speech recognition
(ASR) model to convert speech into text with pause tags. According to the newly
designed task, we label pause locations at the text level and their
appropriateness. We collaborate with speech-language pathologists to establish
labeling criteria, ensuring high-quality annotated data. Finally, we extend the
ASR model with an inappropriate pause prediction layer for end-to-end
inappropriate pause detection. Moreover, we propose a task-tailored metric for
evaluating inappropriate pause detection independent of ASR performance. Our
experiments show that the proposed method better detects inappropriate pauses
in dysarthric speech than baselines. (Inappropriate Pause Error Rate: 14.47%)
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18925" title="Abstract">arXiv:2402.18925</a> [<a href="/pdf/2402.18925" title="Download PDF">pdf</a>, <a href="/format/2402.18925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCDepth: Pattern-based Complementary Learning for Monocular Depth  Estimation by Best of Both Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Sanqing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Z">Zongtao Bu</a>, 
<a href="/search/cs?searchtype=author&query=Roehrbein%2C+F">Florian Roehrbein</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras can record scene dynamics with high temporal resolution,
providing rich scene details for monocular depth estimation (MDE) even at
low-level illumination. Therefore, existing complementary learning approaches
for MDE fuse intensity information from images and scene details from event
data for better scene understanding. However, most methods directly fuse two
modalities at pixel level, ignoring that the attractive complementarity mainly
impacts high-level patterns that only occupy a few pixels. For example, event
data is likely to complement contours of scene objects. In this paper, we
discretize the scene into a set of high-level patterns to explore the
complementarity and propose a Pattern-based Complementary learning architecture
for monocular Depth estimation (PCDepth). Concretely, PCDepth comprises two
primary components: a complementary visual representation learning module for
discretizing the scene into high-level patterns and integrating complementary
patterns across modalities and a refined depth estimator aimed at scene
reconstruction and depth prediction while maintaining an efficiency-accuracy
balance. Through pattern-based complementary learning, PCDepth fully exploits
two modalities and achieves more accurate predictions than existing methods,
especially in challenging nighttime scenarios. Extensive experiments on MVSEC
and DSEC datasets verify the effectiveness and superiority of our PCDepth.
Remarkably, compared with state-of-the-art, PCDepth achieves a 37.9%
improvement in accuracy in MVSEC nighttime scenarios.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18927" title="Abstract">arXiv:2402.18927</a> [<a href="/pdf/2402.18927" title="Download PDF">pdf</a>, <a href="/format/2402.18927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Computing Enabled Real-Time Video Analysis via Adaptive  Spatial-Temporal Semantic Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+C">Changyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jun Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper proposes a novel edge computing enabled real-time video analysis
system for intelligent visual devices. The proposed system consists of a
tracking-assisted object detection module (TAODM) and a region of interesting
module (ROIM). TAODM adaptively determines the offloading decision to process
each video frame locally with a tracking algorithm or to offload it to the edge
server inferred by an object detection model. ROIM determines each offloading
frame's resolution and detection model configuration to ensure that the
analysis results can return in time. TAODM and ROIM interact jointly to filter
the repetitive spatial-temporal semantic information to maximize the processing
rate while ensuring high video analysis accuracy. Unlike most existing works,
this paper investigates the real-time video analysis systems where the
intelligent visual device connects to the edge server through a wireless
network with fluctuating network conditions. We decompose the real-time video
analysis problem into the offloading decision and configurations selection
sub-problems. To solve these two sub-problems, we introduce a double deep Q
network (DDQN) based offloading approach and a contextual multi-armed bandit
(CMAB) based adaptive configurations selection approach, respectively. A
DDQN-CMAB reinforcement learning (DCRL) training framework is further developed
to integrate these two approaches to improve the overall video analyzing
performance. Extensive simulations are conducted to evaluate the performance of
the proposed solution, and demonstrate its superiority over counterparts.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18929" title="Abstract">arXiv:2402.18929</a> [<a href="/pdf/2402.18929" title="Download PDF">pdf</a>, <a href="/format/2402.18929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable  Image Super Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinqiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning has led to a dramatic leap on Single Image Super-Resolution
(SISR) performances in recent years. %Despite the substantial advancement%
While most existing work assumes a simple and fixed degradation model (e.g.,
bicubic downsampling), the research of Blind SR seeks to improve model
generalization ability with unknown degradation. Recently, Kong et al pioneer
the investigation of a more suitable training strategy for Blind SR using
Dropout. Although such method indeed brings substantial generalization
improvements via mitigating overfitting, we argue that Dropout simultaneously
introduces undesirable side-effect that compromises model's capacity to
faithfully reconstruct fine details. We show both the theoretical and
experimental analyses in our paper, and furthermore, we present another easy
yet effective training strategy that enhances the generalization ability of the
model by simply modulating its first and second-order features statistics.
Experimental results have shown that our method could serve as a model-agnostic
regularization and outperforms Dropout on seven benchmark datasets including
both synthetic and real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18933" title="Abstract">arXiv:2402.18933</a> [<a href="/pdf/2402.18933" title="Download PDF">pdf</a>, <a href="/format/2402.18933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality-Agnostic Structural Image Representation Learning for  Deformable Multi-Modality Medical Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mok%2C+T+C+W">Tony C. W. Mok</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yunhao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yan-Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Dakai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiaoli Yin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Le Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Establishing dense anatomical correspondence across distinct imaging
modalities is a foundational yet challenging procedure for numerous medical
image analysis studies and image-guided radiotherapy. Existing multi-modality
image registration algorithms rely on statistical-based similarity measures or
local structural image representations. However, the former is sensitive to
locally varying noise, while the latter is not discriminative enough to cope
with complex anatomical structures in multimodal scans, causing ambiguity in
determining the anatomical correspondence across scans with different
modalities. In this paper, we propose a modality-agnostic structural
representation learning method, which leverages Deep Neighbourhood
Self-similarity (DNS) and anatomy-aware contrastive learning to learn
discriminative and contrast-invariance deep structural image representations
(DSIR) without the need for anatomical delineations or pre-aligned training
images. We evaluate our method on multiphase CT, abdomen MR-CT, and brain MR
T1w-T2w registration. Comprehensive results demonstrate that our method is
superior to the conventional local structural representation and
statistical-based similarity measures in terms of discriminability and
accuracy.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18934" title="Abstract">arXiv:2402.18934</a> [<a href="/pdf/2402.18934" title="Download PDF">pdf</a>, <a href="/format/2402.18934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RELEAD: Resilient Localization with Enhanced LiDAR Odometry in Adverse  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongbo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuhua Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shipeng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dapeng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Weisong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> published in ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">LiDAR-based localization is valuable for applications like mining surveys and
underground facility maintenance. However, existing methods can struggle when
dealing with uninformative geometric structures in challenging scenarios. This
paper presents RELEAD, a LiDAR-centric solution designed to address
scan-matching degradation. Our method enables degeneracy-free point cloud
registration by solving constrained ESIKF updates in the front end and
incorporates multisensor constraints, even when dealing with outlier
measurements, through graph optimization based on Graduated Non-Convexity
(GNC). Additionally, we propose a robust Incremental Fixed Lag Smoother (rIFL)
for efficient GNC-based optimization. RELEAD has undergone extensive evaluation
in degenerate scenarios and has outperformed existing state-of-the-art
LiDAR-Inertial odometry and LiDAR-Visual-Inertial odometry methods.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18936" title="Abstract">arXiv:2402.18936</a> [<a href="/pdf/2402.18936" title="Download PDF">pdf</a>, <a href="/ps/2402.18936" title="Download PostScript">ps</a>, <a href="/format/2402.18936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient UAV Swarm Assisted MEC with Dynamic Clustering and  Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialiuyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+C">Changyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jun Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, the energy-efficient unmanned aerial vehicle (UAV) swarm
assisted mobile edge computing (MEC) with dynamic clustering and scheduling is
studied. In the considered system model, UAVs are divided into multiple swarms,
with each swarm consisting of a leader UAV and several follower UAVs to provide
computing services to end-users. Unlike existing work, we allow UAVs to
dynamically cluster into different swarms, i.e., each follower UAV can change
its leader based on the time-varying spatial positions, updated application
placement, etc. in a dynamic manner. Meanwhile, UAVs are required to
dynamically schedule their energy replenishment, application placement,
trajectory planning and task delegation. With the aim of maximizing the
long-term energy efficiency of the UAV swarm assisted MEC system, a joint
optimization problem of dynamic clustering and scheduling is formulated. Taking
into account the underlying cooperation and competition among intelligent UAVs,
we further reformulate this optimization problem as a combination of a series
of strongly coupled multi-agent stochastic games, and then propose a novel
reinforcement learning-based UAV swarm dynamic coordination (RLDC) algorithm
for obtaining the equilibrium. Simulations are conducted to evaluate the
performance of the RLDC algorithm and demonstrate its superiority over
counterparts.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18937" title="Abstract">arXiv:2402.18937</a> [<a href="/pdf/2402.18937" title="Download PDF">pdf</a>, <a href="/format/2402.18937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalence of ADER and Lax-Wendroff in DG / FR framework for linear  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Babbar%2C+A">Arpit Babbar</a>, 
<a href="/search/math?searchtype=author&query=Chandrashekar%2C+P">Praveen Chandrashekar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">ADER (Arbitrary high order by DERivatives) and Lax-Wendroff (LW) schemes are
two high order single stage methods for solving time dependent partial
differential equations. ADER is based on solving a locally implicit equation to
obtain a space-time predictor solution while LW is based on an explicit
Taylor's expansion in time. We cast the corrector step of ADER Discontinuous
Galerkin (DG) scheme into an equivalent quadrature free Flux Reconstruction
(FR) framework and then show that the obtained ADER-FR scheme is equivalent to
the LWFR scheme with D2 dissipation numerical flux for linear problems. This
also implies that the two schemes have the same Fourier stability limit for
time step size. The equivalence is verified by numerical experiments.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18944" title="Abstract">arXiv:2402.18944</a> [<a href="/pdf/2402.18944" title="Download PDF">pdf</a>, <a href="/format/2402.18944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in  Conversation (EDiReF)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shivani Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+M+S">Md Shad Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Cambria%2C+E">Erik Cambria</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present SemEval-2024 Task 10, a shared task centred on identifying
emotions and finding the rationale behind their flips within monolingual
English and Hindi-English code-mixed dialogues. This task comprises three
distinct subtasks - emotion recognition in conversation for code-mixed
dialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip
reasoning for English dialogues. Participating systems were tasked to
automatically execute one or more of these subtasks. The datasets for these
tasks comprise manually annotated conversations focusing on emotions and
triggers for emotion shifts (The task data is available at
https://github.com/LCS2-IIITD/EDiReF-SemEval2024.git). A total of 84
participants engaged in this task, with the most adept systems attaining
F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper
summarises the results and findings from 24 teams alongside their system
descriptions.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18945" title="Abstract">arXiv:2402.18945</a> [<a href="/pdf/2402.18945" title="Download PDF">pdf</a>, <a href="/format/2402.18945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on  Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengzhou Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fengwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Libo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Pre-trained language models (PLMs) have been found susceptible to backdoor
attacks, which can transfer vulnerabilities to various downstream tasks.
However, existing PLM backdoors are conducted with explicit triggers under the
manually aligned, thus failing to satisfy expectation goals simultaneously in
terms of effectiveness, stealthiness, and universality. In this paper, we
propose a novel approach to achieve invisible and general backdoor
implantation, called \textbf{Syntactic Ghost} (synGhost for short).
Specifically, the method hostilely manipulates poisoned samples with different
predefined syntactic structures as stealth triggers and then implants the
backdoor to pre-trained representation space without disturbing the primitive
knowledge. The output representations of poisoned samples are distributed as
uniformly as possible in the feature space via contrastive learning, forming a
wide range of backdoors. Additionally, in light of the unique properties of
syntactic triggers, we introduce an auxiliary module to drive the PLMs to learn
this knowledge in priority, which can alleviate the interference between
different syntactic structures. Experiments show that our method outperforms
the previous methods and achieves the predefined objectives. Not only do severe
threats to various natural language understanding (NLU) tasks on two tuning
paradigms but also to multiple PLMs. Meanwhile, the synGhost is imperceptible
against three countermeasures based on perplexity, fine-pruning, and the
proposed maxEntropy.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18946" title="Abstract">arXiv:2402.18946</a> [<a href="/pdf/2402.18946" title="Download PDF">pdf</a>, <a href="/format/2402.18946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Adaptive Safety-Critical Control with Gaussian Processes in  High-Order Uncertain Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Long Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiangtong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghuan Kong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents an adaptive online learning framework for systems with
uncertain parameters to ensure safety-critical control in non-stationary
environments. Our approach consists of two phases. The initial phase is
centered on a novel sparse Gaussian process (GP) framework. We first integrate
a forgetting factor to refine a variational sparse GP algorithm, thus enhancing
its adaptability. Subsequently, the hyperparameters of the Gaussian model are
trained with a specially compound kernel, and the Gaussian model's online
inferential capability and computational efficiency are strengthened by
updating a solitary inducing point derived from new samples, in conjunction
with the learned hyperparameters. In the second phase, we propose a safety
filter based on high-order control barrier functions (HOCBFs), synergized with
the previously trained learning model. By leveraging the compound kernel from
the first phase, we effectively address the inherent limitations of GPs in
handling high-dimensional problems for real-time applications. The derived
controller ensures a rigorous lower bound on the probability of satisfying the
safety specification. Finally, the efficacy of our proposed algorithm is
demonstrated through real-time obstacle avoidance experiments executed using
both a simulation platform and a real-world 7-DOF robot.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18949" title="Abstract">arXiv:2402.18949</a> [<a href="/pdf/2402.18949" title="Download PDF">pdf</a>, <a href="/format/2402.18949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Group Connectivity for Generalization of Federated Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Didi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) involves multiple heterogeneous clients
collaboratively training a global model via iterative local updates and model
fusion. The generalization of FL's global model has a large gap compared with
centralized training, which is its bottleneck for broader applications. In this
paper, we study and improve FL's generalization through a fundamental
``connectivity'' perspective, which means how the local models are connected in
the parameter region and fused into a generalized global model. The term
``connectivity'' is derived from linear mode connectivity (LMC), studying the
interpolated loss landscape of two different solutions (e.g., modes) of neural
networks. Bridging the gap between LMC and FL, in this paper, we leverage fixed
anchor models to empirically and theoretically study the transitivity property
of connectivity from two models (LMC) to a group of models (model fusion in
FL). Based on the findings, we propose FedGuCci and FedGuCci+, improving group
connectivity for better generalization. It is shown that our methods can boost
the generalization of FL under client heterogeneity across various tasks (4 CV
datasets and 6 NLP datasets), models (both convolutional and
transformer-based), and training paradigms (both from-scratch and
pretrain-finetune).
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18950" title="Abstract">arXiv:2402.18950</a> [<a href="/pdf/2402.18950" title="Download PDF">pdf</a>, <a href="/format/2402.18950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PopALM: Popularity-Aligned Language Models for Social Media Trendy  Response Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">Erxin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunpu Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media platforms are daily exhibiting millions of events. To
preliminarily predict the mainstream public reaction to these events, we study
trendy response prediction to automatically generate top-liked user replies to
social media events. While previous works focus on generating responses without
factoring in popularity, we propose Popularity-Aligned Language Models (PopALM)
to distinguish responses liked by a larger audience through reinforcement
learning. Recognizing the noisy labels from user "likes", we tailor-make
curriculum learning in proximal policy optimization (PPO) to help models
capture the essential samples for easy-to-hard training. In experiments, we
build a large-scale Weibo dataset for trendy response prediction, and its
results show that PopALM can help boost the performance of advanced language
models.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18951" title="Abstract">arXiv:2402.18951</a> [<a href="/pdf/2402.18951" title="Download PDF">pdf</a>, <a href="/format/2402.18951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Percept, Chat, and then Adapt: Multimodal Knowledge Transfer of  Foundation Models for Open-World Video Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kunchang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qinglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-world video recognition is challenging since traditional networks are
not generalized well on complex environment variations. Alternatively,
foundation models with rich knowledge have recently shown their generalization
power. However, how to apply such knowledge has not been fully explored for
open-world video recognition. To this end, we propose a generic knowledge
transfer pipeline, which progressively exploits and integrates external
multimodal knowledge from foundation models to boost open-world video
recognition. We name it PCA, based on three stages of Percept, Chat, and Adapt.
First, we perform Percept process to reduce the video domain gap and obtain
external visual knowledge. Second, we generate rich linguistic semantics as
external textual knowledge in Chat stage. Finally, we blend external multimodal
knowledge in Adapt stage, by inserting multimodal knowledge adaptation modules
into networks. We conduct extensive experiments on three challenging open-world
video benchmarks, i.e., TinyVIRAT, ARID, and QV-Pipe. Our approach achieves
state-of-the-art performance on all three datasets.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18954" title="Abstract">arXiv:2402.18954</a> [<a href="/pdf/2402.18954" title="Download PDF">pdf</a>, <a href="/ps/2402.18954" title="Download PostScript">ps</a>, <a href="/format/2402.18954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Getting Saturated with Induction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajdu%2C+M">M&#xe1;rton Hajdu</a>, 
<a href="/search/cs?searchtype=author&query=Hozzov%C3%A1%2C+P">Petra Hozzov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Reger%2C+G">Giles Reger</a>, 
<a href="/search/cs?searchtype=author&query=Voronkov%2C+A">Andrei Voronkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages; this is an extended version of the published paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Principles of Systems Design 2022, Lecture Notes in Computer
  Science, vol 13660. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Induction in saturation-based first-order theorem proving is a new exciting
direction in the automation of inductive reasoning. In this paper we survey our
work on integrating induction directly into the saturation-based proof search
framework of first-order theorem proving. We describe our induction inference
rules proving properties with inductively defined datatypes and integers. We
also present additional reasoning heuristics for strengthening inductive
reasoning, as well as for using induction hypotheses and recursive function
definitions for guiding induction. We present exhaustive experimental results
demonstrating the practical impact of our approach as implemented within
Vampire.
<br />This is an extended version of a Principles of Systems Design 2022 paper with
the same title and the same authors.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18956" title="Abstract">arXiv:2402.18956</a> [<a href="/pdf/2402.18956" title="Download PDF">pdf</a>, <a href="/format/2402.18956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WWW: A Unified Framework for Explaining What, Where and Why of Neural  Networks by Interpretation of Neuron Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+Y+H">Yong Hyun Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+B">Hyeon Bae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+T">Seong Tae Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in neural networks have showcased their remarkable
capabilities across various domains. Despite these successes, the "black box"
problem still remains. Addressing this, we propose a novel framework, WWW, that
offers the 'what', 'where', and 'why' of the neural network decisions in
human-understandable terms. Specifically, WWW utilizes adaptive selection for
concept discovery, employing adaptive cosine similarity and thresholding
techniques to effectively explain 'what'. To address the 'where' and 'why', we
proposed a novel combination of neuron activation maps (NAMs) with Shapley
values, generating localized concept maps and heatmaps for individual inputs.
Furthermore, WWW introduces a method for predicting uncertainty, leveraging
heatmap similarities to estimate 'how' reliable the prediction is. Experimental
evaluations of WWW demonstrate superior performance in both quantitative and
qualitative metrics, outperforming existing methods in interpretability. WWW
provides a unified solution for explaining 'what', 'where', and 'why',
introducing a method for localized explanations from global interpretations and
offering a plug-and-play solution adaptable to various architectures.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18958" title="Abstract">arXiv:2402.18958</a> [<a href="/pdf/2402.18958" title="Download PDF">pdf</a>, <a href="/format/2402.18958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Semi-Supervised Object Detection in Remote Sensing Images With  Active Teaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Boxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zengmao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Geoscience and Remote Sensing Letters, vol. 21, pp. 1-5,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The lack of object-level annotations poses a significant challenge for object
detection in remote sensing images (RSIs). To address this issue, active
learning (AL) and semi-supervised learning (SSL) techniques have been proposed
to enhance the quality and quantity of annotations. AL focuses on selecting the
most informative samples for annotation, while SSL leverages the knowledge from
unlabeled samples. In this letter, we propose a novel AL method to boost
semi-supervised object detection (SSOD) for remote sensing images with a
teacher student network, called SSOD-AT. The proposed method incorporates an
RoI comparison module (RoICM) to generate high-confidence pseudo-labels for
regions of interest (RoIs). Meanwhile, the RoICM is utilized to identify the
top-K uncertain images. To reduce redundancy in the top-K uncertain images for
human labeling, a diversity criterion is introduced based on object-level
prototypes of different categories using both labeled and pseudo-labeled
images. Extensive experiments on DOTA and DIOR, two popular datasets,
demonstrate that our proposed method outperforms state-of-the-art methods for
object detection in RSIs. Compared with the best performance in the SOTA
methods, the proposed method achieves 1 percent improvement in most cases in
the whole AL.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18959" title="Abstract">arXiv:2402.18959</a> [<a href="/pdf/2402.18959" title="Download PDF">pdf</a>, <a href="/format/2402.18959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MambaStock: Selective state space model for stock prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhuangwei Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2204.02623">arXiv:2204.02623</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">The stock market plays a pivotal role in economic development, yet its
intricate volatility poses challenges for investors. Consequently, research and
accurate predictions of stock price movements are crucial for mitigating risks.
Traditional time series models fall short in capturing nonlinearity, leading to
unsatisfactory stock predictions. This limitation has spurred the widespread
adoption of neural networks for stock prediction, owing to their robust
nonlinear generalization capabilities. Recently, Mamba, a structured state
space sequence model with a selection mechanism and scan module (S6), has
emerged as a powerful tool in sequence modeling tasks. Leveraging this
framework, this paper proposes a novel Mamba-based model for stock price
prediction, named MambaStock. The proposed MambaStock model effectively mines
historical stock market data to predict future stock prices without handcrafted
features or extensive preprocessing procedures. Empirical studies on several
stocks indicate that the MambaStock model outperforms previous methods,
delivering highly accurate predictions. This enhanced accuracy can assist
investors and institutions in making informed decisions, aiming to maximize
returns while minimizing risks. This work underscores the value of Mamba in
time-series forecasting. Source code is available at
https://github.com/zshicode/MambaStock.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18960" title="Abstract">arXiv:2402.18960</a> [<a href="/pdf/2402.18960" title="Download PDF">pdf</a>, <a href="/format/2402.18960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Out-of-Distribution Detection for breast cancer classification  in Point-of-Care Ultrasound Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karlsson%2C+J">Jennie Karlsson</a>, 
<a href="/search/cs?searchtype=author&query=Wodrich%2C+M">Marisa Wodrich</a>, 
<a href="/search/cs?searchtype=author&query=Overgaard%2C+N+C">Niels Christian Overgaard</a>, 
<a href="/search/cs?searchtype=author&query=Sahlin%2C+F">Freja Sahlin</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A5ng%2C+K">Kristina L&#xe5;ng</a>, 
<a href="/search/cs?searchtype=author&query=Heyden%2C+A">Anders Heyden</a>, 
<a href="/search/cs?searchtype=author&query=Arvidsson%2C+I">Ida Arvidsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning has shown to have great potential in medical applications. In
critical domains as such, it is of high interest to have trustworthy algorithms
which are able to tell when reliable assessments cannot be guaranteed.
Detecting out-of-distribution (OOD) samples is a crucial step towards building
a safe classifier. Following a previous study, showing that it is possible to
classify breast cancer in point-of-care ultrasound images, this study
investigates OOD detection using three different methods: softmax, energy score
and deep ensembles. All methods are tested on three different OOD data sets.
The results show that the energy score method outperforms the softmax method,
performing well on two of the data sets. The ensemble method is the most
robust, performing the best at detecting OOD samples for all three OOD data
sets.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18962" title="Abstract">arXiv:2402.18962</a> [<a href="/pdf/2402.18962" title="Download PDF">pdf</a>, <a href="/ps/2402.18962" title="Download PostScript">ps</a>, <a href="/format/2402.18962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Program Synthesis in Saturation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hozzov%C3%A1%2C+P">Petra Hozzov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Norman%2C+C">Chase Norman</a>, 
<a href="/search/cs?searchtype=author&query=Voronkov%2C+A">Andrei Voronkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages; this is an extended version of the published paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automated Deduction - CADE 29. CADE 2023. Lecture Notes in
  Computer Science, vol 14132. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We present an automated reasoning framework for synthesizing recursion-free
programs using saturation-based theorem proving. Given a functional
specification encoded as a first-order logical formula, we use a first-order
theorem prover to both establish validity of this formula and discover program
fragments satisfying the specification. As a result, when deriving a proof of
program correctness, we also synthesize a program that is correct with respect
to the given specification. We describe properties of the calculus that a
saturation-based prover capable of synthesis should employ, and extend the
superposition calculus in a corresponding way. We implemented our work in the
first-order prover Vampire, extending the successful applicability of
first-order proving to program synthesis.
<br />This is an extended version of an Automated Deduction -- CADE 29 paper with
the same title and the same authors.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18969" title="Abstract">arXiv:2402.18969</a> [<a href="/pdf/2402.18969" title="Download PDF">pdf</a>, <a href="/format/2402.18969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OHTA: One-shot Hand Avatar via Data-driven Implicit Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaozheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zeran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaohu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhou Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024. Project page: <a href="https://zxz267.github.io/OHTA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we delve into the creation of one-shot hand avatars, attaining
high-fidelity and drivable hand representations swiftly from a single image.
With the burgeoning domains of the digital human, the need for quick and
personalized hand avatar creation has become increasingly critical. Existing
techniques typically require extensive input data and may prove cumbersome or
even impractical in certain scenarios. To enhance accessibility, we present a
novel method OHTA (One-shot Hand avaTAr) that enables the creation of detailed
hand avatars from merely one image. OHTA tackles the inherent difficulties of
this data-limited problem by learning and utilizing data-driven hand priors.
Specifically, we design a hand prior model initially employed for 1) learning
various hand priors with available data and subsequently for 2) the inversion
and fitting of the target identity with prior knowledge. OHTA demonstrates the
capability to create high-fidelity hand avatars with consistent animatable
quality, solely relying on a single image. Furthermore, we illustrate the
versatility of OHTA through diverse applications, encompassing text-to-avatar
conversion, hand editing, and identity latent space manipulation.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18970" title="Abstract">arXiv:2402.18970</a> [<a href="/pdf/2402.18970" title="Download PDF">pdf</a>, <a href="/format/2402.18970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrivatEyes: Appearance-based Gaze Estimation Using Federated Secure  Multi-Party Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elfares%2C+M">Mayar Elfares</a>, 
<a href="/search/cs?searchtype=author&query=Reisert%2C+P">Pascal Reisert</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenwu Tang</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCsters%2C+R">Ralf K&#xfc;sters</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Latest gaze estimation methods require large-scale training data but their
collection and exchange pose significant privacy risks. We propose PrivatEyes -
the first privacy-enhancing training approach for appearance-based gaze
estimation based on federated learning (FL) and secure multi-party computation
(MPC). PrivatEyes enables training gaze estimators on multiple local datasets
across different users and server-based secure aggregation of the individual
estimators' updates. PrivatEyes guarantees that individual gaze data remains
private even if a majority of the aggregating servers is malicious. We also
introduce a new data leakage attack DualView that shows that PrivatEyes limits
the leakage of private training data more effectively than previous approaches.
Evaluations on the MPIIGaze, MPIIFaceGaze, GazeCapture, and NVGaze datasets
further show that the improved privacy does not lead to a lower gaze estimation
accuracy or substantially higher computational costs - both of which are on par
with its non-secure counterparts.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18973" title="Abstract">arXiv:2402.18973</a> [<a href="/pdf/2402.18973" title="Download PDF">pdf</a>, <a href="/ps/2402.18973" title="Download PostScript">ps</a>, <a href="/format/2402.18973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Management and Interface Design for a Smart House
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Comeaga%2C+A">Ana-Maria Comeaga</a>, 
<a href="/search/cs?searchtype=author&query=Marin%2C+I">Iuliana Marin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 9th International Aegean Congress on Innovation Technologies &amp;
  Engineering, Izmir, T\"urkiye, February 23-25, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In today's life, more and more people tend to opt for a smart house. In this
way, the idea of including technology has become popular worldwide. Despite
this concept's many benefits, managing security remains an essential problem
due to the shared activities. The Internet of Things system behind a smart
house is based on several sensors to measure temperature, humidity, air
quality, and movement. Because of being supervised every day through sensors
and controlling their house only with a simple click, many people can be afraid
of this new approach in terms of their privacy, and this fact can constrain
them from following their habits. The security aspects should be constantly
analyzed to keep the data's confidentiality and make people feel safe in their
own houses. In this context, the current paper puts light on an alternative
design of a platform in which the safety of homeowners is the primary purpose,
and they maintain complete control over the data generated by smart devices.
The current research highlights the role of security and interface design in
controlling a smart house. The study underscores the importance of providing an
interface that can be used easily by any person to manage data and live
activities in a modern residence in an era dominated by continuously developing
technology.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18974" title="Abstract">arXiv:2402.18974</a> [<a href="/pdf/2402.18974" title="Download PDF">pdf</a>, <a href="/format/2402.18974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Generation via Spectral Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minello%2C+G">Giorgia Minello</a>, 
<a href="/search/cs?searchtype=author&query=Bicciato%2C+A">Alessandro Bicciato</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+L">Luca Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Torsello%2C+A">Andrea Torsello</a>, 
<a href="/search/cs?searchtype=author&query=Cosmo%2C+L">Luca Cosmo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we present GRASP, a novel graph generative model based on 1)
the spectral decomposition of the graph Laplacian matrix and 2) a diffusion
process. Specifically, we propose to use a denoising model to sample
eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian
and adjacency matrix. Our permutation invariant model can also handle node
features by concatenating them to the eigenvectors of each node. Using the
Laplacian spectrum allows us to naturally capture the structural
characteristics of the graph and work directly in the node space while avoiding
the quadratic complexity bottleneck that limits the applicability of other
methods. This is achieved by truncating the spectrum, which as we show in our
experiments results in a faster yet accurate generative process. An extensive
set of experiments on both synthetic and real world graphs demonstrates the
strengths of our model against state-of-the-art alternatives.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18975" title="Abstract">arXiv:2402.18975</a> [<a href="/pdf/2402.18975" title="Download PDF">pdf</a>, <a href="/format/2402.18975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretically Achieving Continuous Representation of Oriented Bounding  Boxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zikai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guo-Ye Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tai-Jiang Mu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shi-min Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 tables, 8 figures. Accepted by CVPR'24. Code: <a href="https://github.com/Jittor/JDet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Considerable efforts have been devoted to Oriented Object Detection (OOD).
However, one lasting issue regarding the discontinuity in Oriented Bounding Box
(OBB) representation remains unresolved, which is an inherent bottleneck for
extant OOD methods. This paper endeavors to completely solve this issue in a
theoretically guaranteed manner and puts an end to the ad-hoc efforts in this
direction. Prior studies typically can only address one of the two cases of
discontinuity: rotation and aspect ratio, and often inadvertently introduce
decoding discontinuity, e.g. Decoding Incompleteness (DI) and Decoding
Ambiguity (DA) as discussed in literature. Specifically, we propose a novel
representation method called Continuous OBB (COBB), which can be readily
integrated into existing detectors e.g. Faster-RCNN as a plugin. It can
theoretically ensure continuity in bounding box regression which to our best
knowledge, has not been achieved in literature for rectangle-based object
representation. For fairness and transparency of experiments, we have developed
a modularized benchmark based on the open-source deep learning framework
Jittor's detection toolbox JDet for OOD evaluation. On the popular DOTA
dataset, by integrating Faster-RCNN as the same baseline model, our new method
outperforms the peer method Gliding Vertex by 1.13% mAP50 (relative improvement
1.54%), and 2.46% mAP75 (relative improvement 5.91%), without any tricks.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18980" title="Abstract">arXiv:2402.18980</a> [<a href="/pdf/2402.18980" title="Download PDF">pdf</a>, <a href="/ps/2402.18980" title="Download PostScript">ps</a>, <a href="/format/2402.18980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helper Data Schemes for Coded Modulation and Shaping in Physical  Unclonable Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+R+F+H">Robert F.H. Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we consider the generation and utilization of helper data for
physical unclonable functions (PUFs) that provide real-valued readout symbols.
Compared to classical binary PUFs, more entropy can be extracted from each
basic building block (PUF node), resulting in longer keys/fingerprints and/or a
higher reliability. To this end, a coded modulation and signal shaping scheme
that matches the (approximately) Gaussian distribution of the readout has to be
employed. A new helper data scheme is proposed that works with any type of
coded modulation/shaping scheme. Compared to the permutation scheme from the
literature, less amount of helper data has to be generated and a higher
reliability is achieved. Moreover, the recently proposed idea of a two-metric
helper data scheme is generalized to coded modulation and a general S-metric
scheme. It is shown how extra helper data can be generated to improve
decodability. The proposed schemes are assessed by numerical simulations and by
evaluation of measurement data. We compare multi-level codes using a new rate
design strategy with bit-interleaved coded modulation and trellis shaping with
a distribution matcher. By selecting a suitable design, the rate per PUF node
that can be reliably extracted can be as high as 2~bit/node.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18982" title="Abstract">arXiv:2402.18982</a> [<a href="/pdf/2402.18982" title="Download PDF">pdf</a>, <a href="/format/2402.18982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splitting integrators for linear Vlasov equations with stochastic  perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Br%C3%A9hier%2C+C">Charles-Edouard Br&#xe9;hier</a>, 
<a href="/search/math?searchtype=author&query=Cohen%2C+D">David Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">We consider a class of linear Vlasov partial differential equations driven by
Wiener noise. Different types of stochastic perturbations are treated: additive
noise, multiplicative It\^o and Stratonovich noise, and transport noise. We
propose to employ splitting integrators for the temporal discretization of
these stochastic partial differential equations. These integrators are designed
in order to preserve qualitative properties of the exact solutions depending on
the stochastic perturbation, such as preservation of norms or positivity of the
solutions. We provide numerical experiments in order to illustrate the
properties of the proposed integrators and investigate mean-square rates of
convergence.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18986" title="Abstract">arXiv:2402.18986</a> [<a href="/pdf/2402.18986" title="Download PDF">pdf</a>, <a href="/format/2402.18986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Always be Pre-Training: Representation Learning for Network Intrusion  Detection with GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhengyao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+D+T">Diego Troy Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Alrahis%2C+L">Lilas Alrahis</a>, 
<a href="/search/cs?searchtype=author&query=Sinanoglu%2C+O">Ozgur Sinanoglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will appear in the 2024 International Symposium on Quality Electronic Design (ISQED'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Graph neural network-based network intrusion detection systems have recently
demonstrated state-of-the-art performance on benchmark datasets. Nevertheless,
these methods suffer from a reliance on target encoding for data
pre-processing, limiting widespread adoption due to the associated need for
annotated labels--a cost-prohibitive requirement. In this work, we propose a
solution involving in-context pre-training and the utilization of dense
representations for categorical features to jointly overcome the
label-dependency limitation. Our approach exhibits remarkable data efficiency,
achieving over 98% of the performance of the supervised state-of-the-art with
less than 4% labeled data on the NF-UQ-NIDS-V2 dataset.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18994" title="Abstract">arXiv:2402.18994</a> [<a href="/pdf/2402.18994" title="Download PDF">pdf</a>, <a href="/ps/2402.18994" title="Download PostScript">ps</a>, <a href="/format/2402.18994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spyx: A Library for Just-In-Time Compiled Optimization of Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heckel%2C+K+M">Kade M. Heckel</a>, 
<a href="/search/cs?searchtype=author&query=Nowotny%2C+T">Thomas Nowotny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As the role of artificial intelligence becomes increasingly pivotal in modern
society, the efficient training and deployment of deep neural networks have
emerged as critical areas of focus. Recent advancements in attention-based
large neural architectures have spurred the development of AI accelerators,
facilitating the training of extensive, multi-billion parameter models. Despite
their effectiveness, these powerful networks often incur high execution costs
in production environments. Neuromorphic computing, inspired by biological
neural processes, offers a promising alternative. By utilizing
temporally-sparse computations, Spiking Neural Networks (SNNs) offer to enhance
energy efficiency through a reduced and low-power hardware footprint. However,
the training of SNNs can be challenging due to their recurrent nature which
cannot as easily leverage the massive parallelism of modern AI accelerators. To
facilitate the investigation of SNN architectures and dynamics researchers have
sought to bridge Python-based deep learning frameworks such as PyTorch or
TensorFlow with custom-implemented compute kernels. This paper introduces Spyx,
a new and lightweight SNN simulation and optimization library designed in JAX.
By pre-staging data in the expansive vRAM of contemporary accelerators and
employing extensive JIT compilation, Spyx allows for SNN optimization to be
executed as a unified, low-level program on NVIDIA GPUs or Google TPUs. This
approach achieves optimal hardware utilization, surpassing the performance of
many existing SNN training frameworks while maintaining considerable
flexibility.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18995" title="Abstract">arXiv:2402.18995</a> [<a href="/pdf/2402.18995" title="Download PDF">pdf</a>, <a href="/format/2402.18995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous  Overdispersed Count Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sikun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Modeling count-valued time series has been receiving increasing attention
since count time series naturally arise in physical and social domains. Poisson
gamma dynamical systems (PGDSs) are newly-developed methods, which can well
capture the expressive latent transition structure and bursty dynamics behind
count sequences. In particular, PGDSs demonstrate superior performance in terms
of data imputation and prediction, compared with canonical linear dynamical
system (LDS) based methods. Despite these advantages, PGDS cannot capture the
heterogeneous overdispersed behaviours of the underlying dynamic processes. To
mitigate this defect, we propose a negative-binomial-randomized gamma Markov
process, which not only significantly improves the predictive performance of
the proposed dynamical system, but also facilitates the fast convergence of the
inference algorithm. Moreover, we develop methods to estimate both
factor-structured and graph-structured transition dynamics, which enable us to
infer more explainable latent structure, compared with PGDSs. Finally, we
demonstrate the explainable latent structure learned by the proposed method,
and show its superior performance in imputing missing data and forecasting
future observations, compared with the related models.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18998" title="Abstract">arXiv:2402.18998</a> [<a href="/pdf/2402.18998" title="Download PDF">pdf</a>, <a href="/format/2402.18998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COFT-AD: COntrastive Fine-Tuning for Few-Shot Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jingyi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+C">Manh Cuong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Goodge%2C+A">Adam Goodge</a>, 
<a href="/search/cs?searchtype=author&query=Foo%2C+C+S">Chuan Sheng Foo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Image Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing approaches towards anomaly detection~(AD) often rely on a
substantial amount of anomaly-free data to train representation and density
models. However, large anomaly-free datasets may not always be available before
the inference stage; in which case an anomaly detection model must be trained
with only a handful of normal samples, a.k.a. few-shot anomaly detection
(FSAD). In this paper, we propose a novel methodology to address the challenge
of FSAD which incorporates two important techniques. Firstly, we employ a model
pre-trained on a large source dataset to initialize model weights. Secondly, to
ameliorate the covariate shift between source and target domains, we adopt
contrastive training to fine-tune on the few-shot target domain data. To learn
suitable representations for the downstream AD task, we additionally
incorporate cross-instance positive pairs to encourage a tight cluster of the
normal samples, and negative pairs for better separation between normal and
synthesized negative samples. We evaluate few-shot anomaly detection on on 3
controlled AD tasks and 4 real-world AD tasks to demonstrate the effectiveness
of the proposed method.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19001" title="Abstract">arXiv:2402.19001</a> [<a href="/pdf/2402.19001" title="Download PDF">pdf</a>, <a href="/format/2402.19001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the Two-Step Heterogeneous Transfer Learning for Laryngeal  Blood Vessel Classification: Issue and Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xinyi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+C+F">Chak Fong Chong</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+L">Kei Long Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yapeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiankui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sio-Kei Im</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transferring features learned from natural to medical images for
classification is common. However, challenges arise due to the scarcity of
certain medical image types and the feature disparities between natural and
medical images. Two-step transfer learning has been recognized as a promising
solution for this issue. However, choosing an appropriate intermediate domain
would be critical in further improving the classification performance. In this
work, we explore the effectiveness of using color fundus photographs of the
diabetic retina dataset as an intermediate domain for two-step heterogeneous
learning (THTL) to classify laryngeal vascular images with nine deep-learning
models. Experiment results confirm that although the images in both the
intermediate and target domains share vascularized characteristics, the
accuracy is drastically reduced compared to one-step transfer learning, where
only the last layer is fine-tuned (e.g., ResNet18 drops 14.7%, ResNet50 drops
14.8%). By analyzing the Layer Class Activation Maps (LayerCAM), we uncover a
novel finding that the prevalent radial vascular pattern in the intermediate
domain prevents learning the features of twisted and tangled vessels that
distinguish the malignant class in the target domain. To address the
performance drop, we propose the Step-Wise Fine-Tuning (SWFT) method on ResNet
in the second step of THTL, resulting in substantial accuracy improvements.
Compared to THTL's second step, where only the last layer is fine-tuned,
accuracy increases by 26.1% for ResNet18 and 20.4% for ResNet50. Additionally,
compared to training from scratch, using ImageNet as the source domain could
slightly improve classification performance for laryngeal vascular, but the
differences are insignificant.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19002" title="Abstract">arXiv:2402.19002</a> [<a href="/pdf/2402.19002" title="Download PDF">pdf</a>, <a href="/format/2402.19002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Ching-Lin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi-Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kuan-Ting Lai</a>, 
<a href="/search/cs?searchtype=author&query=Fadillah%2C+A">Amar Fadillah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting the future trajectories of pedestrians on the road is an important
task for autonomous driving. The pedestrian trajectory prediction is affected
by scene paths, pedestrian's intentions and decision-making, which is a
multi-modal problem. Most recent studies use past trajectories to predict a
variety of potential future trajectory distributions, which do not account for
the scene context and pedestrian targets. Instead of predicting the future
trajectory directly, we propose to use scene context and observed trajectory to
predict the goal points first, and then reuse the goal points to predict the
future trajectories. By leveraging the information from scene context and
observed trajectory, the uncertainty can be limited to a few target areas,
which represent the "goals" of the pedestrians. In this paper, we propose
GoalNet, a new trajectory prediction neural network based on the goal areas of
a pedestrian. Our network can predict both pedestrian's trajectories and
bounding boxes. The overall model is efficient and modular, and its outputs can
be changed according to the usage scenario. Experimental results show that
GoalNet significantly improves the previous state-of-the-art performance by
48.7% on the JAAD and 40.8% on the PIE dataset.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19004" title="Abstract">arXiv:2402.19004</a> [<a href="/pdf/2402.19004" title="Download PDF">pdf</a>, <a href="/format/2402.19004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSAM-Seg: A SAM-based Approach with Prior Knowledge Integration for  Remote Sensing Image Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xubing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The development of high-resolution remote sensing satellites has provided
great convenience for research work related to remote sensing. Segmentation and
extraction of specific targets are essential tasks when facing the vast and
complex remote sensing images. Recently, the introduction of Segment Anything
Model (SAM) provides a universal pre-training model for image segmentation
tasks. While the direct application of SAM to remote sensing image segmentation
tasks does not yield satisfactory results, we propose RSAM-Seg, which stands
for Remote Sensing SAM with Semantic Segmentation, as a tailored modification
of SAM for the remote sensing field and eliminates the need for manual
intervention to provide prompts. Adapter-Scale, a set of supplementary scaling
modules, are proposed in the multi-head attention blocks of the encoder part of
SAM. Furthermore, Adapter-Feature are inserted between the Vision Transformer
(ViT) blocks. These modules aim to incorporate high-frequency image information
and image embedding features to generate image-informed prompts. Experiments
are conducted on four distinct remote sensing scenarios, encompassing cloud
detection, field monitoring, building detection and road mapping tasks . The
experimental results not only showcase the improvement over the original SAM
and U-Net across cloud, buildings, fields and roads scenarios, but also
highlight the capacity of RSAM-Seg to discern absent areas within the ground
truth of certain datasets, affirming its potential as an auxiliary annotation
method. In addition, the performance in few-shot scenarios is commendable,
underscores its potential in dealing with limited datasets.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19007" title="Abstract">arXiv:2402.19007</a> [<a href="/pdf/2402.19007" title="Download PDF">pdf</a>, <a href="/format/2402.19007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOZE: A Dataset for Open-Vocabulary Zero-Shot Object Navigation in  Dynamic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Ji Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hongming Dai</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+X">Xiaowei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Y">Yang Fei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Zero-Shot Object Navigation (ZSON) requires agents to autonomously locate and
approach unseen objects in unfamiliar environments and has emerged as a
particularly challenging task within the domain of Embodied AI. Existing
datasets for developing ZSON algorithms lack consideration of dynamic
obstacles, object attribute diversity, and scene texts, thus exhibiting
noticeable discrepancy from real-world situations. To address these issues, we
propose a Dataset for Open-Vocabulary Zero-Shot Object Navigation in Dynamic
Environments (DOZE) that comprises ten high-fidelity 3D scenes with over 18k
tasks, aiming to mimic complex, dynamic real-world scenarios. Specifically,
DOZE scenes feature multiple moving humanoid obstacles, a wide array of
open-vocabulary objects, diverse distinct-attribute objects, and valuable
textual hints. Besides, different from existing datasets that only provide
collision checking between the agent and static obstacles, we enhance DOZE by
integrating capabilities for detecting collisions between the agent and moving
obstacles. This novel functionality enables evaluation of the agents' collision
avoidance abilities in dynamic environments. We test four representative ZSON
methods on DOZE, revealing substantial room for improvement in existing
approaches concerning navigation efficiency, safety, and object recognition
accuracy. Our dataset could be found at https://DOZE-Dataset.github.io/.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19009" title="Abstract">arXiv:2402.19009</a> [<a href="/pdf/2402.19009" title="Download PDF">pdf</a>, <a href="/format/2402.19009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating, Reconstructing, and Representing Discrete and Continuous  Data: Generalized Diffusion with Learnable Encoding-Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zeyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Liping Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E+P">Eric P. Xing</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The vast applications of deep generative models are anchored in three core
capabilities -- generating new instances, reconstructing inputs, and learning
compact representations -- across various data types, such as discrete
text/protein sequences and continuous images. Existing model families, like
Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs),
autoregressive models, and diffusion models, generally excel in specific
capabilities and data types but fall short in others. We introduce generalized
diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates
the core capabilities for broad applicability and enhanced performance. DiLED
generalizes the Gaussian noising-denoising in standard diffusion by introducing
parameterized encoding-decoding. Crucially, DiLED is compatible with the
well-established diffusion model objective and training recipes, allowing
effective learning of the encoder-decoder parameters jointly with diffusion. By
choosing appropriate encoder/decoder (e.g., large language models), DiLED
naturally applies to different data types. Extensive experiments on text,
proteins, and images demonstrate DiLED's flexibility to handle diverse data and
tasks and its strong improvement over various existing models.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19011" title="Abstract">arXiv:2402.19011</a> [<a href="/pdf/2402.19011" title="Download PDF">pdf</a>, <a href="/format/2402.19011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ruledger: Ensuring Execution Integrity in Trigger-Action IoT Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jingwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yi He</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sandhu%2C+R">Ravi Sandhu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10.1109/INFOCOM42981.2021.9488687
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Smart home IoT systems utilize trigger-action platforms, e.g., IFTTT, to
manage devices from various vendors. However, they may be abused by triggering
malicious rule execution with forged IoT devices or events violating the
execution integrity and the intentions of the users. To address this issue, we
propose a ledger based IoT platform called Ruledger, which ensures the correct
execution of rules by verifying the authenticity of the corresponding
information. Ruledger utilizes smart contracts to enforce verifying the
information associated with rule executions, e.g., the user and configuration
information from users, device events, and triggers in the trigger-action
platforms. In particular, we develop three algorithms to enable ledger-wallet
based applications for Ruledger and guarantee that the records used for
verification are stateful and correct. Thus, the execution integrity of rules
is ensured even if devices and platforms in the smart home systems are
compromised. We prototype Ruledger in a real IoT platform, i.e., IFTTT, and
evaluate the performance with various settings. The experimental results
demonstrate Ruledger incurs an average of 12.53% delay, which is acceptable for
smart home systems.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19012" title="Abstract">arXiv:2402.19012</a> [<a href="/pdf/2402.19012" title="Download PDF">pdf</a>, <a href="/ps/2402.19012" title="Download PostScript">ps</a>, <a href="/format/2402.19012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmically Expressive, Always-Terminating Model for Reversible  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palazzo%2C+M">Matteo Palazzo</a> (1), 
<a href="/search/cs?searchtype=author&query=Roversi%2C+L">Luca Roversi</a> (1) ((1) Universit&#xe0; di Torino)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures, 2 listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Concerning classical computational models able to express all the Primitive
Recursive Functions (PRF), there are interesting results regarding limits on
their algorithmic expressiveness or, equivalently, efficiency, namely the
ability to express algorithms with minimal computational cost. By introducing
the reversible programming model Forest, at our knowledge, we provide a first
study of analogous properties, adapted to the context of reversible
computational models that can represent all the functions in PRF. Firstly, we
show that Forest extends Matos' linear reversible computational model MSRL, the
very extension being a guaranteed terminating iteration that can be halted by
means of logical predicates. The consequence is that Forest is PRF complete,
because MSRL is. Secondly, we show that Forest is strictly algorithmically more
expressive than MSRL: it can encode a reversible algorithm for the minimum
between two integers in optimal time, while MSRL cannot.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19013" title="Abstract">arXiv:2402.19013</a> [<a href="/pdf/2402.19013" title="Download PDF">pdf</a>, <a href="/format/2402.19013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultraviolet Positioning via TDOA: Error Analysis and System Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+S">Shihui Yu</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+C">Chubing Lv</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yueke Yang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Yuchen Pan</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+L">Lei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yubo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+J">Juliang Cao</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+R">Ruihang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+W">Wenqi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhengyuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work performs the design, real-time hardware realization, and
experimental evaluation of a positioning system by ultra-violet (UV)
communication under photon-level signal detection. The positioning is based on
time-difference of arrival (TDOA) principle. Time division-based transmission
of synchronization sequence from three transmitters with known positions is
applied. We investigate the positioning error via decomposing it into two
parts, the transmitter-side timing error and the receiver-side synchronization
error. The theoretical average error matches well with the simulation results,
which indicates that theoretical fitting can provide reliable guidance and
prediction for hardware experiments. We also conduct real-time hardware
realization of the TDOA-based positioning system using Field Programmable Gate
Array (FPGA), which is experimentally evaluated via outdoor experiments.
Experimental results match well with the theoretical and simulation results.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19014" title="Abstract">arXiv:2402.19014</a> [<a href="/pdf/2402.19014" title="Download PDF">pdf</a>, <a href="/format/2402.19014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Visual Document Understanding with Contrastive Learning in  Large Visual-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinghua Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhihao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Mingming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Haoyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinsong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Deqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the advent of Large Visual-Language Models (LVLMs) has received
increasing attention across various domains, particularly in the field of
visual document understanding (VDU). Different from conventional
vision-language tasks, VDU is specifically concerned with text-rich scenarios
containing abundant document elements. Nevertheless, the importance of
fine-grained features remains largely unexplored within the community of LVLMs,
leading to suboptimal performance in text-rich scenarios. In this paper, we
abbreviate it as the fine-grained feature collapse issue. With the aim of
filling this gap, we propose a contrastive learning framework, termed Document
Object COntrastive learning (DoCo), specifically tailored for the downstream
tasks of VDU. DoCo leverages an auxiliary multimodal encoder to obtain the
features of document objects and align them to the visual features generated by
the vision encoder of LVLM, which enhances visual representation in text-rich
scenarios. It can represent that the contrastive learning between the visual
holistic representations and the multimodal fine-grained features of document
objects can assist the vision encoder in acquiring more effective visual cues,
thereby enhancing the comprehension of text-rich documents in LVLMs. We also
demonstrate that the proposed DoCo serves as a plug-and-play pre-training
method, which can be employed in the pre-training of various LVLMs without
inducing any increase in computational complexity during the inference process.
Extensive experimental results on multiple benchmarks of VDU reveal that LVLMs
equipped with our proposed DoCo can achieve superior performance and mitigate
the gap between VDU and generic vision-language tasks.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19015" title="Abstract">arXiv:2402.19015</a> [<a href="/pdf/2402.19015" title="Download PDF">pdf</a>, <a href="/format/2402.19015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional material derivative: pointwise representation and a finite  volume numerical scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=P%C5%82ociniczak%2C+%C5%81">&#x141;ukasz P&#x142;ociniczak</a>, 
<a href="/search/math?searchtype=author&query=Teuerle%2C+M+A">Marek A. Teuerle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The fractional material derivative appears as the fractional operator that
governs the dynamics of the scaling limits of L\'evy walks - a stochastic
process that originates from the famous continuous-time random walks. It is
usually defined as the Fourier-Laplace multiplier, therefore, it can be thought
of as a pseudo-differential operator. In this paper, we show that there exists
a local representation in time and space, pointwise, of the fractional material
derivative. This allows us to define it on a space of locally integrable
functions which is larger than the original one in which Fourier and Laplace
transform exist as functions.
<br />We consider several typical differential equations involving the fractional
material derivative and provide conditions for their solutions to exist. In
some cases, the analytical solution can be found. For the general initial value
problem, we devise a finite volume method and prove its stability, convergence,
and conservation of probability. Numerical illustrations verify our analytical
findings. Moreover, our numerical experiments show superiority in the
computation time of the proposed numerical scheme over a Monte Carlo method
applied to the problem of probability density function's derivation.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19016" title="Abstract">arXiv:2402.19016</a> [<a href="/pdf/2402.19016" title="Download PDF">pdf</a>, <a href="/format/2402.19016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPriFed-OMP: A Differentially Private Federated Learning Algorithm for  Sparse Basis Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mulay%2C+A+K">Ajinkya Kiran Mulay</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaojun Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Sparse basis recovery is a classical and important statistical learning
problem when the number of model dimensions $p$ is much larger than the number
of samples $n$. However, there has been little work that studies sparse basis
recovery in the Federated Learning (FL) setting, where the client data's
differential privacy (DP) must also be simultaneously protected. In particular,
the performance guarantees of existing DP-FL algorithms (such as DP-SGD) will
degrade significantly when $p \gg n$, and thus, they will fail to learn the
true underlying sparse model accurately. In this work, we develop a new
differentially private sparse basis recovery algorithm for the FL setting,
called SPriFed-OMP. SPriFed-OMP converts OMP (Orthogonal Matching Pursuit) to
the FL setting. Further, it combines SMPC (secure multi-party computation) and
DP to ensure that only a small amount of noise needs to be added in order to
achieve differential privacy. As a result, SPriFed-OMP can efficiently recover
the true sparse basis for a linear model with only $n = O(\sqrt{p})$ samples.
We further present an enhanced version of our approach, SPriFed-OMP-GRAD based
on gradient privatization, that improves the performance of SPriFed-OMP. Our
theoretical analysis and empirical results demonstrate that both SPriFed-OMP
and SPriFed-OMP-GRAD terminate in a small number of steps, and they
significantly outperform the previous state-of-the-art DP-FL solutions in terms
of the accuracy-privacy trade-off.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19025" title="Abstract">arXiv:2402.19025</a> [<a href="/pdf/2402.19025" title="Download PDF">pdf</a>, <a href="/format/2402.19025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combination of Weak Learners eXplanations to Improve Random Forest  eXplicability Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pala%2C+R">Riccardo Pala</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Cuesta%2C+E">Esteban Garc&#xed;a-Cuesta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The notion of robustness in XAI refers to the observed variations in the
explanation of the prediction of a learned model with respect to changes in the
input leading to that prediction. Intuitively, if the input being explained is
modified slightly subtly enough so as to not change the prediction of the model
too much, then we would expect that the explanation provided for that new input
does not change much either. We argue that a combination through discriminative
averaging of ensembles weak learners explanations can improve the robustness of
explanations in ensemble methods.This approach has been implemented and tested
with post-hoc SHAP method and Random Forest ensemble with successful results.
The improvements obtained have been measured quantitatively and some insights
into the explicability robustness in ensemble methods are presented.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19026" title="Abstract">arXiv:2402.19026</a> [<a href="/pdf/2402.19026" title="Download PDF">pdf</a>, <a href="/format/2402.19026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Contrastive Learning with Multi-Prototype for Unsupervised  Visible-Infrared Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangbo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoxing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanyun Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised visible-infrared person re-identification (USVI-ReID) aims to
match specified people in infrared images to visible images without annotation,
and vice versa. USVI-ReID is a challenging yet under-explored task. Most
existing methods address the USVI-ReID problem using cluster-based contrastive
learning, which simply employs the cluster center as a representation of a
person. However, the cluster center primarily focuses on shared information,
overlooking disparity. To address the problem, we propose a Progressive
Contrastive Learning with Multi-Prototype (PCLMP) method for USVI-ReID. In
brief, we first generate the hard prototype by selecting the sample with the
maximum distance from the cluster center. This hard prototype is used in the
contrastive loss to emphasize disparity. Additionally, instead of rigidly
aligning query images to a specific prototype, we generate the dynamic
prototype by randomly picking samples within a cluster. This dynamic prototype
is used to retain the natural variety of features while reducing instability in
the simultaneous learning of both common and disparate information. Finally, we
introduce a progressive learning strategy to gradually shift the model's
attention towards hard samples, avoiding cluster deterioration. Extensive
experiments conducted on the publicly available SYSU-MM01 and RegDB datasets
validate the effectiveness of the proposed method. PCLMP outperforms the
existing state-of-the-art method with an average mAP improvement of 3.9%. The
source codes will be released.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19027" title="Abstract">arXiv:2402.19027</a> [<a href="/pdf/2402.19027" title="Download PDF">pdf</a>, <a href="/format/2402.19027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Train your Antivirus: RL-based Hardening through the  Problem-Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortellazzi%2C+J">Jacopo Cortellazzi</a>, 
<a href="/search/cs?searchtype=author&query=Tsingenopoulos%2C+I">Ilias Tsingenopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bo%C5%A1ansk%C3%BD%2C+B">Branislav Bo&#x161;ansk&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Aonzo%2C+S">Simone Aonzo</a>, 
<a href="/search/cs?searchtype=author&query=Preuveneers%2C+D">Davy Preuveneers</a>, 
<a href="/search/cs?searchtype=author&query=Joosen%2C+W">Wouter Joosen</a>, 
<a href="/search/cs?searchtype=author&query=Pierazzi%2C+F">Fabio Pierazzi</a>, 
<a href="/search/cs?searchtype=author&query=Cavallaro%2C+L">Lorenzo Cavallaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages,4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ML-based malware detection on dynamic analysis reports is vulnerable to both
evasion and spurious correlations. In this work, we investigate a specific ML
architecture employed in the pipeline of a widely-known commercial antivirus
company, with the goal to harden it against adversarial malware. Adversarial
training, the sole defensive technique that can confer empirical robustness, is
not applicable out of the box in this domain, for the principal reason that
gradient-based perturbations rarely map back to feasible problem-space
programs. We introduce a novel Reinforcement Learning approach for constructing
adversarial examples, a constituent part of adversarially training a model
against evasion. Our approach comes with multiple advantages. It performs
modifications that are feasible in the problem-space, and only those; thus it
circumvents the inverse mapping problem. It also makes possible to provide
theoretical guarantees on the robustness of the model against a particular set
of adversarial capabilities. Our empirical exploration validates our
theoretical insights, where we can consistently reach 0\% Attack Success Rate
after a few adversarial retraining iterations.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19028" title="Abstract">arXiv:2402.19028</a> [<a href="/pdf/2402.19028" title="Download PDF">pdf</a>, <a href="/ps/2402.19028" title="Download PostScript">ps</a>, <a href="/format/2402.19028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Checking for SMT-based Systems with Quantifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Redondi%2C+G">Gianluca Redondi</a>, 
<a href="/search/cs?searchtype=author&query=Cimatti%2C+A">Alessandro Cimatti</a>, 
<a href="/search/cs?searchtype=author&query=Griggio%2C+A">Alberto Griggio</a>, 
<a href="/search/cs?searchtype=author&query=McMillan%2C+K">Kenneth McMillan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">This paper addresses the problem of checking invariant properties for a large
class of symbolic transition systems, defined by a combination of SMT theories
and quantifiers. State variables can be functions from an uninterpreted sort
(finite, but unbounded) to an interpreted sort, such as the the integers under
the theory of linear arithmetic. This formalism is very expressive and can be
used for modeling parameterized systems, array-manipulating programs, and more.
We propose two algorithms for finding universal inductive invariants for such
systems. The first algorithm combines an IC3-style loop with a form of implicit
predicate abstraction to construct an invariant in an incremental manner. The
second algorithm constructs an under-approximation of the original problem, and
searches for a formula which is an inductive invariant for this case; then, the
invariant is generalized to the original case, and checked with a portfolio of
techniques. We have implemented the two algorithms and conducted an extensive
experimental evaluation, considering various benchmarks and different tools
from the literature. As far as we know, our method is the first capable of
handling in a large class of systems in a uniform way. The experiment shows
that both algorithms are competitive with the state of the art.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19033" title="Abstract">arXiv:2402.19033</a> [<a href="/pdf/2402.19033" title="Download PDF">pdf</a>, <a href="/format/2402.19033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Speed Motion Planning for Aerial Swarms in Unknown and Cluttered  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toumieh%2C+C">Charbel Toumieh</a>, 
<a href="/search/cs?searchtype=author&query=Floreano%2C+D">Dario Floreano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Coordinated flight of multiple drones allows to achieve tasks faster such as
search and rescue and infrastructure inspection. Thus, pushing the
state-of-the-art of aerial swarms in navigation speed and robustness is of
tremendous benefit. In particular, being able to account for unexplored/unknown
environments when planning trajectories allows for safer flight. In this work,
we propose the first high-speed, decentralized, and synchronous motion planning
framework (HDSM) for an aerial swarm that explicitly takes into account the
unknown/undiscovered parts of the environment. The proposed approach generates
an optimized trajectory for each planning agent that avoids obstacles and other
planning agents while moving and exploring the environment. The only global
information that each agent has is the target location. The generated
trajectory is high-speed, safe from unexplored spaces, and brings the agent
closer to its goal. The proposed method outperforms four recent
state-of-the-art methods in success rate (100% success in reaching the target
location), flight speed (67% faster), and flight time (42% lower). Finally, the
method is validated on a set of Crazyflie nano-drones as a proof of concept.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19037" title="Abstract">arXiv:2402.19037</a> [<a href="/pdf/2402.19037" title="Download PDF">pdf</a>, <a href="/format/2402.19037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep-Learning Technique to Locate Cryptographic Operations in  Side-Channel Traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiari%2C+G">Giuseppe Chiari</a>, 
<a href="/search/cs?searchtype=author&query=Galli%2C+D">Davide Galli</a>, 
<a href="/search/cs?searchtype=author&query=Lattari%2C+F">Francesco Lattari</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>, 
<a href="/search/cs?searchtype=author&query=Zoni%2C+D">Davide Zoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation by DATE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Side-channel attacks allow extracting secret information from the execution
of cryptographic primitives by correlating the partially known computed data
and the measured side-channel signal. However, to set up a successful
side-channel attack, the attacker has to perform i) the challenging task of
locating the time instant in which the target cryptographic primitive is
executed inside a side-channel trace and then ii)the time-alignment of the
measured data on that time instant. This paper presents a novel deep-learning
technique to locate the time instant in which the target computed cryptographic
operations are executed in the side-channel trace. In contrast to
state-of-the-art solutions, the proposed methodology works even in the presence
of trace deformations obtained through random delay insertion techniques. We
validated our proposal through a successful attack against a variety of
unprotected and protected cryptographic primitives that have been executed on
an FPGA-implemented system-on-chip featuring a RISC-V CPU.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19038" title="Abstract">arXiv:2402.19038</a> [<a href="/pdf/2402.19038" title="Download PDF">pdf</a>, <a href="/format/2402.19038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Fairness in Software Engineering: Insights from Stack  Exchange
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sesari%2C+E">Emeralda Sesari</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+A">Ayushi Rastogi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software practitioners discuss problems at work with peers, in-person and
online. These discussions can be technical (e.g., how to fix a bug?) and social
(e.g., how to assign work fairly?). While there is a growing body of knowledge
exploring fairness problems and solutions in the human and social factors of
software engineering, most focus has been on specific problems. This study
provides fairness discussions by software practitioners on Stack Exchange
sites. We present an exploratory study presenting the fairness experience of
software practitioners and fairness expectations in software teams. We also
want to identify the fairness aspects software practitioners talk about the
most. For example, do they care more about fairness in income or how they are
treated in the workplace?
<br />Our investigation of fairness discussions on eight Stack Exchange sites
resulted in a list of 136 posts (28 questions and 108 answers) manually curated
from 4,178 candidate posts. The study reveals that the majority of fairness
discussions (24 posts) revolve around the topic of income suggesting that many
software practitioners are highly interested in matters related to their pay
and how it is fairly distributed. Further, we noted that while not discussed as
often, discussions on fairness in recruitment tend to receive the highest
number of views and scores. Interestingly, the study shows that unfairness
experiences extend beyond the protected attributes. In this study, only 25 out
of 136 posts mention protected attributes, with gender mainly being discussed.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19041" title="Abstract">arXiv:2402.19041</a> [<a href="/pdf/2402.19041" title="Download PDF">pdf</a>, <a href="/format/2402.19041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hill%2C+P">P. Hill</a>, 
<a href="/search/cs?searchtype=author&query=Anantrasirichai%2C+N">N. Anantrasirichai</a>, 
<a href="/search/cs?searchtype=author&query=Achim%2C+A">A. Achim</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+D+R">D.R. Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Atmospheric turbulence poses a challenge for the interpretation and visual
perception of visual imagery due to its distortion effects. Model-based
approaches have been used to address this, but such methods often suffer from
artefacts associated with moving content. Conversely, deep learning based
methods are dependent on large and diverse datasets that may not effectively
represent any specific content. In this paper, we address these problems with a
self-supervised learning method that does not require ground truth. The
proposed method is not dependent on any dataset outside of the single data
sequence being processed but is also able to improve the quality of any input
raw sequences or pre-processed sequences. Specifically, our method is based on
an accelerated Deep Image Prior (DIP), but integrates temporal information
using pixel shuffling and a temporal sliding window. This efficiently learns
spatio-temporal priors leading to a system that effectively mitigates
atmospheric turbulence distortions. The experiments show that our method
improves visual quality results qualitatively and quantitatively.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19044" title="Abstract">arXiv:2402.19044</a> [<a href="/pdf/2402.19044" title="Download PDF">pdf</a>, <a href="/format/2402.19044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMSA -- Dense Multi Scan Adjustment for LiDAR Inertial Odometry and  Global Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skuddis%2C+D">David Skuddis</a>, 
<a href="/search/cs?searchtype=author&query=Haala%2C+N">Norbert Haala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose a new method for fine registering multiple point clouds
simultaneously. The approach is characterized by being dense, therefore point
clouds are not reduced to pre-selected features in advance. Furthermore, the
approach is robust against small overlaps and dynamic objects, since no direct
correspondences are assumed between point clouds. Instead, all points are
merged into a global point cloud, whose scattering is then iteratively reduced.
This is achieved by dividing the global point cloud into uniform grid cells
whose contents are subsequently modeled by normal distributions. We show that
the proposed approach can be used in a sliding window continuous trajectory
optimization combined with IMU measurements to obtain a highly accurate and
robust LiDAR inertial odometry estimation. Furthermore, we show that the
proposed approach is also suitable for large scale keyframe optimization to
increase accuracy. We provide the source code and some experimental data on
https://github.com/davidskdds/DMSA_LiDAR_SLAM.git.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19047" title="Abstract">arXiv:2402.19047</a> [<a href="/pdf/2402.19047" title="Download PDF">pdf</a>, <a href="/format/2402.19047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Foundations of Deep Selective State-Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cirone%2C+N+M">Nicola Muca Cirone</a>, 
<a href="/search/cs?searchtype=author&query=Orvieto%2C+A">Antonio Orvieto</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+B">Benjamin Walker</a>, 
<a href="/search/cs?searchtype=author&query=Salvi%2C+C">Cristopher Salvi</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">Structured state-space models (SSMs) such as S4, stemming from the seminal
work of Gu et al., are gaining popularity as effective approaches for modeling
sequential data. Deep SSMs demonstrate outstanding performance across a diverse
set of domains, at a reduced training and inference cost compared to
attention-based transformers. Recent developments show that if the linear
recurrence powering SSMs allows for multiplicative interactions between inputs
and hidden states (e.g. GateLoop, Mamba, GLA), then the resulting architecture
can surpass in both in accuracy and efficiency attention-powered foundation
models trained on text, at scales of billion parameters. In this paper, we give
theoretical grounding to this recent finding using tools from Rough Path
Theory: we show that when random linear recurrences are equipped with simple
input-controlled transitions (selectivity mechanism), then the hidden state is
provably a low-dimensional projection of a powerful mathematical object called
the signature of the input -- capturing non-linear interactions between tokens
at distinct timescales. Our theory not only motivates the success of modern
selective state-space models such as Mamba but also provides a solid framework
to understand the expressive power of future SSM variants.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19052" title="Abstract">arXiv:2402.19052</a> [<a href="/pdf/2402.19052" title="Download PDF">pdf</a>, <a href="/ps/2402.19052" title="Download PostScript">ps</a>, <a href="/format/2402.19052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Efficacy of Large Language Models in Summarizing Mental  Health Counseling Sessions: A Benchmark Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adhikary%2C+P+K">Prottay Kumar Adhikary</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Aseem Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shivani Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+M">Salam Michael Singh</a>, 
<a href="/search/cs?searchtype=author&query=Manuja%2C+P">Puneet Manuja</a>, 
<a href="/search/cs?searchtype=author&query=Gopinath%2C+J+K">Jini K Gopinath</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+V">Vijay Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Kedia%2C+S">Swati Kedia</a>, 
<a href="/search/cs?searchtype=author&query=Deb%2C+K+S">Koushik Sinha Deb</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Comprehensive summaries of sessions enable an effective continuity in mental
health counseling, facilitating informed therapy planning. Yet, manual
summarization presents a significant challenge, diverting experts' attention
from the core counseling process. This study evaluates the effectiveness of
state-of-the-art Large Language Models (LLMs) in selectively summarizing
various components of therapy sessions through aspect-based summarization,
aiming to benchmark their performance. We introduce MentalCLOUDS, a
counseling-component guided summarization dataset consisting of 191 counseling
sessions with summaries focused on three distinct counseling components (aka
counseling aspects). Additionally, we assess the capabilities of 11
state-of-the-art LLMs in addressing the task of component-guided summarization
in counseling. The generated summaries are evaluated quantitatively using
standard summarization metrics and verified qualitatively by mental health
professionals. Our findings demonstrate the superior performance of
task-specific LLMs such as MentalLlama, Mistral, and MentalBART in terms of
standard quantitative metrics such as Rouge-1, Rouge-2, Rouge-L, and BERTScore
across all aspects of counseling components. Further, expert evaluation reveals
that Mistral supersedes both MentalLlama and MentalBART based on six parameters
-- affective attitude, burden, ethicality, coherence, opportunity costs, and
perceived effectiveness. However, these models share the same weakness by
demonstrating a potential for improvement in the opportunity costs and
perceived effectiveness metrics.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19054" title="Abstract">arXiv:2402.19054</a> [<a href="/pdf/2402.19054" title="Download PDF">pdf</a>, <a href="/format/2402.19054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobWE: Robust Watermark Embedding for Personalized Federated Learning  Model Ownership Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yunlin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+K">Kai Chi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Ju Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hongbo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaoxue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Embedding watermarks into models has been widely used to protect model
ownership in federated learning (FL). However, existing methods are inadequate
for protecting the ownership of personalized models acquired by clients in
personalized FL (PFL). This is due to the aggregation of the global model in
PFL, resulting in conflicts over clients' private watermarks. Moreover,
malicious clients may tamper with embedded watermarks to facilitate model
leakage and evade accountability. This paper presents a robust watermark
embedding scheme, named RobWE, to protect the ownership of personalized models
in PFL. We first decouple the watermark embedding of personalized models into
two parts: head layer embedding and representation layer embedding. The head
layer belongs to clients' private part without participating in model
aggregation, while the representation layer is the shared part for aggregation.
For representation layer embedding, we employ a watermark slice embedding
operation, which avoids watermark embedding conflicts. Furthermore, we design a
malicious watermark detection scheme enabling the server to verify the
correctness of watermarks before aggregating local models. We conduct an
exhaustive experimental evaluation of RobWE. The results demonstrate that RobWE
significantly outperforms the state-of-the-art watermark embedding schemes in
FL in terms of fidelity, reliability, and robustness.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19056" title="Abstract">arXiv:2402.19056</a> [<a href="/pdf/2402.19056" title="Download PDF">pdf</a>, <a href="/format/2402.19056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering the Polytropic Exponent in the Porous Medium Equation:  Asymptotic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karakazian%2C+H">Hagop Karakazian</a>, 
<a href="/search/math?searchtype=author&query=Sayah%2C+T">Toni Sayah</a>, 
<a href="/search/math?searchtype=author&query=Triki%2C+F">Faouzi Triki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we consider the time dependent Porous Medium Equation, $u_t =
\Delta u^\gamma$ with real polytropic exponent $\gamma&gt;1$, subject to a
homogeneous Dirichlet boundary condition. We are interested in recovering
$\gamma$ from the knowledge of the solution $u$ at a given large time $T$.
Based on an asymptotic inequality satisfied by the solution $u(T)$, we propose
a numerical algorithm allowing us to recover $\gamma$. An upper bound for the
error between the exact and recovered $\gamma$ is then showed. Finally,
numerical investigations are carried out in two dimensions.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19058" title="Abstract">arXiv:2402.19058</a> [<a href="/pdf/2402.19058" title="Download PDF">pdf</a>, <a href="/ps/2402.19058" title="Download PostScript">ps</a>, <a href="/format/2402.19058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Design of Human-Robot Collaboration Gestures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrinah%2C+A">Anas Shrinah</a>, 
<a href="/search/cs?searchtype=author&query=Bahraini%2C+M+S">Masoud S. Bahraini</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F">Fahad Khan</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+S">Seemal Asif</a>, 
<a href="/search/cs?searchtype=author&query=Lohse%2C+N">Niels Lohse</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+K">Kerstin Eder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Effective communication between humans and collaborative robots is essential
for seamless Human-Robot Collaboration (HRC). In noisy industrial settings,
nonverbal communication, such as gestures, plays a key role in conveying
commands and information to robots efficiently. While existing literature has
thoroughly examined gesture recognition and robots' responses to these
gestures, there is a notable gap in exploring the design of these gestures. The
criteria for creating efficient HRC gestures are scattered across numerous
studies. This paper surveys the design principles of HRC gestures, as contained
in the literature, aiming to consolidate a set of criteria for HRC gesture
design. It also examines the methods used for designing and evaluating HRC
gestures to highlight research gaps and present directions for future research
in this area.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19059" title="Abstract">arXiv:2402.19059</a> [<a href="/pdf/2402.19059" title="Download PDF">pdf</a>, <a href="/format/2402.19059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VEnvision3D: A Synthetic Perception Dataset for 3D Multi-Task Model  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiahao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Chen Long</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yue Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Developing a unified multi-task foundation model has become a critical
challenge in computer vision research. In the current field of 3D computer
vision, most datasets solely focus on a relatively limited set of tasks, which
complicates the concurrent training requirements of various downstream tasks.
This makes the training of multi-objective networks difficult to proceed with,
which further hinders the development of foundation models in the 3D vision
field. In this paper, we introduce VEnvision3D, a large 3D synthetic perception
dataset for multi-task learning, including depth completion, segmentation,
upsampling, place recognition, and 3D reconstruction. Since the data for each
task was collected in the same scenarios, tasks are inherently aligned in terms
of the utilized data. Therefore, such a unique attribute can assist in
exploring the potential for the multi-task model and even the foundation model
without separate training methods. Several new benchmarks based on the
characteristics of the proposed dataset were presented. Extensive studies were
performed on end-to-end models, revealing new observations, challenges, and
opportunities for future research. In addition, we designed a straightfoward
multi-task network to uncover the ability that VEnvision3D can offer for the
foundation model. Our dataset and code will be open-sourced upon acceptance.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19061" title="Abstract">arXiv:2402.19061</a> [<a href="/pdf/2402.19061" title="Download PDF">pdf</a>, <a href="/format/2402.19061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal ANN-SNN Conversion with Group Neurons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+L">Liuzhenghao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+W">Wei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have emerged as a promising third generation
of neural networks, offering unique characteristics such as binary outputs,
high sparsity, and biological plausibility. However, the lack of effective
learning algorithms remains a challenge for SNNs. For instance, while
converting artificial neural networks (ANNs) to SNNs circumvents the need for
direct training of SNNs, it encounters issues related to conversion errors and
high inference time delays. In order to reduce or even eliminate conversion
errors while decreasing inference time-steps, we have introduced a novel type
of neuron called Group Neurons (GNs). One GN is composed of multiple
Integrate-and-Fire (IF) neurons as members, and its neural dynamics are
meticulously designed. Based on GNs, we have optimized the traditional ANN-SNN
conversion framework. Specifically, we replace the IF neurons in the SNNs
obtained by the traditional conversion framework with GNs. The resulting SNNs,
which utilize GNs, are capable of achieving accuracy levels comparable to ANNs
even within extremely short inference time-steps. The experiments on CIFAR10,
CIFAR100, and ImageNet datasets demonstrate the superiority of the proposed
methods in terms of both inference accuracy and latency. Code is available at
https://github.com/Lyu6PosHao/ANN2SNN_GN.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19064" title="Abstract">arXiv:2402.19064</a> [<a href="/pdf/2402.19064" title="Download PDF">pdf</a>, <a href="/format/2402.19064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Influence of Color Stimuli on Adolescents&#x27; Emotion Playing Mobile  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kallabis%2C+L">Leonie Kallabis</a>, 
<a href="/search/cs?searchtype=author&query=Baruque-Zan%C3%B3n%2C+B">Bruno Baruque-Zan&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Klocke%2C+H">Heinrich Klocke</a>, 
<a href="/search/cs?searchtype=author&query=Lara-Palma%2C+A+M">Ana Mar&#xed;a Lara-Palma</a>, 
<a href="/search/cs?searchtype=author&query=Naujoks%2C+B">Boris Naujoks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Video games elicit emotions which can be influenced by color stimuli as shown
by previous studies. However, little research has been conducted on whether
this applies to mobile games played by adolescents. Therefore, we examined the
influence of color stimuli hue and saturation on mobile game play. Adolescents
(n=21) played a mobile platformer game with varying hue and saturation per
level for about 25 minutes. We gathered data on emotional states after each
level using the Self-Assessment Manikin questionnaire, recorded time spent in
each level, and collected participant self-reports on their video game
experience. We performed statistical tests, such as ANOVA, which depict no
significant influence of hue and/or saturation on the emotional state of our
players. We conclude that it is possible that color alone is not an effective
measure for eliciting emotion in mobile games, and further research is needed
to consider measures such as time spent in the game and screen size, as these
are unique to mobile games. There was a noticeable variance in emotional
response between male and female players, with a significant interaction of hue
and saturation among male players for valence ratings. This may be an
indication that color preference influences perceived pleasantness.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19071" title="Abstract">arXiv:2402.19071</a> [<a href="/pdf/2402.19071" title="Download PDF">pdf</a>, <a href="/format/2402.19071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FATE in MMLA: A Student-Centred Exploration of Fairness, Accountability,  Transparency, and Ethics in Multimodal Learning Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yueqiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Echeverria%2C+V">Vanessa Echeverria</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lixiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Linxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Alfredo%2C+R">Riordan Alfredo</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Shan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Maldonado%2C+R">Roberto Martinez-Maldonado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Multimodal Learning Analytics (MMLA) integrates novel sensing technologies
and artificial intelligence algorithms, providing opportunities to enhance
student reflection during complex, collaborative learning experiences. Although
recent advancements in MMLA have shown its capability to generate insights into
diverse learning behaviours across various learning settings, little research
has been conducted to evaluate these systems in authentic learning contexts,
particularly regarding students' perceived fairness, accountability,
transparency, and ethics (FATE). Understanding these perceptions is essential
to using MMLA effectively without introducing ethical complications or
negatively affecting how students learn. This study aimed to address this gap
by assessing the FATE of MMLA in an authentic, collaborative learning context.
We conducted semi-structured interviews with 14 undergraduate students who used
MMLA visualisations for post-activity reflection. The findings highlighted the
significance of accurate and comprehensive data representation to ensure
visualisation fairness, the need for different levels of data access to foster
accountability, the imperative of measuring and cultivating transparency with
students, and the necessity of transforming informed consent from dichotomous
to continuous and measurable scales. While students value the benefits of MMLA,
they also emphasise the importance of ethical considerations, highlighting a
pressing need for the LA and MMLA community to investigate and address FATE
issues actively.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19072" title="Abstract">arXiv:2402.19072</a> [<a href="/pdf/2402.19072" title="Download PDF">pdf</a>, <a href="/format/2402.19072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeXer: Empowering Transformers for Time Series Forecasting with  Exogenous Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haixu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jiaxiang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yunzhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianmin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+M">Mingsheng Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent studies have demonstrated remarkable performance in time series
forecasting. However, due to the partially-observed nature of real-world
applications, solely focusing on the target of interest, so-called endogenous
variables, is usually insufficient to guarantee accurate forecasting. Notably,
a system is often recorded into multiple variables, where the exogenous series
can provide valuable external information for endogenous variables. Thus,
unlike prior well-established multivariate or univariate forecasting that
either treats all the variables equally or overlooks exogenous information,
this paper focuses on a practical setting, which is time series forecasting
with exogenous variables. We propose a novel framework, TimeXer, to utilize
external information to enhance the forecasting of endogenous variables. With a
deftly designed embedding layer, TimeXer empowers the canonical Transformer
architecture with the ability to reconcile endogenous and exogenous
information, where patch-wise self-attention and variate-wise cross-attention
are employed. Moreover, a global endogenous variate token is adopted to
effectively bridge the exogenous series into endogenous temporal patches.
Experimentally, TimeXer significantly improves time series forecasting with
exogenous variables and achieves consistent state-of-the-art performance in
twelve real-world forecasting benchmarks.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19076" title="Abstract">arXiv:2402.19076</a> [<a href="/pdf/2402.19076" title="Download PDF">pdf</a>, <a href="/format/2402.19076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pointing out the Shortcomings of Relation Extraction Models with  Semantically Motivated Adversarials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nolano%2C+G">Gennaro Nolano</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+M">Moritz Blum</a>, 
<a href="/search/cs?searchtype=author&query=Ell%2C+B">Basil Ell</a>, 
<a href="/search/cs?searchtype=author&query=Cimiano%2C+P">Philipp Cimiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, large language models have achieved state-of-the-art
performance across various NLP tasks. However, investigations have shown that
these models tend to rely on shortcut features, leading to inaccurate
predictions and causing the models to be unreliable at generalization to
out-of-distribution (OOD) samples. For instance, in the context of relation
extraction (RE), we would expect a model to identify the same relation
independently of the entities involved in it. For example, consider the
sentence "Leonardo da Vinci painted the Mona Lisa" expressing the
created(Leonardo_da_Vinci, Mona_Lisa) relation. If we substiute "Leonardo da
Vinci" with "Barack Obama", then the sentence still expresses the created
relation. A robust model is supposed to detect the same relation in both cases.
In this work, we describe several semantically-motivated strategies to generate
adversarial examples by replacing entity mentions and investigate how
state-of-the-art RE models perform under pressure. Our analyses show that the
performance of these models significantly deteriorates on the modified datasets
(avg. of -48.5% in F1), which indicates that these models rely to a great
extent on shortcuts, such as surface forms (or patterns therein) of entities,
without making full use of the information present in the sentences.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19078" title="Abstract">arXiv:2402.19078</a> [<a href="/pdf/2402.19078" title="Download PDF">pdf</a>, <a href="/format/2402.19078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth Tchebycheff Scalarization for Multi-Objective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingfu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
<p class="mathjax">Multi-objective optimization problems can be found in many real-world
applications, where the objectives often conflict each other and cannot be
optimized by a single solution. In the past few decades, numerous methods have
been proposed to find Pareto solutions that represent different optimal
trade-offs among the objectives for a given problem. However, these existing
methods could have high computational complexity or may not have good
theoretical properties for solving a general differentiable multi-objective
optimization problem. In this work, by leveraging the smooth optimization
technique, we propose a novel and lightweight smooth Tchebycheff scalarization
approach for gradient-based multi-objective optimization. It has good
theoretical properties for finding all Pareto solutions with valid trade-off
preferences, while enjoying significantly lower computational complexity
compared to other methods. Experimental results on various real-world
application problems fully demonstrate the effectiveness of our proposed
method.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19080" title="Abstract">arXiv:2402.19080</a> [<a href="/pdf/2402.19080" title="Download PDF">pdf</a>, <a href="/format/2402.19080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMDRAM: An End-to-End Processing-Using-DRAM System for High-Throughput,  Energy-Efficient and Programmer-Transparent Multiple-Instruction  Multiple-Data Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fl%C4%B1k%C3%A7%C4%B1%2C+A+G">Abdullah Giray Ya&#x11f;l&#x131;k&#xe7;&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Bostanc%C4%B1%2C+F+N">F. Nisa Bostanc&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Luna%2C+J">Juan G&#xf3;mez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Ghose%2C+S">Saugata Ghose</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2109.05881">arXiv:2109.05881</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Processing-using-DRAM (PUD) is a processing-in-memory (PIM) approach that
uses a DRAM array's massive internal parallelism to execute very-wide
data-parallel operations, in a single-instruction multiple-data (SIMD) fashion.
However, DRAM rows' large and rigid granularity limit the effectiveness and
applicability of PUD in three ways. First, since applications have varying
degrees of SIMD parallelism, PUD execution often leads to underutilization,
throughput loss, and energy waste. Second, most PUD architectures are limited
to the execution of parallel map operations. Third, the need to feed the wide
DRAM row with tens of thousands of data elements combined with the lack of
adequate compiler support for PUD systems create a programmability barrier.
<br />Our goal is to design a flexible PUD system that overcomes the limitations
caused by the large and rigid granularity of PUD. To this end, we propose
MIMDRAM, a hardware/software co-designed PUD system that introduces new
mechanisms to allocate and control only the necessary resources for a given PUD
operation. The key idea of MIMDRAM is to leverage fine-grained DRAM (i.e., the
ability to independently access smaller segments of a large DRAM row) for PUD
computation. MIMDRAM exploits this key idea to enable a multiple-instruction
multiple-data (MIMD) execution model in each DRAM subarray.
<br />We evaluate MIMDRAM using twelve real-world applications and 495
multi-programmed application mixes. Our evaluation shows that MIMDRAM provides
34x the performance, 14.3x the energy efficiency, 1.7x the throughput, and 1.3x
the fairness of a state-of-the-art PUD framework, along with 30.6x and 6.8x the
energy efficiency of a high-end CPU and GPU, respectively. MIMDRAM adds small
area cost to a DRAM chip (1.11%) and CPU die (0.6%).
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19082" title="Abstract">arXiv:2402.19082</a> [<a href="/pdf/2402.19082" title="Download PDF">pdf</a>, <a href="/format/2402.19082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoMAC: Video Masked Autoencoders Meet ConvNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+G">Gensheng Pei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiruo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huafeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeren Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yazhou Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the advancement of self-supervised learning techniques, like masked
autoencoders (MAE), has greatly influenced visual representation learning for
images and videos. Nevertheless, it is worth noting that the predominant
approaches in existing masked image / video modeling rely excessively on
resource-intensive vision transformers (ViTs) as the feature encoder. In this
paper, we propose a new approach termed as \textbf{VideoMAC}, which combines
video masked autoencoders with resource-friendly ConvNets. Specifically,
VideoMAC employs symmetric masking on randomly sampled pairs of video frames.
To prevent the issue of mask pattern dissipation, we utilize ConvNets which are
implemented with sparse convolutional operators as encoders. Simultaneously, we
present a simple yet effective masked video modeling (MVM) approach, a dual
encoder architecture comprising an online encoder and an exponential moving
average target encoder, aimed to facilitate inter-frame reconstruction
consistency in videos. Additionally, we demonstrate that VideoMAC, empowering
classical (ResNet) / modern (ConvNeXt) convolutional encoders to harness the
benefits of MVM, outperforms ViT-based approaches on downstream tasks,
including video object segmentation (+\textbf{5.2\%} / \textbf{6.4\%}
$\mathcal{J}\&amp;\mathcal{F}$), body part propagation (+\textbf{6.3\%} /
\textbf{3.1\%} mIoU), and human pose tracking (+\textbf{10.2\%} /
\textbf{11.1\%} PCK@0.1).
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19085" title="Abstract">arXiv:2402.19085</a> [<a href="/pdf/2402.19085" title="Download PDF">pdf</a>, <a href="/format/2402.19085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Preference Optimization: Toward Controllable  Multi-Objective Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiju Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Ganqu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lifan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiexin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bowen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Systems and Control (eess.SY)

</div>
<p class="mathjax">Alignment in artificial intelligence pursues the consistency between model
responses and human preferences as well as values. In practice, the
multifaceted nature of human preferences inadvertently introduces what is known
as the "alignment tax" -a compromise where enhancements in alignment within one
objective (e.g.,harmlessness) can diminish performance in others
(e.g.,helpfulness). However, existing alignment techniques are mostly
unidirectional, leading to suboptimal trade-offs and poor flexibility over
various objectives. To navigate this challenge, we argue the prominence of
grounding LLMs with evident preferences. We introduce controllable preference
optimization (CPO), which explicitly specifies preference scores for different
objectives, thereby guiding the model to generate responses that meet the
requirements. Our experimental analysis reveals that the aligned models can
provide responses that match various preferences among the "3H" (helpfulness,
honesty, harmlessness) desiderata. Furthermore, by introducing diverse data and
alignment goals, we surpass baseline methods in aligning with single
objectives, hence mitigating the impact of the alignment tax and achieving
Pareto improvements in multi-objective alignment.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19088" title="Abstract">arXiv:2402.19088</a> [<a href="/pdf/2402.19088" title="Download PDF">pdf</a>, <a href="/format/2402.19088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey in Characterization of Semantic Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+S%C3%A1%2C+J+M+C">Jader Martins Camboim de S&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Da+Silveira%2C+M">Marcos Da Silveira</a>, 
<a href="/search/cs?searchtype=author&query=Pruski%2C+C">C&#xe9;dric Pruski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Live languages continuously evolve to integrate the cultural change of human
societies. This evolution manifests through neologisms (new words) or
\textbf{semantic changes} of words (new meaning to existing words).
Understanding the meaning of words is vital for interpreting texts coming from
different cultures (regionalism or slang), domains (e.g., technical terms), or
periods. In computer science, these words are relevant to computational
linguistics algorithms such as translation, information retrieval, question
answering, etc. Semantic changes can potentially impact the quality of the
outcomes of these algorithms. Therefore, it is important to understand and
characterize these changes formally. The study of this impact is a recent
problem that has attracted the attention of the computational linguistics
community. Several approaches propose methods to detect semantic changes with
good precision, but more effort is needed to characterize how the meaning of
words changes and to reason about how to reduce the impact of semantic change.
This survey provides an understandable overview of existing approaches to the
\textit{characterization of semantic changes} and also formally defines three
classes of characterizations: if the meaning of a word becomes more general or
narrow (change in dimension) if the word is used in a more pejorative or
positive/ameliorated sense (change in orientation), and if there is a trend to
use the word in a, for instance, metaphoric or metonymic context (change in
relation). We summarized the main aspects of the selected publications in a
table and discussed the needs and trends in the research activities on semantic
change characterization.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19089" title="Abstract">arXiv:2402.19089</a> [<a href="/pdf/2402.19089" title="Download PDF">pdf</a>, <a href="/ps/2402.19089" title="Download PostScript">ps</a>, <a href="/format/2402.19089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Around Don&#x27;s conjecture for binary completely reachable automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yinfeng Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">A word $w$ is called a reaching word of a subset $S$ of states in a
deterministic finite automaton (DFA) if $S$ is the image of $Q$ under the
action of $w$. A DFA is called completely reachable if every non-empty subset
of the state set has a reaching word. A conjecture states that in every
$n$-state completely reachable DFA, for every $k$-element subset of states,
there exists a reaching word of length at most $n(n-k)$. We present infinitely
many completely reachable DFAs with two letters that violate this conjecture. A
subfamily of completely reachable DFAs with two letters, is called standardized
DFAs, introduced by Casas and Volkov (2023). We prove that every $k$-element
subset of states in an $n$-state standardized DFA has a reaching word of length
$\le n(n-k) + n - 1$. Finally, we confirm the conjecture for standardized DFAs
with additional properties, thus generalizing a result of Casas and Volkov
(2023).
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19090" title="Abstract">arXiv:2402.19090</a> [<a href="/pdf/2402.19090" title="Download PDF">pdf</a>, <a href="/ps/2402.19090" title="Download PostScript">ps</a>, <a href="/format/2402.19090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best Arm Identification with Resource Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zitian Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+W+C">Wang Chi Cheung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Motivated by the cost heterogeneity in experimentation across different
alternatives, we study the Best Arm Identification with Resource Constraints
(BAIwRC) problem. The agent aims to identify the best arm under resource
constraints, where resources are consumed for each arm pull. We make two novel
contributions. We design and analyze the Successive Halving with Resource
Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic
rate of convergence in terms of the probability of successively identifying an
optimal arm. Interestingly, we identify a difference in convergence rates
between the cases of deterministic and stochastic resource consumption.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19091" title="Abstract">arXiv:2402.19091</a> [<a href="/pdf/2402.19091" title="Download PDF">pdf</a>, <a href="/format/2402.19091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Representations from Intermediate Encoder-blocks for  Synthetic Image Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koutlis%2C+C">Christos Koutlis</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+S">Symeon Papadopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recently developed and publicly available synthetic image generation
methods and services make it possible to create extremely realistic imagery on
demand, raising great risks for the integrity and safety of online information.
State-of-the-art Synthetic Image Detection (SID) research has led to strong
evidence on the advantages of feature extraction from foundation models.
However, such extracted features mostly encapsulate high-level visual semantics
instead of fine-grained details, which are more important for the SID task. On
the contrary, shallow layers encode low-level visual information. In this work,
we leverage the image representations extracted by intermediate Transformer
blocks of CLIP's image-encoder via a lightweight network that maps them to a
learnable forgery-aware vector space capable of generalizing exceptionally
well. We also employ a trainable module to incorporate the importance of each
Transformer block to the final prediction. Our method is compared against the
state-of-the-art by evaluating it on 20 test datasets and exhibits an average
+10.6% absolute performance improvement. Notably, the best performing models
require just a single epoch for training (~8 minutes). Code available at
https://github.com/mever-team/rine.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19097" title="Abstract">arXiv:2402.19097</a> [<a href="/pdf/2402.19097" title="Download PDF">pdf</a>, <a href="/format/2402.19097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEncDM: Understanding the Properties of Diffusion Model in the Space of  Language Model Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shabalin%2C+A">Alexander Shabalin</a>, 
<a href="/search/cs?searchtype=author&query=Meshchaninov%2C+V">Viacheslav Meshchaninov</a>, 
<a href="/search/cs?searchtype=author&query=Badmaev%2C+T">Tingir Badmaev</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+D">Dmitry Molchanov</a>, 
<a href="/search/cs?searchtype=author&query=Bartosh%2C+G">Grigory Bartosh</a>, 
<a href="/search/cs?searchtype=author&query=Markov%2C+S">Sergey Markov</a>, 
<a href="/search/cs?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, submitted to ACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Drawing inspiration from the success of diffusion models in various domains,
numerous research papers proposed methods for adapting them to text data.
Despite these efforts, none of them has managed to achieve the quality of the
large language models. In this paper, we conduct a comprehensive analysis of
key components of the text diffusion models and introduce a novel approach
named Text Encoding Diffusion Model (TEncDM). Instead of the commonly used
token embedding space, we train our model in the space of the language model
encodings. Additionally, we propose to use a Transformer-based decoder that
utilizes contextual information for text reconstruction. We also analyse
self-conditioning and find that it increases the magnitude of the model
outputs, allowing the reduction of the number of denoising steps at the
inference stage. Evaluation of TEncDM on two downstream text generation tasks,
QQP and XSum, demonstrates its superiority over existing non-autoregressive
models.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19101" title="Abstract">arXiv:2402.19101</a> [<a href="/pdf/2402.19101" title="Download PDF">pdf</a>, <a href="/format/2402.19101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Two-Stage Knowledge Transfer for Multi-Entity Cross-Domain  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jianyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zongming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Leihui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jufeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuguang Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, the recommendation content on e-commerce platforms has
become increasingly rich -- a single user feed may contain multiple entities,
such as selling products, short videos, and content posts. To deal with the
multi-entity recommendation problem, an intuitive solution is to adopt the
shared-network-based architecture for joint training. The idea is to transfer
the extracted knowledge from one type of entity (source entity) to another
(target entity). However, different from the conventional same-entity
cross-domain recommendation, multi-entity knowledge transfer encounters several
important issues: (1) data distributions of the source entity and target entity
are naturally different, making the shared-network-based joint training
susceptible to the negative transfer issue, (2) more importantly, the
corresponding feature schema of each entity is not exactly aligned (e.g., price
is an essential feature for selling product while missing for content posts),
making the existing methods no longer appropriate. Recent researchers have also
experimented with the pre-training and fine-tuning paradigm. Again, they only
consider the scenarios with the same entity type and feature systems, which is
inappropriate in our case. To this end, we design a pre-training &amp; fine-tuning
based Multi-entity Knowledge Transfer framework called MKT. MKT utilizes a
multi-entity pre-training module to extract transferable knowledge across
different entities. In particular, a feature alignment module is first applied
to scale and align different feature schemas. Afterward, a couple of knowledge
extractors are employed to extract the common and entity-specific knowledge. In
the end, the extracted common knowledge is adopted for target entity model
training. Through extensive offline and online experiments, we demonstrated the
superiority of MKT over multiple State-Of-The-Art methods.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19102" title="Abstract">arXiv:2402.19102</a> [<a href="/pdf/2402.19102" title="Download PDF">pdf</a>, <a href="/format/2402.19102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlatNAS: optimizing Flatness in Neural Architecture Search for  Out-of-Distribution Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gambella%2C+M">Matteo Gambella</a>, 
<a href="/search/cs?searchtype=author&query=Pittorino%2C+F">Fabrizio Pittorino</a>, 
<a href="/search/cs?searchtype=author&query=Roveri%2C+M">Manuel Roveri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural Architecture Search (NAS) paves the way for the automatic definition
of Neural Network (NN) architectures, attracting increasing research attention
and offering solutions in various scenarios. This study introduces a novel NAS
solution, called Flat Neural Architecture Search (FlatNAS), which explores the
interplay between a novel figure of merit based on robustness to weight
perturbations and single NN optimization with Sharpness-Aware Minimization
(SAM). FlatNAS is the first work in the literature to systematically explore
flat regions in the loss landscape of NNs in a NAS procedure, while jointly
optimizing their performance on in-distribution data, their out-of-distribution
(OOD) robustness, and constraining the number of parameters in their
architecture. Differently from current studies primarily concentrating on OOD
algorithms, FlatNAS successfully evaluates the impact of NN architectures on
OOD robustness, a crucial aspect in real-world applications of machine and deep
learning. FlatNAS achieves a good trade-off between performance, OOD
generalization, and the number of parameters, by using only in-distribution
data in the NAS exploration. The OOD robustness of the NAS-designed models is
evaluated by focusing on robustness to input data corruptions, using popular
benchmark datasets in the literature.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19103" title="Abstract">arXiv:2402.19103</a> [<a href="/pdf/2402.19103" title="Download PDF">pdf</a>, <a href="/format/2402.19103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whispers that Shake Foundations: Analyzing and Mitigating False Premise  Hallucinations in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hongbang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pengfei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhuoran Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Daojian Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown impressive capabilities but still
suffer from the issue of hallucinations. A significant type of this issue is
the false premise hallucination, which we define as the phenomenon when LLMs
generate hallucinated text when confronted with false premise questions. In
this paper, we perform a comprehensive analysis of the false premise
hallucination and elucidate its internal working mechanism: a small subset of
attention heads (which we designate as false premise heads) disturb the
knowledge extraction process, leading to the occurrence of false premise
hallucination. Based on our analysis, we propose \textbf{FAITH} (\textbf{F}alse
premise \textbf{A}ttention head constra\textbf{I}ining for mi\textbf{T}igating
\textbf{H}allucinations), a novel and effective method to mitigate false
premise hallucinations. It constrains the false premise attention heads during
the model inference process. Impressively, extensive experiments demonstrate
that constraining only approximately $1\%$ of the attention heads in the model
yields a notable increase of nearly $20\%$ of model performance.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19105" title="Abstract">arXiv:2402.19105</a> [<a href="/pdf/2402.19105" title="Download PDF">pdf</a>, <a href="/format/2402.19105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CollaFuse: Navigating Limited Resources and Privacy in Collaborative  Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zipperling%2C+D">Domenique Zipperling</a>, 
<a href="/search/cs?searchtype=author&query=Allmendinger%2C+S">Simeon Allmendinger</a>, 
<a href="/search/cs?searchtype=author&query=Struppek%2C+L">Lukas Struppek</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-Second European Conference on Information Systems (ECIS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the landscape of generative artificial intelligence, diffusion-based
models present challenges for socio-technical systems in data requirements and
privacy. Traditional approaches like federated learning distribute the learning
process but strain individual clients, especially with constrained resources
(e.g., edge devices). In response to these challenges, we introduce CollaFuse,
a novel framework inspired by split learning. Tailored for efficient and
collaborative use of denoising diffusion probabilistic models, CollaFuse
enables shared server training and inference, alleviating client computational
burdens. This is achieved by retaining data and computationally inexpensive GPU
processes locally at each client while outsourcing the computationally
expensive processes to the shared server. Demonstrated in a healthcare context,
CollaFuse enhances privacy by highly reducing the need for sensitive
information sharing. These capabilities hold the potential to impact various
application areas, such as the design of edge computing solutions, healthcare
research, or autonomous driving. In essence, our work advances distributed
machine learning, shaping the future of collaborative GenAI networks.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19107" title="Abstract">arXiv:2402.19107</a> [<a href="/pdf/2402.19107" title="Download PDF">pdf</a>, <a href="/ps/2402.19107" title="Download PostScript">ps</a>, <a href="/format/2402.19107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rahmani Sort: A Novel Variant of Insertion Sort Algorithm with O(nlogn)  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+M+K+I">Mohammad Khalid Imam Rahmani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> None
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Various decision support systems are available that implement Data Mining and
Data Warehousing techniques for diving into the sea of data for getting useful
patterns of knowledge (pearls). Classification, regression, clustering, and
many other algorithms are used to enhance the precision and accuracy of the
decision process. So, there is scope for increasing the response time of the
decision process, especially in mission-critical operations. If data are
ordered with suitable and efficient sorting operation, the response time of the
decision process can be minimized. Insertion sort is much more suitable for
such applications due to its simple and straight logic along with its dynamic
nature suitable for list implementation. But it is slower than merge sort and
quick sort. The main reasons this is slow: firstly, a sequential search is used
to find the actual position of the next key element into the sorted left
subarray and secondly, shifting of elements is required by one position towards
the right for accommodating the newly inserted element. Therefore, I propose a
new algorithm by using a novel technique of binary search mechanism for finding
the sorted location of the next key item into the previously sorted left
subarray much quicker than the conventional insertion sort algorithm.
Performance measurement in terms of the actual running time of the new
algorithm has been compared with those of other conventional sorting algorithms
apart from the insertion sort. The results obtained on various sample data show
that the new algorithm is better in performance than the conventional insertion
sort and merge sort algorithms.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19108" title="Abstract">arXiv:2402.19108</a> [<a href="/pdf/2402.19108" title="Download PDF">pdf</a>, <a href="/format/2402.19108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepEraser: Deep Iterative Context Mining for Generic Text Eraser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wendi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaokai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiajun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present DeepEraser, an effective deep network for generic
text removal. DeepEraser utilizes a recurrent architecture that erases the text
in an image via iterative operations. Our idea comes from the process of
erasing pencil script, where the text area designated for removal is subject to
continuous monitoring and the text is attenuated progressively, ensuring a
thorough and clean erasure. Technically, at each iteration, an innovative
erasing module is deployed, which not only explicitly aggregates the previous
erasing progress but also mines additional semantic context to erase the target
text. Through iterative refinements, the text regions are progressively
replaced with more appropriate content and finally converge to a relatively
accurate status. Furthermore, a custom mask generation strategy is introduced
to improve the capability of DeepEraser for adaptive text removal, as opposed
to indiscriminately removing all the text in an image. Our DeepEraser is
notably compact with only 1.4M parameters and trained in an end-to-end manner.
To verify its effectiveness, extensive experiments are conducted on several
prevalent benchmarks, including SCUT-Syn, SCUT-EnsText, and Oxford Synthetic
text dataset. The quantitative and qualitative results demonstrate the
effectiveness of our DeepEraser over the state-of-the-art methods, as well as
its strong generalization ability in custom mask text removal. The codes and
pre-trained models are available at https://github.com/fh2019ustc/DeepEraser
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19110" title="Abstract">arXiv:2402.19110</a> [<a href="/pdf/2402.19110" title="Download PDF">pdf</a>, <a href="/format/2402.19110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal-Aware Deep Reinforcement Learning for Energy Storage Bidding in  Energy and Contingency Reserve Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinhao Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changlong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yanru Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Energy Markets, Policy and Regulation, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">The battery energy storage system (BESS) has immense potential for enhancing
grid reliability and security through its participation in the electricity
market. BESS often seeks various revenue streams by taking part in multiple
markets to unlock its full potential, but effective algorithms for joint-market
participation under price uncertainties are insufficiently explored in the
existing research. To bridge this gap, we develop a novel BESS joint bidding
strategy that utilizes deep reinforcement learning (DRL) to bid in the spot and
contingency frequency control ancillary services (FCAS) markets. Our approach
leverages a transformer-based temporal feature extractor to effectively respond
to price fluctuations in seven markets simultaneously and helps DRL learn the
best BESS bidding strategy in joint-market participation. Additionally, unlike
conventional "black-box" DRL model, our approach is more interpretable and
provides valuable insights into the temporal bidding behavior of BESS in the
dynamic electricity market. We validate our method using realistic market
prices from the Australian National Electricity Market. The results show that
our strategy outperforms benchmarks, including both optimization-based and
other DRL-based strategies, by substantial margins. Our findings further
suggest that effective temporal-aware bidding can significantly increase
profits in the spot and contingency FCAS markets compared to individual market
participation.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19116" title="Abstract">arXiv:2402.19116</a> [<a href="/pdf/2402.19116" title="Download PDF">pdf</a>, <a href="/format/2402.19116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Understand &quot;Support&quot;? An Implicit-enhanced Causal Inference  Approach for Weakly-supervised Phrase Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiamin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guodong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the
fine-grained phrase-region matching, while merely leveraging the coarse-grained
sentence-image pairs for training. However, existing studies on WPG largely
ignore the implicit phrase-region matching relations, which are crucial for
evaluating the capability of models in understanding the deep multimodal
semantics. To this end, this paper proposes an Implicit-Enhanced Causal
Inference (IECI) approach to address the challenges of modeling the implicit
relations and highlighting them beyond the explicit. Specifically, this
approach leverages both the intervention and counterfactual techniques to
tackle the above two challenges respectively. Furthermore, a high-quality
implicit-enhanced dataset is annotated to evaluate IECI and detailed
evaluations show the great advantages of IECI over the state-of-the-art
baselines. Particularly, we observe an interesting finding that IECI
outperforms the advanced multimodal LLMs by a large margin on this
implicit-enhanced dataset, which may facilitate more research to evaluate the
multimodal LLMs in this direction.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19118" title="Abstract">arXiv:2402.19118</a> [<a href="/pdf/2402.19118" title="Download PDF">pdf</a>, <a href="/format/2402.19118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Sign Language Recognition Based on Motor attention mechanism  and frame-level Self-distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qidan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Q">Quan Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Changes in facial expression, head movement, body movement and gesture
movement are remarkable cues in sign language recognition, and most of the
current continuous sign language recognition(CSLR) research methods mainly
focus on static images in video sequences at the frame-level feature extraction
stage, while ignoring the dynamic changes in the images. In this paper, we
propose a novel motor attention mechanism to capture the distorted changes in
local motion regions during sign language expression, and obtain a dynamic
representation of image changes. And for the first time, we apply the
self-distillation method to frame-level feature extraction for continuous sign
language, which improves the feature expression without increasing the
computational resources by self-distilling the features of adjacent stages and
using the higher-order features as teachers to guide the lower-order features.
The combination of the two constitutes our proposed holistic model of CSLR
Based on motor attention mechanism and frame-level Self-Distillation (MAM-FSD),
which improves the inference ability and robustness of the model. We conduct
experiments on three publicly available datasets, and the experimental results
show that our proposed method can effectively extract the sign language motion
information in videos, improve the accuracy of CSLR and reach the
state-of-the-art level.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19119" title="Abstract">arXiv:2402.19119</a> [<a href="/pdf/2402.19119" title="Download PDF">pdf</a>, <a href="/format/2402.19119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIXEN: Visual Text Comparison Network for Image Difference Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Black%2C+A">Alexander Black</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fai%2C+Y">Yifei Fai</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+T">Tu Bui</a>, 
<a href="/search/cs?searchtype=author&query=Collomosse%2C+J">John Collomosse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We present VIXEN - a technique that succinctly summarizes in text the visual
differences between a pair of images in order to highlight any content
manipulation present. Our proposed network linearly maps image features in a
pairwise manner, constructing a soft prompt for a pretrained large language
model. We address the challenge of low volume of training data and lack of
manipulation variety in existing image difference captioning (IDC) datasets by
training on synthetically manipulated images from the recent InstructPix2Pix
dataset generated via prompt-to-prompt editing framework. We augment this
dataset with change summaries produced via GPT-3. We show that VIXEN produces
state-of-the-art, comprehensible difference captions for diverse image contents
and edit types, offering a potential mitigation against misinformation
disseminated via manipulated image content. Code and data are available at
<a href="http://github.com/alexblck/vixen">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19120" title="Abstract">arXiv:2402.19120</a> [<a href="/pdf/2402.19120" title="Download PDF">pdf</a>, <a href="/ps/2402.19120" title="Download PostScript">ps</a>, <a href="/format/2402.19120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Naive Approach for Automatic Line-level Code Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naznin%2C+S">Shamima Naznin</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+D+M">Dr.Manishankar Mondal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Coding is an integral aspect of programming. A programmer can automatically
complete a code fragment after writing a few tokens, and the process of
automatic completion is known as code completion. Several research studies on
code completion have previously been conducted for method body completion and
method parameter completion. However, this fundamental study explores the
automatic completion of any program statement that might not even be part of a
method.
<br />The goal is to provide suggestions to the programmer for completing code
throughout the codebase by identifying and analyzing code similarities. The
proposed methodology can be regarded as a fundamental framework for automated
code completion. From the investigation of hundreds of revisions of four
subject systems written in C and Java, it is observed that the proposed method
can automatically complete around 22% of code statements with an average
accuracy of 87% that a programmer writes during development, accelerating
software development time. The empirical analysis further demonstrates that the
approach can be used with programming language neutrality.
<br />The study concludes by illustrating that taking 10 characters as prefixes
before invoking completion provides maximum precision.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19122" title="Abstract">arXiv:2402.19122</a> [<a href="/pdf/2402.19122" title="Download PDF">pdf</a>, <a href="/format/2402.19122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BigGait: Learning Gait Representation You Want by Large Vision Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dingqiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jingzhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait recognition stands as one of the most pivotal remote identification
technologies and progressively expands across research and industrial
communities. However, existing gait recognition methods heavily rely on
task-specific upstream driven by supervised learning to provide explicit gait
representations, which inevitably introduce expensive annotation costs and
potentially cause cumulative errors. Escaping from this trend, this work
explores effective gait representations based on the all-purpose knowledge
produced by task-agnostic Large Vision Models (LVMs) and proposes a simple yet
efficient gait framework, termed BigGait. Specifically, the Gait Representation
Extractor (GRE) in BigGait effectively transforms all-purpose knowledge into
implicit gait features in an unsupervised manner, drawing from design
principles of established gait representation construction approaches.
Experimental results on CCPG, CAISA-B* and SUSTech1K indicate that BigGait
significantly outperforms the previous methods in both self-domain and
cross-domain tasks in most cases, and provides a more practical paradigm for
learning the next-generation gait representation. Eventually, we delve into
prospective challenges and promising directions in LVMs-based gait recognition,
aiming to inspire future work in this emerging topic. The source code will be
available at https://github.com/ShiqiYu/OpenGait.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19125" title="Abstract">arXiv:2402.19125</a> [<a href="/pdf/2402.19125" title="Download PDF">pdf</a>, <a href="/format/2402.19125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highly efficient Gauss&#x27;s law-preserving spectral algorithms for  Maxwell&#x27;s double-curl source and eigenvalue problems based on  eigen-decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+S">Sen Lin</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huiyuan Li</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Z">Zhiguo Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present Gauss's law-preserving spectral methods and their
efficient solution algorithms for curl-curl source and eigenvalue problems in
two and three dimensions arising from Maxwell's equations. Arbitrary order
$H(curl)$-conforming spectral basis functions in two and three dimensions are
firstly proposed using compact combination of Legendre polynomials. A mixed
formulation involving a Lagrange multiplier is then adopted to preserve the
Gauss's law in the weak sense. To overcome the bottleneck of computational
efficiency caused by the saddle-point nature of the mixed scheme, we present
highly efficient solution algorithms based on reordering and decoupling of the
resultant linear algebraic system and numerical eigen-decomposition of one
dimensional mass matrix. The proposed solution algorithms are direct methods
requiring only several matrix-matrix or matrix-tensor products of $N$-by-$N$
matrices, where $N$ is the highest polynomial order in each direction. Compared
with other direct methods, the computational complexities are reduced from
$O(N^6)$ and $O(N^9)$ to $O(N^3)$ and $O(N^4)$ with small and constant
pre-factors for 2D and 3D cases, respectively, and can further be accelerated
to $O(N^{2.807})$ and $O(N^{3.807})$, when boosted with the Strassen's matrix
multiplication algorithm. Moreover, these algorithms strictly obey the
Helmholtz-Hodge decomposition, thus totally eliminate the spurious eigen-modes
of non-physical zero eigenvalues. Extensions of the proposed methods and
algorithms to problems in complex geometries with variable coefficients and
inhomogeneous boundary conditions are discussed to deal with more general
situations. Ample numerical examples for solving Maxwell's source and
eigenvalue problems are presented to demonstrate the accuracy and efficiency of
the proposed methods.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19128" title="Abstract">arXiv:2402.19128</a> [<a href="/pdf/2402.19128" title="Download PDF">pdf</a>, <a href="/format/2402.19128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARMCHAIR: integrated inverse reinforcement learning and model predictive  control for human-robot collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caregnato-Neto%2C+A">Angelo Caregnato-Neto</a>, 
<a href="/search/cs?searchtype=author&query=Siebert%2C+L+C">Luciano Cavalcante Siebert</a>, 
<a href="/search/cs?searchtype=author&query=Zgonnikov%2C+A">Arkady Zgonnikov</a>, 
<a href="/search/cs?searchtype=author&query=de+Albuquerque+Maximo%2C+M+R+O">Marcos Ricardo Omena de Albuquerque Maximo</a>, 
<a href="/search/cs?searchtype=author&query=Afonso%2C+R+J+M">Rubens Junqueira Magalh&#xe3;es Afonso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">One of the key issues in human-robot collaboration is the development of
computational models that allow robots to predict and adapt to human behavior.
Much progress has been achieved in developing such models, as well as control
techniques that address the autonomy problems of motion planning and
decision-making in robotics. However, the integration of computational models
of human behavior with such control techniques still poses a major challenge,
resulting in a bottleneck for efficient collaborative human-robot teams. In
this context, we present a novel architecture for human-robot collaboration:
Adaptive Robot Motion for Collaboration with Humans using Adversarial Inverse
Reinforcement learning (ARMCHAIR). Our solution leverages adversarial inverse
reinforcement learning and model predictive control to compute optimal
trajectories and decisions for a mobile multi-robot system that collaborates
with a human in an exploration task. During the mission, ARMCHAIR operates
without human intervention, autonomously identifying the necessity to support
and acting accordingly. Our approach also explicitly addresses the network
connectivity requirement of the human-robot team. Extensive simulation-based
evaluations demonstrate that ARMCHAIR allows a group of robots to safely
support a simulated human in an exploration scenario, preventing collisions and
network disconnections, and improving the overall performance of the task.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19132" title="Abstract">arXiv:2402.19132</a> [<a href="/pdf/2402.19132" title="Download PDF">pdf</a>, <a href="/ps/2402.19132" title="Download PostScript">ps</a>, <a href="/format/2402.19132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted least $\ell_p$ approximation on compact Riemannian manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiansong Li</a>, 
<a href="/search/math?searchtype=author&query=Ling%2C+Y">Yun Ling</a>, 
<a href="/search/math?searchtype=author&query=Geng%2C+J">Jiaxin Geng</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Heping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Given a sequence of Marcinkiewicz-Zygmund inequalities in $L_2$ on a compact
space, Gr\"ochenig in \cite{G} discussed weighted least squares approximation
and least squares quadrature. Inspired by this work, for all $1\le p\le\infty$,
we develop weighted least $\ell_p$ approximation induced by a sequence of
Marcinkiewicz-Zygmund inequalities in $L_p$ on a compact smooth Riemannian
manifold $\Bbb M$ with normalized Riemannian measure (typical examples are the
torus and the sphere). In this paper we derive corresponding approximation
theorems with the error measured in $L_q,\,1\le q\le\infty$, and least
quadrature errors for both Sobolev spaces $H_p^r(\Bbb M), \, r&gt;d/p$ generated
by eigenfunctions associated with the Laplace-Beltrami operator and Besov
spaces $B_{p,\tau}^r(\Bbb M),\, 0&lt;\tau\le \infty, r&gt;d/p $ defined by best
polynomial approximation. Finally, we discuss the optimality of the obtained
results by giving sharp estimates of sampling numbers and optimal quadrature
errors for the aforementioned spaces.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19133" title="Abstract">arXiv:2402.19133</a> [<a href="/pdf/2402.19133" title="Download PDF">pdf</a>, <a href="/format/2402.19133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Webcam-based Gaze Data as an Alternative for Human Rationale  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brandl%2C+S">Stephanie Brandl</a>, 
<a href="/search/cs?searchtype=author&query=Eberle%2C+O">Oliver Eberle</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+T">Tiago Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B8gaard%2C+A">Anders S&#xf8;gaard</a>, 
<a href="/search/cs?searchtype=author&query=Hollenstein%2C+N">Nora Hollenstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Rationales in the form of manually annotated input spans usually serve as
ground truth when evaluating explainability methods in NLP. They are, however,
time-consuming and often biased by the annotation process. In this paper, we
debate whether human gaze, in the form of webcam-based eye-tracking recordings,
poses a valid alternative when evaluating importance scores. We evaluate the
additional information provided by gaze data, such as total reading times, gaze
entropy, and decoding accuracy with respect to human rationale annotations. We
compare WebQAmGaze, a multilingual dataset for information-seeking QA, with
attention and explainability-based importance scores for 4 different
multilingual Transformer-based language models (mBERT, distil-mBERT, XLMR, and
XLMR-L) and 3 languages (English, Spanish, and German). Our pipeline can easily
be applied to other tasks and languages. Our findings suggest that gaze data
offers valuable linguistic insights that could be leveraged to infer task
difficulty and further show a comparable ranking of explainability methods to
that of human rationales.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19135" title="Abstract">arXiv:2402.19135</a> [<a href="/pdf/2402.19135" title="Download PDF">pdf</a>, <a href="/ps/2402.19135" title="Download PostScript">ps</a>, <a href="/format/2402.19135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think Fast, Think Slow, Think Critical: Designing an Automated  Propaganda Detection Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zavolokina%2C+L">Liudmila Zavolokina</a>, 
<a href="/search/cs?searchtype=author&query=Sprenkamp%2C+K">Kilian Sprenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Katashinskaya%2C+Z">Zoya Katashinskaya</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+D+G">Daniel Gordon Jones</a>, 
<a href="/search/cs?searchtype=author&query=Schwabe%2C+G">Gerhard Schwabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted for publication in proceedings of the CHI Conference on Human Factors in Computing Systems (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In today's digital age, characterized by rapid news consumption and
increasing vulnerability to propaganda, fostering citizens' critical thinking
is crucial for stable democracies. This paper introduces the design of
ClarifAI, a novel automated propaganda detection tool designed to nudge readers
towards more critical news consumption by activating the analytical mode of
thinking, following Kahneman's dual-system theory of cognition. Using Large
Language Models, ClarifAI detects propaganda in news articles and provides
context-rich explanations, enhancing users' understanding and critical
thinking. Our contribution is threefold: first, we propose the design of
ClarifAI; second, in an online experiment, we demonstrate that this design
effectively encourages news readers to engage in more critical reading; and
third, we emphasize the value of explanations for fostering critical thinking.
The study thus offers both a practical tool and useful design knowledge for
mitigating propaganda in digital news.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19142" title="Abstract">arXiv:2402.19142</a> [<a href="/pdf/2402.19142" title="Download PDF">pdf</a>, <a href="/format/2402.19142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoP-OD: Explainable Object Detection with Prototypical Parts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rath-Manakidis%2C+P">Pavlos Rath-Manakidis</a>, 
<a href="/search/cs?searchtype=author&query=Strothmann%2C+F">Frederik Strothmann</a>, 
<a href="/search/cs?searchtype=author&query=Glasmachers%2C+T">Tobias Glasmachers</a>, 
<a href="/search/cs?searchtype=author&query=Wiskott%2C+L">Laurenz Wiskott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Interpretation and visualization of the behavior of detection transformers
tends to highlight the locations in the image that the model attends to, but it
provides limited insight into the \emph{semantics} that the model is focusing
on. This paper introduces an extension to detection transformers that
constructs prototypical local features and uses them in object detection. These
custom features, which we call prototypical parts, are designed to be mutually
exclusive and align with the classifications of the model. The proposed
extension consists of a bottleneck module, the prototype neck, that computes a
discretized representation of prototype activations and a new loss term that
matches prototypes to object classes. This setup leads to interpretable
representations in the prototype neck, allowing visual inspection of the image
content perceived by the model and a better understanding of the model's
reliability. We show experimentally that our method incurs only a limited
performance penalty, and we provide examples that demonstrate the quality of
the explanations provided by our method, which we argue outweighs the
performance penalty.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19144" title="Abstract">arXiv:2402.19144</a> [<a href="/pdf/2402.19144" title="Download PDF">pdf</a>, <a href="/format/2402.19144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Monocular 3D Detection with a Single-View Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xueying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoqin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular 3D detection (M3D) aims for precise 3D object localization from a
single-view image which usually involves labor-intensive annotation of 3D
detection boxes. Weakly supervised M3D has recently been studied to obviate the
3D annotation process by leveraging many existing 2D annotations, but it often
requires extra training data such as LiDAR point clouds or multi-view images
which greatly degrades its applicability and usability in various applications.
We propose SKD-WM3D, a weakly supervised monocular 3D detection framework that
exploits depth information to achieve M3D with a single-view image exclusively
without any 3D annotations or other training data. One key design in SKD-WM3D
is a self-knowledge distillation framework, which transforms image features
into 3D-like representations by fusing depth information and effectively
mitigates the inherent depth ambiguity in monocular scenarios with little
computational overhead in inference. In addition, we design an
uncertainty-aware distillation loss and a gradient-targeted transfer modulation
strategy which facilitate knowledge acquisition and knowledge transfer,
respectively. Extensive experiments show that SKD-WM3D surpasses the
state-of-the-art clearly and is even on par with many fully supervised methods.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19145" title="Abstract">arXiv:2402.19145</a> [<a href="/pdf/2402.19145" title="Download PDF">pdf</a>, <a href="/format/2402.19145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A SAM-guided Two-stream Lightweight Model for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In industrial anomaly detection, model efficiency and mobile-friendliness
become the primary concerns in real-world applications. Simultaneously, the
impressive generalization capabilities of Segment Anything (SAM) have garnered
broad academic attention, making it an ideal choice for localizing unseen
anomalies and diverse real-world patterns. In this paper, considering these two
critical factors, we propose a SAM-guided Two-stream Lightweight Model for
unsupervised anomaly detection (STLM) that not only aligns with the two
practical application requirements but also harnesses the robust generalization
capabilities of SAM. We employ two lightweight image encoders, i.e., our
two-stream lightweight module, guided by SAM's knowledge. To be specific, one
stream is trained to generate discriminative and general feature
representations in both normal and anomalous regions, while the other stream
reconstructs the same images without anomalies, which effectively enhances the
differentiation of two-stream representations when facing anomalous regions.
Furthermore, we employ a shared mask decoder and a feature aggregation module
to generate anomaly maps. Our experiments conducted on MVTec AD benchmark show
that STLM, with about 16M parameters and achieving an inference time in 20ms,
competes effectively with state-of-the-art methods in terms of performance,
98.26% on pixel-level AUC and 94.92% on PRO. We further experiment on more
difficult datasets, e.g., VisA and DAGM, to demonstrate the effectiveness and
generalizability of STLM.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19146" title="Abstract">arXiv:2402.19146</a> [<a href="/pdf/2402.19146" title="Download PDF">pdf</a>, <a href="/format/2402.19146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Longest Common Subsequence under Cartesian-Tree Matching Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsujimoto%2C+T">Taketo Tsujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+K">Koki Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Mieno%2C+T">Takuya Mieno</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuto Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Inenaga%2C+S">Shunsuke Inenaga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Two strings of the same length are said to Cartesian-tree match (CT-match) if
their Cartesian-trees are isomorphic [Park et al., TCS 2020]. Cartesian-tree
matching is a natural model that allows for capturing similarities of numerical
sequences. Oizumi et al. [CPM 2022] showed that subsequence pattern matching
under CT-matching model can be solved in polynomial time. This current article
follows and extends this line of research: We present the first polynomial-time
algorithm that finds the longest common subsequence under CT-matching of two
given strings $S$ and $T$ of length $n$, in $O(n^6)$ time and $O(n^4)$ space
for general ordered alphabets. We then show that the problem has a faster
solution in the binary case, by presenting an $O(n^2 / \log n)$-time and space
algorithm.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19147" title="Abstract">arXiv:2402.19147</a> [<a href="/pdf/2402.19147" title="Download PDF">pdf</a>, <a href="/format/2402.19147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient quaternion CUR method for low-rank approximation to quaternion  matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wu%2C+P">Peng-Ling Wu</a>, 
<a href="/search/math?searchtype=author&query=Kou%2C+K+I">Kit Ian Kou</a>, 
<a href="/search/math?searchtype=author&query=Cai%2C+H">Hongmin Cai</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+Z">Zhaoyuan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The low-rank quaternion matrix approximation has been successfully applied in
many applications involving signal processing and color image processing.
However, the cost of quaternion models for generating low-rank quaternion
matrix approximation is sometimes considerable due to the computation of the
quaternion singular value decomposition (QSVD), which limits their application
to real large-scale data. To address this deficiency, an efficient quaternion
matrix CUR (QMCUR) method for low-rank approximation is suggested, which
provides significant acceleration in color image processing. We first explore
the QMCUR approximation method, which uses actual columns and rows of the given
quaternion matrix, instead of the costly QSVD. Additionally, two different
sampling strategies are used to sample the above-selected columns and rows.
Then, the perturbation analysis is performed on the QMCUR approximation of
noisy versions of low-rank quaternion matrices. Extensive experiments on both
synthetic and real data further reveal the superiority of the proposed
algorithm compared with other algorithms for getting low-rank approximation, in
terms of both efficiency and accuracy.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19150" title="Abstract">arXiv:2402.19150</a> [<a href="/pdf/2402.19150" title="Download PDF">pdf</a>, <a href="/format/2402.19150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typographic Attacks in Large Multimodal Models Can be Alleviated by More  Informative Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+E">Erjia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large Multimodal Models (LMMs) rely on pre-trained Vision Language Models
(VLMs) and Large Language Models (LLMs) to perform amazing emergent abilities
on various multimodal tasks in the joint space of vision and language. However,
the Typographic Attack, which shows disruption to VLMs, has also been certified
as a security vulnerability to LMMs. In this work, we first comprehensively
investigate the distractibility of LMMs by typography. In particular, we
introduce the Typographic Dataset designed to evaluate distractibility across
various multi-modal subtasks, such as object recognition, visual attributes
detection, enumeration, arithmetic computation, and commonsense reasoning. To
further study the effect of typographic patterns on performance, we also
scrutinize the effect of tuning various typographic factors, encompassing font
size, color, opacity, and spatial positioning of typos. We discover that LMMs
can partially distinguish visual contents and typos when confronting
typographic attacks, which suggests that embeddings from vision encoders
contain enough information to distinguish visual contents and typos in images.
Inspired by such phenomena, we demonstrate that CLIP's performance of zero-shot
classification on typo-ridden images can be significantly improved by providing
more informative texts to match images. Furthermore, we also prove that LMMs
can utilize more informative prompts to leverage information in embeddings to
differentiate between visual content and typos. Finally, we propose a prompt
information enhancement method that can effectively mitigate the effects of
typography.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19155" title="Abstract">arXiv:2402.19155</a> [<a href="/pdf/2402.19155" title="Download PDF">pdf</a>, <a href="/format/2402.19155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Language Models: Byte Models are Digital World Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangda Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobing Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traditional deep learning often overlooks bytes, the basic units of the
digital world, where all forms of information and operations are encoded and
manipulated in binary format. Inspired by the success of next token prediction
in natural language processing, we introduce bGPT, a model with next byte
prediction to simulate the digital world. bGPT matches specialized models in
performance across various modalities, including text, audio, and images, and
offers new possibilities for predicting, simulating, and diagnosing algorithm
or hardware behaviour. It has almost flawlessly replicated the process of
converting symbolic music data, achieving a low error rate of 0.0011 bits per
byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates
exceptional capabilities in simulating CPU behaviour, with an accuracy
exceeding 99.99% in executing various operations. Leveraging next byte
prediction, models like bGPT can directly learn from vast binary data,
effectively simulating the intricate patterns of the digital world.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19159" title="Abstract">arXiv:2402.19159</a> [<a href="/pdf/2402.19159" title="Download PDF">pdf</a>, <a href="/format/2402.19159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Consistency Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jianbin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Minghui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhongyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Changxing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cham%2C+T">Tat-Jen Cham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://mhh0318.github.io/tcd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Latent Consistency Model (LCM) extends the Consistency Model to the latent
space and leverages the guided consistency distillation technique to achieve
impressive performance in accelerating text-to-image synthesis. However, we
observed that LCM struggles to generate images with both clarity and detailed
intricacy. To address this limitation, we initially delve into and elucidate
the underlying causes. Our investigation identifies that the primary issue
stems from errors in three distinct areas. Consequently, we introduce
Trajectory Consistency Distillation (TCD), which encompasses trajectory
consistency function and strategic stochastic sampling. The trajectory
consistency function diminishes the distillation errors by broadening the scope
of the self-consistency boundary condition and endowing the TCD with the
ability to accurately trace the entire trajectory of the Probability Flow ODE.
Additionally, strategic stochastic sampling is specifically designed to
circumvent the accumulated errors inherent in multi-step consistency sampling,
which is meticulously tailored to complement the TCD model. Experiments
demonstrate that TCD not only significantly enhances image quality at low NFEs
but also yields more detailed results compared to the teacher model at high
NFEs.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19160" title="Abstract">arXiv:2402.19160</a> [<a href="/pdf/2402.19160" title="Download PDF">pdf</a>, <a href="/format/2402.19160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Message Hiding with Order-Preserving Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xuchong%2C+Q">Qiu Xuchong</a>, 
<a href="/search/cs?searchtype=author&query=Zihan%2C+Y">Ye Zihan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Message hiding, a technique that conceals secret message bits within a cover
image, aims to achieve an optimal balance among message capacity, recovery
accuracy, and imperceptibility. While convolutional neural networks have
notably improved message capacity and imperceptibility, achieving high recovery
accuracy remains challenging. This challenge arises because convolutional
operations struggle to preserve the sequential order of message bits and
effectively address the discrepancy between these two modalities. To address
this, we propose StegaFormer, an innovative MLP-based framework designed to
preserve bit order and enable global fusion between modalities. Specifically,
StegaFormer incorporates three crucial components: Order-Preserving Message
Encoder (OPME), Decoder (OPMD) and Global Message-Image Fusion (GMIF). OPME and
OPMD aim to preserve the order of message bits by segmenting the entire
sequence into equal-length segments and incorporating sequential information
during encoding and decoding. Meanwhile, GMIF employs a cross-modality fusion
mechanism to effectively fuse the features from the two uncorrelated
modalities. Experimental results on the COCO and DIV2K datasets demonstrate
that StegaFormer surpasses existing state-of-the-art methods in terms of
recovery accuracy, message capacity, and imperceptibility. We will make our
code publicly available.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19161" title="Abstract">arXiv:2402.19161</a> [<a href="/pdf/2402.19161" title="Download PDF">pdf</a>, <a href="/format/2402.19161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemoNav: Working Memory Model for Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Shuqi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Image-goal navigation is a challenging task that requires an agent to
navigate to a goal indicated by an image in unfamiliar environments. Existing
methods utilizing diverse scene memories suffer from inefficient exploration
since they use all historical observations for decision-making without
considering the goal-relevant fraction. To address this limitation, we present
MemoNav, a novel memory model for image-goal navigation, which utilizes a
working memory-inspired pipeline to improve navigation performance.
Specifically, we employ three types of navigation memory. The node features on
a map are stored in the short-term memory (STM), as these features are
dynamically updated. A forgetting module then retains the informative STM
fraction to increase efficiency. We also introduce long-term memory (LTM) to
learn global scene representations by progressively aggregating STM features.
Subsequently, a graph attention module encodes the retained STM and the LTM to
generate working memory (WM) which contains the scene features essential for
efficient navigation. The synergy among these three memory types boosts
navigation performance by enabling the agent to learn and leverage
goal-relevant scene features within a topological map. Our evaluation on
multi-goal tasks demonstrates that MemoNav significantly outperforms previous
methods across all difficulty levels in both Gibson and Matterport3D scenes.
Qualitative results further illustrate that MemoNav plans more efficient
routes.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19163" title="Abstract">arXiv:2402.19163</a> [<a href="/pdf/2402.19163" title="Download PDF">pdf</a>, <a href="/format/2402.19163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedStruct: Federated Decoupled Learning over Interconnected Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliakbari%2C+J">Javad Aliakbari</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96stman%2C+J">Johan &#xd6;stman</a>, 
<a href="/search/cs?searchtype=author&query=Amat%2C+A+G+i">Alexandre Graell i Amat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages plus 13 pages of appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We address the challenge of federated learning on graph-structured data
distributed across multiple clients. Specifically, we focus on the prevalent
scenario of interconnected subgraphs, where inter-connections between different
clients play a critical role. We present a novel framework for this scenario,
named FedStruct, that harnesses deep structural dependencies. To uphold
privacy, unlike existing methods, FedStruct eliminates the necessity of sharing
or generating sensitive node features or embeddings among clients. Instead, it
leverages explicit global graph structure information to capture inter-node
dependencies. We validate the effectiveness of FedStruct through experimental
results conducted on six datasets for semi-supervised node classification,
showcasing performance close to the centralized approach across various
scenarios, including different data partitioning methods, varying levels of
label availability, and number of clients.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19166" title="Abstract">arXiv:2402.19166</a> [<a href="/pdf/2402.19166" title="Download PDF">pdf</a>, <a href="/format/2402.19166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Language Models for Human-in-the-Loop Multi-Robot  Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hunt%2C+W">William Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+T">Toby Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Soorati%2C+M+D">Mohammad D. Soorati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the increasing prevalence and diversity of robots interacting in the
real world, there is need for flexible, on-the-fly planning and cooperation.
Large Language Models are starting to be explored in a multimodal setup for
communication, coordination, and planning in robotics. Existing approaches
generally use a single agent building a plan, or have multiple homogeneous
agents coordinating for a simple task. We present a decentralised, dialogical
approach in which a team of agents with different abilities plans solutions
through peer-to-peer and human-robot discussion. We suggest that argument-style
dialogues are an effective way to facilitate adaptive use of each agent's
abilities within a cooperative team. Two robots discuss how to solve a cleaning
problem set by a human, define roles, and agree on paths they each take. Each
step can be interrupted by a human advisor and agents check their plans with
the human. Agents then execute this plan in the real world, collecting rubbish
from people in each room. Our implementation uses text at every step,
maintaining transparency and effective human-multi-robot interaction.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19167" title="Abstract">arXiv:2402.19167</a> [<a href="/pdf/2402.19167" title="Download PDF">pdf</a>, <a href="/format/2402.19167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Large Language Models an Unseen Language on the Fly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiuheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yansong Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing large language models struggle to support numerous low-resource
languages, particularly the extremely low-resource ones where there is minimal
training data available for effective parameter updating. We thus investigate
whether LLMs can learn a new language on the fly solely through prompting. To
study this question, we collect a research suite for Zhuang, a language
supported by no LLMs currently. We introduce \textsc{DiPMT++}, a framework for
adapting LLMs to unseen languages by in-context learning. Using a dictionary
and only 5K parallel sentences, \textsc{DiPMT++} significantly enhances the
performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation and
achieves 32 BLEU for Zhuang-to-Chinese translation. Furthermore, we demonstrate
the practical utility of this framework in aiding humans to translate
completely unseen languages, which could contribute to the preservation of
linguistic diversity.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19168" title="Abstract">arXiv:2402.19168</a> [<a href="/pdf/2402.19168" title="Download PDF">pdf</a>, <a href="/format/2402.19168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disturbance Decoupling Problem for $n$-link chain pendulum on a cart  system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Das%2C+S">Sayar Das</a>, 
<a href="/search/eess?searchtype=author&query=Patil%2C+D">Deepak Patil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A disturbance decoupling problem for a $n$-link chain pendulum on a cart is
considered. A model of the cart developed in a coordinate-free framework and
the linearized equations of this system are considered from [1]. It is shown
that it is possible to design a suitable state feedback such that the angular
position or velocity of the $n^{th}$-link can always be decoupled from the
disturbance coming at the cart.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19170" title="Abstract">arXiv:2402.19170</a> [<a href="/pdf/2402.19170" title="Download PDF">pdf</a>, <a href="/ps/2402.19170" title="Download PostScript">ps</a>, <a href="/format/2402.19170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Legal Judgement Prediction in Romanian with Long Text Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masala%2C+M">Mihai Masala</a>, 
<a href="/search/cs?searchtype=author&query=Rebedea%2C+T">Traian Rebedea</a>, 
<a href="/search/cs?searchtype=author&query=Velicu%2C+H">Horia Velicu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years,the entire field of Natural Language Processing (NLP) has
enjoyed amazing novel results achieving almost human-like performance on a
variety of tasks. Legal NLP domain has also been part of this process, as it
has seen an impressive growth. However, general-purpose models are not readily
applicable for legal domain. Due to the nature of the domain (e.g. specialized
vocabulary, long documents) specific models and methods are often needed for
Legal NLP. In this work we investigate both specialized and general models for
predicting the final ruling of a legal case, task known as Legal Judgment
Prediction (LJP). We particularly focus on methods to extend to sequence length
of Transformer-based models to better understand the long documents present in
legal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating
from 2 sources with significantly different sizes and document lengths, show
that specialized models and handling long texts are critical for a good
performance.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19171" title="Abstract">arXiv:2402.19171</a> [<a href="/pdf/2402.19171" title="Download PDF">pdf</a>, <a href="/format/2402.19171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Assessing Spread in Sets of Software Architecture Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortellessa%2C+V">Vittorio Cortellessa</a>, 
<a href="/search/cs?searchtype=author&query=Diaz-Pace%2C+J+A">J. Andres Diaz-Pace</a>, 
<a href="/search/cs?searchtype=author&query=Di+Pompeo%2C+D">Daniele Di Pompeo</a>, 
<a href="/search/cs?searchtype=author&query=Tucci%2C+M">Michele Tucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17th European Conference on Software Architecture (ECSA 2023), 8 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> European Conference on Software Architecture 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Several approaches have recently used automated techniques to generate
architecture design alternatives by means of optimization techniques. These
approaches aim at improving an initial architecture with respect to quality
aspects, such as performance, reliability, or maintainability. In this context,
each optimization experiment usually produces a different set of architecture
alternatives that is characterized by specific settings. As a consequence, the
designer is left with the task of comparing such sets to identify the settings
that lead to better solution sets for the problem. To assess the quality of
solution sets, multi-objective optimization commonly relies on quality
indicators. Among these, the quality indicator for the maximum spread estimates
the diversity of the generated alternatives, providing a measure of how much of
the solution space has been explored. However, the maximum spread indicator is
computed only on the objective space and does not consider architectural
information (e.g., components structure, design decisions) from the
architectural space. In this paper, we propose a quality indicator for the
spread that assesses the diversity of alternatives by taking into account
architectural features. To compute the spread, we rely on a notion of distance
between alternatives according to the way they were generated during the
optimization. We demonstrate how our architectural quality indicator can be
applied to a dataset from the literature.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19173" title="Abstract">arXiv:2402.19173</a> [<a href="/pdf/2402.19173" title="Download PDF">pdf</a>, <a href="/format/2402.19173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StarCoder 2 and The Stack v2: The Next Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lozhkov%2C+A">Anton Lozhkov</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Raymond Li</a>, 
<a href="/search/cs?searchtype=author&query=Allal%2C+L+B">Loubna Ben Allal</a>, 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Lamy-Poirier%2C+J">Joel Lamy-Poirier</a>, 
<a href="/search/cs?searchtype=author&query=Tazi%2C+N">Nouamane Tazi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Ao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pykhtar%2C+D">Dmytro Pykhtar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Max Tian</a>, 
<a href="/search/cs?searchtype=author&query=Kocetkov%2C+D">Denis Kocetkov</a>, 
<a href="/search/cs?searchtype=author&query=Zucker%2C+A">Arthur Zucker</a>, 
<a href="/search/cs?searchtype=author&query=Belkada%2C+Y">Younes Belkada</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Abulkhanov%2C+D">Dmitry Abulkhanov</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+I">Indraneil Paul</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wen-Ding Li</a>, 
<a href="/search/cs?searchtype=author&query=Risdal%2C+M">Megan Risdal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Zheltonozhskii%2C+E">Evgenii Zheltonozhskii</a>, 
<a href="/search/cs?searchtype=author&query=Dade%2C+N+O+O">Nii Osae Osae Dade</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Krau%C3%9F%2C+L">Lucas Krau&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Naman Jain</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yixuan Su</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuanli He</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+M">Manan Dey</a>, 
<a href="/search/cs?searchtype=author&query=Abati%2C+E">Edoardo Abati</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yekun Chai</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Oblokulov%2C+M">Muhtasham Oblokulov</a>, 
<a href="/search/cs?searchtype=author&query=Akiki%2C+C">Christopher Akiki</a>, 
<a href="/search/cs?searchtype=author&query=Marone%2C+M">Marc Marone</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chenghao Mou</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+M">Mayank Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Alex Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Binyuan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+T">Tri Dao</a>, 
<a href="/search/cs?searchtype=author&query=Zebaze%2C+A">Armel Zebaze</a>, 
<a href="/search/cs?searchtype=author&query=Dehaene%2C+O">Olivier Dehaene</a>, 
<a href="/search/cs?searchtype=author&query=Patry%2C+N">Nicolas Patry</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Canwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Scholak%2C+T">Torsten Scholak</a>, 
<a href="/search/cs?searchtype=author&query=Paquet%2C+S">Sebastien Paquet</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+J">Jennifer Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Chapados%2C+N">Nicolas Chapados</a>,  et al. (10 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The BigCode project, an open-scientific collaboration focused on the
responsible development of Large Language Models for Code (Code LLMs),
introduces StarCoder2. In partnership with Software Heritage (SWH), we build
The Stack v2 on top of the digital commons of their source code archive.
Alongside the SWH repositories spanning 619 programming languages, we carefully
select other high-quality data sources, such as GitHub pull requests, Kaggle
notebooks, and code documentation. This results in a training set that is 4x
larger than the first StarCoder dataset. We train StarCoder2 models with 3B,
7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate
them on a comprehensive set of Code LLM benchmarks. We find that our small
model, StarCoder2-3B, outperforms other Code LLMs of similar size on most
benchmarks, and also outperforms StarCoderBase-15B. Our large model,
StarCoder2- 15B, significantly outperforms other models of comparable size. In
addition, it matches or outperforms CodeLlama-34B, a model more than twice its
size. Although DeepSeekCoder- 33B is the best-performing model at code
completion for high-resource languages, we find that StarCoder2-15B outperforms
it on math and code reasoning benchmarks, as well as several low-resource
languages. We make the model weights available under an OpenRAIL license and
ensure full transparency regarding the training data by releasing the SoftWare
Heritage persistent IDentifiers (SWHIDs) of the source code data.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19180" title="Abstract">arXiv:2402.19180</a> [<a href="/pdf/2402.19180" title="Download PDF">pdf</a>, <a href="/format/2402.19180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModZoo: A Large-Scale Study of Modded Android Apps and their Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saavedra%2C+L+A">Luis A. Saavedra</a> (1), 
<a href="/search/cs?searchtype=author&query=Dutta%2C+H+S">Hridoy S. Dutta</a> (1), 
<a href="/search/cs?searchtype=author&query=Beresford%2C+A+R">Alastair R. Beresford</a> (1), 
<a href="/search/cs?searchtype=author&query=Hutchings%2C+A">Alice Hutchings</a> (1) ((1) University of Cambridge)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Cryptography and Security (cs.CR); Software Engineering (cs.SE)

</div>
<p class="mathjax">We present the results of the first large-scale study into Android markets
that offer modified or modded apps: apps whose features and functionality have
been altered by a third-party. We analyse over 146k (thousand) apps obtained
from 13 of the most popular modded app markets. Around 90% of apps we collect
are altered in some way when compared to the official counterparts on Google
Play. Modifications include games cheats, such as infinite coins or lives;
mainstream apps with premium features provided for free; and apps with modified
advertising identifiers or excluded ads. We find the original app developers
lose significant potential revenue due to: the provision of paid for apps for
free (around 5% of the apps across all markets); the free availability of
premium features that require payment in the official app; and modified
advertising identifiers. While some modded apps have all trackers and ads
removed (3%), in general, the installation of these apps is significantly more
risky for the user than the official version: modded apps are ten times more
likely to be marked as malicious and often request additional permissions.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19184" title="Abstract">arXiv:2402.19184</a> [<a href="/pdf/2402.19184" title="Download PDF">pdf</a>, <a href="/format/2402.19184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Transfer Optimizations for Host-CPU and Accelerators in AXI4MLIR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haris%2C+J">Jude Haris</a>, 
<a href="/search/cs?searchtype=author&query=Agostini%2C+N+B">Nicolas Bohm Agostini</a>, 
<a href="/search/cs?searchtype=author&query=Tumeo%2C+A">Antonino Tumeo</a>, 
<a href="/search/cs?searchtype=author&query=Kaeli%2C+D">David Kaeli</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+J">Jos&#xe9; Cano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">As custom hardware accelerators become more prevalent, it becomes
increasingly important to automatically generate efficient host-driver code
that can fully leverage the capabilities of these accelerators. This approach
saves time and reduces the likelihood of errors that can occur during manual
implementation. AXI4MLIR extends the MLIR compiler framework to generate
host-driver code for custom accelerators for linear algebra problems. By
leveraging specific compiler optimizations, we can further increase accelerator
utilization.
<br />In this work we offer two key observations through a MatMul accelerator case
study. First, the accelerator's compute core utilization is less than 10%, and
second, the critical latency bottleneck is caused by copying data between the
heap and memory-mapped DMA buffers. We identify a set of missing host code
optimizations to improve the under-utilization and the latency bottleneck.
Therefore, we propose three key host-code data-movement-related optimizations,
extending AXI4MLIR. The optimizations provide DMA-based data allocation,
coalescing of DMA transfers, and pipelining of the accelerator's load, compute,
and store stages.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19186" title="Abstract">arXiv:2402.19186</a> [<a href="/pdf/2402.19186" title="Download PDF">pdf</a>, <a href="/format/2402.19186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling representations of retinal images with generative models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+S">Sarah M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+L+M">Lisa M. Koch</a>, 
<a href="/search/cs?searchtype=author&query=Lensch%2C+H+P+A">Hendrik P. A. Lensch</a>, 
<a href="/search/cs?searchtype=author&query=Berens%2C+P">Philipp Berens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Retinal fundus images play a crucial role in the early detection of eye
diseases and, using deep learning approaches, recent studies have even
demonstrated their potential for detecting cardiovascular risk factors and
neurological disorders. However, the impact of technical factors on these
images can pose challenges for reliable AI applications in ophthalmology. For
example, large fundus cohorts are often confounded by factors like camera type,
image quality or illumination level, bearing the risk of learning shortcuts
rather than the causal relationships behind the image generation process. Here,
we introduce a novel population model for retinal fundus images that
effectively disentangles patient attributes from camera effects, thus enabling
controllable and highly realistic image generation. To achieve this, we propose
a novel disentanglement loss based on distance correlation. Through qualitative
and quantitative analyses, we demonstrate the effectiveness of this novel loss
function in disentangling the learned subspaces. Our results show that our
model provides a new perspective on the complex relationship between patient
attributes and technical confounders in retinal fundus image generation.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19189" title="Abstract">arXiv:2402.19189</a> [<a href="/pdf/2402.19189" title="Download PDF">pdf</a>, <a href="/format/2402.19189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Link Recommendation to Augment Influence Diffusion with Provable  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaolong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TheWebConf'24; Corresponding author: Jing Tang
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Link recommendation systems in online social networks (OSNs), such as
Facebook's ``People You May Know'', Twitter's ``Who to Follow'', and
Instagram's ``Suggested Accounts'', facilitate the formation of new connections
among users. This paper addresses the challenge of link recommendation for the
purpose of social influence maximization. In particular, given a graph $G$ and
the seed set $S$, our objective is to select $k$ edges that connect seed nodes
and ordinary nodes to optimize the influence dissemination of the seed set.
This problem, referred to as influence maximization with augmentation (IMA),
has been proven to be NP-hard.
<br />In this paper, we propose an algorithm, namely \textsf{AIS}, consisting of an
efficient estimator for augmented influence estimation and an accelerated
sampling approach. \textsf{AIS} provides a
$(1-1/\mathrm{e}-\varepsilon)$-approximate solution with a high probability of
$1-\delta$, and runs in $O(k^2 (m+n) \log (n / \delta) / \varepsilon^2 + k
\left|E_{\mathcal{C}}\right|)$ time assuming that the influence of any
singleton node is smaller than that of the seed set. To the best of our
knowledge, this is the first algorithm that can be implemented on large graphs
containing millions of nodes while preserving strong theoretical guarantees. We
conduct extensive experiments to demonstrate the effectiveness and efficiency
of our proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19191" title="Abstract">arXiv:2402.19191</a> [<a href="/pdf/2402.19191" title="Download PDF">pdf</a>, <a href="/format/2402.19191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An asymptotic-preserving method for the three-temperature radiative  transfer model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+R">Ruo Li</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+W">Weiming Li</a>, 
<a href="/search/math?searchtype=author&query=Liang%2C+S">Shengtong Liang</a>, 
<a href="/search/math?searchtype=author&query=Shao%2C+Y">Yuehan Shao</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+M">Min Tang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yanli Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">We present an asymptotic-preserving (AP) numerical method for solving the
three-temperature radiative transfer model, which holds significant importance
in inertial confinement fusion. A carefully designedsplitting method is
developed that can provide a general framework of extending AP schemes for the
gray radiative transport equation to the more complex three-temperature
radiative transfer model. The proposed scheme captures two important limiting
models: the three-temperature radiation diffusion equation (3TRDE) when opacity
approaches infinity and the two-temperature limit when the ion-electron
coupling coefficient goes to infinity. We have rigorously demonstrated the AP
property and energy conservation characteristics of the proposed scheme and its
efficiency has been validated through a series of benchmark tests in the
numerical part.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19194" title="Abstract">arXiv:2402.19194</a> [<a href="/pdf/2402.19194" title="Download PDF">pdf</a>, <a href="/format/2402.19194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Expectations: An Observational Study of Programming and Cannabis  Intoxication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenxin He</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+M">Manasvi Parikh</a>, 
<a href="/search/cs?searchtype=author&query=Weimer%2C+W">Westley Weimer</a>, 
<a href="/search/cs?searchtype=author&query=Endres%2C+M">Madeline Endres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of the International Conference of Software Engineering (ICSE), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Anecdotal evidence of cannabis use by professional programmers abounds.
Recent studies have found that some professionals regularly use cannabis while
programming even for work-related tasks. However, accounts of the impacts of
cannabis on programming vary widely and are often contradictory. For example,
some programmers claim that it impairs their ability to generate correct
solutions while others claim it enhances creativity and focus. There remains a
need for an empirical understanding of the true impacts of cannabis on
programming. This paper presents the first controlled observational study of
the effects of cannabis on programming ability. Based on a within-subjects
design with over 70 participants, we find that at ecologically valid dosages,
cannabis significantly impairs programming performance. Programs implemented
while high contain more bugs and take longer to write (p &lt; 0.05), a small to
medium effect (0.22 &lt;= d &lt;= 0.44). We also did not find any evidence that high
programmers generate more divergent solutions. However, programmers can
accurately assess differences in their programming performance (r = 0.59), even
when under the influence of cannabis. We hope that this research will
facilitate evidence-based policies and help developers make informed decisions
regarding cannabis use while programming.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19195" title="Abstract">arXiv:2402.19195</a> [<a href="/pdf/2402.19195" title="Download PDF">pdf</a>, <a href="/format/2402.19195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negative Sampling in Knowledge Graph Representation Learning: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madushanka%2C+T">Tiroshan Madushanka</a>, 
<a href="/search/cs?searchtype=author&query=Ichise%2C+R">Ryutaro Ichise</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Knowledge graph representation learning (KGRL) or knowledge graph embedding
(KGE) plays a crucial role in AI applications for knowledge construction and
information exploration. These models aim to encode entities and relations
present in a knowledge graph into a lower-dimensional vector space. During the
training process of KGE models, using positive and negative samples becomes
essential for discrimination purposes. However, obtaining negative samples
directly from existing knowledge graphs poses a challenge, emphasizing the need
for effective generation techniques. The quality of these negative samples
greatly impacts the accuracy of the learned embeddings, making their generation
a critical aspect of KGRL. This comprehensive survey paper systematically
reviews various negative sampling (NS) methods and their contributions to the
success of KGRL. Their respective advantages and disadvantages are outlined by
categorizing existing NS methods into five distinct categories. Moreover, this
survey identifies open research questions that serve as potential directions
for future investigations. By offering a generalization and alignment of
fundamental NS concepts, this survey provides valuable insights for designing
effective NS methods in the context of KGRL and serves as a motivating force
for further advancements in the field.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19196" title="Abstract">arXiv:2402.19196</a> [<a href="/pdf/2402.19196" title="Download PDF">pdf</a>, <a href="/format/2402.19196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative models struggle with kirigami metamaterials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felsch%2C+G">Gerrit Felsch</a>, 
<a href="/search/cs?searchtype=author&query=Slesarenko%2C+V">Viacheslav Slesarenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci); Soft Condensed Matter (cond-mat.soft)

</div>
<p class="mathjax">Generative machine learning models have shown notable success in identifying
architectures for metamaterials - materials whose behavior is determined
primarily by their internal organization - that match specific target
properties. By examining kirigami metamaterials, in which dependencies between
cuts yield complex design restrictions, we demonstrate that this perceived
success in the employment of generative models for metamaterials might be akin
to survivorship bias. We assess the performance of the four most popular
generative models - the Variational Autoencoder (VAE), the Generative
Adversarial Network (GAN), the Wasserstein GAN (WGAN), and the Denoising
Diffusion Probabilistic Model (DDPM) - in generating kirigami structures.
Prohibiting cut intersections can prevent the identification of an appropriate
similarity measure for kirigami metamaterials, significantly impacting the
effectiveness of VAE and WGAN, which rely on the Euclidean distance - a metric
shown to be unsuitable for considered geometries. This imposes significant
limitations on employing modern generative models for the creation of diverse
metamaterials.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19197" title="Abstract">arXiv:2402.19197</a> [<a href="/pdf/2402.19197" title="Download PDF">pdf</a>, <a href="/format/2402.19197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine Structure-Aware Sampling: A New Sampling Training Scheme for  Pixel-Aligned Implicit Models in Single-View Human Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+Y">Kennard Yanting Chan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Foo%2C+C+S">Chuan Sheng Foo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Proceedings of the AAAI Conference on Artificial Intelligence, 2024 (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for
single-view clothed human reconstruction. These models need to be trained using
a sampling training scheme. Existing sampling training schemes either fail to
capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in
reconstructed meshes. To address these problems, we introduce Fine
Structured-Aware Sampling (FSS), a new sampling training scheme to train
pixel-aligned implicit models for single-view human reconstruction. FSS
resolves the aforementioned problems by proactively adapting to the thickness
and complexity of surfaces. In addition, unlike existing sampling training
schemes, FSS shows how normals of sample points can be capitalized in the
training process to improve results. Lastly, to further improve the training
process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit
models. It becomes computationally feasible to introduce this loss once a
slight reworking of the pixel-aligned implicit function framework is carried
out. Our results show that our methods significantly outperform SOTA methods
qualitatively and quantitatively. Our code is publicly available at
https://github.com/kcyt/FSS.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19199" title="Abstract">arXiv:2402.19199</a> [<a href="/pdf/2402.19199" title="Download PDF">pdf</a>, <a href="/ps/2402.19199" title="Download PostScript">ps</a>, <a href="/format/2402.19199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewriting and Inductive Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajdu%2C+M">M&#xe1;rton Hajdu</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>, 
<a href="/search/cs?searchtype=author&query=Rawson%2C+M">Michael Rawson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Rewriting techniques based on reduction orderings generate "just enough"
consequences to retain first-order completeness. This is ideal for
superposition-based first-order theorem proving, but for at least one approach
to inductive reasoning we show that we are missing crucial consequences. We
therefore extend the superposition calculus with rewriting-based techniques to
generate sufficient consequences for automating induction in saturation. When
applying our work within the unit-equational fragment, our experiments with the
theorem prover Vampire show significant improvements for inductive reasoning.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19200" title="Abstract">arXiv:2402.19200</a> [<a href="/pdf/2402.19200" title="Download PDF">pdf</a>, <a href="/format/2402.19200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRSA: Prompt Reverse Stealing Attacks against Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zonghui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Prompt, recognized as crucial intellectual property, enables large language
models (LLMs) to perform specific tasks without the need of fine-tuning,
underscoring their escalating importance. With the rise of prompt-based
services, such as prompt marketplaces and LLM applications, providers often
display prompts' capabilities through input-output examples to attract users.
However, this paradigm raises a pivotal security concern: does the exposure of
input-output pairs pose the risk of potential prompt leakage, infringing on the
intellectual property rights of the developers? To our knowledge, this problem
still has not been comprehensively explored yet. To remedy this gap, in this
paper, we perform the first in depth exploration and propose a novel attack
framework for reverse-stealing prompts against commercial LLMs, namely PRSA.
The main idea of PRSA is that by analyzing the critical features of the
input-output pairs, we mimic and gradually infer (steal) the target prompts. In
detail, PRSA mainly consists of two key phases: prompt mutation and prompt
pruning. In the mutation phase, we propose a prompt attention algorithm based
on differential feedback to capture these critical features for effectively
inferring the target prompts. In the prompt pruning phase, we identify and mask
the words dependent on specific inputs, enabling the prompts to accommodate
diverse inputs for generalization. Through extensive evaluation, we verify that
PRSA poses a severe threat in real world scenarios. We have reported these
findings to prompt service providers and actively collaborate with them to take
protective measures for prompt copyright.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19204" title="Abstract">arXiv:2402.19204</a> [<a href="/pdf/2402.19204" title="Download PDF">pdf</a>, <a href="/format/2402.19204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PeLLE: Encoder-based language models for Brazilian Portuguese based on  open data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Mello%2C+G+L">Guilherme Lamartine de Mello</a>, 
<a href="/search/cs?searchtype=author&query=Finger%2C+M">Marcelo Finger</a>, 
<a href="/search/cs?searchtype=author&query=Serras%2C+a+F">and Felipe Serras</a>, 
<a href="/search/cs?searchtype=author&query=de+Mello+Carpi%2C+M">Miguel de Mello Carpi</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+M+M">Marcos Menon Jose</a>, 
<a href="/search/cs?searchtype=author&query=Domingues%2C+P+H">Pedro Henrique Domingues</a>, 
<a href="/search/cs?searchtype=author&query=Cavalim%2C+P">Paulo Cavalim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper we present PeLLE, a family of large language models based on
the RoBERTa architecture, for Brazilian Portuguese, trained on curated, open
data from the Carolina corpus. Aiming at reproducible results, we describe
details of the pretraining of the models. We also evaluate PeLLE models against
a set of existing multilingual and PT-BR refined pretrained Transformer-based
LLM encoders, contrasting performance of large versus smaller-but-curated
pretrained models in several downstream tasks. We conclude that several tasks
perform better with larger models, but some tasks benefit from
smaller-but-curated data in its pretraining.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19218" title="Abstract">arXiv:2402.19218</a> [<a href="/pdf/2402.19218" title="Download PDF">pdf</a>, <a href="/format/2402.19218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Augmented Generative Adversarial Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raaijmakers%2C+S">Stephan Raaijmakers</a>, 
<a href="/search/cs?searchtype=author&query=Bakker%2C+R">Roos Bakker</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+A">Anita Cremers</a>, 
<a href="/search/cs?searchtype=author&query=de+Kleijn%2C+R">Roy de Kleijn</a>, 
<a href="/search/cs?searchtype=author&query=Kouwenhoven%2C+T">Tom Kouwenhoven</a>, 
<a href="/search/cs?searchtype=author&query=Verhoef%2C+T">Tessa Verhoef</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conversational AI systems that rely on Large Language Models, like
Transformers, have difficulty interweaving external data (like facts) with the
language they generate. Vanilla Transformer architectures are not designed for
answering factual questions with high accuracy. This paper investigates a
possible route for addressing this problem. We propose to extend the standard
Transformer architecture with an additional memory bank holding extra
information (such as facts drawn from a knowledge base), and an extra attention
layer for addressing this memory. We add this augmented memory to a Generative
Adversarial Network-inspired Transformer architecture. This setup allows for
implementing arbitrary felicity conditions on the generated language of the
Transformer. We first demonstrate how this machinery can be deployed for
handling factual questions in goal-oriented dialogues. Secondly, we demonstrate
that our approach can be useful for applications like {\it style adaptation} as
well: the adaptation of utterances according to certain stylistic (external)
constraints, like social properties of human interlocutors in dialogues.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19222" title="Abstract">arXiv:2402.19222</a> [<a href="/pdf/2402.19222" title="Download PDF">pdf</a>, <a href="/ps/2402.19222" title="Download PostScript">ps</a>, <a href="/format/2402.19222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Airport take-off and landing optimization through genetic algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pecker%2C+F+G">Fernando Guedan Pecker</a>, 
<a href="/search/cs?searchtype=author&query=Atencia%2C+C+R">Cristian Ramirez Atencia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted and accepted in Expert Systems
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems, e13565 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This research addresses the crucial issue of pollution from aircraft
operations, focusing on optimizing both gate allocation and runway scheduling
simultaneously, a novel approach not previously explored. The study presents an
innovative genetic algorithm-based method for minimizing pollution from fuel
combustion during aircraft take-off and landing at airports. This algorithm
uniquely integrates the optimization of both landing gates and take-off/landing
runways, considering the correlation between engine operation time and
pollutant levels. The approach employs advanced constraint handling techniques
to manage the intricate time and resource limitations inherent in airport
operations. Additionally, the study conducts a thorough sensitivity analysis of
the model, with a particular emphasis on the mutation factor and the type of
penalty function, to fine-tune the optimization process. This dual-focus
optimization strategy represents a significant advancement in reducing
environmental impact in the aviation sector, establishing a new standard for
comprehensive and efficient airport operation management.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19223" title="Abstract">arXiv:2402.19223</a> [<a href="/pdf/2402.19223" title="Download PDF">pdf</a>, <a href="/format/2402.19223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edit and Alphabet-Ordering Sensitivity of Lex-parse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuto Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6ppl%2C+D">Dominik K&#xf6;ppl</a>, 
<a href="/search/cs?searchtype=author&query=Funakoshi%2C+M">Mitsuru Funakoshi</a>, 
<a href="/search/cs?searchtype=author&query=Inenaga%2C+S">Shunsuke Inenaga</a>, 
<a href="/search/cs?searchtype=author&query=Bannai%2C+H">Hideo Bannai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We investigate the compression sensitivity [Akagi et al., 2023] of lex-parse
[Navarro et al., 2021] for two operations: (1) single character edit and (2)
modification of the alphabet ordering, and give tight upper and lower bounds
for both operations. For both lower bounds, we use the family of Fibonacci
words. For the bounds on edit operations, our analysis makes heavy use of
properties of the Lyndon factorization of Fibonacci words to characterize the
structure of lex-parse.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19226" title="Abstract">arXiv:2402.19226</a> [<a href="/pdf/2402.19226" title="Download PDF">pdf</a>, <a href="/format/2402.19226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Gender Fairness in Machine Learning-driven Personalized  Care for Chronic Pain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gajane%2C+P">Pratik Gajane</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+S">Sean Newman</a>, 
<a href="/search/cs?searchtype=author&query=Piette%2C+J+D">John D. Piette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This study investigates gender fairness in personalized pain care
recommendations using machine learning algorithms. Leveraging a contextual
bandits framework, personalized recommendations are formulated and evaluated
using LinUCB algorithm on a dataset comprising interactions with $164$ patients
across $10$ sessions each. Results indicate that while adjustments to algorithm
parameters influence the quality of pain care recommendations, this impact
remains consistent across genders. However, when certain patient information,
such as self-reported pain measurements, is absent, the quality of pain care
recommendations for women is notably inferior to that for men.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19229" title="Abstract">arXiv:2402.19229</a> [<a href="/pdf/2402.19229" title="Download PDF">pdf</a>, <a href="/format/2402.19229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAPTURE-24: A large dataset of wrist-worn activity tracker data  collected in the wild for human activity recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Shing Chan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+C">Catherine Tong</a>, 
<a href="/search/cs?searchtype=author&query=Acquah%2C+A">Aidan Acquah</a>, 
<a href="/search/cs?searchtype=author&query=Schonfeldt%2C+A">Abram Schonfeldt</a>, 
<a href="/search/cs?searchtype=author&query=Gershuny%2C+J">Jonathan Gershuny</a>, 
<a href="/search/cs?searchtype=author&query=Doherty%2C+A">Aiden Doherty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Existing activity tracker datasets for human activity recognition are
typically obtained by having participants perform predefined activities in an
enclosed environment under supervision. This results in small datasets with a
limited number of activities and heterogeneity, lacking the mixed and nuanced
movements normally found in free-living scenarios. As such, models trained on
laboratory-style datasets may not generalise out of sample. To address this
problem, we introduce a new dataset involving wrist-worn accelerometers,
wearable cameras, and sleep diaries, enabling data collection for over 24 hours
in a free-living setting. The result is CAPTURE-24, a large activity tracker
dataset collected in the wild from 151 participants, amounting to 3883 hours of
accelerometer data, of which 2562 hours are annotated. CAPTURE-24 is two to
three orders of magnitude larger than existing publicly available datasets,
which is critical to developing accurate human activity recognition models.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19231" title="Abstract">arXiv:2402.19231</a> [<a href="/pdf/2402.19231" title="Download PDF">pdf</a>, <a href="/format/2402.19231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CricaVPR: Cross-image Correlation-aware Representation Learning for  Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xiangyuan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongmei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Over the past decade, most methods in visual place recognition (VPR) have
used neural networks to produce feature representations. These networks
typically produce a global representation of a place image using only this
image itself and neglect the cross-image variations (e.g. viewpoint and
illumination), which limits their robustness in challenging scenes. In this
paper, we propose a robust global representation method with cross-image
correlation awareness for VPR, named CricaVPR. Our method uses the
self-attention mechanism to correlate multiple images within a batch. These
images can be taken in the same place with different conditions or viewpoints,
or even captured from different places. Therefore, our method can utilize the
cross-image variations as a cue to guide the representation learning, which
ensures more robust features are produced. To further facilitate the
robustness, we propose a multi-scale convolution-enhanced adaptation method to
adapt pre-trained visual foundation models to the VPR task, which introduces
the multi-scale local information to further enhance the cross-image
correlation-aware representation. Experimental results show that our method
outperforms state-of-the-art methods by a large margin with significantly less
training time. Our method achieves 94.5% R@1 on Pitts30k using 512-dim global
features. The code is released at https://github.com/Lu-Feng/CricaVPR.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19232" title="Abstract">arXiv:2402.19232</a> [<a href="/pdf/2402.19232" title="Download PDF">pdf</a>, <a href="/format/2402.19232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trained Random Forests Completely Reveal your Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferry%2C+J">Julien Ferry</a>, 
<a href="/search/cs?searchtype=author&query=Fukasawa%2C+R">Ricardo Fukasawa</a>, 
<a href="/search/cs?searchtype=author&query=Pascal%2C+T">Timoth&#xe9;e Pascal</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+T">Thibaut Vidal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We introduce an optimization-based reconstruction attack capable of
completely or near-completely reconstructing a dataset utilized for training a
random forest. Notably, our approach relies solely on information readily
available in commonly used libraries such as scikit-learn. To achieve this, we
formulate the reconstruction problem as a combinatorial problem under a maximum
likelihood objective. We demonstrate that this problem is NP-hard, though
solvable at scale using constraint programming -- an approach rooted in
constraint propagation and solution-domain reduction. Through an extensive
computational investigation, we demonstrate that random forests trained without
bootstrap aggregation but with feature randomization are susceptible to a
complete reconstruction. This holds true even with a small number of trees.
Even with bootstrap aggregation, the majority of the data can also be
reconstructed. These findings underscore a critical vulnerability inherent in
widely adopted ensemble methods, warranting attention and mitigation. Although
the potential for such reconstruction attacks has been discussed in privacy
research, our study provides clear empirical evidence of their practicability.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19233" title="Abstract">arXiv:2402.19233</a> [<a href="/pdf/2402.19233" title="Download PDF">pdf</a>, <a href="/format/2402.19233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shared lightweight autonomous vehicles for urban food deliveries: A  simulation study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cervi%C3%B1o%2C+A+G">Ainhoa Genua Cervi&#xf1;o</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+N+C">Naroa Coretti Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+E+L">Elaine Liu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Grignard%2C+A">Arnaud Grignard</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+K">Kent Larson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 25 including abstract, 16 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In recent years, the rapid growth of on-demand deliveries, especially in food
deliveries, has spurred the exploration of innovative mobility solutions. In
this context, lightweight autonomous vehicles have emerged as a potential
alternative. However, their fleet-level behavior remains largely unexplored. To
address this gap, we have developed an agent-based model and an environmental
impact study assessing the fleet performance of lightweight autonomous food
delivery vehicles. This model explores critical factors such as fleet sizing,
service level, operational strategies, and environmental impacts. We have
applied this model to a case study in Cambridge, MA, USA, where results
indicate that there could be environmental benefits in replacing traditional
car-based deliveries with shared lightweight autonomous vehicle fleets. Lastly,
we introduce an interactive platform that offers a user-friendly means of
comprehending the model's performance and potential trade-offs, which can help
inform decision-makers in the evolving landscape of food delivery innovation.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19237" title="Abstract">arXiv:2402.19237</a> [<a href="/pdf/2402.19237" title="Download PDF">pdf</a>, <a href="/ps/2402.19237" title="Download PostScript">ps</a>, <a href="/format/2402.19237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-based Interpretable Spatio-Temporal Graph Convolutional Network  for Human Motion Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medina%2C+E">Edgar Medina</a>, 
<a href="/search/cs?searchtype=author&query=Loh%2C+L">Leyong Loh</a>, 
<a href="/search/cs?searchtype=author&query=Gurung%2C+N">Namrata Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+K+H">Kyung Hun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+N">Niels Heller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human motion prediction is still an open problem extremely important for
autonomous driving and safety applications. Due to the complex spatiotemporal
relation of motion sequences, this remains a challenging problem not only for
movement prediction but also to perform a preliminary interpretation of the
joint connections. In this work, we present a Context-based Interpretable
Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D
human pose forecasting model based on GCNs that encompasses specific layers,
aiding model interpretability and providing information that might be useful
when analyzing motion distribution and body behavior. Our architecture extracts
meaningful information from pose sequences, aggregates displacements and
accelerations into the input model, and finally predicts the output
displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI
datasets demonstrate that CIST-GCN outperforms previous methods in human motion
prediction and robustness. Since the idea of enhancing interpretability for
motion prediction has its merits, we showcase experiments towards it and
provide preliminary evaluations of such insights here. available code:
https://github.com/QualityMinds/cistgcn
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19242" title="Abstract">arXiv:2402.19242</a> [<a href="/pdf/2402.19242" title="Download PDF">pdf</a>, <a href="/format/2402.19242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Derivative-enhanced Deep Operator Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Bridges%2C+N">Nolan Bridges</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Deep operator networks (DeepONets), a class of neural operators that learn
mappings between function spaces, have recently been developed as surrogate
models for parametric partial differential equations (PDEs). In this work we
propose a derivative-enhanced deep operator network (DE-DeepONet), which
leverages the derivative information to enhance the prediction accuracy, and
provide a more accurate approximation of the derivatives, especially when the
training data are limited. DE-DeepONet incorporates dimension reduction of
input into DeepONet and includes two types of derivative labels in the loss
function for training, that is, the directional derivatives of the output
function with respect to the input function and the gradient of the output
function with respect to the physical domain variables. We test DE-DeepONet on
three different equations with increasing complexity to demonstrate its
effectiveness compared to the vanilla DeepONet.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19248" title="Abstract">arXiv:2402.19248</a> [<a href="/pdf/2402.19248" title="Download PDF">pdf</a>, <a href="/format/2402.19248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question  Answering Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhikun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ruixue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaodong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenlian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">How to better evaluate the capabilities of Large Language Models (LLMs) is
the focal point and hot topic in current LLMs research. Previous work has noted
that due to the extremely high cost of iterative updates of LLMs, they are
often unable to answer the latest dynamic questions well. To promote the
improvement of Chinese LLMs' ability to answer dynamic questions, in this
paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing
question-answer pairs related to the latest news on the Chinese Internet. We
obtain high-quality data through a pipeline that combines humans and models,
and carefully classify the samples according to the frequency of answer changes
to facilitate a more fine-grained observation of LLMs' capabilities. We have
also evaluated and analyzed mainstream and advanced Chinese LLMs on CDQA.
Extensive experiments and valuable insights suggest that our proposed CDQA is
challenging and worthy of more further study. We believe that the benchmark we
provide will become the key data resource for improving LLMs' Chinese
question-answering ability in the future.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19249" title="Abstract">arXiv:2402.19249</a> [<a href="/pdf/2402.19249" title="Download PDF">pdf</a>, <a href="/format/2402.19249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirage: Cross-Embodiment Zero-Shot Policy Transfer with Cross-Painting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L+Y">Lawrence Yunliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+K">Kush Hari</a>, 
<a href="/search/cs?searchtype=author&query=Dharmarajan%2C+K">Karthik Dharmarajan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+K">Ken Goldberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://robot-mirage.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The ability to reuse collected data and transfer trained policies between
robots could alleviate the burden of additional data collection and training.
While existing approaches such as pretraining plus finetuning and co-training
show promise, they do not generalize to robots unseen in training. Focusing on
common robot arms with similar workspaces and 2-jaw grippers, we investigate
the feasibility of zero-shot transfer. Through simulation studies on 8
manipulation tasks, we find that state-based Cartesian control policies can
successfully zero-shot transfer to a target robot after accounting for forward
dynamics. To address robot visual disparities for vision-based policies, we
introduce Mirage, which uses "cross-painting"--masking out the unseen target
robot and inpainting the seen source robot--during execution in real time so
that it appears to the policy as if the trained source robot were performing
the task. Despite its simplicity, our extensive simulation and physical
experiments provide strong evidence that Mirage can successfully zero-shot
transfer between different robot arms and grippers with only minimal
performance degradation on a variety of manipulation tasks such as picking,
stacking, and assembly, significantly outperforming a generalist policy.
Project website: https://robot-mirage.github.io/
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19250" title="Abstract">arXiv:2402.19250</a> [<a href="/pdf/2402.19250" title="Download PDF">pdf</a>, <a href="/format/2402.19250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature boosting with efficient attention for scene parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vivek Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shailza Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Cuzzolin%2C+F">Fabio Cuzzolin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The complexity of scene parsing grows with the number of object and scene
classes, which is higher in unrestricted open scenes. The biggest challenge is
to model the spatial relation between scene elements while succeeding in
identifying objects at smaller scales. This paper presents a novel
feature-boosting network that gathers spatial context from multiple levels of
feature extraction and computes the attention weights for each level of
representation to generate the final class labels. A novel `channel attention
module' is designed to compute the attention weights, ensuring that features
from the relevant extraction stages are boosted while the others are
attenuated. The model also learns spatial context information at low resolution
to preserve the abstract spatial relationships among scene elements and reduce
computation cost. Spatial attention is subsequently concatenated into a final
feature set before applying feature boosting. Low-resolution spatial attention
features are trained using an auxiliary task that helps learning a coarse
global scene structure. The proposed model outperforms all state-of-the-art
models on both the ADE20K and the Cityscapes datasets.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19251" title="Abstract">arXiv:2402.19251</a> [<a href="/pdf/2402.19251" title="Download PDF">pdf</a>, <a href="/format/2402.19251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Haicheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongkang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenning Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiyong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In autonomous vehicle (AV) technology, the ability to accurately predict the
movements of surrounding vehicles is paramount for ensuring safety and
operational efficiency. Incorporating human decision-making insights enables
AVs to more effectively anticipate the potential actions of other vehicles,
significantly improving prediction accuracy and responsiveness in dynamic
environments. This paper introduces the Human-Like Trajectory Prediction (HLTP)
model, which adopts a teacher-student knowledge distillation framework inspired
by human cognitive processes. The HLTP model incorporates a sophisticated
teacher-student knowledge distillation framework. The "teacher" model, equipped
with an adaptive visual sector, mimics the visual processing of the human
brain, particularly the functions of the occipital and temporal lobes. The
"student" model focuses on real-time interaction and decision-making, drawing
parallels to prefrontal and parietal cortex functions. This approach allows for
dynamic adaptation to changing driving scenarios, capturing essential
perceptual cues for accurate prediction. Evaluated using the Macao Connected
and Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD
benchmarks, HLTP demonstrates superior performance compared to existing models,
particularly in challenging environments with incomplete data. The project page
is available at Github.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19254" title="Abstract">arXiv:2402.19254</a> [<a href="/pdf/2402.19254" title="Download PDF">pdf</a>, <a href="/format/2402.19254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning for modular multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lauter%2C+K">Kristin Lauter</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C+Y">Cathy Yuanchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Maughan%2C+K">Krystal Maughan</a>, 
<a href="/search/cs?searchtype=author&query=Newton%2C+R">Rachel Newton</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M">Megha Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures. Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Motivated by cryptographic applications, we investigate two machine learning
approaches to modular multiplication: namely circular regression and a
sequence-to-sequence transformer model. The limited success of both methods
demonstrated in our results gives evidence for the hardness of tasks involving
modular multiplication upon which cryptosystems are based.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19255" title="Abstract">arXiv:2402.19255</a> [<a href="/pdf/2402.19255" title="Download PDF">pdf</a>, <a href="/format/2402.19255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of  LLMs as Mathematical Problem Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qintong Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xueliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have achieved impressive performance across
various mathematical reasoning benchmarks. However, there are increasing
debates regarding whether these models truly understand and apply mathematical
knowledge or merely rely on shortcuts for mathematical reasoning. One essential
and frequently occurring evidence is that when the math questions are slightly
changed, LLMs can behave incorrectly. This motivates us to evaluate the
robustness of LLMs' math reasoning capability by testing a wide range of
question variations. We introduce the adversarial grade school math
(\datasetname) dataset, an extension of GSM8K augmented with various
mathematical perturbations. Our experiments on 25 LLMs and 4 prompting
techniques show that while LLMs exhibit different levels of math reasoning
abilities, their performances are far from robust. In particular, even for
problems that have been solved in GSM8K, LLMs can make mistakes when new
statements are added or the question targets are altered. We also explore
whether more robust performance can be achieved by composing existing prompting
methods, in which we try an iterative method that generates and verifies each
intermediate thought based on its reasoning goal and calculation result. Code
and data are available at \url{https://github.com/qtli/GSM-Plus}.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19257" title="Abstract">arXiv:2402.19257</a> [<a href="/pdf/2402.19257" title="Download PDF">pdf</a>, <a href="/ps/2402.19257" title="Download PostScript">ps</a>, <a href="/format/2402.19257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More algorithmic results for problems of spread of influence in  edge-weighted graphs with and without incentives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Askari%2C+S">Siavash Askari</a>, 
<a href="/search/cs?searchtype=author&query=Zaker%2C+M">Manouchehr Zaker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Many phenomena in real world social networks are interpreted as spread of
influence between activated and non-activated network elements. These phenomena
are formulated by combinatorial graphs, where vertices represent the elements
and edges represent social ties between elements. A main problem is to study
important subsets of elements (target sets or dynamic monopolies) such that
their activation spreads to the entire network. In edge-weighted networks the
influence between two adjacent vertices depends on the weight of their edge. In
models with incentives, the main problem is to minimize total amount of
incentives (called optimal target vectors) which can be offered to vertices
such that some vertices are activated and their activation spreads to the whole
network. Algorithmic study of target sets and vectors is a hot research field.
We prove an inapproximability result for optimal target sets in edge weighted
networks even for complete graphs. Some other hardness and polynomial time
results are presented for optimal target vectors and degenerate threshold
assignments in edge-weighted networks.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19258" title="Abstract">arXiv:2402.19258</a> [<a href="/pdf/2402.19258" title="Download PDF">pdf</a>, <a href="/format/2402.19258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaskFi: Unsupervised Learning of WiFi and Vision Representations for  Multimodal Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shijie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuecong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yunjiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human activity recognition (HAR) has been playing an increasingly important
role in various domains such as healthcare, security monitoring, and metaverse
gaming. Though numerous HAR methods based on computer vision have been
developed to show prominent performance, they still suffer from poor robustness
in adverse visual conditions in particular low illumination, which motivates
WiFi-based HAR to serve as a good complementary modality. Existing solutions
using WiFi and vision modalities rely on massive labeled data that are very
cumbersome to collect. In this paper, we propose a novel unsupervised
multimodal HAR solution, MaskFi, that leverages only unlabeled video and WiFi
activity data for model training. We propose a new algorithm, masked
WiFi-vision modeling (MI2M), that enables the model to learn cross-modal and
single-modal features by predicting the masked sections in representation
learning. Benefiting from our unsupervised learning procedure, the network
requires only a small amount of annotated data for finetuning and can adapt to
the new environment with better performance. We conduct extensive experiments
on two WiFi-vision datasets collected in-house, and our method achieves human
activity recognition and human identification in terms of both robustness and
accuracy.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19259" title="Abstract">arXiv:2402.19259</a> [<a href="/pdf/2402.19259" title="Download PDF">pdf</a>, <a href="/format/2402.19259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Total Completion Time Scheduling Under Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosman%2C+T">Thomas Bosman</a>, 
<a href="/search/cs?searchtype=author&query=van+Ee%2C+M">Martijn van Ee</a>, 
<a href="/search/cs?searchtype=author&query=Ergen%2C+E">Ekin Ergen</a>, 
<a href="/search/cs?searchtype=author&query=Imreh%2C+C">Csanad Imreh</a>, 
<a href="/search/cs?searchtype=author&query=Marchetti-Spaccamela%2C+A">Alberto Marchetti-Spaccamela</a>, 
<a href="/search/cs?searchtype=author&query=Skutella%2C+M">Martin Skutella</a>, 
<a href="/search/cs?searchtype=author&query=Stougie%2C+L">Leen Stougie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Scheduling jobs with given processing times on identical parallel machines so
as to minimize their total completion time is one of the most basic scheduling
problems. We study interesting generalizations of this classical problem
involving scenarios. In our model, a scenario is defined as a subset of a
predefined and fully specified set of jobs. The aim is to find an assignment of
the whole set of jobs to identical parallel machines such that the schedule,
obtained for the given scenarios by simply skipping the jobs not in the
scenario, optimizes a function of the total completion times over all
scenarios.
<br />While the underlying scheduling problem without scenarios can be solved
efficiently by a simple greedy procedure (SPT rule), scenarios, in general,
make the problem NP-hard. We paint an almost complete picture of the evolving
complexity landscape, drawing the line between easy and hard. One of our main
algorithmic contributions relies on a deep structural result on the maximum
imbalance of an optimal schedule, based on a subtle connection to Hilbert bases
of a related convex cone.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19262" title="Abstract">arXiv:2402.19262</a> [<a href="/pdf/2402.19262" title="Download PDF">pdf</a>, <a href="/format/2402.19262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masks, Signs, And Learning Rate Rewinding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadhikar%2C+A">Advait Gadhikar</a>, 
<a href="/search/cs?searchtype=author&query=Burkholz%2C+R">Rebekka Burkholz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publishing at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning Rate Rewinding (LRR) has been established as a strong variant of
Iterative Magnitude Pruning (IMP) to find lottery tickets in deep
overparameterized neural networks. While both iterative pruning schemes couple
structure and parameter learning, understanding how LRR excels in both aspects
can bring us closer to the design of more flexible deep learning algorithms
that can optimize diverse sets of sparse architectures. To this end, we conduct
experiments that disentangle the effect of mask learning and parameter
optimization and how both benefit from overparameterization. The ability of LRR
to flip parameter signs early and stay robust to sign perturbations seems to
make it not only more effective in mask identification but also in optimizing
diverse sets of masks, including random ones. In support of this hypothesis, we
prove in a simplified single hidden neuron setting that LRR succeeds in more
cases than IMP, as it can escape initially problematic sign configurations.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19263" title="Abstract">arXiv:2402.19263</a> [<a href="/pdf/2402.19263" title="Download PDF">pdf</a>, <a href="/format/2402.19263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spinal Osteophyte Detection via Robust Patch Extraction on minimally  annotated X-rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S+S">Soumya Snigdha Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yuanhan Mo</a>, 
<a href="/search/cs?searchtype=author&query=Srikijkasemwat%2C+N">Nicharee Srikijkasemwat</a>, 
<a href="/search/cs?searchtype=author&query=Papiez%2C+B+W">Bart&#x142;omiej W. Papiez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISBI'24 Full Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development and progression of arthritis is strongly associated with
osteophytes, which are small and elusive bone growths. This paper presents one
of the first efforts towards automated spinal osteophyte detection in spinal
X-rays. A novel automated patch extraction process, called SegPatch, has been
proposed based on deep learning-driven vertebrae segmentation and the
enlargement of mask contours. A final patch classification accuracy of 84.5\%
is secured, surpassing a baseline tiling-based patch generation technique by
9.5%. This demonstrates that even with limited annotations, SegPatch can
deliver superior performance for detection of tiny structures such as
osteophytes. The proposed approach has potential to assist clinicians in
expediting the process of manually identifying osteophytes in spinal X-ray.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19264" title="Abstract">arXiv:2402.19264</a> [<a href="/pdf/2402.19264" title="Download PDF">pdf</a>, <a href="/format/2402.19264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T3DNet: Compressing Point Cloud Models for Lightweight 3D Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yunjiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D point cloud has been widely used in many mobile application scenarios,
including autonomous driving and 3D sensing on mobile devices. However,
existing 3D point cloud models tend to be large and cumbersome, making them
hard to deploy on edged devices due to their high memory requirements and
non-real-time latency. There has been a lack of research on how to compress 3D
point cloud models into lightweight models. In this paper, we propose a method
called T3DNet (Tiny 3D Network with augmEntation and disTillation) to address
this issue. We find that the tiny model after network augmentation is much
easier for a teacher to distill. Instead of gradually reducing the parameters
through techniques such as pruning or quantization, we pre-define a tiny model
and improve its performance through auxiliary supervision from augmented
networks and the original model. We evaluate our method on several public
datasets, including ModelNet40, ShapeNet, and ScanObjectNN. Our method can
achieve high compression rates without significant accuracy sacrifice,
achieving state-of-the-art performances on three datasets against existing
methods. Amazingly, our T3DNet is 58 times smaller and 54 times faster than the
original model yet with only 1.4% accuracy descent on the ModelNet40 dataset.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19265" title="Abstract">arXiv:2402.19265</a> [<a href="/pdf/2402.19265" title="Download PDF">pdf</a>, <a href="/format/2402.19265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Logic Specifications for Policy Guidance in POMDPs: an  Inductive Logic Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meli%2C+D">Daniele Meli</a>, 
<a href="/search/cs?searchtype=author&query=Castellini%2C+A">Alberto Castellini</a>, 
<a href="/search/cs?searchtype=author&query=Farinelli%2C+A">Alessandro Farinelli</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research, volume 79 (2024), pp.
  725-776
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Partially Observable Markov Decision Processes (POMDPs) are a powerful
framework for planning under uncertainty. They allow to model state uncertainty
as a belief probability distribution. Approximate solvers based on Monte Carlo
sampling show great success to relax the computational demand and perform
online planning. However, scaling to complex realistic domains with many
actions and long planning horizons is still a major challenge, and a key point
to achieve good performance is guiding the action-selection process with
domain-dependent policy heuristics which are tailored for the specific
application domain. We propose to learn high-quality heuristics from POMDP
traces of executions generated by any solver. We convert the belief-action
pairs to a logical semantics, and exploit data- and time-efficient Inductive
Logic Programming (ILP) to generate interpretable belief-based policy
specifications, which are then used as online heuristics. We evaluate
thoroughly our methodology on two notoriously challenging POMDP problems,
involving large action spaces and long planning horizons, namely, rocksample
and pocman. Considering different state-of-the-art online POMDP solvers,
including POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed
in Answer Set Programming (ASP) yield performance superior to neural networks
and similar to optimal handcrafted task-specific heuristics within lower
computational time. Moreover, they well generalize to more challenging
scenarios not experienced in the training phase (e.g., increasing rocks and
grid size in rocksample, incrementing the size of the map and the aggressivity
of ghosts in pocman).
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19267" title="Abstract">arXiv:2402.19267</a> [<a href="/pdf/2402.19267" title="Download PDF">pdf</a>, <a href="/format/2402.19267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Guidance for Unsupervised Data Selection: Capturing Perplexing  Named Entities for Domain-Specific Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Seunghyun Ji</a>, 
<a href="/search/cs?searchtype=author&query=Sinulingga%2C+H+R">Hagai Raja Sinulingga</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Darongsae Kwon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to SIGUL 2024, a satellite workshop of LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Employing extensive datasets enables the training of multilingual machine
translation models; however, these models often fail to accurately translate
sentences within specialized domains. Although obtaining and translating
domain-specific data incurs high costs, it is inevitable for high-quality
translations. Hence, finding the most 'effective' data with an unsupervised
setting becomes a practical strategy for reducing labeling costs. Recent
research indicates that this effective data could be found by selecting
'properly difficult data' based on its volume. This means the data should not
be excessively challenging or overly simplistic, especially if the amount of
data is limited. However, we found that establishing a criterion for
unsupervised data selection remains challenging, as the 'proper difficulty'
might vary based on the data domain being trained on. We introduce a novel
unsupervised data selection method, 'Capturing Perplexing Named Entities',
which adopts the maximum inference entropy in translated named entities as a
selection measure. The motivation was that named entities in domain-specific
data are considered the most complex portion of the data and should be
predicted with high confidence. When verified with the 'Korean-English Parallel
Corpus of Specialized Domains,' our method served as a robust guidance for
unsupervised data selection, in contrast to existing methods.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19270" title="Abstract">arXiv:2402.19270</a> [<a href="/pdf/2402.19270" title="Download PDF">pdf</a>, <a href="/format/2402.19270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Intra-view and Cross-view Geometric Knowledge for Stereo  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+R">Rui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weide Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zaiwang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xulei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jun Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Geometric knowledge has been shown to be beneficial for the stereo matching
task. However, prior attempts to integrate geometric insights into stereo
matching algorithms have largely focused on geometric knowledge from single
images while crucial cross-view factors such as occlusion and matching
uniqueness have been overlooked. To address this gap, we propose a novel
Intra-view and Cross-view Geometric knowledge learning Network (ICGNet),
specifically crafted to assimilate both intra-view and cross-view geometric
knowledge. ICGNet harnesses the power of interest points to serve as a channel
for intra-view geometric understanding. Simultaneously, it employs the
correspondences among these points to capture cross-view geometric
relationships. This dual incorporation empowers the proposed ICGNet to leverage
both intra-view and cross-view geometric knowledge in its learning process,
substantially improving its ability to estimate disparities. Our extensive
experiments demonstrate the superiority of the ICGNet over contemporary leading
models.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19273" title="Abstract">arXiv:2402.19273</a> [<a href="/pdf/2402.19273" title="Download PDF">pdf</a>, <a href="/format/2402.19273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlanGPT: Enhancing Urban Planning with Tailored Language Model and  Efficient Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">He Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nuoxian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Luyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zipei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lun%2C+T">Tianle Lun</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yicheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Junyou Su</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zhaoya Gong</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chenyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the field of urban planning, general-purpose large language models often
struggle to meet the specific needs of planners. Tasks like generating urban
planning texts, retrieving related information, and evaluating planning
documents pose unique challenges. To enhance the efficiency of urban
professionals and overcome these obstacles, we introduce PlanGPT, the first
specialized Large Language Model tailored for urban and spatial planning.
Developed through collaborative efforts with institutions like the Chinese
Academy of Urban Planning, PlanGPT leverages a customized local database
retrieval framework, domain-specific fine-tuning of base models, and advanced
tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved
advanced performance, delivering responses of superior quality precisely
tailored to the intricacies of urban planning.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19275" title="Abstract">arXiv:2402.19275</a> [<a href="/pdf/2402.19275" title="Download PDF">pdf</a>, <a href="/format/2402.19275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Testing Environment Generation for Connected and Automated  Vehicles with Dense Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jingxuan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+R">Ruoxuan Bai</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+H">Haoyuan Ji</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+J">Jianming Hu</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+S">Shuo Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The assessment of safety performance plays a pivotal role in the development
and deployment of connected and automated vehicles (CAVs). A common approach
involves designing testing scenarios based on prior knowledge of CAVs (e.g.,
surrogate models), conducting tests in these scenarios, and subsequently
evaluating CAVs' safety performances. However, substantial differences between
CAVs and the prior knowledge can significantly diminish the evaluation
efficiency. In response to this issue, existing studies predominantly
concentrate on the adaptive design of testing scenarios during the CAV testing
process. Yet, these methods have limitations in their applicability to
high-dimensional scenarios. To overcome this challenge, we develop an adaptive
testing environment that bolsters evaluation robustness by incorporating
multiple surrogate models and optimizing the combination coefficients of these
surrogate models to enhance evaluation efficiency. We formulate the
optimization problem as a regression task utilizing quadratic programming. To
efficiently obtain the regression target via reinforcement learning, we propose
the dense reinforcement learning method and devise a new adaptive policy with
high sample efficiency. Essentially, our approach centers on learning the
values of critical scenes displaying substantial surrogate-to-real gaps. The
effectiveness of our method is validated in high-dimensional overtaking
scenarios, demonstrating that our approach achieves notable evaluation
efficiency.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19279" title="Abstract">arXiv:2402.19279</a> [<a href="/pdf/2402.19279" title="Download PDF">pdf</a>, <a href="/format/2402.19279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIFT-Aided Rectified 2D-DIC for Displacement and Strain Measurements in  Asphalt Concrete Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Al-Qadi%2C+I+L">Imad L. Al-Qadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Transportation Engineering, Part B: Pavements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Two-dimensional digital image correlation (2D-DIC) is a widely used optical
technique to measure displacement and strain during asphalt concrete (AC)
testing. An accurate 2-D DIC measurement can only be achieved when the camera's
principal axis is perpendicular to the planar specimen surface. However, this
requirement may not be met during testing due to device constraints. This paper
proposes a simple and reliable method to correct errors induced by
non-perpendicularity. The method is based on image feature matching and
rectification. No additional equipment is needed. A theoretical error analysis
was conducted to quantify the effect of a non-perpendicular camera alignment on
measurement accuracy. The proposed method was validated numerically using
synthetic images and experimentally in an AC fracture test. It achieved
relatively high accuracy, even under considerable camera rotation angle and
large deformation. As a pre-processing technique, the proposed method showed
promising performance in assisting the recently developed CrackPropNet for
automated crack propagation measurement under a non-perpendicular camera
alignment.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19280" title="Abstract">arXiv:2402.19280</a> [<a href="/pdf/2402.19280" title="Download PDF">pdf</a>, <a href="/ps/2402.19280" title="Download PostScript">ps</a>, <a href="/format/2402.19280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile Health Text Misinformation Identification Using Mobile Data  Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wen-Chen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pillai%2C+S+E+V+S">Sanjaikanth E Vadakkethil Somanathan Pillai</a>, 
<a href="/search/cs?searchtype=author&query=ElSaid%2C+A+A">Abdelrahman Ahmed ElSaid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">More than six million people died of the COVID-19 by April 2022. The heavy
casualties have put people on great and urgent alert and people try to find all
kinds of information to keep them from being inflected by the coronavirus. This
research tries to find out whether the mobile health text information sent to
peoples devices is correct as smartphones becoming the major information source
for people. The proposed method uses various mobile information retrieval and
data mining technologies including lexical analysis, stopword elimination,
stemming, and decision trees to classify the mobile health text information to
one of the following classes: (i) true, (ii) fake, (iii) misinformative, (iv)
disinformative, and (v) neutral. Experiment results show the accuracy of the
proposed method is above the threshold value 50 percentage, but is not optimal.
It is because the problem, mobile text misinformation identification, is
intrinsically difficult.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19282" title="Abstract">arXiv:2402.19282</a> [<a href="/pdf/2402.19282" title="Download PDF">pdf</a>, <a href="/format/2402.19282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiantao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Haijun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenjiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+W">Wenchang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">ChaoBin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P">Pei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Runyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huanze Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruiliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents WanJuan-CC, a safe and high-quality open-sourced English
webtext dataset derived from Common Crawl data. The study addresses the
challenges of constructing large-scale pre-training datasets for language
models, which require vast amounts of high-quality data. A comprehensive
process was designed to handle Common Crawl data, including extraction,
heuristic rule filtering, fuzzy deduplication, content safety filtering, and
data quality filtering. From approximately 68 billion original English
documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of
high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from
this dataset. The paper also provides statistical information related to data
quality, enabling users to select appropriate data according to their needs. To
evaluate the quality and utility of the dataset, we trained 1B-parameter and
3B-parameter models using WanJuan-CC and another dataset, RefinedWeb. Results
show that WanJuan-CC performs better on validation datasets and downstream
tasks.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19287" title="Abstract">arXiv:2402.19287</a> [<a href="/pdf/2402.19287" title="Download PDF">pdf</a>, <a href="/format/2402.19287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StiefelGen: A Simple, Model Agnostic Approach for Time Series Data  Augmentation over Riemannian Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheema%2C+P">Prasad Cheema</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Mahito Sugiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 41 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data augmentation is an area of research which has seen active development in
many machine learning fields, such as in image-based learning models,
reinforcement learning for self driving vehicles, and general noise injection
for point cloud data. However, convincing methods for general time series data
augmentation still leaves much to be desired, especially since the methods
developed for these models do not readily cross-over. Three common approaches
for time series data augmentation include: (i) Constructing a physics-based
model and then imbuing uncertainty over the coefficient space (for example),
(ii) Adding noise to the observed data set(s), and, (iii) Having access to
ample amounts of time series data sets from which a robust generative neural
network model can be trained. However, for many practical problems that work
with time series data in the industry: (i) One usually does not have access to
a robust physical model, (ii) The addition of noise can in of itself require
large or difficult assumptions (for example, what probability distribution
should be used? Or, how large should the noise variance be?), and, (iii) In
practice, it can be difficult to source a large representative time series data
base with which to train the neural network model for the underlying problem.
In this paper, we propose a methodology which attempts to simultaneously tackle
all three of these previous limitations to a large extent. The method relies
upon the well-studied matrix differential geometry of the Stiefel manifold, as
it proposes a simple way in which time series signals can placed on, and then
smoothly perturbed over the manifold. We attempt to clarify how this method
works by showcasing several potential use cases which in particular work to
take advantage of the unique properties of this underlying manifold.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19290" title="Abstract">arXiv:2402.19290</a> [<a href="/pdf/2402.19290" title="Download PDF">pdf</a>, <a href="/ps/2402.19290" title="Download PostScript">ps</a>, <a href="/format/2402.19290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation and Deconvolution of Second Order Cyclostationary Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makienko%2C+I">Igor Makienko</a>, 
<a href="/search/cs?searchtype=author&query=Grebshtein%2C+M">Michael Grebshtein</a>, 
<a href="/search/cs?searchtype=author&query=Gildish%2C+E">Eli Gildish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This method solves the dual problem of blind deconvolution and estimation of
the time waveform of noisy second-order cyclo-stationary (CS2) signals that
traverse a Transfer Function (TF) en route to a sensor. We have proven that the
deconvolution filter exists and eliminates the TF effect from signals whose
statistics vary over time. This method is blind, meaning it does not require
prior knowledge about the signals or TF. Simulations demonstrate the algorithm
high precision across various signal types, TFs, and Signal-to-Noise Ratios
(SNRs). In this study, the CS2 signals family is restricted to the product of a
deterministic periodic function and white noise. Furthermore, this method has
the potential to improve the training of Machine Learning models where the
aggregation of signals from identical systems but with different TFs is
required.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19292" title="Abstract">arXiv:2402.19292</a> [<a href="/pdf/2402.19292" title="Download PDF">pdf</a>, <a href="/format/2402.19292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental Limits of Throughput and Availability: Applications to  prophet inequalities &amp; transaction fee mechanism design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+A">Aadityan Ganesh</a>, 
<a href="/search/cs?searchtype=author&query=Hartline%2C+J">Jason Hartline</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A+R">Atanu R Sinha</a>, 
<a href="/search/cs?searchtype=author&query=vonAllmen%2C+M">Matthew vonAllmen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This paper studies the fundamental limits of availability and throughput for
independent and heterogeneous demands of a limited resource. Availability is
the probability that the demands are below the capacity of the resource.
Throughput is the expected fraction of the resource that is utilized by the
demands. We offer a concentration inequality generator that gives lower bounds
on feasible availability and throughput pairs with a given capacity and
independent but not necessarily identical distributions of up-to-unit demands.
We show that availability and throughput cannot both be poor. These bounds are
analogous to tail inequalities on sums of independent random variables, but
hold throughout the support of the demand distribution. This analysis gives
analytically tractable bounds supporting the unit-demand characterization of
Chawla, Devanur, and Lykouris (2023) and generalizes to up-to-unit demands. Our
bounds also provide an approach towards improved multi-unit prophet
inequalities (Hajiaghayi, Kleinberg, and Sandholm, 2007). They have
applications to transaction fee mechanism design (for blockchains) where high
availability limits the probability of profitable user-miner coalitions (Chung
and Shi, 2023).
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19294" title="Abstract">arXiv:2402.19294</a> [<a href="/pdf/2402.19294" title="Download PDF">pdf</a>, <a href="/format/2402.19294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Huh%2C+Y+K">Ye Kwon Huh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaibo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Operating units often experience various failure modes in complex systems,
leading to distinct degradation paths. Relying on a prognostic model trained on
a single failure mode may lead to poor generalization performance across
multiple failure modes. Therefore, accurately identifying the failure mode is
of critical importance. Current prognostic approaches either ignore failure
modes during degradation or assume known failure mode labels, which can be
challenging to acquire in practice. Moreover, the high dimensionality and
complex relations of sensor signals make it challenging to identify the failure
modes accurately. To address these issues, we propose a novel failure mode
diagnosis method that leverages a dimension reduction technique called UMAP
(Uniform Manifold Approximation and Projection) to project and visualize each
unit's degradation trajectory into a lower dimension. Then, using these
degradation trajectories, we develop a time series-based clustering method to
identify the training units' failure modes. Finally, we introduce a
monotonically constrained prognostic model to predict the failure mode labels
and RUL of the test units simultaneously using the obtained failure modes of
the training units. The proposed prognostic model provides failure
mode-specific RUL predictions while preserving the monotonic property of the
RUL predictions across consecutive time steps. We evaluate the proposed model
using a case study with the aircraft gas turbine engine dataset.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19295" title="Abstract">arXiv:2402.19295</a> [<a href="/pdf/2402.19295" title="Download PDF">pdf</a>, <a href="/format/2402.19295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical  Bayesian Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+S+M">S. M. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+A+J">A. J. Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Dardeno%2C+T+A">T. A. Dardeno</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+L+A">L. A. Bull</a>, 
<a href="/search/cs?searchtype=author&query=Dervilis%2C+N">N. Dervilis</a>, 
<a href="/search/cs?searchtype=author&query=Worden%2C+K">K. Worden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to International Workshop on Structural Health Monitoring 2023, Stanford University, California, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Population-based structural health monitoring (PBSHM), aims to share
information between members of a population. An offshore wind (OW) farm could
be considered as a population of nominally-identical wind-turbine structures.
However, benign variations exist among members, such as geometry, sea-bed
conditions and temperature differences. These factors could influence
structural properties and therefore the dynamic response, making it more
difficult to detect structural problems via traditional SHM techniques. This
paper explores the use of a hierarchical Bayesian model to infer expected soil
stiffness distributions at both population and local levels, as a basis to
perform anomaly detection, in the form of scour, for new and existing turbines.
To do this, observations of natural frequency will be generated as though they
are from a small population of wind turbines. Differences between individual
observations will be introduced by postulating distributions over the soil
stiffness and measurement noise, as well as reducing soil depth (to represent
scour), in the case of anomaly detection.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19296" title="Abstract">arXiv:2402.19296</a> [<a href="/pdf/2402.19296" title="Download PDF">pdf</a>, <a href="/ps/2402.19296" title="Download PostScript">ps</a>, <a href="/format/2402.19296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI based Digital Score of Tumour-Immune Microenvironment Predicts  Benefit to Maintenance Immunotherapy in Advanced Oesophagogastric  Adenocarcinoma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+Q+D">Quoc Dang Vu</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+C">Caroline Fong</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+A">Anderley Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Lund%2C+T">Tom Lund</a>, 
<a href="/search/cs?searchtype=author&query=Silveira%2C+T+L">Tatiany L Silveira</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+D">Daniel Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=von+Loga%2C+K">Katharina von Loga</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S+E+A">Shan E Ahmed Raza</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+D">David Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Rajpoot%2C+N">Nasir Rajpoot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Gastric and oesophageal (OG) cancers are the leading causes of cancer
mortality worldwide. In OG cancers, recent studies have showed that PDL1 immune
checkpoint inhibitors (ICI) in combination with chemotherapy improves patient
survival. However, our understanding of the tumour immune microenvironment in
OG cancers remains limited. In this study, we interrogate multiplex
immunofluorescence (mIF) images taken from patients with advanced
Oesophagogastric Adenocarcinoma (OGA) who received first-line fluoropyrimidine
and platinum-based chemotherapy in the PLATFORM trial (NCT02678182) to predict
the efficacy of the treatment and to explore the biological basis of patients
responding to maintenance durvalumab (PDL1 inhibitor). Our proposed Artificial
Intelligence (AI) based marker successfully identified responder from
non-responder (p &lt; 0.05) as well as those who could potentially benefit from
ICI with statistical significance (p &lt; 0.05) for both progression free and
overall survival. Our findings suggest that T cells that express FOXP3 seem to
heavily influence the patient treatment response and survival outcome. We also
observed that higher levels of CD8+PD1+ cells are consistently linked to poor
prognosis for both OS and PFS, regardless of ICI.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19298" title="Abstract">arXiv:2402.19298</a> [<a href="/pdf/2402.19298" title="Download PDF">pdf</a>, <a href="/format/2402.19298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suppress and Rebalance: Towards Generalized Multi-Modal Face  Anti-Spoofing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rizhao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zitong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenzhong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A">Alex Kot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepeted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face Anti-Spoofing (FAS) is crucial for securing face recognition systems
against presentation attacks. With advancements in sensor manufacture and
multi-modal learning techniques, many multi-modal FAS approaches have emerged.
However, they face challenges in generalizing to unseen attacks and deployment
conditions. These challenges arise from (1) modality unreliability, where some
modality sensors like depth and infrared undergo significant domain shifts in
varying environments, leading to the spread of unreliable information during
cross-modal feature fusion, and (2) modality imbalance, where training overly
relies on a dominant modality hinders the convergence of others, reducing
effectiveness against attack types that are indistinguishable sorely using the
dominant modality. To address modality unreliability, we propose the
Uncertainty-Guided Cross-Adapter (U-Adapter) to recognize unreliably detected
regions within each modality and suppress the impact of unreliable regions on
other modalities. For modality imbalance, we propose a Rebalanced Modality
Gradient Modulation (ReGrad) strategy to rebalance the convergence speed of all
modalities by adaptively adjusting their gradients. Besides, we provide the
first large-scale benchmark for evaluating multi-modal FAS performance under
domain generalization scenarios. Extensive experiments demonstrate that our
method outperforms state-of-the-art methods. Source code and protocols will be
released on https://github.com/OMGGGGG/mmdg.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19299" title="Abstract">arXiv:2402.19299</a> [<a href="/pdf/2402.19299" title="Download PDF">pdf</a>, <a href="/format/2402.19299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL-GPT: Integrating Reinforcement Learning and Code-as-policy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaoteng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haoqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Minda Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yukang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated proficiency in utilizing
various tools by coding, yet they face limitations in handling intricate logic
and precise control. In embodied tasks, high-level planning is amenable to
direct coding, while low-level actions often necessitate task-specific
refinement, such as Reinforcement Learning (RL). To seamlessly integrate both
modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising
a slow agent and a fast agent. The slow agent analyzes actions suitable for
coding, while the fast agent executes coding tasks. This decomposition
effectively focuses each agent on specific tasks, proving highly efficient
within our pipeline. Our approach outperforms traditional RL methods and
existing GPT agents, demonstrating superior efficiency. In the Minecraft game,
it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it
achieves SOTA performance across all designated MineDojo tasks.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19302" title="Abstract">arXiv:2402.19302</a> [<a href="/pdf/2402.19302" title="Download PDF">pdf</a>, <a href="/format/2402.19302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scarpellini%2C+G">Gianluca Scarpellini</a>, 
<a href="/search/cs?searchtype=author&query=Fiorini%2C+S">Stefano Fiorini</a>, 
<a href="/search/cs?searchtype=author&query=Giuliari%2C+F">Francesco Giuliari</a>, 
<a href="/search/cs?searchtype=author&query=Morerio%2C+P">Pietro Morerio</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bue%2C+A">Alessio Del Bue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reassembly tasks play a fundamental role in many fields and multiple
approaches exist to solve specific reassembly problems. In this context, we
posit that a general unified model can effectively address them all,
irrespective of the input data type (images, 3D, etc.). We introduce
DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to
solve reassembly tasks using a diffusion model formulation. Our method treats
the elements of a set, whether pieces of 2D patch or 3D object fragments, as
nodes of a spatial graph. Training is performed by introducing noise into the
position and rotation of the elements and iteratively denoising them to
reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art
(SOTA) results in most 2D and 3D reassembly tasks and is the first
learning-based approach that solves 2D puzzles for both rotation and
translation. Furthermore, we highlight its remarkable reduction in run-time,
performing 11 times faster than the quickest optimization-based method for
puzzle solving. Code available at https://github.com/IIT-PAVIS/DiffAssemble
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19303" title="Abstract">arXiv:2402.19303</a> [<a href="/pdf/2402.19303" title="Download PDF">pdf</a>, <a href="/ps/2402.19303" title="Download PostScript">ps</a>, <a href="/format/2402.19303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learnability Gaps of Strategic Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+L">Lee Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+Y">Yishay Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Shay Moran</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Han Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In contrast with standard classification tasks, strategic classification
involves agents strategically modifying their features in an effort to receive
favorable predictions. For instance, given a classifier determining loan
approval based on credit scores, applicants may open or close their credit
cards to fool the classifier. The learning goal is to find a classifier robust
against strategic manipulations. Various settings, based on what and when
information is known, have been explored in strategic classification. In this
work, we focus on addressing a fundamental question: the learnability gaps
between strategic classification and standard learning.
<br />We essentially show that any learnable class is also strategically learnable:
we first consider a fully informative setting, where the manipulation structure
(which is modeled by a manipulation graph $G^\star$) is known and during
training time the learner has access to both the pre-manipulation data and
post-manipulation data. We provide nearly tight sample complexity and regret
bounds, offering significant improvements over prior results. Then, we relax
the fully informative setting by introducing two natural types of uncertainty.
First, following Ahmadi et al. (2023), we consider the setting in which the
learner only has access to the post-manipulation data. We improve the results
of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower
bound raised by them. Our second relaxation of the fully informative setting
introduces uncertainty to the manipulation structure. That is, we assume that
the manipulation graph is unknown but belongs to a known class of graphs. We
provide nearly tight bounds on the learning complexity in various unknown
manipulation graph settings. Notably, our algorithm in this setting is of
independent interest and can be applied to other problems such as multi-label
learning.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19305" title="Abstract">arXiv:2402.19305</a> [<a href="/pdf/2402.19305" title="Download PDF">pdf</a>, <a href="/format/2402.19305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyenaPixel: Global Image Context with Convolutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spravil%2C+J">Julian Spravil</a>, 
<a href="/search/cs?searchtype=author&query=Houben%2C+S">Sebastian Houben</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In vision tasks, a larger effective receptive field (ERF) is associated with
better performance. While attention natively supports global context,
convolution requires multiple stacked layers and a hierarchical structure for
large context. In this work, we extend Hyena, a convolution-based attention
replacement, from causal sequences to the non-causal two-dimensional image
space. We scale the Hyena convolution kernels beyond the feature map size up to
191$\times$191 to maximize the ERF while maintaining sub-quadratic complexity
in the number of pixels. We integrate our two-dimensional Hyena, HyenaPixel,
and bidirectional Hyena into the MetaFormer framework. For image
categorization, HyenaPixel and bidirectional Hyena achieve a competitive
ImageNet-1k top-1 accuracy of 83.0% and 83.5%, respectively, while
outperforming other large-kernel networks. Combining HyenaPixel with attention
further increases accuracy to 83.6%. We attribute the success of attention to
the lack of spatial bias in later stages and support this finding with
bidirectional Hyena.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19308" title="Abstract">arXiv:2402.19308</a> [<a href="/pdf/2402.19308" title="Download PDF">pdf</a>, <a href="/format/2402.19308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss-Free Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foster%2C+J">Jack Foster</a>, 
<a href="/search/cs?searchtype=author&query=Schoepf%2C+S">Stefan Schoepf</a>, 
<a href="/search/cs?searchtype=author&query=Brintrup%2C+A">Alexandra Brintrup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a Tiny Paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a machine unlearning approach that is both retraining- and
label-free. Most existing machine unlearning approaches require a model to be
fine-tuned to remove information while preserving performance. This is
computationally expensive and necessitates the storage of the whole dataset for
the lifetime of the model. Retraining-free approaches often utilise Fisher
information, which is derived from the loss and requires labelled data which
may not be available. Thus, we present an extension to the Selective Synaptic
Dampening algorithm, substituting the diagonal of the Fisher information matrix
for the gradient of the l2 norm of the model output to approximate sensitivity.
We evaluate our method in a range of experiments using ResNet18 and Vision
Transformer. Results show our label-free method is competitive with existing
state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19309" title="Abstract">arXiv:2402.19309</a> [<a href="/pdf/2402.19309" title="Download PDF">pdf</a>, <a href="/format/2402.19309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed-loop training of static output feedback neural network  controllers for large systems: A distillation case study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Turan%2C+E+M">E. M. Turan</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%A4schke%2C+J">J. J&#xe4;schke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The online implementation of model predictive control for constrained
multivariate systems has two main disadvantages: it requires an estimate of the
entire model state and an optimisation problem must be solved online. These
issues have typically been treated separately. This work proposes an integrated
approach for the offline training of an output feedback neural network
controller in closed loop. Online this neural network controller computers the
plant inputs cheaply using noisy measurements. In addition, the controller can
be trained to only make use of certain predefined measurements. Further, a
heuristic approach is proposed to perform the automatic selection of important
measurements. The proposed method is demonstrated by extensive simulations
using a non-linear distillation column model of 50 states.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19315" title="Abstract">arXiv:2402.19315</a> [<a href="/pdf/2402.19315" title="Download PDF">pdf</a>, <a href="/format/2402.19315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Static Equilibria of a Cable-Suspended Load with  Non-stopping Flying Carriers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gabellieri%2C+C">Chiara Gabellieri</a>, 
<a href="/search/cs?searchtype=author&query=Franchi%2C+A">Antonio Franchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Aerial cooperative robotic manipulation of cable-suspended objects has been
largely studied as it allows handling large and heavy objects, and cables offer
multiple advantages, such as their low weight and cost efficiency. Multirotors
have been typically considered, which, however, can be unsuitable for
long-lasting manipulation tasks due to their scarce endurance. Hence, this work
investigates whether non-stop flights are possible for maintaining constant the
pose of cable-suspended objects. First, we show that one or two flying carriers
alone cannot perform non-stop flights while maintaining a constant pose of the
suspended object. Instead, we demonstrate that \emph{three} flying carriers can
achieve this task provided that the orientation of the load at the equilibrium
is such that the components of the cable forces that balance the external force
(typically gravity) do not belong to the plane of the cable anchoring points on
the load. Numerical tests are presented in support of the analytical results.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19318" title="Abstract">arXiv:2402.19318</a> [<a href="/pdf/2402.19318" title="Download PDF">pdf</a>, <a href="/format/2402.19318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISCERN: Designing Decision Support Interfaces to Investigate the  Complexities of Workplace Social Decision-Making With Line Managers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khadpe%2C+P">Pranav Khadpe</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+L">Lindy Le</a>, 
<a href="/search/cs?searchtype=author&query=Nowak%2C+K">Kate Nowak</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S+T">Shamsi T. Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+J">Jina Suh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Line managers form the first level of management in organizations, and must
make complex decisions, while maintaining relationships with those impacted by
their decisions. Amidst growing interest in technology-supported
decision-making at work, their needs remain understudied. Further, most
existing design knowledge for supporting social decision-making comes from
domains where decision-makers are more socially detached from those they decide
for. We conducted iterative design research with line managers within a
technology organization, investigating decision-making practices, and
opportunities for technological support. Through formative research,
development of a decision-representation tool -- DISCERN -- and user
enactments, we identify their communication and analysis needs that lack
adequate support. We found they preferred tools for externalizing reasoning
rather than tools that replace interpersonal interactions, and they wanted
tools to support a range of intuitive and calculative decision-making. We
discuss how design of social decision-making supports, especially in the
workplace, can more explicitly support highly interactional social
decision-making.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19319" title="Abstract">arXiv:2402.19319</a> [<a href="/pdf/2402.19319" title="Download PDF">pdf</a>, <a href="/format/2402.19319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacks Against Mobility Prediction in 5G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atiiq%2C+S+A">Syafiq Al Atiiq</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yachao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gehrmann%2C+C">Christian Gehrmann</a>, 
<a href="/search/cs?searchtype=author&query=Sternby%2C+J">Jakob Sternby</a>, 
<a href="/search/cs?searchtype=author&query=Barriga%2C+L">Luis Barriga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the preprint version of a paper which appears in 22th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The $5^{th}$ generation of mobile networks introduces a new Network Function
(NF) that was not present in previous generations, namely the Network Data
Analytics Function (NWDAF). Its primary objective is to provide advanced
analytics services to various entities within the network and also towards
external application services in the 5G ecosystem. One of the key use cases of
NWDAF is mobility trajectory prediction, which aims to accurately support
efficient mobility management of User Equipment (UE) in the network by
allocating ``just in time'' necessary network resources. In this paper, we show
that there are potential mobility attacks that can compromise the accuracy of
these predictions. In a semi-realistic scenario with 10,000 subscribers, we
demonstrate that an adversary equipped with the ability to hijack cellular
mobile devices and clone them can significantly reduce the prediction accuracy
from 75\% to 40\% using just 100 adversarial UEs. While a defense mechanism
largely depends on the attack and the mobility types in a particular area, we
prove that a basic KMeans clustering is effective in distinguishing legitimate
and adversarial UEs.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19322" title="Abstract">arXiv:2402.19322</a> [<a href="/pdf/2402.19322" title="Download PDF">pdf</a>, <a href="/format/2402.19322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of Neural Networks&#x27; Global Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabaha%2C+A">Anan Kabaha</a>, 
<a href="/search/cs?searchtype=author&query=Drachsler-Cohen%2C+D">Dana Drachsler-Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Programming Languages (cs.PL)

</div>
<p class="mathjax">Neural networks are successful in various applications but are also
susceptible to adversarial attacks. To show the safety of network classifiers,
many verifiers have been introduced to reason about the local robustness of a
given input to a given perturbation. While successful, local robustness cannot
generalize to unseen inputs. Several works analyze global robustness
properties, however, neither can provide a precise guarantee about the cases
where a network classifier does not change its classification. In this work, we
propose a new global robustness property for classifiers aiming at finding the
minimal globally robust bound, which naturally extends the popular local
robustness property for classifiers. We introduce VHAGaR, an anytime verifier
for computing this bound. VHAGaR relies on three main ideas: encoding the
problem as a mixed-integer programming and pruning the search space by
identifying dependencies stemming from the perturbation or network computation
and generalizing adversarial attacks to unknown inputs. We evaluate VHAGaR on
several datasets and classifiers and show that, given a three hour timeout, the
average gap between the lower and upper bound on the minimal globally robust
bound computed by VHAGaR is 1.9, while the gap of an existing global robustness
verifier is 154.7. Moreover, VHAGaR is 130.6x faster than this verifier. Our
results further indicate that leveraging dependencies and adversarial attacks
makes VHAGaR 78.6x faster.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19325" title="Abstract">arXiv:2402.19325</a> [<a href="/pdf/2402.19325" title="Download PDF">pdf</a>, <a href="/format/2402.19325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do End-to-End Neural Diarization Attractors Need to Encode Speaker  Characteristic Information?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Stafylakis%2C+T">Themos Stafylakis</a>, 
<a href="/search/cs?searchtype=author&query=Landini%2C+F">Federico Landini</a>, 
<a href="/search/cs?searchtype=author&query=Diez%2C+M">Mireia Diez</a>, 
<a href="/search/cs?searchtype=author&query=Silnova%2C+A">Anna Silnova</a>, 
<a href="/search/cs?searchtype=author&query=Burget%2C+L">Luk&#xe1;&#x161; Burget</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Odyssey 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we apply the variational information bottleneck approach to
end-to-end neural diarization with encoder-decoder attractors (EEND-EDA). This
allows us to investigate what information is essential for the model. EEND-EDA
utilizes vector representations of the speakers in a conversation - attractors.
Our analysis shows that, attractors do not necessarily have to contain speaker
characteristic information. On the other hand, giving the attractors more
freedom allowing them to encode some extra (possibly speaker-specific)
information leads to small but consistent diarization performance improvements.
Despite architectural differences in EEND systems, the notion of attractors and
frame embeddings is common to most of them and not specific to EEND-EDA. We
believe that the main conclusions of this work can apply to other variants of
EEND. Thus, we hope this paper will be a valuable contribution to guide the
community to make more informed decisions when designing new systems.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19326" title="Abstract">arXiv:2402.19326</a> [<a href="/pdf/2402.19326" title="Download PDF">pdf</a>, <a href="/format/2402.19326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Whole Slide Image Classification with Fine-Grained  Visual-Semantic Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenxian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bowen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liansheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rongshan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Whole Slide Image (WSI) classification is often formulated as a Multiple
Instance Learning (MIL) problem. Recently, Vision-Language Models (VLMs) have
demonstrated remarkable performance in WSI classification. However, existing
methods leverage coarse-grained pathogenetic descriptions for visual
representation supervision, which are insufficient to capture the complex
visual appearance of pathogenetic images, hindering the generalizability of
models on diverse downstream tasks. Additionally, processing high-resolution
WSIs can be computationally expensive. In this paper, we propose a novel
"Fine-grained Visual-Semantic Interaction" (FiVE) framework for WSI
classification. It is designed to enhance the model's generalizability by
leveraging the interplay between localized visual patterns and fine-grained
pathological semantics. Specifically, with meticulously designed queries, we
start by utilizing a large language model to extract fine-grained pathological
descriptions from various non-standardized raw reports. The output descriptions
are then reconstructed into fine-grained labels used for training. By
introducing a Task-specific Fine-grained Semantics (TFS) module, we enable
prompts to capture crucial visual information in WSIs, which enhances
representation learning and augments generalization capabilities significantly.
Furthermore, given that pathological visual patterns are redundantly
distributed across tissue slices, we sample a subset of visual instances during
training. Our method demonstrates robust generalizability and strong
transferability, dominantly outperforming the counterparts on the TCGA Lung
Cancer dataset with at least 9.19% higher accuracy in few-shot experiments.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19328" title="Abstract">arXiv:2402.19328</a> [<a href="/pdf/2402.19328" title="Download PDF">pdf</a>, <a href="/format/2402.19328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeking Soulmate via Voice: Understanding Promises and Challenges of  Online Synchronized Voice-Based Mobile Dating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chenxinran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yan Xu</a>, 
<a href="/search/cs?searchtype=author&query=LC%2C+R">Ray LC</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures. Accepted to ACM CHI 2024. In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Online dating has become a popular way for individuals to connect with
potential romantic partners. Many dating apps use personal profiles that
include a headshot and self-description, allowing users to present themselves
and search for compatible matches. However, this traditional model often has
limitations. In this study, we explore a non-traditional voice-based dating app
called "Soul". Unlike traditional platforms that rely heavily on profile
information, Soul facilitates user interactions through voice-based
communication. We conducted semi-structured interviews with 18 dedicated Soul
users to investigate how they engage with the platform and perceive themselves
and others in this unique dating environment. Our findings indicate that the
role of voice as a moderator influences impression management and shapes
perceptions between the sender and the receiver of the voice. Additionally, the
synchronous voice-based and community-based dating model offers benefits to
users in the Chinese cultural context. Our study contributes to understanding
the affordances introduced by voice-based interactions in online dating in
China.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19330" title="Abstract">arXiv:2402.19330</a> [<a href="/pdf/2402.19330" title="Download PDF">pdf</a>, <a href="/format/2402.19330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach to Industrial Defect Generation through Blended Latent  Diffusion Model with Online Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengxun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Deyin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingwen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Effectively addressing the challenge of industrial Anomaly Detection (AD)
necessitates an ample supply of defective samples, a constraint often hindered
by their scarcity in industrial contexts. This paper introduces a novel
algorithm designed to augment defective samples, thereby enhancing AD
performance. The proposed method tailors the blended latent diffusion model for
defect sample generation, employing a diffusion model to generate defective
samples in the latent space. A feature editing process, controlled by a
"trimap" mask and text prompts, refines the generated samples. The image
generation inference process is structured into three stages: a free diffusion
stage, an editing diffusion stage, and an online decoder adaptation stage. This
sophisticated inference strategy yields high-quality synthetic defective
samples with diverse pattern variations, leading to significantly improved AD
accuracies based on the augmented training set. Specifically, on the widely
recognized MVTec AD dataset, the proposed method elevates the state-of-the-art
(SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD
metrics AP, IAP, and IAP90, respectively. The implementation code of this work
can be found at the GitHub repository
https://github.com/GrandpaXun242/AdaBLDM.git
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19333" title="Abstract">arXiv:2402.19333</a> [<a href="/pdf/2402.19333" title="Download PDF">pdf</a>, <a href="/format/2402.19333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Speech Translation Models via Discrete Speech Units Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lam%2C+T+K">Tsz Kin Lam</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+A">Alexandra Birch</a>, 
<a href="/search/cs?searchtype=author&query=Haddow%2C+B">Barry Haddow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Using Self-Supervised Learning (SSL) as model initialization is now common to
obtain strong results in Speech Translation (ST). However, they also impose a
large memory footprint, hindering on-device deployment. In this paper, we
leverage the SSL models by pretraining smaller models on their Discrete Speech
Units (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2)
DSU-to-Translation data, and take the encoder from 1) and the decoder from 2)
to initialise a new model, finetuning this on limited speech-translation data.
The final model becomes compact by using the DSU pretraining to distil the
knowledge of the SSL model. Our method has several benefits over using DSU as
model inputs, such as shorter inference pipeline and robustness over (DSU)
tokenization. In contrast to ASR pretraining, it does not require transcripts,
making it applicable to low-resource settings. Evaluation on CoVoST-2 X-En
shows that our method is &gt;$0.5$ BLEU better than a ST model that directly
finetune the SSL model, given only half the model size, and on a par with ASR
pretraining.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19334" title="Abstract">arXiv:2402.19334</a> [<a href="/pdf/2402.19334" title="Download PDF">pdf</a>, <a href="/format/2402.19334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Here&#x27;s a Free Lunch: Sanitizing Backdoored Models with Model Merge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Ansh Arora</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuanli He</a>, 
<a href="/search/cs?searchtype=author&query=Mozes%2C+M">Maximilian Mozes</a>, 
<a href="/search/cs?searchtype=author&query=Swain%2C+S">Srinibas Swain</a>, 
<a href="/search/cs?searchtype=author&query=Dras%2C+M">Mark Dras</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiongkai Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The democratization of pre-trained language models through open-source
initiatives has rapidly advanced innovation and expanded access to cutting-edge
technologies. However, this openness also brings significant security risks,
including backdoor attacks, where hidden malicious behaviors are triggered by
specific inputs, compromising natural language processing (NLP) system
integrity and reliability. This paper suggests that merging a backdoored model
with other homogeneous models can remediate backdoor vulnerabilities even if
such models are not entirely secure. In our experiments, we explore various
models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets
(SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive
approaches, our method offers an effective and efficient inference-stage
defense against backdoor attacks without additional resources or specific
knowledge. Our approach consistently outperforms the other advanced baselines,
leading to an average of 75% reduction in the attack success rate. Since model
merging has been an established approach for improving model performance, the
extra advantage it provides regarding defense can be seen as a cost-free bonus.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19339" title="Abstract">arXiv:2402.19339</a> [<a href="/pdf/2402.19339" title="Download PDF">pdf</a>, <a href="/format/2402.19339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision  Transformers for High-Level Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandiani%2C+D+S+M">Delfina Sol Martinez Pandiani</a>, 
<a href="/search/cs?searchtype=author&query=Lazzari%2C+N">Nicolas Lazzari</a>, 
<a href="/search/cs?searchtype=author&query=Presutti%2C+V">Valentina Presutti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The increasing demand for automatic high-level image understanding,
particularly in detecting abstract concepts (AC) within images, underscores the
necessity for innovative and more interpretable approaches. These approaches
need to harmonize traditional deep vision methods with the nuanced,
context-dependent knowledge humans employ to interpret images at intricate
semantic levels. In this work, we leverage situated perceptual knowledge of
cultural images to enhance performance and interpretability in AC image
classification. We automatically extract perceptual semantic units from images,
which we then model and integrate into the ARTstract Knowledge Graph (AKG).
This resource captures situated perceptual semantics gleaned from over 14,000
cultural images labeled with ACs. Additionally, we enhance the AKG with
high-level linguistic frames. We compute KG embeddings and experiment with
relative representations and hybrid approaches that fuse these embeddings with
visual transformer embeddings. Finally, for interpretability, we conduct
posthoc qualitative analyses by examining model similarities with training
instances. Our results show that our hybrid KGE-ViT methods outperform existing
techniques in AC image classification. The posthoc interpretability analyses
reveal the visual transformer's proficiency in capturing pixel-level visual
attributes, contrasting with our method's efficacy in representing more
abstract and semantic scene elements. We demonstrate the synergy and
complementarity between KGE embeddings' situated perceptual knowledge and deep
visual model's sensory-perceptual understanding for AC image classification.
This work suggests a strong potential of neuro-symbolic methods for knowledge
integration and robust image representation for use in downstream intricate
visual comprehension tasks. All the materials and code are available online.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19340" title="Abstract">arXiv:2402.19340</a> [<a href="/pdf/2402.19340" title="Download PDF">pdf</a>, <a href="/format/2402.19340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One model to use them all: Training a segmentation model with  complementary datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jenke%2C+A+C">Alexander C. Jenke</a>, 
<a href="/search/cs?searchtype=author&query=Bodenstedt%2C+S">Sebastian Bodenstedt</a>, 
<a href="/search/cs?searchtype=author&query=Kolbinger%2C+F+R">Fiona R. Kolbinger</a>, 
<a href="/search/cs?searchtype=author&query=Distler%2C+M">Marius Distler</a>, 
<a href="/search/cs?searchtype=author&query=Weitz%2C+J">J&#xfc;rgen Weitz</a>, 
<a href="/search/cs?searchtype=author&query=Speidel%2C+S">Stefanie Speidel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IPCAI 2024; submitted to IJCARS (under revision)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding a surgical scene is crucial for computer-assisted surgery
systems to provide any intelligent assistance functionality. One way of
achieving this scene understanding is via scene segmentation, where every pixel
of a frame is classified and therefore identifies the visible structures and
tissues. Progress on fully segmenting surgical scenes has been made using
machine learning. However, such models require large amounts of annotated
training data, containing examples of all relevant object classes. Such fully
annotated datasets are hard to create, as every pixel in a frame needs to be
annotated by medical experts and, therefore, are rarely available. In this
work, we propose a method to combine multiple partially annotated datasets,
which provide complementary annotations, into one model, enabling better scene
segmentation and the use of multiple readily available datasets. Our method
aims to combine available data with complementary labels by leveraging mutual
exclusive properties to maximize information. Specifically, we propose to use
positive annotations of other classes as negative samples and to exclude
background pixels of binary annotations, as we cannot tell if they contain a
class not annotated but predicted by the model. We evaluate our method by
training a DeepLabV3 on the publicly available Dresden Surgical Anatomy
Dataset, which provides multiple subsets of binary segmented anatomical
structures. Our approach successfully combines 6 classes into one model,
increasing the overall Dice Score by 4.4% compared to an ensemble of models
trained on the classes individually. By including information on multiple
classes, we were able to reduce confusion between stomach and colon by 24%. Our
results demonstrate the feasibility of training a model on multiple datasets.
This paves the way for future work further alleviating the need for one large,
fully segmented datasets.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19341" title="Abstract">arXiv:2402.19341</a> [<a href="/pdf/2402.19341" title="Download PDF">pdf</a>, <a href="/format/2402.19341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoadRunner -- Learning Traversability Estimation for Autonomous Off-road  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frey%2C+J">Jonas Frey</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+S">Shehryar Khattak</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Manthan Patel</a>, 
<a href="/search/cs?searchtype=author&query=Atha%2C+D">Deegan Atha</a>, 
<a href="/search/cs?searchtype=author&query=Nubert%2C+J">Julian Nubert</a>, 
<a href="/search/cs?searchtype=author&query=Padgett%2C+C">Curtis Padgett</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Spieler%2C+P">Patrick Spieler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review for Field Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Autonomous navigation at high speeds in off-road environments necessitates
robots to comprehensively understand their surroundings using onboard sensing
only. The extreme conditions posed by the off-road setting can cause degraded
camera image quality due to poor lighting and motion blur, as well as limited
sparse geometric information available from LiDAR sensing when driving at high
speeds. In this work, we present RoadRunner, a novel framework capable of
predicting terrain traversability and an elevation map directly from camera and
LiDAR sensor inputs. RoadRunner enables reliable autonomous navigation, by
fusing sensory information, handling of uncertainty, and generation of
contextually informed predictions about the geometry and traversability of the
terrain while operating at low latency. In contrast to existing methods relying
on classifying handcrafted semantic classes and using heuristics to predict
traversability costs, our method is trained end-to-end in a self-supervised
fashion. The RoadRunner network architecture builds upon popular sensor fusion
network architectures from the autonomous driving domain, which embed LiDAR and
camera information into a common Bird's Eye View perspective. Training is
enabled by utilizing an existing traversability estimation stack to generate
training data in hindsight in a scalable manner from real-world off-road
driving datasets. Furthermore, RoadRunner improves the system latency by a
factor of roughly 4, from 500 ms to 140 ms, while improving the accuracy for
traversability costs and elevation map predictions. We demonstrate the
effectiveness of RoadRunner in enabling safe and reliable off-road navigation
at high speeds in multiple real-world driving scenarios through unstructured
desert environments.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19344" title="Abstract">arXiv:2402.19344</a> [<a href="/pdf/2402.19344" title="Download PDF">pdf</a>, <a href="/format/2402.19344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The 6th Affective Behavior Analysis in-the-wild (ABAW) Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kollias%2C+D">Dimitrios Kollias</a>, 
<a href="/search/cs?searchtype=author&query=Tzirakis%2C+P">Panagiotis Tzirakis</a>, 
<a href="/search/cs?searchtype=author&query=Cowen%2C+A">Alan Cowen</a>, 
<a href="/search/cs?searchtype=author&query=Zafeiriou%2C+S">Stefanos Zafeiriou</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+C">Chunchang Shao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guanyu Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper describes the 6th Affective Behavior Analysis in-the-wild (ABAW)
Competition, which is part of the respective Workshop held in conjunction with
IEEE CVPR 2024. The 6th ABAW Competition addresses contemporary challenges in
understanding human emotions and behaviors, crucial for the development of
human-centered technologies. In more detail, the Competition focuses on affect
related benchmarking tasks and comprises of five sub-challenges: i)
Valence-Arousal Estimation (the target is to estimate two continuous affect
dimensions, valence and arousal), ii) Expression Recognition (the target is to
recognise between the mutually exclusive classes of the 7 basic expressions and
'other'), iii) Action Unit Detection (the target is to detect 12 action units),
iv) Compound Expression Recognition (the target is to recognise between the 7
mutually exclusive compound expression classes), and v) Emotional Mimicry
Intensity Estimation (the target is to estimate six continuous emotion
dimensions). In the paper, we present these Challenges, describe their
respective datasets and challenge protocols (we outline the evaluation metrics)
and present the baseline systems as well as their obtained performance. More
information for the Competition can be found in:
\url{https://affective-behavior-analysis-in-the-wild.github.io/6th}.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19347" title="Abstract">arXiv:2402.19347</a> [<a href="/pdf/2402.19347" title="Download PDF">pdf</a>, <a href="/format/2402.19347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> #PoetsOfInstagram: Navigating The Practices And Challenges Of Novice  Poets On Instagram
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De%2C+A">Ankolika De</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures; Accepted to ACM CHI 2024. In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems (CHI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Commencing as a photo-sharing platform, Instagram has since become
multifaceted, accommodating diverse art forms, with poetry emerging as a
prominent one. However, the academic understanding of Instagram's poetry
community is limited, yet its significance emerges from its distinctive
utilization of a primarily visual social media platform guided by
recommendation algorithms for disseminating poetry, further characterized by a
predominantly novice creative population. We employ qualitative analysis to
explore motivations, experiences, and algorithmic influence within Instagram's
poetry community. We demonstrate that participants prioritize conforming to
algorithmic constraints for visibility, yet maintain their community's values
of integrity and originality, illustrating the tension between algorithmic
growth and participant authenticity. We introduce the concept of
Algorithmically Mediated Creative Labor, a phenomenon specific to
non-monetizing creative users who are impacted by the prioritization of
professional creators and continually adapt their creative endeavors to align
with platform logic, thereby affecting their motivation and creative outputs.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19348" title="Abstract">arXiv:2402.19348</a> [<a href="/pdf/2402.19348" title="Download PDF">pdf</a>, <a href="/format/2402.19348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy,  Advances, and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xingchen Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yibo Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xixuan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuehong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Haomin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+E">Erdong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As cities continue to burgeon, Urban Computing emerges as a pivotal
discipline for sustainable development by harnessing the power of cross-domain
data fusion from diverse sources (e.g., geographical, traffic, social media,
and environmental data) and modalities (e.g., spatio-temporal, visual, and
textual modalities). Recently, we are witnessing a rising trend that utilizes
various deep-learning methods to facilitate cross-domain data fusion in smart
cities. To this end, we propose the first survey that systematically reviews
the latest advancements in deep learning-based data fusion methods tailored for
urban computing. Specifically, we first delve into data perspective to
comprehend the role of each modality and data source. Secondly, we classify the
methodology into four primary categories: feature-based, alignment-based,
contrast-based, and generation-based fusion methods. Thirdly, we further
categorize multi-modal urban applications into seven types: urban planning,
transportation, economy, public safety, society, environment, and energy.
Compared with previous surveys, we focus more on the synergy of deep learning
methods with urban computing applications. Furthermore, we shed light on the
interplay between Large Language Models (LLMs) and urban computing, postulating
future research directions that could revolutionize the field. We firmly
believe that the taxonomy, progress, and prospects delineated in our survey
stand poised to significantly enrich the research community. The summary of the
comprehensive and up-to-date paper list can be found at
https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19350" title="Abstract">arXiv:2402.19350</a> [<a href="/pdf/2402.19350" title="Download PDF">pdf</a>, <a href="/format/2402.19350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Explicit and Implicit Knowledge for Multi-hop Question  Answering Based on Human Reading Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guangming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yunfei Long</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Cunjin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaxing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xia Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to
simulate human reasoning and inference processes, achieving proficient
performance in multi-hop QA. However, a gap persists between PLMs' reasoning
abilities and those of humans when tackling complex problems. Psychological
studies suggest a vital connection between explicit information in passages and
human prior knowledge during reading. Nevertheless, current research has given
insufficient attention to linking input passages and PLMs' pre-training-based
knowledge from the perspective of human cognition studies. In this study, we
introduce a \textbf{P}rompting \textbf{E}xplicit and \textbf{I}mplicit
knowledge (PEI) framework, which uses prompts to connect explicit and implicit
knowledge, aligning with human reading process for multi-hop QA. We consider
the input passages as explicit knowledge, employing them to elicit implicit
knowledge through unified prompt reasoning. Furthermore, our model incorporates
type-specific reasoning via prompts, a form of implicit knowledge. Experimental
results show that PEI performs comparably to the state-of-the-art on HotpotQA.
Ablation studies confirm the efficacy of our model in bridging and integrating
explicit and implicit knowledge.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19355" title="Abstract">arXiv:2402.19355</a> [<a href="/pdf/2402.19355" title="Download PDF">pdf</a>, <a href="/format/2402.19355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Adversarial Examples against Speaker Identification --  Techniques for Attack Detection and Victim Model Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sonal Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Thebaud%2C+T">Thomas Thebaud</a>, 
<a href="/search/cs?searchtype=author&query=Villalba%2C+J">Jes&#xfa;s Villalba</a>, 
<a href="/search/cs?searchtype=author&query=Dehak%2C+N">Najim Dehak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Adversarial examples have proven to threaten speaker identification systems,
and several countermeasures against them have been proposed. In this paper, we
propose a method to detect the presence of adversarial examples, i.e., a binary
classifier distinguishing between benign and adversarial examples. We build
upon and extend previous work on attack type classification by exploring new
architectures. Additionally, we introduce a method for identifying the victim
model on which the adversarial attack is carried out. To achieve this, we
generate a new dataset containing multiple attacks performed against various
victim models. We achieve an AUC of 0.982 for attack detection, with no more
than a 0.03 drop in performance for unknown attacks. Our attack classification
accuracy (excluding benign) reaches 86.48% across eight attack types using our
LightResNet34 architecture, while our victim model classification accuracy
reaches 72.28% across four victim models.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19361" title="Abstract">arXiv:2402.19361</a> [<a href="/pdf/2402.19361" title="Download PDF">pdf</a>, <a href="/format/2402.19361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermark Stealing in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jovanovi%C4%87%2C+N">Nikola Jovanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+R">Robin Staab</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">LLM watermarking has attracted attention as a promising way to detect
AI-generated content, with some works suggesting that current schemes may
already be fit for deployment. In this work we dispute this claim, identifying
watermark stealing (WS) as a fundamental vulnerability of these schemes. We
show that querying the API of the watermarked LLM to approximately
reverse-engineer a watermark enables practical spoofing attacks, as suggested
in prior work, but also greatly boosts scrubbing attacks, which was previously
unnoticed. We are the first to propose an automated WS algorithm and use it in
the first comprehensive study of spoofing and scrubbing in realistic settings.
We show that for under $50 an attacker can both spoof and scrub
state-of-the-art schemes previously considered safe, with average success rate
of over 80%. Our findings challenge common beliefs about LLM watermarking,
stressing the need for more robust schemes. We make all our code and additional
examples available at https://watermark-stealing.org.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19364" title="Abstract">arXiv:2402.19364</a> [<a href="/pdf/2402.19364" title="Download PDF">pdf</a>, <a href="/format/2402.19364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arrow Matrix Decomposition: A Novel Approach for Communication-Efficient  Sparse Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="/search/cs?searchtype=author&query=Ziogas%2C+A+N">Alexandros Nikolaos Ziogas</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Langwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luczynski%2C+P">Piotr Luczynski</a>, 
<a href="/search/cs?searchtype=author&query=Ashkboos%2C+S">Saleh Ashkboos</a>, 
<a href="/search/cs?searchtype=author&query=Scheidl%2C+F">Florian Scheidl</a>, 
<a href="/search/cs?searchtype=author&query=Carigiet%2C+A">Armon Carigiet</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chio Ge</a>, 
<a href="/search/cs?searchtype=author&query=Abubaker%2C+N">Nabil Abubaker</a>, 
<a href="/search/cs?searchtype=author&query=Besta%2C+M">Maciej Besta</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Nun%2C+T">Tal Ben-Nun</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PPoPP'24: Proceedings of the 29th ACM SIGPLAN Annual Symposium on
  Principles and Practice of Parallel Programming (2024) 404-416
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We propose a novel approach to iterated sparse matrix dense matrix
multiplication, a fundamental computational kernel in scientific computing and
graph neural network training. In cases where matrix sizes exceed the memory of
a single compute node, data transfer becomes a bottleneck. An approach based on
dense matrix multiplication algorithms leads to suboptimal scalability and
fails to exploit the sparsity in the problem. To address these challenges, we
propose decomposing the sparse matrix into a small number of highly structured
matrices called arrow matrices, which are connected by permutations. Our
approach enables communication-avoiding multiplications, achieving a polynomial
reduction in communication volume per iteration for matrices corresponding to
planar graphs and other minor-excluded families of graphs. Our evaluation
demonstrates that our approach outperforms a state-of-the-art method for sparse
matrix multiplication on matrices with hundreds of millions of rows, offering
near-linear strong and weak scaling.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19365" title="Abstract">arXiv:2402.19365</a> [<a href="/pdf/2402.19365" title="Download PDF">pdf</a>, <a href="/format/2402.19365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Efficient Computation of DiRe Committees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Relia%2C+K">Kunal Relia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> single-column format. 33 pages. 26 Figures. 6 Tables. 4 Algorithms. 4 Theorems. 9 Lemmas/Lemmata. 2 Observations. 14 Definitions. 2 Examples. Reducing inequality is easier than expected. P=NP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Consider a committee election consisting of (i) a set of candidates who are
divided into arbitrary groups each of size \emph{at most} two and a diversity
constraint that stipulates the selection of \emph{at least} one candidate from
each group and (ii) a set of voters who are divided into arbitrary populations
each approving \emph{at most} two candidates and a representation constraint
that stipulates the selection of \emph{at least} one candidate from each
population who has a non-null set of approved candidates.
<br />The DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the
minimum vertex cover problem on unweighted undirected graphs) concerns the
determination of the smallest size committee that satisfies the given
constraints. Here, for this problem, we discover an unconditional deterministic
polynomial-time algorithm that is an amalgamation of maximum matching,
breadth-first search, maximal matching, and local minimization.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19366" title="Abstract">arXiv:2402.19366</a> [<a href="/pdf/2402.19366" title="Download PDF">pdf</a>, <a href="/format/2402.19366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Exploring the Potential of Large Language Models for Improving  Digital Forensic Investigation Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wickramasekara%2C+A">Akila Wickramasekara</a>, 
<a href="/search/cs?searchtype=author&query=Breitinger%2C+F">Frank Breitinger</a>, 
<a href="/search/cs?searchtype=author&query=Scanlon%2C+M">Mark Scanlon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The growing number of cases requiring digital forensic analysis raises
concerns about law enforcement's ability to conduct investigations promptly.
Consequently, this systemisation of knowledge paper delves into the potential
and effectiveness of integrating Large Language Models (LLMs) into digital
forensic investigation to address these challenges. A thorough literature
review is undertaken, encompassing existing digital forensic models, tools,
LLMs, deep learning techniques, and the utilisation of LLMs in investigations.
The review identifies current challenges within existing digital forensic
processes and explores both the obstacles and possibilities of incorporating
LLMs. In conclusion, the study asserts that the adoption of LLMs in digital
forensics, with appropriate constraints, holds the potential to enhance
investigation efficiency, improve traceability, and alleviate technical and
judicial barriers faced by law enforcement entities.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19369" title="Abstract">arXiv:2402.19369</a> [<a href="/pdf/2402.19369" title="Download PDF">pdf</a>, <a href="/format/2402.19369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure Preserving Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haoye Lu</a>, 
<a href="/search/cs?searchtype=author&query=Szabados%2C+S">Spencer Szabados</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yaoliang Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion models have become the leading distribution-learning method in
recent years. Herein, we introduce structure-preserving diffusion processes, a
family of diffusion processes for learning distributions that possess
additional structure, such as group symmetries, by developing theoretical
conditions under which the diffusion transition steps preserve said symmetry.
While also enabling equivariant data sampling trajectories, we exemplify these
results by developing a collection of different symmetry equivariant diffusion
models capable of learning distributions that are inherently symmetric.
Empirical studies, over both synthetic and real-world datasets, are used to
validate the developed models adhere to the proposed theory and are capable of
achieving improved performance over existing methods in terms of sample
equality. We also show how the proposed models can be used to achieve
theoretically guaranteed equivariant image noise reduction without prior
knowledge of the image orientation.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19371" title="Abstract">arXiv:2402.19371</a> [<a href="/pdf/2402.19371" title="Download PDF">pdf</a>, <a href="/ps/2402.19371" title="Download PostScript">ps</a>, <a href="/format/2402.19371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenMedLM: Prompt engineering can out-perform fine-tuning in medical  question-answering with open-source large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maharjan%2C+J">Jenish Maharjan</a>, 
<a href="/search/cs?searchtype=author&query=Garikipati%2C+A">Anurag Garikipati</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+N+P">Navan Preet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Cyrus%2C+L">Leo Cyrus</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mayank Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Ciobanu%2C+M">Madalina Ciobanu</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+G">Gina Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+R">Rahul Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qingqing Mao</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R">Ritankar Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">LLMs have become increasingly capable at accomplishing a range of
specialized-tasks and can be utilized to expand equitable access to medical
knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging
specialized medical data and significant, thus costly, amounts of computational
power. Many of the top performing LLMs are proprietary and their access is
limited to very few research groups. However, open-source (OS) models represent
a key area of growth for medical LLMs due to significant improvements in
performance and an inherent ability to provide the transparency and compliance
required in healthcare. We present OpenMedLM, a prompting platform which
delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks.
We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks
(MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of
prompting strategies, including zero-shot, few-shot, chain-of-thought (random
selection and kNN selection), and ensemble/self-consistency voting. We found
that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks,
surpassing the previous best performing OS models that leveraged
computationally costly extensive fine-tuning. The model delivers a 72.6%
accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and
achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the
first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight
medical-specific emergent properties in OS LLMs which have not yet been
documented to date elsewhere, and showcase the benefits of further leveraging
prompt engineering to improve the performance of accessible LLMs for medical
applications.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19375" title="Abstract">arXiv:2402.19375</a> [<a href="/pdf/2402.19375" title="Download PDF">pdf</a>, <a href="/format/2402.19375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Internet Censorship: Analysing the Impact of Nation States&#x27;  Content Control Efforts on Internet Architecture and Routing Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levett%2C+J">Joshua Levett</a>, 
<a href="/search/cs?searchtype=author&query=Vassilakis%2C+V">Vassilios Vassilakis</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+P">Poonam Yadav</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Heightened interest from nation states to perform content censorship make it
evermore critical to identify the impact of censorship efforts on the Internet.
We undertake a study of Internet architecture, capturing the state of Internet
topology with greater completeness than existing state-of-the-art. We describe
our methodology for this, including the tooling we create to collect and
process data from a wide range of sources. We analyse this data to find key
patterns in nation states with higher censorship, discovering a funnelling
effect wherein higher Internet censorship effort is reflected in a constraining
effect on a state's Internet routing architecture. However, there are a small
number of nation states that do not follow this trend, for which we provide an
analysis and explanation, demonstrating a relationship between geographical
factors in addition to geopolitics. In summary, our work provides a deeper
understanding of how these censorship measures impact the overall functioning
and dynamics of the Internet.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19376" title="Abstract">arXiv:2402.19376</a> [<a href="/pdf/2402.19376" title="Download PDF">pdf</a>, <a href="/format/2402.19376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit  Design for DL Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+H">Harideep Nair</a>, 
<a href="/search/cs?searchtype=author&query=Vellaisamy%2C+P">Prabhu Vellaisamy</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tsung-Han Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Perry Wang</a>, 
<a href="/search/cs?searchtype=author&query=Blanton%2C+S">Shawn Blanton</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J+P">John Paul Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">General Matrix Multiply (GEMM) hardware, employing large arrays of
multiply-accumulate (MAC) units, perform bulk of the computation in deep
learning (DL). Recent trends have established 8-bit integer (INT8) as the most
widely used precision for DL inference. This paper proposes a novel MAC design
capable of dynamically exploiting bit sparsity (i.e., number of `0' bits within
a binary value) in input data to achieve significant improvements on area,
power and energy. The proposed architecture, called OzMAC (Omit-zero-MAC),
skips over zeros within a binary input value and performs simple
shift-and-add-based compute in place of expensive multipliers. We implement
OzMAC in SystemVerilog and present post-synthesis performance-power-area (PPA)
results using commercial TSMC N5 (5nm) process node. Using eight pretrained
INT8 deep neural networks (DNNs) as benchmarks, we demonstrate the existence of
high bit sparsity in real DNN workloads and show that 8-bit OzMAC improves all
three metrics of area, power, and energy significantly by 21%, 70%, and 28%,
respectively. Similar improvements are achieved when scaling data precisions
(4, 8, 16 bits) and clock frequencies (0.5 GHz, 1 GHz, 1.5 GHz). For the 8-bit
OzMAC, scaling its frequency to normalize the throughput relative to
conventional MAC, it still achieves 30% improvement on both power and energy.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19379" title="Abstract">arXiv:2402.19379</a> [<a href="/pdf/2402.19379" title="Download PDF">pdf</a>, <a href="/format/2402.19379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match  Human Crowd Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schoenegger%2C+P">Philipp Schoenegger</a>, 
<a href="/search/cs?searchtype=author&query=Tuminauskaite%2C+I">Indre Tuminauskaite</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+P+S">Peter S. Park</a>, 
<a href="/search/cs?searchtype=author&query=Tetlock%2C+P+E">Philip E. Tetlock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages; 13 visualizations (nine figures, four tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Human forecasting accuracy in practice relies on the 'wisdom of the crowd'
effect, in which predictions about future events are significantly improved by
aggregating across a crowd of individual forecasters. Past work on the
forecasting ability of large language models (LLMs) suggests that frontier
LLMs, as individual forecasters, underperform compared to the gold standard of
a human crowd forecasting tournament aggregate. In Study 1, we expand this
research by using an LLM ensemble approach consisting of a crowd of twelve
LLMs. We compare the aggregated LLM predictions on 31 binary questions to that
of a crowd of 925 human forecasters from a three-month forecasting tournament.
Our main analysis shows that the LLM crowd outperforms a simple no-information
benchmark and is statistically equivalent to the human crowd. We also observe
an acquiescence effect, with mean model predictions being significantly above
50%, despite an almost even split of positive and negative resolutions.
Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2)
can be improved by drawing on human cognitive output. We find that both models'
forecasting accuracy benefits from exposure to the median human prediction as
information, improving accuracy by between 17% and 28%: though this leads to
less accurate predictions than simply averaging human and machine forecasts.
Our results suggest that LLMs can achieve forecasting accuracy rivaling that of
human crowd forecasting tournaments: via the simple, practically applicable
method of forecast aggregation. This replicates the 'wisdom of the crowd'
effect for LLMs, and opens up their use for a variety applications throughout
society.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19381" title="Abstract">arXiv:2402.19381</a> [<a href="/pdf/2402.19381" title="Download PDF">pdf</a>, <a href="/format/2402.19381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Bayesian Framework for Inverse Heat Transfer Problems Using  Reduced Order Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bakhshaei%2C+K">Kabir Bakhshaei</a>, 
<a href="/search/math?searchtype=author&query=Morelli%2C+U+E">Umberto Emil Morelli</a>, 
<a href="/search/math?searchtype=author&query=Stabile%2C+G">Giovanni Stabile</a>, 
<a href="/search/math?searchtype=author&query=Rozza%2C+G">Gianluigi Rozza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A stochastic inverse heat transfer problem is formulated to infer the
transient heat flux, treated as an unknown Neumann boundary condition.
Therefore, an Ensemble-based Simultaneous Input and State Filtering as a Data
Assimilation technique is utilized for simultaneous temperature distribution
prediction and heat flux estimation. This approach is incorporated with Radial
Basis Functions not only to lessen the size of unknown inputs but also to
mitigate the computational burden of this technique. The procedure applies to
the specific case of a mold used in Continuous Casting machinery, and it is
based on the sequential availability of temperature provided by thermocouples
inside the mold. Our research represents a significant contribution to
achieving probabilistic boundary condition estimation in real-time handling
with noisy measurements and errors in the model. We additionally demonstrate
the procedure's dependence on some hyperparameters that are not documented in
the existing literature. Accurate real-time prediction of the heat flux is
imperative for the smooth operation of Continuous Casting machinery at the
boundary region where the Continuous Casting mold and the molten steel meet
which is not also physically measurable. Thus, this paves the way for efficient
real-time monitoring and control, which is critical for preventing caster
shutdowns.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19385" title="Abstract">arXiv:2402.19385</a> [<a href="/pdf/2402.19385" title="Download PDF">pdf</a>, <a href="/format/2402.19385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe and Reliable Autonomous Driving: Dynamic Occupancy Set  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenbo Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiahui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the rapidly evolving field of autonomous driving, accurate trajectory
prediction is pivotal for vehicular safety. However, trajectory predictions
often deviate from actual paths, particularly in complex and challenging
environments, leading to significant errors. To address this issue, our study
introduces a novel method for Dynamic Occupancy Set (DOS) prediction, enhancing
trajectory prediction capabilities. This method effectively combines advanced
trajectory prediction networks with a DOS prediction module, overcoming the
shortcomings of existing models. It provides a comprehensive and adaptable
framework for predicting the potential occupancy sets of traffic participants.
The main contributions of this research include: 1) A novel DOS prediction
model tailored for complex scenarios, augmenting traditional trajectory
prediction; 2) The development of unique DOS representations and evaluation
metrics; 3) Extensive validation through experiments, demonstrating enhanced
performance and adaptability. This research contributes to the advancement of
safer and more efficient intelligent vehicle and transportation systems.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19401" title="Abstract">arXiv:2402.19401</a> [<a href="/pdf/2402.19401" title="Download PDF">pdf</a>, <a href="/format/2402.19401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Visually-Continuous Corruption Robustness of Neural Networks  Relative to Human Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huakun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B+C">Boyue Caroline Hu</a>, 
<a href="/search/cs?searchtype=author&query=Czarnecki%2C+K">Krzysztof Czarnecki</a>, 
<a href="/search/cs?searchtype=author&query=Marsso%2C+L">Lina Marsso</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+M">Marsha Chechik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While Neural Networks (NNs) have surpassed human accuracy in image
classification on ImageNet, they often lack robustness against image
corruption, i.e., corruption robustness. Yet such robustness is seemingly
effortless for human perception. In this paper, we propose visually-continuous
corruption robustness (VCR) -- an extension of corruption robustness to allow
assessing it over the wide and continuous range of changes that correspond to
the human perceptive quality (i.e., from the original image to the full
distortion of all perceived visual information), along with two novel
human-aware metrics for NN evaluation. To compare VCR of NNs with human
perception, we conducted extensive experiments on 14 commonly used image
corruptions with 7,718 human participants and state-of-the-art robust NN models
with different training objectives (e.g., standard, adversarial, corruption
robustness), different architectures (e.g., convolution NNs, vision
transformers), and different amounts of training data augmentation. Our study
showed that: 1) assessing robustness against continuous corruption can reveal
insufficient robustness undetected by existing benchmarks; as a result, 2) the
gap between NN and human robustness is larger than previously known; and
finally, 3) some image corruptions have a similar impact on human perception,
offering opportunities for more cost-effective robustness assessments. Our
validation set with 14 image corruptions, human robustness data, and the
evaluation code is provided as a toolbox and a benchmark.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19402" title="Abstract">arXiv:2402.19402</a> [<a href="/pdf/2402.19402" title="Download PDF">pdf</a>, <a href="/format/2402.19402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scalable and Transferable Time Series Prediction Framework for Demand  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Young-Jin Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Odermatt%2C+F">Fr&#xe9;d&#xe9;ric Odermatt</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyung-Min Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a full paper at ICDM 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time series forecasting is one of the most essential and ubiquitous tasks in
many business problems, including demand forecasting and logistics
optimization. Traditional time series forecasting methods, however, have
resulted in small models with limited expressive power because they have
difficulty in scaling their model size up while maintaining high accuracy. In
this paper, we propose Forecasting orchestra (Forchestra), a simple but
powerful framework capable of accurately predicting future demand for a diverse
range of items. We empirically demonstrate that the model size is scalable to
up to 0.8 billion parameters. The proposed method not only outperforms existing
forecasting models with a significant margin, but it could generalize well to
unseen data points when evaluated in a zero-shot fashion on downstream
datasets. Last but not least, we present extensive qualitative and quantitative
studies to analyze how the proposed model outperforms baseline models and
differs from conventional approaches. The original paper was presented as a
full paper at ICDM 2022 and is available at:
https://ieeexplore.ieee.org/document/10027662.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19404" title="Abstract">arXiv:2402.19404</a> [<a href="/pdf/2402.19404" title="Download PDF">pdf</a>, <a href="/format/2402.19404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entity-Aware Multimodal Alignment Framework for News Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">News image captioning task is a variant of image captioning task which
requires model to generate a more informative caption with news image and the
associated news article. Multimodal Large Language models have developed
rapidly in recent years and is promising in news image captioning task.
However, according to our experiments, common MLLMs are not good at generating
the entities in zero-shot setting. Their abilities to deal with the entities
information are still limited after simply fine-tuned on news image captioning
dataset. To obtain a more powerful model to handle the multimodal entity
information, we design two multimodal entity-aware alignment tasks and an
alignment framework to align the model and generate the news image captions.
Our method achieves better results than previous state-of-the-art models in
CIDEr score (72.33 -&gt; 86.29) on GoodNews dataset and (70.83 -&gt; 85.61) on
NYTimes800k dataset.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19405" title="Abstract">arXiv:2402.19405</a> [<a href="/pdf/2402.19405" title="Download PDF">pdf</a>, <a href="/format/2402.19405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Hallucinations for Reasoning of Unintentional Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grover%2C+S">Shresth Grover</a>, 
<a href="/search/cs?searchtype=author&query=Vineet%2C+V">Vibhav Vineet</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+Y+S">Yogesh S Rawat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work we present a novel task of understanding unintentional human
activities in videos. We formalize this problem as a reasoning task under
zero-shot scenario, where given a video of an unintentional activity we want to
know why it transitioned from intentional to unintentional. We first evaluate
the effectiveness of current state-of-the-art Large Multimodal Models on this
reasoning task and observe that they suffer from hallucination. We further
propose a novel prompting technique,termed as Dream of Thoughts (DoT), which
allows the model to navigate through hallucinated thoughts to achieve better
reasoning. To evaluate the performance on this task, we also introduce three
different specialized metrics designed to quantify the models reasoning
capability. We perform our experiments on two different datasets, OOPs and
UCF-Crimes, and our findings show that DOT prompting technique is able to
outperform standard prompting, while minimizing hallucinations.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19406" title="Abstract">arXiv:2402.19406</a> [<a href="/pdf/2402.19406" title="Download PDF">pdf</a>, <a href="/format/2402.19406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Scaling Laws of Geographical Representation in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godey%2C+N">Nathan Godey</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Clergerie%2C+%C3%89">&#xc9;ric de la Clergerie</a>, 
<a href="/search/cs?searchtype=author&query=Sagot%2C+B">Beno&#xee;t Sagot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Language models have long been shown to embed geographical information in
their hidden representations. This line of work has recently been revisited by
extending this result to Large Language Models (LLMs). In this paper, we
propose to fill the gap between well-established and recent literature by
observing how geographical knowledge evolves when scaling language models. We
show that geographical knowledge is observable even for tiny models, and that
it scales consistently as we increase the model size. Notably, we observe that
larger language models cannot mitigate the geographical bias that is inherent
to the training data.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19407" title="Abstract">arXiv:2402.19407</a> [<a href="/pdf/2402.19407" title="Download PDF">pdf</a>, <a href="/format/2402.19407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MENTOR: Multi-level Self-supervised Learning for Multimodal  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinze Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hewei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ngai%2C+E+C+-">Edith C.-H. Ngai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With the increasing multimedia information, multimodal recommendation has
received extensive attention. It utilizes multimodal information to alleviate
the data sparsity problem in recommendation systems, thus improving
recommendation accuracy. However, the reliance on labeled data severely limits
the performance of multimodal recommendation models. Recently, self-supervised
learning has been used in multimodal recommendations to mitigate the label
sparsity problem. Nevertheless, the state-of-the-art methods cannot avoid the
modality noise when aligning multimodal information due to the large
differences in the distributions of different modalities. To this end, we
propose a Multi-level sElf-supervised learNing for mulTimOdal Recommendation
(MENTOR) method to address the label sparsity problem and the modality
alignment problem. Specifically, MENTOR first enhances the specific features of
each modality using the graph convolutional network (GCN) and fuses the visual
and textual modalities. It then enhances the item representation via the item
semantic graph for all modalities, including the fused modality. Then, it
introduces two multilevel self-supervised tasks: the multilevel cross-modal
alignment task and the general feature enhancement task. The multilevel
cross-modal alignment task aligns each modality under the guidance of the ID
embedding from multiple levels while maintaining the historical interaction
information. The general feature enhancement task enhances the general feature
from both the graph and feature perspectives to improve the robustness of our
model. Extensive experiments on three publicly available datasets demonstrate
the effectiveness of our method. Our code is publicly available at
https://github.com/Jinfeng-Xu/MENTOR.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19410" title="Abstract">arXiv:2402.19410</a> [<a href="/pdf/2402.19410" title="Download PDF">pdf</a>, <a href="/format/2402.19410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genie: Smart ROS-based Caching for Connected Autonomous Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexin Li</a>, 
<a href="/search/cs?searchtype=author&query=Bateni%2C+S">Soroush Bateni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IROS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Despite the promising future of autonomous robots, several key issues
currently remain that can lead to compromised performance and safety. One such
issue is latency, where we find that even the latest embedded platforms from
NVIDIA fail to execute intelligence tasks (e.g., object detection) of
autonomous vehicles in a real-time fashion. One remedy to this problem is the
promising paradigm of edge computing. Through collaboration with our industry
partner, we identify key prohibitive limitations of the current edge mindset:
(1) servers are not distributed enough and thus, are not close enough to
vehicles, (2) current proposed edge solutions do not provide substantially
better performance and extra information specific to autonomous vehicles to
warrant their cost to the user, and (3) the state-of-the-art solutions are not
compatible with popular frameworks used in autonomous systems, particularly the
Robot Operating System (ROS).
<br />To remedy these issues, we provide Genie, an encapsulation technique that can
enable transparent caching in ROS in a non-intrusive way (i.e., without
modifying the source code), can build the cache in a distributed manner (in
contrast to traditional central caching methods), and can construct a
collective three-dimensional object map to provide substantially better latency
(even on low-power edge servers) and higher quality data to all vehicles in a
certain locality. We fully implement our design on state-of-the-art
industry-adopted embedded and edge platforms, using the prominent autonomous
driving software Autoware, and find that Genie can enhance the latency of
Autoware Vision Detector by 82% on average, enable object reusability 31% of
the time on average and as much as 67% for the incoming requests, and boost the
confidence in its object map considerably over time.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19411" title="Abstract">arXiv:2402.19411</a> [<a href="/pdf/2402.19411" title="Download PDF">pdf</a>, <a href="/ps/2402.19411" title="Download PostScript">ps</a>, <a href="/format/2402.19411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaECTER: Patent-level Representation Learning using Citation-informed  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+M">Mainak Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Erhardt%2C+S">Sebastian Erhardt</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+M+E">Michael E. Rose</a>, 
<a href="/search/cs?searchtype=author&query=Buunk%2C+E">Erik Buunk</a>, 
<a href="/search/cs?searchtype=author&query=Harhoff%2C+D">Dietmar Harhoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">PaECTER is a publicly available, open-source document-level encoder specific
for patents. We fine-tune BERT for Patents with examiner-added citation
information to generate numerical representations for patent documents. PaECTER
performs better in similarity tasks than current state-of-the-art models used
in the patent domain. More specifically, our model outperforms the next-best
patent specific pre-trained language model (BERT for Patents) on our patent
citation prediction test dataset on two different rank evaluation metrics.
PaECTER predicts at least one most similar patent at a rank of 1.32 on average
when compared against 25 irrelevant patents. Numerical representations
generated by PaECTER from patent text can be used for downstream tasks such as
classification, tracing knowledge flows, or semantic similarity search.
Semantic similarity search is especially relevant in the context of prior art
search for both inventors and patent examiners. PaECTER is available on Hugging
Face.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19414" title="Abstract">arXiv:2402.19414</a> [<a href="/pdf/2402.19414" title="Download PDF">pdf</a>, <a href="/ps/2402.19414" title="Download PostScript">ps</a>, <a href="/format/2402.19414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Networks Representation and Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zafarani%2C+R">Reza Zafarani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Network data has become widespread, larger, and more complex over the years.
Traditional network data is dyadic, capturing the relations among pairs of
entities. With the need to model interactions among more than two entities,
significant research has focused on higher-order networks and ways to
represent, analyze, and learn from them. There are two main directions to
studying higher-order networks. One direction has focused on capturing
higher-order patterns in traditional (dyadic) graphs by changing the basic unit
of study from nodes to small frequently observed subgraphs, called motifs. As
most existing network data comes in the form of pairwise dyadic relationships,
studying higher-order structures within such graphs may uncover new insights.
The second direction aims to directly model higher-order interactions using new
and more complex representations such as simplicial complexes or hypergraphs.
Some of these models have long been proposed, but improvements in computational
power and the advent of new computational techniques have increased their
popularity. Our goal in this paper is to provide a succinct yet comprehensive
summary of the advanced higher-order network analysis techniques. We provide a
systematic review of its foundations and algorithms, along with use cases and
applications of higher-order networks in various scientific domains.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19416" title="Abstract">arXiv:2402.19416</a> [<a href="/pdf/2402.19416" title="Download PDF">pdf</a>, <a href="/format/2402.19416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Radio Experimental Infrastructure Architecture Towards 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teixeira%2C+F+B">Filipe B. Teixeira</a>, 
<a href="/search/cs?searchtype=author&query=Ricardo%2C+M">Manuel Ricardo</a>, 
<a href="/search/cs?searchtype=author&query=Coelho%2C+A">Andr&#xe9; Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+H+P">H&#xe9;lder P. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Viana%2C+P">Paula Viana</a>, 
<a href="/search/cs?searchtype=author&query=Paulino%2C+N">Nuno Paulino</a>, 
<a href="/search/cs?searchtype=author&query=Fontes%2C+H">Helder Fontes</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+P">Paulo Marques</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Rui Campos</a>, 
<a href="/search/cs?searchtype=author&query=Pessoa%2C+L+M">Luis M. Pessoa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Telecommunications and computer vision have evolved separately so far. Yet,
with the shift to sub-terahertz (sub-THz) and terahertz (THz) radio
communications, there is an opportunity to explore computer vision technologies
together with radio communications, considering the dependency of both
technologies on Line of Sight. The combination of radio sensing and computer
vision can address challenges such as obstructions and poor lighting. Also,
machine learning algorithms, capable of processing multimodal data, play a
crucial role in deriving insights from raw and low-level sensing data, offering
a new level of abstraction that can enhance various applications and use cases
such as beamforming and terminal handovers.
<br />This paper introduces CONVERGE, a pioneering vision-radio paradigm that
bridges this gap by leveraging Integrated Sensing and Communication (ISAC) to
facilitate a dual "View-to-Communicate, Communicate-to-View" approach. CONVERGE
offers tools that merge wireless communications and computer vision,
establishing a novel Research Infrastructure (RI) that will be open to the
scientific community and capable of providing open datasets. This new
infrastructure will support future research in 6G and beyond concerning
multiple verticals, such as telecommunications, automotive, manufacturing,
media, and health.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19420" title="Abstract">arXiv:2402.19420</a> [<a href="/pdf/2402.19420" title="Download PDF">pdf</a>, <a href="/format/2402.19420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Iterative Combinatorial Auction Designs via Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=d%27Eon%2C+G">Greg d&#x27;Eon</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+N">Neil Newman</a>, 
<a href="/search/cs?searchtype=author&query=Leyton-Brown%2C+K">Kevin Leyton-Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages (body) + 10 pages (acknowledgements, references, appendices)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Iterative combinatorial auctions are widely used in high stakes settings such
as spectrum auctions. Such auctions can be hard to understand analytically,
making it difficult for bidders to determine how to behave and for designers to
optimize auction rules to ensure desirable outcomes such as high revenue or
welfare. In this paper, we investigate whether multi-agent reinforcement
learning (MARL) algorithms can be used to understand iterative combinatorial
auctions, given that these algorithms have recently shown empirical success in
several other domains. We find that MARL can indeed benefit auction analysis,
but that deploying it effectively is nontrivial. We begin by describing
modelling decisions that keep the resulting game tractable without sacrificing
important features such as imperfect information or asymmetry between bidders.
We also discuss how to navigate pitfalls of various MARL algorithms, how to
overcome challenges in verifying convergence, and how to generate and interpret
multiple equilibria. We illustrate the promise of our resulting approach by
using it to evaluate a specific rule change to a clock auction, finding
substantially different auction outcomes due to complex changes in bidders'
behavior.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19421" title="Abstract">arXiv:2402.19421</a> [<a href="/pdf/2402.19421" title="Download PDF">pdf</a>, <a href="/format/2402.19421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based  Search Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lijia Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingchen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yong Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 2 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)

</div>
<p class="mathjax">In the domain of digital information dissemination, search engines act as
pivotal conduits linking information seekers with providers. The advent of
chat-based search engines utilizing Large Language Models (LLMs) and Retrieval
Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary
leap in the search ecosystem. They demonstrate metacognitive abilities in
interpreting web information and crafting responses with human-like
understanding and creativity. Nonetheless, the intricate nature of LLMs renders
their "cognitive" processes opaque, challenging even their designers'
understanding. This research aims to dissect the mechanisms through which an
LLM-powered chat-based search engine, specifically Bing Chat, selects
information sources for its responses. To this end, an extensive dataset has
been compiled through engagements with New Bing, documenting the websites it
cites alongside those listed by the conventional search engine. Employing
natural language processing (NLP) techniques, the research reveals that Bing
Chat exhibits a preference for content that is not only readable and formally
structured, but also demonstrates lower perplexity levels, indicating a unique
inclination towards text that is predictable by the underlying LLM. Further
enriching our analysis, we procure an additional dataset through interactions
with the GPT-4 based knowledge retrieval API, unveiling a congruent text
preference between the RAG API and Bing Chat. This consensus suggests that
these text preferences intrinsically emerge from the underlying language
models, rather than being explicitly crafted by Bing Chat's developers.
Moreover, our investigation documents a greater similarity among websites cited
by RAG technologies compared to those ranked highest by conventional search
engines.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19422" title="Abstract">arXiv:2402.19422</a> [<a href="/pdf/2402.19422" title="Download PDF">pdf</a>, <a href="/format/2402.19422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEM: Prototype-based Efficient MaskFormer for Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cavagnero%2C+N">Niccol&#xf2; Cavagnero</a>, 
<a href="/search/cs?searchtype=author&query=Rosi%2C+G">Gabriele Rosi</a>, 
<a href="/search/cs?searchtype=author&query=Ruttano%2C+C">Claudia Ruttano</a>, 
<a href="/search/cs?searchtype=author&query=Pistilli%2C+F">Francesca Pistilli</a>, 
<a href="/search/cs?searchtype=author&query=Ciccone%2C+M">Marco Ciccone</a>, 
<a href="/search/cs?searchtype=author&query=Averta%2C+G">Giuseppe Averta</a>, 
<a href="/search/cs?searchtype=author&query=Cermelli%2C+F">Fabio Cermelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent transformer-based architectures have shown impressive results in the
field of image segmentation. Thanks to their flexibility, they obtain
outstanding performance in multiple segmentation tasks, such as semantic and
panoptic, under a single unified framework. To achieve such impressive
performance, these architectures employ intensive operations and require
substantial computational resources, which are often not available, especially
on edge devices. To fill this gap, we propose Prototype-based Efficient
MaskFormer (PEM), an efficient transformer-based architecture that can operate
in multiple segmentation tasks. PEM proposes a novel prototype-based
cross-attention which leverages the redundancy of visual features to restrict
the computation and improve the efficiency without harming the performance. In
addition, PEM introduces an efficient multi-scale feature pyramid network,
capable of extracting features that have high semantic content in an efficient
way, thanks to the combination of deformable convolutions and context-based
self-modulation. We benchmark the proposed PEM architecture on two tasks,
semantic and panoptic segmentation, evaluated on two different datasets,
Cityscapes and ADE20K. PEM demonstrates outstanding performance on every task
and dataset, outperforming task-specific architectures while being comparable
and even better than computationally-expensive baselines.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19423" title="Abstract">arXiv:2402.19423</a> [<a href="/pdf/2402.19423" title="Download PDF">pdf</a>, <a href="/format/2402.19423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging AI Predicted and Expert Revised Annotations in Interactive  Segmentation: Continual Tuning or Full Training?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiezheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chongyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zongwei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Symposium on Biomedical Imaging (ISBI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interactive segmentation, an integration of AI algorithms and human
expertise, premises to improve the accuracy and efficiency of curating
large-scale, detailed-annotated datasets in healthcare. Human experts revise
the annotations predicted by AI, and in turn, AI improves its predictions by
learning from these revised annotations. This interactive process continues to
enhance the quality of annotations until no major revision is needed from
experts. The key challenge is how to leverage AI predicted and expert revised
annotations to iteratively improve the AI. Two problems arise: (1) The risk of
catastrophic forgetting--the AI tends to forget the previously learned classes
if it is only retrained using the expert revised classes. (2) Computational
inefficiency when retraining the AI using both AI predicted and expert revised
annotations; moreover, given the dominant AI predicted annotations in the
dataset, the contribution of newly revised annotations--often account for a
very small fraction--to the AI training remains marginal. This paper proposes
Continual Tuning to address the problems from two perspectives: network design
and data reuse. Firstly, we design a shared network for all classes followed by
class-specific networks dedicated to individual classes. To mitigate
forgetting, we freeze the shared network for previously learned classes and
only update the class-specific network for revised classes. Secondly, we reuse
a small fraction of data with previous annotations to avoid over-computing. The
selection of such data relies on the importance estimate of each data. The
importance score is computed by combining the uncertainty and consistency of AI
predictions. Our experiments demonstrate that Continual Tuning achieves a speed
16x greater than repeatedly training AI from scratch without compromising the
performance.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19427" title="Abstract">arXiv:2402.19427</a> [<a href="/pdf/2402.19427" title="Download PDF">pdf</a>, <a href="/format/2402.19427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Griffin: Mixing Gated Linear Recurrences with Local Attention for  Efficient Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De%2C+S">Soham De</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S+L">Samuel L. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+A">Anushan Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Botev%2C+A">Aleksandar Botev</a>, 
<a href="/search/cs?searchtype=author&query=Cristian-Muraru%2C+G">George Cristian-Muraru</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Albert Gu</a>, 
<a href="/search/cs?searchtype=author&query=Haroun%2C+R">Ruba Haroun</a>, 
<a href="/search/cs?searchtype=author&query=Berrada%2C+L">Leonard Berrada</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yutian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Srivatsan Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Desjardins%2C+G">Guillaume Desjardins</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>, 
<a href="/search/cs?searchtype=author&query=Budden%2C+D">David Budden</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+Y+W">Yee Whye Teh</a>, 
<a href="/search/cs?searchtype=author&query=Pascanu%2C+R">Razvan Pascanu</a>, 
<a href="/search/cs?searchtype=author&query=De+Freitas%2C+N">Nando De Freitas</a>, 
<a href="/search/cs?searchtype=author&query=Gulcehre%2C+C">Caglar Gulcehre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recurrent neural networks (RNNs) have fast inference and scale efficiently on
long sequences, but they are difficult to train and hard to scale. We propose
Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that
mixes gated linear recurrences with local attention. Hawk exceeds the reported
performance of Mamba on downstream tasks, while Griffin matches the performance
of Llama-2 despite being trained on over 6 times fewer tokens. We also show
that Griffin can extrapolate on sequences significantly longer than those seen
during training. Our models match the hardware efficiency of Transformers
during training, and during inference they have lower latency and significantly
higher throughput. We scale Griffin up to 14B parameters, and explain how to
shard our models for efficient distributed training.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19431" title="Abstract">arXiv:2402.19431</a> [<a href="/pdf/2402.19431" title="Download PDF">pdf</a>, <a href="/format/2402.19431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional API Recommendation for Library-Oriented Code Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zexiong Ma</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Shengnan An</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Bing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zeqi Lin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 32nd IEEE/ACM International Conference on Program Comprehension
  (ICPC 2024), Apr 2024, Lisboa, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have achieved exceptional performance in code
generation. However, the performance remains unsatisfactory in generating
library-oriented code, especially for the libraries not present in the training
data of LLMs. Previous work utilizes API recommendation technology to help LLMs
use libraries: it retrieves APIs related to the user requirements, then
leverages them as context to prompt LLMs. However, developmental requirements
can be coarse-grained, requiring a combination of multiple fine-grained APIs.
This granularity inconsistency makes API recommendation a challenging task. To
address this, we propose CAPIR (Compositional API Recommendation), which adopts
a "divide-and-conquer" strategy to recommend APIs for coarse-grained
requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down
a coarse-grained task description into several detailed subtasks. Then, CAPIR
applies an embedding-based Retriever to identify relevant APIs corresponding to
each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out
redundant APIs and provides the final recommendation. To facilitate the
evaluation of API recommendation methods on coarse-grained requirements, we
present two challenging benchmarks, RAPID (Recommend APIs based on
Documentation) and LOCG (Library-Oriented Code Generation). Experimental
results on these benchmarks, demonstrate the effectiveness of CAPIR in
comparison to existing baselines. Specifically, on RAPID's Torchdata-AR
dataset, compared to the state-of-the-art API recommendation approach, CAPIR
improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On
LOCG's Torchdata-Code dataset, compared to code generation without API
recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19432" title="Abstract">arXiv:2402.19432</a> [<a href="/pdf/2402.19432" title="Download PDF">pdf</a>, <a href="/format/2402.19432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing the Limits of Cross-Embodiment Learning for Manipulation and  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jonathan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Glossop%2C+C">Catherine Glossop</a>, 
<a href="/search/cs?searchtype=author&query=Bhorkar%2C+A">Arjun Bhorkar</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recent years in robotics and imitation learning have shown remarkable
progress in training large-scale foundation models by leveraging data across a
multitude of embodiments. The success of such policies might lead us to wonder:
just how diverse can the robots in the training set be while still facilitating
positive transfer? In this work, we study this question in the context of
heterogeneous embodiments, examining how even seemingly very different domains,
such as robotic navigation and manipulation, can provide benefits when included
in the training data for the same model. We train a single goal-conditioned
policy that is capable of controlling robotic arms, quadcopters, quadrupeds,
and mobile bases. We then investigate the extent to which transfer can occur
across navigation and manipulation on these embodiments by framing them as a
single goal-reaching task. We find that co-training with navigation data can
enhance robustness and performance in goal-conditioned manipulation with a
wrist-mounted camera. We then deploy our policy trained only from
navigation-only and static manipulation-only data on a mobile manipulator,
showing that it can control a novel embodiment in a zero-shot manner. These
results provide evidence that large-scale robotic policies can benefit from
data collected across various embodiments. Further information and robot videos
can be found on our project website <a href="http://extreme-cross-embodiment.github.io.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19434" title="Abstract">arXiv:2402.19434</a> [<a href="/pdf/2402.19434" title="Download PDF">pdf</a>, <a href="/format/2402.19434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin Aided Massive MIMO: CSI Compression and Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuaifeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICC 2024. Dataset and code files will be available soon on the DeepMIMO website <a href="https://www.deepmimo.net/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Deep learning (DL) approaches have demonstrated high performance in
compressing and reconstructing the channel state information (CSI) and reducing
the CSI feedback overhead in massive MIMO systems. One key challenge, however,
with the DL approaches is the demand for extensive training data. Collecting
this real-world CSI data incurs significant overhead that hinders the DL
approaches from scaling to a large number of communication sites. To address
this challenge, we propose a novel direction that utilizes site-specific
\textit{digital twins} to aid the training of DL models. The proposed digital
twin approach generates site-specific synthetic CSI data from the EM 3D model
and ray tracing, which can then be used to train the DL model without
real-world data collection. To further improve the performance, we adopt online
data selection to refine the DL model training with a small real-world CSI
dataset. Results show that a DL model trained solely on the digital twin data
can achieve high performance when tested in a real-world deployment. Further,
leveraging domain adaptation techniques, the proposed approach requires orders
of magnitude less real-world data to approach the same performance of the model
trained completely on a real-world CSI dataset.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19437" title="Abstract">arXiv:2402.19437</a> [<a href="/pdf/2402.19437" title="Download PDF">pdf</a>, <a href="/ps/2402.19437" title="Download PostScript">ps</a>, <a href="/format/2402.19437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Worst-group Risk Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bassily%2C+R">Raef Bassily</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We initiate a systematic study of worst-group risk minimization under
$(\epsilon, \delta)$-differential privacy (DP). The goal is to privately find a
model that approximately minimizes the maximal risk across $p$ sub-populations
(groups) with different distributions, where each group distribution is
accessed via a sample oracle. We first present a new algorithm that achieves
excess worst-group population risk of $\tilde{O}(\frac{p\sqrt{d}}{K\epsilon} +
\sqrt{\frac{p}{K}})$, where $K$ is the total number of samples drawn from all
groups and $d$ is the problem dimension. Our rate is nearly optimal when each
distribution is observed via a fixed-size dataset of size $K/p$. Our result is
based on a new stability-based analysis for the generalization error. In
particular, we show that $\Delta$-uniform argument stability implies
$\tilde{O}(\Delta + \frac{1}{\sqrt{n}})$ generalization error w.r.t. the
worst-group risk, where $n$ is the number of samples drawn from each sample
oracle. Next, we propose an algorithmic framework for worst-group population
risk minimization using any DP online convex optimization algorithm as a
subroutine. Hence, we give another excess risk bound of $\tilde{O}\left(
\sqrt{\frac{d^{1/2}}{\epsilon K}} +\sqrt{\frac{p}{K\epsilon^2}} \right)$.
Assuming the typical setting of $\epsilon=\Theta(1)$, this bound is more
favorable than our first bound in a certain range of $p$ as a function of $K$
and $d$. Finally, we study differentially private worst-group empirical risk
minimization in the offline setting, where each group distribution is observed
by a fixed-size dataset. We present a new algorithm with nearly optimal excess
risk of $\tilde{O}(\frac{p\sqrt{d}}{K\epsilon})$.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19441" title="Abstract">arXiv:2402.19441</a> [<a href="/pdf/2402.19441" title="Download PDF">pdf</a>, <a href="/ps/2402.19441" title="Download PostScript">ps</a>, <a href="/format/2402.19441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Gaussian Model for Animation and Texturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+E">Xiangzhi Eric Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sin%2C+Z+P+T">Zackary P. T. Sin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">3D Gaussian Splatting has made a marked impact on neural rendering by
achieving impressive fidelity and performance. Despite this achievement,
however, it is not readily applicable to developing interactive applications.
Real-time applications like XR apps and games require functions such as
animation, UV-mapping, and model editing simultaneously manipulated through the
usage of a 3D model. We propose a modeling that is analogous to typical 3D
models, which we call 3D Gaussian Model (3DGM); it provides a manipulatable
proxy for novel animation and texture transfer. By binding the 3D Gaussians in
texture space and re-projecting them back to world space through implicit shell
mapping, we show how our 3D modeling can serve as a valid rendering methodology
for interactive applications. It is further noted that recently, 3D mesh
reconstruction works have been able to produce high-quality mesh for rendering.
Our work, on the other hand, only requires an approximated geometry for
rendering an object in high fidelity. Applicationwise, we will show that our
proxy-based 3DGM is capable of driving novel animation without animated
training data and texture transferring via UV mapping of the 3D Gaussians. We
believe the result indicates the potential of our work for enabling interactive
applications for 3D Gaussian Splatting.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19442" title="Abstract">arXiv:2402.19442</a> [<a href="/pdf/2402.19442" title="Download PDF">pdf</a>, <a href="/format/2402.19442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Dynamics of Multi-Head Softmax Attention for In-Context  Learning: Emergence, Convergence, and Optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sheen%2C+H">Heejune Sheen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 141 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the dynamics of gradient flow for training a multi-head softmax
attention model for in-context learning of multi-task linear regression. We
establish the global convergence of gradient flow under suitable choices of
initialization. In addition, we prove that an interesting "task allocation"
phenomenon emerges during the gradient flow dynamics, where each attention head
focuses on solving a single task of the multi-task model. Specifically, we
prove that the gradient flow dynamics can be split into three phases -- a
warm-up phase where the loss decreases rather slowly and the attention heads
gradually build up their inclination towards individual tasks, an emergence
phase where each head selects a single task and the loss rapidly decreases, and
a convergence phase where the attention parameters converge to a limit.
Furthermore, we prove the optimality of gradient flow in the sense that the
limiting model learned by gradient flow is on par with the best possible
multi-head softmax attention model up to a constant factor. Our analysis also
delineates a strict separation in terms of the prediction accuracy of ICL
between single-head and multi-head attention models. The key technique for our
convergence analysis is to map the gradient flow dynamics in the parameter
space to a set of ordinary differential equations in the spectral domain, where
the relative magnitudes of the semi-singular values of the attention weights
determines task allocation. To our best knowledge, our work provides the first
convergence result for the multi-head softmax attention model.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19443" title="Abstract">arXiv:2402.19443</a> [<a href="/pdf/2402.19443" title="Download PDF">pdf</a>, <a href="/format/2402.19443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing the Information Encoded in Neural-based Acoustic Models of  Automatic Speech Recognition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raymondaud%2C+Q">Quentin Raymondaud</a>, 
<a href="/search/cs?searchtype=author&query=Rouvier%2C+M">Mickael Rouvier</a>, 
<a href="/search/cs?searchtype=author&query=Dufour%2C+R">Richard Dufour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deep learning architectures have made significant progress in terms of
performance in many research areas. The automatic speech recognition (ASR)
field has thus benefited from these scientific and technological advances,
particularly for acoustic modeling, now integrating deep neural network
architectures. However, these performance gains have translated into increased
complexity regarding the information learned and conveyed through these
black-box architectures. Following many researches in neural networks
interpretability, we propose in this article a protocol that aims to determine
which and where information is located in an ASR acoustic model (AM). To do so,
we propose to evaluate AM performance on a determined set of tasks using
intermediate representations (here, at different layer levels). Regarding the
performance variation and targeted tasks, we can emit hypothesis about which
information is enhanced or perturbed at different architecture steps.
Experiments are performed on both speaker verification, acoustic environment
classification, gender classification, tempo-distortion detection systems and
speech sentiment/emotion identification. Analysis showed that neural-based AMs
hold heterogeneous information that seems surprisingly uncorrelated with
phoneme recognition, such as emotion, sentiment or speaker identity. The
low-level hidden layers globally appears useful for the structuring of
information while the upper ones would tend to delete useless information for
phoneme recognition.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19446" title="Abstract">arXiv:2402.19446</a> [<a href="/pdf/2402.19446" title="Download PDF">pdf</a>, <a href="/format/2402.19446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zanette%2C+A">Andrea Zanette</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiayi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aviral Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">A broad use case of large language models (LLMs) is in goal-directed
decision-making tasks (or "agent" tasks), where an LLM needs to not just
generate completions for a given prompt, but rather make intelligent decisions
over a multi-turn interaction to accomplish a task (e.g., when interacting with
the web, using tools, or providing customer support). Reinforcement learning
(RL) provides a general paradigm to address such agent tasks, but current RL
methods for LLMs largely focus on optimizing single-turn rewards. By
construction, most single-turn RL methods cannot endow LLMs with the ability to
intelligently seek information over multiple turns, perform credit assignment,
or reason about their past actions -- all of which are critical in agent tasks.
This raises the question: how can we design effective and efficient multi-turn
RL algorithms for LLMs? In this paper, we develop a framework for building
multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility
of existing single-turn RL methods for LLMs (e.g., proximal policy
optimization), while accommodating multiple turns, long horizons, and delayed
rewards effectively. To do this, our framework adopts a hierarchical RL
approach and runs two RL algorithms in parallel: a high-level off-policy
value-based RL algorithm to aggregate reward over utterances, and a low-level
RL algorithm that utilizes this high-level value function to train a token
policy within each utterance or turn. Our hierarchical framework, Actor-Critic
Framework with a Hierarchical Structure (ArCHer), can also give rise to other
RL methods. Empirically, we find that ArCHer significantly improves efficiency
and performance on agent tasks, attaining a sample efficiency of about 100x
over existing methods, while also improving with larger model capacity (upto
the 7 billion scale that we tested on).
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19449" title="Abstract">arXiv:2402.19449</a> [<a href="/pdf/2402.19449" title="Download PDF">pdf</a>, <a href="/format/2402.19449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent  on Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kunstner%2C+F">Frederik Kunstner</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R">Robin Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Milligan%2C+A">Alan Milligan</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Mark Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Bietti%2C+A">Alberto Bietti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Adam has been shown to outperform gradient descent in optimizing large
language transformers empirically, and by a larger margin than on other tasks,
but it is unclear why this happens. We show that the heavy-tailed class
imbalance found in language modeling tasks leads to difficulties in the
optimization dynamics. When training with gradient descent, the loss associated
with infrequent words decreases slower than the loss associated with frequent
ones. As most samples come from relatively infrequent words, the average loss
decreases slowly with gradient descent. On the other hand, Adam and sign-based
methods do not suffer from this problem and improve predictions on all classes.
To establish that this behavior is indeed caused by class imbalance, we show
empirically that it persist through different architectures and data types, on
language transformers, vision CNNs, and linear models. We further study this
phenomenon on a linear classification with cross-entropy loss, showing that
heavy-tailed class imbalance leads to ill-conditioning, and that the
normalization used by Adam can counteract it.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19450" title="Abstract">arXiv:2402.19450</a> [<a href="/pdf/2402.19450" title="Download PDF">pdf</a>, <a href="/format/2402.19450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Benchmarks for Robust Evaluation of Reasoning Performance,  and the Reasoning Gap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Saurabh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=B%2C+A+M">Annarose M B</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+A+P">Anto P V</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+S">Shashank Menon</a>, 
<a href="/search/cs?searchtype=author&query=Sukumar%2C+A">Ajay Sukumar</a>, 
<a href="/search/cs?searchtype=author&query=T%2C+A+S">Adwaith Samod T</a>, 
<a href="/search/cs?searchtype=author&query=Philipose%2C+A">Alan Philipose</a>, 
<a href="/search/cs?searchtype=author&query=Prince%2C+S">Stevin Prince</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+S">Sooraj Thomas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose a framework for robust evaluation of reasoning capabilities of
language models, using functional variants of benchmarks. Models that solve a
reasoning test should exhibit no difference in performance over the static
version of a problem compared to a snapshot of the functional variant. We have
rewritten the relevant fragment of the MATH benchmark into its functional
variant MATH(), with functionalization of other benchmarks to follow. When
evaluating current state-of-the-art models over snapshots of MATH(), we find a
reasoning gap -- the percentage difference between the static and functional
accuracies. We find reasoning gaps from 58.35% to 80.31% among the
state-of-the-art closed and open weights models that perform well on static
benchmarks, with the caveat that the gaps are likely to be smaller with more
sophisticated prompting strategies. Here we show that models which anecdotally
have good reasoning performance over real-world tasks, have quantifiable lower
gaps, motivating the open problem of building "gap 0" models. Code for
evaluation and new evaluation datasets, three MATH() snapshots, are publicly
available at https://github.com/consequentai/fneval/.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19457" title="Abstract">arXiv:2402.19457</a> [<a href="/pdf/2402.19457" title="Download PDF">pdf</a>, <a href="/format/2402.19457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darrin%2C+M">Maxime Darrin</a>, 
<a href="/search/cs?searchtype=author&query=Formont%2C+P">Philippe Formont</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+J+C+K">Jackie Chi Kit Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Piantanida%2C+P">Pablo Piantanida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Assessing the quality of summarizers poses significant challenges. In
response, we propose a novel task-oriented evaluation approach that assesses
summarizers based on their capacity to produce summaries that are useful for
downstream tasks, while preserving task outcomes. We theoretically establish a
direct relationship between the resulting error probability of these tasks and
the mutual information between source texts and generated summaries. We
introduce $\texttt{COSMIC}$ as a practical implementation of this metric,
demonstrating its strong correlation with human judgment-based metrics and its
effectiveness in predicting downstream task performance. Comparative analyses
against established metrics like $\texttt{BERTScore}$ and $\texttt{ROUGE}$
highlight the competitive performance of $\texttt{COSMIC}$.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19460" title="Abstract">arXiv:2402.19460</a> [<a href="/pdf/2402.19460" title="Download PDF">pdf</a>, <a href="/format/2402.19460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for  Specialized Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mucs%C3%A1nyi%2C+B">B&#xe1;lint Mucs&#xe1;nyi</a>, 
<a href="/search/cs?searchtype=author&query=Kirchhof%2C+M">Michael Kirchhof</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+J">Seong Joon Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Uncertainty quantification, once a singular task, has evolved into a spectrum
of tasks, including abstained prediction, out-of-distribution detection, and
aleatoric uncertainty quantification. The latest goal is disentanglement: the
construction of multiple estimators that are each tailored to one and only one
task. Hence, there is a plethora of recent advances with different intentions -
that often entirely deviate from practical behavior. This paper conducts a
comprehensive evaluation of numerous uncertainty estimators across diverse
tasks on ImageNet. We find that, despite promising theoretical endeavors,
disentanglement is not yet achieved in practice. Additionally, we reveal which
uncertainty estimators excel at which specific tasks, providing insights for
practitioners and guiding future research toward task-centric and disentangled
uncertainty estimation methods. Our code is available at
https://github.com/bmucsanyi/bud.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19463" title="Abstract">arXiv:2402.19463</a> [<a href="/pdf/2402.19463" title="Download PDF">pdf</a>, <a href="/format/2402.19463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeMoLi: What Moves Together Belongs Together
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seidenschwarz%2C+J">Jenny Seidenschwarz</a>, 
<a href="/search/cs?searchtype=author&query=O%C5%A1ep%2C+A">Aljo&#x161;a O&#x161;ep</a>, 
<a href="/search/cs?searchtype=author&query=Ferroni%2C+F">Francesco Ferroni</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>, 
<a href="/search/cs?searchtype=author&query=Leal-Taix%C3%A9%2C+L">Laura Leal-Taix&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle semi-supervised object detection based on motion cues. Recent
results suggest that heuristic-based clustering methods in conjunction with
object trackers can be used to pseudo-label instances of moving objects and use
these as supervisory signals to train 3D object detectors in Lidar data without
manual supervision. We re-think this approach and suggest that both, object
detection, as well as motion-inspired pseudo-labeling, can be tackled in a
data-driven manner. We leverage recent advances in scene flow estimation to
obtain point trajectories from which we extract long-term, class-agnostic
motion patterns. Revisiting correlation clustering in the context of message
passing networks, we learn to group those motion patterns to cluster points to
object instances. By estimating the full extent of the objects, we obtain
per-scan 3D bounding boxes that we use to supervise a Lidar object detection
network. Our method not only outperforms prior heuristic-based approaches (57.5
AP, +14 improvement over prior work), more importantly, we show we can
pseudo-label and train object detectors across datasets.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19464" title="Abstract">arXiv:2402.19464</a> [<a href="/pdf/2402.19464" title="Download PDF">pdf</a>, <a href="/format/2402.19464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curiosity-driven Red-teaming for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Zhang-Wei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Shenfeld%2C+I">Idan Shenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tsun-Hsuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yung-Sung Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Pareja%2C+A">Aldo Pareja</a>, 
<a href="/search/cs?searchtype=author&query=Glass%2C+J">James Glass</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) hold great potential for many natural language
applications but risk generating incorrect or toxic content. To probe when an
LLM generates unwanted content, the current paradigm is to recruit a
\textit{red team} of human testers to design input prompts (i.e., test cases)
that elicit undesirable responses from LLMs. However, relying solely on human
testers is expensive and time-consuming. Recent works automate red teaming by
training a separate red team LLM with reinforcement learning (RL) to generate
test cases that maximize the chance of eliciting undesirable responses from the
target LLM. However, current RL methods are only able to generate a small
number of effective test cases resulting in a low coverage of the span of
prompts that elicit undesirable responses from the target LLM. To overcome this
limitation, we draw a connection between the problem of increasing the coverage
of generated test cases and the well-studied approach of curiosity-driven
exploration that optimizes for novelty. Our method of curiosity-driven red
teaming (CRT) achieves greater coverage of test cases while mantaining or
increasing their effectiveness compared to existing methods. Our method, CRT
successfully provokes toxic responses from LLaMA2 model that has been heavily
fine-tuned using human preferences to avoid toxic outputs. Code is available at
\url{https://github.com/Improbable-AI/curiosity_redteam}
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19465" title="Abstract">arXiv:2402.19465</a> [<a href="/pdf/2402.19465" title="Download PDF">pdf</a>, <a href="/format/2402.19465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period  of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ensuring the trustworthiness of large language models (LLMs) is crucial. Most
studies concentrate on fully pre-trained LLMs to better understand and improve
LLMs' trustworthiness. In this paper, to reveal the untapped potential of
pre-training, we pioneer the exploration of LLMs' trustworthiness during this
period, focusing on five key dimensions: reliability, privacy, toxicity,
fairness, and robustness. To begin with, we apply linear probing to LLMs. The
high probing accuracy suggests that \textit{LLMs in early pre-training can
already distinguish concepts in each trustworthiness dimension}. Therefore, to
further uncover the hidden possibilities of pre-training, we extract steering
vectors from a LLM's pre-training checkpoints to enhance the LLM's
trustworthiness. Finally, inspired by~\citet{choi2023understanding} that mutual
information estimation is bounded by linear probing accuracy, we also probe
LLMs with mutual information to investigate the dynamics of trustworthiness
during pre-training. We are the first to observe a similar two-phase
phenomenon: fitting and compression~\citep{shwartz2017opening}. This research
provides an initial exploration of trustworthiness modeling during LLM
pre-training, seeking to unveil new insights and spur further developments in
the field. We will make our code publicly accessible at
\url{https://github.com/ChnQ/TracingLLM}.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19467" title="Abstract">arXiv:2402.19467</a> [<a href="/pdf/2402.19467" title="Download PDF">pdf</a>, <a href="/format/2402.19467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanders%2C+K">Kate Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Weir%2C+N">Nathaniel Weir</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">It is challenging to perform question-answering over complex, multimodal
content such as television clips. This is in part because current
video-language models rely on single-modality reasoning, have lowered
performance on long inputs, and lack interpetability. We propose TV-TREES, the
first multimodal entailment tree generator. TV-TREES serves as an approach to
video understanding that promotes interpretable joint-modality reasoning by
producing trees of entailment relationships between simple premises directly
entailed by the videos and higher-level conclusions. We then introduce the task
of multimodal entailment tree generation to evaluate the reasoning quality of
such methods. Our method's experimental results on the challenging TVQA dataset
demonstrate intepretable, state-of-the-art zero-shot performance on full video
clips, illustrating a best of both worlds contrast to black-box methods.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19469" title="Abstract">arXiv:2402.19469</a> [<a href="/pdf/2402.19469" title="Download PDF">pdf</a>, <a href="/format/2402.19469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Humanoid Locomotion as Next Token Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radosavovic%2C+I">Ilija Radosavovic</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bike Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Baifeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Rajasegaran%2C+J">Jathushan Rajasegaran</a>, 
<a href="/search/cs?searchtype=author&query=Kamat%2C+S">Sarthak Kamat</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Sreenath%2C+K">Koushil Sreenath</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We cast real-world humanoid control as a next token prediction problem, akin
to predicting the next word in language. Our model is a causal transformer
trained via autoregressive prediction of sensorimotor trajectories. To account
for the multi-modal nature of the data, we perform prediction in a
modality-aligned way, and for each input token predict the next token from the
same modality. This general formulation enables us to leverage data with
missing modalities, like video trajectories without actions. We train our model
on a collection of simulated trajectories coming from prior neural network
policies, model-based controllers, motion capture data, and YouTube videos of
humans. We show that our model enables a full-sized humanoid to walk in San
Francisco zero-shot. Our model can transfer to the real world even when trained
on only 27 hours of walking data, and can generalize to commands not seen
during training like walking backward. These findings suggest a promising path
toward learning challenging real-world control tasks by generative modeling of
sensorimotor trajectories.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19471" title="Abstract">arXiv:2402.19471</a> [<a href="/pdf/2402.19471" title="Download PDF">pdf</a>, <a href="/format/2402.19471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loose LIPS Sink Ships: Asking Questions in Battleship with  Language-Informed Program Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grand%2C+G">Gabriel Grand</a>, 
<a href="/search/cs?searchtype=author&query=Pepe%2C+V">Valerio Pepe</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Questions combine our mastery of language with our remarkable facility for
reasoning about uncertainty. How do people navigate vast hypothesis spaces to
pose informative questions given limited cognitive resources? We study these
tradeoffs in a classic grounded question-asking task based on the board game
Battleship. Our language-informed program sampling (LIPS) model uses large
language models (LLMs) to generate natural language questions, translate them
into symbolic programs, and evaluate their expected information gain. We find
that with a surprisingly modest resource budget, this simple Monte Carlo
optimization strategy yields informative questions that mirror human
performance across varied Battleship board scenarios. In contrast, LLM-only
baselines struggle to ground questions in the board state; notably, GPT-4V
provides no improvement over non-visual baselines. Our results illustrate how
Bayesian models of question-asking can leverage the statistics of language to
capture human priors, while highlighting some shortcomings of pure LLMs as
grounded reasoners.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19472" title="Abstract">arXiv:2402.19472</a> [<a href="/pdf/2402.19472" title="Download PDF">pdf</a>, <a href="/format/2402.19472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid  Progress
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+A">Ameya Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Udandarao%2C+V">Vishaal Udandarao</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>, 
<a href="/search/cs?searchtype=author&query=Bibi%2C+A">Adel Bibi</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Standardized benchmarks drive progress in machine learning. However, with
repeated testing, the risk of overfitting grows as algorithms over-exploit
benchmark idiosyncrasies. In our work, we seek to mitigate this challenge by
compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. As
exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet,
containing (for now) 1.69M and 1.98M test samples, respectively. While reducing
overfitting, lifelong benchmarks introduce a key challenge: the high cost of
evaluating a growing number of models across an ever-expanding sample set. To
address this challenge, we also introduce an efficient evaluation framework:
Sort \&amp; Search (S&amp;S), which reuses previously evaluated models by leveraging
dynamic programming algorithms to selectively rank and sub-select test samples,
enabling cost-effective lifelong benchmarking. Extensive empirical evaluations
across 31,000 models demonstrate that S&amp;S achieves highly-efficient approximate
accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours
(1000x reduction) on a single A100 GPU, with low approximation error. As such,
lifelong benchmarks offer a robust, practical solution to the "benchmark
exhaustion" problem.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19473" title="Abstract">arXiv:2402.19473</a> [<a href="/pdf/2402.19473" title="Download PDF">pdf</a>, <a href="/format/2402.19473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Generation for AI-Generated Content: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Penghao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinhan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yunteng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fangcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Ling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Citing 259 papers, 29 pages, 8 figures. Project: <a href="https://github.com/hymie122/RAG-Survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of Artificial Intelligence Generated Content (AIGC) has been
facilitated by advancements in model algorithms, scalable foundation model
architectures, and the availability of ample high-quality datasets. While AIGC
has achieved remarkable performance, it still faces challenges, such as the
difficulty of maintaining up-to-date and long-tail knowledge, the risk of data
leakage, and the high costs associated with training and inference.
Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to
address such challenges. In particular, RAG introduces the information
retrieval process, which enhances AIGC results by retrieving relevant objects
from available data stores, leading to greater accuracy and robustness. In this
paper, we comprehensively review existing efforts that integrate RAG technique
into AIGC scenarios. We first classify RAG foundations according to how the
retriever augments the generator. We distill the fundamental abstractions of
the augmentation methodologies for various retrievers and generators. This
unified perspective encompasses all RAG scenarios, illuminating advancements
and pivotal technologies that help with potential future progress. We also
summarize additional enhancements methods for RAG, facilitating effective
engineering and implementation of RAG systems. Then from another view, we
survey on practical applications of RAG across different modalities and tasks,
offering valuable references for researchers and practitioners. Furthermore, we
introduce the benchmarks for RAG, discuss the limitations of current RAG
systems, and suggest potential directions for future research. Project:
https://github.com/hymie122/RAG-Survey
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19474" title="Abstract">arXiv:2402.19474</a> [<a href="/pdf/2402.19474" title="Download PDF">pdf</a>, <a href="/format/2402.19474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The All-Seeing Project V2: Towards General Relation Comprehension of the  Open World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yiming Ren</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haowen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tiantong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chenxiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present the All-Seeing Project V2: a new model and dataset designed for
understanding object relations in images. Specifically, we propose the
All-Seeing Model V2 (ASMv2) that integrates the formulation of text generation,
object localization, and relation comprehension into a relation conversation
(ReC) task. Leveraging this unified task, our model excels not only in
perceiving and recognizing all objects within the image but also in grasping
the intricate relation graph between them, diminishing the relation
hallucination often encountered by Multi-modal Large Language Models (MLLMs).
To facilitate training and evaluation of MLLMs in relation understanding, we
created the first high-quality ReC dataset ({AS-V2) which is aligned with the
format of standard instruction tuning data. In addition, we design a new
benchmark, termed Circular-based Relation Probing Evaluation (CRPE) for
comprehensively evaluating the relation comprehension capabilities of MLLMs.
Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware
benchmark, surpassing the 43.14 of LLaVA-1.5 by a large margin. We hope that
our work can inspire more future research and contribute to the evolution
towards artificial general intelligence. Our project is released at
https://github.com/OpenGVLab/all-seeing.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19475" title="Abstract">arXiv:2402.19475</a> [<a href="/pdf/2402.19475" title="Download PDF">pdf</a>, <a href="/format/2402.19475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of  Their Incorrect Generations?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Alex Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wen-Ding Li</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Naman Jain</a>, 
<a href="/search/cs?searchtype=author&query=Olausson%2C+T+X">Theo X. Olausson</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Celine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+K">Koushik Sen</a>, 
<a href="/search/cs?searchtype=author&query=Solar-Lezama%2C+A">Armando Solar-Lezama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages, 25 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While language models are increasingly more proficient at code generation,
they still frequently generate incorrect programs. Many of these programs are
obviously wrong, but others are more subtle and pass weaker correctness checks
such as being able to compile. In this work, we focus on these counterfeit
samples: programs sampled from a language model that 1) have a high enough
log-probability to be generated at a moderate temperature and 2) pass weak
correctness checks. Overall, we discover that most models have a very shallow
understanding of counterfeits through three clear failure modes. First, models
mistakenly classify them as correct. Second, models are worse at reasoning
about the execution behaviour of counterfeits and often predict their execution
results as if they were correct. Third, when asking models to fix counterfeits,
the likelihood of a model successfully repairing a counterfeit is often even
lower than that of sampling a correct program from scratch. Counterfeits also
have very unexpected properties: first, counterfeit programs for problems that
are easier for a model to solve are not necessarily easier to detect and only
slightly easier to execute and repair. Second, counterfeits from a given model
are just as confusing to the model itself as they are to other models. Finally,
both strong and weak models are able to generate counterfeit samples that
equally challenge all models. In light of our findings, we recommend that care
and caution be taken when relying on models to understand their own samples,
especially when no external feedback is incorporated.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19477" title="Abstract">arXiv:2402.19477</a> [<a href="/pdf/2402.19477" title="Download PDF">pdf</a>, <a href="/format/2402.19477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Generalized Physical Face Model From Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lingchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zoss%2C+G">Gaspard Zoss</a>, 
<a href="/search/cs?searchtype=author&query=Chandran%2C+P">Prashanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+M">Markus Gross</a>, 
<a href="/search/cs?searchtype=author&query=Solenthaler%2C+B">Barbara Solenthaler</a>, 
<a href="/search/cs?searchtype=author&query=Sifakis%2C+E">Eftychios Sifakis</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+D">Derek Bradley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Physically-based simulation is a powerful approach for 3D facial animation as
the resulting deformations are governed by physical constraints, allowing to
easily resolve self-collisions, respond to external forces and perform
realistic anatomy edits. Today's methods are data-driven, where the actuations
for finite elements are inferred from captured skin geometry. Unfortunately,
these approaches have not been widely adopted due to the complexity of
initializing the material space and learning the deformation model for each
character separately, which often requires a skilled artist followed by lengthy
network training. In this work, we aim to make physics-based facial animation
more accessible by proposing a generalized physical face model that we learn
from a large 3D face dataset in a simulation-free manner. Once trained, our
model can be quickly fit to any unseen identity and produce a ready-to-animate
physical face model automatically. Fitting is as easy as providing a single 3D
face scan, or even a single face image. After fitting, we offer intuitive
animation controls, as well as the ability to retarget animations across
characters. All the while, the resulting animations allow for physical effects
like collision avoidance, gravity, paralysis, bone reshaping and more.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19479" title="Abstract">arXiv:2402.19479</a> [<a href="/pdf/2402.19479" title="Download PDF">pdf</a>, <a href="/format/2402.19479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tsai-Shien Chen</a>, 
<a href="/search/cs?searchtype=author&query=Siarohin%2C+A">Aliaksandr Siarohin</a>, 
<a href="/search/cs?searchtype=author&query=Menapace%2C+W">Willi Menapace</a>, 
<a href="/search/cs?searchtype=author&query=Deyneka%2C+E">Ekaterina Deyneka</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+H">Hsiang-wei Chao</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+B+E">Byung Eun Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuwei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. Project Page: <a href="https://snap-research.github.io/Panda-70M">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The quality of the data and annotation upper-bounds the quality of a
downstream model. While there exist large text corpora and image-text pairs,
high-quality video-text data is much harder to collect. First of all, manual
labeling is more time-consuming, as it requires an annotator to watch an entire
video. Second, videos have a temporal dimension, consisting of several scenes
stacked together, and showing multiple actions. Accordingly, to establish a
video dataset with high-quality captions, we propose an automatic approach
leveraging multimodal inputs, such as textual video description, subtitles, and
individual video frames. Specifically, we curate 3.8M high-resolution videos
from the publicly available HD-VILA-100M dataset. We then split them into
semantically consistent video clips, and apply multiple cross-modality teacher
models to obtain captions for each video. Next, we finetune a retrieval model
on a small subset where the best caption of each video is manually selected and
then employ the model in the whole dataset to select the best caption as the
annotation. In this way, we get 70M videos paired with high-quality text
captions. We dub the dataset as Panda-70M. We show the value of the proposed
dataset on three downstream tasks: video captioning, video and text retrieval,
and text-driven video generation. The models trained on the proposed data score
substantially better on the majority of metrics across all the tasks.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19481" title="Abstract">arXiv:2402.19481</a> [<a href="/pdf/2402.19481" title="Download PDF">pdf</a>, <a href="/format/2402.19481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DistriFusion: Distributed Parallel Inference for High-Resolution  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Muyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianle Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiaxin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Han Cai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Junjie Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yangqing Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming-Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 Code: <a href="https://github.com/mit-han-lab/distrifuser">this https URL</a> Website: <a href="https://hanlab.mit.edu/projects/distrifusion">this https URL</a> Blog: <a href="https://hanlab.mit.edu/blog/distrifusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have achieved great success in synthesizing high-quality
images. However, generating high-resolution images with diffusion models is
still challenging due to the enormous computational costs, resulting in a
prohibitive latency for interactive applications. In this paper, we propose
DistriFusion to tackle this problem by leveraging parallelism across multiple
GPUs. Our method splits the model input into multiple patches and assigns each
patch to a GPU. However, na\"{\i}vely implementing such an algorithm breaks the
interaction between patches and loses fidelity, while incorporating such an
interaction will incur tremendous communication overhead. To overcome this
dilemma, we observe the high similarity between the input from adjacent
diffusion steps and propose displaced patch parallelism, which takes advantage
of the sequential nature of the diffusion process by reusing the pre-computed
feature maps from the previous timestep to provide context for the current
step. Therefore, our method supports asynchronous communication, which can be
pipelined by computation. Extensive experiments show that our method can be
applied to recent Stable Diffusion XL with no quality degradation and achieve
up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is
publicly available at https://github.com/mit-han-lab/distrifuser.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri,  1 Mar 24</h3>
<dl>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15324" title="Abstract">arXiv:2401.15324</a> (cross-list from hep-ex) [<a href="/pdf/2401.15324" title="Download PDF">pdf</a>, <a href="/format/2401.15324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neutrino Reconstruction in TRIDENT Based on Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Mo%2C+C">Cen Mo</a>, 
<a href="/search/hep-ex?searchtype=author&query=Zhang%2C+F">Fuyudi Zhang</a>, 
<a href="/search/hep-ex?searchtype=author&query=Li%2C+L">Liang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">TRopIcal DEep-sea Neutrino Telescope (TRIDENT) is a next-generation neutrino
telescope to be located in the South China Sea. With a large detector volume
and the use of advanced hybrid digital optical modules (hDOMs), TRIDENT aims to
discover multiple astrophysical neutrino sources and probe all-flavor neutrino
physics. The reconstruction resolution of primary neutrinos is on the critical
path to these scientific goals. We have developed a novel reconstruction method
based on graph neural network (GNN) for TRIDENT. In this paper, we present the
reconstruction performance of the GNN-based approach on both track- and
shower-like neutrino events in TRIDENT.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18575" title="Abstract">arXiv:2402.18575</a> (cross-list from eess.IV) [<a href="/pdf/2402.18575" title="Download PDF">pdf</a>, <a href="/format/2402.18575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dagli%2C+R">Rishit Dagli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Imaging under extremely low-light conditions presents a significant challenge
and is an ill-posed problem due to the low signal-to-noise ratio (SNR) caused
by minimal photon capture. Previously, diffusion models have been used for
multiple kinds of generative tasks and image-to-image tasks, however, these
models work as a post-processing step. These diffusion models are trained on
processed images and learn on processed images. However, such approaches are
often not well-suited for extremely low-light tasks. Unlike the task of
low-light image enhancement or image-to-image enhancement, we tackle the task
of learning the entire image-processing pipeline, from the RAW image to a
processed image. For this task, a traditional image processing pipeline often
consists of multiple specialized parts that are overly reliant on the
downstream tasks. Unlike these, we develop a new generative ISP that relies on
fine-tuning latent diffusion models on RAW images and generating processed
long-exposure images which allows for the apt use of the priors from large
text-to-image generation models. We evaluate our approach on popular end-to-end
low-light datasets for which we see promising results and set a new SoTA on the
See-in-Dark (SID) dataset. Furthermore, with this work, we hope to pave the way
for more generative and diffusion-based image processing and other problems on
RAW data.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18583" title="Abstract">arXiv:2402.18583</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.18583" title="Download PDF">pdf</a>, <a href="/format/2402.18583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binding-Adaptive Diffusion Models for Structure-Based Drug Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+Z">Zhilin Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+L">Ling Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Z">Zaixi Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+X">Xiangxin Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Bao%2C+Y">Yu Bao</a>, 
<a href="/search/q-bio?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Y">Yuwei Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+W">Wenming Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Project: <a href="https://github.com/YangLing0818/BindDM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Structure-based drug design (SBDD) aims to generate 3D ligand molecules that
bind to specific protein targets. Existing 3D deep generative models including
diffusion models have shown great promise for SBDD. However, it is complex to
capture the essential protein-ligand interactions exactly in 3D space for
molecular generation. To address this problem, we propose a novel framework,
namely Binding-Adaptive Diffusion Models (BindDM). In BindDM, we adaptively
extract subcomplex, the essential part of binding sites responsible for
protein-ligand interactions. Then the selected protein-ligand subcomplex is
processed with SE(3)-equivariant neural networks, and transmitted back to each
atom of the complex for augmenting the target-aware 3D molecule diffusion
generation with binding interaction information. We iterate this hierarchical
complex-subcomplex process with cross-hierarchy interaction node for adequately
fusing global binding context between the complex and its corresponding
subcomplex. Empirical studies on the CrossDocked2020 dataset show BindDM can
generate molecules with more realistic 3D structures and higher binding
affinities towards the protein targets, with up to -5.92 Avg. Vina Score, while
maintaining proper molecular properties. Our code is available at
https://github.com/YangLing0818/BindDM
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18598" title="Abstract">arXiv:2402.18598</a> (cross-list from physics.soc-ph) [<a href="/pdf/2402.18598" title="Download PDF">pdf</a>, <a href="/ps/2402.18598" title="Download PostScript">ps</a>, <a href="/format/2402.18598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Note: Evolutionary Game Theory Focus Informational Health: The Cocktail  Party Effect Through Werewolfgame under Incomplete Information and ESS Search  Method Using Expected Gains of Repeated Dilemmas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Werewolf Games, Evolutionary Game Theory, Non-Complete Information Games, Expanding Form Games, Cocktail Party Effect, Fake News, Evolutionary Stability Strategy (ESS), Information Pollution Risk, Numerical Simulation, Strategic Interaction, Replicator Equation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We explore the state of information disruption caused by the cocktail party
effect within the framework of non-perfect information games and evolutive
games with multiple werewolves. In particular, we mathematically model and
analyze the effects on the gain of each strategy choice and the formation
process of evolutionary stable strategies (ESS) under the assumption that the
pollution risk of fake news is randomly assigned in the context of repeated
dilemmas. We will develop the computational process in detail, starting with
the construction of the gain matrix, modeling the evolutionary dynamics using
the replicator equation, and identifying the ESS. In addition, numerical
simulations will be performed to observe system behavior under different
initial conditions and parameter settings to better understand the impact of
the spread of fake news on strategy evolution. This research will provide
theoretical insights into the complex issues of contemporary society regarding
the authenticity of information and expand the range of applications of
evolutionary game theory.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18600" title="Abstract">arXiv:2402.18600</a> (cross-list from eess.IV) [<a href="/pdf/2402.18600" title="Download PDF">pdf</a>, <a href="/ps/2402.18600" title="Download PostScript">ps</a>, <a href="/format/2402.18600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence and Diabetes Mellitus: An Inside Look Through  the Retina
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bazargani%2C+Y+S">Yasin Sadeghi Bazargani</a>, 
<a href="/search/eess?searchtype=author&query=Mirzaei%2C+M">Majid Mirzaei</a>, 
<a href="/search/eess?searchtype=author&query=Sobhi%2C+N">Navid Sobhi</a>, 
<a href="/search/eess?searchtype=author&query=Abdollahi%2C+M">Mirsaeed Abdollahi</a>, 
<a href="/search/eess?searchtype=author&query=Jafarizadeh%2C+A">Ali Jafarizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Pedrammehr%2C+S">Siamak Pedrammehr</a>, 
<a href="/search/eess?searchtype=author&query=Alizadehsani%2C+R">Roohallah Alizadehsani</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+R+S">Ru San Tan</a>, 
<a href="/search/eess?searchtype=author&query=Islam%2C+S+M+S">Sheikh Mohammed Shariful Islam</a>, 
<a href="/search/eess?searchtype=author&query=Acharya%2C+U+R">U. Rajendra Acharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 Pages, 6 figures, 1 table, 166 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18611" title="Abstract">arXiv:2402.18611</a> (cross-list from q-bio.QM) [<a href="/pdf/2402.18611" title="Download PDF">pdf</a>, <a href="/format/2402.18611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HemaGraph: Breaking Barriers in Hematologic Single Cell Classification  with Graph Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bini%2C+L">Lorenzo Bini</a>, 
<a href="/search/q-bio?searchtype=author&query=Mojarrad%2C+F+N">Fatemeh Nassajian Mojarrad</a>, 
<a href="/search/q-bio?searchtype=author&query=Matthes%2C+T">Thomas Matthes</a>, 
<a href="/search/q-bio?searchtype=author&query=Marchand-Maillet%2C+S">St&#xe9;phane Marchand-Maillet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">In the realm of hematologic cell populations classification, the intricate
patterns within flow cytometry data necessitate advanced analytical tools. This
paper presents 'HemaGraph', a novel framework based on Graph Attention Networks
(GATs) for single-cell multi-class classification of hematological cells from
flow cytometry data. Harnessing the power of GATs, our method captures subtle
cell relationships, offering highly accurate patient profiling. Based on
evaluation of data from 30 patients, HemaGraph demonstrates classification
performance across five different cell classes, outperforming traditional
methodologies and state-of-the-art methods. Moreover, the uniqueness of this
framework lies in the training and testing phase of HemaGraph, where it has
been applied for extremely large graphs, containing up to hundreds of thousands
of nodes and two million edges, to detect low frequency cell populations (e.g.
0.01% for one population), with accuracies reaching 98%. Our findings
underscore the potential of HemaGraph in improving hematoligic multi-class
classification, paving the way for patient-personalized interventions. To the
best of our knowledge, this is the first effort to use GATs, and Graph Neural
Networks (GNNs) in general, to classify cell populations from single-cell flow
cytometry data. We envision applying this method to single-cell data from
larger cohort of patients and on other hematologic diseases.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18612" title="Abstract">arXiv:2402.18612</a> (cross-list from stat.ME) [<a href="/pdf/2402.18612" title="Download PDF">pdf</a>, <a href="/ps/2402.18612" title="Download PostScript">ps</a>, <a href="/format/2402.18612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding random forests and overfitting: a visualization and  simulation study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Barre%C3%B1ada%2C+L">Lasai Barre&#xf1;ada</a>, 
<a href="/search/stat?searchtype=author&query=Dhiman%2C+P">Paula Dhiman</a>, 
<a href="/search/stat?searchtype=author&query=Timmerman%2C+D">Dirk Timmerman</a>, 
<a href="/search/stat?searchtype=author&query=Boulesteix%2C+A">Anne-Laure Boulesteix</a>, 
<a href="/search/stat?searchtype=author&query=Van+Calster%2C+B">Ben Van Calster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Random forests have become popular for clinical risk prediction modelling. In
a case study on predicting ovarian malignancy, we observed training
c-statistics close to 1. Although this suggests overfitting, performance was
competitive on test data. We aimed to understand the behaviour of random
forests by (1) visualizing data space in three real world case studies and (2)
a simulation study. For the case studies, risk estimates were visualised using
heatmaps in a 2-dimensional subspace. The simulation study included 48 logistic
data generating mechanisms (DGM), varying the predictor distribution, the
number of predictors, the correlation between predictors, the true c-statistic
and the strength of true predictors. For each DGM, 1000 training datasets of
size 200 or 4000 were simulated and RF models trained with minimum node size 2
or 20 using ranger package, resulting in 192 scenarios in total. The
visualizations suggested that the model learned spikes of probability around
events in the training set. A cluster of events created a bigger peak, isolated
events local peaks. In the simulation study, median training c-statistics were
between 0.97 and 1 unless there were 4 or 16 binary predictors with minimum
node size 20. Median test c-statistics were higher with higher events per
variable, higher minimum node size, and binary predictors. Median training
slopes were always above 1, and were not correlated with median test slopes
across scenarios (correlation -0.11). Median test slopes were higher with
higher true c-statistic, higher minimum node size, and higher sample size.
Random forests learn local probability peaks that often yield near perfect
training c-statistics without strongly affecting c-statistics on test data.
When the aim is probability estimation, the simulation results go against the
common recommendation to use fully grown trees in random forest models.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18684" title="Abstract">arXiv:2402.18684</a> (cross-list from quant-ph) [<a href="/pdf/2402.18684" title="Download PDF">pdf</a>, <a href="/ps/2402.18684" title="Download PostScript">ps</a>, <a href="/format/2402.18684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum State Compression with Polar Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Weinberg%2C+J">Jack Weinberg</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mandal%2C+A">Avijit Mandal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pfister%2C+H+D">Henry D. Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Version of ISIT 2024 Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In the quantum compression scheme proposed by Schumacher, Alice compresses a
message that Bob decompresses. In that approach, there is some probability of
failure and, even when successful, some distortion of the state. For
sufficiently large blocklengths, both of these imperfections can be made
arbitrarily small while achieving a compression rate that asymptotically
approaches the source coding bound. However, direct implementation of
Schumacher compression suffers from poor circuit complexity. In this paper, we
consider a slightly different approach based on classical syndrome source
coding. The idea is to use a linear error-correcting code and treat the message
to be compressed as an error pattern. If the message is a correctable error
(i.e., a coset leader) then Alice can use the error-correcting code to convert
her message to a corresponding quantum syndrome. An implementation of this
based on polar codes is described and simulated. As in classical source coding
based on polar codes, Alice maps the information into the ``frozen" qubits that
constitute the syndrome. To decompress, Bob utilizes a quantum version of
successive cancellation coding.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18697" title="Abstract">arXiv:2402.18697</a> (cross-list from stat.ML) [<a href="/pdf/2402.18697" title="Download PDF">pdf</a>, <a href="/format/2402.18697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Dynamic Networks from Marginals with Iterative Proportional  Fitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chang%2C+S">Serina Chang</a>, 
<a href="/search/stat?searchtype=author&query=Koehler%2C+F">Frederic Koehler</a>, 
<a href="/search/stat?searchtype=author&query=Qu%2C+Z">Zhaonan Qu</a>, 
<a href="/search/stat?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/stat?searchtype=author&query=Ugander%2C+J">Johan Ugander</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
<p class="mathjax">A common network inference problem, arising from real-world data constraints,
is how to infer a dynamic network from its time-aggregated adjacency matrix and
time-varying marginals (i.e., row and column sums). Prior approaches to this
problem have repurposed the classic iterative proportional fitting (IPF)
procedure, also known as Sinkhorn's algorithm, with promising empirical
results. However, the statistical foundation for using IPF has not been well
understood: under what settings does IPF provide principled estimation of a
dynamic network from its marginals, and how well does it estimate the network?
In this work, we establish such a setting, by identifying a generative network
model whose maximum likelihood estimates are recovered by IPF. Our model both
reveals implicit assumptions on the use of IPF in such settings and enables new
analyses, such as structure-dependent error bounds on IPF's parameter
estimates. When IPF fails to converge on sparse network data, we introduce a
principled algorithm that guarantees IPF converges under minimal changes to the
network structure. Finally, we conduct experiments with synthetic and
real-world data, which demonstrate the practical value of our theoretical and
algorithmic contributions.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18703" title="Abstract">arXiv:2402.18703</a> (cross-list from quant-ph) [<a href="/pdf/2402.18703" title="Download PDF">pdf</a>, <a href="/ps/2402.18703" title="Download PostScript">ps</a>, <a href="/format/2402.18703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-error communication, scrambling, and ergodicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Singh%2C+S">Satvik Singh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rahaman%2C+M">Mizanur Rahaman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Datta%2C+N">Nilanjana Datta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Operator Algebras (math.OA); Probability (math.PR)

</div>
<p class="mathjax">The long term behaviour of a quantum channel under iterations (i.e. under
repeated applications of itself) yields a plethora of interesting properties.
These include ergodicity, mixing, eventual scrambling, becoming strictly
positive, and the vanishing of its one-shot zero error capacities. We derive
relations between these seemingly different properties and find novel bounds on
indices which quantify the minimum number of iterations needed for the onset of
some of these properties. We obtain a lower bound on the one-shot zero-error
classical capacity of $n$ iterations of an ergodic channel (for any positive
integer $n$) in terms of the cardinality of its peripheral spectrum. We also
find upper bounds on the minimum number of iterations needed for the one-shot
capacities of any channel to stabilize. We consider two classes of quantum
channels, satisfying certain symmetries, for which upper bounds on the above
indices are optimal, since they reduce to the corresponding indices for a
stochastic matrix (for which the bounds are known to be optimal). As an
auxiliary result, we obtain a trade-off relation between the one-shot zero
error classical and quantum capacities of a quantum channel.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18729" title="Abstract">arXiv:2402.18729</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2402.18729" title="Download PDF">pdf</a>, <a href="/format/2402.18729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Priori Uncertainty Quantification of Reacting Turbulence Closure  Models using Bayesian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pash%2C+G">Graham Pash</a>, 
<a href="/search/physics?searchtype=author&query=Hassanaly%2C+M">Malik Hassanaly</a>, 
<a href="/search/physics?searchtype=author&query=Yellapantula%2C+S">Shashank Yellapantula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">While many physics-based closure model forms have been posited for the
sub-filter scale (SFS) in large eddy simulation (LES), vast amounts of data
available from direct numerical simulation (DNS) create opportunities to
leverage data-driven modeling techniques. Albeit flexible, data-driven models
still depend on the dataset and the functional form of the model chosen.
Increased adoption of such models requires reliable uncertainty estimates both
in the data-informed and out-of-distribution regimes. In this work, we employ
Bayesian neural networks (BNNs) to capture both epistemic and aleatoric
uncertainties in a reacting flow model. In particular, we model the filtered
progress variable scalar dissipation rate which plays a key role in the
dynamics of turbulent premixed flames. We demonstrate that BNN models can
provide unique insights about the structure of uncertainty of the data-driven
closure models. We also propose a method for the incorporation of
out-of-distribution information in a BNN. The efficacy of the model is
demonstrated by a priori evaluation on a dataset consisting of a variety of
flame conditions and fuels.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18758" title="Abstract">arXiv:2402.18758</a> (cross-list from eess.SP) [<a href="/pdf/2402.18758" title="Download PDF">pdf</a>, <a href="/format/2402.18758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analog Isolated Multilevel Quantizer for Voltage Sensing while  Maintaining Galvanic Isolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weber%2C+P">Peter Weber</a>, 
<a href="/search/eess?searchtype=author&query=Papandreou-Suppappola%2C+A">Antonia Papandreou-Suppappola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">A low-power, compact device for performing measurements in electrical systems
with isolated voltage domains is proposed. Isolated measurements are required
in numerous applications. For instance, a measurement of the bus voltage for a
system with a high supply voltage and lower isolated local voltage level may be
needed for system health monitoring and control. Such a requirement may
necessitate the use of isolation amplifiers to provide voltage telemetry for
the local system. Isolation amplifiers require dual galvanically isolated
supplies and use magnetic, capacitive, or optical barriers between primary and
secondary sides. Producing this supplemental voltage requires an extra voltage
converter, which consumes power and generates electromagnetic interference
which must, in turn, be filtered. Complex designs incorporating feedback are
needed to achieve linear response. The proposed Analog Isolated Multilevel
Quantizer (AIMQ) addresses these issues by monitoring the primary-side signal
and communicating the results to the secondary side using a novel scheme
involving Zener diodes, optocouplers, transistors, one-hot coding, and discrete
outputs. The result is a low power isolated transducer that can in principle be
extended to an arbitrary bit depth.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18761" title="Abstract">arXiv:2402.18761</a> (cross-list from eess.IV) [<a href="/pdf/2402.18761" title="Download PDF">pdf</a>, <a href="/format/2402.18761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration of Learned Lifting-Based Transform Structures for Fully  Scalable and Accessible Wavelet-Like Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinyue Li</a>, 
<a href="/search/eess?searchtype=author&query=Naman%2C+A">Aous Naman</a>, 
<a href="/search/eess?searchtype=author&query=Taubman%2C+D">David Taubman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">This paper provides a comprehensive study on features and performance of
different ways to incorporate neural networks into lifting-based wavelet-like
transforms, within the context of fully scalable and accessible image
compression. Specifically, we explore different arrangements of lifting steps,
as well as various network architectures for learned lifting operators.
Moreover, we examine the impact of the number of learned lifting steps, the
number of channels, the number of layers and the support of kernels in each
learned lifting operator. To facilitate the study, we investigate two generic
training methodologies that are simultaneously appropriate to a wide variety of
lifting structures considered. Experimental results ultimately suggest that
retaining fixed lifting steps from the base wavelet transform is highly
beneficial. Moreover, we demonstrate that employing more learned lifting steps
and more layers in each learned lifting operator do not contribute strongly to
the compression performance. However, benefits can be obtained by utilizing
more channels in each learned lifting operator. Ultimately, the learned
wavelet-like transform proposed in this paper achieves over 25% bit-rate
savings compared to JPEG 2000 with compact spatial support.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18777" title="Abstract">arXiv:2402.18777</a> (cross-list from eess.IV) [<a href="/pdf/2402.18777" title="Download PDF">pdf</a>, <a href="/ps/2402.18777" title="Download PostScript">ps</a>, <a href="/format/2402.18777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GDCNet: Calibrationless geometric distortion correction of echo planar  imaging data using deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jimeno%2C+M+M">Marina Manso Jimeno</a>, 
<a href="/search/eess?searchtype=author&query=Bachi%2C+K">Keren Bachi</a>, 
<a href="/search/eess?searchtype=author&query=Gardner%2C+G">George Gardner</a>, 
<a href="/search/eess?searchtype=author&query=Hurd%2C+Y+L">Yasmin L. Hurd</a>, 
<a href="/search/eess?searchtype=author&query=Vaughan%2C+J+T">John Thomas Vaughan Jr.</a>, 
<a href="/search/eess?searchtype=author&query=Geethanath%2C+S">Sairam Geethanath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 9 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Functional magnetic resonance imaging techniques benefit from echo-planar
imaging's fast image acquisition but are susceptible to inhomogeneities in the
main magnetic field, resulting in geometric distortion and signal loss
artifacts in the images. Traditional methods leverage a field map or voxel
displacement map for distortion correction. However, voxel displacement map
estimation requires additional sequence acquisitions, and the accuracy of the
estimation influences correction performance. This work implements a novel
approach called GDCNet, which estimates a geometric distortion map by
non-linear registration to T1-weighted anatomical images and applies it for
distortion correction. GDCNet demonstrated fast distortion correction of
functional images in retrospectively and prospectively acquired datasets. Among
the compared models, the 2D self-supervised configuration resulted in a
statistically significant improvement to normalized mutual information between
distortion-corrected functional and T1-weighted images compared to the
benchmark methods FUGUE and TOPUP. Furthermore, GDCNet models achieved
processing speeds 14 times faster than TOPUP in the prospective dataset.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18790" title="Abstract">arXiv:2402.18790</a> (cross-list from quant-ph) [<a href="/pdf/2402.18790" title="Download PDF">pdf</a>, <a href="/ps/2402.18790" title="Download PostScript">ps</a>, <a href="/format/2402.18790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Unentangled Quantum Proofs with Non-negative Amplitudes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jeronimo%2C+F+G">Fernando Granha Jeronimo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+P">Pei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 64 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Quantum entanglement is a fundamental property of quantum mechanics and plays
a crucial role in quantum computation and information. We study entanglement
via the lens of computational complexity by considering quantum generalizations
of the class NP with multiple unentangled quantum proofs, the so-called QMA(2)
and its variants. The complexity of QMA(2) is a longstanding open problem, and
only the trivial bounds QMA $\subseteq$ QMA(2) $\subseteq$ NEXP are known.
<br />In this work, we study the power of unentangled quantum proofs with
non-negative amplitudes, a class which we denote $\text{QMA}^+(2)$. In this
setting, we are able to design proof verification protocols for problems both
using logarithmic size quantum proofs and having a constant probability gap in
distinguishing yes from no instances. In particular, we design global protocols
for small set expansion, unique games, and PCP verification. As a consequence,
we obtain NP $\subseteq \text{QMA}^+_{\log}(2)$ with a constant gap. By virtue
of the new constant gap, we are able to ``scale up'' this result to
$\text{QMA}^+(2)$, obtaining the full characterization $\text{QMA}^+(2)$=NEXP
by establishing stronger explicitness properties of the PCP for NEXP.
<br />One key novelty of these protocols is the manipulation of quantum proofs in a
global and coherent way yielding constant gaps. Previous protocols (only
available for general amplitudes) are either local having vanishingly small
gaps or treat the quantum proofs as classical probability distributions
requiring polynomially many proofs thereby not implying non-trivial bounds on
QMA(2).
<br />Finally, we show that QMA(2) is equal to $\text{QMA}^+(2)$ provided the gap
of the latter is a sufficiently large constant. In particular, if
$\text{QMA}^+(2)$ admits gap amplification, then QMA(2)=NEXP.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18830" title="Abstract">arXiv:2402.18830</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2402.18830" title="Download PDF">pdf</a>, <a href="/format/2402.18830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training-set-free two-stage deep learning for Spectroscopic data  de-noising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+D+H+J">Dongchen Huang. Junde Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Qian%2C+T">Tian Qian</a>, 
<a href="/search/cond-mat?searchtype=author&query=Weng%2C+H">Hongming Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">De-noising is a prominent step in the spectra post-processing procedure.
Previous machine learning-based methods are fast but mostly based on supervised
learning and require a training set that may be typically expensive in real
experimental measurements. Unsupervised learning-based algorithms are slow and
require many iterations to achieve convergence. Here, we bridge this gap by
proposing a training-set-free two-stage deep learning method. We show that the
fuzzy fixed input in previous methods can be improved by introducing an
adaptive prior. Combined with more advanced optimization techniques, our
approach can achieve five times acceleration compared to previous work.
Theoretically, we study the landscape of a corresponding non-convex linear
problem, and our results indicates that this problem has benign geometry for
first-order algorithms to converge.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18856" title="Abstract">arXiv:2402.18856</a> (cross-list from eess.IV) [<a href="/pdf/2402.18856" title="Download PDF">pdf</a>, <a href="/format/2402.18856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomy-guided fiber trajectory distribution estimation for cranial  nerves tractography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Q">Qingrun Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Huajun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+G">Guoqiang Xie</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Mingchu Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jiahao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+J">Jianan Cui</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Y">Yuanjing Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion MRI tractography is an important tool for identifying and analyzing
the intracranial course of cranial nerves (CNs). However, the complex
environment of the skull base leads to ambiguous spatial correspondence between
diffusion directions and fiber geometry, and existing diffusion tractography
methods of CNs identification are prone to producing erroneous trajectories and
missing true positive connections. To overcome the above challenge, we propose
a novel CNs identification framework with anatomy-guided fiber trajectory
distribution, which incorporates anatomical shape prior knowledge during the
process of CNs tracing to build diffusion tensor vector fields. We introduce
higher-order streamline differential equations for continuous flow field
representations to directly characterize the fiber trajectory distribution of
CNs from the tract-based level. The experimental results on the vivo HCP
dataset and the clinical MDM dataset demonstrate that the proposed method
reduces false-positive fiber production compared to competing methods and
produces reconstructed CNs (i.e. CN II, CN III, CN V, and CN VII/VIII) that are
judged to better correspond to the known anatomy.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18867" title="Abstract">arXiv:2402.18867</a> (cross-list from eess.SP) [<a href="/pdf/2402.18867" title="Download PDF">pdf</a>, <a href="/format/2402.18867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message-Enhanced DeGroot Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhanjiang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H+V">H. Vicky Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Social and Information Networks (cs.SI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Understanding the impact of messages on agents' opinions over social networks
is important. However, to our best knowledge, there has been limited
quantitative investigation into this phenomenon in the prior works. To address
this gap, this paper proposes the Message-Enhanced DeGroot model. The Bounded
Brownian Message model provides a quantitative description of the message
evolution, jointly considering temporal continuity, randomness, and
polarization from mass media theory. The Message-Enhanced DeGroot model,
combining the Bounded Brownian Message model with the traditional DeGroot
model, quantitatively describes the evolution of agents' opinions under the
influence of messages. We theoretically study the probability distribution and
statistics of the messages and agents' opinions and quantitatively analyze the
impact of messages on opinions. We also conduct simulations to validate our
analyses.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18871" title="Abstract">arXiv:2402.18871</a> (cross-list from eess.IV) [<a href="/pdf/2402.18871" title="Download PDF">pdf</a>, <a href="/format/2402.18871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoLiSRFlow: Joint Single Image Low-light Enhancement and  Super-resolution via Cross-scale Transformer-based Conditional Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yue%2C+Z">Ziyu Yue</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jiaxin Gao</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+S">Sihan Xie</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+Z">Zhixun Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The visibility of real-world images is often limited by both low-light and
low-resolution, however, these issues are only addressed in the literature
through Low-Light Enhancement (LLE) and Super- Resolution (SR) methods.
Admittedly, a simple cascade of these approaches cannot work harmoniously to
cope well with the highly ill-posed problem for simultaneously enhancing
visibility and resolution. In this paper, we propose a normalizing flow
network, dubbed LoLiSRFLow, specifically designed to consider the degradation
mechanism inherent in joint LLE and SR. To break the bonds of the one-to-many
mapping for low-light low-resolution images to normal-light high-resolution
images, LoLiSRFLow directly learns the conditional probability distribution
over a variety of feasible solutions for high-resolution well-exposed images.
Specifically, a multi-resolution parallel transformer acts as a conditional
encoder that extracts the Retinex-induced resolution-and-illumination invariant
map as the previous one. And the invertible network maps the distribution of
usually exposed high-resolution images to a latent distribution. The backward
inference is equivalent to introducing an additional constrained loss for the
normal training route, thus enabling the manifold of the natural exposure of
the high-resolution image to be immaculately depicted. We also propose a
synthetic dataset modeling the realistic low-light low-resolution degradation,
named DFSR-LLE, containing 7100 low-resolution dark-light/high-resolution
normal sharp pairs. Quantitative and qualitative experimental results
demonstrate the effectiveness of our method on both the proposed synthetic and
real datasets.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18930" title="Abstract">arXiv:2402.18930</a> (cross-list from eess.IV) [<a href="/pdf/2402.18930" title="Download PDF">pdf</a>, <a href="/format/2402.18930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variable-Rate Learned Image Compression with Multi-Objective  Optimization and Quantization-Reconstruction Offsets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kamisli%2C+F">Fatih Kamisli</a>, 
<a href="/search/eess?searchtype=author&query=Racape%2C+F">Fabien Racape</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+H">Hyomin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a paper at DCC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Achieving successful variable bitrate compression with computationally simple
algorithms from a single end-to-end learned image or video compression model
remains a challenge. Many approaches have been proposed, including conditional
auto-encoders, channel-adaptive gains for the latent tensor or uniformly
quantizing all elements of the latent tensor. This paper follows the
traditional approach to vary a single quantization step size to perform uniform
quantization of all latent tensor elements. However, three modifications are
proposed to improve the variable rate compression performance. First, multi
objective optimization is used for (post) training. Second, a
quantization-reconstruction offset is introduced into the quantization
operation. Third, variable rate quantization is used also for the hyper latent.
All these modifications can be made on a pre-trained single-rate compression
model by performing post training. The algorithms are implemented into three
well-known image compression models and the achieved variable rate compression
results indicate negligible or minimal compression performance loss compared to
training multiple models. (Codes will be shared at
https://github.com/InterDigitalInc/CompressAI)
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18932" title="Abstract">arXiv:2402.18932</a> (cross-list from eess.AS) [<a href="/pdf/2402.18932" title="Download PDF">pdf</a>, <a href="/format/2402.18932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Multilingual Speech Synthesis to 100+ Languages without  Transcribed Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saeki%2C+T">Takaaki Saeki</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Gary Wang</a>, 
<a href="/search/eess?searchtype=author&query=Morioka%2C+N">Nobuyuki Morioka</a>, 
<a href="/search/eess?searchtype=author&query=Elias%2C+I">Isaac Elias</a>, 
<a href="/search/eess?searchtype=author&query=Kastner%2C+K">Kyle Kastner</a>, 
<a href="/search/eess?searchtype=author&query=Rosenberg%2C+A">Andrew Rosenberg</a>, 
<a href="/search/eess?searchtype=author&query=Ramabhadran%2C+B">Bhuvana Ramabhadran</a>, 
<a href="/search/eess?searchtype=author&query=Zen%2C+H">Heiga Zen</a>, 
<a href="/search/eess?searchtype=author&query=Beaufays%2C+F">Fran&#xe7;oise Beaufays</a>, 
<a href="/search/eess?searchtype=author&query=Shemtov%2C+H">Hadar Shemtov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Collecting high-quality studio recordings of audio is challenging, which
limits the language coverage of text-to-speech (TTS) systems. This paper
proposes a framework for scaling a multilingual TTS model to 100+ languages
using found data without supervision. The proposed framework combines
speech-text encoder pretraining with unsupervised training using untranscribed
speech and unspoken text data sources, thereby leveraging massively
multilingual joint speech and text representation learning. Without any
transcribed speech in a new language, this TTS model can generate intelligible
speech in &gt;30 unseen languages (CER difference of &lt;10% to ground truth). With
just 15 minutes of transcribed, found data, we can reduce the intelligibility
difference to 1% or less from the ground-truth, and achieve naturalness scores
that match the ground-truth in several languages.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18968" title="Abstract">arXiv:2402.18968</a> (cross-list from eess.AS) [<a href="/pdf/2402.18968" title="Download PDF">pdf</a>, <a href="/format/2402.18968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ambisonics Networks -- The Effect Of Radial Functions Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shaybet%2C+B">Bar Shaybet</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+A">Anurag Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Tourbabin%2C+V">Vladimir Tourbabin</a>, 
<a href="/search/eess?searchtype=author&query=Rafaely%2C+B">Boaz Rafaely</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in Icassp 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Ambisonics, a popular format of spatial audio, is the spherical harmonic (SH)
representation of the plane wave density function of a sound field. Many
algorithms operate in the SH domain and utilize the Ambisonics as their input
signal. The process of encoding Ambisonics from a spherical microphone array
involves dividing by the radial functions, which may amplify noise at low
frequencies. This can be overcome by regularization, with the downside of
introducing errors to the Ambisonics encoding. This paper aims to investigate
the impact of different ways of regularization on Deep Neural Network (DNN)
training and performance. Ideally, these networks should be robust to the way
of regularization. Simulated data of a single speaker in a room and
experimental data from the LOCATA challenge were used to evaluate this
robustness on an example algorithm of speaker localization based on the
direct-path dominance (DPD) test. Results show that performance may be
sensitive to the way of regularization, and an informed approach is proposed
and investigated, highlighting the importance of regularization information.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18984" title="Abstract">arXiv:2402.18984</a> (cross-list from math.CO) [<a href="/pdf/2402.18984" title="Download PDF">pdf</a>, <a href="/ps/2402.18984" title="Download PostScript">ps</a>, <a href="/format/2402.18984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Burning: Bounds and Hardness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antony%2C+D">Dhanyamol Antony</a>, 
<a href="/search/math?searchtype=author&query=Das%2C+A">Anita Das</a>, 
<a href="/search/math?searchtype=author&query=Gosavi%2C+S">Shirish Gosavi</a>, 
<a href="/search/math?searchtype=author&query=Jacob%2C+D">Dalu Jacob</a>, 
<a href="/search/math?searchtype=author&query=Kulamarva%2C+S">Shashanka Kulamarva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The burning number of a graph $G$, denoted by $b(G)$, is the minimum number
of steps required to burn all the vertices of a graph where in each step the
existing fire spreads to all the adjacent vertices and one additional vertex
can be burned as a new fire source. In this paper, we study the burning number
problem both from an algorithmic and a structural point of view. The decision
problem of computing the burning number of an input graph is known to be
NP-Complete for trees with maximum degree at most three and interval graphs.
Here, we prove that this problem is NP-Complete even when restricted to
connected proper interval graphs and connected cubic graphs. The well-known
burning number conjecture asserts that all the vertices of any graph of order
$n$ can be burned in $\lceil \sqrt{n}~\rceil$ steps. In line with this
conjecture, upper and lower bounds of $b(G)$ are well-studied for various
special graph classes. Here, we provide an improved upper bound for the burning
number of connected $P_k$-free graphs and show that the bound is tight up to an
additive constant $1$. Finally, we study two variants of the problem, namely
edge burning (only edges are burned) and total burning (both vertices and edges
are burned). In particular, we establish their relationship with the burning
number problem and evaluate the complexity of these variants.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19020" title="Abstract">arXiv:2402.19020</a> (cross-list from eess.IV) [<a href="/pdf/2402.19020" title="Download PDF">pdf</a>, <a href="/format/2402.19020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning of High-resolution Light Field Imaging via Beam  Splitter-based Hybrid Lenses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lei%2C+J">Jianxin Lei</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+C">Chengcai Xu</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Langqing Shi</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+P">Ping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we design a beam splitter-based hybrid light field imaging
prototype to record 4D light field image and high-resolution 2D image
simultaneously, and make a hybrid light field dataset. The 2D image could be
considered as the high-resolution ground truth corresponding to the
low-resolution central sub-aperture image of 4D light field image.
Subsequently, we propose an unsupervised learning-based super-resolution
framework with the hybrid light field dataset, which adaptively settles the
light field spatial super-resolution problem with a complex degradation model.
Specifically, we design two loss functions based on pre-trained models that
enable the super-resolution network to learn the detailed features and light
field parallax structure with only one ground truth. Extensive experiments
demonstrate the same superiority of our approach with supervised learning-based
state-of-the-art ones. To our knowledge, it is the first end-to-end
unsupervised learning-based spatial super-resolution approach in light field
imaging research, whose input is available from our beam splitter-based hybrid
light field system. The hardware and software together may help promote the
application of light field super-resolution to a great extent.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19043" title="Abstract">arXiv:2402.19043</a> (cross-list from eess.IV) [<a href="/pdf/2402.19043" title="Download PDF">pdf</a>, <a href="/format/2402.19043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WDM: 3D Wavelet Diffusion Models for High-Resolution Medical Image  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Friedrich%2C+P">Paul Friedrich</a>, 
<a href="/search/eess?searchtype=author&query=Wolleb%2C+J">Julia Wolleb</a>, 
<a href="/search/eess?searchtype=author&query=Bieder%2C+F">Florentin Bieder</a>, 
<a href="/search/eess?searchtype=author&query=Durrer%2C+A">Alicia Durrer</a>, 
<a href="/search/eess?searchtype=author&query=Cattin%2C+P+C">Philippe C. Cattin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/pfriedri/wdm-3d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Due to the three-dimensional nature of CT- or MR-scans, generative modeling
of medical images is a particularly challenging task. Existing approaches
mostly apply patch-wise, slice-wise, or cascaded generation techniques to fit
the high-dimensional data into the limited GPU memory. However, these
approaches may introduce artifacts and potentially restrict the model's
applicability for certain downstream tasks. This work presents WDM, a
wavelet-based medical image synthesis framework that applies a diffusion model
on wavelet decomposed images. The presented approach is a simple yet effective
way of scaling diffusion models to high resolutions and can be trained on a
single 40 GB GPU. Experimental results on BraTS and LIDC-IDRI unconditional
image generation at a resolution of $128 \times 128 \times 128$ show
state-of-the-art image fidelity (FID) and sample diversity (MS-SSIM) scores
compared to GANs, Diffusion Models, and Latent Diffusion Models. Our proposed
method is the only one capable of generating high-quality images at a
resolution of $256 \times 256 \times 256$.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19062" title="Abstract">arXiv:2402.19062</a> (cross-list from eess.IV) [<a href="/pdf/2402.19062" title="Download PDF">pdf</a>, <a href="/format/2402.19062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Convolutional Neural Networks for Automated Echocardiography View  Recognition: A Holistic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Thomas%2C+S">Sarina Thomas</a>, 
<a href="/search/eess?searchtype=author&query=Tiago%2C+C">Cristiana Tiago</a>, 
<a href="/search/eess?searchtype=author&query=Andreassen%2C+B+S">B&#xf8;rge Solli Andreassen</a>, 
<a href="/search/eess?searchtype=author&query=Aase%2C+S">Svein-Arne Aase</a>, 
<a href="/search/eess?searchtype=author&query=Sprem%2C+J">Jurica Sprem</a>, 
<a href="/search/eess?searchtype=author&query=Steen%2C+E">Erik Steen</a>, 
<a href="/search/eess?searchtype=author&query=Solberg%2C+A">Anne Solberg</a>, 
<a href="/search/eess?searchtype=author&query=Ben-Yosef%2C+G">Guy Ben-Yosef</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ASMUS - MICCAI conference 2023, Vancouver
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">To facilitate diagnosis on cardiac ultrasound (US), clinical practice has
established several standard views of the heart, which serve as reference
points for diagnostic measurements and define viewports from which images are
acquired. Automatic view recognition involves grouping those images into
classes of standard views. Although deep learning techniques have been
successful in achieving this, they still struggle with fully verifying the
suitability of an image for specific measurements due to factors like the
correct location, pose, and potential occlusions of cardiac structures. Our
approach goes beyond view classification and incorporates a 3D mesh
reconstruction of the heart that enables several more downstream tasks, like
segmentation and pose estimation. In this work, we explore learning 3D heart
meshes via graph convolutions, using similar techniques to learn 3D meshes in
natural images, such as human pose estimation. As the availability of fully
annotated 3D images is limited, we generate synthetic US images from 3D meshes
by training an adversarial denoising diffusion model. Experiments were
conducted on synthetic and clinical cases for view recognition and structure
detection. The approach yielded good performance on synthetic images and,
despite being exclusively trained on synthetic data, it already showed
potential when applied to clinical images. With this proof-of-concept, we aim
to demonstrate the benefits of graphs to improve cardiac view recognition that
can ultimately lead to better efficiency in cardiac diagnosis.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19084" title="Abstract">arXiv:2402.19084</a> (cross-list from math.AP) [<a href="/pdf/2402.19084" title="Download PDF">pdf</a>, <a href="/format/2402.19084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High multiplicity of positive solutions in a superlinear problem of  Moore-Nehari type
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cubillos%2C+P">Pablo Cubillos</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B3pez-G%C3%B3mez%2C+J">Juli&#xe1;n L&#xf3;pez-G&#xf3;mez</a>, 
<a href="/search/math?searchtype=author&query=Tellini%2C+A">Andrea Tellini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Classical Analysis and ODEs (math.CA); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper we consider a superlinear one-dimensional elliptic boundary
value problem that generalizes the one studied by Moore and Nehari in [43].
Specifically, we deal with piecewise-constant weight functions in front of the
nonlinearity with an arbitrary number $\kappa\geq 1$ of vanishing regions. We
study, from an analytic and numerical point of view, the number of positive
solutions, depending on the value of a parameter $\lambda$ and on $\kappa$.
<br />Our main results are twofold. On the one hand, we study analytically the
behavior of the solutions, as $\lambda\downarrow-\infty$, in the regions where
the weight vanishes. Our result leads us to conjecture the existence of
$2^{\kappa+1}-1$ solutions for sufficiently negative $\lambda$. On the other
hand, we support such a conjecture with the results of numerical simulations
which also shed light on the structure of the global bifurcation diagrams in
$\lambda$ and the profiles of positive solutions.
<br />Finally, we give additional numerical results suggesting that the same high
multiplicity result holds true for a much larger class of weights, also
arbitrarily close to situations where there is uniqueness of positive
solutions.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19095" title="Abstract">arXiv:2402.19095</a> (cross-list from q-bio.BM) [<a href="/pdf/2402.19095" title="Download PDF">pdf</a>, <a href="/ps/2402.19095" title="Download PostScript">ps</a>, <a href="/format/2402.19095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Protein Structure Prediction Approach Leveraging Transformer and CNN  Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+Y">Yanlin Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Tan%2C+K">Kai Tan</a>, 
<a href="/search/q-bio?searchtype=author&query=Shen%2C+X">Xinyu Shen</a>, 
<a href="/search/q-bio?searchtype=author&query=He%2C+Z">Zheng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Proteins are essential for life, and their structure determines their
function. The protein secondary structure is formed by the folding of the
protein primary structure, and the protein tertiary structure is formed by the
bending and folding of the secondary structure. Therefore, the study of protein
secondary structure is very helpful to the overall understanding of protein
structure. Although the accuracy of protein secondary structure prediction has
continuously improved with the development of machine learning and deep
learning, progress in the field of protein structure prediction, unfortunately,
remains insufficient to meet the large demand for protein information.
Therefore, based on the advantages of deep learning-based methods in feature
extraction and learning ability, this paper adopts a two-dimensional fusion
deep neural network model, DstruCCN, which uses Convolutional Neural Networks
(CCN) and a supervised Transformer protein language model for single-sequence
protein structure prediction. The training features of the two are combined to
predict the protein Transformer binding site matrix, and then the
three-dimensional structure is reconstructed using energy minimization.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19106" title="Abstract">arXiv:2402.19106</a> (cross-list from eess.AS) [<a href="/pdf/2402.19106" title="Download PDF">pdf</a>, <a href="/format/2402.19106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A SOUND APPROACH: Using Large Language Models to generate audio  descriptions for egocentric text-audio retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oncescu%2C+A">Andreea-Maria Oncescu</a>, 
<a href="/search/eess?searchtype=author&query=Henriques%2C+J+F">Jo&#xe3;o F. Henriques</a>, 
<a href="/search/eess?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>, 
<a href="/search/eess?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>, 
<a href="/search/eess?searchtype=author&query=Koepke%2C+A+S">A. Sophia Koepke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 9 tables, Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Information Retrieval (cs.IR); Sound (cs.SD)

</div>
<p class="mathjax">Video databases from the internet are a valuable source of text-audio
retrieval datasets. However, given that sound and vision streams represent
different "views" of the data, treating visual descriptions as audio
descriptions is far from optimal. Even if audio class labels are present, they
commonly are not very detailed, making them unsuited for text-audio retrieval.
To exploit relevant audio information from video-text datasets, we introduce a
methodology for generating audio-centric descriptions using Large Language
Models (LLMs). In this work, we consider the egocentric video setting and
propose three new text-audio retrieval benchmarks based on the EpicMIR and
EgoMCQ tasks, and on the EpicSounds dataset. Our approach for obtaining
audio-centric descriptions gives significantly higher zero-shot performance
than using the original visual-centric descriptions. Furthermore, we show that
using the same prompts, we can successfully employ LLMs to improve the
retrieval on EpicSounds, compared to using the original audio class labels of
the dataset. Finally, we confirm that LLMs can be used to determine the
difficulty of identifying the action associated with a sound.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19109" title="Abstract">arXiv:2402.19109</a> (cross-list from stat.ME) [<a href="/pdf/2402.19109" title="Download PDF">pdf</a>, <a href="/format/2402.19109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence and Assurance of Percentiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Joshi%2C+S+M">Sanjay M. Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Confidence interval of mean is often used when quoting statistics. The same
rigor is often missing when quoting percentiles and tolerance or percentile
intervals. This article derives the expression for confidence in percentiles of
a sample population. Confidence intervals of median is compared to those of
mean for a few sample distributions. The concept of assurance from reliability
engineering is then extended to percentiles. The assurance level of sorted
samples simply matches the confidence and percentile levels. Numerical method
to compute assurance using Brent's optimization method is provided as an
open-source python package.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19111" title="Abstract">arXiv:2402.19111</a> (cross-list from eess.IV) [<a href="/pdf/2402.19111" title="Download PDF">pdf</a>, <a href="/format/2402.19111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Network for Image Compressed Sensing Coding Using Local Structural  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+W">Wenxue Cui</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xingtao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+X">Xiaopeng Fan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shaohui Liu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+X">Xinwei Gao</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+D">Debin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Multimedia Computing Communications and Applications (TOMM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Existing image compressed sensing (CS) coding frameworks usually solve an
inverse problem based on measurement coding and optimization-based image
reconstruction, which still exist the following two challenges: 1) The widely
used random sampling matrix, such as the Gaussian Random Matrix (GRM), usually
leads to low measurement coding efficiency. 2) The optimization-based
reconstruction methods generally maintain a much higher computational
complexity. In this paper, we propose a new CNN based image CS coding framework
using local structural sampling (dubbed CSCNet) that includes three functional
modules: local structural sampling, measurement coding and Laplacian pyramid
reconstruction. In the proposed framework, instead of GRM, a new local
structural sampling matrix is first developed, which is able to enhance the
correlation between the measurements through a local perceptual sampling
strategy. Besides, the designed local structural sampling matrix can be jointly
optimized with the other functional modules during training process. After
sampling, the measurements with high correlations are produced, which are then
coded into final bitstreams by the third-party image codec. At last, a
Laplacian pyramid reconstruction network is proposed to efficiently recover the
target image from the measurement domain to the image domain. Extensive
experimental results demonstrate that the proposed scheme outperforms the
existing state-of-the-art CS coding methods, while maintaining fast
computational speed.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19172" title="Abstract">arXiv:2402.19172</a> (cross-list from eess.SP) [<a href="/pdf/2402.19172" title="Download PDF">pdf</a>, <a href="/format/2402.19172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Processes and spatial statistics in time-frequency analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pascal%2C+B">Barbara Pascal</a>, 
<a href="/search/eess?searchtype=author&query=Bardenet%2C+R">R&#xe9;mi Bardenet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS); Probability (math.PR)

</div>
<p class="mathjax">A finite-energy signal is represented by a square-integrable, complex-valued
function $t\mapsto s(t)$ of a real variable $t$, interpreted as time.
Similarly, a noisy signal is represented by a random process. Time-frequency
analysis, a subfield of signal processing, amounts to describing the temporal
evolution of the frequency content of a signal. Loosely speaking, if $s$ is the
audio recording of a musical piece, time-frequency analysis somehow consists in
writing the musical score of the piece. Mathematically, the operation is
performed through a transform $\mathcal{V}$, mapping $s \in L^2(\mathbb{R})$
onto a complex-valued function $\mathcal{V}s \in L^2(\mathbb{R}^2)$ of time $t$
and angular frequency $\omega$. The squared modulus $(t, \omega) \mapsto
\vert\mathcal{V}s(t,\omega)\vert^2$ of the time-frequency representation is
known as the spectrogram of $s$; in the musical score analogy, a peaked
spectrogram at $(t_0,\omega_0)$ corresponds to a musical note at angular
frequency $\omega_0$ localized at time $t_0$. More generally, the intuition is
that upper level sets of the spectrogram contain relevant information about in
the original signal. Hence, many signal processing algorithms revolve around
identifying maxima of the spectrogram. In contrast, zeros of the spectrogram
indicate perfect silence, that is, a time at which a particular frequency is
absent. Assimilating $\mathbb{R}^2$ to $\mathbb{C}$ through $z = \omega +
\mathrm{i}t$, this chapter focuses on time-frequency transforms $\mathcal{V}$
that map signals to analytic functions. The zeros of the spectrogram of a noisy
signal are then the zeros of a random analytic function, hence forming a Point
Process in $\mathbb{C}$. This chapter is devoted to the study of these Point
Processes, to their links with zeros of Gaussian Analytic Functions, and to
designing signal detection and denoising algorithms using spatial statistics.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19212" title="Abstract">arXiv:2402.19212</a> (cross-list from math.OC) [<a href="/pdf/2402.19212" title="Download PDF">pdf</a>, <a href="/ps/2402.19212" title="Download PostScript">ps</a>, <a href="/format/2402.19212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning: A Convex Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gattami%2C+A">Ather Gattami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we consider reinforcement learning of nonlinear systems with
continuous state and action spaces. We present an episodic learning algorithm,
where we for each episode use convex optimization to find a two-layer neural
network approximation of the optimal $Q$-function. The convex optimization
approach guarantees that the weights calculated at each episode are optimal,
with respect to the given sampled states and actions of the current episode.
For stable nonlinear systems, we show that the algorithm converges and that the
converging parameters of the trained neural network can be made arbitrarily
close to the optimal neural network parameters. In particular, if the
regularization parameter is $\rho$ and the time horizon is $T$, then the
parameters of the trained neural network converge to $w$, where the distance
between $w$ from the optimal parameters $w^\star$ is bounded by
$\mathcal{O}(\rho T^{-1})$. That is, when the number of episodes goes to
infinity, there exists a constant $C$ such that \[\|w-w^\star\| \le
C\cdot\frac{\rho}{T}.\] In particular, our algorithm converges arbitrarily
close to the optimal neural network parameters as the time horizon increases or
as the regularization parameter decreases.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19215" title="Abstract">arXiv:2402.19215</a> (cross-list from eess.IV) [<a href="/pdf/2402.19215" title="Download PDF">pdf</a>, <a href="/format/2402.19215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Generative Image Super-Resolution Models by Wavelet-Domain  Losses Enables Better Control of Artifacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Korkmaz%2C+C">Cansu Korkmaz</a>, 
<a href="/search/eess?searchtype=author&query=Tekalp%2C+A+M">A. Murat Tekalp</a>, 
<a href="/search/eess?searchtype=author&query=Dogan%2C+Z">Zafer Dogan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IEEE CVPR 2024, total of 11 pages, 3 pages for references, 7 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Super-resolution (SR) is an ill-posed inverse problem, where the size of the
set of feasible solutions that are consistent with a given low-resolution image
is very large. Many algorithms have been proposed to find a "good" solution
among the feasible solutions that strike a balance between fidelity and
perceptual quality. Unfortunately, all known methods generate artifacts and
hallucinations while trying to reconstruct high-frequency (HF) image details. A
fundamental question is: Can a model learn to distinguish genuine image details
from artifacts? Although some recent works focused on the differentiation of
details and artifacts, this is a very challenging problem and a satisfactory
solution is yet to be found. This paper shows that the characterization of
genuine HF details versus artifacts can be better learned by training GAN-based
SR models using wavelet-domain loss functions compared to RGB-domain or
Fourier-space losses. Although wavelet-domain losses have been used in the
literature before, they have not been used in the context of the SR task. More
specifically, we train the discriminator only on the HF wavelet sub-bands
instead of on RGB images and the generator is trained by a fidelity loss over
wavelet subbands to make it sensitive to the scale and orientation of
structures. Extensive experimental results demonstrate that our model achieves
better perception-distortion trade-off according to multiple objective measures
and visual evaluations.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19234" title="Abstract">arXiv:2402.19234</a> (cross-list from math.CO) [<a href="/pdf/2402.19234" title="Download PDF">pdf</a>, <a href="/ps/2402.19234" title="Download PostScript">ps</a>, <a href="/format/2402.19234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Broadcast independence number of oriented circulant graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Laouar%2C+A">Abdelamin Laouar</a>, 
<a href="/search/math?searchtype=author&query=Bouchemakh%2C+I">Isma Bouchemakh</a>, 
<a href="/search/math?searchtype=author&query=Sopena%2C+E">Eric Sopena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2102.04094">arXiv:2102.04094</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In 2001, D. Erwin \cite{Erw01} introduced in his Ph.D. dissertation the
notion of broadcast independence in unoriented graphs. Since then, some results
but not many, are published on this notion, including research work on the
broadcast independence number of unoriented circulant graphs \cite{LBS23}. In
this paper, we are focused in the same parameter but of the class of oriented
circulant graphs. An independent broadcast on an oriented graph
$\overrightarrow{G}$ is a function $f: V\longrightarrow
\{0,\ldots,\diam(\overrightarrow{G})\}$ such that $(i)$ $f(v)\leq e(v)$ for
every vertex $v\in V(\overrightarrow{G})$, where $\diam(\overrightarrow{G})$
denotes the diameter of $\overrightarrow{G}$ and $e(v)$ the eccentricity of
vertex $v$, and $(ii)$ $d_{\overrightarrow{G}}(u,v) &gt; f(u)$ for every distinct
vertices $u$, $v$ with $f(u)$, $f(v)&gt;0$, where $d_{\overrightarrow{G}}(u,v)$
denotes the length of a shortest oriented path from $u$ to $v$. The broadcast
independence number $\beta_b(\overrightarrow{G})$ of $\overrightarrow{G}$ is
then the maximum value of $\sum_{v \in V} f(v)$, taken over all independent
broadcasts on $\overrightarrow{G}$. The goal of this paper is to study the
properties of independent broadcasts of oriented circulant graphs
$\overrightarrow{C}(n;1,a)$, for any integers $n$ and $a$ with $n&gt;|a|\geq 1$
and $a \notin \{1,n-1\}$. Then, we give some bounds and some exact values for
the number $\beta_b(\overrightarrow{C}(n;1,a))$.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19266" title="Abstract">arXiv:2402.19266</a> (cross-list from math.CT) [<a href="/pdf/2402.19266" title="Download PDF">pdf</a>, <a href="/ps/2402.19266" title="Download PostScript">ps</a>, <a href="/format/2402.19266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cauchy-completions and the rule of unique choice in relational doctrines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dagnino%2C+F">Francesco Dagnino</a>, 
<a href="/search/math?searchtype=author&query=Pasquali%2C+F">Fabio Pasquali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
<p class="mathjax">Lawvere's generalised the notion of complete metric space to the field of
enriched categories: an enriched category is said to be Cauchy-complete if
every left adjoint bimodule into it is represented by an enriched functor.
Looking at this definition from a logical standpoint, regarding bimodules as an
abstraction of relations and functors as an abstraction of functions,
Cauchy-completeness resembles a formulation of the rule of unique choice. In
this paper, we make this analogy precise, using the language of relational
doctrines, a categorical tool that provides a functorial description of the
calculus of relations, in the same way Lawvere's hyperdoctrines give a
functorial description of predicate logic. Given a relational doctrine, we
define Cauchy-complete objects as those objects of the domain category
satisfying the rule of unique choice. Then, we present a universal construction
that completes a relational doctrine with the rule of unique choice, that is,
producing a new relational doctrine where all objects are Cauchy-complete. We
also introduce relational doctrines with singleton objects and show that these
have the minimal structure needed to build the reflector of the full
subcategory of its domain on Cauchy-complete objects. The main result is that
this reflector exists if and only if the relational doctrine has singleton
objects and this happens if and only if its restriction to Cauchy-complete
objects is equivalent to its completion with the rule of unique choice. We
support our results with many examples, also falling outside the scope of
standard doctrines, such as complete metric spaces, Banach spaces and compact
Hausdorff spaces in the general context of monoidal topology, which are all
shown to be Cauchy-complete objects for appropriate relational doctrines.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19276" title="Abstract">arXiv:2402.19276</a> (cross-list from eess.IV) [<a href="/pdf/2402.19276" title="Download PDF">pdf</a>, <a href="/format/2402.19276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Blind Video Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+W">Wen Wen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Mu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yabin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+Y">Yiting Liao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Junlin Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+K">Kede Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Blind video quality assessment (BVQA) plays a pivotal role in evaluating and
improving the viewing experience of end-users across a wide range of
video-based platforms and services. Contemporary deep learning-based models
primarily analyze the video content in its aggressively downsampled format,
while being blind to the impact of actual spatial resolution and frame rate on
video quality. In this paper, we propose a modular BVQA model, and a method of
training it to improve its modularity. Specifically, our model comprises a base
quality predictor, a spatial rectifier, and a temporal rectifier, responding to
the visual content and distortion, spatial resolution, and frame rate changes
on video quality, respectively. During training, spatial and temporal
rectifiers are dropped out with some probabilities so as to make the base
quality predictor a standalone BVQA model, which should work better with the
rectifiers. Extensive experiments on both professionally-generated content and
user generated content video databases show that our quality model achieves
superior or comparable performance to current methods. Furthermore, the
modularity of our model offers a great opportunity to analyze existing video
quality databases in terms of their spatial and temporal complexities. Last,
our BVQA model is cost-effective to add other quality-relevant video attributes
such as dynamic range and color gamut as additional rectifiers.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19286" title="Abstract">arXiv:2402.19286</a> (cross-list from eess.IV) [<a href="/pdf/2402.19286" title="Download PDF">pdf</a>, <a href="/format/2402.19286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrPSeg: Universal Proposition Learning for Panoramic Renal Pathology  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Quan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+T">Tianyuan Yao</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+J">Jialin Yue</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+J">Juming Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+L">Lining Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yifei Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+M">Mengmeng Yin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Shilin Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yucheng Tang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Haichun Yang</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE / CVF Computer Vision and Pattern Recognition Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Understanding the anatomy of renal pathology is crucial for advancing disease
diagnostics, treatment evaluation, and clinical research. The complex kidney
system comprises various components across multiple levels, including regions
(cortex, medulla), functional units (glomeruli, tubules), and cells (podocytes,
mesangial cells in glomerulus). Prior studies have predominantly overlooked the
intricate spatial interrelations among objects from clinical knowledge. In this
research, we introduce a novel universal proposition learning approach, called
panoramic renal pathology segmentation (PrPSeg), designed to segment
comprehensively panoramic structures within kidney by integrating extensive
knowledge of kidney anatomy.
<br />In this paper, we propose (1) the design of a comprehensive universal
proposition matrix for renal pathology, facilitating the incorporation of
classification and spatial relationships into the segmentation process; (2) a
token-based dynamic head single network architecture, with the improvement of
the partial label image segmentation and capability for future data
enlargement; and (3) an anatomy loss function, quantifying the inter-object
relationships across the kidney.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19289" title="Abstract">arXiv:2402.19289</a> (cross-list from eess.IV) [<a href="/pdf/2402.19289" title="Download PDF">pdf</a>, <a href="/format/2402.19289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMixerSR: Only Details Need More &quot;Attention&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Shijie Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Junlin Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024. Paper and supplementary material, under camera-ready revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">To satisfy the rapidly increasing demands on the large image (2K-8K)
super-resolution (SR), prevailing methods follow two independent tracks: 1)
accelerate existing networks by content-aware routing, and 2) design better
super-resolution networks via token mixer refining. Despite directness, they
encounter unavoidable defects (e.g., inflexible route or non-discriminative
processing) limiting further improvements of quality-complexity trade-off. To
erase the drawbacks, we integrate these schemes by proposing a content-aware
mixer (CAMixer), which assigns convolution for simple contexts and additional
deformable window-attention for sparse textures. Specifically, the CAMixer uses
a learnable predictor to generate multiple bootstraps, including offsets for
windows warping, a mask for classifying windows, and convolutional attentions
for endowing convolution with the dynamic property, which modulates attention
to include more useful textures self-adaptively and improves the representation
capability of convolution. We further introduce a global classification loss to
improve the accuracy of predictors. By simply stacking CAMixers, we obtain
CAMixerSR which achieves superior performance on large-image SR, lightweight
SR, and omnidirectional-image SR.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19329" title="Abstract">arXiv:2402.19329</a> (cross-list from physics.soc-ph) [<a href="/pdf/2402.19329" title="Download PDF">pdf</a>, <a href="/format/2402.19329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Links vs. Language Barriers: Decoding the Global Spread of  Streaming Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Park%2C+S">Seoyoung Park</a>, 
<a href="/search/physics?searchtype=author&query=Park%2C+S">Sanghyeok Park</a>, 
<a href="/search/physics?searchtype=author&query=You%2C+T">Taekho You</a>, 
<a href="/search/physics?searchtype=author&query=Yun%2C+J">Jinhyuk Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages, 4 figures, and 1 table in manuscript, including 5 SI figures and 7 SI tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The development of the internet has allowed for the global distribution of
content, redefining media communication and property structures through various
streaming platforms. Previous studies successfully clarified the factors
contributing to trends in each streaming service, yet the similarities and
differences between platforms are commonly unexplored; moreover, the influence
of social connections and cultural similarity is usually overlooked. We hereby
examine the social aspects of three significant streaming services--Netflix,
Spotify, and YouTube--with an emphasis on the dissemination of content across
countries. Using two-year-long trending chart datasets, we find that streaming
content can be divided into two types: video-oriented (Netflix) and
audio-oriented (Spotify). This characteristic is differentiated by accounting
for the significance of social connectedness and linguistic similarity:
audio-oriented content travels via social links, but video-oriented content
tends to spread throughout linguistically akin countries. Interestingly,
user-generated contents, YouTube, exhibits a dual characteristic by integrating
both visual and auditory characteristics, indicating the platform is evolving
into unique medium rather than simply residing a midpoint between video and
audio media.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19351" title="Abstract">arXiv:2402.19351</a> (cross-list from math.CO) [<a href="/pdf/2402.19351" title="Download PDF">pdf</a>, <a href="/ps/2402.19351" title="Download PostScript">ps</a>, <a href="/format/2402.19351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oriented trees in $O(k \sqrt{k})$-chromatic digraphs, a subquadratic  bound for Burr&#x27;s conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bessy%2C+S">St&#xe9;phane Bessy</a>, 
<a href="/search/math?searchtype=author&query=Gon%C3%A7alves%2C+D">Daniel Gon&#xe7;alves</a>, 
<a href="/search/math?searchtype=author&query=Reinald%2C+A">Amadeus Reinald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In 1980, Burr conjectured that every directed graph with chromatic number
$2k-2$ contains any oriented tree of order $k$ as a subdigraph. Burr showed
that chromatic number $(k-1)^2$ suffices, which was improved in 2013 to
$\frac{k^2}{2} - \frac{k}{2} + 1$ by Addario-Berry et al. We give the first
subquadratic bound for Burr's conjecture, by showing that every directed graph
with chromatic number $8\sqrt{\frac{2}{15}} k \sqrt{k} + O(k)$ contains any
oriented tree of order $k$. Moreover, we provide improved bounds of
$\sqrt{\frac{4}{3}} k \sqrt{k}+O(k)$ for arborescences, and $(b-1)(k-3)+3$ for
paths on $b$ blocks, with $b\ge 2$.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19360" title="Abstract">arXiv:2402.19360</a> (cross-list from math.OC) [<a href="/pdf/2402.19360" title="Download PDF">pdf</a>, <a href="/format/2402.19360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Chance Constrained Optimal Control via Linear Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schmid%2C+N">Niklas Schmid</a>, 
<a href="/search/math?searchtype=author&query=Fochesato%2C+M">Marta Fochesato</a>, 
<a href="/search/math?searchtype=author&query=Sutter%2C+T">Tobias Sutter</a>, 
<a href="/search/math?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We establish a linear programming formulation for the solution of joint
chance constrained optimal control problems over finite time horizons. The
joint chance constraint may represent an invariance, reachability or
reach-avoid specification that the trajectory must satisfy with a predefined
probability. Compared to the existing literature, the formulation is
computationally tractable and the solution exact.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19387" title="Abstract">arXiv:2402.19387</a> (cross-list from eess.IV) [<a href="/pdf/2402.19387" title="Download PDF">pdf</a>, <a href="/format/2402.19387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeD: Semantic-Aware Discriminator for Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bingchen Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+H">Hanxin Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Y">Yeying Jin</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+R">Ruoyu Feng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhizheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have been widely used to recover vivid
textures in image super-resolution (SR) tasks. In particular, one discriminator
is utilized to enable the SR network to learn the distribution of real-world
high-quality images in an adversarial training manner. However, the
distribution learning is overly coarse-grained, which is susceptible to virtual
textures and causes counter-intuitive generation results. To mitigate this, we
propose the simple and effective Semantic-aware Discriminator (denoted as SeD),
which encourages the SR network to learn the fine-grained distributions by
introducing the semantics of images as a condition. Concretely, we aim to
excavate the semantics of images from a well-trained semantic extractor. Under
different semantics, the discriminator is able to distinguish the real-fake
images individually and adaptively, which guides the SR network to learn the
more fine-grained semantic-aware textures. To obtain accurate and abundant
semantics, we take full advantage of recently popular pretrained vision models
(PVMs) with extensive datasets, and then incorporate its semantic features into
the discriminator through a well-designed spatial cross-attention module. In
this way, our proposed semantic-aware discriminator empowered the SR network to
produce more photo-realistic and pleasing images. Extensive experiments on two
typical tasks, i.e., SR and Real SR have demonstrated the effectiveness of our
proposed methods.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19455" title="Abstract">arXiv:2402.19455</a> (cross-list from stat.ML) [<a href="/pdf/2402.19455" title="Download PDF">pdf</a>, <a href="/format/2402.19455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Listening to the Noise: Blind Denoising with Gibbs Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Heurtel-Depeiges%2C+D">David Heurtel-Depeiges</a>, 
<a href="/search/stat?searchtype=author&query=Margossian%2C+C+C">Charles C. Margossian</a>, 
<a href="/search/stat?searchtype=author&query=Ohana%2C+R">Ruben Ohana</a>, 
<a href="/search/stat?searchtype=author&query=Blancard%2C+B+R">Bruno R&#xe9;galdo-Saint Blancard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12+8 pages, 7+3 figures, 1+1 tables, code: <a href="https://github.com/rubenohana/Gibbs-Diffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">In recent years, denoising problems have become intertwined with the
development of deep generative models. In particular, diffusion models are
trained like denoisers, and the distribution they model coincide with denoising
priors in the Bayesian picture. However, denoising through diffusion-based
posterior sampling requires the noise level and covariance to be known,
preventing blind denoising. We overcome this limitation by introducing Gibbs
Diffusion (GDiff), a general methodology addressing posterior sampling of both
the signal and the noise parameters. Assuming arbitrary parametric Gaussian
noise, we develop a Gibbs algorithm that alternates sampling steps from a
conditional diffusion model trained to map the signal prior to the family of
noise distributions, and a Monte Carlo sampler to infer the noise parameters.
Our theoretical analysis highlights potential pitfalls, guides diagnostic
usage, and quantifies errors in the Gibbs stationary distribution caused by the
diffusion model. We showcase our method for 1) blind denoising of natural
images involving colored noises with unknown amplitude and spectral index, and
2) a cosmology problem, namely the analysis of cosmic microwave background
data, where Bayesian inference of "noise" parameters means constraining models
of the evolution of the Universe.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19456" title="Abstract">arXiv:2402.19456</a> (cross-list from quant-ph) [<a href="/pdf/2402.19456" title="Download PDF">pdf</a>, <a href="/format/2402.19456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Estimation in the Spiked Tensor Model via the Quantum  Approximate Optimization Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+L">Leo Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Basso%2C+J">Joao Basso</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mei%2C+S">Song Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">The quantum approximate optimization algorithm (QAOA) is a general-purpose
algorithm for combinatorial optimization. In this paper, we analyze the
performance of the QAOA on a statistical estimation problem, namely, the spiked
tensor model, which exhibits a statistical-computational gap classically. We
prove that the weak recovery threshold of $1$-step QAOA matches that of
$1$-step tensor power iteration. Additional heuristic calculations suggest that
the weak recovery threshold of $p$-step QAOA matches that of $p$-step tensor
power iteration when $p$ is a fixed constant. This further implies that
multi-step QAOA with tensor unfolding could achieve, but not surpass, the
classical computation threshold $\Theta(n^{(q-2)/4})$ for spiked $q$-tensors.
<br />Meanwhile, we characterize the asymptotic overlap distribution for $p$-step
QAOA, finding an intriguing sine-Gaussian law verified through simulations. For
some $p$ and $q$, the QAOA attains an overlap that is larger by a constant
factor than the tensor power iteration overlap. Of independent interest, our
proof techniques employ the Fourier transform to handle difficult combinatorial
sums, a novel approach differing from prior QAOA analyses on spin-glass models
without planted structure.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19462" title="Abstract">arXiv:2402.19462</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2402.19462" title="Download PDF">pdf</a>, <a href="/format/2402.19462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating materials discovery for polymer solar cells: Data-driven  insights enabled by natural language processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Shetty%2C+P">Pranav Shetty</a>, 
<a href="/search/cond-mat?searchtype=author&query=Adeboye%2C+A">Aishat Adeboye</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gupta%2C+S">Sonakshi Gupta</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ramprasad%2C+R">Rampi Ramprasad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computation and Language (cs.CL); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">We present a natural language processing pipeline that was used to extract
polymer solar cell property data from the literature and simulate various
active learning strategies. While data-driven methods have been well
established to discover novel materials faster than Edisonian trial-and-error
approaches, their benefits have not been quantified. Our approach demonstrates
a potential reduction in discovery time by approximately 75 %, equivalent to a
15 year acceleration in material innovation. Our pipeline enables us to extract
data from more than 3300 papers which is ~5 times larger than similar data sets
reported by others. We also trained machine learning models to predict the
power conversion efficiency and used our model to identify promising
donor-acceptor combinations that are as yet unreported. We thus demonstrate a
workflow that goes from published literature to extracted material property
data which in turn is used to obtain data-driven insights. Our insights include
active learning strategies that can simultaneously optimize the material system
and train strong predictive models of material properties. This work provides a
valuable framework for research in material science.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19470" title="Abstract">arXiv:2402.19470</a> (cross-list from eess.IV) [<a href="/pdf/2402.19470" title="Download PDF">pdf</a>, <a href="/format/2402.19470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalizable Tumor Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaoxi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+H">Haorui Song</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Z">Zongwei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Tumor synthesis enables the creation of artificial tumors in medical images,
facilitating the training of AI models for tumor detection and segmentation.
However, success in tumor synthesis hinges on creating visually realistic
tumors that are generalizable across multiple organs and, furthermore, the
resulting AI models being capable of detecting real tumors in images sourced
from different domains (e.g., hospitals). This paper made a progressive stride
toward generalizable tumor synthesis by leveraging a critical observation:
early-stage tumors (&lt; 2cm) tend to have similar imaging characteristics in
computed tomography (CT), whether they originate in the liver, pancreas, or
kidneys. We have ascertained that generative AI models, e.g., Diffusion Models,
can create realistic tumors generalized to a range of organs even when trained
on a limited number of tumor examples from only one organ. Moreover, we have
shown that AI models trained on these synthetic tumors can be generalized to
detect and segment real tumors from CT volumes, encompassing a broad spectrum
of patient demographics, imaging protocols, and healthcare facilities.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri,  1 Mar 24</h3>
<dl>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1806.05451" title="Abstract">arXiv:1806.05451</a> (replaced) [<a href="/pdf/1806.05451" title="Download PDF">pdf</a>, <a href="/format/1806.05451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The committee machine: Computational to statistical gaps in learning a  two-layers neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aubin%2C+B">Benjamin Aubin</a>, 
<a href="/search/cs?searchtype=author&query=Maillard%2C+A">Antoine Maillard</a>, 
<a href="/search/cs?searchtype=author&query=Barbier%2C+J">Jean Barbier</a>, 
<a href="/search/cs?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>, 
<a href="/search/cs?searchtype=author&query=Macris%2C+N">Nicolas Macris</a>, 
<a href="/search/cs?searchtype=author&query=Zdeborov%C3%A1%2C+L">Lenka Zdeborov&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages + supplementary material, 3 figures. (v2: update to match the published version ; v3: clarification of the caption of Fig. 3)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Stat. Mech. (2019) 124023. &amp; NeurIPS 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.12438" title="Abstract">arXiv:2002.12438</a> (replaced) [<a href="/pdf/2002.12438" title="Download PDF">pdf</a>, <a href="/format/2002.12438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Public Quantum Coins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Behera%2C+A">Amit Behera</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sattath%2C+O">Or Sattath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.10628" title="Abstract">arXiv:2006.10628</a> (replaced) [<a href="/pdf/2006.10628" title="Download PDF">pdf</a>, <a href="/format/2006.10628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline detection of change-points in the mean for stationary graph  signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+la+Concha%2C+A">Alejandro de la Concha</a>, 
<a href="/search/cs?searchtype=author&query=Vayatis%2C+N">Nicolas Vayatis</a>, 
<a href="/search/cs?searchtype=author&query=Kalogeratos%2C+A">Argyris Kalogeratos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures, 1 table, 1 annex. 9 pages of main text
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.10479" title="Abstract">arXiv:2106.10479</a> (replaced) [<a href="/pdf/2106.10479" title="Download PDF">pdf</a>, <a href="/format/2106.10479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Transferability Estimation for Image Classification Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shao-Lun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is not the latest version. Please refer to Transferability-Guided Cross-Domain Cross-Task Transfer Learning (IEEE TNNLS'24) for more details.<a href="https://ieeexplore.ieee.org/abstract/document/10420486">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.14969" title="Abstract">arXiv:2106.14969</a> (replaced) [<a href="/pdf/2106.14969" title="Download PDF">pdf</a>, <a href="/format/2106.14969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hop-Constrained Metric Embeddings and their Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filtser%2C+A">Arnold Filtser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.02270" title="Abstract">arXiv:2107.02270</a> (replaced) [<a href="/pdf/2107.02270" title="Download PDF">pdf</a>, <a href="/format/2107.02270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accessible Color Sequences for Data Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petroff%2C+M+A">Matthew A. Petroff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures, 4 tables; comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.02743" title="Abstract">arXiv:2107.02743</a> (replaced) [<a href="/pdf/2107.02743" title="Download PDF">pdf</a>, <a href="/ps/2107.02743" title="Download PostScript">ps</a>, <a href="/format/2107.02743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Submodular Order Functions and Assortment Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Udwani%2C+R">Rajan Udwani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Management Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.15242" title="Abstract">arXiv:2109.15242</a> (replaced) [<a href="/pdf/2109.15242" title="Download PDF">pdf</a>, <a href="/format/2109.15242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferability Estimation for Semantic Segmentation Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shao-Lun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is not the latest version. Please refer to Efficient Prediction of Model Transferability in Semantic Segmentation Tasks (ICIP'23) for more details. <a href="https://ieeexplore.ieee.org/abstract/document/10222912">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11385" title="Abstract">arXiv:2110.11385</a> (replaced) [<a href="/pdf/2110.11385" title="Download PDF">pdf</a>, <a href="/ps/2110.11385" title="Download PostScript">ps</a>, <a href="/format/2110.11385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Initiated Open World Learning for Autonomous AI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+E">Eric Robertson</a>, 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+S">Scott Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+S">Sahisnu Mazumder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AAAI 2022 Spring Symposium Series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.05478" title="Abstract">arXiv:2112.05478</a> (replaced) [<a href="/pdf/2112.05478" title="Download PDF">pdf</a>, <a href="/format/2112.05478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical configurations for three projective views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Br%C3%A5telund%2C+M">Martin Br&#xe5;telund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 9 figures. This is a companion paper to <a href="/abs/2112.05074">arXiv:2112.05074</a>. Accepted manuscript published in Mathematica Scandinavica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.08370" title="Abstract">arXiv:2202.08370</a> (replaced) [<a href="/pdf/2202.08370" title="Download PDF">pdf</a>, <a href="/format/2202.08370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAREER: A Foundation Model for Labor Sequence Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vafa%2C+K">Keyon Vafa</a>, 
<a href="/search/cs?searchtype=author&query=Palikot%2C+E">Emil Palikot</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Kanodia%2C+A">Ayush Kanodia</a>, 
<a href="/search/cs?searchtype=author&query=Athey%2C+S">Susan Athey</a>, 
<a href="/search/cs?searchtype=author&query=Blei%2C+D+M">David M. Blei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01360" title="Abstract">arXiv:2203.01360</a> (replaced) [<a href="/pdf/2203.01360" title="Download PDF">pdf</a>, <a href="/format/2203.01360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Galerkin Schemes with Active Learning for High-Dimensional  Evolution Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bruna%2C+J">Joan Bruna</a>, 
<a href="/search/math?searchtype=author&query=Peherstorfer%2C+B">Benjamin Peherstorfer</a>, 
<a href="/search/math?searchtype=author&query=Vanden-Eijnden%2C+E">Eric Vanden-Eijnden</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational Physics, Volume 496, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08964" title="Abstract">arXiv:2203.08964</a> (replaced) [<a href="/pdf/2203.08964" title="Download PDF">pdf</a>, <a href="/format/2203.08964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-Unet: A Context-aware Point-based Neural Network for Volumetric  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+N">Ngoc-Vuong Ho</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Diep%2C+G">Gia-Han Diep</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in MICCAI 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04377" title="Abstract">arXiv:2204.04377</a> (replaced) [<a href="/pdf/2204.04377" title="Download PDF">pdf</a>, <a href="/format/2204.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Surgery Remote Mentoring via AR with 3D Scene Streaming and Hand  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yonghao Long</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengkun Li</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10485" title="Abstract">arXiv:2206.10485</a> (replaced) [<a href="/pdf/2206.10485" title="Download PDF">pdf</a>, <a href="/format/2206.10485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight bounds for the learning of homotopy &#xe0; la Niyogi, Smale, and  Weinberger for subsets of Euclidean spaces and of Riemannian manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attali%2C+D">Dominique Attali</a>, 
<a href="/search/cs?searchtype=author&query=Kou%C5%99imsk%C3%A1%2C+H+D+P">Hana Dal Poz Kou&#x159;imsk&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Fillmore%2C+C">Christopher Fillmore</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+I">Ishika Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Lieutier%2C+A">Andr&#xe9; Lieutier</a>, 
<a href="/search/cs?searchtype=author&query=Stephenson%2C+E">Elizabeth Stephenson</a>, 
<a href="/search/cs?searchtype=author&query=Wintraecken%2C+M">Mathijs Wintraecken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages, 29 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Algebraic Topology (math.AT)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05510" title="Abstract">arXiv:2207.05510</a> (replaced) [<a href="/pdf/2207.05510" title="Download PDF">pdf</a>, <a href="/format/2207.05510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferability-Guided Cross-Domain Cross-Task Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shao-Lun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is accepted by IEEE TNNLS. Please see the official version <a href="https://ieeexplore.ieee.org/abstract/document/10420486.Copyright">this https URL</a> may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00945" title="Abstract">arXiv:2209.00945</a> (replaced) [<a href="/pdf/2209.00945" title="Download PDF">pdf</a>, <a href="/format/2209.00945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMG2IMU: Translating Knowledge from Large-Scale Images to IMU Sensing  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hyungjun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+H">Hyeongheon Cha</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+C">Hoang C. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Taesik Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sung-Ju Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12044" title="Abstract">arXiv:2209.12044</a> (replaced) [<a href="/pdf/2209.12044" title="Download PDF">pdf</a>, <a href="/format/2209.12044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising memory in infinite games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casares%2C+A">Antonio Casares</a>, 
<a href="/search/cs?searchtype=author&query=Ohlmann%2C+P">Pierre Ohlmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01834" title="Abstract">arXiv:2210.01834</a> (replaced) [<a href="/pdf/2210.01834" title="Download PDF">pdf</a>, <a href="/format/2210.01834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Aggregator for Defending against Federated Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dimitriadis%2C+D">Dimitrios Dimitriadis</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Tople%2C+S">Shruti Tople</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14484" title="Abstract">arXiv:2210.14484</a> (replaced) [<a href="/pdf/2210.14484" title="Download PDF">pdf</a>, <a href="/format/2210.14484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imputation of missing values in multi-view data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=van+Loon%2C+W">Wouter van Loon</a>, 
<a href="/search/stat?searchtype=author&query=Fokkema%2C+M">Marjolein Fokkema</a>, 
<a href="/search/stat?searchtype=author&query=de+Vos%2C+F">Frank de Vos</a>, 
<a href="/search/stat?searchtype=author&query=Koini%2C+M">Marisa Koini</a>, 
<a href="/search/stat?searchtype=author&query=Schmidt%2C+R">Reinhold Schmidt</a>, 
<a href="/search/stat?searchtype=author&query=de+Rooij%2C+M">Mark de Rooij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 15 figures. Major revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05269" title="Abstract">arXiv:2211.05269</a> (replaced) [<a href="/pdf/2211.05269" title="Download PDF">pdf</a>, <a href="/format/2211.05269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Adversarial Networks for Weakly Supervised Generation and  Evaluation of Brain Tumor Segmentations on MR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yoo%2C+J+J">Jay J. Yoo</a>, 
<a href="/search/eess?searchtype=author&query=Namdar%2C+K">Khashayar Namdar</a>, 
<a href="/search/eess?searchtype=author&query=Wagner%2C+M+W">Matthias W. Wagner</a>, 
<a href="/search/eess?searchtype=author&query=Nobre%2C+L">Liana Nobre</a>, 
<a href="/search/eess?searchtype=author&query=Tabori%2C+U">Uri Tabori</a>, 
<a href="/search/eess?searchtype=author&query=Hawkins%2C+C">Cynthia Hawkins</a>, 
<a href="/search/eess?searchtype=author&query=Ertl-Wagner%2C+B+B">Birgit B. Ertl-Wagner</a>, 
<a href="/search/eess?searchtype=author&query=Khalvati%2C+F">Farzad Khalvati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07303" title="Abstract">arXiv:2211.07303</a> (replaced) [<a href="/pdf/2211.07303" title="Download PDF">pdf</a>, <a href="/format/2211.07303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Federated Minimax Optimization with Lower Complexities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feihu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songcan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10307" title="Abstract">arXiv:2211.10307</a> (replaced) [<a href="/pdf/2211.10307" title="Download PDF">pdf</a>, <a href="/format/2211.10307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeaTurtleID: A novel long-span dataset highlighting the importance of  timestamps in wildlife re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papafitsoros%2C+K">Kostas Papafitsoros</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+L">Luk&#xe1;&#x161; Adam</a>, 
<a href="/search/cs?searchtype=author&query=%C4%8Cerm%C3%A1k%2C+V">Vojt&#x11b;ch &#x10c;erm&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+L">Luk&#xe1;&#x161; Picek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10529" title="Abstract">arXiv:2212.10529</a> (replaced) [<a href="/pdf/2212.10529" title="Download PDF">pdf</a>, <a href="/format/2212.10529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Psychological Safety of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yutong Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Lidong Bing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07002" title="Abstract">arXiv:2301.07002</a> (replaced) [<a href="/pdf/2301.07002" title="Download PDF">pdf</a>, <a href="/format/2301.07002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opti-CAM: Optimizing saliency maps for interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+F">Felipe Torres</a>, 
<a href="/search/cs?searchtype=author&query=Sicre%2C+R">Ronan Sicre</a>, 
<a href="/search/cs?searchtype=author&query=Avrithis%2C+Y">Yannis Avrithis</a>, 
<a href="/search/cs?searchtype=author&query=Ayache%2C+S">Stephane Ayache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12584" title="Abstract">arXiv:2301.12584</a> (replaced) [<a href="/pdf/2301.12584" title="Download PDF">pdf</a>, <a href="/format/2301.12584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Exact Leverage Score Sampling from Khatri-Rao Products with  Applications to Tensor Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bharadwaj%2C+V">Vivek Bharadwaj</a>, 
<a href="/search/math?searchtype=author&query=Malik%2C+O+A">Osman Asif Malik</a>, 
<a href="/search/math?searchtype=author&query=Murray%2C+R">Riley Murray</a>, 
<a href="/search/math?searchtype=author&query=Grigori%2C+L">Laura Grigori</a>, 
<a href="/search/math?searchtype=author&query=Buluc%2C+A">Aydin Buluc</a>, 
<a href="/search/math?searchtype=author&query=Demmel%2C+J">James Demmel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 37th Conference on Neural Information Processing Systems (Neurips'23). 28 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02237" title="Abstract">arXiv:2302.02237</a> (replaced) [<a href="/pdf/2302.02237" title="Download PDF">pdf</a>, <a href="/format/2302.02237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformalized Semi-supervised Random Forest for Classification and  Abnormality Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yujin Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingwenchan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Leying Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04831" title="Abstract">arXiv:2302.04831</a> (replaced) [<a href="/pdf/2302.04831" title="Download PDF">pdf</a>, <a href="/format/2302.04831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Open-ended Learning Framework for Zero-shot Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jichen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wei Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages with 9 pages main body
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06089" title="Abstract">arXiv:2302.06089</a> (replaced) [<a href="/pdf/2302.06089" title="Download PDF">pdf</a>, <a href="/format/2302.06089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated attention contrastive learning models for prostate cancer  diagnosis and Gleason grading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+F">Fei Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jinxi Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+M">Meng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junhan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuhan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Biyue Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yueping Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07457" title="Abstract">arXiv:2302.07457</a> (replaced) [<a href="/pdf/2302.07457" title="Download PDF">pdf</a>, <a href="/format/2302.07457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Demonstrations Meet Generative World Models: A Maximum Likelihood  Framework for Offline Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Siliang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alfredo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07715" title="Abstract">arXiv:2302.07715</a> (replaced) [<a href="/pdf/2302.07715" title="Download PDF">pdf</a>, <a href="/format/2302.07715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Management Core -- Towards an Explicit Representation of Risk in  Automated Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salem%2C+N+F">Nayel Fabian Salem</a>, 
<a href="/search/eess?searchtype=author&query=Kirschbaum%2C+T">Thomas Kirschbaum</a>, 
<a href="/search/eess?searchtype=author&query=Nolte%2C+M">Marcus Nolte</a>, 
<a href="/search/eess?searchtype=author&query=Lalitsch-Schneider%2C+C">Christian Lalitsch-Schneider</a>, 
<a href="/search/eess?searchtype=author&query=Graubohm%2C+R">Robert Graubohm</a>, 
<a href="/search/eess?searchtype=author&query=Reich%2C+J">Jan Reich</a>, 
<a href="/search/eess?searchtype=author&query=Maurer%2C+M">Markus Maurer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09597" title="Abstract">arXiv:2302.09597</a> (replaced) [<a href="/pdf/2302.09597" title="Download PDF">pdf</a>, <a href="/format/2302.09597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Differential-Algebraic Equations in Power System Dynamic  Analysis with Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tran%2C+H+T+T">Huynh Trung Thanh Tran</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+H+T">Hieu T.Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Vu%2C+L+T">Long T. Vu</a>, 
<a href="/search/eess?searchtype=author&query=Ojetola%2C+S+T">Samuel T. Ojetola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I am an author of this article, due to it quality, I want to remove it
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energy Conversion and Economics, Volume 5, Issue 1, Feb 2024,
  pages 40-53
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13991" title="Abstract">arXiv:2302.13991</a> (replaced) [<a href="/pdf/2302.13991" title="Download PDF">pdf</a>, <a href="/format/2302.13991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generalize towards Unseen Domains via a Content-Aware Style  Invariant Model for Disease Detection from Chest X-rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunaed%2C+M">Mohammad Zunaed</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+M+A">Md. Aynal Haque</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+T">Taufiq Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Journal of Biomedical and Health Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00042" title="Abstract">arXiv:2303.00042</a> (replaced) [<a href="/pdf/2303.00042" title="Download PDF">pdf</a>, <a href="/format/2303.00042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design, Kinematics, and Deployment of a Continuum Underwater  Vehicle-Manipulator System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sitler%2C+J+L">Justin L. Sitler</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Long Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, revision submitted to IEEE ASME Transactions on Mechatronics, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00696" title="Abstract">arXiv:2303.00696</a> (replaced) [<a href="/pdf/2303.00696" title="Download PDF">pdf</a>, <a href="/format/2303.00696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust your source: quantifying source condition elements for variational  regularisation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Benning%2C+M">Martin Benning</a>, 
<a href="/search/math?searchtype=author&query=Bubba%2C+T+A">Tatiana A. Bubba</a>, 
<a href="/search/math?searchtype=author&query=Ratti%2C+L">Luca Ratti</a>, 
<a href="/search/math?searchtype=author&query=Riccio%2C+D">Danilo Riccio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09992" title="Abstract">arXiv:2303.09992</a> (replaced) [<a href="/pdf/2303.09992" title="Download PDF">pdf</a>, <a href="/format/2303.09992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LION: Implicit Vision Prompt Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jianlong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jinan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024; 9 pages, 3 figures, 4 tables;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12402" title="Abstract">arXiv:2303.12402</a> (replaced) [<a href="/pdf/2303.12402" title="Download PDF">pdf</a>, <a href="/format/2303.12402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benders decomposition algorithms for minimizing the spread of harmful  contagions in networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%C4%B1nm%C4%B1%C5%9F%2C+K">K&#xfc;bra Tan&#x131;nm&#x131;&#x15f;</a>, 
<a href="/search/math?searchtype=author&query=Aras%2C+N">Necati Aras</a>, 
<a href="/search/math?searchtype=author&query=G%C3%BCney%2C+E">Evren G&#xfc;ney</a>, 
<a href="/search/math?searchtype=author&query=Sinnl%2C+M">Markus Sinnl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New theoretical and computational results added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17355" title="Abstract">arXiv:2303.17355</a> (replaced) [<a href="/pdf/2303.17355" title="Download PDF">pdf</a>, <a href="/format/2303.17355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic Soft Tactile Skin (AST Skin)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+V+R">Vishnu Rajendran S</a>, 
<a href="/search/cs?searchtype=author&query=Mandil%2C+W">Willow Mandil</a>, 
<a href="/search/cs?searchtype=author&query=Parsons%2C+S">Simon Parsons</a>, 
<a href="/search/cs?searchtype=author&query=E%2C+A+G">Amir Ghalamzan E</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Robotics and Automation (ICRA) 2024 (accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17674" title="Abstract">arXiv:2303.17674</a> (replaced) [<a href="/pdf/2303.17674" title="Download PDF">pdf</a>, <a href="/format/2303.17674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Hulls of Reachable Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lew%2C+T">Thomas Lew</a>, 
<a href="/search/math?searchtype=author&query=Bonalli%2C+R">Riccardo Bonalli</a>, 
<a href="/search/math?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages. Submitted to the IEEE Transactions on Automatic Control. Substantial extension of <a href="/abs/2303.17674">arXiv:2303.17674v2</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00933" title="Abstract">arXiv:2304.00933</a> (replaced) [<a href="/pdf/2304.00933" title="Download PDF">pdf</a>, <a href="/format/2304.00933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Accumulation in Continually Learned Representations and the  Issue of Feature Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hess%2C+T">Timm Hess</a>, 
<a href="/search/cs?searchtype=author&query=Verwimp%2C+E">Eli Verwimp</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Ven%2C+G+M">Gido M. van de Ven</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05805" title="Abstract">arXiv:2304.05805</a> (replaced) [<a href="/pdf/2304.05805" title="Download PDF">pdf</a>, <a href="/format/2304.05805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GDP nowcasting with artificial neural networks: How much does long-term  memory matter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=N%C3%A9meth%2C+K">Krist&#xf3;f N&#xe9;meth</a>, 
<a href="/search/econ?searchtype=author&query=Hadh%C3%A1zi%2C+D">D&#xe1;niel Hadh&#xe1;zi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2106.08901">arXiv:2106.08901</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10398" title="Abstract">arXiv:2304.10398</a> (replaced) [<a href="/pdf/2304.10398" title="Download PDF">pdf</a>, <a href="/format/2304.10398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label Node Classification On Graph-Structured Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N+T">Ngan Thi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hanjalic%2C+A">Alan Hanjalic</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+M">Megha Khosla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TMLR 2023. Link: <a href="https://openreview.net/forum?id=EZhkV2BjDP">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transaction Of Machine Learning Research, 2835-8856, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02215" title="Abstract">arXiv:2305.02215</a> (replaced) [<a href="/pdf/2305.02215" title="Download PDF">pdf</a>, <a href="/format/2305.02215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Linguistic Properties of Monolingual BERTs with Typological  Classification among Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruzzetti%2C+E+S">Elena Sofia Ruzzetti</a>, 
<a href="/search/cs?searchtype=author&query=Ranaldi%2C+F">Federico Ranaldi</a>, 
<a href="/search/cs?searchtype=author&query=Logozzo%2C+F">Felicia Logozzo</a>, 
<a href="/search/cs?searchtype=author&query=Mastromattei%2C+M">Michele Mastromattei</a>, 
<a href="/search/cs?searchtype=author&query=Ranaldi%2C+L">Leonardo Ranaldi</a>, 
<a href="/search/cs?searchtype=author&query=Zanzotto%2C+F+M">Fabio Massimo Zanzotto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04666" title="Abstract">arXiv:2305.04666</a> (replaced) [<a href="/pdf/2305.04666" title="Download PDF">pdf</a>, <a href="/format/2305.04666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Distribution Grid Enhancement via Online Feedback Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Matt%2C+J+G">Jonas G. Matt</a>, 
<a href="/search/eess?searchtype=author&query=Ortmann%2C+L">Lukas Ortmann</a>, 
<a href="/search/eess?searchtype=author&query=Bolognani%2C+S">Saverio Bolognani</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06548" title="Abstract">arXiv:2305.06548</a> (replaced) [<a href="/pdf/2305.06548" title="Download PDF">pdf</a>, <a href="/ps/2305.06548" title="Download PostScript">ps</a>, <a href="/format/2305.06548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layered Modal Type Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+Z+S">Jason Z. S. Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pientka%2C+B">Brigitte Pientka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08460" title="Abstract">arXiv:2305.08460</a> (replaced) [<a href="/pdf/2305.08460" title="Download PDF">pdf</a>, <a href="/ps/2305.08460" title="Download PostScript">ps</a>, <a href="/format/2305.08460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Population Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ga%C5%84czorz%2C+A">Adam Ga&#x144;czorz</a>, 
<a href="/search/cs?searchtype=author&query=G%C4%85sieniec%2C+L">Leszek G&#x105;sieniec</a>, 
<a href="/search/cs?searchtype=author&query=Jurdzi%C5%84ski%2C+T">Tomasz Jurdzi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+J">Jakub Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Stachowiak%2C+G">Grzegorz Stachowiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09675" title="Abstract">arXiv:2305.09675</a> (replaced) [<a href="/pdf/2305.09675" title="Download PDF">pdf</a>, <a href="/format/2305.09675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Computing Opportunities in Biomedical Decision Support: The  Atlas-EHR Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhadloo%2C+M">Majid Farhadloo</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Arun Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+S">Shashi Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=Markovic%2C+S+N">Svetomir N. Markovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10361" title="Abstract">arXiv:2305.10361</a> (replaced) [<a href="/pdf/2305.10361" title="Download PDF">pdf</a>, <a href="/format/2305.10361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Choice Prediction in Language-based Persuasion Games:  Simulation-based Off-Policy Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapira%2C+E">Eilam Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Apel%2C+R">Reut Apel</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11461" title="Abstract">arXiv:2305.11461</a> (replaced) [<a href="/pdf/2305.11461" title="Download PDF">pdf</a>, <a href="/format/2305.11461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hint of Thought prompting: an explainable and zero-shot approach to  reasoning tasks with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+I">Ioktong Lei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhidong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15560" title="Abstract">arXiv:2305.15560</a> (replaced) [<a href="/pdf/2305.15560" title="Download PDF">pdf</a>, <a href="/format/2305.15560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Synthetic Data via Foundation Model APIs 1:  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gopi%2C+S">Sivakanth Gopi</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+J">Janardhan Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+H">Harsha Nori</a>, 
<a href="/search/cs?searchtype=author&query=Yekhanin%2C+S">Sergey Yekhanin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 42 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00950" title="Abstract">arXiv:2306.00950</a> (replaced) [<a href="/pdf/2306.00950" title="Download PDF">pdf</a>, <a href="/format/2306.00950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Diffusion: Giving Each Pixel Its Strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levin%2C+E">Eran Levin</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+O">Ohad Fried</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://differential-diffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15012" title="Abstract">arXiv:2306.15012</a> (replaced) [<a href="/pdf/2306.15012" title="Download PDF">pdf</a>, <a href="/format/2306.15012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Component Separation for Targeted Signal Recovery in Noisy  Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Blancard%2C+B+R">Bruno R&#xe9;galdo-Saint Blancard</a>, 
<a href="/search/stat?searchtype=author&query=Eickenberg%2C+M">Michael Eickenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13+17 pages, 6+8 figures, published in TMLR, code: <a href="https://github.com/bregaldo/stat_comp_sep">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01412" title="Abstract">arXiv:2307.01412</a> (replaced) [<a href="/pdf/2307.01412" title="Download PDF">pdf</a>, <a href="/format/2307.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant-time edge label and leaf pointer maintenance on sliding suffix  trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leonard%2C+L">Laurentius Leonard</a>, 
<a href="/search/cs?searchtype=author&query=Inenaga%2C+S">Shunsuke Inenaga</a>, 
<a href="/search/cs?searchtype=author&query=Bannai%2C+H">Hideo Bannai</a>, 
<a href="/search/cs?searchtype=author&query=Mieno%2C+T">Takuya Mieno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02140" title="Abstract">arXiv:2307.02140</a> (replaced) [<a href="/pdf/2307.02140" title="Download PDF">pdf</a>, <a href="/format/2307.02140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open Federated Learning Platforms: Survey and Vision from  Technical and Legal Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+M">Moming Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Linshan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Download Appendix from <a href="https://github.com/morningD/Towards-Open-Federated-Learning-Platforms-Survey/blob/main/TKDE-Tex/APPENDIX.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03997" title="Abstract">arXiv:2307.03997</a> (replaced) [<a href="/pdf/2307.03997" title="Download PDF">pdf</a>, <a href="/format/2307.03997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Model-Free Exploration in Low-Rank MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mhammedi%2C+Z">Zakaria Mhammedi</a>, 
<a href="/search/cs?searchtype=author&query=Block%2C+A">Adam Block</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+D+J">Dylan J. Foster</a>, 
<a href="/search/cs?searchtype=author&query=Rakhlin%2C+A">Alexander Rakhlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07357" title="Abstract">arXiv:2307.07357</a> (replaced) [<a href="/pdf/2307.07357" title="Download PDF">pdf</a>, <a href="/format/2307.07357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Optimization for Routing Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Scroccaro%2C+P+Z">Pedro Zattoni Scroccaro</a>, 
<a href="/search/math?searchtype=author&query=van+Beek%2C+P">Piet van Beek</a>, 
<a href="/search/math?searchtype=author&query=Esfahani%2C+P+M">Peyman Mohajerin Esfahani</a>, 
<a href="/search/math?searchtype=author&query=Atasoy%2C+B">Bilge Atasoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08773" title="Abstract">arXiv:2307.08773</a> (replaced) [<a href="/pdf/2307.08773" title="Download PDF">pdf</a>, <a href="/format/2307.08773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Customization is Key&quot;: Reconfigurable Content Tokens for Accessible  Data Visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jones%2C+S">Shuli Jones</a>, 
<a href="/search/cs?searchtype=author&query=Pineros%2C+I+P">Isabella Pedraza Pineros</a>, 
<a href="/search/cs?searchtype=author&query=Hajas%2C+D">Daniel Hajas</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+J">Jonathan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Satyanarayan%2C+A">Arvind Satyanarayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages. 6 figures. 2 tables. ACM CHI Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08924" title="Abstract">arXiv:2307.08924</a> (replaced) [<a href="/pdf/2307.08924" title="Download PDF">pdf</a>, <a href="/format/2307.08924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Task Sampler Learning for Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xingzhe Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 11 tables, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09465" title="Abstract">arXiv:2307.09465</a> (replaced) [<a href="/e-print/2307.09465" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occlusion Aware Student Emotion Recognition based on Facial Action Unit  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wally%2C+S">Shrouk Wally</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+A">Ahmed Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Alkabbany%2C+I">Islam Alkabbany</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Asem Ali</a>, 
<a href="/search/cs?searchtype=author&query=Farag%2C+A">Aly Farag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> it doesn't meet the requirements of the CVIP Lab concerning authorship and acknowledging the funding sources
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09950" title="Abstract">arXiv:2307.09950</a> (replaced) [<a href="/pdf/2307.09950" title="Download PDF">pdf</a>, <a href="/format/2307.09950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting for Automatic Log Template Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junjielong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruichun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yintong Huo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICSE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10811" title="Abstract">arXiv:2307.10811</a> (replaced) [<a href="/pdf/2307.10811" title="Download PDF">pdf</a>, <a href="/format/2307.10811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;It Felt Like Having a Second Mind&quot;: Investigating Human-AI  Co-creativity in Prewriting with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Q">Qian Wan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siying Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Piaohong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACM CSCW 2024; Accepted to PACM HCI (CSCW); 25 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Hum.-Comput. Interact. 8, CSCW1, Article 84 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11025" title="Abstract">arXiv:2307.11025</a> (replaced) [<a href="/pdf/2307.11025" title="Download PDF">pdf</a>, <a href="/format/2307.11025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating VTubing as a Reconstruction of Streamer Self-Presentation:  Identity, Performance, and Gender
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Q">Qian Wan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACM CSCW 2024 (Accepted to PACM HCI(CSCW))
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. ACM Hum.-Comput. Interact. 8, CSCW1, Article 80 (April
  2024), 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Multimedia (cs.MM); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13717" title="Abstract">arXiv:2307.13717</a> (replaced) [<a href="/pdf/2307.13717" title="Download PDF">pdf</a>, <a href="/format/2307.13717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Leakage of Fuzzy Matchers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durbet%2C+A">Axel Durbet</a>, 
<a href="/search/cs?searchtype=author&query=Thiry-Atighehchi%2C+K">Kevin Thiry-Atighehchi</a>, 
<a href="/search/cs?searchtype=author&query=Chagnon%2C+D">Dorine Chagnon</a>, 
<a href="/search/cs?searchtype=author&query=Grollemund%2C+P">Paul-Marie Grollemund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15852" title="Abstract">arXiv:2307.15852</a> (replaced) [<a href="/pdf/2307.15852" title="Download PDF">pdf</a>, <a href="/format/2307.15852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionless Policies based on the Buckingham $&#x3c0;$ Theorem: Is This a  Good Way to Generalize Numerical Results?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Girard%2C+A">Alexandre Girard</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematics 2024, 12(5), 709
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16230" title="Abstract">arXiv:2307.16230</a> (replaced) [<a href="/pdf/2307.16230" title="Download PDF">pdf</a>, <a href="/format/2307.16230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Unforgeable Publicly Verifiable Watermark for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shu&#x27;ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR2024, 17 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04075" title="Abstract">arXiv:2308.04075</a> (replaced) [<a href="/pdf/2308.04075" title="Download PDF">pdf</a>, <a href="/ps/2308.04075" title="Download PostScript">ps</a>, <a href="/format/2308.04075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary-preserving Lamperti-splitting schemes for some Stochastic  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ulander%2C+J">Johan Ulander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04689" title="Abstract">arXiv:2308.04689</a> (replaced) [<a href="/pdf/2308.04689" title="Download PDF">pdf</a>, <a href="/ps/2308.04689" title="Download PostScript">ps</a>, <a href="/format/2308.04689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Web crawler strategies for web pages under robot.txt restriction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyas%2C+P">Piyush Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+A">Akhilesh Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Mandge%2C+T">Tushar Mandge</a>, 
<a href="/search/cs?searchtype=author&query=Hardikar%2C+S">Surbhi Hardikar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05500" title="Abstract">arXiv:2308.05500</a> (replaced) [<a href="/pdf/2308.05500" title="Download PDF">pdf</a>, <a href="/ps/2308.05500" title="Download PostScript">ps</a>, <a href="/format/2308.05500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Algorithm Based on Stochastic Discontinuous Galerkin for  Convection Dominated Equations with Random Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C3%87ilo%C4%9Flu%2C+P">Pelin &#xc7;ilo&#x11f;lu</a>, 
<a href="/search/math?searchtype=author&query=Y%C3%BCcel%2C+H">Hamdullah Y&#xfc;cel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 19 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05696" title="Abstract">arXiv:2308.05696</a> (replaced) [<a href="/pdf/2308.05696" title="Download PDF">pdf</a>, <a href="/format/2308.05696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Preliminary Study of the Intrinsic Relationship between Complexity and  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yingxiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Binyuan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N+L">Nevin L. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LREC-Coling 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07470" title="Abstract">arXiv:2308.07470</a> (replaced) [<a href="/pdf/2308.07470" title="Download PDF">pdf</a>, <a href="/format/2308.07470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symphony: Optimized DNN Model Serving using Deferred Batch Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lequn Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weixin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Canumalla%2C+A">Anirudh Canumalla</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yu Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+D">Danyang Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Philipose%2C+M">Matthai Philipose</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Arvind Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08567" title="Abstract">arXiv:2308.08567</a> (replaced) [<a href="/pdf/2308.08567" title="Download PDF">pdf</a>, <a href="/ps/2308.08567" title="Download PostScript">ps</a>, <a href="/format/2308.08567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMISR: Circular Medical Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Honggui Li</a>, 
<a href="/search/eess?searchtype=author&query=Hossain%2C+N+M+L">Nahid Md Lokman Hossain</a>, 
<a href="/search/eess?searchtype=author&query=Trocan%2C+M">Maria Trocan</a>, 
<a href="/search/eess?searchtype=author&query=Galayko%2C+D">Dimitri Galayko</a>, 
<a href="/search/eess?searchtype=author&query=Sawan%2C+M">Mohamad Sawan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08705" title="Abstract">arXiv:2308.08705</a> (replaced) [<a href="/pdf/2308.08705" title="Download PDF">pdf</a>, <a href="/format/2308.08705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partially Observable Multi-agent RL with (Quasi-)Efficiency: The  Blessing of Information Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Machine Learning (ICML) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10562" title="Abstract">arXiv:2308.10562</a> (replaced) [<a href="/pdf/2308.10562" title="Download PDF">pdf</a>, <a href="/format/2308.10562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing the Intangible: Survey of Image Classification into High-Level  and Abstract Categories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandiani%2C+D+S+M">Delfina Sol Martinez Pandiani</a>, 
<a href="/search/cs?searchtype=author&query=Presutti%2C+V">Valentina Presutti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10686" title="Abstract">arXiv:2308.10686</a> (replaced) [<a href="/pdf/2308.10686" title="Download PDF">pdf</a>, <a href="/format/2308.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normative Conditional Reasoning as a Fragment of HOL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parent%2C+X">Xavier Parent</a>, 
<a href="/search/cs?searchtype=author&query=Benzm%C3%BCller%2C+C">Christoph Benzm&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 34 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11131" title="Abstract">arXiv:2308.11131</a> (replaced) [<a href="/pdf/2308.11131" title="Download PDF">pdf</a>, <a href="/format/2308.11131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential  Behavior Comprehension in Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+R">Rong Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kounianhua Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+S">Shigang Quan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024. Full and More Readable Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13424" title="Abstract">arXiv:2308.13424</a> (replaced) [<a href="/pdf/2308.13424" title="Download PDF">pdf</a>, <a href="/ps/2308.13424" title="Download PostScript">ps</a>, <a href="/format/2308.13424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AG codes have no list-decoding friends: Approaching the generalized  Singleton bound requires exponential alphabets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alrabiah%2C+O">Omar Alrabiah</a>, 
<a href="/search/cs?searchtype=author&query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ray Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14947" title="Abstract">arXiv:2308.14947</a> (replaced) [<a href="/pdf/2308.14947" title="Download PDF">pdf</a>, <a href="/format/2308.14947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Generalization in Reinforcement Learning Training Regimes for  Social Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sigal%2C+A">Adam Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsiu-Chin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+A">AJung Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Generalization in Planning, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16089" title="Abstract">arXiv:2308.16089</a> (replaced) [<a href="/pdf/2308.16089" title="Download PDF">pdf</a>, <a href="/format/2308.16089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Zone Method based Physics-Informed Neural Networks in  Reheating Furnaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+U+K">Ujjal Kr Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Lipani%2C+A">Aldo Lipani</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yukun Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in: NeurIPS 2023 - Machine Learning and the Physical Sciences Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00344" title="Abstract">arXiv:2309.00344</a> (replaced) [<a href="/pdf/2309.00344" title="Download PDF">pdf</a>, <a href="/ps/2309.00344" title="Download PostScript">ps</a>, <a href="/format/2309.00344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Complete Dependency Pair Framework for Almost-Sure Innermost  Termination of Probabilistic Term Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kassing%2C+J">Jan-Christoph Kassing</a>, 
<a href="/search/cs?searchtype=author&query=Dollase%2C+S">Stefan Dollase</a>, 
<a href="/search/cs?searchtype=author&query=Giesl%2C+J">J&#xfc;rgen Giesl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.11741">arXiv:2305.11741</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00799" title="Abstract">arXiv:2309.00799</a> (replaced) [<a href="/pdf/2309.00799" title="Download PDF">pdf</a>, <a href="/format/2309.00799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Elementary Construction of Modified Hamiltonians and Modified  Measures of 2D Kahan Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gubbiotti%2C+G">Giorgio Gubbiotti</a>, 
<a href="/search/math?searchtype=author&query=McLaren%2C+D">David McLaren</a>, 
<a href="/search/math?searchtype=author&query=Quispel%2C+G+R+W">G.R.W. Quispel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02561" title="Abstract">arXiv:2309.02561</a> (replaced) [<a href="/pdf/2309.02561" title="Download PDF">pdf</a>, <a href="/format/2309.02561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physically Grounded Vision-Language Models for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jensen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+B">Bidipta Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05134" title="Abstract">arXiv:2309.05134</a> (replaced) [<a href="/pdf/2309.05134" title="Download PDF">pdf</a>, <a href="/format/2309.05134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking ground truth trajectories with robotic total stations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daum%2C+E">Effie Daum</a>, 
<a href="/search/cs?searchtype=author&query=Vaidis%2C+M">Maxime Vaidis</a>, 
<a href="/search/cs?searchtype=author&query=Pomerleau%2C+F">Fran&#xe7;ois Pomerleau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at IROS23, Workshop on Methods for Objective Comparison of Results in Intelligent Robotics Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05605" title="Abstract">arXiv:2309.05605</a> (replaced) [<a href="/pdf/2309.05605" title="Download PDF">pdf</a>, <a href="/format/2309.05605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Injections: Correcting Multi-Hop Reasoning Failures during  Inference in Transformer-Based Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakarvadia%2C+M">Mansi Sakarvadia</a>, 
<a href="/search/cs?searchtype=author&query=Ajith%2C+A">Aswathy Ajith</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Arham Khan</a>, 
<a href="/search/cs?searchtype=author&query=Grzenda%2C+D">Daniel Grzenda</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+N">Nathaniel Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+A">Andr&#xe9; Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Chard%2C+K">Kyle Chard</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Oral Presentation at BlackboxNLP Workshop at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05979" title="Abstract">arXiv:2309.05979</a> (replaced) [<a href="/pdf/2309.05979" title="Download PDF">pdf</a>, <a href="/format/2309.05979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measure preservation and integrals for Lotka--Volterra tree-systems and  their Kahan discretisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=van+der+Kamp%2C+P+H">Peter H. van der Kamp</a>, 
<a href="/search/math?searchtype=author&query=McLachlan%2C+R+I">Robert I. McLachlan</a>, 
<a href="/search/math?searchtype=author&query=McLaren%2C+D+I">David I. McLaren</a>, 
<a href="/search/math?searchtype=author&query=Quispel%2C+G+R+W">G. R. W. Quispel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational Dynamics, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06275" title="Abstract">arXiv:2309.06275</a> (replaced) [<a href="/pdf/2309.06275" title="Download PDF">pdf</a>, <a href="/format/2309.06275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-Reading Improves Reasoning in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian-guang Lou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08315" title="Abstract">arXiv:2309.08315</a> (replaced) [<a href="/pdf/2309.08315" title="Download PDF">pdf</a>, <a href="/format/2309.08315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> i-Octree: A Fast, Lightweight, and Dynamic Octree for Proximity Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhepeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09865" title="Abstract">arXiv:2309.09865</a> (replaced) [<a href="/pdf/2309.09865" title="Download PDF">pdf</a>, <a href="/format/2309.09865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Enhancing Robust Scene Transfer in Vision-based  Agile Flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Jiaxu Xing</a>, 
<a href="/search/cs?searchtype=author&query=Bauersfeld%2C+L">Leonard Bauersfeld</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yunlong Song</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chunwei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Robotics and Automation (ICRA),
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10314" title="Abstract">arXiv:2309.10314</a> (replaced) [<a href="/pdf/2309.10314" title="Download PDF">pdf</a>, <a href="/format/2309.10314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dive Deeper into Rectifying Homography for Stereo Camera Online  Self-Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10834" title="Abstract">arXiv:2309.10834</a> (replaced) [<a href="/pdf/2309.10834" title="Download PDF">pdf</a>, <a href="/format/2309.10834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Federated Learning via Regularized Sparse Random  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mestoukirdi%2C+M">Mohamad Mestoukirdi</a>, 
<a href="/search/cs?searchtype=author&query=Esrafilian%2C+O">Omid Esrafilian</a>, 
<a href="/search/cs?searchtype=author&query=Gesbert%2C+D">David Gesbert</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qianrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Gresset%2C+N">Nicolas Gresset</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11143" title="Abstract">arXiv:2309.11143</a> (replaced) [<a href="/pdf/2309.11143" title="Download PDF">pdf</a>, <a href="/format/2309.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoT-BERT: Enhancing Unsupervised Sentence Representation through  Chain-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kehua Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12309" title="Abstract">arXiv:2309.12309</a> (replaced) [<a href="/pdf/2309.12309" title="Download PDF">pdf</a>, <a href="/format/2309.12309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rehearsal: Simulating Conflict to Teach Conflict Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+O">Omar Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+V">Valentino Chai</a>, 
<a href="/search/cs?searchtype=author&query=Gelfand%2C+M+J">Michele J. Gelfand</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+M+S">Michael S. Bernstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12444" title="Abstract">arXiv:2309.12444</a> (replaced) [<a href="/pdf/2309.12444" title="Download PDF">pdf</a>, <a href="/format/2309.12444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Metrics for Evaluating Effectiveness of Healthcare  Conversations Powered by Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasian%2C+M">Mahyar Abbasian</a>, 
<a href="/search/cs?searchtype=author&query=Khatibi%2C+E">Elahe Khatibi</a>, 
<a href="/search/cs?searchtype=author&query=Azimi%2C+I">Iman Azimi</a>, 
<a href="/search/cs?searchtype=author&query=Oniani%2C+D">David Oniani</a>, 
<a href="/search/cs?searchtype=author&query=Abad%2C+Z+S+H">Zahra Shakeri Hossein Abad</a>, 
<a href="/search/cs?searchtype=author&query=Thieme%2C+A">Alexander Thieme</a>, 
<a href="/search/cs?searchtype=author&query=Sriram%2C+R">Ram Sriram</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhongqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bryant Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gevaert%2C+O">Olivier Gevaert</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li-Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ramesh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+A+M">Amir M. Rahmani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 2 tables, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12924" title="Abstract">arXiv:2309.12924</a> (replaced) [<a href="/pdf/2309.12924" title="Download PDF">pdf</a>, <a href="/format/2309.12924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated grading workflows for providing personalized feedback to  open-ended data science assignments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ricci%2C+F+Z">Federica Zoe Ricci</a>, 
<a href="/search/physics?searchtype=author&query=Medina%2C+C+M">Catalina Mari Medina</a>, 
<a href="/search/physics?searchtype=author&query=Dogucu%2C+M">Mine Dogucu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Computers and Society (cs.CY); Other Statistics (stat.OT)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13192" title="Abstract">arXiv:2309.13192</a> (replaced) [<a href="/pdf/2309.13192" title="Download PDF">pdf</a>, <a href="/format/2309.13192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Green AI in Fine-tuning Large Language Models via Adaptive  Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hanyun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13339" title="Abstract">arXiv:2309.13339</a> (replaced) [<a href="/pdf/2309.13339" title="Download PDF">pdf</a>, <a href="/format/2309.13339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models  through Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xufeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengdi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jae Hee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+K">Kun Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in COLING 2024. Rename LogiCoT (previous version) to LoT (Logical Thoughts, current)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14150" title="Abstract">arXiv:2309.14150</a> (replaced) [<a href="/pdf/2309.14150" title="Download PDF">pdf</a>, <a href="/format/2309.14150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Contextual LiDAR Informed Visual Search in Unseen Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ryan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstein%2C+K">Kyle Morgenstein</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+S">Steven Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Sentis%2C+L">Luis Sentis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages + references. 6 figures. 1 algorithm. 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16598" title="Abstract">arXiv:2309.16598</a> (replaced) [<a href="/pdf/2309.16598" title="Download PDF">pdf</a>, <a href="/format/2309.16598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Prediction-Powered Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>, 
<a href="/search/stat?searchtype=author&query=Cand%C3%A8s%2C+E+J">Emmanuel J. Cand&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16782" title="Abstract">arXiv:2309.16782</a> (replaced) [<a href="/pdf/2309.16782" title="Download PDF">pdf</a>, <a href="/format/2309.16782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgical Tattoos in Infrared: A Dataset for Quantifying Tissue Tracking  and Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+A">Adam Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>, 
<a href="/search/cs?searchtype=author&query=DiMaio%2C+S">Simon DiMaio</a>, 
<a href="/search/cs?searchtype=author&query=Salcudean%2C+S+E">Septimiu E. Salcudean</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16909" title="Abstract">arXiv:2309.16909</a> (replaced) [<a href="/pdf/2309.16909" title="Download PDF">pdf</a>, <a href="/format/2309.16909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASAP: Automated Sequence Planning for Complex Robotic Assembly with  Physical Feasibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yunsheng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+K+D+D">Karl D.D. Willis</a>, 
<a href="/search/cs?searchtype=author&query=Omari%2C+B+A">Bassel Al Omari</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jieliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Javid%2C+F">Farhad Javid</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+E">Edward Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+J">Joshua Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Sueda%2C+S">Shinjiro Sueda</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chitta%2C+S">Sachin Chitta</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+W">Wojciech Matusik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17260" title="Abstract">arXiv:2309.17260</a> (replaced) [<a href="/pdf/2309.17260" title="Download PDF">pdf</a>, <a href="/format/2309.17260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlaceNav: Topological Navigation through Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suomela%2C+L">Lauri Suomela</a>, 
<a href="/search/cs?searchtype=author&query=Kalliola%2C+J">Jussi Kalliola</a>, 
<a href="/search/cs?searchtype=author&query=Edelman%2C+H">Harry Edelman</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4m%C3%A4r%C3%A4inen%2C+J">Joni-Kristian K&#xe4;m&#xe4;r&#xe4;inen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA2024 camera ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00762" title="Abstract">arXiv:2310.00762</a> (replaced) [<a href="/pdf/2310.00762" title="Download PDF">pdf</a>, <a href="/ps/2310.00762" title="Download PostScript">ps</a>, <a href="/format/2310.00762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on the stabilizer formalism via noncommutative graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Araiza%2C+R">Roy Araiza</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jihong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yushan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Holtermann%2C+A">Abraham Holtermann</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chieh Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+T">Tushar Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peixue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zeyuan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version. To appear in "Quantum Information Processing''
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Operator Algebras (math.OA); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01236" title="Abstract">arXiv:2310.01236</a> (replaced) [<a href="/pdf/2310.01236" title="Download PDF">pdf</a>, <a href="/format/2310.01236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirror Diffusion Models for Constrained and Watermarked Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+G">Guan-Horng Liu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+T">Tianrong Chen</a>, 
<a href="/search/stat?searchtype=author&query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>, 
<a href="/search/stat?searchtype=author&query=Tao%2C+M">Molei Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to NeurIPS on 5/18 but did not arxiv per NeurIPS policy, accepted on 9/22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01678" title="Abstract">arXiv:2310.01678</a> (replaced) [<a href="/pdf/2310.01678" title="Download PDF">pdf</a>, <a href="/format/2310.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score dynamics: scaling molecular dynamics with picosecond timesteps via  conditional diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hsu%2C+T">Tim Hsu</a>, 
<a href="/search/physics?searchtype=author&query=Sadigh%2C+B">Babak Sadigh</a>, 
<a href="/search/physics?searchtype=author&query=Bulatov%2C+V">Vasily Bulatov</a>, 
<a href="/search/physics?searchtype=author&query=Zhou%2C+F">Fei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02195" title="Abstract">arXiv:2310.02195</a> (replaced) [<a href="/pdf/2310.02195" title="Download PDF">pdf</a>, <a href="/ps/2310.02195" title="Download PostScript">ps</a>, <a href="/format/2310.02195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Online Scheduling and Routing for Automated Guided Vehicles In  Loop-Based Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stubbe%2C+L">Louis Stubbe</a>, 
<a href="/search/cs?searchtype=author&query=Goemaere%2C+J">Jens Goemaere</a>, 
<a href="/search/cs?searchtype=author&query=Goedgebeur%2C+J">Jan Goedgebeur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02592" title="Abstract">arXiv:2310.02592</a> (replaced) [<a href="/pdf/2310.02592" title="Download PDF">pdf</a>, <a href="/ps/2310.02592" title="Download PostScript">ps</a>, <a href="/format/2310.02592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Faster Deterministic Approximation Algorithm for TTP-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanaya%2C+Y">Yuga Kanaya</a>, 
<a href="/search/cs?searchtype=author&query=Takazawa%2C+K">Kenjiro Takazawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 42 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03560" title="Abstract">arXiv:2310.03560</a> (replaced) [<a href="/pdf/2310.03560" title="Download PDF">pdf</a>, <a href="/format/2310.03560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Digital Health Interfaces with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imrie%2C+F">Fergus Imrie</a>, 
<a href="/search/cs?searchtype=author&query=Rauba%2C+P">Paulius Rauba</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06356" title="Abstract">arXiv:2310.06356</a> (replaced) [<a href="/pdf/2310.06356" title="Download PDF">pdf</a>, <a href="/format/2310.06356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semantic Invariant Robust Watermark for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR2024, 21 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07333" title="Abstract">arXiv:2310.07333</a> (replaced) [<a href="/pdf/2310.07333" title="Download PDF">pdf</a>, <a href="/ps/2310.07333" title="Download PostScript">ps</a>, <a href="/format/2310.07333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing approximate roots of monotone functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hollender%2C+A">Alexandros Hollender</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+C">Chester Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We solved all the open cases, except the case when f has 3 or more dimensions, and satisfies all monotonicity conditions except one. Any ideas?
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07555" title="Abstract">arXiv:2310.07555</a> (replaced) [<a href="/pdf/2310.07555" title="Download PDF">pdf</a>, <a href="/format/2310.07555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does resistance to style-transfer equal Global Shape Bias? Measuring  network sensitivity to global shape configuration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Ziqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Z">Zhi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T+S">Tai Sing Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07576" title="Abstract">arXiv:2310.07576</a> (replaced) [<a href="/pdf/2310.07576" title="Download PDF">pdf</a>, <a href="/format/2310.07576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Trendy Twitter Hashtags in the 2022 French Election
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandviwalla%2C+A">Aamir Mandviwalla</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lake Yin</a>, 
<a href="/search/cs?searchtype=author&query=Szymanski%2C+B+K">Boleslaw K. Szymanski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, published in Complex Networks and their Applications XII
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07649" title="Abstract">arXiv:2310.07649</a> (replaced) [<a href="/pdf/2310.07649" title="Download PDF">pdf</a>, <a href="/format/2310.07649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Layout Design and Control of Robust Cooperative Grasped-Load  Aerial Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosio%2C+C">Carlo Bosio</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jerry Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting-Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+M+W">Mark W. Mueller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07779" title="Abstract">arXiv:2310.07779</a> (replaced) [<a href="/pdf/2310.07779" title="Download PDF">pdf</a>, <a href="/format/2310.07779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Approval and Network Homophily as Motivators of Online Toxicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Julie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luceri%2C+L">Luca Luceri</a>, 
<a href="/search/cs?searchtype=author&query=Walther%2C+J+B">Joseph B. Walther</a>, 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08540" title="Abstract">arXiv:2310.08540</a> (replaced) [<a href="/pdf/2310.08540" title="Download PDF">pdf</a>, <a href="/format/2310.08540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context  by Gradient Descent?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aayush Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08929" title="Abstract">arXiv:2310.08929</a> (replaced) [<a href="/pdf/2310.08929" title="Download PDF">pdf</a>, <a href="/format/2310.08929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Image Augmentation for Object Manipulation: Towards  Interpretable Controllability in Object-Centric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Janghyuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaehyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Ho-Jin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Seon Joo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11143" title="Abstract">arXiv:2310.11143</a> (replaced) [<a href="/pdf/2310.11143" title="Download PDF">pdf</a>, <a href="/ps/2310.11143" title="Download PostScript">ps</a>, <a href="/format/2310.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring a new machine learning based probabilistic model for  high-resolution indoor radon mapping, using the German indoor radon survey  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Petermann%2C+E">Eric Petermann</a>, 
<a href="/search/stat?searchtype=author&query=Bossew%2C+P">Peter Bossew</a>, 
<a href="/search/stat?searchtype=author&query=Kemski%2C+J">Joachim Kemski</a>, 
<a href="/search/stat?searchtype=author&query=Gruber%2C+V">Valeria Gruber</a>, 
<a href="/search/stat?searchtype=author&query=Suhr%2C+N">Nils Suhr</a>, 
<a href="/search/stat?searchtype=author&query=Hoffmann%2C+B">Bernd Hoffmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14566" title="Abstract">arXiv:2310.14566</a> (replaced) [<a href="/pdf/2310.14566" title="Download PDF">pdf</a>, <a href="/format/2310.14566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HallusionBench: An Advanced Diagnostic Suite for Entangled Language  Hallucination and Visual Illusion in Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tianrui Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+R">Ruiqi Xian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yacoob%2C+Y">Yaser Yacoob</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14720" title="Abstract">arXiv:2310.14720</a> (replaced) [<a href="/pdf/2310.14720" title="Download PDF">pdf</a>, <a href="/format/2310.14720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Deep Adaptive Input Normalization for Preprocessing Time Series  Data for Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=September%2C+M+A+K">Marcus A. K. September</a>, 
<a href="/search/cs?searchtype=author&query=Passino%2C+F+S">Francesco Sanna Passino</a>, 
<a href="/search/cs?searchtype=author&query=Goldmann%2C+L">Leonie Goldmann</a>, 
<a href="/search/cs?searchtype=author&query=Hinel%2C+A">Anton Hinel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14884" title="Abstract">arXiv:2310.14884</a> (replaced) [<a href="/pdf/2310.14884" title="Download PDF">pdf</a>, <a href="/format/2310.14884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Budgeted Embedding Table For Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yunke Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17273" title="Abstract">arXiv:2310.17273</a> (replaced) [<a href="/pdf/2310.17273" title="Download PDF">pdf</a>, <a href="/format/2310.17273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Looping in the Human Collaborative and Explainable Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adachi%2C+M">Masaki Adachi</a>, 
<a href="/search/cs?searchtype=author&query=Planden%2C+B">Brady Planden</a>, 
<a href="/search/cs?searchtype=author&query=Howey%2C+D+A">David A. Howey</a>, 
<a href="/search/cs?searchtype=author&query=Osborne%2C+M+A">Michael A. Osborne</a>, 
<a href="/search/cs?searchtype=author&query=Orbell%2C+S">Sebastian Orbell</a>, 
<a href="/search/cs?searchtype=author&query=Ares%2C+N">Natalia Ares</a>, 
<a href="/search/cs?searchtype=author&query=Muandet%2C+K">Krikamol Muandet</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+S+L">Siu Lun Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024, 24 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18127" title="Abstract">arXiv:2310.18127</a> (replaced) [<a href="/pdf/2310.18127" title="Download PDF">pdf</a>, <a href="/format/2310.18127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ask more, know better: Reinforce-Learned Prompt Questions for Decision  Making with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xue Yan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xinyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Christianos%2C+F">Filippos Christianos</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mguni%2C+D+H">David Henry Mguni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19673" title="Abstract">arXiv:2310.19673</a> (replaced) [<a href="/pdf/2310.19673" title="Download PDF">pdf</a>, <a href="/format/2310.19673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Non-Pyrotechnic Radial Deployment Mechanism for Payloads in  Sounding Rockets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+T+P+G">Thakur Pranav G. Singh</a>, 
<a href="/search/eess?searchtype=author&query=Anand%2C+U">Utkarsh Anand</a>, 
<a href="/search/eess?searchtype=author&query=Agrawal%2C+T">Tanvi Agrawal</a>, 
<a href="/search/eess?searchtype=author&query=G%2C+S">Srinivas G</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The results in this paper had to be verified again and hence a new paper has been written with new detailed mechanical simulations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20354" title="Abstract">arXiv:2310.20354</a> (replaced) [<a href="/pdf/2310.20354" title="Download PDF">pdf</a>, <a href="/format/2310.20354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Complexity of Heterogeneous Geometric Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+M">Keith Malcolm Smith</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J+P">Jason P. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01410" title="Abstract">arXiv:2311.01410</a> (replaced) [<a href="/pdf/2311.01410" title="Download PDF">pdf</a>, <a href="/format/2311.01410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Blessing of Randomness: SDE Beats ODE in General Diffusion-based  Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+S">Shen Nie</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H+A">Hanzhong Allan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chenyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01947" title="Abstract">arXiv:2311.01947</a> (replaced) [<a href="/pdf/2311.01947" title="Download PDF">pdf</a>, <a href="/format/2311.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lengths of divisible codes -- the missing cases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02013" title="Abstract">arXiv:2311.02013</a> (replaced) [<a href="/pdf/2311.02013" title="Download PDF">pdf</a>, <a href="/format/2311.02013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMORE: Score Models for Offline Goal-Conditioned Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sikchi%2C+H">Harshit Sikchi</a>, 
<a href="/search/cs?searchtype=author&query=Chitnis%2C+R">Rohan Chitnis</a>, 
<a href="/search/cs?searchtype=author&query=Touati%2C+A">Ahmed Touati</a>, 
<a href="/search/cs?searchtype=author&query=Geramifard%2C+A">Alborz Geramifard</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Amy Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niekum%2C+S">Scott Niekum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at International Conference of Learning Representations (ICLR) 2024. 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04590" title="Abstract">arXiv:2311.04590</a> (replaced) [<a href="/pdf/2311.04590" title="Download PDF">pdf</a>, <a href="/format/2311.04590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Cross-Domain Sequential Recommendation under Open-World  Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wujiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qitian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runzhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+M">Mingming Ha</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qiongxu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linxun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM Web Conference 2024 (WWW '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05181" title="Abstract">arXiv:2311.05181</a> (replaced) [<a href="/pdf/2311.05181" title="Download PDF">pdf</a>, <a href="/format/2311.05181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient flocking with nonlinear navigational feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dykhovychnyi%2C+O">Oleksandr Dykhovychnyi</a>, 
<a href="/search/math?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08168" title="Abstract">arXiv:2311.08168</a> (replaced) [<a href="/pdf/2311.08168" title="Download PDF">pdf</a>, <a href="/format/2311.08168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Uniform Confidence Spheres for Means of Random Vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chugg%2C+B">Ben Chugg</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Hongjian Wang</a>, 
<a href="/search/math?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08631" title="Abstract">arXiv:2311.08631</a> (replaced) [<a href="/pdf/2311.08631" title="Download PDF">pdf</a>, <a href="/format/2311.08631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence of Video Dynamics on EEG-based Single-Trial Video Target  Surveillance System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwak%2C+H">Heon-Gyu Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sung-Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Hyeon-Taek Han</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Ji-Hoon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 International BCI winter conference accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08675" title="Abstract">arXiv:2311.08675</a> (replaced) [<a href="/pdf/2311.08675" title="Download PDF">pdf</a>, <a href="/format/2311.08675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Coreset Selection: Towards Minimal Coreset Size under Model  Performance Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiale Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaokun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hongxin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09758" title="Abstract">arXiv:2311.09758</a> (replaced) [<a href="/pdf/2311.09758" title="Download PDF">pdf</a>, <a href="/format/2311.09758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OrchestraLLM: Efficient Orchestration of Language Models for Dialogue  State Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chia-Hsuan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ostendorf%2C+M">Mari Ostendorf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09827" title="Abstract">arXiv:2311.09827</a> (replaced) [<a href="/pdf/2311.09827" title="Download PDF">pdf</a>, <a href="/format/2311.09827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Overload: Jailbreaking Large Language Models with Overloaded  Logical Thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Ben Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B+Z">Bang Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12451" title="Abstract">arXiv:2311.12451</a> (replaced) [<a href="/pdf/2311.12451" title="Download PDF">pdf</a>, <a href="/format/2311.12451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A frame approach for equations involving the fractional Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Papadopoulos%2C+I+P+A">Ioannis P. A. Papadopoulos</a>, 
<a href="/search/math?searchtype=author&query=Gutleb%2C+T+S">Timon S. Gutleb</a>, 
<a href="/search/math?searchtype=author&query=Carrillo%2C+J+A">Jos&#xe9; A. Carrillo</a>, 
<a href="/search/math?searchtype=author&query=Olver%2C+S">Sheehan Olver</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13250" title="Abstract">arXiv:2311.13250</a> (replaced) [<a href="/pdf/2311.13250" title="Download PDF">pdf</a>, <a href="/format/2311.13250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedHCA$^2$: Towards Hetero-Client Federated Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Suizhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sirejiding%2C+S">Shalayiding Sirejiding</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13817" title="Abstract">arXiv:2311.13817</a> (replaced) [<a href="/pdf/2311.13817" title="Download PDF">pdf</a>, <a href="/format/2311.13817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular Identification and Peak Assignment: Leveraging Multi-Level  Multimodal Alignment on NMR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+P">Pengyu Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14175" title="Abstract">arXiv:2311.14175</a> (replaced) [<a href="/pdf/2311.14175" title="Download PDF">pdf</a>, <a href="/format/2311.14175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Appearance-based gaze estimation enhanced with synthetic images using  deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herashchenko%2C+D">Dmytro Herashchenko</a>, 
<a href="/search/cs?searchtype=author&query=Farka%C5%A1%2C+I">Igor Farka&#x161;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures, accepted to 2023 IEEE Symposium Series on Computational Intelligence (SSCI). Published version copyrighted by IEEE. This work was funded by the Horizon Europe Twinning project TERAIS G.A. number 101079338, and in part by the national project APVV-21-0105. The link to the code: <a href="https://zenodo.org/doi/10.5281/zenodo.10696083">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14431" title="Abstract">arXiv:2311.14431</a> (replaced) [<a href="/pdf/2311.14431" title="Download PDF">pdf</a>, <a href="/format/2311.14431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What you need to know about a learning robot: Identifying the enabling  architecture of complex systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beierling%2C+H">Helen Beierling</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+P">Phillip Richter</a>, 
<a href="/search/cs?searchtype=author&query=Brandt%2C+M">Mara Brandt</a>, 
<a href="/search/cs?searchtype=author&query=Terfloth%2C+L">Lutz Terfloth</a>, 
<a href="/search/cs?searchtype=author&query=Schulte%2C+C">Carsten Schulte</a>, 
<a href="/search/cs?searchtype=author&query=Wersing%2C+H">Heiko Wersing</a>, 
<a href="/search/cs?searchtype=author&query=Vollmer%2C+A">Anna-Lisa Vollmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Cognitive Systems Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14658" title="Abstract">arXiv:2311.14658</a> (replaced) [<a href="/pdf/2311.14658" title="Download PDF">pdf</a>, <a href="/format/2311.14658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis for Learning Orthonormal Deep Linear Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xuwei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihui Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14902" title="Abstract">arXiv:2311.14902</a> (replaced) [<a href="/pdf/2311.14902" title="Download PDF">pdf</a>, <a href="/format/2311.14902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parkinson&#x27;s Disease classification Using Contrastive Graph Cross-View  Learning with Multimodal Fusion of SPECT Images and Clinical Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jun-En Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chien-Chin Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15328" title="Abstract">arXiv:2311.15328</a> (replaced) [<a href="/pdf/2311.15328" title="Download PDF">pdf</a>, <a href="/format/2311.15328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models  from Chest X-Ray Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhanghao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+W">Wenjian Qin</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+C">Cheng Pan</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+W">Wenming Deng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhou Liu</a>, 
<a href="/search/eess?searchtype=author&query=Min%2C+W">Wenwen Min</a>, 
<a href="/search/eess?searchtype=author&query=Elazab%2C+A">Ahmed Elazab</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changmiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, accepted by IEEE ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17911" title="Abstract">arXiv:2311.17911</a> (replaced) [<a href="/pdf/2311.17911" title="Download PDF">pdf</a>, <a href="/format/2311.17911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OPERA: Alleviating Hallucination in Multi-Modal Large Language Models  via Over-Trust Penalty and Retrospection-Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qidong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024, code is available at <a href="https://github.com/shikiw/OPERA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17950" title="Abstract">arXiv:2311.17950</a> (replaced) [<a href="/pdf/2311.17950" title="Download PDF">pdf</a>, <a href="/format/2311.17950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Large-Scale Data Condensation via Various Backbone and  Statistical Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shitong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zeyuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Muxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xindong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqiang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00082" title="Abstract">arXiv:2312.00082</a> (replaced) [<a href="/pdf/2312.00082" title="Download PDF">pdf</a>, <a href="/format/2312.00082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compact Implicit Neural Representation for Efficient Storage of  Massive 4D Functional Magnetic Resonance Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ruoran Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+R">Runzhao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+W">Wenxin Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+Y">Yuxiao Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+T">Tingxiong Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Suo%2C+J">Jinli Suo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00746" title="Abstract">arXiv:2312.00746</a> (replaced) [<a href="/pdf/2312.00746" title="Download PDF">pdf</a>, <a href="/format/2312.00746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering Digital Detectives: Understanding LLM Behaviors and  Capabilities in Multi-Agent Mystery Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dekun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01534" title="Abstract">arXiv:2312.01534</a> (replaced) [<a href="/pdf/2312.01534" title="Download PDF">pdf</a>, <a href="/format/2312.01534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skeletal Cut Loci on Convex Polyhedra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Rourke%2C+J">Joseph O&#x27;Rourke</a>, 
<a href="/search/cs?searchtype=author&query=Vilcu%2C+C">Costin Vilcu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures, 9 references. v2: Many minor improvements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02528" title="Abstract">arXiv:2312.02528</a> (replaced) [<a href="/pdf/2312.02528" title="Download PDF">pdf</a>, <a href="/format/2312.02528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Power Battery Detection: New Challenge, Benchmark  Dataset and Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaoqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Youwei Pang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jiaming Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02959" title="Abstract">arXiv:2312.02959</a> (replaced) [<a href="/pdf/2312.02959" title="Download PDF">pdf</a>, <a href="/format/2312.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting algorithmic bias in medical AI-models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Smith%2C+J">Jeffrey Smith</a>, 
<a href="/search/stat?searchtype=author&query=Holder%2C+A">Andre Holder</a>, 
<a href="/search/stat?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03151" title="Abstract">arXiv:2312.03151</a> (replaced) [<a href="/pdf/2312.03151" title="Download PDF">pdf</a>, <a href="/format/2312.03151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Learning Can Improve Worst-Group Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Atharva Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Dery%2C+L">Lucio Dery</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+A">Amrith Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Aditi Raghunathan</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 tables, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04141" title="Abstract">arXiv:2312.04141</a> (replaced) [<a href="/pdf/2312.04141" title="Download PDF">pdf</a>, <a href="/ps/2312.04141" title="Download PostScript">ps</a>, <a href="/format/2312.04141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Approximate Computing with Constant Locality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Deheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05248" title="Abstract">arXiv:2312.05248</a> (replaced) [<a href="/pdf/2312.05248" title="Download PDF">pdf</a>, <a href="/format/2312.05248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Based Reconstruction Prevention for Decentralised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dekker%2C+F+W">Florine W. Dekker</a> (1), 
<a href="/search/cs?searchtype=author&query=Erkin%2C+Z">Zekeriya Erkin</a> (1), 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a> (2 and 1) ((1) Delft University of Technology, the Netherlands and (2) Universit&#xe0; di Padova, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, submitted to PETS 2024, for associated experiment source code see doi:10.4121/21572601
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05760" title="Abstract">arXiv:2312.05760</a> (replaced) [<a href="/pdf/2312.05760" title="Download PDF">pdf</a>, <a href="/format/2312.05760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RepViT-SAM: Towards Real-Time Segmenting Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Ao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report of RepViT+SAM in our CVPR 2024 work. Project page: <a href="https://jameslahm.github.io/repvit-sam/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07193" title="Abstract">arXiv:2312.07193</a> (replaced) [<a href="/pdf/2312.07193" title="Download PDF">pdf</a>, <a href="/ps/2312.07193" title="Download PostScript">ps</a>, <a href="/format/2312.07193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $(&#x3c3;,&#x3b4;)$-polycyclic codes in Ore extensions over rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bajalan%2C+M">Maryam Bajalan</a>, 
<a href="/search/cs?searchtype=author&query=Landjev%2C+I">Ivan Landjev</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Moro%2C+E">Edgar Mart&#xed;nez-Moro</a>, 
<a href="/search/cs?searchtype=author&query=Szabo%2C+S">Steve Szabo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, no figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07337" title="Abstract">arXiv:2312.07337</a> (replaced) [<a href="/pdf/2312.07337" title="Download PDF">pdf</a>, <a href="/format/2312.07337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petracek%2C+P">Pavel Petracek</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>, 
<a href="/search/cs?searchtype=author&query=Saska%2C+M">Martin Saska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE RA-L on December 1, 2023. Resubmitted on February 28, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07706" title="Abstract">arXiv:2312.07706</a> (replaced) [<a href="/pdf/2312.07706" title="Download PDF">pdf</a>, <a href="/format/2312.07706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Differentially Private k-Core Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Z">George Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. Abstract shortened to fit requirements. In the new version, we show that our techniques can also help give better analysis of the algorithms in [DLRSSY22]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09468" title="Abstract">arXiv:2312.09468</a> (replaced) [<a href="/pdf/2312.09468" title="Download PDF">pdf</a>, <a href="/format/2312.09468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Reinforcement Learning in a Simulated Robotic Arm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C4%8D%2C+L">Luka Kova&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Farka%C5%A1%2C+I">Igor Farka&#x161;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures. Appeared in 2023 International Conference on Artificial Neural Networks (ICANN) proceedings. Published version copyrighted by Springer. This work was funded by the Horizon Europe Twinning project TERAIS, G.A. number 101079338 and in part by the national project APVV-21-0105. Link to the code: <a href="https://zenodo.org/doi/10.5281/zenodo.10694747">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12183" title="Abstract">arXiv:2312.12183</a> (replaced) [<a href="/pdf/2312.12183" title="Download PDF">pdf</a>, <a href="/format/2312.12183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poincar&#xe9; Differential Privacy for Hierarchy-Aware Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuecen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haonan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunming Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12478" title="Abstract">arXiv:2312.12478</a> (replaced) [<a href="/pdf/2312.12478" title="Download PDF">pdf</a>, <a href="/format/2312.12478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProS: Prompting-to-simulate Generalized knowledge for Universal  Cross-Domain Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kaipeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+P">Pengpeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14305" title="Abstract">arXiv:2312.14305</a> (replaced) [<a href="/pdf/2312.14305" title="Download PDF">pdf</a>, <a href="/format/2312.14305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Exact Spanning Ratio of the Parallelogram Delaunay Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+P">Prosenjit Bose</a>, 
<a href="/search/cs?searchtype=author&query=De+Carufel%2C+J">Jean-Lou De Carufel</a>, 
<a href="/search/cs?searchtype=author&query=Njoo%2C+S">Sandrine Njoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14949" title="Abstract">arXiv:2312.14949</a> (replaced) [<a href="/pdf/2312.14949" title="Download PDF">pdf</a>, <a href="/format/2312.14949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Interactive Optimization of Open Source Python Libraries -- Case  Studies and Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Florath%2C+A">Andreas Florath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16624" title="Abstract">arXiv:2312.16624</a> (replaced) [<a href="/pdf/2312.16624" title="Download PDF">pdf</a>, <a href="/format/2312.16624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-stage optimizer for systematic overestimation adjustment applied to  multi-objective genetic algorithms for biomarker selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Cattelani%2C+L">Luca Cattelani</a>, 
<a href="/search/q-bio?searchtype=author&query=Fortino%2C+V">Vittorio Fortino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added link to source code repository
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16731" title="Abstract">arXiv:2312.16731</a> (replaced) [<a href="/pdf/2312.16731" title="Download PDF">pdf</a>, <a href="/format/2312.16731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite dSprites for Disentangled Continual Learning: Separating Memory  Edits from Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dziadzio%2C+S">Sebastian Dziadzio</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+%C3%87">&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Ven%2C+G+M">Gido M. van de Ven</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02982" title="Abstract">arXiv:2401.02982</a> (replaced) [<a href="/pdf/2401.02982" title="Download PDF">pdf</a>, <a href="/format/2401.02982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIBench: Benchmarking Data Analysis Knowledge of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shangqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chenghao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xinlin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zhaoguang Long</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aimin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+M">Man Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04350" title="Abstract">arXiv:2401.04350</a> (replaced) [<a href="/pdf/2401.04350" title="Download PDF">pdf</a>, <a href="/format/2401.04350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Model Guided Fine-Tuning for Zero-Shot Adversarial  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06349" title="Abstract">arXiv:2401.06349</a> (replaced) [<a href="/pdf/2401.06349" title="Download PDF">pdf</a>, <a href="/format/2401.06349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADAPT: Alzheimer Diagnosis through Adaptive Profiling Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06788" title="Abstract">arXiv:2401.06788</a> (replaced) [<a href="/pdf/2401.06788" title="Download PDF">pdf</a>, <a href="/format/2401.06788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in  CNVSRC 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+P">Pengcheng Guo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Included in CNVSRC Workshop 2023, NCMMSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07408" title="Abstract">arXiv:2401.07408</a> (replaced) [<a href="/pdf/2401.07408" title="Download PDF">pdf</a>, <a href="/format/2401.07408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Language and Graph Learning of Adsorption Configuration in  Catalysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ock%2C+J">Janghoon Ock</a>, 
<a href="/search/cs?searchtype=author&query=Magar%2C+R">Rishikesh Magar</a>, 
<a href="/search/cs?searchtype=author&query=Antony%2C+A">Akshay Antony</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures, supplementary information added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09181" title="Abstract">arXiv:2401.09181</a> (replaced) [<a href="/pdf/2401.09181" title="Download PDF">pdf</a>, <a href="/format/2401.09181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with  Positive Forward Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianli Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Binquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Huawen Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09512" title="Abstract">arXiv:2401.09512</a> (replaced) [<a href="/pdf/2401.09512" title="Download PDF">pdf</a>, <a href="/format/2401.09512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLAAD: The Multi-Language Audio Anti-Spoofing Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+N+M">Nicolas M. M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Kawa%2C+P">Piotr Kawa</a>, 
<a href="/search/cs?searchtype=author&query=Choong%2C+W+H">Wei Herng Choong</a>, 
<a href="/search/cs?searchtype=author&query=Casanova%2C+E">Edresson Casanova</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6lge%2C+E">Eren G&#xf6;lge</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+T">Thorsten M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Syga%2C+P">Piotr Syga</a>, 
<a href="/search/cs?searchtype=author&query=Sperl%2C+P">Philip Sperl</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6ttinger%2C+K">Konstantin B&#xf6;ttinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IJCNN 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11627" title="Abstract">arXiv:2401.11627</a> (replaced) [<a href="/pdf/2401.11627" title="Download PDF">pdf</a>, <a href="/format/2401.11627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Verification of Probabilistic Robustness in Bayesian Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batten%2C+B">Ben Batten</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+M">Mehran Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Lomuscio%2C+A">Alessio Lomuscio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12202" title="Abstract">arXiv:2401.12202</a> (replaced) [<a href="/pdf/2401.12202" title="Download PDF">pdf</a>, <a href="/format/2401.12202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OK-Robot: What Really Matters in Integrating Open-Knowledge Models for  Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Orru%2C+Y">Yaswanth Orru</a>, 
<a href="/search/cs?searchtype=author&query=Vakil%2C+J">Jay Vakil</a>, 
<a href="/search/cs?searchtype=author&query=Paxton%2C+C">Chris Paxton</a>, 
<a href="/search/cs?searchtype=author&query=Shafiullah%2C+N+M+M">Nur Muhammad Mahi Shafiullah</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+L">Lerrel Pinto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github repo: <a href="https://github.com/ok-robot/ok-robot">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13172" title="Abstract">arXiv:2401.13172</a> (replaced) [<a href="/pdf/2401.13172" title="Download PDF">pdf</a>, <a href="/format/2401.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADMap: Anti-disturbance framework for reconstructing online vectorized  HD map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fanyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaonong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Laifeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiwang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13919" title="Abstract">arXiv:2401.13919</a> (replaced) [<a href="/pdf/2401.13919" title="Download PDF">pdf</a>, <a href="/format/2401.13919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WebVoyager: Building an End-to-End Web Agent with Large Multimodal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hongliang He</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wenlin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhenzhong Lan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14292" title="Abstract">arXiv:2401.14292</a> (replaced) [<a href="/pdf/2401.14292" title="Download PDF">pdf</a>, <a href="/format/2401.14292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single and bi-layered 2-D acoustic soft tactile skin (AST2)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+V">Vishnu Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Parsons%2C+S">Simon Parsons</a>, 
<a href="/search/cs?searchtype=author&query=E%2C+A+G">Amir Ghalamzan E</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Robosoft conference 2024 (accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15721" title="Abstract">arXiv:2401.15721</a> (replaced) [<a href="/pdf/2401.15721" title="Download PDF">pdf</a>, <a href="/format/2401.15721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Acquisition Functions for Medical Imaging Deep Active  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dossou%2C+B+F+P">Bonaventure F. P. Dossou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best Poster Award at Deep Learning Indaba 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15741" title="Abstract">arXiv:2401.15741</a> (replaced) [<a href="/pdf/2401.15741" title="Download PDF">pdf</a>, <a href="/ps/2401.15741" title="Download PostScript">ps</a>, <a href="/format/2401.15741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SERNet-Former: Semantic Segmentation by Efficient Residual Network with  Attention-Boosting Gates and Attention-Fusion Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erisen%2C+S">Serdar Erisen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.15861" title="Abstract">arXiv:2401.15861</a> (replaced) [<a href="/pdf/2401.15861" title="Download PDF">pdf</a>, <a href="/format/2401.15861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BPDec: Unveiling the Potential of Masked Language Modeling Decoder in  BERT pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youzhi Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17010" title="Abstract">arXiv:2401.17010</a> (replaced) [<a href="/pdf/2401.17010" title="Download PDF">pdf</a>, <a href="/ps/2401.17010" title="Download PostScript">ps</a>, <a href="/format/2401.17010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finetuning Large Language Models for Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shestov%2C+A">Alexey Shestov</a>, 
<a href="/search/cs?searchtype=author&query=Levichev%2C+R">Rodion Levichev</a>, 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Ravil Mussabayev</a>, 
<a href="/search/cs?searchtype=author&query=Cheshkov%2C+A">Anton Cheshkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00128" title="Abstract">arXiv:2402.00128</a> (replaced) [<a href="/pdf/2402.00128" title="Download PDF">pdf</a>, <a href="/format/2402.00128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Traffic Object Detection for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+H">Abdul Hannan Khan</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+T+R">Syed Tahseen Raza Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.00752" title="Abstract">arXiv:2402.00752</a> (replaced) [<a href="/pdf/2402.00752" title="Download PDF">pdf</a>, <a href="/format/2402.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Error Analysis of 3D Gaussian Splatting and an Optimal Projection  Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Letian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiayang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanwen Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01109" title="Abstract">arXiv:2402.01109</a> (replaced) [<a href="/pdf/2402.01109" title="Download PDF">pdf</a>, <a href="/format/2402.01109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vaccine: Perturbation-aware Alignment for Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiansheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sihao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Ling Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01368" title="Abstract">arXiv:2402.01368</a> (replaced) [<a href="/pdf/2402.01368" title="Download PDF">pdf</a>, <a href="/ps/2402.01368" title="Download PostScript">ps</a>, <a href="/format/2402.01368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIR: A Lightweight Baseline for Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dongqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Ting Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+L">Liang Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01431" title="Abstract">arXiv:2402.01431</a> (replaced) [<a href="/pdf/2402.01431" title="Download PDF">pdf</a>, <a href="/format/2402.01431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Control for Continuous-Time POMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eich%2C+Y">Yannick Eich</a>, 
<a href="/search/cs?searchtype=author&query=Alt%2C+B">Bastian Alt</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01744" title="Abstract">arXiv:2402.01744</a> (replaced) [<a href="/pdf/2402.01744" title="Download PDF">pdf</a>, <a href="/format/2402.01744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Molecular Moieties through Hierarchical Graph Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sortino%2C+P">Paolo Sortino</a>, 
<a href="/search/q-bio?searchtype=author&query=Contino%2C+S">Salvatore Contino</a>, 
<a href="/search/q-bio?searchtype=author&query=Perricone%2C+U">Ugo Perricone</a>, 
<a href="/search/q-bio?searchtype=author&query=Pirrone%2C+R">Roberto Pirrone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Molecular Networks (q-bio.MN)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02694" title="Abstract">arXiv:2402.02694</a> (replaced) [<a href="/pdf/2402.02694" title="Download PDF">pdf</a>, <a href="/format/2402.02694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Description on IEEE ICME 2024 Grand Challenge: Semi-supervised Acoustic  Scene Classification under Domain Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+J">Jisheng Bai</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Mou Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+H">Han Yin</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+Y">Yafei Jia</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+S">Siwei Huang</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+Y">Yutong Du</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Dongzhe Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+D">Dongyuan Shi</a>, 
<a href="/search/eess?searchtype=author&query=Gan%2C+W">Woon-Seng Gan</a>, 
<a href="/search/eess?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
<a href="/search/eess?searchtype=author&query=Rahardja%2C+S">Susanto Rahardja</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+B">Bin Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jianfeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03659" title="Abstract">arXiv:2402.03659</a> (replaced) [<a href="/pdf/2402.03659" title="Download PDF">pdf</a>, <a href="/format/2402.03659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Explainable Stock Predictions using Self-Reflective  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koa%2C+K+J+L">Kelvin J.L. Koa</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+R">Ritchie Ng</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Statistical Finance (q-fin.ST)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03726" title="Abstract">arXiv:2402.03726</a> (replaced) [<a href="/pdf/2402.03726" title="Download PDF">pdf</a>, <a href="/format/2402.03726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Granger Causality from Instance-wise Self-attentive Hawkes  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Id%C3%A9%2C+T">Tsuyoshi Id&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Aur&#xe9;lie Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Kollias%2C+G">Georgios Kollias</a>, 
<a href="/search/cs?searchtype=author&query=Navr%C3%A1til%2C+J">Ji&#x159;&#xed; Navr&#xe1;til</a>, 
<a href="/search/cs?searchtype=author&query=Abe%2C+N">Naoki Abe</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi-An Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04140" title="Abstract">arXiv:2402.04140</a> (replaced) [<a href="/pdf/2402.04140" title="Download PDF">pdf</a>, <a href="/ps/2402.04140" title="Download PostScript">ps</a>, <a href="/format/2402.04140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Legal Reasoning: The Integration of AI to Navigate  Complexities and Biases in Global Jurisprudence with Semi-Automated  Arbitration Processes (SAAPs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De%27Shazer%2C+M">Michael De&#x27;Shazer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05699" title="Abstract">arXiv:2402.05699</a> (replaced) [<a href="/pdf/2402.05699" title="Download PDF">pdf</a>, <a href="/format/2402.05699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Alignment of Large Language Models via Monopolylogue-based Social  Scene Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">Xianghe Pang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shuo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuxin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bolun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08208" title="Abstract">arXiv:2402.08208</a> (replaced) [<a href="/pdf/2402.08208" title="Download PDF">pdf</a>, <a href="/format/2402.08208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherent Diverse Redundant Safety Mechanisms for AI-based Software  Elements in Automotive Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pitale%2C+M">Mandar Pitale</a>, 
<a href="/search/cs?searchtype=author&query=Abbaspour%2C+A">Alireza Abbaspour</a>, 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+D">Devesh Upadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is accepted for the SAE WCX 2024 conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09164" title="Abstract">arXiv:2402.09164</a> (replaced) [<a href="/pdf/2402.09164" title="Download PDF">pdf</a>, <a href="/format/2402.09164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More: Fewer Interpretable Region via Submodular Subset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10060" title="Abstract">arXiv:2402.10060</a> (replaced) [<a href="/pdf/2402.10060" title="Download PDF">pdf</a>, <a href="/format/2402.10060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Backtracking in Qrisp Applied to Sudoku Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Seidel%2C+R">Raphael Seidel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zander%2C+R">Ren&#xe9; Zander</a>, 
<a href="/search/quant-ph?searchtype=author&query=Petri%C4%8D%2C+M">Matic Petri&#x10d;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Steinmann%2C+N">Niklas Steinmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+D+Q">David Q. Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tcholtchev%2C+N">Nikolay Tcholtchev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hauswirth%2C+M">Manfred Hauswirth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10153" title="Abstract">arXiv:2402.10153</a> (replaced) [<a href="/pdf/2402.10153" title="Download PDF">pdf</a>, <a href="/format/2402.10153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study  for Diabetes Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasian%2C+M">Mahyar Abbasian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhongqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Khatibi%2C+E">Elahe Khatibi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nagesh%2C+N">Nitish Nagesh</a>, 
<a href="/search/cs?searchtype=author&query=Azimi%2C+I">Iman Azimi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ramesh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+A+M">Amir M. Rahmani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, and 2 tables, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10192" title="Abstract">arXiv:2402.10192</a> (replaced) [<a href="/pdf/2402.10192" title="Download PDF">pdf</a>, <a href="/format/2402.10192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Excitation Projective Simulation with a Many-Body Physics Inspired  Inductive Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=LeMaitre%2C+P+A">Philip A. LeMaitre</a>, 
<a href="/search/cs?searchtype=author&query=Krumm%2C+M">Marius Krumm</a>, 
<a href="/search/cs?searchtype=author&query=Briegel%2C+H+J">Hans J. Briegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures; Code repository at <a href="https://github.com/MariusKrumm/ManyBodyMEPS.">this https URL</a> Added figures and shortened computer maintenance section text for better readability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10311" title="Abstract">arXiv:2402.10311</a> (replaced) [<a href="/pdf/2402.10311" title="Download PDF">pdf</a>, <a href="/format/2402.10311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The optimal placement of the head in the noun phrase. The case of  demonstrative, numeral, adjective and noun
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrer-i-Cancho%2C+R">Ramon Ferrer-i-Cancho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Many typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10401" title="Abstract">arXiv:2402.10401</a> (replaced) [<a href="/pdf/2402.10401" title="Download PDF">pdf</a>, <a href="/format/2402.10401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ManiFPT: Defining and Analyzing Fingerprints of Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H+J">Hae Jin Song</a>, 
<a href="/search/cs?searchtype=author&query=Khayatkhoei%2C+M">Mahyar Khayatkhoei</a>, 
<a href="/search/cs?searchtype=author&query=AbdAlmageed%2C+W">Wael AbdAlmageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10487" title="Abstract">arXiv:2402.10487</a> (replaced) [<a href="/pdf/2402.10487" title="Download PDF">pdf</a>, <a href="/format/2402.10487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Projection Layers for Multidimensional Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Aboagye%2C+P+O">Prince Osei Aboagye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11050" title="Abstract">arXiv:2402.11050</a> (replaced) [<a href="/pdf/2402.11050" title="Download PDF">pdf</a>, <a href="/format/2402.11050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Constellation Multiple Access for Beyond 5G Wireless Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shakya%2C+I+L">Indu L. Shakya</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+F+H">Falah H. Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures, Submission to an IEEE Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11194" title="Abstract">arXiv:2402.11194</a> (replaced) [<a href="/pdf/2402.11194" title="Download PDF">pdf</a>, <a href="/format/2402.11194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating LLMs&#x27; Mathematical Reasoning in Financial Document Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+P">Pragya Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+M">Manuj Malik</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vivek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ganu%2C+T">Tanuja Ganu</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+D">Dan Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11352" title="Abstract">arXiv:2402.11352</a> (replaced) [<a href="/pdf/2402.11352" title="Download PDF">pdf</a>, <a href="/format/2402.11352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Capacity Results for Free-Space Optical Communication Systems  Over Gamma-Gamma Atmospheric Turbulence Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+H">Himani Verma</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Kamal Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11480" title="Abstract">arXiv:2402.11480</a> (replaced) [<a href="/pdf/2402.11480" title="Download PDF">pdf</a>, <a href="/format/2402.11480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pattern-wise Transparent Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11791" title="Abstract">arXiv:2402.11791</a> (replaced) [<a href="/pdf/2402.11791" title="Download PDF">pdf</a>, <a href="/format/2402.11791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDGE: Stereo Guided Depth Estimation for 360$^\circ$ Camera Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jialei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Dong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12374" title="Abstract">arXiv:2402.12374</a> (replaced) [<a href="/pdf/2402.12374" title="Download PDF">pdf</a>, <a href="/format/2402.12374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=May%2C+A">Avner May</a>, 
<a href="/search/cs?searchtype=author&query=Svirschevski%2C+R">Ruslan Svirschevski</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhsun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ryabinin%2C+M">Max Ryabinin</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12814" title="Abstract">arXiv:2402.12814</a> (replaced) [<a href="/pdf/2402.12814" title="Download PDF">pdf</a>, <a href="/format/2402.12814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of AI Value Alignment in Collaborative Ideation:  Effects on Perception, Ownership, and Output
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+A">Alicia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pataranutaporn%2C+P">Pat Pataranutaporn</a>, 
<a href="/search/cs?searchtype=author&query=Maes%2C+P">Pattie Maes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12928" title="Abstract">arXiv:2402.12928</a> (replaced) [<a href="/pdf/2402.12928" title="Download PDF">pdf</a>, <a href="/format/2402.12928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Literature Review of Literature Reviews in Pattern Analysis and  Machine Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Penghai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE version v1. [February 19, 2024] IEEE version v2 with typos fixed. [February 23, 2024] IEEE version v3 with errors fixed. [February 29, 2024]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13616" title="Abstract">arXiv:2402.13616</a> (replaced) [<a href="/pdf/2402.13616" title="Download PDF">pdf</a>, <a href="/format/2402.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLOv9: Learning What You Want to Learn Using Programmable Gradient  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chien-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+I">I-Hau Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H+M">Hong-Yuan Mark Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14041" title="Abstract">arXiv:2402.14041</a> (replaced) [<a href="/pdf/2402.14041" title="Download PDF">pdf</a>, <a href="/ps/2402.14041" title="Download PostScript">ps</a>, <a href="/format/2402.14041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2USD: Efficient-yet-effective Unsupervised State Detection for  Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhichen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dalin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weizhu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by The Web Conference 2024 (WWW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14096" title="Abstract">arXiv:2402.14096</a> (replaced) [<a href="/pdf/2402.14096" title="Download PDF">pdf</a>, <a href="/format/2402.14096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EyeTrans: Merging Human and Machine Attention for Neural Code  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Karas%2C+Z">Zachary Karas</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+A">Aakash Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=McMillan%2C+C">Collin McMillan</a>, 
<a href="/search/cs?searchtype=author&query=Leach%2C+K">Kevin Leach</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14148" title="Abstract">arXiv:2402.14148</a> (replaced) [<a href="/pdf/2402.14148" title="Download PDF">pdf</a>, <a href="/format/2402.14148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks and Friction: Slide, Hold, Learn
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Garcia-Suarez%2C+J">Joaquin Garcia-Suarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 paged, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14485" title="Abstract">arXiv:2402.14485</a> (replaced) [<a href="/pdf/2402.14485" title="Download PDF">pdf</a>, <a href="/format/2402.14485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-Checked Categorical Diagrammatic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guillemet%2C+B">Beno&#xee;t Guillemet</a>, 
<a href="/search/cs?searchtype=author&query=Mahboubi%2C+A">Assia Mahboubi</a>, 
<a href="/search/cs?searchtype=author&query=Piquerez%2C+M">Matthieu Piquerez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14614" title="Abstract">arXiv:2402.14614</a> (replaced) [<a href="/pdf/2402.14614" title="Download PDF">pdf</a>, <a href="/format/2402.14614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Counterexamples to Tokenization and the Noiseless Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cognetta%2C+M">Marco Cognetta</a>, 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Sangwhan Moon</a>, 
<a href="/search/cs?searchtype=author&query=Okazaki%2C+N">Naoaki Okazaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, to appear in LREC-COLING 2024, de-texified metadata
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14808" title="Abstract">arXiv:2402.14808</a> (replaced) [<a href="/pdf/2402.14808" title="Download PDF">pdf</a>, <a href="/format/2402.14808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RelayAttention for Efficient Large Language Model Serving with Long  System Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinjiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wayne Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+R+W+H">Rynson W.H. Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> fix typos; add code link
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15183" title="Abstract">arXiv:2402.15183</a> (replaced) [<a href="/pdf/2402.15183" title="Download PDF">pdf</a>, <a href="/format/2402.15183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphEdit: Large Language Models for Graph Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zirui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zixuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15784" title="Abstract">arXiv:2402.15784</a> (replaced) [<a href="/pdf/2402.15784" title="Download PDF">pdf</a>, <a href="/format/2402.15784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRConStyle: Image Restoration Framework Using Contrastive Learning and  Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dongqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+L">Liang Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15813" title="Abstract">arXiv:2402.15813</a> (replaced) [<a href="/pdf/2402.15813" title="Download PDF">pdf</a>, <a href="/format/2402.15813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Bargaining Abilities of LLMs: A Benchmark and A  Buyer-Enhancement Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tian Xia</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Yibo Miao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The dataset AmazonHistoryPrice and our code are available at <a href="https://github.com/TianXiaSJTU/AmazonPriceHistory">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15893" title="Abstract">arXiv:2402.15893</a> (replaced) [<a href="/pdf/2402.15893" title="Download PDF">pdf</a>, <a href="/format/2402.15893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concurrent Learning of Policy and Unknown Safety Constraints in  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yifru%2C+L">Lunet Yifru</a>, 
<a href="/search/eess?searchtype=author&query=Baheri%2C+A">Ali Baheri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16041" title="Abstract">arXiv:2402.16041</a> (replaced) [<a href="/pdf/2402.16041" title="Download PDF">pdf</a>, <a href="/format/2402.16041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Machine-Generated Texts by Multi-Population Aware Optimization  for Maximum Mean Discrepancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuhai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yiliao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiahao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16068" title="Abstract">arXiv:2402.16068</a> (replaced) [<a href="/pdf/2402.16068" title="Download PDF">pdf</a>, <a href="/format/2402.16068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot  Interaction Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castri%2C+L">Luca Castri</a>, 
<a href="/search/cs?searchtype=author&query=Beraldo%2C+G">Gloria Beraldo</a>, 
<a href="/search/cs?searchtype=author&query=Mghames%2C+S">Sariah Mghames</a>, 
<a href="/search/cs?searchtype=author&query=Hanheide%2C+M">Marc Hanheide</a>, 
<a href="/search/cs?searchtype=author&query=Bellotto%2C+N">Nicola Bellotto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the "Causal-HRI: Causal Learning for Human-Robot Interaction" workshop at the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16192" title="Abstract">arXiv:2402.16192</a> (replaced) [<a href="/pdf/2402.16192" title="Download PDF">pdf</a>, <a href="/format/2402.16192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Large Language Models against Jailbreak Attacks via Semantic  Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiabao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+B">Bairu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Robey%2C+A">Alexander Robey</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16235" title="Abstract">arXiv:2402.16235</a> (replaced) [<a href="/pdf/2402.16235" title="Download PDF">pdf</a>, <a href="/format/2402.16235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-AI Co-Creation of Worked Examples for Programming Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassany%2C+M">Mohammad Hassany</a>, 
<a href="/search/cs?searchtype=author&query=Brusilovsky%2C+P">Peter Brusilovsky</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+J">Jiaze Ke</a>, 
<a href="/search/cs?searchtype=author&query=Akhuseyinoglu%2C+K">Kamil Akhuseyinoglu</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A+B+L">Arun Balajiee Lekshmi Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.02105">arXiv:2312.02105</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16326" title="Abstract">arXiv:2402.16326</a> (replaced) [<a href="/pdf/2402.16326" title="Download PDF">pdf</a>, <a href="/format/2402.16326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Provably Accurate Randomized Sampling Algorithm for Logistic  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chowdhury%2C+A">Agniva Chowdhury</a>, 
<a href="/search/stat?searchtype=author&query=Ramuhalli%2C+P">Pradeep Ramuhalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16338" title="Abstract">arXiv:2402.16338</a> (replaced) [<a href="/pdf/2402.16338" title="Download PDF">pdf</a>, <a href="/format/2402.16338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLO-SAM: Bi-level Optimization Based Overfitting-Preventing Finetuning  of SAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengtao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16363" title="Abstract">arXiv:2402.16363</a> (replaced) [<a href="/pdf/2402.16363" title="Download PDF">pdf</a>, <a href="/format/2402.16363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM Inference Unveiled: Survey and Roofline Model Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Chenhao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qingyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16459" title="Abstract">arXiv:2402.16459</a> (replaced) [<a href="/pdf/2402.16459" title="Download PDF">pdf</a>, <a href="/format/2402.16459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending LLMs against Jailbreaking Attacks via Backtranslation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhouxing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+A">Andrew Bai</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16532" title="Abstract">arXiv:2402.16532</a> (replaced) [<a href="/pdf/2402.16532" title="Download PDF">pdf</a>, <a href="/format/2402.16532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast, Fair and Truthful Distributed Stable Matching for Common  Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirvonen%2C+J">Juho Hirvonen</a>, 
<a href="/search/cs?searchtype=author&query=Ranjbaran%2C+S">Sara Ranjbaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16631" title="Abstract">arXiv:2402.16631</a> (replaced) [<a href="/pdf/2402.16631" title="Download PDF">pdf</a>, <a href="/format/2402.16631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenAINet: Enabling Wireless Collective Intelligence via Knowledge  Transfer and Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Hang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qiyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bariah%2C+L">Lina Bariah</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>, 
<a href="/search/cs?searchtype=author&query=Lasaulce%2C+S">Samson Lasaulce</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Bader%2C+F">Faouzi Bader</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16741" title="Abstract">arXiv:2402.16741</a> (replaced) [<a href="/pdf/2402.16741" title="Download PDF">pdf</a>, <a href="/format/2402.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More Revisit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+N">Nobuko Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+P">Ping Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16749" title="Abstract">arXiv:2402.16749</a> (replaced) [<a href="/pdf/2402.16749" title="Download PDF">pdf</a>, <a href="/format/2402.16749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MISC: Ultra-low Bitrate Image Semantic Compression Driven by Large  Multimodal Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Donghui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16982" title="Abstract">arXiv:2402.16982</a> (replaced) [<a href="/pdf/2402.16982" title="Download PDF">pdf</a>, <a href="/format/2402.16982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Tight Privacy and Accuracy Bounds via Weighted Model  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oakley%2C+L">Lisa Oakley</a>, 
<a href="/search/cs?searchtype=author&query=Holtzen%2C+S">Steven Holtzen</a>, 
<a href="/search/cs?searchtype=author&query=Oprea%2C+A">Alina Oprea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17002" title="Abstract">arXiv:2402.17002</a> (replaced) [<a href="/pdf/2402.17002" title="Download PDF">pdf</a>, <a href="/format/2402.17002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Symmetry Group Structures via Implicit Orthogonality Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huh%2C+D">Dongsung Huh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Group Theory (math.GR); Representation Theory (math.RT)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17187" title="Abstract">arXiv:2402.17187</a> (replaced) [<a href="/pdf/2402.17187" title="Download PDF">pdf</a>, <a href="/format/2402.17187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PE-MVCNet: Multi-view and Cross-modal Fusion Network for Pulmonary  Embolism Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zhaoxin Guo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianxun Yu</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+F">Feiwei Qin</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yuqing Peng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yonghong Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changmiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17242" title="Abstract">arXiv:2402.17242</a> (replaced) [<a href="/pdf/2402.17242" title="Download PDF">pdf</a>, <a href="/format/2402.17242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Community Search with Accuracy Guarantee on Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shuzhan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yuxia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenghe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+X">Xiangyu Ke</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17279" title="Abstract">arXiv:2402.17279</a> (replaced) [<a href="/pdf/2402.17279" title="Download PDF">pdf</a>, <a href="/format/2402.17279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiFashion: Towards Personalized Outfit Generation and Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17289" title="Abstract">arXiv:2402.17289</a> (replaced) [<a href="/pdf/2402.17289" title="Download PDF">pdf</a>, <a href="/format/2402.17289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active propulsion noise shaping for multi-rotor aircraft localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serussi%2C+G">Gabriele Serussi</a>, 
<a href="/search/cs?searchtype=author&query=Shor%2C+T">Tamir Shor</a>, 
<a href="/search/cs?searchtype=author&query=Hirshberg%2C+T">Tom Hirshberg</a>, 
<a href="/search/cs?searchtype=author&query=Baskin%2C+C">Chaim Baskin</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+A">Alex Bronstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17316" title="Abstract">arXiv:2402.17316</a> (replaced) [<a href="/pdf/2402.17316" title="Download PDF">pdf</a>, <a href="/format/2402.17316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust and Efficient Cloud-Edge Elastic Model Adaptation via  Selective Entropy Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaofo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+S">Shuaicheng Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shoukai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hengjie Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17398" title="Abstract">arXiv:2402.17398</a> (replaced) [<a href="/pdf/2402.17398" title="Download PDF">pdf</a>, <a href="/format/2402.17398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mohanty%2C+N">Nishikanta Mohanty</a>, 
<a href="/search/quant-ph?searchtype=author&query=Behera%2C+B+K">Bikash K. Behera</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ferrie%2C+C">Christopher Ferrie</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dash%2C+P">Pravat Dash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 Pages, 22 Figures, 2 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17414" title="Abstract">arXiv:2402.17414</a> (replaced) [<a href="/pdf/2402.17414" title="Download PDF">pdf</a>, <a href="/format/2402.17414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Video Compression with Feature Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. Codes are at <a href="https://github.com/microsoft/DCVC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17532" title="Abstract">arXiv:2402.17532</a> (replaced) [<a href="/pdf/2402.17532" title="Download PDF">pdf</a>, <a href="/format/2402.17532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval is Accurate Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bowen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xuxin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuexian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17569" title="Abstract">arXiv:2402.17569</a> (replaced) [<a href="/pdf/2402.17569" title="Download PDF">pdf</a>, <a href="/format/2402.17569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backpropagation-Based Analytical Derivatives of EKF Covariance for  Active Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benhamou%2C+J">Jonas Benhamou</a>, 
<a href="/search/cs?searchtype=author&query=Bonnabel%2C+S">Silv&#xe8;re Bonnabel</a>, 
<a href="/search/cs?searchtype=author&query=Chapdelaine%2C+C">Camille Chapdelaine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted at IORS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17688" title="Abstract">arXiv:2402.17688</a> (replaced) [<a href="/pdf/2402.17688" title="Download PDF">pdf</a>, <a href="/format/2402.17688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel spectral methods for shock capturing and the removal of tygers in  computational fluid dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kolluru%2C+S+S+V">Sai Swetha Venkata Kolluru</a>, 
<a href="/search/math?searchtype=author&query=Besse%2C+N">Nicolas Besse</a>, 
<a href="/search/math?searchtype=author&query=Pandit%2C+R">Rahul Pandit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17886" title="Abstract">arXiv:2402.17886</a> (replaced) [<a href="/pdf/2402.17886" title="Download PDF">pdf</a>, <a href="/format/2402.17886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zeroth-Order Sampling Methods for Non-Log-Concave Distributions:  Alleviating Metastability by Denoising Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=He%2C+Y">Ye He</a>, 
<a href="/search/stat?searchtype=author&query=Rojas%2C+K">Kevin Rojas</a>, 
<a href="/search/stat?searchtype=author&query=Tao%2C+M">Molei Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Figure 4 on page 13 corrected. Comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17932" title="Abstract">arXiv:2402.17932</a> (replaced) [<a href="/pdf/2402.17932" title="Download PDF">pdf</a>, <a href="/format/2402.17932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Heterogeneous Agent Model of Mortgage Servicing: An Income-based  Relief Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+D">Deepeka Garg</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+B+P">Benjamin Patrick Evans</a>, 
<a href="/search/cs?searchtype=author&query=Ardon%2C+L">Leo Ardon</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A+L">Annapoorani Lakshmi Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Vann%2C+J">Jared Vann</a>, 
<a href="/search/cs?searchtype=author&query=Madhushani%2C+U">Udari Madhushani</a>, 
<a href="/search/cs?searchtype=author&query=Henry-Nickie%2C+M">Makada Henry-Nickie</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+S">Sumitra Ganesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 - AI in Finance for Social Impact
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; General Finance (q-fin.GN)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17951" title="Abstract">arXiv:2402.17951</a> (replaced) [<a href="/pdf/2402.17951" title="Download PDF">pdf</a>, <a href="/format/2402.17951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ayad%2C+I">Ishak Ayad</a>, 
<a href="/search/eess?searchtype=author&query=Larue%2C+N">Nicolas Larue</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+M+K">Ma&#xef; K. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2024. Project page: <a href="https://towzeur.github.io/QN-Mixer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17970" title="Abstract">arXiv:2402.17970</a> (replaced) [<a href="/pdf/2402.17970" title="Download PDF">pdf</a>, <a href="/ps/2402.17970" title="Download PostScript">ps</a>, <a href="/format/2402.17970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Advanced Methodologies in Security Evaluation for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Weihong Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanchun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18060" title="Abstract">arXiv:2402.18060</a> (replaced) [<a href="/pdf/2402.18060" title="Download PDF">pdf</a>, <a href="/format/2402.18060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Models on Answering and Explaining  Challenging Medical Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhouxiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+Y">Yash Singla</a>, 
<a href="/search/cs?searchtype=author&query=Dredze%2C+M">Mark Dredze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18065" title="Abstract">arXiv:2402.18065</a> (replaced) [<a href="/pdf/2402.18065" title="Download PDF">pdf</a>, <a href="/format/2402.18065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Probabilistic Motion Model for Skid-Steer Wheeled Mobile Robot  Navigation on Off-Road Terrains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Ananya Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Zolotas%2C+M">Mark Zolotas</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Adeeb Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Prajapati%2C+S">Sarvesh Prajapati</a>, 
<a href="/search/cs?searchtype=author&query=Bazzi%2C+S">Salah Bazzi</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C4%B1r%2C+T">Task&#x131;n Pad&#x131;r</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18101" title="Abstract">arXiv:2402.18101</a> (replaced) [<a href="/pdf/2402.18101" title="Download PDF">pdf</a>, <a href="/ps/2402.18101" title="Download PostScript">ps</a>, <a href="/format/2402.18101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Efficacy of Grammar Error Correction: A Human Evaluation  Approach in the Japanese Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18169" title="Abstract">arXiv:2402.18169</a> (replaced) [<a href="/pdf/2402.18169" title="Download PDF">pdf</a>, <a href="/ps/2402.18169" title="Download PostScript">ps</a>, <a href="/format/2402.18169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIKO: Multimodal Intention Knowledge Distillation from Large Language  Models for Social-Media Commonsense Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feihong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yangyifei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Ziqin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18181" title="Abstract">arXiv:2402.18181</a> (replaced) [<a href="/pdf/2402.18181" title="Download PDF">pdf</a>, <a href="/format/2402.18181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CFDNet: A Generalizable Foggy Stereo Matching Network with Contrastive  Feature Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18222" title="Abstract">arXiv:2402.18222</a> (replaced) [<a href="/pdf/2402.18222" title="Download PDF">pdf</a>, <a href="/format/2402.18222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HearHere: Mitigating Echo Chambers in News Consumption through an  AI-based Web System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Youngseung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sohyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+Y">Yunyong Ko</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+S">Seongeun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kyungsik Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures, 6 tables, CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18275" title="Abstract">arXiv:2402.18275</a> (replaced) [<a href="/pdf/2402.18275" title="Download PDF">pdf</a>, <a href="/format/2402.18275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation of Adapter for Automatic Speech Recognition in Noisy  Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18321" title="Abstract">arXiv:2402.18321</a> (replaced) [<a href="/pdf/2402.18321" title="Download PDF">pdf</a>, <a href="/format/2402.18321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Policies and Consent Management Platforms: Growth and Users&#x27;  Interactions over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+N">Nikhil Jha</a>, 
<a href="/search/cs?searchtype=author&query=Trevisan%2C+M">Martino Trevisan</a>, 
<a href="/search/cs?searchtype=author&query=Mellia%2C+M">Marco Mellia</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+D">Daniel Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Irarrazaval%2C+R">Rodrigo Irarrazaval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18394" title="Abstract">arXiv:2402.18394</a> (replaced) [<a href="/pdf/2402.18394" title="Download PDF">pdf</a>, <a href="/format/2402.18394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-IMU State Estimation for Relative Localization of Two Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wenqian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruonan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K+J">Kejian J. Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18402" title="Abstract">arXiv:2402.18402</a> (replaced) [<a href="/pdf/2402.18402" title="Download PDF">pdf</a>, <a href="/format/2402.18402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular System for Enhanced Robustness of Multimedia Understanding  Networks via Deep Parametric Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbato%2C+F">Francesco Barbato</a>, 
<a href="/search/cs?searchtype=author&query=Michieli%2C+U">Umberto Michieli</a>, 
<a href="/search/cs?searchtype=author&query=Yucel%2C+M+K">Mehmet Kerim Yucel</a>, 
<a href="/search/cs?searchtype=author&query=Zanuttigh%2C+P">Pietro Zanuttigh</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+M">Mete Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM MMSys'24. 10 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18409" title="Abstract">arXiv:2402.18409</a> (replaced) [<a href="/pdf/2402.18409" title="Download PDF">pdf</a>, <a href="/format/2402.18409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cognitive Evaluation Benchmark of Image Reasoning and Description for  Large Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiujie Song</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanyi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18467" title="Abstract">arXiv:2402.18467</a> (replaced) [<a href="/pdf/2402.18467" title="Download PDF">pdf</a>, <a href="/format/2402.18467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separate and Conquer: Decoupling Co-occurrence via Decomposition and  Representation for Weakly Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kexue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+M">Minghong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Linhao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhijian Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18470" title="Abstract">arXiv:2402.18470</a> (replaced) [<a href="/pdf/2402.18470" title="Download PDF">pdf</a>, <a href="/format/2402.18470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Higher-Order Lens for Social Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Preti%2C+G">Giulia Preti</a>, 
<a href="/search/cs?searchtype=author&query=Fazzone%2C+A">Adriano Fazzone</a>, 
<a href="/search/cs?searchtype=author&query=Petri%2C+G">Giovanni Petri</a>, 
<a href="/search/cs?searchtype=author&query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18485" title="Abstract">arXiv:2402.18485</a> (replaced) [<a href="/pdf/2402.18485" title="Download PDF">pdf</a>, <a href="/format/2402.18485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multimodal Foundation Agent for Financial Trading: Tool-Augmented,  Diversified, and Generalist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+L">Lingxuan Zhao</a>, 
<a href="/search/q-fin?searchtype=author&query=Xia%2C+H">Haochong Xia</a>, 
<a href="/search/q-fin?searchtype=author&query=Sun%2C+S">Shuo Sun</a>, 
<a href="/search/q-fin?searchtype=author&query=Sun%2C+J">Jiaze Sun</a>, 
<a href="/search/q-fin?searchtype=author&query=Qin%2C+M">Molei Qin</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+X">Xinyi Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+Y">Yuqing Zhao</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhao%2C+Y">Yilei Zhao</a>, 
<a href="/search/q-fin?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/q-fin?searchtype=author&query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18495" title="Abstract">arXiv:2402.18495</a> (replaced) [<a href="/pdf/2402.18495" title="Download PDF">pdf</a>, <a href="/format/2402.18495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROG$_{PL}$: Robust Open-Set Graph Learning via Region-Based Prototype  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiexin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Liping Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18496" title="Abstract">arXiv:2402.18496</a> (replaced) [<a href="/pdf/2402.18496" title="Download PDF">pdf</a>, <a href="/format/2402.18496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models Represent Beliefs of Self and Others
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhining Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://walter0807.github.io/RepBelief/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18510" title="Abstract">arXiv:2402.18510</a> (replaced) [<a href="/pdf/2402.18510" title="Download PDF">pdf</a>, <a href="/format/2402.18510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RNNs are not Transformers (Yet): The Key Bottleneck on In-context  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kaiyue Wen</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+X">Xingyu Dang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+K">Kaifeng Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18546" title="Abstract">arXiv:2402.18546</a> (replaced) [<a href="/pdf/2402.18546" title="Download PDF">pdf</a>, <a href="/format/2402.18546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizability Under Sensor Failure: Tokenization + Transformers  Enable More Robust Latent Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chau%2C+G">Geeling Chau</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yujin An</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+A+R">Ahamed Raffey Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">Soon-Jo Chung</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yisong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Talukder%2C+S">Sabera Talukder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18571" title="Abstract">arXiv:2402.18571</a> (replaced) [<a href="/pdf/2402.18571" title="Download PDF">pdf</a>, <a href="/format/2402.18571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Control of LLMs for Diverse User Preferences: Directional  Preference Alignment with Multi-Objective Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+S">Shizhe Diao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shuang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and model are released at <a href="https://github.com/Haoxiang-Wang/directional-preference-alignment">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item381">Cross-lists</a></li>
<li><a href="#item428">Replacements</a></li>
</ul>
<small>[ total of 689 entries:  <b>1-689</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2402">2402</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
