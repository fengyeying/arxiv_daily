<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed  6 Mar 24  to  Thu  7 Mar 24, announced Fri,  8 Mar 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item360">Cross-lists</a></li>
<li><a href="#item397">Replacements</a></li>
</ul>
<small>[ total of 664 entries:  <b>1-664</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri,  8 Mar 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03962" title="Abstract">arXiv:2403.03962</a> [<a href="/pdf/2403.03962" title="Download PDF">pdf</a>, <a href="/format/2403.03962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identify Critical Nodes in Complex Network with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jinzhu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongyun Zou</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Li Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Identifying critical nodes in networks is a classical decision-making task,
and many methods struggle to strike a balance between adaptability and utility.
Therefore, we propose an approach that empowers Evolutionary Algorithm (EA)
with Large Language Models (LLMs), to generate a function called "score\_nodes"
which can further be used to identify crucial nodes based on their assigned
scores. Our model consists of three main components: Manual Initialization,
Population Management, and LLMs-based Evolution. It evolves from initial
populations with a set of designed node scoring functions created manually.
LLMs leverage their strong contextual understanding and rich programming skills
to perform crossover and mutation operations on the individuals, generating
excellent new functions. These functions are then categorized, ranked, and
eliminated to ensure the stable development of the populations while preserving
diversity. Extensive experiments demonstrate the excellent performance of our
method, showcasing its strong generalization ability compared to other
state-of-the-art algorithms. It can consistently and orderly generate diverse
and efficient node scoring functions. All source codes and models that can
reproduce all results in this work are publicly available at this link:
\url{https://anonymous.4open.science/r/LLM4CN-6520}
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03967" title="Abstract">arXiv:2403.03967</a> [<a href="/pdf/2403.03967" title="Download PDF">pdf</a>, <a href="/format/2403.03967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haldar%2C+R">Rajdeep Haldar</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yue Xing</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qifan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">The existence of adversarial attacks on machine learning models imperceptible
to a human is still quite a mystery from a theoretical perspective. In this
work, we introduce two notions of adversarial attacks: natural or on-manifold
attacks, which are perceptible by a human/oracle, and unnatural or off-manifold
attacks, which are not. We argue that the existence of the off-manifold attacks
is a natural consequence of the dimension gap between the intrinsic and ambient
dimensions of the data. For 2-layer ReLU networks, we prove that even though
the dimension gap does not affect generalization performance on samples drawn
from the observed data space, it makes the clean-trained model more vulnerable
to adversarial perturbations in the off-manifold direction of the data space.
Our main results provide an explicit relationship between the
$\ell_2,\ell_{\infty}$ attack strength of the on/off-manifold attack and the
dimension gap.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03990" title="Abstract">arXiv:2403.03990</a> [<a href="/pdf/2403.03990" title="Download PDF">pdf</a>, <a href="/format/2403.03990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sierpinski Triangle Data Structure for Efficient Array Value Update  and Prefix Sum Calculation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harrison%2C+B">Brent Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Necaise%2C+J">Jason Necaise</a>, 
<a href="/search/cs?searchtype=author&query=Projansky%2C+A">Andrew Projansky</a>, 
<a href="/search/cs?searchtype=author&query=Whitfield%2C+J+D">James D. Whitfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The binary indexed tree, or Fenwick tree, is a data structure that can
efficiently update values and calculate prefix sums in an array. It allows both
of these operations to be performed in $O(\log_2 N)$ time. Here we present a
novel data structure resembling the Sierpinski triangle, which accomplishes
these operations with the same memory usage in $O(\log_3 N)$ time instead. We
show this order to be optimal by making use of a connection to quantum
computing.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03993" title="Abstract">arXiv:2403.03993</a> [<a href="/pdf/2403.03993" title="Download PDF">pdf</a>, <a href="/format/2403.03993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Negative Reservoir for Incremental Learning in Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valkanas%2C+A">Antonios Valkanas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuening Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Coates%2C+M">Mark Coates</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recommender systems have become an integral part of online platforms. Every
day the volume of training data is expanding and the number of user
interactions is constantly increasing. The exploration of larger and more
expressive models has become a necessary pursuit to improve user experience.
However, this progression carries with it an increased computational burden. In
commercial settings, once a recommendation system model has been trained and
deployed it typically needs to be updated frequently as new client data arrive.
Cumulatively, the mounting volume of data is guaranteed to eventually make full
batch retraining of the model from scratch computationally infeasible. Naively
fine-tuning solely on the new data runs into the well-documented problem of
catastrophic forgetting. Despite the fact that negative sampling is a crucial
part of training with implicit feedback, no specialized technique exists that
is tailored to the incremental learning framework. In this work, we take the
first step to propose, a personalized negative reservoir strategy which is used
to obtain negative samples for the standard triplet loss. This technique
balances alleviation of forgetting with plasticity by encouraging the model to
remember stable user preferences and selectively forget when user interests
change. We derive the mathematical formulation of a negative sampler to
populate and update the reservoir. We integrate our design in three SOTA and
commonly used incremental recommendation models. We show that these concrete
realizations of our negative reservoir framework achieve state-of-the-art
results in standard benchmarks, on multiple standard top-k evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03994" title="Abstract">arXiv:2403.03994</a> [<a href="/pdf/2403.03994" title="Download PDF">pdf</a>, <a href="/format/2403.03994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Relationship Detection Using Mixture of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaabana%2C+A">Ala Shaabana</a>, 
<a href="/search/cs?searchtype=author&query=Gharaee%2C+Z">Zahra Gharaee</a>, 
<a href="/search/cs?searchtype=author&query=Fieguth%2C+P">Paul Fieguth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine comprehension of visual information from images and videos by neural
networks faces two primary challenges. Firstly, there exists a computational
and inference gap in connecting vision and language, making it difficult to
accurately determine which object a given agent acts on and represent it
through language. Secondly, classifiers trained by a single, monolithic neural
network often lack stability and generalization. To overcome these challenges,
we introduce MoE-VRD, a novel approach to visual relationship detection
utilizing a mixture of experts. MoE-VRD identifies language triplets in the
form of &lt; subject, predicate, object&gt; tuples to extract relationships from
visual processing. Leveraging recent advancements in visual relationship
detection, MoE-VRD addresses the requirement for action recognition in
establishing relationships between subjects (acting) and objects (being acted
upon). In contrast to single monolithic networks, MoE-VRD employs multiple
small models as experts, whose outputs are aggregated. Each expert in MoE-VRD
specializes in visual relationship learning and object tagging. By utilizing a
sparsely-gated mixture of experts, MoE-VRD enables conditional computation and
significantly enhances neural network capacity without increasing computational
complexity. Our experimental results demonstrate that the conditional
computation capabilities and scalability of the mixture-of-experts approach
lead to superior performance in visual relationship detection compared to
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03995" title="Abstract">arXiv:2403.03995</a> [<a href="/pdf/2403.03995" title="Download PDF">pdf</a>, <a href="/format/2403.03995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cafe-Mpc: A Cascaded-Fidelity Model Predictive Control Framework with  Tuning-Free Whole-Body Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">He Li</a>, 
<a href="/search/cs?searchtype=author&query=Wensing%2C+P+M">Patrick M. Wensing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work introduces an optimization-based locomotion control framework for
on-the-fly synthesis of complex dynamic maneuvers. At the core of the proposed
framework is a cascaded-fidelity model predictive controller (Cafe-Mpc).
Cafe-Mpc strategically relaxes the planning problem along the prediction
horizon (i.e., with descending model fidelity, increasingly coarse time steps,
and relaxed constraints) for computational and performance gains. This problem
is numerically solved with an efficient customized multiple-shooting iLQR
(MS-iLQR) solver that is tailored for hybrid systems. The action-value function
from Cafe-Mpc is then used as the basis for a new value-function-based
whole-body control (VWBC) technique that avoids additional tuning for the WBC.
In this respect, the proposed framework unifies whole-body MPC and more
conventional whole-body quadratic programming (QP), which have been treated as
separate components in previous works. We study the effects of the cascaded
relaxations in Cafe-Mpc on the tracking performance and required computation
time. We also show that the \cmpc , if configured appropriately, advances the
performance of whole-body MPC without necessarily increasing computational
cost. Further, we show the superior performance of the proposed VWBC over the
Ricatti feedback controller in terms of constraint handling. The proposed
framework enables accomplishing for the first time gymnastic-style running
barrel roll on the MIT Mini Cheetah, a task where conventional MPC fails.
Video: https://youtu.be/YiNqrgj9mb8.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03996" title="Abstract">arXiv:2403.03996</a> [<a href="/pdf/2403.03996" title="Download PDF">pdf</a>, <a href="/ps/2403.03996" title="Download PostScript">ps</a>, <a href="/format/2403.03996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Urban Flood Risk Assessment By Adapting Health Domain  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhewei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Kai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+A">Ali Mostafavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Inspired by ideas from health risk assessment, this paper presents a new
perspective for flood risk assessment. The proposed perspective focuses on
three pillars for examining flood risk: (1) inherent susceptibility, (2)
mitigation strategies, and (3) external stressors. These pillars collectively
encompass the physical and environmental characteristics of urban areas, the
effectiveness of human-intervention measures, and the influence of
uncontrollable external factors, offering a fresh point of view for decoding
flood risks. For each pillar, we delineate its individual contributions to
flood risk and illustrate their interactive and overall impact. The
three-pillars model embodies a shift in focus from the quest to precisely model
and quantify flood risk to evaluating pathways to high flood risk. The shift in
perspective is intended to alleviate the quest for quantifying and predicting
flood risk at fine resolutions as a panacea for enhanced flood risk management.
The decomposition of flood risk pathways into the three intertwined pillars
(i.e., inherent factors, mitigation factors, and external factors) enables
evaluation of changes in factors within each pillar enhance and exacerbate
flood risk, creating a platform from which to inform plans, decisions, and
actions. Building on this foundation, we argue that a flood risk pathway
analysis approach, which examines the individual and collective impacts of
inherent factors, mitigation strategies, and external stressors, is essential
for a nuanced evaluation of flood risk. Accordingly, the proposed perspective
could complement the existing frameworks and approaches for flood risk
assessment.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03997" title="Abstract">arXiv:2403.03997</a> [<a href="/pdf/2403.03997" title="Download PDF">pdf</a>, <a href="/ps/2403.03997" title="Download PostScript">ps</a>, <a href="/format/2403.03997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding Enumerative Program Synthesis with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Parsert%2C+J">Julian Parsert</a>, 
<a href="/search/cs?searchtype=author&query=Polgreen%2C+E">Elizabeth Polgreen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Pre-trained Large Language Models (LLMs) are beginning to dominate the
discourse around automatic code generation with natural language
specifications. In contrast, the best-performing synthesizers in the domain of
formal synthesis with precise logical specifications are still based on
enumerative algorithms. In this paper, we evaluate the abilities of LLMs to
solve formal synthesis benchmarks by carefully crafting a library of prompts
for the domain. When one-shot synthesis fails, we propose a novel enumerative
synthesis algorithm, which integrates calls to an LLM into a weighted
probabilistic search. This allows the synthesizer to provide the LLM with
information about the progress of the enumerator, and the LLM to provide the
enumerator with syntactic guidance in an iterative loop. We evaluate our
techniques on benchmarks from the Syntax-Guided Synthesis (SyGuS) competition.
We find that GPT-3.5 as a stand-alone tool for formal synthesis is easily
outperformed by state-of-the-art formal synthesis algorithms, but our approach
integrating the LLM into an enumerative synthesis algorithm shows significant
performance gains over both the LLM and the enumerative synthesizer alone and
the winning SyGuS competition tool.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03998" title="Abstract">arXiv:2403.03998</a> [<a href="/pdf/2403.03998" title="Download PDF">pdf</a>, <a href="/format/2403.03998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenVPN is Open to VPN Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+D">Diwen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+R">Reethika Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Arham Jain</a>, 
<a href="/search/cs?searchtype=author&query=Kallitsis%2C+M">Michalis Kallitsis</a>, 
<a href="/search/cs?searchtype=author&query=Halderman%2C+J+A">J. Alex Halderman</a>, 
<a href="/search/cs?searchtype=author&query=Crandall%2C+J+R">Jedidiah R. Crandall</a>, 
<a href="/search/cs?searchtype=author&query=Ensafi%2C+R">Roya Ensafi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In: USENIX Security Symposium 2022 (USENIX Security '22)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 31st USENIX Security Symposium (USENIX Security 22). 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">VPN adoption has seen steady growth over the past decade due to increased
public awareness of privacy and surveillance threats. In response, certain
governments are attempting to restrict VPN access by identifying connections
using "dual use" DPI technology. To investigate the potential for VPN blocking,
we develop mechanisms for accurately fingerprinting connections using OpenVPN,
the most popular protocol for commercial VPN services. We identify three
fingerprints based on protocol features such as byte pattern, packet size, and
server response. Playing the role of an attacker who controls the network, we
design a two-phase framework that performs passive fingerprinting and active
probing in sequence. We evaluate our framework in partnership with a
million-user ISP and find that we identify over 85% of OpenVPN flows with only
negligible false positives, suggesting that OpenVPN-based services can be
effectively blocked with little collateral damage. Although some commercial
VPNs implement countermeasures to avoid detection, our framework successfully
identified connections to 34 out of 41 "obfuscated" VPN configurations. We
discuss the implications of the VPN fingerprintability for different threat
models and propose short-term defenses. In the longer term, we urge commercial
VPN providers to be more transparent about their obfuscation approaches and to
adopt more principled detection countermeasures, such as those developed in
censorship circumvention research.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03999" title="Abstract">arXiv:2403.03999</a> [<a href="/pdf/2403.03999" title="Download PDF">pdf</a>, <a href="/format/2403.03999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Artificial Currency Incentives in Repeated Weighted Congestion  Games: Equity vs. Equality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedroso%2C+L">Leonardo Pedroso</a>, 
<a href="/search/cs?searchtype=author&query=Agazzi%2C+A">Andrea Agazzi</a>, 
<a href="/search/cs?searchtype=author&query=Heemels%2C+W+P+M+H">W.P.M.H. Heemels</a>, 
<a href="/search/cs?searchtype=author&query=Salazar%2C+M">Mauro Salazar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">When users access shared resources in a selfish manner, the resulting
societal cost and perceived users' cost is often higher than what would result
from a centrally coordinated optimal allocation. While several contributions in
mechanism design manage to steer the aggregate users choices to the desired
optimum by using monetary tolls, such approaches bear the inherent drawback of
discriminating against users with a lower income. More recently, incentive
schemes based on artificial currencies have been studied with the goal of
achieving a system-optimal resource allocation that is also fair. In this
resource-sharing context, this paper focuses on repeated weighted congestion
game with two resources, where users contribute to the congestion to different
extents that are captured by individual weights. First, we address the broad
concept of fairness by providing a rigorous mathematical characterization of
the distinct societal metrics of equity and equality, i.e., the concepts of
providing equal outcomes and equal opportunities, respectively. Second, we
devise weight-dependent and time-invariant optimal pricing policies to maximize
equity and equality, and prove convergence of the aggregate user choices to the
system-optimum. In our framework it is always possible to achieve
system-optimal allocations with perfect equity, while the maximum equality that
can be reached may not be perfect, which is also shown via numerical
simulations.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04001" title="Abstract">arXiv:2403.04001</a> [<a href="/pdf/2403.04001" title="Download PDF">pdf</a>, <a href="/format/2403.04001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bidirectional Progressive Neural Networks with Episodic Return Progress  for Emergent Task Sequencing and Robotic Skill Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ada%2C+S+E">Suzan Ece Ada</a>, 
<a href="/search/cs?searchtype=author&query=Say%2C+H">Hanne Say</a>, 
<a href="/search/cs?searchtype=author&query=Ugur%2C+E">Emre Ugur</a>, 
<a href="/search/cs?searchtype=author&query=Oztop%2C+E">Erhan Oztop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Human brain and behavior provide a rich venue that can inspire novel control
and learning methods for robotics. In an attempt to exemplify such a
development by inspiring how humans acquire knowledge and transfer skills among
tasks, we introduce a novel multi-task reinforcement learning framework named
Episodic Return Progress with Bidirectional Progressive Neural Networks
(ERP-BPNN). The proposed ERP-BPNN model (1) learns in a human-like interleaved
manner by (2) autonomous task switching based on a novel intrinsic motivation
signal and, in contrast to existing methods, (3) allows bidirectional skill
transfer among tasks. ERP-BPNN is a general architecture applicable to several
multi-task learning settings; in this paper, we present the details of its
neural architecture and show its ability to enable effective learning and skill
transfer among morphologically different robots in a reaching task. The
developed Bidirectional Progressive Neural Network (BPNN) architecture enables
bidirectional skill transfer without requiring incremental training and
seamlessly integrates with online task arbitration. The task arbitration
mechanism developed is based on soft Episodic Return progress (ERP), a novel
intrinsic motivation (IM) signal. To evaluate our method, we use quantifiable
robotics metrics such as 'expected distance to goal' and 'path straightness' in
addition to the usual reward-based measure of episodic return common in
reinforcement learning. With simulation experiments, we show that ERP-BPNN
achieves faster cumulative convergence and improves performance in all metrics
considered among morphologically different robots compared to the baselines.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04007" title="Abstract">arXiv:2403.04007</a> [<a href="/pdf/2403.04007" title="Download PDF">pdf</a>, <a href="/format/2403.04007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-based Safe Reinforcement Learning for Nonlinear Dynamical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suttle%2C+W+A">Wesley A. Suttle</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V+K">Vipul K. Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Kosaraju%2C+K+C">Krishna C. Kosaraju</a>, 
<a href="/search/cs?searchtype=author&query=Sivaranjani%2C+S">S. Sivaranjani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vijay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sadler%2C+B+M">Brian M. Sadler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We develop provably safe and convergent reinforcement learning (RL)
algorithms for control of nonlinear dynamical systems, bridging the gap between
the hard safety guarantees of control theory and the convergence guarantees of
RL theory. Recent advances at the intersection of control and RL follow a
two-stage, safety filter approach to enforcing hard safety constraints:
model-free RL is used to learn a potentially unsafe controller, whose actions
are projected onto safe sets prescribed, for example, by a control barrier
function. Though safe, such approaches lose any convergence guarantees enjoyed
by the underlying RL methods. In this paper, we develop a single-stage,
sampling-based approach to hard constraint satisfaction that learns RL
controllers enjoying classical convergence guarantees while satisfying hard
safety constraints throughout training and deployment. We validate the efficacy
of our approach in simulation, including safe control of a quadcopter in a
challenging obstacle avoidance problem, and demonstrate that it outperforms
existing benchmarks.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04008" title="Abstract">arXiv:2403.04008</a> [<a href="/pdf/2403.04008" title="Download PDF">pdf</a>, <a href="/format/2403.04008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human I/O: Towards a Unified Approach to Detecting Situational  Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X+B">Xingyu Bruce Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+N">Jiahao Nick Li</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">David Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X+%27">Xiang &#x27;Anthony&#x27; Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+R">Ruofei Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Situationally Induced Impairments and Disabilities (SIIDs) can significantly
hinder user experience in contexts such as poor lighting, noise, and
multi-tasking. While prior research has introduced algorithms and systems to
address these impairments, they predominantly cater to specific tasks or
environments and fail to accommodate the diverse and dynamic nature of SIIDs.
We introduce Human I/O, a unified approach to detecting a wide range of SIIDs
by gauging the availability of human input/output channels. Leveraging
egocentric vision, multimodal sensing and reasoning with large language models,
Human I/O achieves a 0.22 mean absolute error and a 82% accuracy in
availability prediction across 60 in-the-wild egocentric video recordings in 32
different scenarios. Furthermore, while the core focus of our work is on the
detection of SIIDs rather than the creation of adaptive user interfaces, we
showcase the efficacy of our prototype via a user study with 10 participants.
Findings suggest that Human I/O significantly reduces effort and improves user
experience in the presence of SIIDs, paving the way for more adaptive and
accessible interactive systems in the future.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04009" title="Abstract">arXiv:2403.04009</a> [<a href="/pdf/2403.04009" title="Download PDF">pdf</a>, <a href="/format/2403.04009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Media Bias Matters: Understanding the Impact of Politically Biased News  on Vaccine Attitudes in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bohan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">News media has been utilized as a political tool to stray from facts,
presenting biased claims without evidence. Amid the COVID-19 pandemic,
politically biased news (PBN) has significantly undermined public trust in
vaccines, despite strong medical evidence supporting their efficacy. In this
paper, we analyze: (i) how inherent vaccine stances subtly influence
individuals' selection of news sources and participation in social media
discussions; and (ii) the impact of exposure to PBN on users' attitudes toward
vaccines. In doing so, we first curate a comprehensive dataset that connects
PBN with related social media discourse. Utilizing advanced deep learning and
causal inference techniques, we reveal distinct user behaviors between social
media groups with various vaccine stances. Moreover, we observe that
individuals with moderate stances, particularly the vaccine-hesitant majority,
are more vulnerable to the influence of PBN compared to those with extreme
views. Our findings provide critical insights to foster this line of research.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04010" title="Abstract">arXiv:2403.04010</a> [<a href="/pdf/2403.04010" title="Download PDF">pdf</a>, <a href="/format/2403.04010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three Revisits to Node-Level Graph Anomaly Detection: Outliers, Message  Passing and Hyperbolic Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jing Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongmian Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Second Learning on Graphs Conference (LoG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph anomaly detection plays a vital role for identifying abnormal instances
in complex networks. Despite advancements of methodology based on deep learning
in recent years, existing benchmarking approaches exhibit limitations that
hinder a comprehensive comparison. In this paper, we revisit datasets and
approaches for unsupervised node-level graph anomaly detection tasks from three
aspects. Firstly, we introduce outlier injection methods that create more
diverse and graph-based anomalies in graph datasets. Secondly, we compare
methods employing message passing against those without, uncovering the
unexpected decline in performance associated with message passing. Thirdly, we
explore the use of hyperbolic neural networks, specifying crucial architecture
and loss design that contribute to enhanced performance. Through rigorous
experiments and evaluations, our study sheds light on general strategies for
improving node-level graph anomaly detection methods.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04012" title="Abstract">arXiv:2403.04012</a> [<a href="/pdf/2403.04012" title="Download PDF">pdf</a>, <a href="/format/2403.04012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Cross-Attention for Dynamic Embedding and Tokenization of  Multimodal Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kolla%2C+S">Suraj Kolla</a>, 
<a href="/search/cs?searchtype=author&query=Kaliraman%2C+D">Dhruv Kaliraman</a>, 
<a href="/search/cs?searchtype=author&query=Nolan%2C+V">Victoria Nolan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhenhong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyuan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuanfang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Armfield%2C+B">Brooke Armfield</a>, 
<a href="/search/cs?searchtype=author&query=Ozrazgat-Baslanti%2C+T">Tezcan Ozrazgat-Baslanti</a>, 
<a href="/search/cs?searchtype=author&query=Loftus%2C+T+J">Tyler J. Loftus</a>, 
<a href="/search/cs?searchtype=author&query=Rashidi%2C+P">Parisa Rashidi</a>, 
<a href="/search/cs?searchtype=author&query=Bihorac%2C+A">Azra Bihorac</a>, 
<a href="/search/cs?searchtype=author&query=Shickel%2C+B">Benjamin Shickel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Workshop on Learning From Time Series for Health. 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The breadth, scale, and temporal granularity of modern electronic health
records (EHR) systems offers great potential for estimating personalized and
contextual patient health trajectories using sequential deep learning. However,
learning useful representations of EHR data is challenging due to its high
dimensionality, sparsity, multimodality, irregular and variable-specific
recording frequency, and timestamp duplication when multiple measurements are
recorded simultaneously. Although recent efforts to fuse structured EHR and
unstructured clinical notes suggest the potential for more accurate prediction
of clinical outcomes, less focus has been placed on EHR embedding approaches
that directly address temporal EHR challenges by learning time-aware
representations from multimodal patient time series. In this paper, we
introduce a dynamic embedding and tokenization framework for precise
representation of multimodal clinical time series that combines novel methods
for encoding time and sequential position with temporal cross-attention. Our
embedding and tokenization framework, when integrated into a multitask
transformer classifier with sliding window attention, outperformed baseline
approaches on the exemplar task of predicting the occurrence of nine
postoperative complications of more than 120,000 major inpatient surgeries
using multimodal data from three hospitals and two academic health centers in
the United States.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04013" title="Abstract">arXiv:2403.04013</a> [<a href="/pdf/2403.04013" title="Download PDF">pdf</a>, <a href="/format/2403.04013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whodunit: Classifying Code as Human Authored or GPT-4 Generated -- A  case study on CodeChef problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Idialu%2C+O+J">Oseremen Joy Idialu</a>, 
<a href="/search/cs?searchtype=author&query=Mathews%2C+N+S">Noble Saji Mathews</a>, 
<a href="/search/cs?searchtype=author&query=Maipradit%2C+R">Rungroj Maipradit</a>, 
<a href="/search/cs?searchtype=author&query=Atlee%2C+J+M">Joanne M. Atlee</a>, 
<a href="/search/cs?searchtype=author&query=Nagappan%2C+M">Mei Nagappan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, MSR Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT,
built on large language models like GPT-4, are revolutionizing how programming
tasks are performed, raising questions about whether code is authored by
generative AI models. Such questions are of particular interest to educators,
who worry that these tools enable a new form of academic dishonesty, in which
students submit AI generated code as their own work. Our research explores the
viability of using code stylometry and machine learning to distinguish between
GPT-4 generated and human-authored code. Our dataset comprises human-authored
solutions from CodeChef and AI-authored solutions generated by GPT-4. Our
classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A
variant of our classifier that excludes gameable features (e.g., empty lines,
whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We
also evaluated our classifier with respect to the difficulty of the programming
problem and found that there was almost no difference between easier and
intermediate problems, and the classifier performed only slightly worse on
harder problems. Our study shows that code stylometry is a promising approach
for distinguishing between GPT-4 generated code and human-authored code.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04014" title="Abstract">arXiv:2403.04014</a> [<a href="/pdf/2403.04014" title="Download PDF">pdf</a>, <a href="/format/2403.04014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptCharm: Text-to-Image Generation through Multi-modal Prompting and  Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Da Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 2024 CHI Conference on Human Factors in Computing Systems (CHI '24), May 11--16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent advancements in Generative AI have significantly advanced the
field of text-to-image generation. The state-of-the-art text-to-image model,
Stable Diffusion, is now capable of synthesizing high-quality images with a
strong sense of aesthetics. Crafting text prompts that align with the model's
interpretation and the user's intent thus becomes crucial. However, prompting
remains challenging for novice users due to the complexity of the stable
diffusion model and the non-trivial efforts required for iteratively editing
and refining the text prompts. To address these challenges, we propose
PromptCharm, a mixed-initiative system that facilitates text-to-image creation
through multi-modal prompt engineering and refinement. To assist novice users
in prompting, PromptCharm first automatically refines and optimizes the user's
initial prompt. Furthermore, PromptCharm supports the user in exploring and
selecting different image styles within a large database. To assist users in
effectively refining their prompts and images, PromptCharm renders model
explanations by visualizing the model's attention values. If the user notices
any unsatisfactory areas in the generated images, they can further refine the
images through model attention adjustment or image inpainting within the rich
feedback loop of PromptCharm. To evaluate the effectiveness and usability of
PromptCharm, we conducted a controlled user study with 12 participants and an
exploratory user study with another 12 participants. These two studies show
that participants using PromptCharm were able to create images with higher
quality and better aligned with the user's expectations compared with using two
variants of PromptCharm that lacked interaction or visualization support.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04015" title="Abstract">arXiv:2403.04015</a> [<a href="/pdf/2403.04015" title="Download PDF">pdf</a>, <a href="/format/2403.04015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knockoff-Guided Feature Selection via A Single Pre-trained Reinforced  Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+W">Wangyang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Rui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Feature selection prepares the AI-readiness of data by eliminating redundant
features. Prior research falls into two primary categories: i) Supervised
Feature Selection, which identifies the optimal feature subset based on their
relevance to the target variable; ii) Unsupervised Feature Selection, which
reduces the feature space dimensionality by capturing the essential information
within the feature set instead of using target variable. However, SFS
approaches suffer from time-consuming processes and limited generalizability
due to the dependence on the target variable and downstream ML tasks. UFS
methods are constrained by the deducted feature space is latent and
untraceable. To address these challenges, we introduce an innovative framework
for feature selection, which is guided by knockoff features and optimized
through reinforcement learning, to identify the optimal and effective feature
subset. In detail, our method involves generating "knockoff" features that
replicate the distribution and characteristics of the original features but are
independent of the target variable. Each feature is then assigned a pseudo
label based on its correlation with all the knockoff features, serving as a
novel metric for feature evaluation. Our approach utilizes these pseudo labels
to guide the feature selection process in 3 novel ways, optimized by a single
reinforced agent: 1). A deep Q-network, pre-trained with the original features
and their corresponding pseudo labels, is employed to improve the efficacy of
the exploration process in feature selection. 2). We introduce unsupervised
rewards to evaluate the feature subset quality based on the pseudo labels and
the feature space reconstruction loss to reduce dependencies on the target
variable. 3). A new {\epsilon}-greedy strategy is used, incorporating insights
from the pseudo labels to make the feature selection process more effective.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04017" title="Abstract">arXiv:2403.04017</a> [<a href="/pdf/2403.04017" title="Download PDF">pdf</a>, <a href="/ps/2403.04017" title="Download PostScript">ps</a>, <a href="/format/2403.04017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Guided Automated Reasoning: A Brief Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blaauwbroek%2C+L">Lasse Blaauwbroek</a>, 
<a href="/search/cs?searchtype=author&query=Cerna%2C+D">David Cerna</a>, 
<a href="/search/cs?searchtype=author&query=Gauthier%2C+T">Thibault Gauthier</a>, 
<a href="/search/cs?searchtype=author&query=Jakub%C5%AFv%2C+J">Jan Jakub&#x16f;v</a>, 
<a href="/search/cs?searchtype=author&query=Kaliszyk%2C+C">Cezary Kaliszyk</a>, 
<a href="/search/cs?searchtype=author&query=Suda%2C+M">Martin Suda</a>, 
<a href="/search/cs?searchtype=author&query=Urban%2C+J">Josef Urban</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Neural and Evolutionary Computing (cs.NE); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Automated theorem provers and formal proof assistants are general reasoning
systems that are in theory capable of proving arbitrarily hard theorems, thus
solving arbitrary problems reducible to mathematics and logical reasoning. In
practice, such systems however face large combinatorial explosion, and
therefore include many heuristics and choice points that considerably influence
their performance. This is an opportunity for trained machine learning
predictors, which can guide the work of such reasoning systems. Conversely,
deductive search supported by the notion of logically valid proof allows one to
train machine learning systems on large reasoning corpora. Such bodies of proof
are usually correct by construction and when combined with more and more
precise trained guidance they can be boostrapped into very large corpora, with
increasingly long reasoning chains and possibly novel proof ideas. In this
paper we provide an overview of several automated reasoning and theorem proving
domains and the learning and AI methods that have been so far developed for
them. These include premise selection, proof guidance in several settings, AI
systems and feedback loops iterating between reasoning and learning, and
symbolic classification problems.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04018" title="Abstract">arXiv:2403.04018</a> [<a href="/pdf/2403.04018" title="Download PDF">pdf</a>, <a href="/format/2403.04018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Game-Theoretic Analysis: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wellman%2C+M+P">Michael P. Wellman</a>, 
<a href="/search/cs?searchtype=author&query=Tuyls%2C+K">Karl Tuyls</a>, 
<a href="/search/cs?searchtype=author&query=Greenwald%2C+A">Amy Greenwald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 72 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In the empirical approach to game-theoretic analysis (EGTA), the model of the
game comes not from declarative representation, but is derived by interrogation
of a procedural description of the game environment. The motivation for
developing this approach was to enable game-theoretic reasoning about strategic
situations too complex for analytic specification and solution. Since its
introduction over twenty years ago, EGTA has been applied to a wide range of
multiagent domains, from auctions and markets to recreational games to
cyber-security. We survey the extensive methodology developed for EGTA over the
years, organized by the elemental subproblems comprising the EGTA process. We
describe key EGTA concepts and techniques, and the questions at the frontier of
EGTA research. Recent advances in machine learning have accelerated progress in
EGTA, and promise to significantly expand our capacities for reasoning about
complex game situations.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04021" title="Abstract">arXiv:2403.04021</a> [<a href="/pdf/2403.04021" title="Download PDF">pdf</a>, <a href="/format/2403.04021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Autonomous Exploration and Mapping Under Localization  Uncertainty with Expectation-Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yewei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Englot%2C+B">Brendan Englot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose an autonomous exploration algorithm designed for decentralized
multi-robot teams, which takes into account map and localization uncertainties
of range-sensing mobile robots. Virtual landmarks are used to quantify the
combined impact of process noise and sensor noise on map uncertainty.
Additionally, we employ an iterative expectation-maximization inspired
algorithm to assess the potential outcomes of both a local robot's and its
neighbors' next-step actions. To evaluate the effectiveness of our framework,
we conduct a comparative analysis with state-of-the-art algorithms. The results
of our experiments show the proposed algorithm's capacity to strike a balance
between curbing map uncertainty and achieving efficient task allocation among
robots.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04026" title="Abstract">arXiv:2403.04026</a> [<a href="/pdf/2403.04026" title="Download PDF">pdf</a>, <a href="/format/2403.04026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning Tree-based Query Plan Enumeration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izenov%2C+Y">Yesdaulet Izenov</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Asoke Datta</a>, 
<a href="/search/cs?searchtype=author&query=Tsan%2C+B">Brian Tsan</a>, 
<a href="/search/cs?searchtype=author&query=Amanbayev%2C+A">Abylay Amanbayev</a>, 
<a href="/search/cs?searchtype=author&query=Rusu%2C+F">Florin Rusu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In this work, we define the problem of finding an optimal query plan as
finding spanning trees with low costs. This approach empowers the utilization
of a series of spanning tree algorithms, thereby enabling systematic
exploration of the plan search space over a join graph. Capitalizing on the
polynomial time complexity of spanning tree algorithms, we present the Ensemble
Spanning Tree Enumeration (ESTE) strategy. ESTE employs two conventional
spanning tree algorithms, Prim's and Kruskal's, together to enhance the
robustness of the query optimizer. In ESTE, multiple query plans are enumerated
exploring different areas of the search space. This positions ESTE as an
intermediate strategy between exhaustive and heuristic enumeration strategies.
We show that ESTE is more robust in identifying efficient query plans for large
queries. In the case of data modifications and workload demand increase, we
believe that our approach can be a cheaper alternative to maintain optimizer
robustness by integrating additional spanning tree algorithms rather than
completely changing the optimizer to another plan enumeration algorithm. The
experimental evaluation shows that ESTE achieves better consistency in plan
quality and optimization time than existing solutions while identifying
similarly optimal plans.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04028" title="Abstract">arXiv:2403.04028</a> [<a href="/pdf/2403.04028" title="Download PDF">pdf</a>, <a href="/format/2403.04028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RISnet: A Domain-Knowledge Driven Neural Network Architecture for RIS  Optimization with Mutual Coupling and Partial CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bile Peng</a>, 
<a href="/search/cs?searchtype=author&query=Besser%2C+K">Karl-Ludwig Besser</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shanpu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Siegismund-Poschmann%2C+F">Finn Siegismund-Poschmann</a>, 
<a href="/search/cs?searchtype=author&query=Raghunath%2C+R">Ramprasad Raghunath</a>, 
<a href="/search/cs?searchtype=author&query=Mittleman%2C+D">Daniel Mittleman</a>, 
<a href="/search/cs?searchtype=author&query=Jamali%2C+V">Vahid Jamali</a>, 
<a href="/search/cs?searchtype=author&query=Jorswieck%2C+E+A">Eduard A. Jorswieck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Multiple access techniques are cornerstones of wireless communications. Their
performance depends on the channel properties, which can be improved by
reconfigurable intelligent surfaces (RISs). In this work, we jointly optimize
MA precoding at the base station (BS) and RIS configuration. We tackle
difficulties of mutual coupling between RIS elements, scalability to more than
1000 RIS elements, and channel estimation. We first derive an RIS-assisted
channel model considering mutual coupling, then propose an unsupervised machine
learning (ML) approach to optimize the RIS. In particular, we design a
dedicated neural network (NN) architecture RISnet with good scalability and
desired symmetry. Moreover, we combine ML-enabled RIS configuration and
analytical precoding at BS since there exist analytical precoding schemes.
Furthermore, we propose another variant of RISnet, which requires the channel
state information (CSI) of a small portion of RIS elements (in this work, 16
out of 1296 elements) if the channel comprises a few specular propagation
paths. More generally, this work is an early contribution to combine ML
technique and domain knowledge in communication for NN architecture design.
Compared to generic ML, the problem-specific ML can achieve higher performance,
lower complexity and symmetry.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04031" title="Abstract">arXiv:2403.04031</a> [<a href="/pdf/2403.04031" title="Download PDF">pdf</a>, <a href="/format/2403.04031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models do Analytical Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yebowen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiqiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sangwoo Cho</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Foroosh%2C+H">Hassan Foroosh</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the cutting-edge Large Language Model with analytical
reasoning on sports. Our analytical reasoning embodies the tasks of letting
large language models count how many points each team scores in a quarter in
the NBA and NFL games. Our major discoveries are in two folds. Firstly, we find
among all the models we employed, GPT-4 stands out in effectiveness, followed
by Claude-2.1, with GPT-3.5, Gemini-Pro, and Llama-2-70b lagging behind.
Specifically, we compare three different prompting techniques and a
divide-and-conquer approach, we find that the latter was the most effective.
Our divide-and-conquer approach breaks down play-by-play data into smaller,
more manageable segments, solves each piece individually, and then aggregates
them together. Besides the divide-and-conquer approach, we also explore the
Chain of Thought (CoT) strategy, which markedly improves outcomes for certain
models, notably GPT-4 and Claude-2.1, with their accuracy rates increasing
significantly. However, the CoT strategy has negligible or even detrimental
effects on the performance of other models like GPT-3.5 and Gemini-Pro.
Secondly, to our surprise, we observe that most models, including GPT-4,
struggle to accurately count the total scores for NBA quarters despite showing
strong performance in counting NFL quarter scores. This leads us to further
investigate the factors that impact the complexity of analytical reasoning
tasks with extensive experiments, through which we conclude that task
complexity depends on the length of context, the information density, and the
presence of related information. Our research provides valuable insights into
the complexity of analytical reasoning tasks and potential directions for
developing future large language models.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04033" title="Abstract">arXiv:2403.04033</a> [<a href="/pdf/2403.04033" title="Download PDF">pdf</a>, <a href="/ps/2403.04033" title="Download PostScript">ps</a>, <a href="/format/2403.04033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning with Unknown Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+K">Karthik Sridharan</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S+W+W">Seung Won Wilson Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of online learning where the sequence of actions
played by the learner must adhere to an unknown safety constraint at every
round. The goal is to minimize regret with respect to the best safe action in
hindsight while simultaneously satisfying the safety constraint with high
probability on each round. We provide a general meta-algorithm that leverages
an online regression oracle to estimate the unknown safety constraint, and
converts the predictions of an online learning oracle to predictions that
adhere to the unknown safety constraint. On the theoretical side, our
algorithm's regret can be bounded by the regret of the online regression and
online learning oracles, the eluder dimension of the model class containing the
unknown safety constraint, and a novel complexity measure that captures the
difficulty of safe learning. We complement our result with an asymptotic lower
bound that shows that the aforementioned complexity measure is necessary. When
the constraints are linear, we instantiate our result to provide a concrete
algorithm with $\sqrt{T}$ regret using a scaling transformation that balances
optimistic exploration with pessimistic constraint satisfaction.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04035" title="Abstract">arXiv:2403.04035</a> [<a href="/pdf/2403.04035" title="Download PDF">pdf</a>, <a href="/format/2403.04035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalizing explanations of AI-driven hints to users cognitive  abilities: an empirical evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahel%2C+V">Vedant Bahel</a>, 
<a href="/search/cs?searchtype=author&query=Sriram%2C+H">Harshinee Sriram</a>, 
<a href="/search/cs?searchtype=author&query=Conati%2C+C">Cristina Conati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We investigate personalizing the explanations that an Intelligent Tutoring
System generates to justify the hints it provides to students to foster their
learning. The personalization targets students with low levels of two traits,
Need for Cognition and Conscientiousness, and aims to enhance these students'
engagement with the explanations, based on prior findings that these students
do not naturally engage with the explanations but they would benefit from them
if they do. To evaluate the effectiveness of the personalization, we conducted
a user study where we found that our proposed personalization significantly
increases our target users' interaction with the hint explanations, their
understanding of the hints and their learning. Hence, this work provides
valuable insights into effectively personalizing AI-driven explanations for
cognitively demanding tasks such as learning.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04036" title="Abstract">arXiv:2403.04036</a> [<a href="/pdf/2403.04036" title="Download PDF">pdf</a>, <a href="/format/2403.04036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Contrastive Learning for Robust RF Device Fingerprinting  Under Time-Domain Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W">Weng-Keen Wong</a>, 
<a href="/search/cs?searchtype=author&query=Hamdaoui%2C+B">Bechir Hamdaoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, accepted by 2024 IEEE International Conference on Communications (ICC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Radio Frequency (RF) device fingerprinting has been recognized as a potential
technology for enabling automated wireless device identification and
classification. However, it faces a key challenge due to the domain shift that
could arise from variations in the channel conditions and environmental
settings, potentially degrading the accuracy of RF-based device classification
when testing and training data is collected in different domains. This paper
introduces a novel solution that leverages contrastive learning to mitigate
this domain shift problem. Contrastive learning, a state-of-the-art
self-supervised learning approach from deep learning, learns a distance metric
such that positive pairs are closer (i.e. more similar) in the learned metric
space than negative pairs. When applied to RF fingerprinting, our model treats
RF signals from the same transmission as positive pairs and those from
different transmissions as negative pairs. Through experiments on wireless and
wired RF datasets collected over several days, we demonstrate that our
contrastive learning approach captures domain-invariant features, diminishing
the effects of domain-specific variations. Our results show large and
consistent improvements in accuracy (10.8\% to 27.8\%) over baseline models,
thus underscoring the effectiveness of contrastive learning in improving device
classification under domain shift.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04037" title="Abstract">arXiv:2403.04037</a> [<a href="/pdf/2403.04037" title="Download PDF">pdf</a>, <a href="/format/2403.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCD-FL: A Novel Communication-Efficient Peer Selection-based  Decentralized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masmoudi%2C+N">Nizar Masmoudi</a>, 
<a href="/search/cs?searchtype=author&query=Jaafar%2C+W">Wael Jaafar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to IEEE Transactions on Vehicular Technology as a Correspondance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The conjunction of edge intelligence and the ever-growing Internet-of-Things
(IoT) network heralds a new era of collaborative machine learning, with
federated learning (FL) emerging as the most prominent paradigm. With the
growing interest in these learning schemes, researchers started addressing some
of their most fundamental limitations. Indeed, conventional FL with a central
aggregator presents a single point of failure and a network bottleneck. To
bypass this issue, decentralized FL where nodes collaborate in a peer-to-peer
network has been proposed. Despite the latter's efficiency, communication costs
and data heterogeneity remain key challenges in decentralized FL. In this
context, we propose a novel scheme, called opportunistic
communication-efficient decentralized federated learning, a.k.a., OCD-FL,
consisting of a systematic FL peer selection for collaboration, aiming to
achieve maximum FL knowledge gain while reducing energy consumption.
Experimental results demonstrate the capability of OCD-FL to achieve similar or
better performances than the fully collaborative FL, while significantly
reducing consumed energy by at least 30% and up to 80%.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04039" title="Abstract">arXiv:2403.04039</a> [<a href="/pdf/2403.04039" title="Download PDF">pdf</a>, <a href="/format/2403.04039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample size planning for conditional counterfactual mean estimation with  a K-armed randomized experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+G">Gabriel Ruiz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">We cover how to determine a sufficiently large sample size for a $K$-armed
randomized experiment in order to estimate conditional counterfactual
expectations in data-driven subgroups. The sub-groups can be output by any
feature space partitioning algorithm, including as defined by binning users
having similar predictive scores or as defined by a learned policy tree. After
carefully specifying the inference target, a minimum confidence level, and a
maximum margin of error, the key is to turn the original goal into a
simultaneous inference problem where the recommended sample size to offset an
increased possibility of estimation error is directly related to the number of
inferences to be conducted. Given a fixed sample size budget, our result allows
us to invert the question to one about the feasible number of treatment arms or
partition complexity (e.g. number of decision tree leaves). Using policy trees
to learn sub-groups, we evaluate our nominal guarantees on a large
publicly-available randomized experiment test data set.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04045" title="Abstract">arXiv:2403.04045</a> [<a href="/pdf/2403.04045" title="Download PDF">pdf</a>, <a href="/ps/2403.04045" title="Download PostScript">ps</a>, <a href="/format/2403.04045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Computational Notions of Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bienvenu%2C+L">Laurent Bienvenu</a>, 
<a href="/search/cs?searchtype=author&query=Porter%2C+C+P">Christopher P. Porter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">In this article, we study the relationship between notions of depth for
sequences, namely, Bennett's notions of strong and weak depth, and deep
$\Pi^0_1$ classes, introduced by the authors and motivated by previous work of
Levin. For the first main result of the study, we show that every member of a
$\Pi^0_1$ class is order-deep, a property that implies strong depth. From this
result, we obtain new examples of strongly deep sequences based on properties
studied in computability theory and algorithmic randomness. We further show
that not every strongly deep sequence is a member of a deep $\Pi^0_1$ class.
For the second main result, we show that the collection of strongly deep
sequences is negligible, which is equivalent to the statement that the
probability of computing a strongly deep sequence with some random oracle is 0,
a property also shared by every deep $\Pi^0_1$ class. Finally, we show that
variants of strong depth, given in terms of a priori complexity and monotone
complexity, are equivalent to weak depth.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04050" title="Abstract">arXiv:2403.04050</a> [<a href="/pdf/2403.04050" title="Download PDF">pdf</a>, <a href="/format/2403.04050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Belief-Enriched Pessimistic Q-Learning against Adversarial State  Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaolin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zizhan Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement learning (RL) has achieved phenomenal success in various
domains. However, its data-driven nature also introduces new vulnerabilities
that can be exploited by malicious opponents. Recent work shows that a
well-trained RL agent can be easily manipulated by strategically perturbing its
state observations at the test stage. Existing solutions either introduce a
regularization term to improve the smoothness of the trained policy against
perturbations or alternatively train the agent's policy and the attacker's
policy. However, the former does not provide sufficient protection against
strong attacks, while the latter is computationally prohibitive for large
environments. In this work, we propose a new robust RL algorithm for deriving a
pessimistic policy to safeguard against an agent's uncertainty about true
states. This approach is further enhanced with belief state inference and
diffusion-based state purification to reduce uncertainty. Empirical results
show that our approach obtains superb performance under strong attacks and has
a comparable training overhead with regularization-based methods. Our code is
available at https://github.com/SliencerX/Belief-enriched-robust-Q-learning.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04052" title="Abstract">arXiv:2403.04052</a> [<a href="/pdf/2403.04052" title="Download PDF">pdf</a>, <a href="/ps/2403.04052" title="Download PostScript">ps</a>, <a href="/format/2403.04052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Identity of Hankel Matrices Generated from the Moments of Gaussian  Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sha Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this letter, we proved a matrix identity of Hankel matrices that seems
unrevealed before, generated from the moments of Gaussian distributions. In
particular, we derived the Cholesky decompositions of the Hankel matrices in
closed-forms, and showed some interesting connections between them. The results
have potential applications in such as optimizing a nonlinear (NL) distortion
function that maximizes the receiving gain in wireless communication systems.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04057" title="Abstract">arXiv:2403.04057</a> [<a href="/pdf/2403.04057" title="Download PDF">pdf</a>, <a href="/format/2403.04057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Spend or to Gain: Online Learning in Repeated Karma Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berriaud%2C+D">Damien Berriaud</a>, 
<a href="/search/cs?searchtype=author&query=Elokda%2C+E">Ezzat Elokda</a>, 
<a href="/search/cs?searchtype=author&query=Jalota%2C+D">Devansh Jalota</a>, 
<a href="/search/cs?searchtype=author&query=Frazzoli%2C+E">Emilio Frazzoli</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript submitted for review to the 25th ACM Conference on Economics &amp; Computation (EC'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Recent years have seen a surge of artificial currency-based mechanisms in
contexts where monetary instruments are deemed unfair or inappropriate, e.g.,
in allocating food donations to food banks, course seats to students, and, more
recently, even for traffic congestion management. Yet the applicability of
these mechanisms remains limited in repeated auction settings, as it is
challenging for users to learn how to bid an artificial currency that has no
value outside the auctions. Indeed, users must jointly learn the value of the
currency in addition to how to spend it optimally. In this work, we study the
problem of learning to bid in two prominent classes of artificial currency
auctions: those in which currency, which users spend to obtain public
resources, is only issued at the beginning of a finite period; and those where,
in addition to the initial currency endowment, currency payments are
redistributed to users at each time step. In the latter class, the currency has
been referred to as karma, since users do not only spend karma to obtain public
resources but also gain karma for yielding them. In both classes, we propose a
simple learning strategy, called adaptive karma pacing, and show that this
strategy a) is asymptotically optimal for a single user bidding against
competing bids drawn from a stationary distribution; b) leads to convergent
learning dynamics when all users adopt it; and c) constitutes an approximate
Nash equilibrium as the number of users grows. Our results require a novel
analysis in comparison to adaptive pacing strategies in monetary auctions,
since we depart from the classical assumption that the currency has known value
outside the auctions, and moreover consider that the currency is both spent and
gained in the class of auctions with redistribution.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04063" title="Abstract">arXiv:2403.04063</a> [<a href="/pdf/2403.04063" title="Download PDF">pdf</a>, <a href="/format/2403.04063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assigning Entities to Teams as a Hypergraph Discovery Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Arruda%2C+G+F">Guilherme Ferraz de Arruda</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wan He</a>, 
<a href="/search/cs?searchtype=author&query=Heydaribeni%2C+N">Nasimeh Heydaribeni</a>, 
<a href="/search/cs?searchtype=author&query=Javidi%2C+T">Tara Javidi</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+Y">Yamir Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Eliassi-Rad%2C+T">Tina Eliassi-Rad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Spectral Theory (math.SP)

</div>
<p class="mathjax">We propose a team assignment algorithm based on a hypergraph approach
focusing on resilience and diffusion optimization. Specifically, our method is
based on optimizing the algebraic connectivity of the Laplacian matrix of an
edge-dependent vertex-weighted hypergraph. We used constrained simulated
annealing, where we constrained the effort agents can exert to perform a task
and the minimum effort a task requires to be completed. We evaluated our
methods in terms of the number of unsuccessful patches to drive our solution
into the feasible region and the cost of patching. We showed that our
formulation provides more robust solutions than the original data and the
greedy approach. We hope that our methods motivate further research in applying
hypergraphs to similar problems in different research areas and in exploring
variations of our methods.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04066" title="Abstract">arXiv:2403.04066</a> [<a href="/pdf/2403.04066" title="Download PDF">pdf</a>, <a href="/ps/2403.04066" title="Download PostScript">ps</a>, <a href="/format/2403.04066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoDisc: Learning Global-Local Discriminative Features for  Self-Supervised Fine-Grained Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jialu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jie Nie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised contrastive learning strategy has attracted remarkable
attention due to its exceptional ability in representation learning. However,
current contrastive learning tends to learn global coarse-grained
representations of the image that benefit generic object recognition, whereas
such coarse-grained features are insufficient for fine-grained visual
recognition. In this paper, we present to incorporate the subtle local
fine-grained feature learning into global self-supervised contrastive learning
through a pure self-supervised global-local fine-grained contrastive learning
framework. Specifically, a novel pretext task called Local Discrimination
(LoDisc) is proposed to explicitly supervise self-supervised model's focus
towards local pivotal regions which are captured by a simple-but-effective
location-wise mask sampling strategy. We show that Local Discrimination pretext
task can effectively enhance fine-grained clues in important local regions, and
the global-local framework further refines the fine-grained feature
representations of images. Extensive experimental results on different
fine-grained object recognition tasks demonstrate that the proposed method can
lead to a decent improvement in different evaluation settings. Meanwhile, the
proposed method is also effective in general object recognition tasks.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04067" title="Abstract">arXiv:2403.04067</a> [<a href="/pdf/2403.04067" title="Download PDF">pdf</a>, <a href="/format/2403.04067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feel the Bite: Robot-Assisted Inside-Mouth Bite Transfer using Robust  Mouth Perception and Physical Interaction-Aware Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jenamani%2C+R+K">Rajat Kumar Jenamani</a>, 
<a href="/search/cs?searchtype=author&query=Stabile%2C+D">Daniel Stabile</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+A">Abrar Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Dimitropoulou%2C+K">Katherine Dimitropoulou</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+T">Tapomayukh Bhattacharjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> HRI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robot-assisted feeding can greatly enhance the lives of those with mobility
limitations. Modern feeding systems can pick up and position food in front of a
care recipient's mouth for a bite. However, many with severe mobility
constraints cannot lean forward and need direct inside-mouth food placement.
This demands precision, especially for those with restricted mouth openings,
and appropriately reacting to various physical interactions - incidental
contacts as the utensil moves inside, impulsive contacts due to sudden muscle
spasms, deliberate tongue maneuvers by the person being fed to guide the
utensil, and intentional bites. In this paper, we propose an inside-mouth bite
transfer system that addresses these challenges with two key components: a
multi-view mouth perception pipeline robust to tool occlusion, and a control
mechanism that employs multimodal time-series classification to discern and
react to different physical interactions. We demonstrate the efficacy of these
individual components through two ablation studies. In a full system
evaluation, our system successfully fed 13 care recipients with diverse
mobility challenges. Participants consistently emphasized the comfort and
safety of our inside-mouth bite transfer system, and gave it high technology
acceptance ratings - underscoring its transformative potential in real-world
scenarios. Supplementary materials and videos can be found at
<a href="http://emprise.cs.cornell.edu/bitetransfer/">this http URL</a> .
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04070" title="Abstract">arXiv:2403.04070</a> [<a href="/pdf/2403.04070" title="Download PDF">pdf</a>, <a href="/format/2403.04070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Training using Vulnerability-Aware Perturbation  Budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fakorede%2C+O">Olukorede Fakorede</a>, 
<a href="/search/cs?searchtype=author&query=Atsague%2C+M">Modeste Atsague</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jin Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Adversarial Training (AT) effectively improves the robustness of Deep Neural
Networks (DNNs) to adversarial attacks. Generally, AT involves training DNN
models with adversarial examples obtained within a pre-defined, fixed
perturbation bound. Notably, individual natural examples from which these
adversarial examples are crafted exhibit varying degrees of intrinsic
vulnerabilities, and as such, crafting adversarial examples with fixed
perturbation radius for all instances may not sufficiently unleash the potency
of AT. Motivated by this observation, we propose two simple, computationally
cheap vulnerability-aware reweighting functions for assigning perturbation
bounds to adversarial examples used for AT, named Margin-Weighted Perturbation
Budget (MWPB) and Standard-Deviation-Weighted Perturbation Budget (SDWPB). The
proposed methods assign perturbation radii to individual adversarial samples
based on the vulnerability of their corresponding natural examples.
Experimental results show that the proposed methods yield genuine improvements
in the robustness of AT algorithms against various adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04071" title="Abstract">arXiv:2403.04071</a> [<a href="/pdf/2403.04071" title="Download PDF">pdf</a>, <a href="/format/2403.04071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-device Self-supervised Learning of Visual Perception Tasks aboard  Hardware-limited Nano-quadrotors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cereda%2C+E">Elia Cereda</a>, 
<a href="/search/cs?searchtype=author&query=Rusci%2C+M">Manuele Rusci</a>, 
<a href="/search/cs?searchtype=author&query=Giusti%2C+A">Alessandro Giusti</a>, 
<a href="/search/cs?searchtype=author&query=Palossi%2C+D">Daniele Palossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sub-\SI{50}{\gram} nano-drones are gaining momentum in both academia and
industry. Their most compelling applications rely on onboard deep learning
models for perception despite severe hardware constraints (\ie
sub-\SI{100}{\milli\watt} processor). When deployed in unknown environments not
represented in the training data, these models often underperform due to domain
shift. To cope with this fundamental problem, we propose, for the first time,
on-device learning aboard nano-drones, where the first part of the in-field
mission is dedicated to self-supervised fine-tuning of a pre-trained
convolutional neural network (CNN). Leveraging a real-world vision-based
regression task, we thoroughly explore performance-cost trade-offs of the
fine-tuning phase along three axes: \textit{i}) dataset size (more data
increases the regression performance but requires more memory and longer
computation); \textit{ii}) methodologies (\eg fine-tuning all model parameters
vs. only a subset); and \textit{iii}) self-supervision strategy. Our approach
demonstrates an improvement in mean absolute error up to 30\% compared to the
pre-trained baseline, requiring only \SI{22}{\second} fine-tuning on an
ultra-low-power GWT GAP9 System-on-Chip. Addressing the domain shift problem
via on-device learning aboard nano-drones not only marks a novel result for
hardware-limited robots but lays the ground for more general advancements for
the entire robotics community.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04072" title="Abstract">arXiv:2403.04072</a> [<a href="/pdf/2403.04072" title="Download PDF">pdf</a>, <a href="/format/2403.04072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting and Mitigating Disruptions in Public Bus Transit Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chaeeun Han</a>, 
<a href="/search/cs?searchtype=author&query=Talusan%2C+J+P">Jose Paolo Talusan</a>, 
<a href="/search/cs?searchtype=author&query=Freudberg%2C+D">Dan Freudberg</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Ayan Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Abhishek Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Laszka%2C+A">Aron Laszka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Public transportation systems often suffer from unexpected fluctuations in
demand and disruptions, such as mechanical failures and medical emergencies.
These fluctuations and disruptions lead to delays and overcrowding, which are
detrimental to the passengers' experience and to the overall performance of the
transit service. To proactively mitigate such events, many transit agencies
station substitute (reserve) vehicles throughout their service areas, which
they can dispatch to augment or replace vehicles on routes that suffer
overcrowding or disruption. However, determining the optimal locations where
substitute vehicles should be stationed is a challenging problem due to the
inherent randomness of disruptions and due to the combinatorial nature of
selecting locations across a city. In collaboration with the transit agency of
Nashville, TN, we address this problem by introducing data-driven statistical
and machine-learning models for forecasting disruptions and an effective
randomized local-search algorithm for selecting locations where substitute
vehicles are to be stationed. Our research demonstrates promising results in
proactive disruption management, offering a practical and easily implementable
solution for transit agencies to enhance the reliability of their services. Our
results resonate beyond mere operational efficiency: by advancing proactive
strategies, our approach fosters more resilient and accessible public
transportation, contributing to equitable urban mobility and ultimately
benefiting the communities that rely on public transportation the most.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04073" title="Abstract">arXiv:2403.04073</a> [<a href="/pdf/2403.04073" title="Download PDF">pdf</a>, <a href="/format/2403.04073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Dialogue Abstractive Summarization via High-Quality  Pseudolabel Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jason Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shalyminov%2C+I">Igor Shalyminov</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semi-supervised dialogue summarization (SSDS) leverages model-generated
summaries to reduce reliance on human-labeled data and improve the performance
of summarization models. While addressing label noise, previous works on
semi-supervised learning primarily focus on natural language understanding
tasks, assuming each sample has a unique label. However, these methods are not
directly applicable to SSDS, as it is a generative task, and each dialogue can
be summarized in different ways. In this work, we propose a novel scoring
approach, SiCF, which encapsulates three primary dimensions of summarization
model quality: Semantic invariance (indicative of model confidence), Coverage
(factual recall), and Faithfulness (factual precision). Using the SiCF score,
we select unlabeled dialogues with high-quality generated summaries to train
summarization models. Comprehensive experiments on three public datasets
demonstrate the effectiveness of SiCF scores in uncertainty estimation and
semi-supervised learning for dialogue summarization tasks. Our code is
available at \url{https://github.com/amazon-science/summarization-sicf-score}.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04074" title="Abstract">arXiv:2403.04074</a> [<a href="/pdf/2403.04074" title="Download PDF">pdf</a>, <a href="/format/2403.04074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving HTTP/3 Quality of Experience with EPS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhinav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bartos%2C+R">Radim Bartos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">With the introduction of QUIC, a modern transport-layer network protocol,
HTTP/3 leverages its benefits to enhance web content delivery. This paper
proposes a mechanism based on the recently standardized Extensible
Prioritization Scheme (EPS) for weighted incremental web content delivery. The
mechanism augments the sequential scheduling to provide incremental and
weighted incremental resource delivery. An existing HTTP/3 implementation was
extended with the proposed mechanism and tested with the content of eight
popular websites. The results of our experimental analysis show that weighted
incremental prioritization improves Quality of Experience (QoE) as measured by
Lighthouse, a standard QoE test tool. While overall improvements were generally
achieved, we also observed a few cases where the performance degraded slightly,
highlighting that the QoE is sensitive to factors such as web page structure.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04080" title="Abstract">arXiv:2403.04080</a> [<a href="/pdf/2403.04080" title="Download PDF">pdf</a>, <a href="/format/2403.04080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers and Language Models in Form Understanding: A Comprehensive  Review of Scanned Document Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+A">Abdelrahman Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Eberharter%2C+D">Daniel Eberharter</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+Z">Zoe Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Jatowt%2C+A">Adam Jatowt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper presents a comprehensive survey of research works on the topic of
form understanding in the context of scanned documents. We delve into recent
advancements and breakthroughs in the field, highlighting the significance of
language models and transformers in solving this challenging task. Our research
methodology involves an in-depth analysis of popular documents and forms of
understanding of trends over the last decade, enabling us to offer valuable
insights into the evolution of this domain. Focusing on cutting-edge models, we
showcase how transformers have propelled the field forward, revolutionizing
form-understanding techniques. Our exploration includes an extensive
examination of state-of-the-art language models designed to effectively tackle
the complexities of noisy scanned documents. Furthermore, we present an
overview of the latest and most relevant datasets, which serve as essential
benchmarks for evaluating the performance of selected models. By comparing and
contrasting the capabilities of these models, we aim to provide researchers and
practitioners with useful guidance in choosing the most suitable solutions for
their specific form understanding tasks.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04081" title="Abstract">arXiv:2403.04081</a> [<a href="/pdf/2403.04081" title="Download PDF">pdf</a>, <a href="/format/2403.04081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directional Smoothness and Gradient Methods: Convergence and Adaptivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishkin%2C+A">Aaron Mishkin</a>, 
<a href="/search/cs?searchtype=author&query=Khaled%2C+A">Ahmed Khaled</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Defazio%2C+A">Aaron Defazio</a>, 
<a href="/search/cs?searchtype=author&query=Gower%2C+R+M">Robert M. Gower</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Twenty-four pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We develop new sub-optimality bounds for gradient descent (GD) that depend on
the conditioning of the objective along the path of optimization, rather than
on global, worst-case constants. Key to our proofs is directional smoothness, a
measure of gradient variation that we use to develop upper-bounds on the
objective. Minimizing these upper-bounds requires solving implicit equations to
obtain a sequence of strongly adapted step-sizes; we show that these equations
are straightforward to solve for convex quadratics and lead to new guarantees
for two classical step-sizes. For general functions, we prove that the Polyak
step-size and normalized GD obtain fast, path-dependent rates despite using no
knowledge of the directional smoothness. Experiments on logistic regression
show our convergence guarantees are tighter than the classical theory based on
L-smoothness.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04082" title="Abstract">arXiv:2403.04082</a> [<a href="/pdf/2403.04082" title="Download PDF">pdf</a>, <a href="/format/2403.04082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference via Interpolation: Contrastive Representations Provably Enable  Planning and Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eysenbach%2C+B">Benjamin Eysenbach</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+V">Vivek Myers</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/vivekmyers/contrastive_planning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Given time series data, how can we answer questions like "what will happen in
the future?" and "how did we get here?" These sorts of probabilistic inference
questions are challenging when observations are high-dimensional. In this
paper, we show how these questions can have compact, closed form solutions in
terms of learned representations. The key idea is to apply a variant of
contrastive learning to time series data. Prior work already shows that the
representations learned by contrastive learning encode a probability ratio. By
extending prior work to show that the marginal distribution over
representations is Gaussian, we can then prove that joint distribution of
representations is also Gaussian. Taken together, these results show that
representations learned via temporal contrastive learning follow a Gauss-Markov
chain, a graphical model where inference (e.g., prediction, planning) over
representations corresponds to inverting a low-dimensional matrix. In one
special case, inferring intermediate representations will be equivalent to
interpolating between the learned representations. We validate our theory using
numerical simulations on tasks up to 46-dimensions.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04085" title="Abstract">arXiv:2403.04085</a> [<a href="/pdf/2403.04085" title="Download PDF">pdf</a>, <a href="/format/2403.04085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Blame the Data, Blame the Model: Understanding Noise and Bias When  Learning from Subjective Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Abhishek Anand</a>, 
<a href="/search/cs?searchtype=author&query=Mokhberian%2C+N">Negar Mokhberian</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P+N">Prathyusha Naresh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Anweasha Saha</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zihao He</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Ashwin Rao</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+K">Kristina Lerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Researchers have raised awareness about the harms of aggregating labels
especially in subjective tasks that naturally contain disagreements among human
annotators. In this work we show that models that are only provided aggregated
labels show low confidence on high-disagreement data instances. While previous
studies consider such instances as mislabeled, we argue that the reason the
high-disagreement text instances have been hard-to-learn is that the
conventional aggregated models underperform in extracting useful signals from
subjective tasks. Inspired by recent studies demonstrating the effectiveness of
learning from raw annotations, we investigate classifying using Multiple Ground
Truth (Multi-GT) approaches. Our experiments show an improvement of confidence
for the high-disagreement instances.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04086" title="Abstract">arXiv:2403.04086</a> [<a href="/pdf/2403.04086" title="Download PDF">pdf</a>, <a href="/format/2403.04086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Multi-Task Learning for Joint Disease Prediction on Electronic  Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Suhan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the realm of big data and digital healthcare, Electronic Health Records
(EHR) have become a rich source of information with the potential to improve
patient care and medical research. In recent years, machine learning models
have proliferated for analyzing EHR data to predict patients future health
conditions. Among them, some studies advocate for multi-task learning (MTL) to
jointly predict multiple target diseases for improving the prediction
performance over single task learning. Nevertheless, current MTL frameworks for
EHR data have significant limitations due to their heavy reliance on human
experts to identify task groups for joint training and design model
architectures. To reduce human intervention and improve the framework design,
we propose an automated approach named AutoDP, which can search for the optimal
configuration of task grouping and architectures simultaneously. To tackle the
vast joint search space encompassing task combinations and architectures, we
employ surrogate model-based optimization, enabling us to efficiently discover
the optimal solution. Experimental results on real-world EHR data demonstrate
the efficacy of the proposed AutoDP framework. It achieves significant
performance improvements over both hand-crafted and automated state-of-the-art
methods, also maintains a feasible search cost at the same time.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04087" title="Abstract">arXiv:2403.04087</a> [<a href="/pdf/2403.04087" title="Download PDF">pdf</a>, <a href="/format/2403.04087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cognitive Type Project -- Mapping Typography to Cognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+N+B">Nik Bear Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The Cognitive Type Project is focused on developing computational tools to
enable the design of typefaces with varying cognitive properties. This
initiative aims to empower typographers to craft fonts that enhance
click-through rates for online ads, improve reading levels in children's books,
enable dyslexics to create personalized type, or provide insights into customer
reactions to textual content in media. A significant challenge in research
related to mapping typography to cognition is the creation of thousands of
typefaces with minor variations, a process that is both labor-intensive and
requires the expertise of skilled typographers. Cognitive science research
highlights that the design and form of letters, along with the text's overall
layout, are crucial in determining the ease of reading and other cognitive
properties of type such as perceived beauty and memorability. These factors
affect not only the legibility and clarity of information presentation but also
the likability of a typeface.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04095" title="Abstract">arXiv:2403.04095</a> [<a href="/pdf/2403.04095" title="Download PDF">pdf</a>, <a href="/format/2403.04095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helmholtz preconditioning for the compressible Euler equations using  mixed finite elements with Lorenz staggering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+D">David Lee</a>, 
<a href="/search/math?searchtype=author&query=Martin%2C+A">Alberto Martin</a>, 
<a href="/search/math?searchtype=author&query=Ricardo%2C+K">Kieran Ricardo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Implicit solvers for atmospheric models are often accelerated via the
solution of a preconditioned system. For block preconditioners this typically
involves the factorisation of the (approximate) Jacobian for the coupled system
into a Helmholtz equation for some function of the pressure. Here we present a
preconditioner for the compressible Euler equations with a flux form
representation of the potential temperature on the Lorenz grid using mixed
finite elements. This formulation allows for spatial discretisations that
conserve both energy and potential temperature variance. By introducing the dry
thermodynamic entropy as an auxiliary variable for the solution of the
algebraic system, the resulting preconditioner is shown to have a similar block
structure to an existing preconditioner for the material form transport of
potential temperature on the Charney-Phillips grid, and to be more efficient
and stable than either this or a previous Helmholtz preconditioner for the flux
form transport of density weighted potential temperature on the Lorenz grid for
a one dimensional thermal bubble configuration. The new preconditioner is
further verified against standard two dimensional test cases in a vertical
slice geometry.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04096" title="Abstract">arXiv:2403.04096</a> [<a href="/pdf/2403.04096" title="Download PDF">pdf</a>, <a href="/ps/2403.04096" title="Download PostScript">ps</a>, <a href="/format/2403.04096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assisting International Migrants with Everyday Information Seeking: From  the Providers&#x27; Lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongle Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">International migrants face difficulties obtaining information for a quality
life and well-being in the host country. Prior research indicates that
international migrants often seek information from their co-national cohort or
contacts from the same country. The downside of this practice, however, is that
people can end up clustering in a small-world environment, hindering the
information seekers' social adaptation in the long run. In the current
research, we investigated the ongoing practices and future opportunities to
connect international migrants with others beyond their co-national contacts.
Our work zooms in on the providers' perspectives, which complements previous
studies that pay exclusive attention to the information seekers. Specifically,
we conducted in-depth interviews with 21 participants assisting the needs of
informational migrants in the United States. Some of these people are fellow
migrants from a different home country than the information seeker, whereas the
rest are domestic residents. Our data revealed how these participants dealt
with language barriers, overcame knowledge disparities, and calibrated their
effort commitment as information providers. Based on these findings, we discuss
directions for future information and communication technologies (ICT) design
that can facilitate international migrants' daily information seeking by
accounting for the provider's needs and concerns.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04099" title="Abstract">arXiv:2403.04099</a> [<a href="/pdf/2403.04099" title="Download PDF">pdf</a>, <a href="/format/2403.04099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Many-Objective Multi-Solution Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tian Li</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeff Bilmes</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Optimizing the performance of many objectives (instantiated by tasks or
clients) jointly with a few Pareto stationary solutions (models) is critical in
machine learning. However, previous multi-objective optimization methods often
focus on a few number of objectives and cannot scale to many objectives that
outnumber the solutions, leading to either subpar performance or ignored
objectives. We introduce Many-objective multi-solution Transport (MosT), a
framework that finds multiple diverse solutions in the Pareto front of many
objectives. Our insight is to seek multiple solutions, each performing as a
domain expert and focusing on a specific subset of objectives while
collectively covering all of them. MosT formulates the problem as a bi-level
optimization of weighted objectives for each solution, where the weights are
defined by an optimal transport between the objectives and solutions. Our
algorithm ensures convergence to Pareto stationary solutions for complementary
subsets of objectives. On a range of applications in federated learning,
multi-task learning, and mixture-of-prompt learning for LLMs, MosT distinctly
outperforms strong baselines, delivering high-quality, diverse solutions that
profile the entire Pareto frontier, thus ensuring balanced trade-offs across
many objectives.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04105" title="Abstract">arXiv:2403.04105</a> [<a href="/pdf/2403.04105" title="Download PDF">pdf</a>, <a href="/format/2403.04105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence Exploring the Patent Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lekang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Goetz%2C+S">Stephan Goetz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 14 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Advanced language-processing and machine-learning techniques promise massive
efficiency improvements in the previously widely manual field of patent and
technical knowledge management. This field presents large-scale and complex
data with very precise contents and language representation of those contents.
Particularly, patent texts can differ from mundane texts in various aspects,
which entails significant opportunities and challenges. This paper presents a
systematic overview of patent-related tasks and popular methodologies with a
special focus on evolving and promising techniques. Language processing and
particularly large language models as well as the recent boost of general
generative methods promise to become game changers in the patent field. The
patent literature and the fact-based argumentative procedures around patents
appear almost as an ideal use case. However, patents entail a number of
difficulties with which existing models struggle. The paper introduces
fundamental aspects of patents and patent-related data that affect technology
that wants to explore or manage them. It further reviews existing methods and
approaches and points out how important reliable and unbiased evaluation
metrics become. Although research has made substantial progress on certain
tasks, the performance across many others remains suboptimal, sometimes because
of either the special nature of patents and their language or inconsistencies
between legal terms and the everyday meaning of terms. Moreover, yet few
methods have demonstrated the ability to produce satisfactory text for specific
sections of patents. By pointing out key developments, opportunities, and gaps,
we aim to encourage further research and accelerate the advancement of this
field.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04106" title="Abstract">arXiv:2403.04106</a> [<a href="/pdf/2403.04106" title="Download PDF">pdf</a>, <a href="/ps/2403.04106" title="Download PostScript">ps</a>, <a href="/format/2403.04106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Biology in the Age of Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+E">Elsa Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=El-Shazly%2C+A">Adham El-Shazly</a>, 
<a href="/search/cs?searchtype=author&query=Seal%2C+S">Srijit Seal</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+C+K">Chaitanya K Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shantanu Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bender%2C+A">Andreas Bender</a>, 
<a href="/search/cs?searchtype=author&query=Sormanni%2C+P">Pietro Sormanni</a>, 
<a href="/search/cs?searchtype=author&query=Greenig%2C+M">Matthew Greenig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Modern life sciences research is increasingly relying on artificial
intelligence approaches to model biological systems, primarily centered around
the use of machine learning (ML) models. Although ML is undeniably useful for
identifying patterns in large, complex data sets, its widespread application in
biological sciences represents a significant deviation from traditional methods
of scientific inquiry. As such, the interplay between these models and
scientific understanding in biology is a topic with important implications for
the future of scientific research, yet it is a subject that has received little
attention. Here, we draw from an epistemological toolkit to contextualize
recent applications of ML in biological sciences under modern philosophical
theories of understanding, identifying general principles that can guide the
design and application of ML systems to model biological phenomena and advance
scientific knowledge. We propose that conceptions of scientific understanding
as information compression, qualitative intelligibility, and dependency
relation modelling provide a useful framework for interpreting ML-mediated
understanding of biological systems. Through a detailed analysis of two key
application areas of ML in modern biological research - protein structure
prediction and single cell RNA-sequencing - we explore how these features have
thus far enabled ML systems to advance scientific understanding of their target
phenomena, how they may guide the development of future ML models, and the key
obstacles that remain in preventing ML from achieving its potential as a tool
for biological discovery. Consideration of the epistemological features of ML
applications in biology will improve the prospects of these methods to solve
important problems and advance scientific understanding of living systems.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04109" title="Abstract">arXiv:2403.04109</a> [<a href="/pdf/2403.04109" title="Download PDF">pdf</a>, <a href="/format/2403.04109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Causal Trees to Estimate Personalized Task Difficulty in  Post-Stroke Individuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dennler%2C+N">Nathaniel Dennler</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Matari%C4%87%2C+M">Maja Matari&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 IROS Workshop on Assistive Robots for Citizens
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adaptive training programs are crucial for recovery post stroke. However,
developing programs that automatically adapt depends on quantifying how
difficult a task is for a specific individual at a particular stage of their
recovery. In this work, we propose a method that automatically generates
regions of different task difficulty levels based on an individual's
performance. We show that this technique explains the variance in user
performance for a reaching task better than previous approaches to estimating
task difficulty.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04111" title="Abstract">arXiv:2403.04111</a> [<a href="/pdf/2403.04111" title="Download PDF">pdf</a>, <a href="/ps/2403.04111" title="Download PostScript">ps</a>, <a href="/format/2403.04111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Level Attention Aggregation for Language-Agnostic Speaker  Replication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yejin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+G">Gary Geunbae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL Main 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper explores the task of language-agnostic speaker replication, a
novel endeavor that seeks to replicate a speaker's voice irrespective of the
language they are speaking. Towards this end, we introduce a multi-level
attention aggregation approach that systematically probes and amplifies various
speaker-specific attributes in a hierarchical manner. Through rigorous
evaluations across a wide range of scenarios including seen and unseen speakers
conversing in seen and unseen lingua, we establish that our proposed model is
able to achieve substantial speaker similarity, and is able to generalize to
out-of-domain (OOD) cases.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04112" title="Abstract">arXiv:2403.04112</a> [<a href="/pdf/2403.04112" title="Download PDF">pdf</a>, <a href="/format/2403.04112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Object Tracking with Camera-LiDAR Fusion for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pieroni%2C+R">Riccardo Pieroni</a>, 
<a href="/search/cs?searchtype=author&query=Specchia%2C+S">Simone Specchia</a>, 
<a href="/search/cs?searchtype=author&query=Corno%2C+M">Matteo Corno</a>, 
<a href="/search/cs?searchtype=author&query=Savaresi%2C+S+M">Sergio Matteo Savaresi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at IEEE European Control Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper presents a novel multi-modal Multi-Object Tracking (MOT) algorithm
for self-driving cars that combines camera and LiDAR data. Camera frames are
processed with a state-of-the-art 3D object detector, whereas classical
clustering techniques are used to process LiDAR observations. The proposed MOT
algorithm comprises a three-step association process, an Extended Kalman filter
for estimating the motion of each detected dynamic obstacle, and a track
management phase. The EKF motion model requires the current measured relative
position and orientation of the observed object and the longitudinal and
angular velocities of the ego vehicle as inputs. Unlike most state-of-the-art
multi-modal MOT approaches, the proposed algorithm does not rely on maps or
knowledge of the ego global pose. Moreover, it uses a 3D detector exclusively
for cameras and is agnostic to the type of LiDAR sensor used. The algorithm is
validated both in simulation and with real-world data, with satisfactory
results.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04113" title="Abstract">arXiv:2403.04113</a> [<a href="/pdf/2403.04113" title="Download PDF">pdf</a>, <a href="/format/2403.04113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZTRAN: Prototyping Zero Trust Security xApps for Open Radio Access  Network Deployments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdalla%2C+A+S">Aly S. Abdalla</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J">Joshua Moore</a>, 
<a href="/search/cs?searchtype=author&query=Adhikari%2C+N">Nisha Adhikari</a>, 
<a href="/search/cs?searchtype=author&query=Marojevic%2C+V">Vuk Marojevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in the IEEE Wireless Communications Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET); Systems and Control (eess.SY)

</div>
<p class="mathjax">The open radio access network (O-RAN) offers new degrees of freedom for
building and operating advanced cellular networks. Emphasizing on RAN
disaggregation, open interfaces, multi-vendor support, and RAN intelligent
controllers (RICs), O-RAN facilitates adaptation to new applications and
technology trends. Yet, this architecture introduces new security challenges.
This paper proposes leveraging zero trust principles for O-RAN security. We
introduce zero trust RAN (ZTRAN), which embeds service authentication,
intrusion detection, and secure slicing subsystems that are encapsulated as
xApps. We implement ZTRAN on the open artificial intelligence cellular (OAIC)
research platform and demonstrate its feasibility and effectiveness in terms of
legitimate user throughput and latency figures. Our experimental analysis
illustrates how ZTRAN's intrusion detection and secure slicing microservices
operate effectively and in concert as part of O-RAN Alliance's containerized
near-real time RIC. Research directions include exploring machine learning and
additional threat intelligence feeds for improving the performance and
extending the scope of ZTRAN.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04114" title="Abstract">arXiv:2403.04114</a> [<a href="/pdf/2403.04114" title="Download PDF">pdf</a>, <a href="/format/2403.04114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Visual Sim-to-Real Gap with Object-Composable NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+N">Nikhil Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Sieb%2C+M">Maximilian Sieb</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning methods for perception are the cornerstone of many robotic
systems. Despite their potential for impressive performance, obtaining
real-world training data is expensive, and can be impractically difficult for
some tasks. Sim-to-real transfer with domain randomization offers a potential
workaround, but often requires extensive manual tuning and results in models
that are brittle to distribution shift between sim and real. In this work, we
introduce Composable Object Volume NeRF (COV-NeRF), an object-composable NeRF
model that is the centerpiece of a real-to-sim pipeline for synthesizing
training data targeted to scenes and objects from the real world. COV-NeRF
extracts objects from real images and composes them into new scenes, generating
photorealistic renderings and many types of 2D and 3D supervision, including
depth maps, segmentation masks, and meshes. We show that COV-NeRF matches the
rendering quality of modern NeRF methods, and can be used to rapidly close the
sim-to-real gap across a variety of perceptual modalities.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04115" title="Abstract">arXiv:2403.04115</a> [<a href="/pdf/2403.04115" title="Download PDF">pdf</a>, <a href="/format/2403.04115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNAct: Diffusion Guided Multi-Task 3D Policy Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Ge Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yueh-Hua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper presents DNAct, a language-conditioned multi-task policy framework
that integrates neural rendering pre-training and diffusion training to enforce
multi-modality learning in action sequence spaces. To learn a generalizable
multi-task policy with few demonstrations, the pre-training phase of DNAct
leverages neural rendering to distill 2D semantic features from foundation
models such as Stable Diffusion to a 3D space, which provides a comprehensive
semantic understanding regarding the scene. Consequently, it allows various
applications to challenging robotic tasks requiring rich 3D semantics and
accurate geometry. Furthermore, we introduce a novel approach utilizing
diffusion training to learn a vision and language feature that encapsulates the
inherent multi-modality in the multi-task demonstrations. By reconstructing the
action sequences from different tasks via the diffusion process, the model is
capable of distinguishing different modalities and thus improving the
robustness and the generalizability of the learned representation. DNAct
significantly surpasses SOTA NeRF-based multi-task manipulation approaches with
over 30% improvement in success rate. Project website: dnact.github.io.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04118" title="Abstract">arXiv:2403.04118</a> [<a href="/pdf/2403.04118" title="Download PDF">pdf</a>, <a href="/format/2403.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Globally Stable Neural Imitation Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abyaneh%2C+A">Amin Abyaneh</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n%2C+M+S">Mariana Sosa Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsiu-Chin Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning presents an effective approach to alleviate the
resource-intensive and time-consuming nature of policy learning from scratch in
the solution space. Even though the resulting policy can mimic expert
demonstrations reliably, it often lacks predictability in unexplored regions of
the state-space, giving rise to significant safety concerns in the face of
perturbations. To address these challenges, we introduce the Stable Neural
Dynamical System (SNDS), an imitation learning regime which produces a policy
with formal stability guarantees. We deploy a neural policy architecture that
facilitates the representation of stability based on Lyapunov theorem, and
jointly train the policy and its corresponding Lyapunov candidate to ensure
global stability. We validate our approach by conducting extensive experiments
in simulation and successfully deploying the trained policies on a real-world
manipulator arm. The experimental results demonstrate that our method overcomes
the instability, accuracy, and computational intensity problems associated with
previous imitation learning methods, making our method a promising solution for
stable policy learning in complex planning scenarios.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04120" title="Abstract">arXiv:2403.04120</a> [<a href="/pdf/2403.04120" title="Download PDF">pdf</a>, <a href="/format/2403.04120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A data-centric approach to class-specific bias in image data  augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelakis%2C+A">Athanasios Angelakis</a>, 
<a href="/search/cs?searchtype=author&query=Rass%2C+A">Andrey Rass</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data augmentation (DA) enhances model generalization in computer vision but
may introduce biases, impacting class accuracy unevenly. Our study extends this
inquiry, examining DA's class-specific bias across various datasets, including
those distinct from ImageNet, through random cropping. We evaluated this
phenomenon with ResNet50, EfficientNetV2S, and SWIN ViT, discovering that while
residual models showed similar bias effects, Vision Transformers exhibited
greater robustness or altered dynamics. This suggests a nuanced approach to
model selection, emphasizing bias mitigation. We also refined a "data
augmentation robustness scouting" method to manage DA-induced biases more
efficiently, reducing computational demands significantly (training 112 models
instead of 1860; a reduction of factor 16.2) while still capturing essential
bias trends.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04121" title="Abstract">arXiv:2403.04121</a> [<a href="/pdf/2403.04121" title="Download PDF">pdf</a>, <a href="/format/2403.04121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Reason and Plan?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kambhampati%2C+S">Subbarao Kambhampati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2402.01817">arXiv:2402.01817</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Annals of The New York Academy of Sciences; March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">While humans sometimes do show the capability of correcting their own
erroneous guesses with self-critiquing, there seems to be no basis for that
assumption in the case of LLMs.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04123" title="Abstract">arXiv:2403.04123</a> [<a href="/pdf/2403.04123" title="Download PDF">pdf</a>, <a href="/format/2403.04123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring LLM-based Agents for Root Cause Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Devjeet Roy</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuchao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhave%2C+R">Rashi Bhave</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+C">Chetan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Las-Casas%2C+P">Pedro Las-Casas</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+R">Rodrigo Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The growing complexity of cloud based software systems has resulted in
incident management becoming an integral part of the software development
lifecycle. Root cause analysis (RCA), a critical part of the incident
management process, is a demanding task for on-call engineers, requiring deep
domain knowledge and extensive experience with a team's specific services.
Automation of RCA can result in significant savings of time, and ease the
burden of incident management on on-call engineers. Recently, researchers have
utilized Large Language Models (LLMs) to perform RCA, and have demonstrated
promising results. However, these approaches are not able to dynamically
collect additional diagnostic information such as incident related logs,
metrics or databases, severely restricting their ability to diagnose root
causes. In this work, we explore the use of LLM based agents for RCA to address
this limitation. We present a thorough empirical evaluation of a ReAct agent
equipped with retrieval tools, on an out-of-distribution dataset of production
incidents collected at Microsoft. Results show that ReAct performs
competitively with strong retrieval and reasoning baselines, but with highly
increased factual accuracy. We then extend this evaluation by incorporating
discussions associated with incident reports as additional inputs for the
models, which surprisingly does not yield significant performance improvements.
Lastly, we conduct a case study with a team at Microsoft to equip the ReAct
agent with tools that give it access to external diagnostic services that are
used by the team for manual RCA. Our results show how agents can overcome the
limitations of prior work, and practical considerations for implementing such a
system in practice.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04124" title="Abstract">arXiv:2403.04124</a> [<a href="/pdf/2403.04124" title="Download PDF">pdf</a>, <a href="/format/2403.04124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-preserving Fine-tuning of Large Language Models through Flatness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiejin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Longchao Da</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huixue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pingzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024 SeT LLM Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The privacy concerns associated with the use of Large Language Models (LLMs)
have grown recently with the development of LLMs such as ChatGPT. Differential
Privacy (DP) techniques are explored in existing work to mitigate their privacy
risks at the cost of generalization degradation. Our paper reveals that the
flatness of DP-trained models' loss landscape plays an essential role in the
trade-off between their privacy and generalization. We further propose a
holistic framework to enforce appropriate weight flatness, which substantially
improves model generalization with competitive privacy preservation. It
innovates from three coarse-to-grained levels, including perturbation-aware
min-max optimization on model weights within a layer, flatness-guided sparse
prefix-tuning on weights across layers, and weight knowledge distillation
between DP \&amp; non-DP weights copies. Comprehensive experiments of both
black-box and white-box scenarios are conducted to demonstrate the
effectiveness of our proposal in enhancing generalization and maintaining DP
characteristics. For instance, on text classification dataset QNLI, DP-Flat
achieves similar performance with non-private full fine-tuning but with DP
guarantee under privacy budget $\epsilon=3$, and even better performance given
higher privacy budgets. Codes are provided in the supplement.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04125" title="Abstract">arXiv:2403.04125</a> [<a href="/pdf/2403.04125" title="Download PDF">pdf</a>, <a href="/format/2403.04125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Robust Transformer Decoders for Interpretable Image  Classification with Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannix%2C+E">Evelyn Mannix</a>, 
<a href="/search/cs?searchtype=author&query=Bondell%2C+H">Howard Bondell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Interpretable computer vision models can produce transparent predictions,
where the features of an image are compared with prototypes from a training
dataset and the similarity between them forms a basis for classification.
Nevertheless these methods are computationally expensive to train, introduce
additional complexity and may require domain knowledge to adapt
hyper-parameters to a new dataset. Inspired by developments in object
detection, segmentation and large-scale self-supervised foundation vision
models, we introduce Component Features (ComFe), a novel explainable-by-design
image classification approach using a transformer-decoder head and hierarchical
mixture-modelling. With only global image labels and no segmentation or part
annotations, ComFe can identify consistent image components, such as the head,
body, wings and tail of a bird, and the image background, and determine which
of these features are informative in making a prediction. We demonstrate that
ComFe obtains higher accuracy compared to previous interpretable models across
a range of fine-grained vision benchmarks, without the need to individually
tune hyper-parameters for each dataset. We also show that ComFe outperforms a
non-interpretable linear head across a range of datasets, including ImageNet,
and improves performance on generalisation and robustness benchmarks.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04130" title="Abstract">arXiv:2403.04130</a> [<a href="/pdf/2403.04130" title="Download PDF">pdf</a>, <a href="/format/2403.04130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable AI Framework for Artificial Intelligence of Medical  Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amin%2C+A">Al Amin</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+K">Kamrul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Zein-Sabatto%2C+S">Saleh Zein-Sabatto</a>, 
<a href="/search/cs?searchtype=author&query=Chimba%2C+D">Deo Chimba</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Imtiaz Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+T">Tariqul Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The healthcare industry has been revolutionized by the convergence of
Artificial Intelligence of Medical Things (AIoMT), allowing advanced
data-driven solutions to improve healthcare systems. With the increasing
complexity of Artificial Intelligence (AI) models, the need for Explainable
Artificial Intelligence (XAI) techniques become paramount, particularly in the
medical domain, where transparent and interpretable decision-making becomes
crucial. Therefore, in this work, we leverage a custom XAI framework,
incorporating techniques such as Local Interpretable Model-Agnostic
Explanations (LIME), SHapley Additive exPlanations (SHAP), and
Gradient-weighted Class Activation Mapping (Grad-Cam), explicitly designed for
the domain of AIoMT. The proposed framework enhances the effectiveness of
strategic healthcare methods and aims to instill trust and promote
understanding in AI-driven medical applications. Moreover, we utilize a
majority voting technique that aggregates predictions from multiple
convolutional neural networks (CNNs) and leverages their collective
intelligence to make robust and accurate decisions in the healthcare system.
Building upon this decision-making process, we apply the XAI framework to brain
tumor detection as a use case demonstrating accurate and transparent diagnosis.
Evaluation results underscore the exceptional performance of the XAI framework,
achieving high precision, recall, and F1 scores with a training accuracy of 99%
and a validation accuracy of 98%. Combining advanced XAI techniques with
ensemble-based deep-learning (DL) methodologies allows for precise and reliable
brain tumor diagnoses as an application of AIoMT.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04132" title="Abstract">arXiv:2403.04132</a> [<a href="/pdf/2403.04132" title="Download PDF">pdf</a>, <a href="/format/2403.04132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiang%2C+W">Wei-Lin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+A+N">Anastasios Nikolas Angelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianle Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M">Michael Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have unlocked new capabilities and applications;
however, evaluating the alignment with human preferences still poses
significant challenges. To address this issue, we introduce Chatbot Arena, an
open platform for evaluating LLMs based on human preferences. Our methodology
employs a pairwise comparison approach and leverages input from a diverse user
base through crowdsourcing. The platform has been operational for several
months, amassing over 240K votes. This paper describes the platform, analyzes
the data we have collected so far, and explains the tried-and-true statistical
methods we are using for efficient and accurate evaluation and ranking of
models. We confirm that the crowdsourced questions are sufficiently diverse and
discriminating and that the crowdsourced human votes are in good agreement with
those of expert raters. These analyses collectively establish a robust
foundation for the credibility of Chatbot Arena. Because of its unique value
and openness, Chatbot Arena has emerged as one of the most referenced LLM
leaderboards, widely cited by leading LLM developers and companies. Our demo is
publicly available at \url{https://chat.lmsys.org}.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04133" title="Abstract">arXiv:2403.04133</a> [<a href="/pdf/2403.04133" title="Download PDF">pdf</a>, <a href="/format/2403.04133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards learning-based planning:The nuPlan benchmark for real-world  autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karnchanachari%2C+N">Napat Karnchanachari</a>, 
<a href="/search/cs?searchtype=author&query=Geromichalos%2C+D">Dimitris Geromichalos</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K+S">Kok Seang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nanxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Eriksen%2C+C">Christopher Eriksen</a>, 
<a href="/search/cs?searchtype=author&query=Yaghoubi%2C+S">Shakiba Yaghoubi</a>, 
<a href="/search/cs?searchtype=author&query=Mehdipour%2C+N">Noushin Mehdipour</a>, 
<a href="/search/cs?searchtype=author&query=Bernasconi%2C+G">Gianmarco Bernasconi</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+W+K">Whye Kit Fong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiluan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Caesar%2C+H">Holger Caesar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024 camera ready incl. supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Machine Learning (ML) has replaced traditional handcrafted methods for
perception and prediction in autonomous vehicles. Yet for the equally important
planning task, the adoption of ML-based techniques is slow. We present nuPlan,
the world's first real-world autonomous driving dataset, and benchmark. The
benchmark is designed to test the ability of ML-based planners to handle
diverse driving situations and to make safe and efficient decisions. To that
end, we introduce a new large-scale dataset that consists of 1282 hours of
diverse driving scenarios from 4 cities (Las Vegas, Boston, Pittsburgh, and
Singapore) and includes high-quality auto-labeled object tracks and traffic
light data. We exhaustively mine and taxonomize common and rare driving
scenarios which are used during evaluation to get fine-grained insights into
the performance and characteristics of a planner. Beyond the dataset, we
provide a simulation and evaluation framework that enables a planner's actions
to be simulated in closed-loop to account for interactions with other traffic
participants. We present a detailed analysis of numerous baselines and
investigate gaps between ML-based and traditional methods. Find the nuPlan
dataset and code at nuplan.org.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04134" title="Abstract">arXiv:2403.04134</a> [<a href="/pdf/2403.04134" title="Download PDF">pdf</a>, <a href="/format/2403.04134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptable, Safe, and Portable Robot-Assisted Feeding System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gordon%2C+E+K">Ethan Kroll Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Jenamani%2C+R+K">Rajat Kumar Jenamani</a>, 
<a href="/search/cs?searchtype=author&query=Nanavati%2C+A">Amal Nanavati</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bolotski%2C+H">Haya Bolotski</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+R">Raida Karim</a>, 
<a href="/search/cs?searchtype=author&query=Stabile%2C+D">Daniel Stabile</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+A">Atharva Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B+H">Bernie Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xilai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Schrenk%2C+T">Tyler Schrenk</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Jonathan Ko</a>, 
<a href="/search/cs?searchtype=author&query=Faulkner%2C+T+K">Taylor Kessler Faulkner</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+T">Tapomayukh Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+S">Siddhartha Srinivasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> HRI 2024 Demo; Corrected inaccurate author ordering in ACM DL which occurred due to formatting issues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We demonstrate a robot-assisted feeding system that enables people with
mobility impairments to feed themselves. Our system design embodies Safety,
Portability, and User Control, with comprehensive full-stack safety checks, the
ability to be mounted on and powered by any powered wheelchair, and a custom
web-app allowing care-recipients to leverage their own assistive devices for
robot control. For bite acquisition, we leverage multi-modal online learning to
tractably adapt to unseen food types. For bite transfer, we leverage real-time
mouth perception and interaction-aware control. Co-designed with community
researchers, our system has been validated through multiple end-user studies.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04135" title="Abstract">arXiv:2403.04135</a> [<a href="/pdf/2403.04135" title="Download PDF">pdf</a>, <a href="/format/2403.04135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning of Harmonic Analysis Based on Neural HSMM with  Code Quality Templates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uehara%2C+Y">Yui Uehara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, the original edition of this paper will be published in the ICNMC2024 Proceedings and this arXiv publication is a copy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper presents a method of unsupervised learning of harmonic analysis
based on a hidden semi-Markov model (HSMM). We introduce the chord quality
templates, which specify the probability of pitch class emissions given a root
note and a chord quality. Other probability distributions that comprise the
HSMM are automatically learned via unsupervised learning, which has been a
challenge in existing research. The results of the harmonic analysis of the
proposed model were evaluated using existing labeled data. While our proposed
method has yet to perform as well as existing models that used supervised
learning and complex rule design, it has the advantage of not requiring
expensive labeled data or rule elaboration. Furthermore, we also show how to
recognize the tonic without prior knowledge, based on the transition
probabilities of the Markov model.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04140" title="Abstract">arXiv:2403.04140</a> [<a href="/pdf/2403.04140" title="Download PDF">pdf</a>, <a href="/format/2403.04140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Augmented Graph2Graph Memory Interaction for Few Shot  Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+B">Biqing Qi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Ligang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Few-Shot Class-Incremental Learning (FSCIL) has gained considerable attention
in recent years for its pivotal role in addressing continuously arriving
classes. However, it encounters additional challenges. The scarcity of samples
in new sessions intensifies overfitting, causing incompatibility between the
output features of new and old classes, thereby escalating catastrophic
forgetting. A prevalent strategy involves mitigating catastrophic forgetting
through the Explicit Memory (EM), which comprise of class prototypes. However,
current EM-based methods retrieves memory globally by performing
Vector-to-Vector (V2V) interaction between features corresponding to the input
and prototypes stored in EM, neglecting the geometric structure of local
features. This hinders the accurate modeling of their positional relationships.
To incorporate information of local geometric structure, we extend the V2V
interaction to Graph-to-Graph (G2G) interaction. For enhancing local structures
for better G2G alignment and the prevention of local feature collapse, we
propose the Local Graph Preservation (LGP) mechanism. Additionally, to address
sample scarcity in classes from new sessions, the Contrast-Augmented G2G
(CAG2G) is introduced to promote the aggregation of same class features thus
helps few-shot learning. Extensive comparisons on CIFAR100, CUB200, and the
challenging ImageNet-R dataset demonstrate the superiority of our method over
existing methods.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04143" title="Abstract">arXiv:2403.04143</a> [<a href="/pdf/2403.04143" title="Download PDF">pdf</a>, <a href="/format/2403.04143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Bayesian Learning for Fail-Operational Control in Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zengqi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+Y">Michael Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, accepted for publication in the 22nd European Control Conference (ECC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Abrupt maneuvers by surrounding vehicles (SVs) can typically lead to safety
concerns and affect the task efficiency of the ego vehicle (EV), especially
with model uncertainties stemming from environmental disturbances. This paper
presents a real-time fail-operational controller that ensures the asymptotic
convergence of an uncertain EV to a safe state, while preserving task
efficiency in dynamic environments. An incremental Bayesian learning approach
is developed to facilitate online learning and inference of changing
environmental disturbances. Leveraging disturbance quantification and
constraint transformation, we develop a stochastic fail-operational barrier
based on the control barrier function (CBF). With this development, the
uncertain EV is able to converge asymptotically from an unsafe state to a
defined safe state with probabilistic stability. Subsequently, the stochastic
fail-operational barrier is integrated into an efficient fail-operational
controller based on quadratic programming (QP). This controller is tailored for
the EV operating under control constraints in the presence of environmental
disturbances, with both safety and efficiency objectives taken into
consideration. We validate the proposed framework in connected cruise control
(CCC) tasks, where SVs perform aggressive driving maneuvers. The simulation
results demonstrate that our method empowers the EV to swiftly return to a safe
state while upholding task efficiency in real time, even under time-varying
environmental disturbances.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04144" title="Abstract">arXiv:2403.04144</a> [<a href="/pdf/2403.04144" title="Download PDF">pdf</a>, <a href="/format/2403.04144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedClust: Optimizing Federated Learning on Non-IID Data through  Weight-Driven Client Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Sirajul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Javaherian%2C+S">Simin Javaherian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tzeng%2C+N">Nian-Feng Tzeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) is an emerging distributed machine learning paradigm
enabling collaborative model training on decentralized devices without exposing
their local data. A key challenge in FL is the uneven data distribution across
client devices, violating the well-known assumption of
independent-and-identically-distributed (IID) training samples in conventional
machine learning. Clustered federated learning (CFL) addresses this challenge
by grouping clients based on the similarity of their data distributions.
However, existing CFL approaches require a large number of communication rounds
for stable cluster formation and rely on a predefined number of clusters, thus
limiting their flexibility and adaptability. This paper proposes FedClust, a
novel CFL approach leveraging correlations between local model weights and
client data distributions. FedClust groups clients into clusters in a one-shot
manner using strategically selected partial model weights and dynamically
accommodates newcomers in real-time. Experimental results demonstrate FedClust
outperforms baseline approaches in terms of accuracy and communication costs.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04145" title="Abstract">arXiv:2403.04145</a> [<a href="/pdf/2403.04145" title="Download PDF">pdf</a>, <a href="/format/2403.04145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Crosstalk-Aware Timing Prediction Method in Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jin%2C+L">Leilei Jin</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jiajie Xu</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+W">Wenjie Fu</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+H">Hao Yan</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Longxing Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With shrinking interconnect spacing in advanced technology nodes, existing
timing predictions become less precise due to the challenging quantification of
crosstalk-induced delay. During the routing, the crosstalk effect is typically
modeled by predicting coupling capacitance with congestion information.
However, the timing estimation tends to be overly pessimistic, as the
crosstalk-induced delay depends not only on the coupling capacitance but also
on the signal arrival time. This work presents a crosstalk-aware timing
estimation method using a two-step machine learning approach. Interconnects
that are physically adjacent and overlap in signal timing windows are filtered
first. Crosstalk delay is predicted by integrating physical topology and timing
features without relying on post-routing results and the parasitic extraction.
Experimental results show a match rate of over 99% for identifying crosstalk
nets compared to the commercial tool on the OpenCores benchmarks, with
prediction results being more accurate than those of other state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04146" title="Abstract">arXiv:2403.04146</a> [<a href="/pdf/2403.04146" title="Download PDF">pdf</a>, <a href="/ps/2403.04146" title="Download PostScript">ps</a>, <a href="/format/2403.04146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FL-GUARD: A Holistic Framework for Run-Time Detection and Recovery of  Negative Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Lidan Shou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sai Wu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Data Science and Engineering (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) is a promising approach for learning a model from
data distributed on massive clients without exposing data privacy. It works
effectively in the ideal federation where clients share homogeneous data
distribution and learning behavior. However, FL may fail to function
appropriately when the federation is not ideal, amid an unhealthy state called
Negative Federated Learning (NFL), in which most clients gain no benefit from
participating in FL. Many studies have tried to address NFL. However, their
solutions either (1) predetermine to prevent NFL in the entire learning
life-cycle or (2) tackle NFL in the aftermath of numerous learning rounds.
Thus, they either (1) indiscriminately incur extra costs even if FL can perform
well without such costs or (2) waste numerous learning rounds. Additionally,
none of the previous work takes into account the clients who may be
unwilling/unable to follow the proposed NFL solutions when using those
solutions to upgrade an FL system in use. This paper introduces FL-GUARD, a
holistic framework that can be employed on any FL system for tackling NFL in a
run-time paradigm. That is, to dynamically detect NFL at the early stage (tens
of rounds) of learning and then to activate recovery measures when necessary.
Specifically, we devise a cost-effective NFL detection mechanism, which relies
on an estimation of performance gain on clients. Only when NFL is detected, we
activate the NFL recovery process, in which each client learns in parallel an
adapted model when training the global model. Extensive experiment results
confirm the effectiveness of FL-GUARD in detecting NFL and recovering from NFL
to a healthy learning state. We also show that FL-GUARD is compatible with
previous NFL solutions and robust against clients unwilling/unable to take any
recovery measures.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04149" title="Abstract">arXiv:2403.04149</a> [<a href="/pdf/2403.04149" title="Download PDF">pdf</a>, <a href="/format/2403.04149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAP: MAsk-Pruning for Source-Free Model Intellectual Property Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Boyang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Sanqing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+T">Tianpei Zou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lianghua He</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>, 
<a href="/search/cs?searchtype=author&query=jiang%2C+c">changjun jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning has achieved remarkable progress in various applications,
heightening the importance of safeguarding the intellectual property (IP) of
well-trained models. It entails not only authorizing usage but also ensuring
the deployment of models in authorized data domains, i.e., making models
exclusive to certain target domains. Previous methods necessitate concurrent
access to source training data and target unauthorized data when performing IP
protection, making them risky and inefficient for decentralized private data.
In this paper, we target a practical setting where only a well-trained source
model is available and investigate how we can realize IP protection. To achieve
this, we propose a novel MAsk Pruning (MAP) framework. MAP stems from an
intuitive hypothesis, i.e., there are target-related parameters in a
well-trained model, locating and pruning them is the key to IP protection.
Technically, MAP freezes the source model and learns a target-specific binary
mask to prevent unauthorized data usage while minimizing performance
degradation on authorized data. Moreover, we introduce a new metric aimed at
achieving a better balance between source and target performance degradation.
To verify the effectiveness and versatility, we have evaluated MAP in a variety
of scenarios, including vanilla source-available, practical source-free, and
challenging data-free. Extensive experiments indicate that MAP yields new
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04151" title="Abstract">arXiv:2403.04151</a> [<a href="/pdf/2403.04151" title="Download PDF">pdf</a>, <a href="/format/2403.04151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-path Frequency Discriminators for Few-shot Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuhu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuhang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+G">Guanzhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunkang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot anomaly detection (FSAD) is essential in industrial manufacturing.
However, existing FSAD methods struggle to effectively leverage a limited
number of normal samples, and they may fail to detect and locate inconspicuous
anomalies in the spatial domain. We further discover that these subtle
anomalies would be more noticeable in the frequency domain. In this paper, we
propose a Dual-Path Frequency Discriminators (DFD) network from a frequency
perspective to tackle these issues. Specifically, we generate anomalies at both
image-level and feature-level. Differential frequency components are extracted
by the multi-frequency information construction module and supplied into the
fine-grained feature construction module to provide adapted features. We
consider anomaly detection as a discriminative classification problem,
wherefore the dual-path feature discrimination module is employed to detect and
locate the image-level and feature-level anomalies in the feature space. The
discriminators aim to learn a joint representation of anomalous features and
normal features in the latent space. Extensive experiments conducted on MVTec
AD and VisA benchmarks demonstrate that our DFD surpasses current
state-of-the-art methods. Source code will be available.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04153" title="Abstract">arXiv:2403.04153</a> [<a href="/pdf/2403.04153" title="Download PDF">pdf</a>, <a href="/format/2403.04153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Social Robots that Engage Older Adults in Exercise: A Case  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antony%2C+V+N">Victor Nikhil Antony</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present and evaluate a prototype social robot to encourage daily exercise
among older adults in a home setting. Our prototype system, designed to lead
users through exercise sessions with motivational feedback, was assessed
through a case study with a 78-year-old participant for one week. Our case
study highlighted preferences for greater user control over exercise choices
and questioned the necessity of precise motion tracking. Feedback also
indicated a desire for more varied exercises and suggested improvements in user
engagement techniques. The insights suggest that further research is needed to
enhance system adaptability and effectiveness to better promote daily exercise.
Future efforts will aim to refine the prototype based on participant feedback
and extend the evaluation to broader in-home deployments.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04154" title="Abstract">arXiv:2403.04154</a> [<a href="/pdf/2403.04154" title="Download PDF">pdf</a>, <a href="/format/2403.04154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Policy Gradients for Stochastic Differential Equations via  Consistency with Perturbation Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiangxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yichi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Considering generating samples with high rewards, we focus on optimizing deep
neural networks parameterized stochastic differential equations (SDEs), the
advanced generative models with high expressiveness, with policy gradient, the
leading algorithm in reinforcement learning. Nevertheless, when applying policy
gradients to SDEs, since the policy gradient is estimated on a finite set of
trajectories, it can be ill-defined, and the policy behavior in data-scarce
regions may be uncontrolled. This challenge compromises the stability of policy
gradients and negatively impacts sample complexity. To address these issues, we
propose constraining the SDE to be consistent with its associated perturbation
process. Since the perturbation process covers the entire space and is easy to
sample, we can mitigate the aforementioned problems. Our framework offers a
general approach allowing for a versatile selection of policy gradient methods
to effectively and efficiently train SDEs. We evaluate our algorithm on the
task of structure-based drug design and optimize the binding affinity of
generated ligand molecules. Our method achieves the best Vina score -9.07 on
the CrossDocked2020 dataset.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04158" title="Abstract">arXiv:2403.04158</a> [<a href="/pdf/2403.04158" title="Download PDF">pdf</a>, <a href="/format/2403.04158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DA-Net: A Disentangled and Adaptive Network for Multi-Source  Cross-Lingual Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+L">Ling Ge</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guanghui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jihong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-Source cross-lingual transfer learning deals with the transfer of task
knowledge from multiple labelled source languages to an unlabeled target
language under the language shift. Existing methods typically focus on
weighting the predictions produced by language-specific classifiers of
different sources that follow a shared encoder. However, all source languages
share the same encoder, which is updated by all these languages. The extracted
representations inevitably contain different source languages' information,
which may disturb the learning of the language-specific classifiers.
Additionally, due to the language gap, language-specific classifiers trained
with source labels are unable to make accurate predictions for the target
language. Both facts impair the model's performance. To address these
challenges, we propose a Disentangled and Adaptive Network (DA-Net). Firstly,
we devise a feedback-guided collaborative disentanglement method that seeks to
purify input representations of classifiers, thereby mitigating mutual
interference from multiple sources. Secondly, we propose a class-aware parallel
adaptation method that aligns class-level distributions for each source-target
language pair, thereby alleviating the language pairs' language gap.
Experimental results on three different tasks involving 38 languages validate
the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04160" title="Abstract">arXiv:2403.04160</a> [<a href="/pdf/2403.04160" title="Download PDF">pdf</a>, <a href="/format/2403.04160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Retrieval in Theme-specific Applications using a Corpus  Topical Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">SeongKu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shivam Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Bowen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hwanjo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TheWebConf'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Document retrieval has greatly benefited from the advancements of large-scale
pre-trained language models (PLMs). However, their effectiveness is often
limited in theme-specific applications for specialized areas or industries, due
to unique terminologies, incomplete contexts of user queries, and specialized
search intents. To capture the theme-specific information and improve
retrieval, we propose to use a corpus topical taxonomy, which outlines the
latent topic structure of the corpus while reflecting user-interested aspects.
We introduce ToTER (Topical Taxonomy Enhanced Retrieval) framework, which
identifies the central topics of queries and documents with the guidance of the
taxonomy, and exploits their topical relatedness to supplement missing
contexts. As a plug-and-play framework, ToTER can be flexibly employed to
enhance various PLM-based retrievers. Through extensive quantitative, ablative,
and exploratory experiments on two real-world datasets, we ascertain the
benefits of using topical taxonomy for retrieval in theme-specific applications
and demonstrate the effectiveness of ToTER.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04161" title="Abstract">arXiv:2403.04161</a> [<a href="/pdf/2403.04161" title="Download PDF">pdf</a>, <a href="/format/2403.04161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SWAP-NAS: Sample-Wise Activation Patterns For Ultra-Fast NAS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yameng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+A">Andy Song</a>, 
<a href="/search/cs?searchtype=author&query=Fayek%2C+H+M">Haytham M. Fayek</a>, 
<a href="/search/cs?searchtype=author&query=Ciesielski%2C+V">Vic Ciesielski</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR2024 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid
resource-intensive neural network training, especially in Neural Architecture
Search (NAS). Recent studies show that existing training-free metrics have
several limitations, such as limited correlation and poor generalisation across
different search spaces and tasks. Hence, we propose Sample-Wise Activation
Patterns and its derivative, SWAP-Score, a novel high-performance training-free
metric. It measures the expressivity of networks over a batch of input samples.
The SWAP-Score is strongly correlated with ground-truth performance across
various search spaces and tasks, outperforming 15 existing training-free
metrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be
further enhanced by regularisation, which leads to even higher correlations in
cell-based search space and enables model size control during the search. For
example, Spearman's rank correlation coefficient between regularised SWAP-Score
and CIFAR-100 validation accuracies on NAS-Bench-201 networks is 0.90,
significantly higher than 0.80 from the second-best metric, NWOT. When
integrated with an evolutionary algorithm for NAS, our SWAP-NAS achieves
competitive performance on CIFAR-10 and ImageNet in approximately 6 minutes and
9 minutes of GPU time respectively.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04162" title="Abstract">arXiv:2403.04162</a> [<a href="/pdf/2403.04162" title="Download PDF">pdf</a>, <a href="/format/2403.04162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy Spiking Actor Network for Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Ding Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Peixi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">As a general method for exploration in deep reinforcement learning (RL),
NoisyNet can produce problem-specific exploration strategies. Spiking neural
networks (SNNs), due to their binary firing mechanism, have strong robustness
to noise, making it difficult to realize efficient exploration with local
disturbances. To solve this exploration problem, we propose a noisy spiking
actor network (NoisySAN) that introduces time-correlated noise during charging
and transmission. Moreover, a noise reduction method is proposed to find a
stable policy for the agent. Extensive experimental results demonstrate that
our method outperforms the state-of-the-art performance on a wide range of
continuous control tasks from OpenAI gym.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04164" title="Abstract">arXiv:2403.04164</a> [<a href="/pdf/2403.04164" title="Download PDF">pdf</a>, <a href="/ps/2403.04164" title="Download PostScript">ps</a>, <a href="/format/2403.04164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProMISe: Promptable Medical Image Segmentation using SAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Sifan Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Yiyi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jionglong Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the proposal of the Segment Anything Model (SAM), fine-tuning SAM for
medical image segmentation (MIS) has become popular. However, due to the large
size of the SAM model and the significant domain gap between natural and
medical images, fine-tuning-based strategies are costly with potential risk of
instability, feature damage and catastrophic forgetting. Furthermore, some
methods of transferring SAM to a domain-specific MIS through fine-tuning
strategies disable the model's prompting capability, severely limiting its
utilization scenarios. In this paper, we propose an Auto-Prompting Module
(APM), which provides SAM-based foundation model with Euclidean adaptive
prompts in the target domain. Our experiments demonstrate that such adaptive
prompts significantly improve SAM's non-fine-tuned performance in MIS. In
addition, we propose a novel non-invasive method called Incremental Pattern
Shifting (IPS) to adapt SAM to specific medical domains. Experimental results
show that the IPS enables SAM to achieve state-of-the-art or competitive
performance in MIS without the need for fine-tuning. By coupling these two
methods, we propose ProMISe, an end-to-end non-fine-tuned framework for
Promptable Medical Image Segmentation. Our experiments demonstrate that both
using our methods individually or in combination achieves satisfactory
performance in low-cost pattern shifting, with all of SAM's parameters frozen.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04165" title="Abstract">arXiv:2403.04165</a> [<a href="/pdf/2403.04165" title="Download PDF">pdf</a>, <a href="/format/2403.04165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-resolution on network telemetry time series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+F">Fengchen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+D">Divya Raghunathan</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aarti Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Apostolaki%2C+M">Maria Apostolaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Fine-grained monitoring is crucial for multiple data-driven tasks such as
debugging, provisioning, and securing networks. Yet, practical constraints in
collecting, extracting, and storing data often force operators to use
coarse-grained sampled monitoring, degrading the performance of the various
tasks. In this work, we explore the feasibility of leveraging the correlations
among coarse-grained time series to impute their fine-grained counterparts in
software. We present Zoom2Net, a transformer-based model for network imputation
that incorporates domain knowledge through operational and measurement
constraints, ensuring that the imputed network telemetry time series are not
only realistic but also align with existing measurements and are plausible.
This approach enhances the capabilities of current monitoring infrastructures,
allowing operators to gain more insights into system behaviors without the need
for hardware upgrades. We evaluate Zoom2Net on four diverse datasets (e.g.
cloud telemetry and Internet data transfer) and use cases (such as bursts
analysis and traffic classification). We demonstrate that Zoom2Net consistently
achieves high imputation accuracy with a zoom-in factor of up to 100 and
performs better on downstream tasks compared to baselines by an average of 38%.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04169" title="Abstract">arXiv:2403.04169</a> [<a href="/pdf/2403.04169" title="Download PDF">pdf</a>, <a href="/format/2403.04169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Robots for Sleep Health: A Scoping Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antony%2C+V+N">Victor Nikhil Antony</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengchi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shu-Han Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chein-Ming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Poor sleep health is an increasingly concerning public healthcare crisis,
especially when coupled with a dwindling number of health professionals
qualified to combat it. However, there is a growing body of scientific
literature on the use of digital technologies in supporting and sustaining
individuals' healthy sleep habits. Social robots are a relatively recent
technology that has been used to facilitate health care interventions and may
have potential in improving sleep health outcomes, as well. Social robots'
unique characteristics -- such as anthropomorphic physical embodiment or
effective communication methods -- help to engage users and motivate them to
comply with specific interventions, thus improving the interventions' outcomes.
This scoping review aims to evaluate current scientific evidence for employing
social robots in sleep health interventions, identify critical research gaps,
and suggest future directions for developing and using social robots to improve
people's sleep health. Our analysis of the reviewed studies found them limited
due to a singular focus on the older adult population, use of small sample
sizes, limited intervention durations, and other compounding factors.
Nevertheless, the reviewed studies reported several positive outcomes,
highlighting the potential social robots hold in this field. Although our
review found limited clinical evidence for the efficacy of social robots as
purveyors of sleep health interventions, it did elucidate the potential for a
successful future in this domain if current limitations are addressed and more
research is conducted.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04172" title="Abstract">arXiv:2403.04172</a> [<a href="/pdf/2403.04172" title="Download PDF">pdf</a>, <a href="/format/2403.04172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDPL: Shifting-Dense Partition Learning for UAV-View Geo-Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zihao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Rongfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yaoqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bolun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chenggang Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-view geo-localization aims to match images of the same target from
different platforms, e.g., drone and satellite. It is a challenging task due to
the changing both appearance of targets and environmental content from
different views. Existing methods mainly focus on digging more comprehensive
information through feature maps segmentation, while inevitably destroy the
image structure and are sensitive to the shifting and scale of the target in
the query. To address the above issues, we introduce a simple yet effective
part-based representation learning, called shifting-dense partition learning
(SDPL). Specifically, we propose the dense partition strategy (DPS), which
divides the image into multiple parts to explore contextual-information while
explicitly maintain the global structure. To handle scenarios with non-centered
targets, we further propose the shifting-fusion strategy, which generates
multiple sets of parts in parallel based on various segmentation centers and
then adaptively fuses all features to select the best partitions. Extensive
experiments show that our SDPL is robust to position shifting and scale
variations, and achieves competitive performance on two prevailing benchmarks,
i.e., University-1652 and SUES-200.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04173" title="Abstract">arXiv:2403.04173</a> [<a href="/pdf/2403.04173" title="Download PDF">pdf</a>, <a href="/format/2403.04173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Coding for Machines with Edge Information Learning Using Segment  Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shindo%2C+T">Takahiro Shindo</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+K">Kein Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+T">Taiju Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+H">Hiroshi Watanabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image Coding for Machines (ICM) is an image compression technique for image
recognition.
<br />This technique is essential due to the growing demand for image recognition
AI.
<br />In this paper, we propose a method for ICM that focuses on encoding and
decoding only the edge information of object parts in an image, which we call
SA-ICM.
<br />This is an Learned Image Compression (LIC) model trained using edge
information created by Segment Anything.
<br />Our method can be used for image recognition models with various tasks.
<br />SA-ICM is also robust to changes in input data, making it effective for a
variety of use cases.
<br />Additionally, our method provides benefits from a privacy point of view, as
it removes human facial information on the encoder's side, thus protecting
one's privacy.
<br />Furthermore, this LIC model training method can be used to train Neural
Representations for Videos (NeRV), which is a video compression model.
<br />By training NeRV using edge information created by Segment Anything, it is
possible to create a NeRV that is effective for image recognition (SA-NeRV).
<br />Experimental results confirm the advantages of SA-ICM, presenting the best
performance in image compression for image recognition.
<br />We also show that SA-NeRV is superior to ordinary NeRV in video compression
for machines.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04178" title="Abstract">arXiv:2403.04178</a> [<a href="/pdf/2403.04178" title="Download PDF">pdf</a>, <a href="/format/2403.04178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attempt Towards Stress Transfer in Speech-to-Speech Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akarsh%2C+S">Sai Akarsh</a>, 
<a href="/search/cs?searchtype=author&query=Raghusimha%2C+V">Vamshi Raghusimha</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+A">Anindita Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Vuppala%2C+A">Anil Vuppala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The language diversity in India's education sector poses a significant
challenge, hindering inclusivity. Despite the democratization of knowledge
through online educational content, the dominance of English, as the internet's
lingua franca, limits accessibility, emphasizing the crucial need for
translation into Indian languages. Despite existing Speech-to-Speech Machine
Translation (SSMT) technologies, the lack of intonation in these systems gives
monotonous translations, leading to a loss of audience interest and
disengagement from the content. To address this, our paper introduces a dataset
with stress annotations in Indian English and also a Text-to-Speech (TTS)
architecture capable of incorporating stress into synthesized speech. This
dataset is used for training a stress detection model, which is then used in
the SSMT system for detecting stress in the source speech and transferring it
into the target language speech. The TTS architecture is based on FastPitch and
can modify the variances based on stressed words given. We present an Indian
English-to-Hindi SSMT system that can transfer stress and aim to enhance the
overall quality and engagement of educational content.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04179" title="Abstract">arXiv:2403.04179</a> [<a href="/pdf/2403.04179" title="Download PDF">pdf</a>, <a href="/ps/2403.04179" title="Download PostScript">ps</a>, <a href="/format/2403.04179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Transactional Data To Produce Extended Association Rules Using  Collaborative Apriori, Fsa-Red And M5p Predictive Algorithm As A Basis Of  Business Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulianta%2C+F">Feri Sulianta</a>, 
<a href="/search/cs?searchtype=author&query=Angga%2C+L+E">Laksana Eka Angga</a>, 
<a href="/search/cs?searchtype=author&query=Liong%2C+T+H">Thee Houw Liong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">There are large amounts of transactional data which showed consumer shopping
cart at a store that sells more than 150 types of products. In this case, the
company is utilizing these data in making business action. In previous studies,
the data that has a lot of attributes and record data reduction algorithms
handled by the FSA Red (Feature Selection for Association Rules)are then mined
using Apriori algorithm. The resulting association rules have high levels of
accuracy and excellent test results, which rely more than 90%. In this study,
the association rules generated in previous research will be updated by using
prediction algorithms M5P, so that the association rules can be used within a
period of several months in the future. Furthermore, some data mining technique
such as: clustering and time series pattern will be implemented to examine the
truth and extend the validity of association rules which were built. It can be
concluded that the association rules were established after will generate
strong association rules with confidence equal or higher than 70% and the rules
established truth can be seen from the time series pattern on each group of
goods which are then used as the basis of business actions.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04180" title="Abstract">arXiv:2403.04180</a> [<a href="/pdf/2403.04180" title="Download PDF">pdf</a>, <a href="/ps/2403.04180" title="Download PostScript">ps</a>, <a href="/format/2403.04180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RATSF: Empowering Customer Service Volume Management through  Retrieval-Augmented Time-Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Gaojie Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for review to KDD24 (ADS Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">An efficient customer service management system hinges on precise forecasting
of service volume. In this scenario, where data non-stationarity is pronounced,
successful forecasting heavily relies on identifying and leveraging similar
historical data rather than merely summarizing periodic patterns. Existing
models based on RNN or Transformer architectures often struggle with this
flexible and effective utilization. To address this challenge, we propose an
efficient and adaptable cross-attention module termed RACA, which effectively
leverages historical segments in forecasting task, and we devised a precise
representation scheme for querying historical sequences, coupled with the
design of a knowledge repository. These critical components collectively form
our Retrieval-Augmented Temporal Sequence Forecasting framework (RATSF). RATSF
not only significantly enhances performance in the context of Fliggy hotel
service volume forecasting but, more crucially, can be seamlessly integrated
into other Transformer-based time-series forecasting models across various
application scenarios. Extensive experimentation has validated the
effectiveness and generalizability of this system design across multiple
diverse contexts.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04182" title="Abstract">arXiv:2403.04182</a> [<a href="/pdf/2403.04182" title="Download PDF">pdf</a>, <a href="/format/2403.04182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric-aware LLM inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lukasik%2C+M">Michal Lukasik</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+H">Harikrishna Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+A+K">Aditya Krishna Menon</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Felix Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated strong results on a range of
NLP tasks. Typically, outputs are obtained via autoregressive sampling from the
LLM's underlying distribution. We show that this inference strategy can be
suboptimal for a range of tasks and associated evaluation metrics. As a remedy,
we propose metric aware LLM inference: a decision theoretic approach optimizing
for custom metrics at inference time. We report improvements over baselines on
academic benchmarks and publicly available models.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04183" title="Abstract">arXiv:2403.04183</a> [<a href="/pdf/2403.04183" title="Download PDF">pdf</a>, <a href="/format/2403.04183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YYDS: Visible-Infrared Person Re-Identification with Coarse Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yunhao Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+F">Fei Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visible-infrared person re-identification (VI-ReID) is challenging due to
considerable cross-modality discrepancies. Existing works mainly focus on
learning modality-invariant features while suppressing modality-specific ones.
However, retrieving visible images only depends on infrared samples is an
extreme problem because of the absence of color information. To this end, we
present the Refer-VI-ReID settings, which aims to match target visible images
from both infrared images and coarse language descriptions (e.g., "a man with
red top and black pants") to complement the missing color information. To
address this task, we design a Y-Y-shape decomposition structure, dubbed YYDS,
to decompose and aggregate texture and color features of targets. Specifically,
the text-IoU regularization strategy is firstly presented to facilitate the
decomposition training, and a joint relation module is then proposed to infer
the aggregation. Furthermore, the cross-modal version of k-reciprocal
re-ranking algorithm is investigated, named CMKR, in which three neighbor
search strategies and one local query expansion method are explored to
alleviate the modality bias problem of the near neighbors. We conduct
experiments on SYSU-MM01, RegDB and LLCM datasets with our manually annotated
descriptions. Both YYDS and CMKR achieve remarkable improvements over SOTA
methods on all three datasets. Codes are available at
https://github.com/dyhBUPT/YYDS.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04184" title="Abstract">arXiv:2403.04184</a> [<a href="/pdf/2403.04184" title="Download PDF">pdf</a>, <a href="/format/2403.04184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Opinion Polarization on Short Video Consumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bangde Du</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhijing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Investigating the increasingly popular domain of short video consumption,
this study focuses on the impact of Opinion Polarization (OP), a significant
factor in the digital landscape influencing public opinions and social
interactions. We analyze OP's effect on viewers' perceptions and behaviors,
finding that traditional feedback metrics like likes and watch time fail to
fully capture and measure OP. Addressing this gap, our research utilizes
Electroencephalogram (EEG) signals to introduce a novel, non-invasive approach
for evaluating neural responses to OP, affecting perception and cognition.
Empirical analysis reveals OP's considerable impact on viewers' emotions,
evidenced by changes in brain activity. Our findings also highlight the
potential of EEG data in predicting exposure to polarized short video content,
offering a new perspective on the dynamics of short video consumption and a
unique method for quantifying OP's effects.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04189" title="Abstract">arXiv:2403.04189</a> [<a href="/pdf/2403.04189" title="Download PDF">pdf</a>, <a href="/ps/2403.04189" title="Download PostScript">ps</a>, <a href="/format/2403.04189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Silicon Photonic 2.5D Interposer Networks for Overcoming Communication  Bottlenecks in Scale-out Machine Learning Hardware Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sunny%2C+F">Febin Sunny</a>, 
<a href="/search/cs?searchtype=author&query=Taheri%2C+E">Ebadollah Taheri</a>, 
<a href="/search/cs?searchtype=author&query=Nikdast%2C+M">Mahdi Nikdast</a>, 
<a href="/search/cs?searchtype=author&query=Pasricha%2C+S">Sudeep Pasricha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Modern machine learning (ML) applications are becoming increasingly complex
and monolithic (single chip) accelerator architectures cannot keep up with
their energy efficiency and throughput demands. Even though modern digital
electronic accelerators are gradually adopting 2.5D architectures with multiple
smaller chiplets to improve scalability, they face fundamental limitations due
to a reliance on slow metallic interconnects. This paper outlines how optical
communication and computation can be leveraged in 2.5D platforms to realize
energy-efficient and high throughput 2.5D ML accelerator architectures.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04190" title="Abstract">arXiv:2403.04190</a> [<a href="/pdf/2403.04190" title="Download PDF">pdf</a>, <a href="/format/2403.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Synthetic Data Generation: Methods, Challenges and the  Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiqiang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The recent surge in research focused on generating synthetic data from large
language models (LLMs), especially for scenarios with limited data
availability, marks a notable shift in Generative Artificial Intelligence (AI).
Their ability to perform comparably to real-world data positions this approach
as a compelling solution to low-resource challenges. This paper delves into
advanced technologies that leverage these gigantic LLMs for the generation of
task-specific training data. We outline methodologies, evaluation techniques,
and practical applications, discuss the current limitations, and suggest
potential pathways for future research.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04193" title="Abstract">arXiv:2403.04193</a> [<a href="/pdf/2403.04193" title="Download PDF">pdf</a>, <a href="/ps/2403.04193" title="Download PostScript">ps</a>, <a href="/format/2403.04193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VAEMax: Open-Set Intrusion Detection based on OpenMax and Variational  Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhiyin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Ding Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yahui Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiuxin Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 5 tables, 2024 5th ICTC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Promptly discovering unknown network attacks is critical for reducing the
risk of major loss imposed on system or equipment. This paper aims to develop
an open-set intrusion detection model to classify known attacks as well as
inferring unknown ones. To achieve this, we employ OpenMax and variational
autoencoder to propose a dual detection model, VAEMax. First, we extract flow
payload feature based on one-dimensional convolutional neural network. Then,
the OpenMax is used to classify flows, during which some unknown attacks can be
detected, while the rest are misclassified into a certain class of known flows.
Finally, use VAE to perform secondary detection on each class of flows, and
determine whether the flow is an unknown attack based on the reconstruction
loss. Experiments performed on dataset CIC-IDS2017 and CSE-CIC-IDS2018 show our
approach is better than baseline models and can be effectively applied to
realistic network environments.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04194" title="Abstract">arXiv:2403.04194</a> [<a href="/pdf/2403.04194" title="Download PDF">pdf</a>, <a href="/format/2403.04194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-PD: How Far Can SAM Take Us in Tracking and Segmenting Anything in  Videos by Prompt Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhiguo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, promptable segmentation models, such as the Segment Anything Model
(SAM), have demonstrated robust zero-shot generalization capabilities on static
images. These promptable models exhibit denoising abilities for imprecise
prompt inputs, such as imprecise bounding boxes. In this paper, we explore the
potential of applying SAM to track and segment objects in videos where we
recognize the tracking task as a prompt denoising task. Specifically, we
iteratively propagate the bounding box of each object's mask in the preceding
frame as the prompt for the next frame. Furthermore, to enhance SAM's denoising
capability against position and size variations, we propose a multi-prompt
strategy where we provide multiple jittered and scaled box prompts for each
object and preserve the mask prediction with the highest semantic similarity to
the template mask. We also introduce a point-based refinement stage to handle
occlusions and reduce cumulative errors. Without involving tracking modules,
our approach demonstrates comparable performance in video object/instance
segmentation tasks on three datasets: DAVIS2017, YouTubeVOS2018, and UVO,
serving as a concise baseline and endowing SAM-based downstream applications
with tracking capabilities.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04195" title="Abstract">arXiv:2403.04195</a> [<a href="/pdf/2403.04195" title="Download PDF">pdf</a>, <a href="/ps/2403.04195" title="Download PostScript">ps</a>, <a href="/format/2403.04195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fill-and-Spill: Deep Reinforcement Learning Policy Gradient Methods for  Reservoir Operation Decision and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabas%2C+S+S">Sadegh Sadeghi Tabas</a>, 
<a href="/search/cs?searchtype=author&query=Samadi%2C+V">Vidya Samadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Changes in demand, various hydrological inputs, and environmental stressors
are among the issues that water managers and policymakers face on a regular
basis. These concerns have sparked interest in applying different techniques to
determine reservoir operation policy decisions. As the resolution of the
analysis increases, it becomes more difficult to effectively represent a
real-world system using traditional methods such as Dynamic Programming (DP)
and Stochastic Dynamic Programming (SDP) for determining the best reservoir
operation policy. One of the challenges is the "curse of dimensionality," which
means the number of samples needed to estimate an arbitrary function with a
given level of accuracy grows exponentially with respect to the number of input
variables (i.e., dimensionality) of the function. Deep Reinforcement Learning
(DRL) is an intelligent approach to overcome the curses of stochastic
optimization problems for reservoir operation policy decisions. To our
knowledge, this study is the first attempt that examine various novel DRL
continuous-action policy gradient methods (PGMs), including Deep Deterministic
Policy Gradients (DDPG), Twin Delayed DDPG (TD3), and two different versions of
Soft Actor-Critic (SAC18 and SAC19) for optimizing reservoir operation policy.
In this study, multiple DRL techniques were implemented in order to find the
optimal operation policy of Folsom Reservoir in California, USA. The reservoir
system supplies agricultural, municipal, hydropower, and environmental flow
demands and flood control operations to the City of Sacramento. Analysis
suggests that the TD3 and SAC are robust to meet the Folsom Reservoir's demands
and optimize reservoir operation policies.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04197" title="Abstract">arXiv:2403.04197</a> [<a href="/pdf/2403.04197" title="Download PDF">pdf</a>, <a href="/format/2403.04197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are In-Context Molecule Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiatong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhihao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated exceptional performance in
biochemical tasks, especially the molecule caption translation task, which aims
to bridge the gap between molecules and natural language texts. However,
previous methods in adapting LLMs to the molecule-caption translation task
required extra domain-specific pre-training stages, suffered weak alignment
between molecular and textual spaces, or imposed stringent demands on the scale
of LLMs. To resolve the challenges, we propose In-Context Molecule Adaptation
(ICMA), as a new paradigm allowing LLMs to learn the molecule-text alignment
from context examples via In-Context Molecule Tuning. Specifically, ICMA
incorporates the following three stages: Cross-modal Retrieval, Post-retrieval
Re-ranking, and In-context Molecule Tuning. Initially, Cross-modal Retrieval
utilizes BM25 Caption Retrieval and Molecule Graph Retrieval to retrieve
informative context examples. Additionally, we also propose Post-retrieval
Re-ranking with Sequence Reversal and Random Walk to further improve the
quality of retrieval results. Finally, In-Context Molecule Tuning unlocks the
in-context molecule learning capability of LLMs with retrieved examples and
adapts the parameters of LLMs for the molecule-caption translation task.
Experimental results demonstrate that ICMT can empower LLMs to achieve
state-of-the-art or comparable performance without extra training corpora and
intricate structures, showing that LLMs are inherently in-context molecule
learners.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04198" title="Abstract">arXiv:2403.04198</a> [<a href="/pdf/2403.04198" title="Download PDF">pdf</a>, <a href="/format/2403.04198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CN-RMA: Combined Network with Ray Marching Aggregation for 3D Indoors  Object Detection from Multi-view Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guanlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jingwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhihua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024 poster paper, 8 pages of main part, and 4 pages of supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces CN-RMA, a novel approach for 3D indoor object detection
from multi-view images. We observe the key challenge as the ambiguity of image
and 3D correspondence without explicit geometry to provide occlusion
information. To address this issue, CN-RMA leverages the synergy of 3D
reconstruction networks and 3D object detection networks, where the
reconstruction network provides a rough Truncated Signed Distance Function
(TSDF) and guides image features to vote to 3D space correctly in an end-to-end
manner. Specifically, we associate weights to sampled points of each ray
through ray marching, representing the contribution of a pixel in an image to
corresponding 3D locations. Such weights are determined by the predicted signed
distances so that image features vote only to regions near the reconstructed
surface. Our method achieves state-of-the-art performance in 3D object
detection from multi-view images, as measured by mAP@0.25 and mAP@0.5 on the
ScanNet and ARKitScenes datasets. The code and models are released at
https://github.com/SerCharles/CN-RMA.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04200" title="Abstract">arXiv:2403.04200</a> [<a href="/pdf/2403.04200" title="Download PDF">pdf</a>, <a href="/format/2403.04200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACC-ViT : Atrous Convolution&#x27;s Comeback in Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibtehaz%2C+N">Nabil Ibtehaz</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+N">Ning Yan</a>, 
<a href="/search/cs?searchtype=author&query=Mortazavi%2C+M">Masood Mortazavi</a>, 
<a href="/search/cs?searchtype=author&query=Kihara%2C+D">Daisuke Kihara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformers have elevated to the state-of-the-art vision architectures
through innovations in attention mechanism inspired from visual perception. At
present two classes of attentions prevail in vision transformers, regional and
sparse attention. The former bounds the pixel interactions within a region; the
latter spreads them across sparse grids. The opposing natures of them have
resulted in a dilemma between either preserving hierarchical relation or
attaining a global context. In this work, taking inspiration from atrous
convolution, we introduce Atrous Attention, a fusion of regional and sparse
attention, which can adaptively consolidate both local and global information,
while maintaining hierarchical relations. As a further tribute to atrous
convolution, we redesign the ubiquitous inverted residual convolution blocks
with atrous convolution. Finally, we propose a generalized, hybrid vision
transformer backbone, named ACC-ViT, following conventional practices for
standard vision tasks. Our tiny version model achieves $\sim 84 \%$ accuracy on
ImageNet-1K, with less than $28.5$ million parameters, which is $0.42\%$
improvement over state-of-the-art MaxViT while having $8.4\%$ less parameters.
In addition, we have investigated the efficacy of ACC-ViT backbone under
different evaluation settings, such as finetuning, linear probing, and
zero-shot learning on tasks involving medical image analysis, object detection,
and language-image contrastive learning. ACC-ViT is therefore a strong vision
backbone, which is also competitive in mobile-scale versions, ideal for niche
applications with small datasets.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04201" title="Abstract">arXiv:2403.04201</a> [<a href="/pdf/2403.04201" title="Download PDF">pdf</a>, <a href="/format/2403.04201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-Static Sensing in OFDM Wireless Systems for Indoor Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yajnanarayana%2C+V">Vijaya Yajnanarayana</a>, 
<a href="/search/cs?searchtype=author&query=Geuer%2C+P">Philipp Geuer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 11 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The sixth generation (6G) systems will likely employ orthogonal frequency
division multiplexing (OFDM) waveform for performing the joint task of sensing
and communication. In this paper, we design an OFDM system for integrated
sensing and communication (ISAC) and propose a novel approach for passive
target detection in an indoor deployment using a data driven AI approach. The
delay-Doppler profile (DDP) and power delay profile (PDP) is used to train the
proposed AI-based detector. We analyze the detection performance of the
proposed methods under line of sight (LOS) and non-line of sight (NLOS)
conditions for various training strategies. We show that the proposed method
provides 10 dB performance improvement over the baseline for 80% target
detection under LOS conditions and the performance drops by 10-20 dB for NLOS
depending on the usecase scenarios.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04202" title="Abstract">arXiv:2403.04202</a> [<a href="/pdf/2403.04202" title="Download PDF">pdf</a>, <a href="/format/2403.04202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics of Moral Behavior in Heterogeneous Populations of Learning  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tennant%2C+E">Elizaveta Tennant</a>, 
<a href="/search/cs?searchtype=author&query=Hailes%2C+S">Stephen Hailes</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Growing concerns about safety and alignment of AI systems highlight the
importance of embedding moral capabilities in artificial agents. A promising
solution is the use of learning from experience, i.e., Reinforcement Learning.
In multi-agent (social) environments, complex population-level phenomena may
emerge from interactions between individual learning agents. Many of the
existing studies rely on simulated social dilemma environments to study the
interactions of independent learning agents. However, they tend to ignore the
moral heterogeneity that is likely to be present in societies of agents in
practice. For example, at different points in time a single learning agent may
face opponents who are consequentialist (i.e., caring about maximizing some
outcome over time) or norm-based (i.e., focusing on conforming to a specific
norm here and now). The extent to which agents' co-development may be impacted
by such moral heterogeneity in populations is not well understood. In this
paper, we present a study of the learning dynamics of morally heterogeneous
populations interacting in a social dilemma setting. Using a Prisoner's Dilemma
environment with a partner selection mechanism, we investigate the extent to
which the prevalence of diverse moral agents in populations affects individual
agents' learning behaviors and emergent population-level outcomes. We observe
several types of non-trivial interactions between pro-social and anti-social
agents, and find that certain classes of moral agents are able to steer selfish
agents towards more cooperative behavior.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04204" title="Abstract">arXiv:2403.04204</a> [<a href="/pdf/2403.04204" title="Download PDF">pdf</a>, <a href="/format/2403.04204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Essence and Prospect: An Investigation of Alignment Approaches  for Big Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shitong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shanlin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhihua Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Big models have achieved revolutionary breakthroughs in the field of AI, but
they might also pose potential concerns. Addressing such concerns, alignment
technologies were introduced to make these models conform to human preferences
and values. Despite considerable advancements in the past year, various
challenges lie in establishing the optimal alignment strategy, such as data
cost and scalable oversight, and how to align remains an open question. In this
survey paper, we comprehensively investigate value alignment approaches. We
first unpack the historical context of alignment tracing back to the 1920s
(where it comes from), then delve into the mathematical essence of alignment
(what it is), shedding light on the inherent challenges. Following this
foundation, we provide a detailed examination of existing alignment methods,
which fall into three categories: Reinforcement Learning, Supervised
Fine-Tuning, and In-context Learning, and demonstrate their intrinsic
connections, strengths, and limitations, helping readers better understand this
research area. In addition, two emerging topics, personal alignment, and
multimodal alignment, are also discussed as novel frontiers in this field.
Looking forward, we discuss potential alignment paradigms and how they could
handle remaining challenges, prospecting where future alignment will go.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04205" title="Abstract">arXiv:2403.04205</a> [<a href="/pdf/2403.04205" title="Download PDF">pdf</a>, <a href="/format/2403.04205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OGMP: Oracle Guided Multimodal Policies for Agile and Versatile Robot  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+L">Lokesh Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Sobanbabu%2C+N">Nikhil Sobanbabu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quan Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Amidst task-specific learning-based control synthesis frameworks that achieve
impressive empirical results, a unified framework that systematically
constructs an optimal policy for sufficiently solving a general notion of a
task is absent. Hence, we propose a theoretical framework for a task-centered
control synthesis leveraging two critical ideas: 1) oracle-guided policy
optimization for the non-limiting integration of sub-optimal task-based priors
to guide the policy optimization and 2) task-vital multimodality to break down
solving a task into executing a sequence of behavioral modes. The proposed
approach results in highly agile parkour and diving on a 16-DoF dynamic bipedal
robot. The obtained policy advances indefinitely on a track, performing leaps
and jumps of varying lengths and heights for the parkour task. Corresponding to
the dive task, the policy demonstrates front, back, and side flips from various
initial heights. Finally, we introduce a novel latent mode space reachability
analysis to study our policies' versatility and generalization by computing a
feasible mode set function through which we certify a set of failure-free modes
for our policy to perform at any given state.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04206" title="Abstract">arXiv:2403.04206</a> [<a href="/pdf/2403.04206" title="Download PDF">pdf</a>, <a href="/format/2403.04206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRAWA: Gradient-based Weighted Averaging for Distributed Training of  Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dimlioglu%2C+T">Tolga Dimlioglu</a>, 
<a href="/search/cs?searchtype=author&query=Choromanska%2C+A">Anna Choromanska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages main of main text, in total 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study distributed training of deep learning models in time-constrained
environments. We propose a new algorithm that periodically pulls workers
towards the center variable computed as a weighted average of workers, where
the weights are inversely proportional to the gradient norms of the workers
such that recovering the flat regions in the optimization landscape is
prioritized. We develop two asynchronous variants of the proposed algorithm
that we call Model-level and Layer-level Gradient-based Weighted Averaging
(resp. MGRAWA and LGRAWA), which differ in terms of the weighting scheme that
is either done with respect to the entire model or is applied layer-wise. On
the theoretical front, we prove the convergence guarantee for the proposed
approach in both convex and non-convex settings. We then experimentally
demonstrate that our algorithms outperform the competitor methods by achieving
faster convergence and recovering better quality and flatter local optima. We
also carry out an ablation study to analyze the scalability of the proposed
algorithms in more crowded distributed training environments. Finally, we
report that our approach requires less frequent communication and fewer
distributed updates compared to the state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04207" title="Abstract">arXiv:2403.04207</a> [<a href="/pdf/2403.04207" title="Download PDF">pdf</a>, <a href="/format/2403.04207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeteroSwitch: Characterizing and Taming System-Induced Data  Heterogeneity in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gyudong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+M">Mehdi Ghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+S">Soroush Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+G">Young Geun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Vrudhula%2C+S">Sarma Vrudhula</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Carole-Jean Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is a practical approach to train deep learning models
collaboratively across user-end devices, protecting user privacy by retaining
raw data on-device. In FL, participating user-end devices are highly fragmented
in terms of hardware and software configurations. Such fragmentation introduces
a new type of data heterogeneity in FL, namely \textit{system-induced data
heterogeneity}, as each device generates distinct data depending on its
hardware and software configurations. In this paper, we first characterize the
impact of system-induced data heterogeneity on FL model performance. We collect
a dataset using heterogeneous devices with variations across vendors and
performance tiers. By using this dataset, we demonstrate that
\textit{system-induced data heterogeneity} negatively impacts accuracy, and
deteriorates fairness and domain generalization problems in FL. To address
these challenges, we propose HeteroSwitch, which adaptively adopts
generalization techniques (i.e., ISP transformation and SWAD) depending on the
level of bias caused by varying HW and SW configurations. In our evaluation
with a realistic FL dataset (FLAIR), HeteroSwitch reduces the variance of
averaged precision by 6.3\% across device types.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04212" title="Abstract">arXiv:2403.04212</a> [<a href="/pdf/2403.04212" title="Download PDF">pdf</a>, <a href="/format/2403.04212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persona Extraction Through Semantic Similarity for Emotional Support  Conversation Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Seunghee Han</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S+J">Se Jin Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C+W">Chae Won Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Providing emotional support through dialogue systems is becoming increasingly
important in today's world, as it can support both mental health and social
interactions in many conversation scenarios. Previous works have shown that
using persona is effective for generating empathetic and supportive responses.
They have often relied on pre-provided persona rather than inferring them
during conversations. However, it is not always possible to obtain a user
persona before the conversation begins. To address this challenge, we propose
PESS (Persona Extraction through Semantic Similarity), a novel framework that
can automatically infer informative and consistent persona from dialogues. We
devise completeness loss and consistency loss based on semantic similarity
scores. The completeness loss encourages the model to generate missing persona
information, and the consistency loss guides the model to distinguish between
consistent and inconsistent persona. Our experimental results demonstrate that
high-quality persona information inferred by PESS is effective in generating
emotionally supportive responses.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04221" title="Abstract">arXiv:2403.04221</a> [<a href="/pdf/2403.04221" title="Download PDF">pdf</a>, <a href="/format/2403.04221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Online Reinforcement Learning is Causal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schulte%2C+O">Oliver Schulte</a>, 
<a href="/search/cs?searchtype=author&query=Poupart%2C+P">Pascal Poupart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement learning (RL) and causal modelling naturally complement each
other. The goal of causal modelling is to predict the effects of interventions
in an environment, while the goal of reinforcement learning is to select
interventions that maximize the rewards the agent receives from the
environment. Reinforcement learning includes the two most powerful sources of
information for estimating causal relationships: temporal ordering and the
ability to act on an environment. This paper examines which reinforcement
learning settings we can expect to benefit from causal modelling, and how. In
online learning, the agent has the ability to interact directly with their
environment, and learn from exploring it. Our main argument is that in online
learning, conditional probabilities are causal, and therefore offline RL is the
setting where causal learning has the most potential to make a difference.
Essentially, the reason is that when an agent learns from their {\em own}
experience, there are no unobserved confounders that influence both the agent's
own exploratory actions and the rewards they receive. Our paper formalizes this
argument. For offline RL, where an agent may and typically does learn from the
experience of {\em others}, we describe previous and new methods for leveraging
a causal model, including support for counterfactual queries.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04222" title="Abstract">arXiv:2403.04222</a> [<a href="/pdf/2403.04222" title="Download PDF">pdf</a>, <a href="/format/2403.04222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Evaluation of Large Language Model based on Glass-box Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yingqi Qu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Muyun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiejun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The proliferation of open-source Large Language Models (LLMs) underscores the
pressing need for evaluation methods. Existing works primarily rely on external
evaluators, focusing on training and prompting strategies. However, a crucial
aspect - model-aware glass-box features - is overlooked. In this study, we
explore the utility of glass-box features under the scenario of
self-evaluation, namely applying an LLM to evaluate its own output. We
investigate various glass-box feature groups and discovered that the softmax
distribution serves as a reliable indicator for quality evaluation.
Furthermore, we propose two strategies to enhance the evaluation by
incorporating features derived from references. Experimental results on public
benchmarks validate the feasibility of self-evaluation of LLMs using glass-box
features.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04224" title="Abstract">arXiv:2403.04224</a> [<a href="/pdf/2403.04224" title="Download PDF">pdf</a>, <a href="/format/2403.04224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligners: Decoupling LLMs and Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngweta%2C+L">Lilian Ngweta</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+M">Mayank Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Maity%2C+S">Subha Maity</a>, 
<a href="/search/cs?searchtype=author&query=Gittens%2C+A">Alex Gittens</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuekai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tiny Papers Track at the International Conference on Learning Representations (ICLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) need to be aligned with human expectations to
ensure their safety and utility in most applications. Alignment is challenging,
costly, and needs to be repeated for every LLM and alignment criterion. We
propose to decouple LLMs and alignment by training aligner models that can be
used to align any LLM for a given criteria on an as-needed basis, thus also
reducing the potential negative impacts of alignment on performance. Our recipe
for training the aligner models solely relies on synthetic data generated with
a (prompted) LLM and can be easily adjusted for a variety of alignment
criteria. We illustrate our method by training an "ethical" aligner and verify
its efficacy empirically.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04225" title="Abstract">arXiv:2403.04225</a> [<a href="/pdf/2403.04225" title="Download PDF">pdf</a>, <a href="/format/2403.04225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DTextureTransformer: Geometry Aware Texture Generation for Arbitrary  Mesh Topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=KC%2C+D">Dharma KC</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+C+T">Clayton T. Morrison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning to generate textures for a novel 3D mesh given a collection of 3D
meshes and real-world 2D images is an important problem with applications in
various domains such as 3D simulation, augmented and virtual reality, gaming,
architecture, and design. Existing solutions either do not produce high-quality
textures or deform the original high-resolution input mesh topology into a
regular grid to make this generation easier but also lose the original mesh
topology. In this paper, we present a novel framework called the
3DTextureTransformer that enables us to generate high-quality textures without
deforming the original, high-resolution input mesh. Our solution, a hybrid of
geometric deep learning and StyleGAN-like architecture, is flexible enough to
work on arbitrary mesh topologies and also easily extensible to texture
generation for point cloud representations. Our solution employs a
message-passing framework in 3D in conjunction with a StyleGAN-like
architecture for 3D texture generation. The architecture achieves
state-of-the-art performance among a class of solutions that can learn from a
collection of 3D geometry and real-world 2D images while working with any
arbitrary mesh topology.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04226" title="Abstract">arXiv:2403.04226</a> [<a href="/pdf/2403.04226" title="Download PDF">pdf</a>, <a href="/format/2403.04226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disciplining deliberation: a sociotechnical perspective on machine  learning trade-offs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fazelpour%2C+S">Sina Fazelpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper focuses on two highly publicized formal trade-offs in the field of
responsible artificial intelligence (AI) -- between predictive accuracy and
fairness and between predictive accuracy and interpretability. These formal
trade-offs are often taken by researchers, practitioners, and policy-makers to
directly imply corresponding tensions between underlying values. Thus
interpreted, the trade-offs have formed a core focus of normative engagement in
AI governance, accompanied by a particular division of labor along disciplinary
lines. This paper argues against this prevalent interpretation by drawing
attention to three sets of considerations that are critical for bridging the
gap between these formal trade-offs and their practical impacts on relevant
values. I show how neglecting these considerations can distort our normative
deliberations, and result in costly and misaligned interventions and
justifications. Taken together, these considerations form a sociotechnical
framework that could guide those involved in AI governance to assess how, in
many cases, we can and should have higher aspirations than the prevalent
interpretation of the trade-offs would suggest. I end by drawing out the
normative opportunities and challenges that emerge out of these considerations,
and highlighting the imperative of interdisciplinary collaboration in fostering
responsible AI.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04228" title="Abstract">arXiv:2403.04228</a> [<a href="/pdf/2403.04228" title="Download PDF">pdf</a>, <a href="/format/2403.04228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Image HDR Reconstruction Assisted Ghost Suppression and Detail  Preservation Network for Multi-Exposure HDR Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huafeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenmei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yafei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Computational Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The reconstruction of high dynamic range (HDR) images from multi-exposure low
dynamic range (LDR) images in dynamic scenes presents significant challenges,
especially in preserving and restoring information in oversaturated regions and
avoiding ghosting artifacts. While current methods often struggle to address
these challenges, our work aims to bridge this gap by developing a
multi-exposure HDR image reconstruction network for dynamic scenes,
complemented by single-frame HDR image reconstruction. This network, comprising
single-frame HDR reconstruction with enhanced stop image (SHDR-ESI) and
SHDR-ESI-assisted multi-exposure HDR reconstruction (SHDRA-MHDR), effectively
leverages the ghost-free characteristic of single-frame HDR reconstruction and
the detail-enhancing capability of ESI in oversaturated areas. Specifically,
SHDR-ESI innovatively integrates single-frame HDR reconstruction with the
utilization of ESI. This integration not only optimizes the single image HDR
reconstruction process but also effectively guides the synthesis of
multi-exposure HDR images in SHDR-AMHDR. In this method, the single-frame HDR
reconstruction is specifically applied to reduce potential ghosting effects in
multiexposure HDR synthesis, while the use of ESI images assists in enhancing
the detail information in the HDR synthesis process. Technically, SHDR-ESI
incorporates a detail enhancement mechanism, which includes a
self-representation module and a mutual-representation module, designed to
aggregate crucial information from both reference image and ESI. To fully
leverage the complementary information from non-reference images, a feature
interaction fusion module is integrated within SHDRA-MHDR. Additionally, a
ghost suppression module, guided by the ghost-free results of SHDR-ESI, is
employed to suppress the ghosting artifacts.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04230" title="Abstract">arXiv:2403.04230</a> [<a href="/pdf/2403.04230" title="Download PDF">pdf</a>, <a href="/ps/2403.04230" title="Download PostScript">ps</a>, <a href="/format/2403.04230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalence Testing: The Power of Bounded Adaptivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Diptarka Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sourav Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+G">Gunjan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Equivalence testing, a fundamental problem in the field of distribution
testing, seeks to infer if two unknown distributions on $[n]$ are the same or
far apart in the total variation distance. Conditional sampling has emerged as
a powerful query model and has been investigated by theoreticians and
practitioners alike, leading to the design of optimal algorithms albeit in a
sequential setting (also referred to as adaptive tester). Given the profound
impact of parallel computing over the past decades, there has been a strong
desire to design algorithms that enable high parallelization. Despite
significant algorithmic advancements over the last decade, parallelizable
techniques (also termed non-adaptive testers) have $\tilde{O}(\log^{12}n)$
query complexity, a prohibitively large complexity to be of practical usage.
Therefore, the primary challenge is whether it is possible to design algorithms
that enable high parallelization while achieving efficient query complexity.
<br />Our work provides an affirmative answer to the aforementioned challenge: we
present a highly parallelizable tester with a query complexity of
$\tilde{O}(\log n)$, achieved through a single round of adaptivity, marking a
significant stride towards harmonizing parallelizability and efficiency in
equivalence testing.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04232" title="Abstract">arXiv:2403.04232</a> [<a href="/pdf/2403.04232" title="Download PDF">pdf</a>, <a href="/format/2403.04232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Cooperative Eco-driving via Multi-residual Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayawardana%2C+V">Vindula Jayawardana</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cathy Wu</a>, 
<a href="/search/cs?searchtype=author&query=Farid%2C+Y">Yashar Farid</a>, 
<a href="/search/cs?searchtype=author&query=Oguchi%2C+K">Kentaro Oguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">Conventional control, such as model-based control, is commonly utilized in
autonomous driving due to its efficiency and reliability. However, real-world
autonomous driving contends with a multitude of diverse traffic scenarios that
are challenging for these planning algorithms. Model-free Deep Reinforcement
Learning (DRL) presents a promising avenue in this direction, but learning DRL
control policies that generalize to multiple traffic scenarios is still a
challenge. To address this, we introduce Multi-residual Task Learning (MRTL), a
generic learning framework based on multi-task learning that, for a set of task
scenarios, decomposes the control into nominal components that are effectively
solved by conventional control methods and residual terms which are solved
using learning. We employ MRTL for fleet-level emission reduction in mixed
traffic using autonomous vehicles as a means of system control. By analyzing
the performance of MRTL across nearly 600 signalized intersections and 1200
traffic scenarios, we demonstrate that it emerges as a promising approach to
synergize the strengths of DRL and conventional methods in generalizable
control.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04233" title="Abstract">arXiv:2403.04233</a> [<a href="/pdf/2403.04233" title="Download PDF">pdf</a>, <a href="/format/2403.04233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEEP-ICL: Definition-Enriched Experts for Language Model In-Context  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xingwei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yiming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yucheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tommy Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+W">Stephen W. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It has long been assumed that the sheer number of parameters in large
language models (LLMs) drives in-context learning (ICL) capabilities, enabling
remarkable performance improvements by leveraging task-specific demonstrations.
Challenging this hypothesis, we introduce DEEP-ICL, a novel task Definition
Enriched ExPert Ensembling methodology for ICL. DEEP-ICL explicitly extracts
task definitions from given demonstrations and generates responses through
learning task-specific examples. We argue that improvement from ICL does not
directly rely on model size, but essentially stems from understanding task
definitions and task-guided learning. Inspired by this, DEEP-ICL combines two
3B models with distinct roles (one for concluding task definitions and the
other for learning task demonstrations) and achieves comparable performance to
LLaMA2-13B. Furthermore, our framework outperforms conventional ICL by
overcoming pretraining sequence length limitations, by supporting unlimited
demonstrations. We contend that DEEP-ICL presents a novel alternative for
achieving efficient few-shot learning, extending beyond the conventional ICL.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04236" title="Abstract">arXiv:2403.04236</a> [<a href="/pdf/2403.04236" title="Download PDF">pdf</a>, <a href="/ps/2403.04236" title="Download PostScript">ps</a>, <a href="/format/2403.04236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized DeepIV with Model Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+H">Hui Lan</a>, 
<a href="/search/cs?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Uehara%2C+M">Masatoshi Uehara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Econometrics (econ.EM); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study nonparametric estimation of instrumental variable
(IV) regressions. While recent advancements in machine learning have introduced
flexible methods for IV estimation, they often encounter one or more of the
following limitations: (1) restricting the IV regression to be uniquely
identified; (2) requiring minimax computation oracle, which is highly unstable
in practice; (3) absence of model selection procedure. In this paper, we
present the first method and analysis that can avoid all three limitations,
while still enabling general function approximation. Specifically, we propose a
minimax-oracle-free method called Regularized DeepIV (RDIV) regression that can
converge to the least-norm IV solution. Our method consists of two stages:
first, we learn the conditional distribution of covariates, and by utilizing
the learned distribution, we learn the estimator by minimizing a
Tikhonov-regularized loss function. We further show that our method allows
model selection procedures that can achieve the oracle rates in the
misspecified regime. When extended to an iterative estimator, our method
matches the current state-of-the-art convergence rate. Our method is a Tikhonov
regularized variant of the popular DeepIV method with a non-parametric MLE
first-stage estimator, and our results provide the first rigorous guarantees
for this empirically used method, showcasing the importance of regularization
which was absent from the original work.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04243" title="Abstract">arXiv:2403.04243</a> [<a href="/pdf/2403.04243" title="Download PDF">pdf</a>, <a href="/format/2403.04243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Barrier Functions for Linear Continuous-Time Input-Delay Systems  with Limited-Horizon Previewable Disturbances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pati%2C+T">Tarun Pati</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+S">Seunghoon Hwang</a>, 
<a href="/search/eess?searchtype=author&query=Yong%2C+S+Z">Sze Zheng Yong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 3 figures. This paper was submitted and accepted to the American Controls Conference 2024, we are in the process of final manuscript submission to ACC after addressing the reviewers. In this Arxiv version of the paper, most of the comments from ACC reviewers have been addressed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Cyber-physical and autonomous systems are often equipped with mechanisms that
provide predictions/projections of future disturbances, e.g., road curvatures,
commonly referred to as preview or lookahead, but this preview information is
typically not leveraged in the context of deriving control barrier functions
(CBFs) for safety. This paper proposes a novel limited preview control barrier
function (LPrev-CBF) that avoids both ends of the spectrum, where on one end,
the standard CBF approach treats the (previewable) disturbances simply as
worst-case adversarial signals and on the other end, a recent Prev-CBF approach
assumes that the disturbances are previewable and known for the entire future.
Moreover, our approach applies to input-delay systems and has recursive
feasibility guarantees since we explicitly take input constraints/bounds into
consideration. Thus, our approach provides strong safety guarantees in a less
conservative manner than standard CBF approaches while considering a more
realistic setting with limited preview and input delays.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04245" title="Abstract">arXiv:2403.04245</a> [<a href="/pdf/2403.04245" title="Download PDF">pdf</a>, <a href="/format/2403.04245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Dropout-Induced Modality Bias on Robustness to Missing Video  Frames for Audio-Visual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yusheng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiefeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chin-Hui Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the paper is accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Advanced Audio-Visual Speech Recognition (AVSR) systems have been observed to
be sensitive to missing video frames, performing even worse than
single-modality models. While applying the dropout technique to the video
modality enhances robustness to missing frames, it simultaneously results in a
performance loss when dealing with complete data input. In this paper, we
investigate this contrasting phenomenon from the perspective of modality bias
and reveal that an excessive modality bias on the audio caused by dropout is
the underlying reason. Moreover, we present the Modality Bias Hypothesis (MBH)
to systematically describe the relationship between modality bias and
robustness against missing modality in multimodal systems. Building on these
findings, we propose a novel Multimodal Distribution Approximation with
Knowledge Distillation (MDA-KD) framework to reduce over-reliance on the audio
modality and to maintain performance and robustness simultaneously. Finally, to
address an entirely missing modality, we adopt adapters to dynamically switch
decision strategies. The effectiveness of our proposed approach is evaluated
and validated through a series of comprehensive experiments using the MISP2021
and MISP2022 datasets. Our code is available at
https://github.com/dalision/ModalBiasAVSR
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04247" title="Abstract">arXiv:2403.04247</a> [<a href="/pdf/2403.04247" title="Download PDF">pdf</a>, <a href="/format/2403.04247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed  Entities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qingsong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shulin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tingwei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=JIang%2C+W">Wenhao JIang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to VLDB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Entity Set Expansion (ESE) aims to identify new entities belonging to the
same semantic class as a given set of seed entities. Traditional methods
primarily relied on positive seed entities to represent a target semantic
class, which poses challenge for the representation of ultra-fine-grained
semantic classes. Ultra-fine-grained semantic classes are defined based on
fine-grained semantic classes with more specific attribute constraints.
Describing it with positive seed entities alone cause two issues: (i) Ambiguity
among ultra-fine-grained semantic classes. (ii) Inability to define "unwanted"
semantic. Due to these inherent shortcomings, previous methods struggle to
address the ultra-fine-grained ESE (Ultra-ESE). To solve this issue, we first
introduce negative seed entities in the inputs, which belong to the same
fine-grained semantic class as the positive seed entities but differ in certain
attributes. Negative seed entities eliminate the semantic ambiguity by contrast
between positive and negative attributes. Meanwhile, it provide a
straightforward way to express "unwanted". To assess model performance in
Ultra-ESE, we constructed UltraWiki, the first large-scale dataset tailored for
Ultra-ESE. UltraWiki encompasses 236 ultra-fine-grained semantic classes, where
each query of them is represented with 3-5 positive and negative seed entities.
A retrieval-based framework RetExpan and a generation-based framework GenExpan
are proposed to comprehensively assess the efficacy of large language models
from two different paradigms in Ultra-ESE. Moreover, we devised three
strategies to enhance models' comprehension of ultra-fine-grained entities
semantics: contrastive learning, retrieval augmentation, and chain-of-thought
reasoning. Extensive experiments confirm the effectiveness of our proposed
strategies and also reveal that there remains a large space for improvement in
Ultra-ESE.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04253" title="Abstract">arXiv:2403.04253</a> [<a href="/pdf/2403.04253" title="Download PDF">pdf</a>, <a href="/format/2403.04253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mastering Memory Tasks with World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samsami%2C+M+R">Mohammad Reza Samsami</a>, 
<a href="/search/cs?searchtype=author&query=Zholus%2C+A">Artem Zholus</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+J">Janarthanan Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at The International Conference on Learning Representations 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Current model-based reinforcement learning (MBRL) agents struggle with
long-term dependencies. This limits their ability to effectively solve tasks
involving extended time gaps between actions and outcomes, or tasks demanding
the recalling of distant observations to inform current actions. To improve
temporal coherence, we integrate a new family of state space models (SSMs) in
world models of MBRL agents to present a new method, Recall to Imagine (R2I).
This integration aims to enhance both long-term memory and long-horizon credit
assignment. Through a diverse set of illustrative tasks, we systematically
demonstrate that R2I not only establishes a new state-of-the-art for
challenging memory and credit assignment RL tasks, such as BSuite and POPGym,
but also showcases superhuman performance in the complex memory domain of
Memory Maze. At the same time, it upholds comparable performance in classic RL
tasks, such as Atari and DMC, suggesting the generality of our method. We also
show that R2I is faster than the state-of-the-art MBRL method, DreamerV3,
resulting in faster wall-time convergence.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04256" title="Abstract">arXiv:2403.04256</a> [<a href="/pdf/2403.04256" title="Download PDF">pdf</a>, <a href="/format/2403.04256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Recommendation via Hybrid Retrieval Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Huimin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhenrui Yue</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Q">Qian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Recommendation (FR) emerges as a novel paradigm that enables
privacy-preserving recommendations. However, traditional FR systems usually
represent users/items with discrete identities (IDs), suffering from
performance degradation due to the data sparsity and heterogeneity in FR. On
the other hand, Large Language Models (LLMs) as recommenders have proven
effective across various recommendation scenarios. Yet, LLM-based recommenders
encounter challenges such as low inference efficiency and potential
hallucination, compromising their performance in real-world scenarios. To this
end, we propose GPT-FedRec, a federated recommendation framework leveraging
ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism.
GPT-FedRec is a two-stage solution. The first stage is a hybrid retrieval
process, mining ID-based user patterns and text-based item features. Next, the
retrieved results are converted into text prompts and fed into GPT for
re-ranking. Our proposed hybrid retrieval mechanism and LLM-based re-rank aims
to extract generalized features from data and exploit pretrained knowledge
within LLM, overcoming data sparsity and heterogeneity in FR. In addition, the
RAG approach also prevents LLM hallucination, improving the recommendation
performance for real-world users. Experimental results on diverse benchmark
datasets demonstrate the superior performance of GPT-FedRec against
state-of-the-art baseline methods.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04257" title="Abstract">arXiv:2403.04257</a> [<a href="/pdf/2403.04257" title="Download PDF">pdf</a>, <a href="/format/2403.04257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robustness Analysis of E-Commerce Ranking System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yupin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Han Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gesi%2C+J">Jiri Gesi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+V">Vivek Mittal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Information retrieval (IR) is a pivotal component in various applications.
Recent advances in machine learning (ML) have enabled the integration of ML
algorithms into IR, particularly in ranking systems. While there is a plethora
of research on the robustness of ML-based ranking systems, these studies
largely neglect commercial e-commerce systems and fail to establish a
connection between real-world and manipulated query relevance. In this paper,
we present the first systematic measurement study on the robustness of
e-commerce ranking systems. We define robustness as the consistency of ranking
outcomes for semantically identical queries. To quantitatively analyze
robustness, we propose a novel metric that considers both ranking position and
item-specific information that are absent in existing metrics. Our large-scale
measurement study with real-world data from e-commerce retailers reveals an
open opportunity to measure and improve robustness since semantically identical
queries often yield inconsistent ranking results. Based on our observations, we
propose several solution directions to enhance robustness, such as the use of
Large Language Models. Note that the issue of robustness discussed herein does
not constitute an error or oversight. Rather, in scenarios where there exists a
vast array of choices, it is feasible to present a multitude of products in
various permutations, all of which could be equally appealing. However, this
extensive selection may lead to customer confusion. As e-commerce retailers use
various techniques to improve the quality of search results, we hope that this
research offers valuable guidance for measuring the robustness of the ranking
systems.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04258" title="Abstract">arXiv:2403.04258</a> [<a href="/pdf/2403.04258" title="Download PDF">pdf</a>, <a href="/format/2403.04258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-aware Test-Time Training for Zero-shot Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weihuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haolun Li</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+X">Xiuli Bi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot Video Object Segmentation (ZSVOS) aims at segmenting the primary
moving object without any human annotations. Mainstream solutions mainly focus
on learning a single model on large-scale video datasets, which struggle to
generalize to unseen videos. In this work, we introduce a test-time training
(TTT) strategy to address the problem. Our key insight is to enforce the model
to predict consistent depth during the TTT process. In detail, we first train a
single network to perform both segmentation and depth prediction tasks. This
can be effectively learned with our specifically designed depth modulation
layer. Then, for the TTT process, the model is updated by predicting consistent
depth maps for the same frame under different data augmentations. In addition,
we explore different TTT weight updating strategies. Our empirical results
suggest that the momentum-based weight initialization and looping-based
training scheme lead to more stable improvements. Experiments show that the
proposed method achieves clear improvements on ZSVOS. Our proposed video TTT
strategy provides significant superiority over state-of-the-art TTT methods.
Our code is available at: https://nifangbaage.github.io/DATTT.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04260" title="Abstract">arXiv:2403.04260</a> [<a href="/pdf/2403.04260" title="Download PDF">pdf</a>, <a href="/format/2403.04260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Small Language Models be Good Reasoners for Sequential  Recommendation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Changxin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) open up new horizons for sequential
recommendations, owing to their remarkable language comprehension and
generation capabilities. However, there are still numerous challenges that
should be addressed to successfully implement sequential recommendations
empowered by LLMs. Firstly, user behavior patterns are often complex, and
relying solely on one-step reasoning from LLMs may lead to incorrect or
task-irrelevant responses. Secondly, the prohibitively resource requirements of
LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real
sequential recommender systems. In this paper, we propose a novel Step-by-step
knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising
path for sequential recommenders to enjoy the exceptional reasoning
capabilities of LLMs in a "slim" (i.e., resource-efficient) manner. We
introduce CoT prompting based on user behavior sequences for the larger teacher
model. The rationales generated by the teacher model are then utilized as
labels to distill the downstream smaller student model (e.g., LLaMA2-7B). In
this way, the student model acquires the step-by-step reasoning capabilities in
recommendation tasks. We encode the generated rationales from the student model
into a dense vector, which empowers recommendation in both ID-based and
ID-agnostic scenarios. Extensive experiments demonstrate the effectiveness of
SLIM over state-of-the-art baselines, and further analysis showcasing its
ability to generate meaningful recommendation reasoning at affordable costs.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04261" title="Abstract">arXiv:2403.04261</a> [<a href="/pdf/2403.04261" title="Download PDF">pdf</a>, <a href="/ps/2403.04261" title="Download PostScript">ps</a>, <a href="/format/2403.04261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Biomedical Text Mining with Community Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+H">Hui Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rongrong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Jiaxue Cha</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+E">Erman Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiakun Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Liang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuofeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Buzhou Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bairong Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The field of biomedical research has witnessed a significant increase in the
accumulation of vast amounts of textual data from various sources such as
scientific literatures, electronic health records, clinical trial reports, and
social media. However, manually processing and analyzing these extensive and
complex resources is time-consuming and inefficient. To address this challenge,
biomedical text mining, also known as biomedical natural language processing,
has garnered great attention. Community challenge evaluation competitions have
played an important role in promoting technology innovation and
interdisciplinary collaboration in biomedical text mining research. These
challenges provide platforms for researchers to develop state-of-the-art
solutions for data mining and information processing in biomedical research. In
this article, we review the recent advances in community challenges specific to
Chinese biomedical text mining. Firstly, we collect the information of these
evaluation tasks, such as data sources and task types. Secondly, we conduct
systematic summary and comparative analysis, including named entity
recognition, entity normalization, attribute extraction, relation extraction,
event extraction, text classification, text similarity, knowledge graph
construction, question answering, text generation, and large language model
evaluation. Then, we summarize the potential clinical applications of these
community challenge tasks from translational informatics perspective. Finally,
we discuss the contributions and limitations of these community challenges,
while highlighting future directions in the era of large language models.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04263" title="Abstract">arXiv:2403.04263</a> [<a href="/pdf/2403.04263" title="Download PDF">pdf</a>, <a href="/ps/2403.04263" title="Download PostScript">ps</a>, <a href="/format/2403.04263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Switching Classes: Characterization and Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antony%2C+D">Dhanyamol Antony</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Sagartanu Pal</a>, 
<a href="/search/cs?searchtype=author&query=Sandeep%2C+R+B">R.B. Sandeep</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">In a graph, the switching operation reverses adjacencies between a subset of
vertices and the others. For a hereditary graph class $\mathcal{G}$, we are
concerned with the maximum subclass and the minimum superclass of $\mathcal{G}$
that are closed under switching. We characterize the maximum subclass for many
important classes $\mathcal{G}$, and prove that it is finite when $\mathcal{G}$
is minor-closed and omits at least one graph. For several graph classes, we
develop polynomial-time algorithms to recognize the minimum superclass. We also
show that the recognition of the superclass is NP-complete for $H$-free graphs
when $H$ is a sufficiently long path or cycle, and it cannot be solved in
subexponential time assuming the Exponential Time Hypothesis.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04264" title="Abstract">arXiv:2403.04264</a> [<a href="/pdf/2403.04264" title="Download PDF">pdf</a>, <a href="/format/2403.04264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competitive Facility Location under Random Utilities and Routing  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+G">Hoang Giang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Dam%2C+T+T">Tien Thanh Dam</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+N+H">Ngan Ha Duong</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+T">Tien Mai</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+M+H">Minh Hoang Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, we study a facility location problem within a competitive
market context, where customer demand is predicted by a random utility choice
model. Unlike prior research, which primarily focuses on simple constraints
such as a cardinality constraint on the number of selected locations, we
introduce routing constraints that necessitate the selection of locations in a
manner that guarantees the existence of a tour visiting all chosen locations
while adhering to a specified tour length upper bound. Such routing constraints
find crucial applications in various real-world scenarios. The problem at hand
features a non-linear objective function, resulting from the utilization of
random utilities, together with complex routing constraints, making it
computationally challenging. To tackle this problem, we explore three types of
valid cuts, namely, outer-approximation and submodular cuts to handle the
nonlinear objective function, as well as sub-tour elimination cuts to address
the complex routing constraints. These lead to the development of two exact
solution methods: a nested cutting plane and nested branch-and-cut algorithms,
where these valid cuts are iteratively added to a master problem through two
nested loops. We also prove that our nested cutting plane method always
converges to optimality after a finite number of iterations. Furthermore, we
develop a local search-based metaheuristic tailored for solving large-scale
instances and show its pros and cons compared to exact methods. Extensive
experiments are conducted on problem instances of varying sizes, demonstrating
that our approach excels in terms of solution quality and computation time when
compared to other baseline approaches.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04265" title="Abstract">arXiv:2403.04265</a> [<a href="/pdf/2403.04265" title="Download PDF">pdf</a>, <a href="/format/2403.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conflict and Fairness in Resource Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandopadhyay%2C+S">Susobhan Bandopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Banik%2C+A">Aritra Banik</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sushmita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Pallavi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Sahu%2C+A">Abhishek Sahu</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+S">Saket Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Tale%2C+P">Prafullkumar Tale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2309.04995">arXiv:2309.04995</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In the standard model of fair allocation of resources to agents, every agent
has some utility for every resource, and the goal is to assign resources to
agents so that the agents' welfare is maximized. Motivated by job scheduling,
interest in this problem dates back to the work of Deuermeyer et al. [SIAM J.
on Algebraic Discrete Methods'82]. Recent works consider the compatibility
between resources and assign only mutually compatible resources to an agent. We
study a fair allocation problem in which we are given a set of agents, a set of
resources, a utility function for every agent over a set of resources, and a
{\it conflict graph} on the set of resources (where an edge denotes
incompatibility). The goal is to assign resources to the agents such that $(i)$
the set of resources allocated to an agent are compatible with each other, and
$(ii)$ the minimum satisfaction of an agent is maximized, where the
satisfaction of an agent is the sum of the utility of the assigned resources.
Chiarelli et al. [Algorithmica'22] explore this problem from the classical
complexity perspective to draw the boundary between the cases that are
polynomial-time solvable and those that are \NP-hard. In this article, we study
the parameterized complexity of the problem (and its variants) by considering
several natural and structural parameters.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04269" title="Abstract">arXiv:2403.04269</a> [<a href="/pdf/2403.04269" title="Download PDF">pdf</a>, <a href="/format/2403.04269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure MIMO Communication Relying on Movable Antennas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kezhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers a movable antenna (MA)-aided secure multiple-input
multiple-output (MIMO) communication system consisting of a base station (BS),
a legitimate information receiver (IR) and an eavesdropper (Eve), where the BS
is equipped with MAs to enhance the system's physical layer security (PLS).
Specifically, we aim to maximize the secrecy rate (SR) by jointly optimizing
the transmit precoding (TPC) matrix, the artificial noise (AN) covariance
matrix and the MAs' positions under the constraints of the maximum transmit
power and the minimum distance between MAs. To solve this non-convex problem
with highly coupled optimization variables, the block coordinate descent (BCD)
method is applied to alternately update the variables. Specifically, we first
reformulate the SR into a tractable form by utilizing the minimum mean square
error (MMSE) method, and derive the optimal TPC matrix and the AN covariance
matrix with fixed MAs' positions by applying the Lagrangian multiplier method
in semi-closed forms. Then, the majorization-minimization (MM) algorithm is
employed to iteratively optimize each MA's position while keeping others fixed.
Finally, simulation results are provided to demonstrate the effectiveness of
the proposed algorithms and the significant advantages of the MA-aided system
over conventional fixed position antenna (FPA)-based system in enhancing
system's security.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04272" title="Abstract">arXiv:2403.04272</a> [<a href="/pdf/2403.04272" title="Download PDF">pdf</a>, <a href="/format/2403.04272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Generalized Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shijie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu-Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Lin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalized Category Discovery (GCD) is a pragmatic and challenging
open-world task, which endeavors to cluster unlabeled samples from both novel
and old classes, leveraging some labeled data of old classes. Given that
knowledge learned from old classes is not fully transferable to new classes,
and that novel categories are fully unlabeled, GCD inherently faces intractable
problems, including imbalanced classification performance and inconsistent
confidence between old and new classes, especially in the low-labeling regime.
Hence, some annotations of new classes are deemed necessary. However, labeling
new classes is extremely costly. To address this issue, we take the spirit of
active learning and propose a new setting called Active Generalized Category
Discovery (AGCD). The goal is to improve the performance of GCD by actively
selecting a limited amount of valuable samples for labeling from the oracle. To
solve this problem, we devise an adaptive sampling strategy, which jointly
considers novelty, informativeness and diversity to adaptively select novel
samples with proper uncertainty. However, owing to the varied orderings of
label indices caused by the clustering of novel classes, the queried labels are
not directly applicable to subsequent training. To overcome this issue, we
further propose a stable label mapping algorithm that transforms ground truth
labels to the label space of the classifier, thereby ensuring consistent
training across different active selection stages. Our method achieves
state-of-the-art performance on both generic and fine-grained datasets. Our
code is available at https://github.com/mashijie1028/ActiveGCD
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04273" title="Abstract">arXiv:2403.04273</a> [<a href="/pdf/2403.04273" title="Download PDF">pdf</a>, <a href="/format/2403.04273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenML: A Python Library to Generate the Mittag-Leffler Correlated Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wenjie Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zihan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Statistical Mechanics (cond-mat.stat-mech); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Mittag-Leffler correlated noise (M-L noise) plays a crucial role in the
dynamics of complex systems, yet the scientific community has lacked tools for
its direct generation. Addressing this gap, our work introduces GenML, a Python
library specifically designed for generating M-L noise. We detail the
architecture and functionalities of GenML and its underlying algorithmic
approach, which enables the precise simulation of M-L noise. The effectiveness
of GenML is validated through quantitative analyses of autocorrelation
functions and diffusion behaviors, showcasing its capability to accurately
replicate theoretical noise properties. Our contribution with GenML enables the
effective application of M-L noise data in numerical simulation and data-driven
methods for describing complex systems, moving beyond mere theoretical
modeling.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04278" title="Abstract">arXiv:2403.04278</a> [<a href="/pdf/2403.04278" title="Download PDF">pdf</a>, <a href="/format/2403.04278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSDRec: Self-Augmented Sequence Denoising for Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qilong Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+P">Peng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hongtao Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Traditional sequential recommendation methods assume that users' sequence
data is clean enough to learn accurate sequence representations to reflect user
preferences. In practice, users' sequences inevitably contain noise (e.g.,
accidental interactions), leading to incorrect reflections of user preferences.
Consequently, some pioneer studies have explored modeling sequentiality and
correlations in sequences to implicitly or explicitly reduce noise's influence.
However, relying on only available intra-sequence information (i.e.,
sequentiality and correlations in a sequence) is insufficient and may result in
over-denoising and under-denoising problems (OUPs), especially for short
sequences. To improve reliability, we propose to augment sequences by inserting
items before denoising. However, due to the data sparsity issue and
computational costs, it is challenging to select proper items from the entire
item universe to insert into proper positions in a target sequence. Motivated
by the above observation, we propose a novel framework--Self-augmented Sequence
Denoising for sequential Recommendation (SSDRec) with a three-stage learning
paradigm to solve the above challenges. In the first stage, we empower SSDRec
by a global relation encoder to learn multi-faceted inter-sequence relations in
a data-driven manner. These relations serve as prior knowledge to guide
subsequent stages. In the second stage, we devise a self-augmentation module to
augment sequences to alleviate OUPs. Finally, we employ a hierarchical
denoising module in the third stage to reduce the risk of false augmentations
and pinpoint all noise in raw sequences. Extensive experiments on five
real-world datasets demonstrate the superiority of \model over state-of-the-art
denoising methods and its flexible applications to mainstream sequential
recommendation models. The source code is available at
https://github.com/zc-97/SSDRec.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04279" title="Abstract">arXiv:2403.04279</a> [<a href="/pdf/2403.04279" title="Download PDF">pdf</a>, <a href="/format/2403.04279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Generation with Text-to-Image Diffusion Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qing Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A collection of resources on controllable generation with text-to-image diffusion models: <a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the rapidly advancing realm of visual generation, diffusion models have
revolutionized the landscape, marking a significant shift in capabilities with
their impressive text-guided generative functions. However, relying solely on
text for conditioning these models does not fully cater to the varied and
complex requirements of different applications and scenarios. Acknowledging
this shortfall, a variety of studies aim to control pre-trained text-to-image
(T2I) models to support novel conditions. In this survey, we undertake a
thorough review of the literature on controllable generation with T2I diffusion
models, covering both the theoretical foundations and practical advancements in
this domain. Our review begins with a brief introduction to the basics of
denoising diffusion probabilistic models (DDPMs) and widely used T2I diffusion
models. We then reveal the controlling mechanisms of diffusion models,
theoretically analyzing how novel conditions are introduced into the denoising
process for conditional generation. Additionally, we offer a detailed overview
of research in this area, organizing it into distinct categories from the
condition perspective: generation with specific conditions, generation with
multiple conditions, and universal controllable generation. For an exhaustive
list of the controllable generation literature surveyed, please refer to our
curated repository at
\url{https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04280" title="Abstract">arXiv:2403.04280</a> [<a href="/pdf/2403.04280" title="Download PDF">pdf</a>, <a href="/format/2403.04280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Benchmark for Evaluating Automatic Speech Recognition in the  Arabic Call Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Obaidah%2C+Q+A">Qusai Abo Obaidah</a>, 
<a href="/search/cs?searchtype=author&query=Zater%2C+M+E">Muhy Eddin Zater</a>, 
<a href="/search/cs?searchtype=author&query=Jaljuli%2C+A">Adnan Jaljuli</a>, 
<a href="/search/cs?searchtype=author&query=Mahboub%2C+A">Ali Mahboub</a>, 
<a href="/search/cs?searchtype=author&query=Hakouz%2C+A">Asma Hakouz</a>, 
<a href="/search/cs?searchtype=author&query=Alfrou%2C+B">Bashar Alfrou</a>, 
<a href="/search/cs?searchtype=author&query=Estaitia%2C+Y">Yazan Estaitia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This work is an attempt to introduce a comprehensive benchmark for Arabic
speech recognition, specifically tailored to address the challenges of
telephone conversations in Arabic language. Arabic, characterized by its rich
dialectal diversity and phonetic complexity, presents a number of unique
challenges for automatic speech recognition (ASR) systems. These challenges are
further amplified in the domain of telephone calls, where audio quality,
background noise, and conversational speech styles negatively affect
recognition accuracy. Our work aims to establish a robust benchmark that not
only encompasses the broad spectrum of Arabic dialects but also emulates the
real-world conditions of call-based communications. By incorporating diverse
dialectical expressions and accounting for the variable quality of call
recordings, this benchmark seeks to provide a rigorous testing ground for the
development and evaluation of ASR systems capable of navigating the
complexities of Arabic speech in telephonic contexts. This work also attempts
to establish a baseline performance evaluation using state-of-the-art ASR
technologies.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04282" title="Abstract">arXiv:2403.04282</a> [<a href="/pdf/2403.04282" title="Download PDF">pdf</a>, <a href="/format/2403.04282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving link prediction accuracy of network embedding algorithms via  rich node attribute information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Weiwei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jinqiang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Weiyi Gu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Social Computing, 2023, 4(4): 326-336
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Complex networks are widely used to represent an abundance of real-world
relations ranging from social networks to brain networks. Inferring missing
links or predicting future ones based on the currently observed network is
known as the link prediction task.Recent network embedding based link
prediction algorithms have demonstrated ground-breaking performance on link
prediction accuracy. Those algorithms usually apply node attributes as the
initial feature input to accelerate the convergence speed during the training
process. However, they do not take full advantage of node feature information.
In this paper,besides applying feature attributes as the initial input, we make
better utilization of node attribute information by building attributable
networks and plugging attributable networks into some typical link prediction
algorithms and naming this algorithm Attributive Graph Enhanced Embedding
(AGEE). AGEE is able to automatically learn the weighting trades-off between
the structure and the attributive networks. Numerical experiments show that
AGEE can improve the link prediction accuracy by around 3% compared with link
prediction framework SEAL, Variational Graph AutoEncoder (VGAE), and Node2vec.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04283" title="Abstract">arXiv:2403.04283</a> [<a href="/pdf/2403.04283" title="Download PDF">pdf</a>, <a href="/format/2403.04283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model  with Proxy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chuxiong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianzhu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+F">Feiyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=yang%2C+M">Mingchuan yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) is the prevailing approach
to ensure Large Language Models (LLMs) align with human values. However,
existing RLHF methods require a high computational cost, one main reason being
that RLHF assigns both the generation and alignment tasks to the LLM
simultaneously. In this paper, we introduce Proxy-RLHF, which decouples the
generation and alignment processes of LLMs, achieving alignment with human
values at a much lower computational cost. We start with a novel Markov
Decision Process (MDP) designed for the alignment process and employ
Reinforcement Learning (RL) to train a streamlined proxy model that oversees
the token generation of the LLM, without altering the LLM itself. Experiments
show that our method achieves a comparable level of alignment with only 1\% of
the training parameters of other methods.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04287" title="Abstract">arXiv:2403.04287</a> [<a href="/pdf/2403.04287" title="Download PDF">pdf</a>, <a href="/format/2403.04287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGR: A General Graph Desmoothing Framework for Recommendation via Global  and Local Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Leilei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dazhong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianfu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanyong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Graph Convolutional Networks (GCNs) have become pivotal in recommendation
systems for learning user and item embeddings by leveraging the user-item
interaction graph's node information and topology. However, these models often
face the famous over-smoothing issue, leading to indistinct user and item
embeddings and reduced personalization. Traditional desmoothing methods in
GCN-based systems are model-specific, lacking a universal solution. This paper
introduces a novel, model-agnostic approach named \textbf{D}esmoothing
Framework for \textbf{G}CN-based \textbf{R}ecommendation Systems
(\textbf{DGR}). It effectively addresses over-smoothing on general GCN-based
recommendation models by considering both global and local perspectives.
Specifically, we first introduce vector perturbations during each message
passing layer to penalize the tendency of node embeddings approximating overly
to be similar with the guidance of the global topological structure. Meanwhile,
we further develop a tailored-design loss term for the readout embeddings to
preserve the local collaborative relations between users and their neighboring
items. In particular, items that exhibit a high correlation with neighboring
items are also incorporated to enhance the local topological information. To
validate our approach, we conduct extensive experiments on 5 benchmark datasets
based on 5 well-known GCN-based recommendation models, demonstrating the
effectiveness and generalization of our proposed framework.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04291" title="Abstract">arXiv:2403.04291</a> [<a href="/pdf/2403.04291" title="Download PDF">pdf</a>, <a href="/format/2403.04291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positivity preserving and mass conservative projection method for the  Poisson-Nernst-Planck equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tong%2C+F">Fenghua Tong</a>, 
<a href="/search/math?searchtype=author&query=Cai%2C+Y">Yongyong Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose and analyze a novel approach to construct structure preserving
approximations for the Poisson-Nernst-Planck equations, focusing on the
positivity preserving and mass conservation properties. The strategy consists
of a standard time marching step with a projection (or correction) step to
satisfy the desired physical constraints (positivity and mass conservation).
Based on the $L^2$ projection, we construct a second order Crank-Nicolson type
finite difference scheme, which is linear (exclude the very efficient $L^2$
projection part), positivity preserving and mass conserving. Rigorous error
estimates in $L^2$ norm are established, which are both second order accurate
in space and time. The other choice of projection, e.g. $H^1$ projection, is
discussed.
<br />Numerical examples are presented to verify the theoretical results and
demonstrate the efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04292" title="Abstract">arXiv:2403.04292</a> [<a href="/pdf/2403.04292" title="Download PDF">pdf</a>, <a href="/ps/2403.04292" title="Download PostScript">ps</a>, <a href="/format/2403.04292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A challenge in A(G)I, cybernetics revived in the Ouroboros Model as one  algorithm for all thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomsen%2C+K">Knud Thomsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Artificial Intelligence and Autonomous Systems Volume 1 Issue 1,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">A topical challenge for algorithms in general and for automatic image
categorization and generation in particular is presented in the form of a
drawing for AI to understand. In a second vein, AI is challenged to produce
something similar from verbal description. The aim of the paper is to highlight
strengths and deficiencies of current Artificial Intelligence approaches while
coarsely sketching a way forward. A general lack of encompassing
symbol-embedding and (not only) -grounding in some bodily basis is made
responsible for current deficiencies. A concomitant dearth of hierarchical
organization of concepts follows suite. As a remedy for these shortcomings, it
is proposed to take a wide step back and to newly incorporate aspects of
cybernetics and analog control processes. It is claimed that a promising
overarching perspective is provided by the Ouroboros Model with a valid and
versatile algorithmic backbone for general cognition at all accessible levels
of abstraction and capabilities. Reality, rules, truth, and Free Will are all
useful abstractions according to the Ouroboros Model. Logic deduction as well
as intuitive guesses are claimed as produced on the basis of one
compartmentalized memory for schemata and a pattern-matching, i.e., monitoring
process termed consumption analysis. The latter directs attention on short
(attention proper) and also on long times scales (emotional biases). In this
cybernetic approach, discrepancies between expectations and actual activations
(e.g., sensory precepts) drive the general process of cognition and at the same
time steer the storage of new and adapted memory entries. Dedicated structures
in the human brain work in concert according to this scheme.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04293" title="Abstract">arXiv:2403.04293</a> [<a href="/pdf/2403.04293" title="Download PDF">pdf</a>, <a href="/format/2403.04293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MKF-ADS: A Multi-Knowledge Fused Anomaly Detection System for Automotive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengzhou Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">With the requirements of Intelligent Transport Systems (ITSs) for extensive
connectivity of Electronic Control Units (ECUs) to the outside world, safety
and security have become stringent problems. Intrusion detection systems (IDSs)
are a crucial safety component in remediating Controller Area Network (CAN) bus
vulnerabilities. However, supervised-based IDSs fail to identify complexity
attacks and anomaly-based IDSs have higher false alarms owing to capability
bottleneck. In this paper, we propose a novel multi-knowledge fused anomaly
detection model, called MKF-IDS. Specifically, the method designs an
integration framework, including spatial-temporal correlation with an attention
mechanism (STcAM) module and patch sparse-transformer module (PatchST). The
STcAM with fine-pruning uses one-dimensional convolution (Conv1D) to extract
spatial features and subsequently utilizes the Bidirectional Long Short Term
Memory (Bi-LSTM) to extract the temporal features, where the attention
mechanism will focus on the important time steps. Meanwhile, the PatchST
captures the combined long-time historical features from independent univariate
time series. Finally, the proposed method is based on knowledge distillation to
STcAM as a student model for learning intrinsic knowledge and cross the ability
to mimic PatchST. In the detection phase, the MKF-ADS only deploys STcAM to
maintain efficiency in a resource-limited IVN environment. Moreover, the
redundant noisy signal is reduced with bit flip rate and boundary decision
estimation. We conduct extensive experiments on six simulation attack scenarios
across various CAN IDs and time steps, and two real attack scenarios, which
present a competitive prediction and detection performance. Compared with the
baseline in the same paradigm, the error rate and FAR are 2.62% and 2.41% and
achieve a promising F1-score of 97.3%.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04294" title="Abstract">arXiv:2403.04294</a> [<a href="/pdf/2403.04294" title="Download PDF">pdf</a>, <a href="/format/2403.04294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A$^{3}$lign-DFER: Pioneering Comprehensive Dynamic Affective Alignment  for Dynamic Facial Expression Recognition with CLIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junxiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+X">Xinji Mai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiawen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xuan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shaoqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Liyuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The performance of CLIP in dynamic facial expression recognition (DFER) task
doesn't yield exceptional results as observed in other CLIP-based
classification tasks. While CLIP's primary objective is to achieve alignment
between images and text in the feature space, DFER poses challenges due to the
abstract nature of text and the dynamic nature of video, making label
representation limited and perfect alignment difficult. To address this issue,
we have designed A$^{3}$lign-DFER, which introduces a new DFER labeling
paradigm to comprehensively achieve alignment, thus enhancing CLIP's
suitability for the DFER task. Specifically, our A$^{3}$lign-DFER method is
designed with multiple modules that work together to obtain the most suitable
expanded-dimensional embeddings for classification and to achieve alignment in
three key aspects: affective, dynamic, and bidirectional. We replace the input
label text with a learnable Multi-Dimensional Alignment Token (MAT), enabling
alignment of text to facial expression video samples in both affective and
dynamic dimensions. After CLIP feature extraction, we introduce the Joint
Dynamic Alignment Synchronizer (JAS), further facilitating synchronization and
alignment in the temporal dimension. Additionally, we implement a Bidirectional
Alignment Training Paradigm (BAP) to ensure gradual and steady training of
parameters for both modalities. Our insightful and concise A$^{3}$lign-DFER
method achieves state-of-the-art results on multiple DFER datasets, including
DFEW, FERV39k, and MAFW. Extensive ablation experiments and visualization
studies demonstrate the effectiveness of A$^{3}$lign-DFER. The code will be
available in the future.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04298" title="Abstract">arXiv:2403.04298</a> [<a href="/pdf/2403.04298" title="Download PDF">pdf</a>, <a href="/format/2403.04298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding how social discussion platforms like Reddit are  influencing financial behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thukral%2C+S">Sachin Thukral</a>, 
<a href="/search/cs?searchtype=author&query=Sangwan%2C+S">Suyash Sangwan</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Arnab Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+L">Lipika Dey</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Aaditya Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+P+K">Pramit Kumar Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, 3 tables, and 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This study proposes content and interaction analysis techniques for a large
repository created from social media content. Though we have presented our
study for a large platform dedicated to discussions around financial topics,
the proposed methods are generic and applicable to all platforms. Along with an
extension of topic extraction method using Latent Dirichlet Allocation, we
propose a few measures to assess user participation, influence and topic
affinities specifically. Our study also maps user-generated content to
components of behavioral finance. While these types of information are usually
gathered through surveys, it is obvious that large scale data analysis from
social media can reveal many potentially unknown or rare insights.
Characterising users based on their platform behavior to provide critical
insights about how communities are formed and trust is established in these
platforms using graphical analysis is also studied.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04299" title="Abstract">arXiv:2403.04299</a> [<a href="/pdf/2403.04299" title="Download PDF">pdf</a>, <a href="/format/2403.04299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LitSim: Conflict-aware Policy for Long-term Interactive Traffic  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+H">Haojie Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Renzhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Songyang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qianrui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chunze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Simulation is pivotal in evaluating the performance of autonomous driving
systems due to the advantages in efficiency and cost compared to on-road
testing. Realistic multi-agent behavior~(e.g., interactive and long-term) is
needed to narrow the gap between the simulation and the reality. The existing
work has the following shortcomings in achieving this goal:~(1) log replay
offers realistic scenarios but leads to unrealistic collisions due to lacking
dynamic interactions, and~(2) model-based and learning-based solutions
encourage interactions but often deviate from real-world data in long horizons.
In this work, we propose LitSim, a long-term interactive simulation approach
that maximizes realism while avoiding unrealistic collisions. Specifically, we
replay the log for most scenarios and intervene only when LitSim predicts
unrealistic conflicts. We then encourage interactions among the agents and
resolve the conflicts, thereby reducing the likelihood of unrealistic
collisions. We train and validate our model on the real-world dataset NGSIM,
and the experimental results demonstrate that LitSim outperforms the current
popular approaches in realism and reactivity.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04301" title="Abstract">arXiv:2403.04301</a> [<a href="/pdf/2403.04301" title="Download PDF">pdf</a>, <a href="/ps/2403.04301" title="Download PostScript">ps</a>, <a href="/format/2403.04301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizations of Controlled Generation of Right Linear Grammars with  Unknown Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ise%2C+D">Daihei Ise</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+S">Satoshi Kobayashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">This paper deals with the control generation of right linear grammars with
unknown behaviors (RLUBs, for short) in which derivation behavior is not
determined completely. In particular, we consider a physical property of
control devices used in control systems and formulate it as a partial order
over control alphabet of the control system. We give necessary and sufficient
conditions for given finite language classes to be generated by RLUBs and their
control systems using a given partial order over control alphabet.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04303" title="Abstract">arXiv:2403.04303</a> [<a href="/pdf/2403.04303" title="Download PDF">pdf</a>, <a href="/format/2403.04303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LORS: Low-rank Residual Structure for Parameter-Efficient Network  Stacking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Weifu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuhuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guangpin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 11 tables, CVPR2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models, particularly those based on transformers, often employ
numerous stacked structures, which possess identical architectures and perform
similar functions. While effective, this stacking paradigm leads to a
substantial increase in the number of parameters, posing challenges for
practical applications. In today's landscape of increasingly large models,
stacking depth can even reach dozens, further exacerbating this issue. To
mitigate this problem, we introduce LORS (LOw-rank Residual Structure). LORS
allows stacked modules to share the majority of parameters, requiring a much
smaller number of unique ones per module to match or even surpass the
performance of using entirely distinct ones, thereby significantly reducing
parameter usage. We validate our method by applying it to the stacked decoders
of a query-based object detector, and conduct extensive experiments on the
widely used MS COCO dataset. Experimental results demonstrate the effectiveness
of our method, as even with a 70\% reduction in the parameters of the decoder,
our method still enables the model to achieve comparable or
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04306" title="Abstract">arXiv:2403.04306</a> [<a href="/pdf/2403.04306" title="Download PDF">pdf</a>, <a href="/format/2403.04306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effectiveness Assessment of Recent Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xinyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Ge-Peng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Keren Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Meijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of large vision-language models (LVLMs) represents a noteworthy
advancement towards the pursuit of artificial general intelligence. However,
the extent of their efficacy across both specialized and general tasks warrants
further investigation. This article endeavors to evaluate the competency of
popular LVLMs in specialized and general tasks, respectively, aiming to offer a
comprehensive comprehension of these innovative methodologies. To gauge their
efficacy in specialized tasks, we tailor a comprehensive testbed comprising
three distinct scenarios: natural, healthcare, and industrial, encompassing six
challenging tasks. These tasks include salient, camouflaged, and transparent
object detection, as well as polyp and skin lesion detection, alongside
industrial anomaly detection. We examine the performance of three recent
open-source LVLMs -- MiniGPT-v2, LLaVA-1.5, and Shikra -- in the realm of
visual recognition and localization. Moreover, we conduct empirical
investigations utilizing the aforementioned models alongside GPT-4V, assessing
their multi-modal understanding capacities in general tasks such as object
counting, absurd question answering, affordance reasoning, attribute
recognition, and spatial relation reasoning. Our investigations reveal that
these models demonstrate limited proficiency not only in specialized tasks but
also in general tasks. We delve deeper into this inadequacy and suggest several
potential factors, including limited cognition in specialized tasks, object
hallucination, text-to-image interference, and decreased robustness in complex
problems. We hope this study would provide valuable insights for the future
development of LVLMs, augmenting their power in coping with both general and
specialized applications.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04307" title="Abstract">arXiv:2403.04307</a> [<a href="/pdf/2403.04307" title="Download PDF">pdf</a>, <a href="/format/2403.04307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiying Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Hallucinations pose a significant challenge to the reliability of large
language models (LLMs) in critical domains. Recent benchmarks designed to
assess LLM hallucinations within conventional NLP tasks, such as
knowledge-intensive question answering (QA) and summarization, are insufficient
for capturing the complexities of user-LLM interactions in dynamic, real-world
settings. To address this gap, we introduce HaluEval-Wild, the first benchmark
specifically designed to evaluate LLM hallucinations in the wild. We
meticulously collect challenging (adversarially filtered by Alpaca) user
queries from existing real-world user-LLM interaction datasets, including
ShareGPT, to evaluate the hallucination rates of various LLMs. Upon analyzing
the collected queries, we categorize them into five distinct types, which
enables a fine-grained analysis of the types of hallucinations LLMs exhibit,
and synthesize the reference answers with the powerful GPT-4 model and
retrieval-augmented generation (RAG). Our benchmark offers a novel approach
towards enhancing our comprehension and improvement of LLM reliability in
scenarios reflective of real-world interactions.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04308" title="Abstract">arXiv:2403.04308</a> [<a href="/pdf/2403.04308" title="Download PDF">pdf</a>, <a href="/format/2403.04308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating insights about financial asks from Reddit posts and user  interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thukral%2C+S">Sachin Thukral</a>, 
<a href="/search/cs?searchtype=author&query=Sangwan%2C+S">Suyash Sangwan</a>, 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+V">Vipul Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+A">Arnab Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+L">Lipika Dey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">As an increasingly large number of people turn to platforms like Reddit,
YouTube, Twitter, Instagram, etc. for financial advice, generating insights
about the content generated and interactions taking place within these
platforms have become a key research question. This study proposes content and
interaction analysis techniques for a large repository created from social
media content, where people interactions are centered around financial
information exchange. We propose methods for content analysis that can generate
human-interpretable insights using topic-centered clustering and multi-document
abstractive summarization. We share details of insights generated from our
experiments with a large repository of data gathered from subreddit for
personal finance. We have also explored the use of ChatGPT and Vicuna for
generating responses to queries and compared them with human responses. The
methods proposed in this work are generic and applicable to all large social
media platforms.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04309" title="Abstract">arXiv:2403.04309</a> [<a href="/pdf/2403.04309" title="Download PDF">pdf</a>, <a href="/format/2403.04309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AO-DETR: Anti-Overlapping DETR for X-Ray Prohibited Items Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+T">Tong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Bowen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shuyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Da Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongyue Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Prohibited item detection in X-ray images is one of the most essential and
highly effective methods widely employed in various security inspection
scenarios. Considering the significant overlapping phenomenon in X-ray
prohibited item images, we propose an Anti-Overlapping DETR (AO-DETR) based on
one of the state-of-the-art general object detectors, DINO. Specifically, to
address the feature coupling issue caused by overlapping phenomena, we
introduce the Category-Specific One-to-One Assignment (CSA) strategy to
constrain category-specific object queries in predicting prohibited items of
fixed categories, which can enhance their ability to extract features specific
to prohibited items of a particular category from the overlapping
foreground-background features. To address the edge blurring problem caused by
overlapping phenomena, we propose the Look Forward Densely (LFD) scheme, which
improves the localization accuracy of reference boxes in mid-to-high-level
decoder layers and enhances the ability to locate blurry edges of the final
layer. Similar to DINO, our AO-DETR provides two different versions with
distinct backbones, tailored to meet diverse application requirements.
Extensive experiments on the PIXray and OPIXray datasets demonstrate that the
proposed method surpasses the state-of-the-art object detectors, indicating its
potential applications in the field of prohibited item detection. The source
code will be released at https://github.com/Limingyuan001/AO-DETR-test.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04311" title="Abstract">arXiv:2403.04311</a> [<a href="/pdf/2403.04311" title="Download PDF">pdf</a>, <a href="/format/2403.04311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALTO: An Efficient Network Orchestrator for Compound AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santhanam%2C+K">Keshav Santhanam</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+D">Deepti Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+S">Muhammad Shahir Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+T">Thejas Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Kunjal%2C+N">Neha Kunjal</a>, 
<a href="/search/cs?searchtype=author&query=Thaker%2C+P">Pratiksha Thaker</a>, 
<a href="/search/cs?searchtype=author&query=Levis%2C+P">Philip Levis</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR)

</div>
<p class="mathjax">We present ALTO, a network orchestrator for efficiently serving compound AI
systems such as pipelines of language models. ALTO achieves high throughput and
low latency by taking advantage of an optimization opportunity specific to
generative language models: streaming intermediate outputs. As language models
produce outputs token by token, ALTO exposes opportunities to stream
intermediate outputs between stages when possible. We highlight two new
challenges of correctness and load balancing which emerge when streaming
intermediate data across distributed pipeline stage instances. We also motivate
the need for an aggregation-aware routing interface and distributed
prompt-aware scheduling to address these challenges. We demonstrate the impact
of ALTO's partial output streaming on a complex chatbot verification pipeline,
increasing throughput by up to 3x for a fixed latency target of 4 seconds /
request while also reducing tail latency by 1.8x compared to a baseline serving
approach.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04313" title="Abstract">arXiv:2403.04313</a> [<a href="/pdf/2403.04313" title="Download PDF">pdf</a>, <a href="/format/2403.04313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust shifted proper orthogonal decomposition: Proximal methods for  decomposing flows with multiple transports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krah%2C+P">Philipp Krah</a>, 
<a href="/search/math?searchtype=author&query=Marmin%2C+A">Arthur Marmin</a>, 
<a href="/search/math?searchtype=author&query=Zorawski%2C+B">Beata Zorawski</a>, 
<a href="/search/math?searchtype=author&query=Reiss%2C+J">Julius Reiss</a>, 
<a href="/search/math?searchtype=author&query=Schneider%2C+K">Kai Schneider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We present a new methodology for decomposing flows with multiple transports
that further extends the shifted proper orthogonal decomposition (sPOD). The
sPOD tries to approximate transport-dominated flows by a sum of co-moving data
fields. The proposed methods stem from sPOD but optimize the co-moving fields
directly and penalize their nuclear norm to promote low rank of the individual
data in the decomposition. Furthermore, we add a robustness term to the
decomposition that can deal with interpolation error and data noises.
Leveraging tools from convex optimization, we derive three proximal algorithms
to solve the decomposition problem. We report a numerical comparison with
existing methods against synthetic data benchmarks and then show the separation
ability of our methods on 1D and 2D incompressible and reactive flows. The
resulting methodology is the basis of a new analysis paradigm that results in
the same interpretability as the POD for the individual co-moving fields.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04314" title="Abstract">arXiv:2403.04314</a> [<a href="/pdf/2403.04314" title="Download PDF">pdf</a>, <a href="/format/2403.04314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Your Model Tell a Negation from an Implicature? Unravelling  Challenges With Intent Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siffi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Sailik Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Shalyminov%2C+I">Igor Shalyminov</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conversational systems often rely on embedding models for intent
classification and intent clustering tasks. The advent of Large Language Models
(LLMs), which enable instructional embeddings allowing one to adjust semantics
over the embedding space using prompts, are being viewed as a panacea for these
downstream conversational tasks. However, traditional evaluation benchmarks
rely solely on task metrics that don't particularly measure gaps related to
semantic understanding. Thus, we propose an intent semantic toolkit that gives
a more holistic view of intent embedding models by considering three tasks --
(1) intent classification, (2) intent clustering, and (3) a novel triplet task.
The triplet task gauges the model's understanding of two semantic concepts
paramount in real-world conversational systems -- negation and implicature. We
observe that current embedding models fare poorly in semantic understanding of
these concepts. To address this, we propose a pre-training approach to improve
the embedding model by leveraging augmentation with data generated by an
auto-regressive model and a contrastive loss term. Our approach improves the
semantic understanding of the intent embedding model on the aforementioned
linguistic dimensions while slightly effecting their performance on downstream
task metrics.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04317" title="Abstract">arXiv:2403.04317</a> [<a href="/pdf/2403.04317" title="Download PDF">pdf</a>, <a href="/format/2403.04317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Adaptation of Language Models with a Memory of Amortized Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tack%2C+J">Jihoon Tack</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+E">Eric Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jinwoo Shin</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+Y+W">Yee Whye Teh</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+J+R">Jonathan Richard Schwarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Due to the rapid generation and dissemination of information, large language
models (LLMs) quickly run out of date despite enormous development costs. Due
to this crucial need to keep models updated, online learning has emerged as a
critical necessity when utilizing LLMs for real-world applications. However,
given the ever-expanding corpus of unseen documents and the large parameter
space of modern LLMs, efficient adaptation is essential. To address these
challenges, we propose Memory of Amortized Contexts (MAC), an efficient and
effective online adaptation framework for LLMs with strong knowledge retention.
We propose an amortized feature extraction and memory-augmentation approach to
compress and extract information from new documents into compact modulations
stored in a memory bank. When answering questions, our model attends to and
extracts relevant knowledge from this memory bank. To learn informative
modulations in an efficient manner, we utilize amortization-based
meta-learning, which substitutes the optimization process with a single forward
pass of the encoder. Subsequently, we learn to choose from and aggregate
selected documents into a single modulation by conditioning on the question,
allowing us to adapt a frozen language model during test time without requiring
further gradient updates. Our experiment demonstrates the superiority of MAC in
multiple aspects, including online adaptation performance, time, and memory
efficiency. Code is available at: https://github.com/jihoontack/MAC.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04321" title="Abstract">arXiv:2403.04321</a> [<a href="/pdf/2403.04321" title="Download PDF">pdf</a>, <a href="/format/2403.04321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Probing and Tuning for Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Leigang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024; project page: <a href="https://dpt-t2i.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">Despite advancements in text-to-image generation (T2I), prior methods often
face text-image misalignment problems such as relation confusion in generated
images. Existing solutions involve cross-attention manipulation for better
compositional understanding or integrating large language models for improved
layout planning. However, the inherent alignment capabilities of T2I models are
still inadequate. By reviewing the link between generative and discriminative
modeling, we posit that T2I models' discriminative abilities may reflect their
text-image alignment proficiency during generation. In this light, we advocate
bolstering the discriminative abilities of T2I models to achieve more precise
text-to-image alignment for generation. We present a discriminative adapter
built on T2I models to probe their discriminative abilities on two
representative tasks and leverage discriminative fine-tuning to improve their
text-image alignment. As a bonus of the discriminative adapter, a
self-correction mechanism can leverage discriminative gradients to better align
generated images to text prompts during inference. Comprehensive evaluations
across three benchmark datasets, including both in-distribution and
out-of-distribution scenarios, demonstrate our method's superior generation
performance. Meanwhile, it achieves state-of-the-art discriminative performance
on the two discriminative tasks compared to other generative models.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04325" title="Abstract">arXiv:2403.04325</a> [<a href="/pdf/2403.04325" title="Download PDF">pdf</a>, <a href="/format/2403.04325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Meaning Composition in the Human Brain with Composition Scores  from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changjiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jixing Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The process of meaning composition, wherein smaller units like morphemes or
words combine to form the meaning of phrases and sentences, is essential for
human sentence comprehension. Despite extensive neurolinguistic research into
the brain regions involved in meaning composition, a computational metric to
quantify the extent of composition is still lacking. Drawing on the key-value
memory interpretation of transformer feed-forward network blocks, we introduce
the Composition Score, a novel model-based metric designed to quantify the
degree of meaning composition during sentence comprehension. Experimental
findings show that this metric correlates with brain clusters associated with
word frequency, structural processing, and general sensitivity to words,
suggesting the multifaceted nature of meaning composition during human sentence
comprehension.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04326" title="Abstract">arXiv:2403.04326</a> [<a href="/pdf/2403.04326" title="Download PDF">pdf</a>, <a href="/format/2403.04326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-based Parametric Digital Twins for Intelligent Building Indoor  Climate Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ni%2C+Z">Zhongjun Ni</a> (1), 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chi Zhang</a> (2), 
<a href="/search/eess?searchtype=author&query=Karlsson%2C+M">Magnus Karlsson</a> (1), 
<a href="/search/eess?searchtype=author&query=Gong%2C+S">Shaofang Gong</a> (1) ((1) Department of Science and Technology, Link&#xf6;ping University, Campus Norrk&#xf6;ping, Norrk&#xf6;ping, Sweden. (2) Department of Computer Science and Engineering, University of Gothenburg, Gothenburg, Sweden.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, accepted in the 20th IEEE International Conference on Factory Communication Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Digital transformation in the built environment generates vast data for
developing data-driven models to optimize building operations. This study
presents an integrated solution utilizing edge computing, digital twins, and
deep learning to enhance the understanding of climate in buildings. Parametric
digital twins, created using an ontology, ensure consistent data representation
across diverse service systems equipped by different buildings. Based on
created digital twins and collected data, deep learning methods are employed to
develop predictive models for identifying patterns in indoor climate and
providing insights. Both the parametric digital twin and deep learning models
are deployed on edge for low latency and privacy compliance. As a
demonstration, a case study was conducted in a historic building in
\"Osterg\"otland, Sweden, to compare the performance of five deep learning
architectures. The results indicate that the time-series dense encoder model
exhibited strong competitiveness in performing multi-horizon forecasts of
indoor temperature and relative humidity with low computational costs.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04327" title="Abstract">arXiv:2403.04327</a> [<a href="/pdf/2403.04327" title="Download PDF">pdf</a>, <a href="/format/2403.04327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProMoAI: Process Modeling with Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kourani%2C+H">Humam Kourani</a>, 
<a href="/search/cs?searchtype=author&query=Berti%2C+A">Alessandro Berti</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+D">Daniel Schuster</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W+M+P">Wil M. P. van der Aalst</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">ProMoAI is a novel tool that leverages Large Language Models (LLMs) to
automatically generate process models from textual descriptions, incorporating
advanced prompt engineering, error handling, and code generation techniques.
Beyond automating the generation of complex process models, ProMoAI also
supports process model optimization. Users can interact with the tool by
providing feedback on the generated model, which is then used for refining the
process model. ProMoAI utilizes the capabilities LLMs to offer a novel,
AI-driven approach to process modeling, significantly reducing the barrier to
entry for users without deep technical knowledge in process modeling.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04329" title="Abstract">arXiv:2403.04329</a> [<a href="/pdf/2403.04329" title="Download PDF">pdf</a>, <a href="/format/2403.04329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A mechanism-informed reinforcement learning framework for shape  optimization of airfoils
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+J">Jingfeng Wang</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+G">Guanghui Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we present the mechanism-informed reinforcement learning
framework for airfoil shape optimization. By leveraging the twin delayed deep
deterministic policy gradient algorithm for its notable stability, our approach
addresses the complexities of optimizing shapes governed by fluid dynamics. The
PDEs-based solver is adopted for its accuracy even when the configurations and
geometries are extraordinarily changed during the exploration. Dual-weighted
residual-based mesh refinement strategy is applied to ensure the accurate
calculation of target functionals. To streamline the iterative optimization
process and handle geometric deformations, our approach integrates Laplacian
smoothing, adaptive refinement, and a B\'ezier fitting strategy. This
combination not only remits mesh tangling but also guarantees a precise
manipulation of the airfoil geometry. Our neural network architecture leverages
B\'ezier curves for efficient dimensionality reduction, thereby enhancing the
learning process and ensuring the geometric accuracy of the airfoil shapes. An
attention mechanism is embedded within the network to calculate potential
action on the state as well. Furthermore, we have introduced different reward
and penalty mechanisms tailored to the specific challenges of airfoil
optimization. This algorithm is designed to support the optimization task,
facilitating a more targeted and effective approach for airfoil shape
optimization.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04331" title="Abstract">arXiv:2403.04331</a> [<a href="/pdf/2403.04331" title="Download PDF">pdf</a>, <a href="/format/2403.04331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-Barrier-Aided Teleoperation with Visual-Inertial SLAM for Safe  MAV Navigation in Complex Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Papatheodorou%2C+S">Sotiris Papatheodorou</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2024, 7 pages, 7 figures, supplementary video is available at <a href="https://youtu.be/rCxbWY4PIfQ?si=DC-9mg7g1WooNdaV">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we consider a Micro Aerial Vehicle (MAV) system teleoperated
by a non-expert and introduce a perceptive safety filter that leverages Control
Barrier Functions (CBFs) in conjunction with Visual-Inertial Simultaneous
Localization and Mapping (VI-SLAM) and dense 3D occupancy mapping to guarantee
safe navigation in complex and unstructured environments. Our system relies
solely on onboard IMU measurements, stereo infrared images, and depth images
and autonomously corrects teleoperated inputs when they are deemed unsafe. We
define a point in 3D space as unsafe if it satisfies either of two conditions:
(i) it is occupied by an obstacle, or (ii) it remains unmapped. At each time
step, an occupancy map of the environment is updated by the VI-SLAM by fusing
the onboard measurements, and a CBF is constructed to parameterize the (un)safe
region in the 3D space. Given the CBF and state feedback from the VI-SLAM
module, a safety filter computes a certified reference that best matches the
teleoperation input while satisfying the safety constraint encoded by the CBF.
In contrast to existing perception-based safe control frameworks, we directly
close the perception-action loop and demonstrate the full capability of safe
control in combination with real-time VI-SLAM without any external
infrastructure or prior knowledge of the environment. We verify the efficacy of
the perceptive safety filter in real-time MAV experiments using exclusively
onboard sensing and computation and show that the teleoperated MAV is able to
safely navigate through unknown environments despite arbitrary inputs sent by
the teleoperator.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04334" title="Abstract">arXiv:2403.04334</a> [<a href="/pdf/2403.04334" title="Download PDF">pdf</a>, <a href="/format/2403.04334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High-order Nystr&#xf6;m-based Scheme Explicitly Enforcing Surface Density  Continuity for the Electric Field Integral Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jin Hu</a>, 
<a href="/search/math?searchtype=author&query=Sideris%2C+C">Constantine Sideris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This paper introduces an efficient approach for solving the Electric Field
Integral Equation (EFIE) with high-order accuracy by explicitly enforcing the
continuity of the impressed current densities across boundaries of the surface
patch discretization. The integral operator involved is discretized via a
Nystr\"om-collocation approach based on Chebyshev polynomial expansion within
each patch and a closed quadrature rule is utilized such that the
discretization points inside one patch coincide with those inside another patch
on the shared boundary of those two patches. The continuity enforcement is
achieved by constructing a mapping from those coninciding points to a vector
containing unique discretization points used in the GMRES iterative solver. The
proposed approach is applied to the scattering of several different geometries
including a sphere, a cube, a NURBS model imported from CAD software, and a
dipole structure and results are compared with the Magnetic Field Integral
Equation (MFIE) and the EFIE without enforcing continuity to illustrate the
effectiveness of the approach.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04337" title="Abstract">arXiv:2403.04337</a> [<a href="/pdf/2403.04337" title="Download PDF">pdf</a>, <a href="/format/2403.04337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable AI for Embedded Systems Design: A Case Study of Static  Redundant NVM Memory Write Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamati%C3%A9%2C+A">Abdoulaye Gamati&#xe9;</a> (LIRMM | ADAC), 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a> (LIRMM | ADAC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">This paper investigates the application of eXplainable Artificial
Intelligence (XAI) in the design of embedded systems using machine learning
(ML). As a case study, it addresses the challenging problem of static silent
store prediction. This involves identifying redundant memory writes based only
on static program features. Eliminating such stores enhances performance and
energy efficiency by reducing memory access and bus traffic, especially in the
presence of emerging non-volatile memory technologies. To achieve this, we
propose a methodology consisting of: 1) the development of relevant ML models
for explaining silent store prediction, and 2) the application of XAI to
explain these models. We employ two state-of-the-art model-agnostic XAI methods
to analyze the causes of silent stores. Through the case study, we evaluate the
effectiveness of the methods. We find that these methods provide explanations
for silent store predictions, which are consistent with known causes of silent
store occurrences from previous studies. Typically, this allows us to confirm
the prevalence of silent stores in operations that write the zero constant into
memory, or the absence of silent stores in operations involving loop induction
variables. This suggests the potential relevance of XAI in analyzing ML models'
decision in embedded system design. From the case study, we share some valuable
insights and pitfalls we encountered. More generally, this study aims to lay
the groundwork for future research in the emerging field of XAI for embedded
system design.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04343" title="Abstract">arXiv:2403.04343</a> [<a href="/pdf/2403.04343" title="Download PDF">pdf</a>, <a href="/format/2403.04343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoTBal: Comprehensive Task Balancing for Multi-Task Visual Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yanqi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+D">Dong Jing</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+N">Nanyi Fei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiwu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Visual instruction tuning is a key training stage of large multimodal models
(LMMs). Nevertheless, the common practice of indiscriminately mixing
instruction-following data from various tasks may result in suboptimal overall
performance due to different instruction formats and knowledge domains across
tasks. To mitigate this issue, we propose a novel Comprehensive Task Balancing
(CoTBal) algorithm for multi-task visual instruction tuning of LMMs. To our
knowledge, this is the first work that explores multi-task optimization in
visual instruction tuning. Specifically, we consider two key dimensions for
task balancing: (1) Inter-Task Contribution, the phenomenon where learning one
task potentially enhances the performance in other tasks, attributable to the
overlapping knowledge domains, and (2) Intra-Task Difficulty, which refers to
the learning difficulty within a single task. By quantifying these two
dimensions with performance-based metrics, task balancing is thus enabled by
assigning more weights to tasks that offer substantial contributions to others,
receive minimal contributions from others, and also have great intra-task
difficulties. Experiments show that our CoTBal leads to superior overall
performance in multi-task visual instruction tuning.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04344" title="Abstract">arXiv:2403.04344</a> [<a href="/pdf/2403.04344" title="Download PDF">pdf</a>, <a href="/format/2403.04344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL-CFR: Improving Action Abstraction for Imperfect Information  Extensive-Form Games with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boning Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhixuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longbo Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Effective action abstraction is crucial in tackling challenges associated
with large action spaces in Imperfect Information Extensive-Form Games
(IIEFGs). However, due to the vast state space and computational complexity in
IIEFGs, existing methods often rely on fixed abstractions, resulting in
sub-optimal performance. In response, we introduce RL-CFR, a novel
reinforcement learning (RL) approach for dynamic action abstraction. RL-CFR
builds upon our innovative Markov Decision Process (MDP) formulation, with
states corresponding to public information and actions represented as feature
vectors indicating specific action abstractions. The reward is defined as the
expected payoff difference between the selected and default action
abstractions. RL-CFR constructs a game tree with RL-guided action abstractions
and utilizes counterfactual regret minimization (CFR) for strategy derivation.
Impressively, it can be trained from scratch, achieving higher expected payoff
without increased CFR solving time. In experiments on Heads-up No-limit Texas
Hold'em, RL-CFR outperforms ReBeL's replication and Slumbot, demonstrating
significant win-rate margins of $64\pm 11$ and $84\pm 17$ mbb/hand,
respectively.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04346" title="Abstract">arXiv:2403.04346</a> [<a href="/pdf/2403.04346" title="Download PDF">pdf</a>, <a href="/ps/2403.04346" title="Download PostScript">ps</a>, <a href="/format/2403.04346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainKnow -- Extracting, Linking, and Associating Neuroscience Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huangfu%2C+C">Cunqing Huangfu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Z">Zizhe Ruan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The vast accumulation of neuroscience knowledge presents a challenge for
researchers to timely and accurately locate the specific information they
require. Constructing a knowledge engine that automatically extracts and
organizes information from academic papers can provide researchers with timely
and accurate informational services. We present the Brain Knowledge Engine
(BrainKnow), which extracts and integrates neuroscience knowledge from
published papers from PubMed. BrainKnow comprises a substantial repository,
containing 3,626,931 relations spanning a broad spectrum of 37,011 neuroscience
concepts extracted from 1817744 articles. The relations in BrainKnow can be
accessed and navigated through a user-friendly web interface. Additionally,
BrainKnow employs graph network algorithms for the recommendation and
visualization of knowledge. BrainKnow is capable of automatic real-time
updates. BrainKnow represents the first neuroscience knowledge graph that not
only integrates knowledge in-depth but also facilitates fully automated
updates.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04353" title="Abstract">arXiv:2403.04353</a> [<a href="/pdf/2403.04353" title="Download PDF">pdf</a>, <a href="/ps/2403.04353" title="Download PostScript">ps</a>, <a href="/format/2403.04353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Pooling on Appropriate Topological Maps Represented as  Two-Dimensional Images for EEG Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fukushima%2C+T">Takuto Fukushima</a>, 
<a href="/search/cs?searchtype=author&query=Miyamoto%2C+R">Ryusuke Miyamoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Motor imagery classification based on electroencephalography (EEG) signals is
one of the most important brain-computer interface applications, although it
needs further improvement. Several methods have attempted to obtain useful
information from EEG signals by using recent deep learning techniques such as
transformers. To improve the classification accuracy, this study proposes a
novel EEG-based motor imagery classification method with three key features:
generation of a topological map represented as a two-dimensional image from EEG
signals with coordinate transformation based on t-SNE, use of the InternImage
to extract spatial features, and use of spatiotemporal pooling inspired by
PoolFormer to exploit spatiotemporal information concealed in a sequence of EEG
images. Experimental results using the PhysioNet EEG Motor Movement/Imagery
dataset showed that the proposed method achieved the best classification
accuracy of 88.57%, 80.65%, and 70.17% on two-, three-, and four-class motor
imagery tasks in cross-individual validation.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04356" title="Abstract">arXiv:2403.04356</a> [<a href="/pdf/2403.04356" title="Download PDF">pdf</a>, <a href="/format/2403.04356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Complexity of Earth Mover&#x27;s Distance under Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+K">Karl Bringmann</a>, 
<a href="/search/cs?searchtype=author&query=Staals%2C+F">Frank Staals</a>, 
<a href="/search/cs?searchtype=author&query=W%C4%99grzycki%2C+K">Karol W&#x119;grzycki</a>, 
<a href="/search/cs?searchtype=author&query=van+Wordragen%2C+G">Geert van Wordragen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the paper "Fine-Grained Complexity of Earth Mover's Distance under Translation" accepted for SoCG 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The Earth Mover's Distance is a popular similarity measure in several
branches of computer science. It measures the minimum total edge length of a
perfect matching between two point sets. The Earth Mover's Distance under
Translation ($\mathrm{EMDuT}$) is a translation-invariant version thereof. It
minimizes the Earth Mover's Distance over all translations of one point set.
<br />For $\mathrm{EMDuT}$ in $\mathbb{R}^1$, we present an
$\widetilde{\mathcal{O}}(n^2)$-time algorithm. We also show that this algorithm
is nearly optimal by presenting a matching conditional lower bound based on the
Orthogonal Vectors Hypothesis. For $\mathrm{EMDuT}$ in $\mathbb{R}^d$, we
present an $\widetilde{\mathcal{O}}(n^{2d+2})$-time algorithm for the $L_1$ and
$L_\infty$ metric. We show that this dependence on $d$ is asymptotically tight,
as an $n^{o(d)}$-time algorithm for $L_1$ or $L_\infty$ would contradict the
Exponential Time Hypothesis (ETH). Prior to our work, only approximation
algorithms were known for these problems.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04357" title="Abstract">arXiv:2403.04357</a> [<a href="/pdf/2403.04357" title="Download PDF">pdf</a>, <a href="/format/2403.04357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMU Tracking of Kinematic Chains in the Absence of Gravitational and  Magnetic Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stretton%2C+G+K">Greg K. Stretton</a>, 
<a href="/search/cs?searchtype=author&query=Koulieris%2C+G+A">George Alex Koulieris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Tracking kinematic chains has many uses from healthcare to virtual reality.
Inertial measurement units, IMUs, are well-recognised for their body tracking
capabilities, however, existing solutions rely on gravity and often magnetic
fields for drift correction. As humanity's presence in space increases, systems
that don't rely on gravity or magnetism are required. We aim to demonstrate the
viability of IMU body tracking in a microgravity environment by showing that
gravity and magnetism are not necessary for correcting gyroscope-based
dead-reckoning drift. We aim to build and evaluate an end-to-end solution
accomplishing this. A novel algorithm is developed that compensates for drift
using local accelerations alone, without needing gravity or magnetism. Custom
PCB sensor, IMU, nodes are created and combined into a body-sensor-network to
implement the algorithm and the system is evaluated to determine its strengths
and weaknesses. Dead-reckoning alone is accurate to within 1 degree for 30s.
The drift correction solution can correct large drifts in yaw within 4 seconds
of lateral accelerations to within 3.3 degrees RMSE. Correction accuracy when
drift-free and under motion is 1.1 degrees RSME. We demonstrate that gyroscopic
drift can be compensated for in a kinematic chain by making use of local
acceleration information and often-discarded centripetal and tangential
acceleration information, even in the absence of gravitational and magnetic
fields. Therefore, IMU body tracking is a viable technology for use in
microgravity environments.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04359" title="Abstract">arXiv:2403.04359</a> [<a href="/pdf/2403.04359" title="Download PDF">pdf</a>, <a href="/format/2403.04359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetry Considerations for Learning Task Symmetric Robot Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+M">Mayank Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+N">Nikita Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Klemm%2C+V">Victor Klemm</a>, 
<a href="/search/cs?searchtype=author&query=Allshire%2C+A">Arthur Allshire</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> M. Mittal and N. Rudin contributed equally. Accepted for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Symmetry is a fundamental aspect of many real-world robotic tasks. However,
current deep reinforcement learning (DRL) approaches can seldom harness and
exploit symmetry effectively. Often, the learned behaviors fail to achieve the
desired transformation invariances and suffer from motion artifacts. For
instance, a quadruped may exhibit different gaits when commanded to move
forward or backward, even though it is symmetrical about its torso. This issue
becomes further pronounced in high-dimensional or complex environments, where
DRL methods are prone to local optima and fail to explore regions of the state
space equally. Past methods on encouraging symmetry for robotic tasks have
studied this topic mainly in a single-task setting, where symmetry usually
refers to symmetry in the motion, such as the gait patterns. In this paper, we
revisit this topic for goal-conditioned tasks in robotics, where symmetry lies
mainly in task execution and not necessarily in the learned motions themselves.
In particular, we investigate two approaches to incorporate symmetry invariance
into DRL -- data augmentation and mirror loss function. We provide a
theoretical foundation for using augmented samples in an on-policy setting.
Based on this, we show that the corresponding approach achieves faster
convergence and improves the learned behaviors in various challenging robotic
tasks, from climbing boxes with a quadruped to dexterous manipulation.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04363" title="Abstract">arXiv:2403.04363</a> [<a href="/pdf/2403.04363" title="Download PDF">pdf</a>, <a href="/format/2403.04363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-step Temporal Modeling for UAV Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaoying Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingfa Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xincong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haolin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuqiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of unmanned aerial vehicle (UAV) tracking, Siamese-based
approaches have gained traction due to their optimal balance between efficiency
and precision. However, UAV scenarios often present challenges such as
insufficient sampling resolution, fast motion and small objects with limited
feature information. As a result, temporal context in UAV tracking tasks plays
a pivotal role in target location, overshadowing the target's precise features.
In this paper, we introduce MT-Track, a streamlined and efficient multi-step
temporal modeling framework designed to harness the temporal context from
historical frames for enhanced UAV tracking. This temporal integration occurs
in two steps: correlation map generation and correlation map refinement.
Specifically, we unveil a unique temporal correlation module that dynamically
assesses the interplay between the template and search region features. This
module leverages temporal information to refresh the template feature, yielding
a more precise correlation map. Subsequently, we propose a mutual transformer
module to refine the correlation maps of historical and current frames by
modeling the temporal knowledge in the tracking sequence. This method
significantly trims computational demands compared to the raw transformer. The
compact yet potent nature of our tracking framework ensures commendable
tracking outcomes, particularly in extended tracking scenarios.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04365" title="Abstract">arXiv:2403.04365</a> [<a href="/pdf/2403.04365" title="Download PDF">pdf</a>, <a href="/format/2403.04365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DV-Hop localization based on Distance Estimation using Multinode and Hop  Loss in WSNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Penghong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaopeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Debin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Location awareness is a critical issue in wireless sensor network
applications. For more accurate location estimation, the two issues should be
considered extensively: 1) how to sufficiently utilize the connection
information between multiple nodes and 2) how to select a suitable solution
from multiple solutions obtained by the Euclidean distance loss. In this paper,
a DV-Hop localization based on the distance estimation using multinode (DEMN)
and the hop loss in WSNs is proposed to address the two issues. In DEMN, when
multiple anchor nodes can detect an unknown node, the distance expectation
between the unknown node and an anchor node is calculated using the
cross-domain information and is considered as the expected distance between
them, which narrows the search space. When minimizing the traditional Euclidean
distance loss, multiple solutions may exist. To select a suitable solution, the
hop loss is proposed, which minimizes the difference between the real and its
predicted hops. Finally, the Euclidean distance loss calculated by the DEMN and
the hop loss are embedded into the multi-objective optimization algorithm. The
experimental results show that the proposed method gains 86.11\% location
accuracy in the randomly distributed network, which is 6.05% better than the
DEM-DV-Hop, while DEMN and the hop loss can contribute 2.46% and 3.41%,
respectively.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04366" title="Abstract">arXiv:2403.04366</a> [<a href="/pdf/2403.04366" title="Download PDF">pdf</a>, <a href="/format/2403.04366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Court View Generation with Knowledge Injection and Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Ming Cai</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Court View Generation (CVG) is a challenging task in the field of Legal
Artificial Intelligence (LegalAI), which aims to generate court views based on
the plaintiff claims and the fact descriptions. While Pretrained Language
Models (PLMs) have showcased their prowess in natural language generation,
their application to the complex, knowledge-intensive domain of CVG often
reveals inherent limitations. In this paper, we present a novel approach, named
Knowledge Injection and Guidance (KIG), designed to bolster CVG using PLMs. To
efficiently incorporate domain knowledge during the training stage, we
introduce a knowledge-injected prompt encoder for prompt tuning, thereby
reducing computational overhead. Moreover, to further enhance the model's
ability to utilize domain knowledge, we employ a generating navigator, which
dynamically guides the text generation process in the inference stage without
altering the model's architecture, making it readily transferable.
Comprehensive experiments on real-world data demonstrate the effectiveness of
our approach compared to several established baselines, especially in the
responsivity of claims, where it outperforms the best baseline by 11.87%.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04368" title="Abstract">arXiv:2403.04368</a> [<a href="/pdf/2403.04368" title="Download PDF">pdf</a>, <a href="/format/2403.04368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Remove Wrinkled Transparent Film with Polarized Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruizheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Sixing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-Cong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we study a new problem, Film Removal (FR), which attempts to
remove the interference of wrinkled transparent films and reconstruct the
original information under films for industrial recognition systems. We first
physically model the imaging of industrial materials covered by the film.
Considering the specular highlight from the film can be effectively recorded by
the polarized camera, we build a practical dataset with polarization
information containing paired data with and without transparent film. We aim to
remove interference from the film (specular highlights and other degradations)
with an end-to-end framework. To locate the specular highlight, we use an angle
estimation network to optimize the polarization angle with the minimized
specular highlight. The image with minimized specular highlight is set as a
prior for supporting the reconstruction network. Based on the prior and the
polarized images, the reconstruction network can decouple all degradations from
the film. Extensive experiments show that our framework achieves SOTA
performance in both image reconstruction and industrial downstream tasks. Our
code will be released at \url{https://github.com/jqtangust/FilmRemoval}.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04369" title="Abstract">arXiv:2403.04369</a> [<a href="/pdf/2403.04369" title="Download PDF">pdf</a>, <a href="/format/2403.04369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiangchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Ming Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Confusing charge prediction is a challenging task in legal AI, which involves
predicting confusing charges based on fact descriptions. While existing charge
prediction methods have shown impressive performance, they face significant
challenges when dealing with confusing charges, such as Snatch and Robbery. In
the legal domain, constituent elements play a pivotal role in distinguishing
confusing charges. Constituent elements are fundamental behaviors underlying
criminal punishment and have subtle distinctions among charges. In this paper,
we introduce a novel From Graph to Word Bag (FWGB) approach, which introduces
domain knowledge regarding constituent elements to guide the model in making
judgments on confusing charges, much like a judge's reasoning process.
Specifically, we first construct a legal knowledge graph containing constituent
elements to help select keywords for each charge, forming a word bag.
Subsequently, to guide the model's attention towards the differentiating
information for each charge within the context, we expand the attention
mechanism and introduce a new loss function with attention supervision through
words in the word bag. We construct the confusing charges dataset from
real-world judicial documents. Experiments demonstrate the effectiveness of our
method, especially in maintaining exceptional performance in imbalanced label
distributions.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04370" title="Abstract">arXiv:2403.04370</a> [<a href="/pdf/2403.04370" title="Download PDF">pdf</a>, <a href="/ps/2403.04370" title="Download PostScript">ps</a>, <a href="/format/2403.04370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Task Execution in Multi-Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karishma">Karishma</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+S">Shrisha Rao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, in LNCS format
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">We propose a multi-agent system that enables groups of agents to collaborate
and work autonomously to execute tasks. Groups can work in a decentralized
manner and can adapt to dynamic changes in the environment. Groups of agents
solve assigned tasks by exploring the solution space cooperatively based on the
highest reward first. The tasks have a dependency structure associated with
them. We rigorously evaluated the performance of the system and the individual
group performance using centralized and decentralized control approaches for
task distribution. Based on the results, the centralized approach is more
efficient for systems with a less-dependent system $G_{18}$, while the
decentralized approach performs better for systems with a highly-dependent
system $G_{40}$. We also evaluated task allocation to groups that do not have
interdependence. Our findings reveal that there was significantly less
difference in the number of tasks allocated to each group in a less-dependent
system than in a highly-dependent one. The experimental results showed that a
large number of small-size cooperative groups of agents unequivocally improved
the system's performance compared to a small number of large-size cooperative
groups of agents. Therefore, it is essential to identify the optimal group size
for a system to enhance its performance.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04374" title="Abstract">arXiv:2403.04374</a> [<a href="/pdf/2403.04374" title="Download PDF">pdf</a>, <a href="/format/2403.04374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Load Frequency Control of Nonlinear Power Systems Based on  Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaodi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Meng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhengguang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+L">Ligang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+X">Xiaohong Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Load frequency control (LFC) is widely employed in power systems to stabilize
frequency fluctuation and guarantee power quality. However, most existing LFC
methods rely on accurate power system modeling and usually ignore the nonlinear
characteristics of the system, limiting controllers' performance. To solve
these problems, this paper proposes a model-free LFC method for nonlinear power
systems based on deep deterministic policy gradient (DDPG) framework. The
proposed method establishes an emulator network to emulate power system
dynamics. After defining the action-value function, the emulator network is
applied for control actions evaluation instead of the critic network. Then the
actor network controller is effectively optimized by estimating the policy
gradient based on zeroth-order optimization (ZOO) and backpropagation
algorithm. Simulation results and corresponding comparisons demonstrate the
designed controller can generate appropriate control actions and has strong
adaptability for nonlinear power systems.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04376" title="Abstract">arXiv:2403.04376</a> [<a href="/pdf/2403.04376" title="Download PDF">pdf</a>, <a href="/format/2403.04376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Modelling of Plurality and Definiteness in Chinese Noun  Phrases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=van+Deemter%2C+K">Kees van Deemter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Theoretical linguists have suggested that some languages (e.g., Chinese and
Japanese) are "cooler" than other languages based on the observation that the
intended meaning of phrases in these languages depends more on their contexts.
As a result, many expressions in these languages are shortened, and their
meaning is inferred from the context. In this paper, we focus on the omission
of the plurality and definiteness markers in Chinese noun phrases (NPs) to
investigate the predictability of their intended meaning given the contexts. To
this end, we built a corpus of Chinese NPs, each of which is accompanied by its
corresponding context, and by labels indicating its singularity/plurality and
definiteness/indefiniteness. We carried out corpus assessments and analyses.
The results suggest that Chinese speakers indeed drop plurality and
definiteness markers very frequently. Building on the corpus, we train a bank
of computational models using both classic machine learning models and
state-of-the-art pre-trained language models to predict the plurality and
definiteness of each NP. We report on the performance of these models and
analyse their behaviours.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04377" title="Abstract">arXiv:2403.04377</a> [<a href="/pdf/2403.04377" title="Download PDF">pdf</a>, <a href="/ps/2403.04377" title="Download PostScript">ps</a>, <a href="/format/2403.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lagrangian approach for solving an axisymmetric thermo-electromagnetic  problem. Application to time-varying geometry processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ben%C3%ADtez%2C+M">Marta Ben&#xed;tez</a>, 
<a href="/search/math?searchtype=author&query=Berm%C3%BAdez%2C+A">Alfredo Berm&#xfa;dez</a>, 
<a href="/search/math?searchtype=author&query=Font%C3%A1n%2C+P">Pedro Font&#xe1;n</a>, 
<a href="/search/math?searchtype=author&query=Mart%C3%ADnez%2C+I">Iv&#xe1;n Mart&#xed;nez</a>, 
<a href="/search/math?searchtype=author&query=Salgado%2C+P">Pilar Salgado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The aim of this work is to introduce a thermo-electromagnetic model for
calculating the temperature and the power dissipated in cylindrical pieces
whose geometry var\'ies with time and undergoes large deformations; the motion
will be a known data. The work will be a first step towards building a complete
thermoelectromagnetic-mechanical model suitable for simulating electrically
assisted forming processes, which is the main motivation of the work. The
electromagnetic model will be obtained from the time-harmonic eddy current
problem with an inplane current; the source will be given in terms of currents
or voltages defined at sorne parts of the boundary. Finite element methods
based on a Lagrangian weak formulation will be used for the numerical solution.
This approach will avoid the need to compute and remesh the
thermo-electromagnetic domain along the time. The numerical tools will be
implemented in FEniCS and validated by using a suitable test also solved in
Eulerian coordinates.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04378" title="Abstract">arXiv:2403.04378</a> [<a href="/pdf/2403.04378" title="Download PDF">pdf</a>, <a href="/format/2403.04378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARISMA: CAR-Integrated Service Mesh Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+K">Kevin Klein</a>, 
<a href="/search/cs?searchtype=author&query=Hirmer%2C+P">Pascal Hirmer</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+S">Steffen Becker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The amount of software in modern cars is increasing continuously with
traditional electric/electronic (E/E) architectures reaching their limit when
deploying complex applications, e.g., regarding bandwidth or computational
power. To mitigate this situation, more powerful computing platforms are being
employed and applications are developed as distributed applications, e.g.,
involving microservices. Microservices received widespread adoption and changed
the way modern applications are developed. However, they also introduce
additional complexity regarding inter-service communication. This has led to
the emergence of service meshes, a promising approach to cope with this
complexity. In this paper, we present an architecture applying the service mesh
approach to automotive E/E platforms comprising multiple interlinked
High-Performance Computers (HPCs). We validate the feasibility of our approach
through a prototypical implementation.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04379" title="Abstract">arXiv:2403.04379</a> [<a href="/pdf/2403.04379" title="Download PDF">pdf</a>, <a href="/format/2403.04379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance evaluation of conditional handover in 5G systems under  fading scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deb%2C+S">Souvik Deb</a>, 
<a href="/search/cs?searchtype=author&query=Rathod%2C+M">Megh Rathod</a>, 
<a href="/search/cs?searchtype=author&query=Balamurugan%2C+R">Rishi Balamurugan</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S+K">Shankar K. Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R+K">Rajeev K. Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Samriddha Sanyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">To enhance the handover performance in fifth generation (5G) cellular
systems, conditional handover (CHO) has been evolved as a promising solution.
Unlike A3 based handover where handover execution is certain after receiving
handover command from the serving access network, in CHO, handover execution is
conditional on the RSRP measurements from both current and target access
networks, as well as on mobility parameters such as preparation and execution
offsets. Analytic evaluation of conditional handover performance is
unprecedented in literature. In this work, handover performance of CHO has been
carried out in terms of handover latency, handover packet loss and handover
failure probability. A Markov model accounting the effect of different mobility
parameters (e.g., execution offset, preparation offset, time-to-preparation and
time-to-execution), UE velocity and channel fading characteristics; has been
proposed to characterize handover failure. Results obtained from the analytic
model has been validated against extensive simulation results. Our study reveal
that optimal configuration of $O_{exec}$, $O_{prep}$, $T_{exec}$ and $T_{prep}$
is actually conditional on underlying UE velocity and fading characteristics.
This study will be helpful for the mobile operators to choose appropriate
thresholds of the mobility parameters under different channel condition and UE
velocities.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04380" title="Abstract">arXiv:2403.04380</a> [<a href="/pdf/2403.04380" title="Download PDF">pdf</a>, <a href="/format/2403.04380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Driven Animation of Neural Head Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paier%2C+W">Wolfgang Paier</a>, 
<a href="/search/cs?searchtype=author&query=Hinzer%2C+P">Paul Hinzer</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. International Workshop on Vision, Modeling, and
  Visualization (VMV), Braunschweig, Germany, Sep. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a new approach for video-driven animation of high-quality neural
3D head models, addressing the challenge of person-independent animation from
video input. Typically, high-quality generative models are learned for specific
individuals from multi-view video footage, resulting in person-specific latent
representations that drive the generation process. In order to achieve
person-independent animation from video input, we introduce an LSTM-based
animation network capable of translating person-independent expression features
into personalized animation parameters of person-specific 3D head models. Our
approach combines the advantages of personalized head models (high quality and
realism) with the convenience of video-driven animation employing multi-person
facial performance capture. We demonstrate the effectiveness of our approach on
synthesized animations with high quality based on different source videos as
well as an ablation study.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04381" title="Abstract">arXiv:2403.04381</a> [<a href="/pdf/2403.04381" title="Download PDF">pdf</a>, <a href="/format/2403.04381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-to-Dual-View Adaptation for Egocentric 3D Hand Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruicong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ohkawa%2C+T">Takehiko Ohkawa</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingfang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by CVPR2024. Code will be released at <a href="https://github.com/MickeyLLG/S2DHand">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The pursuit of accurate 3D hand pose estimation stands as a keystone for
understanding human activity in the realm of egocentric vision. The majority of
existing estimation methods still rely on single-view images as input, leading
to potential limitations, e.g., limited field-of-view and ambiguity in depth.
To address these problems, adding another camera to better capture the shape of
hands is a practical direction. However, existing multi-view hand pose
estimation methods suffer from two main drawbacks: 1) Requiring multi-view
annotations for training, which are expensive. 2) During testing, the model
becomes inapplicable if camera parameters/layout are not the same as those used
in training. In this paper, we propose a novel Single-to-Dual-view adaptation
(S2DHand) solution that adapts a pre-trained single-view estimator to dual
views. Compared with existing multi-view training methods, 1) our adaptation
process is unsupervised, eliminating the need for multi-view annotation. 2)
Moreover, our method can handle arbitrary dual-view pairs with unknown camera
parameters, making the model applicable to diverse camera settings.
Specifically, S2DHand is built on certain stereo constraints, including
pair-wise cross-view consensus and invariance of transformation between both
views. These two stereo constraints are used in a complementary manner to
generate pseudo-labels, allowing reliable adaptation. Evaluation results reveal
that S2DHand achieves significant improvements on arbitrary camera pairs under
both in-dataset and cross-dataset settings, and outperforms existing adaptation
methods with leading performance. Project page:
https://github.com/MickeyLLG/S2DHand.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04382" title="Abstract">arXiv:2403.04382</a> [<a href="/pdf/2403.04382" title="Download PDF">pdf</a>, <a href="/format/2403.04382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acceleron: A Tool to Accelerate Research Ideation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigam%2C+H">Harshit Nigam</a>, 
<a href="/search/cs?searchtype=author&query=Patwardhan%2C+M">Manasi Patwardhan</a>, 
<a href="/search/cs?searchtype=author&query=Vig%2C+L">Lovekesh Vig</a>, 
<a href="/search/cs?searchtype=author&query=Shroff%2C+G">Gautam Shroff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AI2ASE Workshop at AAAI'24 Conference. 13 Pages and 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Several tools have recently been proposed for assisting researchers during
various stages of the research life-cycle. However, these primarily concentrate
on tasks such as retrieving and recommending relevant literature, reviewing and
critiquing the draft, and writing of research manuscripts. Our investigation
reveals a significant gap in availability of tools specifically designed to
assist researchers during the challenging ideation phase of the research
life-cycle. To aid with research ideation, we propose `Acceleron', a research
accelerator for different phases of the research life cycle, and which is
specially designed to aid the ideation process. Acceleron guides researchers
through the formulation of a comprehensive research proposal, encompassing a
novel research problem. The proposals motivation is validated for novelty by
identifying gaps in the existing literature and suggesting a plausible list of
techniques to solve the proposed problem. We leverage the reasoning and
domain-specific skills of Large Language Models (LLMs) to create an agent-based
architecture incorporating colleague and mentor personas for LLMs. The LLM
agents emulate the ideation process undertaken by researchers, engaging
researchers in an interactive fashion to aid in the development of the research
proposal. Notably, our tool addresses challenges inherent in LLMs, such as
hallucinations, implements a two-stage aspect-based retrieval to manage
precision-recall trade-offs, and tackles issues of unanswerability. As
evaluation, we illustrate the execution of our motivation validation and method
synthesis workflows on proposals from the ML and NLP domain, given by 3
distinct researchers. Our observations and evaluations provided by the
researchers illustrate the efficacy of the tool in terms of assisting
researchers with appropriate inputs at distinct stages and thus leading to
improved time efficiency.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04384" title="Abstract">arXiv:2403.04384</a> [<a href="/pdf/2403.04384" title="Download PDF">pdf</a>, <a href="/format/2403.04384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeROS: a miniaturised platform for research and development on  Heterogeneous RObotic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winiarski%2C+T">Tomasz Winiarski</a>, 
<a href="/search/cs?searchtype=author&query=Gie%C5%82dowski%2C+D">Daniel Gie&#x142;dowski</a>, 
<a href="/search/cs?searchtype=author&query=Kaniuka%2C+J">Jan Kaniuka</a>, 
<a href="/search/cs?searchtype=author&query=Ostrysz%2C+J">Jakub Ostrysz</a>, 
<a href="/search/cs?searchtype=author&query=Sadowski%2C+J">Jakub Sadowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Tests and prototyping are vital in the research and development of robotic
systems. Work with target hardware is problematic. Hence, in the article, a
low-cost, miniaturised physical platform is presented to deal with experiments
on heterogeneous robotic systems. The platform comprises a physical board with
tiles of the standardised base, diverse mobile robots, and manipulation robots.
The number of exemplary applications validates the usefulness of the solution.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04385" title="Abstract">arXiv:2403.04385</a> [<a href="/pdf/2403.04385" title="Download PDF">pdf</a>, <a href="/format/2403.04385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impacts of Color and Texture Distortions on Earth Observation Data in  Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willbo%2C+M">Martin Willbo</a>, 
<a href="/search/cs?searchtype=author&query=Pirinen%2C+A">Aleksis Pirinen</a>, 
<a href="/search/cs?searchtype=author&query=Martinsson%2C+J">John Martinsson</a>, 
<a href="/search/cs?searchtype=author&query=Zec%2C+E+L">Edvin Listo Zec</a>, 
<a href="/search/cs?searchtype=author&query=Mogren%2C+O">Olof Mogren</a>, 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+M">Mikael Nilsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Land cover classification and change detection are two important applications
of remote sensing and Earth observation (EO) that have benefited greatly from
the advances of deep learning. Convolutional and transformer-based U-net models
are the state-of-the-art architectures for these tasks, and their performances
have been boosted by an increased availability of large-scale annotated EO
datasets. However, the influence of different visual characteristics of the
input EO data on a model's predictions is not well understood. In this work we
systematically examine model sensitivities with respect to several color- and
texture-based distortions on the input EO data during inference, given models
that have been trained without such distortions. We conduct experiments with
multiple state-of-the-art segmentation networks for land cover classification
and show that they are in general more sensitive to texture than to color
distortions. Beyond revealing intriguing characteristics of widely used land
cover classification models, our results can also be used to guide the
development of more robust models within the EO domain.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04387" title="Abstract">arXiv:2403.04387</a> [<a href="/pdf/2403.04387" title="Download PDF">pdf</a>, <a href="/ps/2403.04387" title="Download PostScript">ps</a>, <a href="/format/2403.04387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Deep Learning Techniques on Human Activity Recognition  using Ankle Inertial Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazari%2C+F">Farhad Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Nahavandi%2C+D">Darius Nahavandi</a>, 
<a href="/search/cs?searchtype=author&query=Mohajer%2C+N">Navid Mohajer</a>, 
<a href="/search/cs?searchtype=author&query=Khosravi%2C+A">Abbas Khosravi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the accepted version of an article published in the proceedings of the 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Systems, Man, and
  Cybernetics (SMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Human Activity Recognition (HAR) is one of the fundamental building blocks of
human assistive devices like orthoses and exoskeletons. There are different
approaches to HAR depending on the application. Numerous studies have been
focused on improving them by optimising input data or classification
algorithms. However, most of these studies have been focused on applications
like security and monitoring, smart devices, the internet of things, etc. On
the other hand, HAR can help adjust and control wearable assistive devices, yet
there has not been enough research facilitating its implementation. In this
study, we propose several models to predict four activities from inertial
sensors located in the ankle area of a lower-leg assistive device user. This
choice is because they do not need to be attached to the user's skin and can be
directly implemented inside the control unit of the device. The proposed models
are based on Artificial Neural Networks and could achieve up to 92.8% average
classification accuracy
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04388" title="Abstract">arXiv:2403.04388</a> [<a href="/pdf/2403.04388" title="Download PDF">pdf</a>, <a href="/ps/2403.04388" title="Download PostScript">ps</a>, <a href="/format/2403.04388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based pressure tracking using a feedback linearisation technique  in thermoplastic injection moulding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kariminejad%2C+M">Mandana Kariminejad</a>, 
<a href="/search/eess?searchtype=author&query=Tormey%2C+D">David Tormey</a>, 
<a href="/search/eess?searchtype=author&query=McAfee%2C+M">Marion McAfee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Injection moulding is a well-established automated process for manufacturing
a wide variety of plastic components in large volumes and with high precision.
There are, however, process control challenges associated with each stage of
injection moulding, which should be monitored and controlled precisely to
prevent defects in the injection moulded component. One of the process
variables is the pressure profile during the injection and packing phases,
which has a direct impact on the quality of the manufactured part. This
research proposes a model-based controller design for the injection and cavity
pressure during the moulding cycle, with a feedback linearisation controller.
First, the injection and packing phases were mathematically modelled and
converted to a state-space model. The procedure of designing the controller for
the process was outlined. A pressure profile was defined as the target
trajectory in the proposed controller and the ability of the designed
controller to follow the set profile was explored.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04390" title="Abstract">arXiv:2403.04390</a> [<a href="/pdf/2403.04390" title="Download PDF">pdf</a>, <a href="/ps/2403.04390" title="Download PostScript">ps</a>, <a href="/format/2403.04390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-memory Lanczos method with rational Krylov compression for matrix  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Casulli%2C+A+A">Angelo A. Casulli</a>, 
<a href="/search/math?searchtype=author&query=Simunec%2C+I">Igor Simunec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we introduce a memory-efficient method for computing the action
of a Hermitian matrix function on a vector. Our method consists of a rational
Lanczos algorithm combined with a basis compression procedure based on rational
Krylov subspaces that only involve small matrices. The cost of the compression
procedure is negligible with respect to the cost of the Lanczos algorithm. This
enables us to avoid storing the whole Krylov basis, leading to substantial
reductions in memory requirements. This method is particularly effective when
the rational Lanczos algorithm needs a significant number of iterations to
converge and each iteration involves a low computational effort. This scenario
often occurs when polynomial Lanczos, as well as extended and shift-and-invert
Lanczos are employed. Theoretical results prove that, for a wide variety of
functions, the proposed algorithm differs from rational Lanczos by an error
term that is usually negligible. The algorithm is compared with other
low-memory Krylov methods from the literature on a variety of test problems,
showing competitive performance.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04398" title="Abstract">arXiv:2403.04398</a> [<a href="/pdf/2403.04398" title="Download PDF">pdf</a>, <a href="/format/2403.04398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAGR: Manifold-Aligned Graph Regularization for Continual Action Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kanglei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shum%2C+H+P+H">Hubert P. H. Shum</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F+W+B">Frederick W. B. Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaohui Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Action Quality Assessment (AQA) evaluates diverse skills but models struggle
with non-stationary data. We propose Continual AQA (CAQA) to refine models
using sparse new data. Feature replay preserves memory without storing raw
inputs. However, the misalignment between static old features and the
dynamically changing feature manifold causes severe catastrophic forgetting. To
address this novel problem, we propose Manifold-Aligned Graph Regularization
(MAGR), which first aligns deviated old features to the current feature
manifold, ensuring representation consistency. It then constructs a graph
jointly arranging old and new features aligned with quality scores. Experiments
show MAGR outperforms recent strong baselines with up to 6.56%, 5.66%, 15.64%,
and 9.05% correlation gains on the MTL-AQA, FineDiving, UNLV-Dive, and JDM-MSA
split datasets, respectively. This validates MAGR for continual assessment
challenges arising from non-stationary skill variations.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04399" title="Abstract">arXiv:2403.04399</a> [<a href="/pdf/2403.04399" title="Download PDF">pdf</a>, <a href="/format/2403.04399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The 2nd Workshop on Recommendation with Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xinyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The rise of generative models has driven significant advancements in
recommender systems, leaving unique opportunities for enhancing users'
personalized recommendations. This workshop serves as a platform for
researchers to explore and exchange innovative concepts related to the
integration of generative models into recommender systems. It primarily focuses
on five key perspectives: (i) improving recommender algorithms, (ii) generating
personalized content, (iii) evolving the user-system interaction paradigm, (iv)
enhancing trustworthiness checks, and (v) refining evaluation methodologies for
generative recommendations. With generative models advancing rapidly, an
increasing body of research is emerging in these domains, underscoring the
timeliness and critical importance of this workshop. The related research will
introduce innovative technologies to recommender systems and contribute to
fresh challenges in both academia and industry. In the long term, this research
direction has the potential to revolutionize the traditional recommender
paradigms and foster the development of next-generation recommender systems.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04400" title="Abstract">arXiv:2403.04400</a> [<a href="/pdf/2403.04400" title="Download PDF">pdf</a>, <a href="/format/2403.04400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Continual Learning of Compositional Generalization in NLI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiyan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+A">Anette Frank</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Compositional Natural Language Inference has been explored to assess the true
abilities of neural models to perform NLI. Yet, current evaluations assume
models to have full access to all primitive inferences in advance, in contrast
to humans that continuously acquire inference knowledge. In this paper, we
introduce the Continual Compositional Generalization in Inference (C2Gen NLI)
challenge, where a model continuously acquires knowledge of constituting
primitive inference tasks as a basis for compositional inferences. We explore
how continual learning affects compositional generalization in NLI, by
designing a continual learning setup for compositional NLI inference tasks. Our
experiments demonstrate that models fail to compositionally generalize in a
continual scenario. To address this problem, we first benchmark various
continual learning algorithms and verify their efficacy. We then further
analyze C2Gen, focusing on how to order primitives and compositional inference
types and examining correlations between subtasks. Our analyses show that by
learning subtasks continuously while observing their dependencies and
increasing degrees of difficulty, continual learning can enhance composition
generalization ability.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04403" title="Abstract">arXiv:2403.04403</a> [<a href="/pdf/2403.04403" title="Download PDF">pdf</a>, <a href="/format/2403.04403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conjugate operators for transparent, explorable research outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bond%2C+J">Joseph Bond</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+C">Cristina David</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Orchard%2C+D">Dominic Orchard</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+R">Roly Perera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Charts, figures, and text derived from data play an important role in
decision making, from data-driven policy development to day-to-day choices
informed by online articles. Making sense of, or fact-checking, outputs means
understanding how they relate to the underlying data. Even for domain experts
with access to the source code and data sets, this poses a significant
challenge. In this paper we introduce a new program analysis framework which
supports interactive exploration of fine-grained I/O relationships directly
through computed outputs, making use of dynamic dependence graphs. Our main
contribution is a novel notion in data provenance which we call related inputs,
a relation of mutual relevance or "cognacy" which arises between inputs when
they contribute to common features of the output. Queries of this form allow
readers to ask questions like "What outputs use this data element, and what
other data elements are used along with it?". We show how Jonsson and Tarski's
concept of conjugate operators on Boolean algebras appropriately characterises
the notion of cognacy in a dependence graph, and give a procedure for computing
related inputs over such a graph.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04407" title="Abstract">arXiv:2403.04407</a> [<a href="/pdf/2403.04407" title="Download PDF">pdf</a>, <a href="/ps/2403.04407" title="Download PostScript">ps</a>, <a href="/format/2403.04407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Markov chain quasi-Monte Carlo for Gibbs samplers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Du%2C+J">Jiarui Du</a>, 
<a href="/search/math?searchtype=author&query=He%2C+Z">Zhijian He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In statistical analysis, Monte Carlo (MC) stands as a classical numerical
integration method. When encountering challenging sample problem, Markov chain
Monte Carlo (MCMC) is a commonly employed method. However, the MCMC estimator
is biased after a fixed number of iterations. Unbiased MCMC, an advancement
achieved through coupling techniques, addresses this bias issue in MCMC.
However, its variance retains the traditional $O(N^{-1/2})$ convergence rate.
Quasi-Monte Carlo (QMC), known for its high order of convergence, is an
alternative of MC. By incorporating the idea of QMC into MCMC, Markov chain
quasi-Monte Carlo (MCQMC) effectively reduces the variance of MCMC, especially
in Gibbs samplers. This work presents a novel approach that integrates unbiased
MCMC with MCQMC, called as an unbiased MCQMC method. This method renders
unbiased estimators while improving the rate of convergence significantly.
Numerical experiments demonstrate that the unbiased MCQMC method yields a
substantial reduction in variance compared to unbiased MCMC in several Gibbs
sampling problems. Particularly, unbiased MCQMC achieves convergence rates of
approximately $O(N^{-1})$ in moderate dimensions.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04410" title="Abstract">arXiv:2403.04410</a> [<a href="/pdf/2403.04410" title="Download PDF">pdf</a>, <a href="/format/2403.04410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Cybersecurity Using Blockchain: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miller%2C+L">Lo&#xef;c Miller</a>, 
<a href="/search/cs?searchtype=author&query=Pahl%2C+M">Marc-Oliver Pahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Collaborative cybersecurity relies on organizations sharing information to
boost security, but trust management is a key concern. Decentralized solutions
like distributed ledgers, particularly blockchain, are crucial for eliminating
single points of failure. However, the existing literature on blockchain-based
collaborative cybersecurity is limited, lacking comprehensive insights. This
paper addresses this gap by surveying blockchain's role in collaborative
cybersecurity from 2016 to 2023. It explores various applications, trends, and
the evolution of blockchain technology, focusing on access control, data
validation policies, underlying tech, and consensus mechanisms. A key finding
is the fragmentation of the field with no dominant research group or venue.
Many recent projects poorly select consensus protocols for their blockchain. To
aid researchers and practitioners, this paper offers guidelines for choosing
the right blockchain for specific purposes and highlights open research areas
and lessons learned from past blockchain applications in collaborative
cybersecurity, encouraging further exploration in this field.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04414" title="Abstract">arXiv:2403.04414</a> [<a href="/pdf/2403.04414" title="Download PDF">pdf</a>, <a href="/format/2403.04414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A methodology to automatically optimize dynamic memory managers applying  grammatical evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Risco-Mart%C3%ADn%2C+J+L">Jos&#xe9; L. Risco-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Colmenar%2C+J+M">J. Manuel Colmenar</a>, 
<a href="/search/cs?searchtype=author&query=Hidalgo%2C+J+I">J. Ignacio Hidalgo</a>, 
<a href="/search/cs?searchtype=author&query=Lanchares%2C+J">Juan Lanchares</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+J">Josefa D&#xed;az</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Systems and Software, 91, pp. 109-123, 2014
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Modern consumer devices must execute multimedia applications that exhibit
high resource utilization. In order to efficiently execute these applications,
the dynamic memory subsystem needs to be optimized. This complex task can be
tackled in two complementary ways: optimizing the application source code or
designing custom dynamic memory management mechanisms. Currently, the first
approach has been well established, and several automatic methodologies have
been proposed. Regarding the second approach, software engineers often write
custom dynamic memory managers from scratch, which is a difficult and
error-prone work. This paper presents a novel way to automatically generate
custom dynamic memory managers optimizing both performance and memory usage of
the target application. The design space is pruned using grammatical evolution
converging to the best dynamic memory manager implementation for the target
application. Our methodology achieves important improvements (62.55\% and
30.62\% better on average in performance and memory usage, respectively) when
its results are compared to five different general-purpose dynamic memory
managers.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04416" title="Abstract">arXiv:2403.04416</a> [<a href="/pdf/2403.04416" title="Download PDF">pdf</a>, <a href="/format/2403.04416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iTRPL: An Intelligent and Trusted RPL Protocol based on Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+D">Debasmita Dey</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+N">Nirnay Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Routing Protocol for Low Power and Lossy Networks (RPL) is the de-facto
routing standard in IoT networks. It enables nodes to collaborate and
autonomously build ad-hoc networks modeled by tree-like destination-oriented
direct acyclic graphs (DODAG). Despite its widespread usage in industry and
healthcare domains, RPL is susceptible to insider attacks. Although the
state-of-the-art RPL ensures that only authenticated nodes participate in
DODAG, such hard security measures are still inadequate to prevent insider
threats. This entails a need to integrate soft security mechanisms to support
decision-making. This paper proposes iTRPL, an intelligent and behavior-based
framework that incorporates trust to segregate honest and malicious nodes
within a DODAG. It also leverages multi-agent reinforcement learning (MARL) to
make autonomous decisions concerning the DODAG. The framework enables a parent
node to compute the trust for its child and decide if the latter can join the
DODAG. It tracks the behavior of the child node, updates the trust, computes
the rewards (or penalties), and shares with the root. The root aggregates the
rewards/penalties of all nodes, computes the overall return, and decides via
its $\epsilon$-Greedy MARL module if the DODAG will be retained or modified for
the future. A simulation-based performance evaluation demonstrates that iTRPL
learns to make optimal decisions with time.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04417" title="Abstract">arXiv:2403.04417</a> [<a href="/pdf/2403.04417" title="Download PDF">pdf</a>, <a href="/ps/2403.04417" title="Download PostScript">ps</a>, <a href="/format/2403.04417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promising and worth-to-try future directions for advancing  state-of-the-art surrogates methods of agent-based models in social and  health computational sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsheikh%2C+A">Atiyah Elsheikh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">The execution and runtime performance of model-based analysis tools for
realistic large-scale ABMs (Agent-Based Models) can be excessively long. This
due to the computational demand exponentially proportional to the model size
(e.g. Population size) and the number of model parameters. Even the runtime of
a single simulation of a realistic ABM may demand huge computational resources
when attempting to employ realistic population size. The main aim of this
ad-hoc brief report is to highlight some of surrogate models that were adequate
and computationally less demanding for nonlinear dynamical models in various
modeling application areas.To the author knowledge, these methods have been
not, at least extensively, employed for ABMs within the field of (SHCS) Social
Health Computational Sciences, yet. Thus, they might be, but not necessarily,
useful in progressing state of the art for establishing surrogate models for
ABMs in the field of SHCS.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04419" title="Abstract">arXiv:2403.04419</a> [<a href="/pdf/2403.04419" title="Download PDF">pdf</a>, <a href="/format/2403.04419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling A Hidden Risk: Exposing Educational but Malicious Repositories  in GitHub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masud%2C+M+R">Md Rayhanul Masud</a> (University of California, Riverside), 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+M">Michalis Faloutsos</a> (University of California, Riverside)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Are malicious repositories hiding under the educational label in GitHub?
Recent studies have identified collections of GitHub repositories hosting
malware source code with notable collaboration among the developers. Thus,
analyzing GitHub repositories deserves inevitable attention due to its
open-source nature providing easy access to malicious software code and
artifacts. Here we leverage the capabilities of ChatGPT in a qualitative study
to annotate an educational GitHub repository based on maliciousness of its
metadata contents. Our contribution is twofold. First, we demonstrate the
employment of ChatGPT to understand and annotate the content published in
software repositories. Second, we provide evidence of hidden risk in
educational repositories contributing to the opportunities of potential threats
and malicious intents. We carry out a systematic study on a collection of 35.2K
GitHub repositories claimed to be created for educational purposes only. First,
our study finds an increasing trend in the number of such repositories
published every year. Second, 9294 of them are labeled by ChatGPT as malicious,
and further categorization of the malicious ones detects 14 different malware
families including DDoS, keylogger, ransomware and so on. Overall, this
exploratory study flags a wake-up call for the community for better
understanding and analysis of software platforms.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04427" title="Abstract">arXiv:2403.04427</a> [<a href="/pdf/2403.04427" title="Download PDF">pdf</a>, <a href="/format/2403.04427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment-driven prediction of financial returns: a Bayesian-enhanced  FinBERT approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cestari%2C+R+G">Raffaele Giuseppe Cestari</a>, 
<a href="/search/cs?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version exposed at XXV Workshop on Quantitative Finance Bologna (Italy), April 11-13 2024 (not peer reviewed but accepted for the workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting financial returns accurately poses a significant challenge due to
the inherent uncertainty in financial time series data. Enhancing prediction
models' performance hinges on effectively capturing both social and financial
sentiment. In this study, we showcase the efficacy of leveraging sentiment
information extracted from tweets using the FinBERT large language model. By
meticulously curating an optimal feature set through correlation analysis and
employing Bayesian-optimized Recursive Feature Elimination for automatic
feature selection, we surpass existing methodologies, achieving an F1-score
exceeding 70% on the test set. This success translates into demonstrably higher
cumulative profits during backtested trading. Our investigation focuses on
real-world SPY ETF data alongside corresponding tweets sourced from the
StockTwits platform.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04429" title="Abstract">arXiv:2403.04429</a> [<a href="/pdf/2403.04429" title="Download PDF">pdf</a>, <a href="/format/2403.04429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Influence of Dimensionality Reduction on Anomaly Detection  Performance in Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altin%2C+M">Mahsun Altin</a>, 
<a href="/search/cs?searchtype=author&query=Cakir%2C+A">Altan Cakir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper presents an extensive empirical study on the integration of
dimensionality reduction techniques with advanced unsupervised time series
anomaly detection models, focusing on the MUTANT and Anomaly-Transformer
models. The study involves a comprehensive evaluation across three different
datasets: MSL, SMAP, and SWaT. Each dataset poses unique challenges, allowing
for a robust assessment of the models' capabilities in varied contexts. The
dimensionality reduction techniques examined include PCA, UMAP, Random
Projection, and t-SNE, each offering distinct advantages in simplifying
high-dimensional data. Our findings reveal that dimensionality reduction not
only aids in reducing computational complexity but also significantly enhances
anomaly detection performance in certain scenarios. Moreover, a remarkable
reduction in training times was observed, with reductions by approximately
300\% and 650\% when dimensionality was halved and minimized to the lowest
dimensions, respectively. This efficiency gain underscores the dual benefit of
dimensionality reduction in both performance enhancement and operational
efficiency. The MUTANT model exhibits notable adaptability, especially with
UMAP reduction, while the Anomaly-Transformer demonstrates versatility across
various reduction techniques. These insights provide a deeper understanding of
the synergistic effects of dimensionality reduction and anomaly detection,
contributing valuable perspectives to the field of time series analysis. The
study underscores the importance of selecting appropriate dimensionality
reduction strategies based on specific model requirements and dataset
characteristics, paving the way for more efficient, accurate, and scalable
solutions in anomaly detection.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04430" title="Abstract">arXiv:2403.04430</a> [<a href="/pdf/2403.04430" title="Download PDF">pdf</a>, <a href="/format/2403.04430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-demand Quantization for Green Federated Generative Diffusion in  Mobile Edge Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+B">Bingkun Lai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayi He</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gaolei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minrui Xu</a>, 
<a href="/search/cs?searchtype=author&query=zhang%2C+T">Tao zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shengli Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Generative Artificial Intelligence (GAI) shows remarkable productivity and
creativity in Mobile Edge Networks, such as the metaverse and the Industrial
Internet of Things. Federated learning is a promising technique for effectively
training GAI models in mobile edge networks due to its data distribution.
However, there is a notable issue with communication consumption when training
large GAI models like generative diffusion models in mobile edge networks.
Additionally, the substantial energy consumption associated with training
diffusion-based models, along with the limited resources of edge devices and
complexities of network environments, pose challenges for improving the
training efficiency of GAI models. To address this challenge, we propose an
on-demand quantized energy-efficient federated diffusion approach for mobile
edge networks. Specifically, we first design a dynamic quantized federated
diffusion training scheme considering various demands from the edge devices.
Then, we study an energy efficiency problem based on specific quantization
requirements. Numerical results show that our proposed method significantly
reduces system energy consumption and transmitted model size compared to both
baseline federated diffusion and fixed quantized federated diffusion methods
while effectively maintaining reasonable quality and diversity of generated
data.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04431" title="Abstract">arXiv:2403.04431</a> [<a href="/pdf/2403.04431" title="Download PDF">pdf</a>, <a href="/ps/2403.04431" title="Download PostScript">ps</a>, <a href="/format/2403.04431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Fairness and Robustness in Over-the-Air Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oksuz%2C+H+Y">Halil Yigit Oksuz</a>, 
<a href="/search/cs?searchtype=author&query=Molinari%2C+F">Fabio Molinari</a>, 
<a href="/search/cs?searchtype=author&query=Sprekeler%2C+H">Henning Sprekeler</a>, 
<a href="/search/cs?searchtype=author&query=Raisch%2C+J">Joerg Raisch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 2 figures. arXiv admin note: text overlap with <a href="/abs/2305.04630">arXiv:2305.04630</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Over-the-Air Computation is a beyond-5G communication strategy that has
recently been shown to be useful for the decentralized training of machine
learning models due to its efficiency. In this paper, we propose an
Over-the-Air federated learning algorithm that aims to provide fairness and
robustness through minmax optimization. By using the epigraph form of the
problem at hand, we show that the proposed algorithm converges to the optimal
solution of the minmax problem. Moreover, the proposed approach does not
require reconstructing channel coefficients by complex encoding-decoding
schemes as opposed to state-of-the-art approaches. This improves both
efficiency and privacy.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04435" title="Abstract">arXiv:2403.04435</a> [<a href="/pdf/2403.04435" title="Download PDF">pdf</a>, <a href="/format/2403.04435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pilot Spoofing Attack on the Downlink of Cell-Free Massive MIMO: From  the Perspective of Adversaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wei Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The channel hardening effect is less pronounced in the cell-free massive
multiple-input multiple-output (mMIMO) system compared to its cellular
counterpart, making it necessary to estimate the downlink effective channel
gains to ensure decent performance. However, the downlink training
inadvertently creates an opportunity for adversarial nodes to launch pilot
spoofing attacks (PSAs). First, we demonstrate that adversarial distributed
access points (APs) can severely degrade the achievable downlink rate. They
achieve this by estimating their channels to users in the uplink training phase
and then precoding and sending the same pilot sequences as those used by
legitimate APs during the downlink training phase. Then, the impact of the
downlink PSA is investigated by rigorously deriving a closed-form expression of
the per-user achievable downlink rate. By employing the min-max criterion to
optimize the power allocation coefficients, the maximum per-user achievable
rate of downlink transmission is minimized from the perspective of adversarial
APs. As an alternative to the downlink PSA, adversarial APs may opt to precode
random interference during the downlink data transmission phase in order to
disrupt legitimate communications. In this scenario, the achievable downlink
rate is derived, and then power optimization algorithms are also developed. We
present numerical results to showcase the detrimental impact of the downlink
PSA and compare the effects of these two types of attacks.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04436" title="Abstract">arXiv:2403.04436</a> [<a href="/pdf/2403.04436" title="Download PDF">pdf</a>, <a href="/format/2403.04436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tairan He</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhengyi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wenli Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://human2humanoid.com/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We present Human to Humanoid (H2O), a reinforcement learning (RL) based
framework that enables real-time whole-body teleoperation of a full-sized
humanoid robot with only an RGB camera. To create a large-scale retargeted
motion dataset of human movements for humanoid robots, we propose a scalable
"sim-to-data" process to filter and pick feasible motions using a privileged
motion imitator. Afterwards, we train a robust real-time humanoid motion
imitator in simulation using these refined motions and transfer it to the real
humanoid robot in a zero-shot manner. We successfully achieve teleoperation of
dynamic whole-body motions in real-world scenarios, including walking, back
jumping, kicking, turning, waving, pushing, boxing, etc. To the best of our
knowledge, this is the first demonstration to achieve learning-based real-time
whole-body humanoid teleoperation.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04437" title="Abstract">arXiv:2403.04437</a> [<a href="/pdf/2403.04437" title="Download PDF">pdf</a>, <a href="/format/2403.04437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableDrag: Stable Dragging for Point-based Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yutao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaotong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guozhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shengming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point-based image editing has attracted remarkable attention since the
emergence of DragGAN. Recently, DragDiffusion further pushes forward the
generative quality via adapting this dragging technique to diffusion models.
Despite these great success, this dragging scheme exhibits two major drawbacks,
namely inaccurate point tracking and incomplete motion supervision, which may
result in unsatisfactory dragging outcomes. To tackle these issues, we build a
stable and precise drag-based editing framework, coined as StableDrag, by
designing a discirminative point tracking method and a confidence-based latent
enhancement strategy for motion supervision. The former allows us to precisely
locate the updated handle points, thereby boosting the stability of long-range
manipulation, while the latter is responsible for guaranteeing the optimized
latent as high-quality as possible across all the manipulation steps. Thanks to
these unique designs, we instantiate two types of image editing models
including StableDrag-GAN and StableDrag-Diff, which attains more stable
dragging performance, through extensive qualitative experiments and
quantitative assessment on DragBench.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04440" title="Abstract">arXiv:2403.04440</a> [<a href="/pdf/2403.04440" title="Download PDF">pdf</a>, <a href="/format/2403.04440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboKube: Establishing a New Foundation for the Cloud Native Evolution  in Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Herranz%2C+A+H">Aitor Hernandez Herranz</a>, 
<a href="/search/cs?searchtype=author&query=Sundin%2C+R+C">Roberto C. Sundin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 10th International Conference on Automation, Robotics, and Applications (ICARA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Cloud native technologies have been observed to expand into the realm of
Internet of Things (IoT) and Cyber-physical Systems, of which an important
application domain is robotics. In this paper, we review the cloudification
practice in the robotics domain from both literature and industrial
perspectives. We propose RoboKube, an adaptive framework that is based on the
Kubernetes (K8s) ecosystem to set up a common platform across the device-cloud
continuum for the deployment of cloudified Robotic Operating System (ROS)
powered applications, to facilitate the cloud native evolution in robotics. We
examine the process of modernizing ROS applications using cloud-native
technologies, focusing on both the platform and application perspectives. In
addition, we address the challenges of networking setups for heterogeneous
environments. This paper intends to serves as a guide for developers and
researchers, offering insights into containerization strategies, ROS node
distribution and clustering, and deployment options. To demonstrate the
feasibility of our approach, we present a case study involving the
cloudification of a teleoperation testbed.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04442" title="Abstract">arXiv:2403.04442</a> [<a href="/pdf/2403.04442" title="Download PDF">pdf</a>, <a href="/format/2403.04442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Bayesian Optimization for Imperfect Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoshvishkaie%2C+A">Ali Khoshvishkaie</a>, 
<a href="/search/cs?searchtype=author&query=Mikkola%2C+P">Petrus Mikkola</a>, 
<a href="/search/cs?searchtype=author&query=Murena%2C+P">Pierre-Alexandre Murena</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases, ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We introduce a cooperative Bayesian optimization problem for optimizing
black-box functions of two variables where two agents choose together at which
points to query the function but have only control over one variable each. This
setting is inspired by human-AI teamwork, where an AI-assistant helps its human
user solve a problem, in this simplest case, collaborative optimization. We
formulate the solution as sequential decision-making, where the agent we
control models the user as a computationally rational agent with prior
knowledge about the function. We show that strategic planning of the queries
enables better identification of the global maximum of the function as long as
the user avoids excessive exploration. This planning is made possible by using
Bayes Adaptive Monte Carlo planning and by endowing the agent with a user model
that accounts for conservative belief updates and exploratory sampling of the
points to query.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04443" title="Abstract">arXiv:2403.04443</a> [<a href="/pdf/2403.04443" title="Download PDF">pdf</a>, <a href="/format/2403.04443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FriendNet: Detection-Friendly Dehazing Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yihua Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongzhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mingqiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F+L">Fu Lee Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adverse weather conditions often impair the quality of captured images,
inevitably inducing cutting-edge object detection models for advanced driver
assistance systems (ADAS) and autonomous driving. In this paper, we raise an
intriguing question: can the combination of image restoration and object
detection enhance detection performance in adverse weather conditions? To
answer it, we propose an effective architecture that bridges image dehazing and
object detection together via guidance information and task-driven learning to
achieve detection-friendly dehazing, termed FriendNet. FriendNet aims to
deliver both high-quality perception and high detection capacity. Different
from existing efforts that intuitively treat image dehazing as pre-processing,
FriendNet establishes a positive correlation between these two tasks. Clean
features generated by the dehazing network potentially contribute to
improvements in object detection performance. Conversely, object detection
crucially guides the learning process of the image dehazing network under the
task-driven learning scheme. We shed light on how downstream tasks can guide
upstream dehazing processes, considering both network architecture and learning
objectives. We design Guidance Fusion Block (GFB) and Guidance Attention Block
(GAB) to facilitate the integration of detection information into the network.
Furthermore, the incorporation of the detection task loss aids in refining the
optimization process. Additionally, we introduce a new Physics-aware Feature
Enhancement Block (PFEB), which integrates physics-based priors to enhance the
feature extraction and representation capabilities. Extensive experiments on
synthetic and real-world datasets demonstrate the superiority of our method
over state-of-the-art methods on both image quality and detection precision.
Our source code is available at https://github.com/fanyihua0309/FriendNet.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04444" title="Abstract">arXiv:2403.04444</a> [<a href="/pdf/2403.04444" title="Download PDF">pdf</a>, <a href="/format/2403.04444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Diffusion-Based 3D Human Pose Estimation with Hierarchical  Spatial and Temporal Denoiser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qingyuan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuecai Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Saihui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Li Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongzhen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, diffusion-based methods for monocular 3D human pose estimation have
achieved state-of-the-art (SOTA) performance by directly regressing the 3D
joint coordinates from the 2D pose sequence. Although some methods decompose
the task into bone length and bone direction prediction based on the human
anatomical skeleton to explicitly incorporate more human body prior
constraints, the performance of these methods is significantly lower than that
of the SOTA diffusion-based methods. This can be attributed to the tree
structure of the human skeleton. Direct application of the disentangled method
could amplify the accumulation of hierarchical errors, propagating through each
hierarchy. Meanwhile, the hierarchical information has not been fully explored
by the previous methods. To address these problems, a Disentangled
Diffusion-based 3D Human Pose Estimation method with Hierarchical Spatial and
Temporal Denoiser is proposed, termed DDHPose. In our approach: (1) We
disentangle the 3D pose and diffuse the bone length and bone direction during
the forward process of the diffusion model to effectively model the human pose
prior. A disentanglement loss is proposed to supervise diffusion model
learning. (2) For the reverse process, we propose Hierarchical Spatial and
Temporal Denoiser (HSTDenoiser) to improve the hierarchical modeling of each
joint. Our HSTDenoiser comprises two components: the Hierarchical-Related
Spatial Transformer (HRST) and the Hierarchical-Related Temporal Transformer
(HRTT). HRST exploits joint spatial information and the influence of the parent
joint on each joint for spatial modeling, while HRTT utilizes information from
both the joint and its hierarchical adjacent joints to explore the hierarchical
temporal correlations among joints.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04445" title="Abstract">arXiv:2403.04445</a> [<a href="/pdf/2403.04445" title="Download PDF">pdf</a>, <a href="/format/2403.04445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classist Tools: Social Class Correlates with Performance in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Curry%2C+A+C">Amanda Cercas Curry</a>, 
<a href="/search/cs?searchtype=author&query=Attanasio%2C+G">Giuseppe Attanasio</a>, 
<a href="/search/cs?searchtype=author&query=Talat%2C+Z">Zeerak Talat</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Since the foundational work of William Labov on the social stratification of
language (Labov, 1964), linguistics has made concentrated efforts to explore
the links between sociodemographic characteristics and language production and
perception. But while there is strong evidence for socio-demographic
characteristics in language, they are infrequently used in Natural Language
Processing (NLP). Age and gender are somewhat well represented, but Labov's
original target, socioeconomic status, is noticeably absent. And yet it
matters. We show empirically that NLP disadvantages less-privileged
socioeconomic groups. We annotate a corpus of 95K utterances from movies with
social class, ethnicity and geographical language variety and measure the
performance of NLP systems on three tasks: language modelling, automatic speech
recognition, and grammar error correction. We find significant performance
disparities that can be attributed to socioeconomic status as well as ethnicity
and geographical differences. With NLP technologies becoming ever more
ubiquitous and quotidian, they must accommodate all language varieties to avoid
disadvantaging already marginalised groups. We argue for the inclusion of
socioeconomic class in future language technologies.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04447" title="Abstract">arXiv:2403.04447</a> [<a href="/pdf/2403.04447" title="Download PDF">pdf</a>, <a href="/ps/2403.04447" title="Download PostScript">ps</a>, <a href="/format/2403.04447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRRI: a novel algorithm for fuzzy-rough rule induction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bollaert%2C+H">Henri Bollaert</a>, 
<a href="/search/cs?searchtype=author&query=Palangeti%C4%87%2C+M">Marko Palangeti&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cornelis%2C+C">Chris Cornelis</a>, 
<a href="/search/cs?searchtype=author&query=Greco%2C+S">Salvatore Greco</a>, 
<a href="/search/cs?searchtype=author&query=S%C5%82owi%C5%84ski%2C+R">Roman S&#x142;owi&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interpretability is the next frontier in machine learning research. In the
search for white box models - as opposed to black box models, like random
forests or neural networks - rule induction algorithms are a logical and
promising option, since the rules can easily be understood by humans. Fuzzy and
rough set theory have been successfully applied to this archetype, almost
always separately. As both approaches to rule induction involve granular
computing based on the concept of equivalence classes, it is natural to combine
them. The QuickRules\cite{JensenCornelis2009} algorithm was a first attempt at
using fuzzy rough set theory for rule induction. It is based on QuickReduct, a
greedy algorithm for building decision reducts. QuickRules already showed an
improvement over other rule induction methods. However, to evaluate the full
potential of a fuzzy rough rule induction algorithm, one needs to start from
the foundations. In this paper, we introduce a novel rule induction algorithm
called Fuzzy Rough Rule Induction (FRRI). We provide background and explain the
workings of our algorithm. Furthermore, we perform a computational experiment
to evaluate the performance of our algorithm and compare it to other
state-of-the-art rule induction approaches. We find that our algorithm is more
accurate while creating small rulesets consisting of relatively short rules. We
end the paper by outlining some directions for future work.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04448" title="Abstract">arXiv:2403.04448</a> [<a href="/pdf/2403.04448" title="Download PDF">pdf</a>, <a href="/ps/2403.04448" title="Download PostScript">ps</a>, <a href="/format/2403.04448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-discrete derivative-free extended Kalman filter based on  Euler-Maruyama and It&#xf4;-Taylor discretizations: Conventional and  square-root implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kulikova%2C+M+V">Maria V. Kulikova</a>, 
<a href="/search/math?searchtype=author&query=Kulikov%2C+G+Y">Gennady Yu. Kulikov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> European Journal of Control, 76: 100960, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we continue to study the derivative-free extended Kalman
filtering (DF-EKF) framework for state estimation of continuous-discrete
nonlinear stochastic systems. Having considered the Euler-Maruyama and
It\^{o}-Taylor discretization schemes for solving stochastic differential
equations, we derive the related filters' moment equations based on the
derivative-free EKF principal. In contrast to the recently derived MATLAB-based
continuous-discrete DF-EKF techniques, the novel DF-EKF methods preserve an
information about the underlying stochastic process and provide the estimation
procedure for a fixed number of iterates at the propagation steps.
Additionally, the DF-EKF approach is particularly effective for working with
stochastic systems with highly nonlinear and/or nondifferentiable drift and
observation functions, but the price to be paid is its degraded numerical
stability (to roundoff) compared to the standard EKF framework. To eliminate
the mentioned pitfall of the derivative-free EKF methodology, we develop the
conventional algorithms together with their stable square-root implementation
methods. In contrast to the published DF-EKF results, the new square-root
techniques are derived within both the Cholesky and singular value
decompositions. A performance of the novel filters is demonstrated on a number
of numerical tests including well- and ill-conditioned scenarios.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04449" title="Abstract">arXiv:2403.04449</a> [<a href="/pdf/2403.04449" title="Download PDF">pdf</a>, <a href="/format/2403.04449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback-Generation for Programming Exercises With GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azaiz%2C+I">Imen Azaiz</a>, 
<a href="/search/cs?searchtype=author&query=Kiesler%2C+N">Natalie Kiesler</a>, 
<a href="/search/cs?searchtype=author&query=Strickroth%2C+S">Sven Strickroth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ITiCSE 2024, Milan, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Ever since Large Language Models (LLMs) and related applications have become
broadly available, several studies investigated their potential for assisting
educators and supporting students in higher education. LLMs such as Codex,
GPT-3.5, and GPT 4 have shown promising results in the context of large
programming courses, where students can benefit from feedback and hints if
provided timely and at scale. This paper explores the quality of GPT-4 Turbo's
generated output for prompts containing both the programming task specification
and a student's submission as input. Two assignments from an introductory
programming course were selected, and GPT-4 was asked to generate feedback for
55 randomly chosen, authentic student programming submissions. The output was
qualitatively analyzed regarding correctness, personalization, fault
localization, and other features identified in the material. Compared to prior
work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements. For
example, the output is more structured and consistent. GPT-4 Turbo can also
accurately identify invalid casing in student programs' output. In some cases,
the feedback also includes the output of the student program. At the same time,
inconsistent feedback was noted such as stating that the submission is correct
but an error needs to be fixed. The present work increases our understanding of
LLMs' potential, limitations, and how to integrate them into e-assessment
systems, pedagogical scenarios, and instructing students who are using
applications based on GPT-4.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04451" title="Abstract">arXiv:2403.04451</a> [<a href="/pdf/2403.04451" title="Download PDF">pdf</a>, <a href="/format/2403.04451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Membership Inference Attacks and Privacy in Topic Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manzonelli%2C+N">Nico Manzonelli</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vadhan%2C+S">Salil Vadhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages + appendices and references. 9 figures. Submitted to USENIX '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent research shows that large language models are susceptible to privacy
attacks that infer aspects of the training data. However, it is unclear if
simpler generative models, like topic models, share similar vulnerabilities. In
this work, we propose an attack against topic models that can confidently
identify members of the training data in Latent Dirichlet Allocation. Our
results suggest that the privacy risks associated with generative modeling are
not restricted to large neural models. Additionally, to mitigate these
vulnerabilities, we explore differentially private (DP) topic modeling. We
propose a framework for private topic modeling that incorporates DP vocabulary
selection as a pre-processing step, and show that it improves privacy while
having limited effects on practical utility.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04453" title="Abstract">arXiv:2403.04453</a> [<a href="/pdf/2403.04453" title="Download PDF">pdf</a>, <a href="/format/2403.04453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vlearn: Off-Policy Learning with Efficient State-Value Function  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Otto%2C+F">Fabian Otto</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+P">Philipp Becker</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+V+A">Vien Ang Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+G">Gerhard Neumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Existing off-policy reinforcement learning algorithms typically necessitate
an explicit state-action-value function representation, which becomes
problematic in high-dimensional action spaces. These algorithms often encounter
challenges where they struggle with the curse of dimensionality, as maintaining
a state-action-value function in such spaces becomes data-inefficient. In this
work, we propose a novel off-policy trust region optimization approach, called
Vlearn, that eliminates the requirement for an explicit state-action-value
function. Instead, we demonstrate how to efficiently leverage just a
state-value function as the critic, thus overcoming several limitations of
existing methods. By doing so, Vlearn addresses the computational challenges
posed by high-dimensional action spaces. Furthermore, Vlearn introduces an
efficient approach to address the challenges associated with pure state-value
function learning in the off-policy setting. This approach not only simplifies
the implementation of off-policy policy gradient algorithms but also leads to
consistent and robust performance across various benchmark tasks. Specifically,
by removing the need for a state-action-value function Vlearn simplifies the
learning process and allows for more efficient exploration and exploitation in
complex environments
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04454" title="Abstract">arXiv:2403.04454</a> [<a href="/pdf/2403.04454" title="Download PDF">pdf</a>, <a href="/format/2403.04454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Resource Court Judgment Summarization for Common Law Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiannong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yicong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruosong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhiyuan Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First submitted to Information Processing and Management on Oct. 29, 2023. Major Revision submitted on Mar.6, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Common law courts need to refer to similar precedents' judgments to inform
their current decisions. Generating high-quality summaries of court judgment
documents can facilitate legal practitioners to efficiently review previous
cases and assist the general public in accessing how the courts operate and how
the law is applied. Previous court judgment summarization research focuses on
civil law or a particular jurisdiction's judgments. However, judges can refer
to the judgments from all common law jurisdictions. Current summarization
datasets are insufficient to satisfy the demands of summarizing precedents
across multiple jurisdictions, especially when labeled data are scarce for many
jurisdictions. To address the lack of datasets, we present CLSum, the first
dataset for summarizing multi-jurisdictional common law court judgment
documents. Besides, this is the first court judgment summarization work
adopting large language models (LLMs) in data augmentation, summary generation,
and evaluation. Specifically, we design an LLM-based data augmentation method
incorporating legal knowledge. We also propose a legal knowledge enhanced
evaluation metric based on LLM to assess the quality of generated judgment
summaries. Our experimental results verify that the LLM-based summarization
methods can perform well in the few-shot and zero-shot settings. Our LLM-based
data augmentation method can mitigate the impact of low data resources.
Furthermore, we carry out comprehensive comparative experiments to find
essential model components and settings that are capable of enhancing
summarization performance.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04457" title="Abstract">arXiv:2403.04457</a> [<a href="/pdf/2403.04457" title="Download PDF">pdf</a>, <a href="/ps/2403.04457" title="Download PostScript">ps</a>, <a href="/format/2403.04457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of turbulent diffusion in modeling anaerobic digestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J+Z">Jeremy Z. Yan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Prashant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Rauch%2C+W">Wolfgang Rauch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this study, the impact of turbulent diffusion on mixing of biochemical
reaction models is explored by implementing and validating different models. An
original codebase called CHAD (Coupled Hydrodynamics and Anaerobic Digestion)
is extended to incorporate turbulent diffusion and validate it against results
from OpenFOAM with 2D Rayleigh-Taylor Instability and lid-driven cavity
simulations. The models are then tested for the applications with Anaerobic
Digestion - a widely used wastewater treatment method. The findings demonstrate
that the implemented models accurately capture turbulent diffusion when
provided with an accurate flow field. Specifically, a minor effect of chemical
turbulent diffusion on biochemical reactions within the anaerobic digestion
tank is observed, while thermal turbulent diffusion significantly influences
mixing. By successfully implementing turbulent diffusion models in CHAD, its
capabilities for more accurate anaerobic digestion simulations are enhanced,
aiding in optimizing the design and operation of anaerobic digestion reactors
in real-world wastewater treatment applications.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04460" title="Abstract">arXiv:2403.04460</a> [<a href="/pdf/2403.04460" title="Download PDF">pdf</a>, <a href="/format/2403.04460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pearl: A Review-driven Persona-Knowledge Grounded Conversational  Recommendation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minju Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hana Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+B">Beong-woo Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S">Soyeon Chun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunseo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">SeongKu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conversational recommender system is an emerging area that has garnered an
increasing interest in the community, especially with the advancements in large
language models (LLMs) that enable diverse reasoning over conversational input.
Despite the progress, the field has many aspects left to explore. The currently
available public datasets for conversational recommendation lack specific user
preferences and explanations for recommendations, hindering high-quality
recommendations. To address such challenges, we present a novel conversational
recommendation dataset named PEARL, synthesized with persona- and
knowledge-augmented LLM simulators. We obtain detailed persona and knowledge
from real-world reviews and construct a large-scale dataset with over 57k
dialogues. Our experimental results demonstrate that utterances in PEARL
include more specific user preferences, show expertise in the target domain,
and provide recommendations more relevant to the dialogue context than those in
prior datasets.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04467" title="Abstract">arXiv:2403.04467</a> [<a href="/pdf/2403.04467" title="Download PDF">pdf</a>, <a href="/ps/2403.04467" title="Download PostScript">ps</a>, <a href="/format/2403.04467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Magnetic Millirobot Walks on Slippery Biological Surfaces for Targeted  Cargo Delivery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Moonkwang Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiangzhou Tan</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+F">Felix Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tian Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Small-scale robots hold great potential for targeted cargo delivery in
minimally-inv asive medicine. However, current robots often face challenges to
locomote efficiently on slip pery biological tissue surfaces, especially when
loaded with heavy cargos. Here, we report a magnetic millirobot that can walk
on rough and slippery biological tissues by anchoring itself on the soft tissue
surface alternatingly with two feet and reciprocally rotating the body to mov e
forward. We experimentally studied the locomotion, validated it with numerical
simulations and optimized the actuation parameters to fit various terrains and
loading conditions. Further more, we developed a permanent magnet set-up to
enable wireless actuation within a huma n-scale volume which allows precise
control of the millirobot to follow complex trajectories, cl imb vertical
walls, and carry cargo up to four times of its own weight. Upon reaching the
targ et location, it performs a deployment sequence to release the liquid drug
into tissues. The ro bust gait of our millirobot on rough biological terrains,
combined with its heavy load capacity, make it a versatile and effective
miniaturized vehicle for targeted cargo delivery.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04468" title="Abstract">arXiv:2403.04468</a> [<a href="/pdf/2403.04468" title="Download PDF">pdf</a>, <a href="/format/2403.04468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Graph Neural Networks in Real world: Imbalance, Noise,  Privacy and OOD Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Siyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhiping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhengyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hourun Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Nan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Senzhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph-structured data exhibits universality and widespread applicability
across diverse domains, such as social network analysis, biochemistry,
financial fraud detection, and network security. Significant strides have been
made in leveraging Graph Neural Networks (GNNs) to achieve remarkable success
in these areas. However, in real-world scenarios, the training environment for
models is often far from ideal, leading to substantial performance degradation
of GNN models due to various unfavorable factors, including imbalance in data
distribution, the presence of noise in erroneous data, privacy protection of
sensitive information, and generalization capability for out-of-distribution
(OOD) scenarios. To tackle these issues, substantial efforts have been devoted
to improving the performance of GNN models in practical real-world scenarios,
as well as enhancing their reliability and robustness. In this paper, we
present a comprehensive survey that systematically reviews existing GNN models,
focusing on solutions to the four mentioned real-world challenges including
imbalance, noise, privacy, and OOD in practical scenarios that many existing
reviews have not considered. Specifically, we first highlight the four key
challenges faced by existing GNNs, paving the way for our exploration of
real-world GNN models. Subsequently, we provide detailed discussions on these
four aspects, dissecting how these solutions contribute to enhancing the
reliability and robustness of GNN models. Last but not least, we outline
promising directions and offer future perspectives in the field.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04471" title="Abstract">arXiv:2403.04471</a> [<a href="/pdf/2403.04471" title="Download PDF">pdf</a>, <a href="/ps/2403.04471" title="Download PostScript">ps</a>, <a href="/format/2403.04471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Shutdown Problem: Three Theorems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thornley%2C+E">Elliott Thornley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">I explain the shutdown problem: the problem of designing artificial agents
that (1) shut down when a shutdown button is pressed, (2) don't try to prevent
or cause the pressing of the shutdown button, and (3) otherwise pursue goals
competently. I prove three theorems that make the difficulty precise. These
theorems show that agents satisfying some innocuous-seeming conditions will
often try to prevent or cause the pressing of the shutdown button, even in
cases where it's costly to do so. And patience trades off against
shutdownability: the more patient an agent, the greater the costs that agent is
willing to incur to manipulate the shutdown button. I end by noting that these
theorems can guide our search for solutions.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04473" title="Abstract">arXiv:2403.04473</a> [<a href="/pdf/2403.04473" title="Download PDF">pdf</a>, <a href="/format/2403.04473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextMonkey: An OCR-Free Large Multimodal Model for Understanding  Document
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Biao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present TextMonkey, a large multimodal model (LMM) tailored for
text-centric tasks, including document question answering (DocVQA) and scene
text analysis. Our approach introduces enhancement across several dimensions:
by adopting Shifted Window Attention with zero-initialization, we achieve
cross-window connectivity at higher input resolutions and stabilize early
training; We hypothesize that images may contain redundant tokens, and by using
similarity to filter out significant tokens, we can not only streamline the
token length but also enhance the model's performance. Moreover, by expanding
our model's capabilities to encompass text spotting and grounding, and
incorporating positional information into responses, we enhance
interpretability and minimize hallucinations. Additionally, TextMonkey can be
finetuned to gain the ability to comprehend commands for clicking screenshots.
Overall, our method notably boosts performance across various benchmark
datasets, achieving increases of 5.2%, 6.9%, and 2.8% in Scene Text-Centric
VQA, Document Oriented VQA, and KIE, respectively, especially with a score of
561 on OCRBench, surpassing prior open-sourced large multimodal models for
document understanding. Code will be released at
https://github.com/Yuliang-Liu/Monkey.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04477" title="Abstract">arXiv:2403.04477</a> [<a href="/pdf/2403.04477" title="Download PDF">pdf</a>, <a href="/format/2403.04477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperparameter Tuning MLPs for Probabilistic Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madhusudhanan%2C+K">Kiran Madhusudhanan</a>, 
<a href="/search/cs?searchtype=author&query=Jawed%2C+S">Shayan Jawed</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, Accepted at PAKDD24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series forecasting attempts to predict future events by analyzing past
trends and patterns. Although well researched, certain critical aspects
pertaining to the use of deep learning in time series forecasting remain
ambiguous. Our research primarily focuses on examining the impact of specific
hyperparameters related to time series, such as context length and validation
strategy, on the performance of the state-of-the-art MLP model in time series
forecasting. We have conducted a comprehensive series of experiments involving
4800 configurations per dataset across 20 time series forecasting datasets, and
our findings demonstrate the importance of tuning these parameters.
Furthermore, in this work, we introduce the largest metadataset for timeseries
forecasting to date, named TSBench, comprising 97200 evaluations, which is a
twentyfold increase compared to previous works in the field. Finally, we
demonstrate the utility of the created metadataset on multi-fidelity
hyperparameter optimization tasks.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04479" title="Abstract">arXiv:2403.04479</a> [<a href="/pdf/2403.04479" title="Download PDF">pdf</a>, <a href="/format/2403.04479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Methane Intensity of Oil and Gas Upstream Activities by  Production Profile
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peyle%2C+Q">Quentin Peyle</a>, 
<a href="/search/cs?searchtype=author&query=Rejeb-Mzah%2C+I+B">Imene Ben Rejeb-Mzah</a>, 
<a href="/search/cs?searchtype=author&query=Piofret%2C+B">Baptiste Piofret</a>, 
<a href="/search/cs?searchtype=author&query=Benoit%2C+A">Antoine Benoit</a>, 
<a href="/search/cs?searchtype=author&query=d%27Aspremont%2C+A">Alexandre d&#x27;Aspremont</a>, 
<a href="/search/cs?searchtype=author&query=Yaalaoui%2C+A+E">Adil El Yaalaoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We propose a methodology for modelling methane intensities of Oil and Gas
upstream activities for different production profiles with diverse combinations
of region of operation and production volumes associated. This methodology
leverages different data sources, including satellite measurements and public
estimates of methane emissions but also country-level oil and gas production
data and company reporting. The obtained methane intensity models are compared
to the reference companies' own reporting in order to better understand methane
emissions for different types of companies. The results show that regions of
operation within the different production profiles have a significant impact on
the value of modelled methane intensities, especially for operators located in
a single or few countries, such as national and medium-sized international
operators. This paper also shows that methane intensities reported by the
companies tend to be on average 16.1 times smaller than that obtained using the
methodology presented here, and cannot account for total methane emissions that
are estimated for upstream operations in the different regions observed.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04480" title="Abstract">arXiv:2403.04480</a> [<a href="/pdf/2403.04480" title="Download PDF">pdf</a>, <a href="/format/2403.04480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The role of conformity in opinion dynamics modelling with multiple  social circles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=St%C4%99pie%C5%84%2C+S">Stanis&#x142;aw St&#x119;pie&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=Jankowski%2C+J">Jaros&#x142;aw Jankowski</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%B3dka%2C+P">Piotr Br&#xf3;dka</a>, 
<a href="/search/cs?searchtype=author&query=Michalski%2C+R">Rados&#x142;aw Michalski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCS 2023 - 23rd International Conference on Computational Science
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LNCS vol. 10475, pp. 33-47, ISSN 0302-9743, 2023, Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Interaction with others influences our opinions and behaviours. Our
activities within various social circles lead to different opinions expressed
in various situations, groups, and ways of communication. Earlier studies on
agent-based modelling of conformism within networks were based on a
single-layer approach. Contrary to that, in this work, we propose a model
incorporating conformism in which a person can share different continuous
opinions on different layers depending on the social circle. Afterwards, we
extend the model with more components that are known to influence opinions,
e.g. authority or openness to new views. These two models are then compared to
show that only sole conformism leads to opinion convergence.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04481" title="Abstract">arXiv:2403.04481</a> [<a href="/pdf/2403.04481" title="Download PDF">pdf</a>, <a href="/format/2403.04481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Large Language Model Understand Multi-Intent Spoken Language ?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shangjian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haojing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiatian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study marks a significant advancement by harnessing Large Language
Models (LLMs) for multi-intent spoken language understanding (SLU), proposing a
unique methodology that capitalizes on the generative power of LLMs within an
SLU context. Our innovative technique reconfigures entity slots specifically
for LLM application in multi-intent SLU environments and introduces the concept
of Sub-Intent Instruction (SII), enhancing the dissection and interpretation of
intricate, multi-intent communication within varied domains. The resultant
datasets, dubbed LM-MixATIS and LM-MixSNIPS, are crafted from pre-existing
benchmarks. Our research illustrates that LLMs can match and potentially excel
beyond the capabilities of current state-of-the-art multi-intent SLU models. It
further explores LLM efficacy across various intent configurations and dataset
proportions. Moreover, we introduce two pioneering metrics, Entity Slot
Accuracy (ESA) and Combined Semantic Accuracy (CSA), to provide an in-depth
analysis of LLM proficiency in this complex field.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04482" title="Abstract">arXiv:2403.04482</a> [<a href="/pdf/2403.04482" title="Download PDF">pdf</a>, <a href="/format/2403.04482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Topology Awareness and Generalization Performance of Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Junwei Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many computer vision and machine learning problems are modelled as learning
tasks on graphs, where graph neural networks (GNNs) have emerged as a dominant
tool for learning representations of graph-structured data. A key feature of
GNNs is their use of graph structures as input, enabling them to exploit the
graphs' inherent topological properties-known as the topology awareness of
GNNs. Despite the empirical successes of GNNs, the influence of topology
awareness on generalization performance remains unexplored, particularly for
node-level tasks that diverge from the assumption of data being independent and
identically distributed (I.I.D.). The precise definition and characterization
of the topology awareness of GNNs, especially concerning different topological
features, are still unclear. This paper introduces a comprehensive framework to
characterize the topology awareness of GNNs across any topological feature.
Using this framework, we investigate the effects of topology awareness on GNN
generalization performance. Contrary to the prevailing belief that enhancing
the topology awareness of GNNs is always advantageous, our analysis reveals a
critical insight: improving the topology awareness of GNNs may inadvertently
lead to unfair generalization across structural groups, which might not be
desired in some scenarios. Additionally, we conduct a case study using the
intrinsic graph metric, the shortest path distance, on various benchmark
datasets. The empirical results of this case study confirm our theoretical
insights. Moreover, we demonstrate the practical applicability of our framework
by using it to tackle the cold start problem in graph active learning.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04483" title="Abstract">arXiv:2403.04483</a> [<a href="/pdf/2403.04483" title="Download PDF">pdf</a>, <a href="/format/2403.04483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphInstruct: Empowering Large Language Models with Graph Understanding  and Reasoning Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zihan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiran Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jianxun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jinqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Evaluating and enhancing the general capabilities of large language models
(LLMs) has been an important research topic. Graph is a common data structure
in the real world, and understanding graph data is a crucial part for advancing
general intelligence. To evaluate and enhance the graph understanding abilities
of LLMs, in this paper, we propose a benchmark named GraphInstruct, which
comprehensively includes 21 classical graph reasoning tasks, providing diverse
graph generation pipelines and detailed reasoning steps. Based on
GraphInstruct, we further construct GraphLM through efficient
instruction-tuning, which shows prominent graph understanding capability. In
order to enhance the LLM with graph reasoning capability as well, we propose a
step mask training strategy, and construct a model named GraphLM+. As one of
the pioneering efforts to enhance the graph understanding and reasoning
abilities of LLMs, extensive experiments have demonstrated the superiority of
GraphLM and GraphLM+ over other LLMs. We look forward to more researchers
exploring the potential of LLMs in the graph data mining domain through
GraphInstruct. Our code for generating GraphInstruct is released publicly at:
https://github.com/CGCL-codes/GraphInstruct.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04484" title="Abstract">arXiv:2403.04484</a> [<a href="/pdf/2403.04484" title="Download PDF">pdf</a>, <a href="/format/2403.04484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source Matters: Source Dataset Impact on Model Robustness in Medical  Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Juodelyte%2C+D">Dovile Juodelyte</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yucheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-S%C3%A1nchez%2C+A">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bottazzi%2C+S">Sabrina Bottazzi</a>, 
<a href="/search/cs?searchtype=author&query=Ferrante%2C+E">Enzo Ferrante</a>, 
<a href="/search/cs?searchtype=author&query=Cheplygina%2C+V">Veronika Cheplygina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to MICCAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning has become an essential part of medical imaging
classification algorithms, often leveraging ImageNet weights. However, the
domain shift from natural to medical images has prompted alternatives such as
RadImageNet, often demonstrating comparable classification performance.
However, it remains unclear whether the performance gains from transfer
learning stem from improved generalization or shortcut learning. To address
this, we investigate potential confounders -- whether synthetic or sampled from
the data -- across two publicly available chest X-ray and CT datasets. We show
that ImageNet and RadImageNet achieve comparable classification performance,
yet ImageNet is much more prone to overfitting to confounders. We recommend
that researchers using ImageNet-pretrained models reexamine their model
robustness by conducting similar experiments. Our code and experiments are
available at https://github.com/DovileDo/source-matters.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04485" title="Abstract">arXiv:2403.04485</a> [<a href="/pdf/2403.04485" title="Download PDF">pdf</a>, <a href="/format/2403.04485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy in Cloud Computing through Immersion-based Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayati%2C+H">Haleh Hayati</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Wouw%2C+N">Nathan van de Wouw</a>, 
<a href="/search/cs?searchtype=author&query=Murguia%2C+C">Carlos Murguia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cloud computing enables users to process and store data remotely on
high-performance computers and servers by sharing data over the Internet.
However, transferring data to clouds causes unavoidable privacy concerns. Here,
we present a synthesis framework to design coding mechanisms that allow sharing
and processing data in a privacy-preserving manner without sacrificing data
utility and algorithmic performance. We consider the setup where the user aims
to run an algorithm in the cloud using private data. The cloud then returns
some data utility back to the user (utility refers to the service that the
algorithm provides, e.g., classification, prediction, AI models, etc.). To
avoid privacy concerns, the proposed scheme provides tools to co-design: 1)
coding mechanisms to distort the original data and guarantee a prescribed
differential privacy level; 2) an equivalent-but-different algorithm (referred
here to as the target algorithm) that runs on distorted data and produces
distorted utility; and 3) a decoding function that extracts the true utility
from the distorted one with a negligible error. Then, instead of sharing the
original data and algorithm with the cloud, only the distorted data and target
algorithm are disclosed, thereby avoiding privacy concerns. The proposed scheme
is built on the synergy of differential privacy and system immersion tools from
control theory. The key underlying idea is to design a higher-dimensional
target algorithm that embeds all trajectories of the original algorithm and
works on randomly encoded data to produce randomly encoded utility. We show
that the proposed scheme can be designed to offer any level of differential
privacy without degrading the algorithm's utility. We present two use cases to
illustrate the performance of the developed tools: privacy in
optimization/learning algorithms and a nonlinear networked control system.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04489" title="Abstract">arXiv:2403.04489</a> [<a href="/pdf/2403.04489" title="Download PDF">pdf</a>, <a href="/ps/2403.04489" title="Download PostScript">ps</a>, <a href="/format/2403.04489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Denial-of-Service Attacks Against Status Updating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kriouile%2C+S">Saad Kriouile</a>, 
<a href="/search/cs?searchtype=author&query=Assaad%2C+M">Mohamad Assaad</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnd%C3%BCz%2C+D">Deniz G&#xfc;nd&#xfc;z</a>, 
<a href="/search/cs?searchtype=author&query=Soleymani%2C+T">Touraj Soleymani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we investigate denial-of-service attacks against status
updating. The target system is modeled by a Markov chain and an unreliable
wireless channel, and the performance of status updating in the target system
is measured based on two metrics: age of information and age of incorrect
information. Our objective is to devise optimal attack policies that strike a
balance between the deterioration of the system's performance and the
adversary's energy. We model the optimal problem as a Markov decision process
and prove rigorously that the optimal jamming policy is a threshold-based
policy under both metrics. In addition, we provide a low-complexity algorithm
to obtain the optimal threshold value of the jamming policy. Our numerical
results show that the networked system with the age-of-incorrect-information
metric is less sensitive to jamming attacks than with the age-of-information
metric. Index Terms-age of incorrect information, age of information,
cyber-physical systems, status updating, remote monitoring.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04491" title="Abstract">arXiv:2403.04491</a> [<a href="/pdf/2403.04491" title="Download PDF">pdf</a>, <a href="/format/2403.04491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable approximation and solvers for ionic electrodiffusion in  cellular geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Benedusi%2C+P">Pietro Benedusi</a>, 
<a href="/search/math?searchtype=author&query=Ellingsrud%2C+A+J">Ada J. Ellingsrud</a>, 
<a href="/search/math?searchtype=author&query=Herlyng%2C+H">Halvor Herlyng</a>, 
<a href="/search/math?searchtype=author&query=Rognes%2C+M+E">Marie E. Rognes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The activity and dynamics of excitable cells are fundamentally regulated and
moderated by extracellular and intracellular ion concentrations and their
electric potentials. The increasing availability of dense reconstructions of
excitable tissue at extreme geometric detail pose a new and clear scientific
computing challenge for computational modelling of ion dynamics and transport.
In this paper, we design, develop and evaluate a scalable numerical algorithm
for solving the time-dependent and nonlinear KNP-EMI equations describing ionic
electrodiffusion for excitable cells with an explicit geometric representation
of intracellular and extracellular compartments and interior interfaces. We
also introduce and specify a set of model scenarios of increasing complexity
suitable for benchmarking. Our solution strategy is based on an
implicit-explicit discretization and linearization in time, a mixed finite
element discretization of ion concentrations and electric potentials in
intracellular and extracellular domains, and an algebraic multigrid-based,
inexact block-diagonal preconditioner for GMRES. Numerical experiments with up
to $10^8$ unknowns per time step and up to 256 cores demonstrate that this
solution strategy is robust and scalable with respect to the problem size, time
discretization and number of cores.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04492" title="Abstract">arXiv:2403.04492</a> [<a href="/pdf/2403.04492" title="Download PDF">pdf</a>, <a href="/format/2403.04492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Sample-Guided and Parameter-Efficient Feature Space  Adaptation for Cross-Domain Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perera%2C+R">Rashindrie Perera</a>, 
<a href="/search/cs?searchtype=author&query=Halgamuge%2C+S">Saman Halgamuge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we look at cross-domain few-shot classification which presents
the challenging task of learning new classes in unseen domains with few
labelled examples. Existing methods, though somewhat effective, encounter
several limitations, which we address in this work through two significant
improvements. First, to address overfitting associated with fine-tuning a large
number of parameters on small datasets, we introduce a lightweight
parameter-efficient adaptation strategy. This strategy employs a linear
transformation of pre-trained features, significantly reducing the trainable
parameter count. Second, we replace the traditional nearest centroid classifier
with a variance-aware loss function, enhancing the model's sensitivity to the
inter- and intra-class variances within the training set for improved
clustering in feature space. Empirical evaluations on the Meta-Dataset
benchmark showcase that our approach not only improves accuracy up to 7.7% and
5.3% on seen and unseen datasets respectively but also achieves this
performance while being at least ~3x more parameter-efficient than existing
methods, establishing a new state-of-the-art in cross-domain few-shot learning.
Our code can be found at https://github.com/rashindrie/DIPA.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04493" title="Abstract">arXiv:2403.04493</a> [<a href="/pdf/2403.04493" title="Download PDF">pdf</a>, <a href="/ps/2403.04493" title="Download PostScript">ps</a>, <a href="/format/2403.04493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What makes an image realistic?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theis%2C+L">Lucas Theis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The last decade has seen tremendous progress in our ability to generate
realistic-looking data, be it images, text, audio, or video. Here, we discuss
the closely related problem of quantifying realism, that is, designing
functions that can reliably tell realistic data from unrealistic data. This
problem turns out to be significantly harder to solve and remains poorly
understood, despite its prevalence in machine learning and recent breakthroughs
in generative AI. Drawing on insights from algorithmic information theory, we
discuss why this problem is challenging, why a good generative model alone is
insufficient to solve it, and what a good solution would look like. In
particular, we introduce the notion of a universal critic, which unlike
adversarial critics does not require adversarial training. While universal
critics are not immediately practical, they can serve both as a North Star for
guiding practical implementations and as a tool for analyzing existing attempts
to capture realism.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04499" title="Abstract">arXiv:2403.04499</a> [<a href="/pdf/2403.04499" title="Download PDF">pdf</a>, <a href="/ps/2403.04499" title="Download PostScript">ps</a>, <a href="/format/2403.04499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pressure-improved Scott-Vogelius type elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bohne%2C+N">Nis-Erik Bohne</a>, 
<a href="/search/math?searchtype=author&query=Gr%C3%A4%C3%9Fle%2C+B">Benedikt Gr&#xe4;&#xdf;le</a>, 
<a href="/search/math?searchtype=author&query=Sauter%2C+S+A">Stefan A. Sauter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Scott-Vogelius element is a popular finite element for the discretization
of the Stokes equations which enjoys inf-sup stability and gives
divergence-free velocity approximation. However, it is well known that the
convergence rates for the discrete pressure deteriorate in the presence of
certain $critical$ $vertices$ in a triangulation of the domain. Modifications
of the Scott-Vogelius element such as the recently introduced pressure-wired
Stokes element also suffer from this effect. In this paper we introduce a
simple modification strategy for these pressure spaces that preserves the
inf-sup stability while the pressure converges at an optimal rate.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04502" title="Abstract">arXiv:2403.04502</a> [<a href="/pdf/2403.04502" title="Download PDF">pdf</a>, <a href="/format/2403.04502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matched-filter Precoded Rate Splitting Multiple Access: A Simple and  Energy-efficient Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Slock%2C+D">Dirk Slock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We introduce an energy-efficient downlink rate splitting multiple access
(RSMA) scheme, employing a simple matched filter (MF) for precoding. We
consider a transmitter equipped with multiple antennas, serving several
single-antenna users at the same frequency-time resource, each with distinct
message requests. Within the conventional 1-layer RSMA framework, requested
messages undergo splitting into common and private streams, which are then
precoded separately before transmission. In contrast, we propose a novel
strategy where only an MF is employed to precode both the common and private
streams in RSMA, promising significantly improved energy efficiency and reduced
complexity. We demonstrate that this MF-precoded RSMA achieves the same
delivery performance as conventional RSMA, where the common stream is
beamformed using maximal ratio transmission (MRT) and the private streams are
precoded by MF. Taking into account imperfect channel state information at the
transmitter, we proceed to analyze the delivery performance of the MF-precoded
RSMA. We derive the ergodic rates for decoding the common and private streams
at a target user respectively in the massive MIMO regime. Finally, numerical
simulations validate the accuracy of our analytical models, as well as
demonstrate the advantages over conventional RSMA.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04503" title="Abstract">arXiv:2403.04503</a> [<a href="/pdf/2403.04503" title="Download PDF">pdf</a>, <a href="/format/2403.04503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing  Framework for Multimodal Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attimonelli%2C+M">Matteo Attimonelli</a>, 
<a href="/search/cs?searchtype=author&query=Danese%2C+D">Danilo Danese</a>, 
<a href="/search/cs?searchtype=author&query=Malitesta%2C+D">Daniele Malitesta</a>, 
<a href="/search/cs?searchtype=author&query=Pomo%2C+C">Claudio Pomo</a>, 
<a href="/search/cs?searchtype=author&query=Gassi%2C+G">Giuseppe Gassi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In this work, we introduce Ducho 2.0, the latest stable version of our
framework. Differently from Ducho, Ducho 2.0 offers a more personalized user
experience with the definition and import of custom extraction models
fine-tuned on specific tasks and datasets. Moreover, the new version is capable
of extracting and processing features through multimodal-by-design large
models. Notably, all these new features are supported by optimized data loading
and storing to the local memory. To showcase the capabilities of Ducho 2.0, we
demonstrate a complete multimodal recommendation pipeline, from the
extraction/processing to the final recommendation. The idea is to provide
practitioners and experienced scholars with a ready-to-use tool that, put on
top of any multimodal recommendation framework, may permit them to run
extensive benchmarking analyses. All materials are accessible at:
\url{https://github.com/sisinflab/Ducho}.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04504" title="Abstract">arXiv:2403.04504</a> [<a href="/pdf/2403.04504" title="Download PDF">pdf</a>, <a href="/format/2403.04504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Matrix Completion by Exploiting Rating Ordinality in Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seonku Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hwanjo Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Matrix completion is an important area of research in recommender systems.
Recent methods view a rating matrix as a user-item bi-partite graph with
labeled edges denoting observed ratings and predict the edges between the user
and item nodes by using the graph neural network (GNN). Despite their
effectiveness, they treat each rating type as an independent relation type and
thus cannot sufficiently consider the ordinal nature of the ratings. In this
paper, we explore a new approach to exploit rating ordinality for GNN, which
has not been studied well in the literature. We introduce a new method, called
ROGMC, to leverage Rating Ordinality in GNN-based Matrix Completion. It uses
cumulative preference propagation to directly incorporate rating ordinality in
GNN's message passing, allowing for users' stronger preferences to be more
emphasized based on inherent orders of rating types. This process is
complemented by interest regularization which facilitates preference learning
using the underlying interest information. Our extensive experiments show that
ROGMC consistently outperforms the existing strategies of using rating types
for GNN. We expect that our attempt to explore the feasibility of utilizing
rating ordinality for GNN may stimulate further research in this direction.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04507" title="Abstract">arXiv:2403.04507</a> [<a href="/pdf/2403.04507" title="Download PDF">pdf</a>, <a href="/format/2403.04507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLPre: a revised approach towards language-centric benchmarking of  Natural Language Preprocessing systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wi%C4%85cek%2C+M">Martyna Wi&#x105;cek</a>, 
<a href="/search/cs?searchtype=author&query=Rybak%2C+P">Piotr Rybak</a>, 
<a href="/search/cs?searchtype=author&query=Pszenny%2C+%C5%81">&#x141;ukasz Pszenny</a>, 
<a href="/search/cs?searchtype=author&query=Wr%C3%B3blewska%2C+A">Alina Wr&#xf3;blewska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the advancements of transformer-based architectures, we observe the rise
of natural language preprocessing (NLPre) tools capable of solving preliminary
NLP tasks (e.g. tokenisation, part-of-speech tagging, dependency parsing, or
morphological analysis) without any external linguistic guidance. It is arduous
to compare novel solutions to well-entrenched preprocessing toolkits, relying
on rule-based morphological analysers or dictionaries. Aware of the
shortcomings of existing NLPre evaluation approaches, we investigate a novel
method of reliable and fair evaluation and performance reporting. Inspired by
the GLUE benchmark, the proposed language-centric benchmarking system enables
comprehensive ongoing evaluation of multiple NLPre tools, while credibly
tracking their performance. The prototype application is configured for Polish
and integrated with the thoroughly assembled NLPre-PL benchmark. Based on this
benchmark, we conduct an extensive evaluation of a variety of Polish NLPre
systems. To facilitate the construction of benchmarking environments for other
languages, e.g. NLPre-GA for Irish or NLPre-ZH for Chinese, we ensure full
customization of the publicly released source code of the benchmarking system.
The links to all the resources (deployed platforms, source code, trained
models, datasets etc.) can be found on the project website:
https://sites.google.com/view/nlpre-benchmark.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04508" title="Abstract">arXiv:2403.04508</a> [<a href="/pdf/2403.04508" title="Download PDF">pdf</a>, <a href="/format/2403.04508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Waldo: Towards Efficient Exploration of NeRF Scene Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skartados%2C+E">Evangelos Skartados</a>, 
<a href="/search/cs?searchtype=author&query=Yucel%2C+M+K">Mehmet Kerim Yucel</a>, 
<a href="/search/cs?searchtype=author&query=Manganelli%2C+B">Bruno Manganelli</a>, 
<a href="/search/cs?searchtype=author&query=Drosou%2C+A">Anastasios Drosou</a>, 
<a href="/search/cs?searchtype=author&query=Sa%C3%A0-Garriga%2C+A">Albert Sa&#xe0;-Garriga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM MMSys'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have quickly become the primary approach for 3D
reconstruction and novel view synthesis in recent years due to their remarkable
performance. Despite the huge interest in NeRF methods, a practical use case of
NeRFs has largely been ignored; the exploration of the scene space modelled by
a NeRF. In this paper, for the first time in the literature, we propose and
formally define the scene exploration framework as the efficient discovery of
NeRF model inputs (i.e. coordinates and viewing angles), using which one can
render novel views that adhere to user-selected criteria. To remedy the lack of
approaches addressing scene exploration, we first propose two baseline methods
called Guided-Random Search (GRS) and Pose Interpolation-based Search (PIBS).
We then cast scene exploration as an optimization problem, and propose the
criteria-agnostic Evolution-Guided Pose Search (EGPS) for efficient
exploration. We test all three approaches with various criteria (e.g. saliency
maximization, image quality maximization, photo-composition quality
improvement) and show that our EGPS performs more favourably than other
baselines. We finally highlight key points and limitations, and outline
directions for future research in scene exploration.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04510" title="Abstract">arXiv:2403.04510</a> [<a href="/pdf/2403.04510" title="Download PDF">pdf</a>, <a href="/format/2403.04510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where does In-context Translation Happen in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sia%2C+S">Suzanna Sia</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+D">David Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Duh%2C+K">Kevin Duh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-supervised large language models have demonstrated the ability to
perform Machine Translation (MT) via in-context learning, but little is known
about where the model performs the task with respect to prompt instructions and
demonstration examples. In this work, we attempt to characterize the region
where large language models transition from in-context learners to translation
models. Through a series of layer-wise context-masking experiments on
\textsc{GPTNeo2.7B}, \textsc{Bloom3B}, \textsc{Llama7b} and
\textsc{Llama7b-chat}, we demonstrate evidence of a "task recognition" point
where the translation task is encoded into the input representations and
attention to context is no longer necessary. We further observe correspondence
between the low performance when masking out entire layers, and the task
recognition layers. Taking advantage of this redundancy results in 45\%
computational savings when prompting with 5 examples, and task recognition
achieved at layer 14 / 32. Our layer-wise fine-tuning experiments indicate that
the most effective layers for MT fine-tuning are the layers critical to task
recognition.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04511" title="Abstract">arXiv:2403.04511</a> [<a href="/pdf/2403.04511" title="Download PDF">pdf</a>, <a href="/format/2403.04511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering the Deep Filter Bubble: Narrow Exposure in Short-Video  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukiennik%2C+N">Nicholas Sukiennik</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Filter bubbles have been studied extensively within the context of online
content platforms due to their potential to cause undesirable outcomes such as
user dissatisfaction or polarization. With the rise of short-video platforms,
the filter bubble has been given extra attention because these platforms rely
on an unprecedented use of the recommender system to provide relevant content.
In our work, we investigate the deep filter bubble, which refers to the user
being exposed to narrow content within their broad interests. We accomplish
this using one-year interaction data from a top short-video platform in China,
which includes hierarchical data with three levels of categories for each
video. We formalize our definition of a "deep" filter bubble within this
context, and then explore various correlations within the data: first
understanding the evolution of the deep filter bubble over time, and later
revealing some of the factors that give rise to this phenomenon, such as
specific categories, user demographics, and feedback type. We observe that
while the overall proportion of users in a filter bubble remains largely
constant over time, the depth composition of their filter bubble changes. In
addition, we find that some demographic groups that have a higher likelihood of
seeing narrower content and implicit feedback signals can lead to less bubble
formation. Finally, we propose some ways in which recommender systems can be
designed to reduce the risk of a user getting caught in a bubble.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04513" title="Abstract">arXiv:2403.04513</a> [<a href="/pdf/2403.04513" title="Download PDF">pdf</a>, <a href="/format/2403.04513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Coreset for Approximate Furthest-Neighbor Queries in a Simple Polygon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Berg%2C+M">Mark de Berg</a>, 
<a href="/search/cs?searchtype=author&query=Theocharous%2C+L">Leonidas Theocharous</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SoCG 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Let $\mathcal{P}$ be a simple polygon with $m$ vertices and let $P$ be a set
of $n$ points inside $\mathcal{P}$. We prove that there exists, for any
$\varepsilon&gt;0$, a set $\mathcal{C} \subset P$ of size $O(1/\varepsilon^2)$
such that the following holds: for any query point $q$ inside the polygon
$\mathcal{P}$, the geodesic distance from $q$ to its furthest neighbor in
$\mathcal{C}$ is at least $1-\varepsilon$ times the geodesic distance to its
further neighbor in $P$. Thus the set $\mathcal{C}$ can be used for answering
$\varepsilon$-approximate furthest-neighbor queries with a data structure whose
storage requirement is independent of the size of $P$. The coreset can be
constructed in $O\left(\frac{1}{\varepsilon} \left( n\log(1/\varepsilon) +
(n+m)\log(n+m)\right) \right)$ time.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04514" title="Abstract">arXiv:2403.04514</a> [<a href="/pdf/2403.04514" title="Download PDF">pdf</a>, <a href="/format/2403.04514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A finite element contour integral method for computing the resonances of  metallic grating structures with subwavelength holes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xi%2C+Y">Yingxia Xi</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Junshan Lin</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+J">Jiguang Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages and 27 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the numerical computation of resonances for metallic grating
structures with dispersive media and small slit holes. The underlying
eigenvalue problem is nonlinear and the mathematical model is multiscale due to
the existence of several length scales in problem geometry and material
contrast. We discretize the partial differential equation model over the
truncated domain using the finite element method and develop a multi-step
contour integral eigensolver to compute the resonances. The eigensolver first
locates eigenvalues using a spectral indicator and then computes eigenvalues by
a subspace projection scheme. The proposed numerical method is robust and
scalable, and does not require initial guess as the iteration methods.
Numerical examples are presented to demonstrate its effectiveness.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04517" title="Abstract">arXiv:2403.04517</a> [<a href="/pdf/2403.04517" title="Download PDF">pdf</a>, <a href="/ps/2403.04517" title="Download PostScript">ps</a>, <a href="/format/2403.04517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A structure-preserving semi-implicit IMEX finite volume scheme for ideal  magnetohydrodynamics at all Mach and Alfv&#xe9;n numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boscheri%2C+W">Walter Boscheri</a>, 
<a href="/search/math?searchtype=author&query=Thomann%2C+A">Andrea Thomann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a divergence-free semi-implicit finite volume scheme for the
simulation of the ideal magnetohydrodynamics (MHD) equations which is stable
for large time steps controlled by the local transport speed at all Mach and
Alfv\'en numbers. An operator splitting technique allows to treat the
convective terms explicitly while the hydrodynamic pressure and the magnetic
field contributions are integrated implicitly, yielding two decoupled linear
implicit systems. The linearity of the implicit part is achieved by means of a
semi-implicit time linearization. This structure is favorable as second-order
accuracy in time can be achieved relying on the class of semi-implicit
IMplicit-EXplicit Runge-Kutta (IMEX-RK) methods. In space, implicit
cell-centered finite difference operators are designed to discretely preserve
the divergence-free property of the magnetic field on three-dimensional
Cartesian meshes. The new scheme is also particularly well suited for low Mach
number flows and for the incompressible limit of the MHD equations, since no
explicit numerical dissipation is added to the implicit contribution and the
time step is scale independent. Likewise, highly magnetized flows can benefit
from the implicit treatment of the magnetic fluxes, hence improving the
computational efficiency of the novel method. The convective terms undergo a
shock-capturing second order finite volume discretization to guarantee the
effectiveness of the proposed method even for high Mach number flows. The new
scheme is benchmarked against a series of test cases for the ideal MHD
equations addressing different acoustic and Alfv\'en Mach number regimes where
the performance and the stability of the new scheme is assessed.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04521" title="Abstract">arXiv:2403.04521</a> [<a href="/pdf/2403.04521" title="Download PDF">pdf</a>, <a href="/format/2403.04521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Relational Graph Neural Network for Few-Shot Knowledge  Graph Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingjia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+C">Cheng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Jiawei Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Few-shot knowledge graph completion (FKGC) aims to query the unseen facts of
a relation given its few-shot reference entity pairs. The side effect of noises
due to the uncertainty of entities and triples may limit the few-shot learning,
but existing FKGC works neglect such uncertainty, which leads them more
susceptible to limited reference samples with noises. In this paper, we propose
a novel uncertainty-aware few-shot KG completion framework (UFKGC) to model
uncertainty for a better understanding of the limited data by learning
representations under Gaussian distribution. Uncertainty representation is
first designed for estimating the uncertainty scope of the entity pairs after
transferring feature representations into a Gaussian distribution. Further, to
better integrate the neighbors with uncertainty characteristics for entity
features, we design an uncertainty-aware relational graph neural network
(UR-GNN) to conduct convolution operations between the Gaussian distributions.
Then, multiple random samplings are conducted for reference triples within the
Gaussian distribution to generate smooth reference representations during the
optimization. The final completion score for each query instance is measured by
the designed uncertainty optimization to make our approach more robust to the
noises in few-shot scenarios. Experimental results show that our approach
achieves excellent performance on two benchmark datasets compared to its
competitors.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04523" title="Abstract">arXiv:2403.04523</a> [<a href="/pdf/2403.04523" title="Download PDF">pdf</a>, <a href="/format/2403.04523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-TAME: Trainable Attention Mechanism for Explaining Convolutional  Networks and Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ntrougkas%2C+M+V">Mariano V. Ntrougkas</a>, 
<a href="/search/cs?searchtype=author&query=Gkalelis%2C+N">Nikolaos Gkalelis</a>, 
<a href="/search/cs?searchtype=author&query=Mezaris%2C+V">Vasileios Mezaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">The development and adoption of Vision Transformers and other deep-learning
architectures for image classification tasks has been rapid. However, the
"black box" nature of neural networks is a barrier to adoption in applications
where explainability is essential. While some techniques for generating
explanations have been proposed, primarily for Convolutional Neural Networks,
adapting such techniques to the new paradigm of Vision Transformers is
non-trivial. This paper presents T-TAME, Transformer-compatible Trainable
Attention Mechanism for Explanations, a general methodology for explaining deep
neural networks used in image classification tasks. The proposed architecture
and training technique can be easily applied to any convolutional or Vision
Transformer-like neural network, using a streamlined training approach. After
training, explanation maps can be computed in a single forward pass; these
explanation maps are comparable to or outperform the outputs of computationally
expensive perturbation-based explainability techniques, achieving SOTA
performance. We apply T-TAME to three popular deep learning classifier
architectures, VGG-16, ResNet-50, and ViT-B-16, trained on the ImageNet
dataset, and we demonstrate improvements over existing state-of-the-art
explainability methods. A detailed analysis of the results and an ablation
study provide insights into how the T-TAME design choices affect the quality of
the generated explanation maps.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04526" title="Abstract">arXiv:2403.04526</a> [<a href="/pdf/2403.04526" title="Download PDF">pdf</a>, <a href="/format/2403.04526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral unmixing for Raman spectroscopy via physics-constrained  autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+D">Dimitar Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Galiana%2C+%C3%81">&#xc1;lvaro Fern&#xe1;ndez-Galiana</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+S+V">Simon Vilms Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+G">Georgios Papadopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruoxiao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+M+M">Molly M. Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Barahona%2C+M">Mauricio Barahona</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Raman spectroscopy is widely used across scientific domains to characterize
the chemical composition of samples in a non-destructive, label-free manner.
Many applications entail the unmixing of signals from mixtures of molecular
species to identify the individual components present and their proportions,
yet conventional methods for chemometrics often struggle with complex mixture
scenarios encountered in practice. Here, we develop hyperspectral unmixing
algorithms based on autoencoder neural networks, and we systematically validate
them using both synthetic and experimental benchmark datasets created in-house.
Our results demonstrate that unmixing autoencoders provide improved accuracy,
robustness and efficiency compared to standard unmixing methods. We also
showcase the applicability of autoencoders to complex biological settings by
showing improved biochemical characterization of volumetric Raman imaging data
from a monocytic cell.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04529" title="Abstract">arXiv:2403.04529</a> [<a href="/pdf/2403.04529" title="Download PDF">pdf</a>, <a href="/format/2403.04529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Data Quality in Federated Fine-Tuning of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wanru Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yaxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+N+D">Nicholas Donald Lane</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024 Workshop on Navigating and Addressing Data Problems for Foundation Models (DPFM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the current landscape of foundation model training, there is a significant
reliance on public domain data, which is nearing exhaustion according to recent
research. To further scale up, it is crucial to incorporate collaboration among
multiple specialized and high-quality private domain data sources. However, the
challenge of training models locally without sharing private data presents
numerous obstacles in data quality control. To tackle this issue, we propose a
data quality control pipeline for federated fine-tuning of foundation models.
This pipeline computes scores reflecting the quality of training data and
determines a global threshold for a unified standard, aiming for improved
global performance. Our experiments show that the proposed quality control
pipeline facilitates the effectiveness and reliability of the model training,
leading to better performance.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04530" title="Abstract">arXiv:2403.04530</a> [<a href="/pdf/2403.04530" title="Download PDF">pdf</a>, <a href="/format/2403.04530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-District School Choice: Playing on Several Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonczarowski%2C+Y+A">Yannai A. Gonczarowski</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Michael Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shirley Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We extend the seminal model of Pathak and S\"onmez (2008) to a setting with
multiple school districts, each running its own separate centralized match, and
focus on the case of two districts. In our setting, in addition to each student
being either sincere or sophisticated, she is also either constrained - able to
apply only to schools within her own district of residence - or unconstrained -
able to choose any single district within which to apply. We show that several
key results from Pathak and S\"onmez (2008) qualitatively flip: A sophisticated
student may prefer for a sincere student to become sophisticated, and a
sophisticated student may prefer for her own district to use Deferred
Acceptance over the Boston Mechanism, irrespective of the mechanism used by the
other district. We furthermore investigate the preferences of students over the
constraint levels of other students. Many of these phenomena appear abundantly
in large random markets.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04537" title="Abstract">arXiv:2403.04537</a> [<a href="/pdf/2403.04537" title="Download PDF">pdf</a>, <a href="/ps/2403.04537" title="Download PostScript">ps</a>, <a href="/format/2403.04537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLSI Architectures of Forward Kinematic Processor for Robotics  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sourav Roy</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Subhadeep Paul</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+T+K">Tapas Kumar Maiti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper aims to get a comprehensive review of current-day robotic
computation technologies at VLSI architecture level. We studied several repots
in the domain of robotic processor architecture. In this work, we focused on
the forward kinematics architectures which consider CORDIC algorithms, VLSI
circuits of WE DSP16 chip, parallel processing and pipelined architecture, and
lookup table formula and FPGA processor. This study gives us an understanding
of different implementation methods for forward kinematics. Our goal is to
develop a forward kinematics processor with FPGA for real-time applications,
requires a fast response time and low latency of these devices, useful for
industrial automation where the processing speed plays a great role.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04539" title="Abstract">arXiv:2403.04539</a> [<a href="/pdf/2403.04539" title="Download PDF">pdf</a>, <a href="/format/2403.04539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PUMA: Efficient and Low-Cost Memory Allocation and Alignment Support for  Processing-Using-Memory Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+E+G">Emanuele G. Esposito</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Luna%2C+J">Juan G&#xf3;mez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Processing-using-DRAM (PUD) architectures impose a restrictive data layout
and alignment for their operands, where source and destination operands (i)
must reside in the same DRAM subarray (i.e., a group of DRAM rows sharing the
same row buffer and row decoder) and (ii) are aligned to the boundaries of a
DRAM row. However, standard memory allocation routines (i.e., malloc,
posix_memalign, and huge pages-based memory allocation) fail to meet the data
layout and alignment requirements for PUD architectures to operate
successfully. To allow the memory allocation API to influence the OS memory
allocator and ensure that memory objects are placed within specific DRAM
subarrays, we propose a new lazy data allocation routine (in the kernel) for
PUD memory objects called PUMA. The key idea of PUMA is to use the internal
DRAM mapping information together with huge pages and then split huge pages
into finer-grained allocation units that are (i) aligned to the page address
and size and (ii) virtually contiguous.
<br />We implement PUMA as a kernel module using QEMU and emulate a RISC-V machine
running Fedora 33 with v5.9.0 Linux Kernel. We emulate the implementation of a
PUD system capable of executing row copy operations (as in RowClone) and
Boolean AND/OR/NOT operations (as in Ambit). In our experiments, such an
operation is performed in the host CPU if a given operation cannot be executed
in our PUD substrate (due to data misalignment). PUMA significantly outperforms
the baseline memory allocators for all evaluated microbenchmarks and allocation
sizes.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04541" title="Abstract">arXiv:2403.04541</a> [<a href="/pdf/2403.04541" title="Download PDF">pdf</a>, <a href="/format/2403.04541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Composition of ASP Programs from Natural Language  Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borroto%2C+M">Manuel Borroto</a>, 
<a href="/search/cs?searchtype=author&query=Kareem%2C+I">Irfan Kareem</a>, 
<a href="/search/cs?searchtype=author&query=Ricca%2C+F">Francesco Ricca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper moves the first step towards automating the composition of Answer
Set Programming (ASP) specifications. In particular, the following
contributions are provided: (i) A dataset focused on graph-related problem
specifications, designed to develop and assess tools for ASP automatic coding;
(ii) A two-step architecture, implemented in the NL2ASP tool, for generating
ASP programs from natural language specifications. NL2ASP uses neural machine
translation to transform natural language into Controlled Natural Language
(CNL) statements. Subsequently, CNL statements are converted into ASP code
using the CNL2ASP tool. An experiment confirms the viability of the approach.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04542" title="Abstract">arXiv:2403.04542</a> [<a href="/pdf/2403.04542" title="Download PDF">pdf</a>, <a href="/ps/2403.04542" title="Download PostScript">ps</a>, <a href="/format/2403.04542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and Near-Optimal Algorithm for Directed Expander Decompositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulser%2C+A+L">Aurelio L. Sulser</a>, 
<a href="/search/cs?searchtype=author&query=Gutenberg%2C+M+P">Maximilian Probst Gutenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In this work, we present the first algorithm to compute expander
decompositions in an $m$-edge directed graph with near-optimal time
$\tilde{O}(m)$. Further, our algorithm can maintain such a decomposition in a
dynamic graph and again obtains near-optimal update times. Our result improves
over previous algorithms of Bernstein-Probst Gutenberg-Saranurak (FOCS 2020),
Hua-Kyng-Probst Gutenberg-Wu (SODA 2023) that only obtained algorithms optimal
up to subpolynomial factors. At the same time, our algorithm is much simpler
and more accessible than previous work. In order to obtain our new algorithm,
we present a new push-pull-relabel flow framework that generalizes the classic
push-relabel flow algorithm of Goldberg-Tarjan (JACM 1988), which was later
dynamized for computing expander decompositions in undirected graphs by
Henzinger-Rao-Wang (SIAM J. Comput. 2020), Saranurak-Wang (SODA 2019). We then
show that the flow problems formulated in recent work of Hua-Kyng-Probst
Gutenberg-Wu (SODA 2023) to decompose directed graphs can be solved much more
efficiently in the push-pull-relabel flow framework.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04545" title="Abstract">arXiv:2403.04545</a> [<a href="/pdf/2403.04545" title="Download PDF">pdf</a>, <a href="/format/2403.04545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improve Generalization Ability of Deep Wide Residual Network with A  Suitable Scaling Factor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Songtao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zixiong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Deep Residual Neural Networks (ResNets) have demonstrated remarkable success
across a wide range of real-world applications. In this paper, we identify a
suitable scaling factor (denoted by $\alpha$) on the residual branch of deep
wide ResNets to achieve good generalization ability. We show that if $\alpha$
is a constant, the class of functions induced by Residual Neural Tangent Kernel
(RNTK) is asymptotically not learnable, as the depth goes to infinity. We also
highlight a surprising phenomenon: even if we allow $\alpha$ to decrease with
increasing depth $L$, the degeneration phenomenon may still occur. However,
when $\alpha$ decreases rapidly with $L$, the kernel regression with deep RNTK
with early stopping can achieve the minimax rate provided that the target
regression function falls in the reproducing kernel Hilbert space associated
with the infinite-depth RNTK. Our simulation studies on synthetic data and real
classification tasks such as MNIST, CIFAR10 and CIFAR100 support our
theoretical criteria for choosing $\alpha$.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04546" title="Abstract">arXiv:2403.04546</a> [<a href="/pdf/2403.04546" title="Download PDF">pdf</a>, <a href="/format/2403.04546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architectural Blueprint For Heterogeneity-Resilient Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bashir%2C+S">Satwat Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Dagiuklas%2C+T">Tasos Dagiuklas</a>, 
<a href="/search/cs?searchtype=author&query=Kassai%2C+K">Kasra Kassai</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+M">Muddesar Iqbal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper proposes a novel three tier architecture for federated learning to
optimize edge computing environments. The proposed architecture addresses the
challenges associated with client data heterogeneity and computational
constraints. It introduces a scalable, privacy preserving framework that
enhances the efficiency of distributed machine learning. Through
experimentation, the paper demonstrates the architecture capability to manage
non IID data sets more effectively than traditional federated learning models.
Additionally, the paper highlights the potential of this innovative approach to
significantly improve model accuracy, reduce communication overhead, and
facilitate broader adoption of federated learning technologies.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04547" title="Abstract">arXiv:2403.04547</a> [<a href="/pdf/2403.04547" title="Download PDF">pdf</a>, <a href="/format/2403.04547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP the Bias: How Useful is Balancing Data in Multimodal Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabdulmohsin%2C+I">Ibrahim Alabdulmohsin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+A">Andreas Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Priya Goyal</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amour%2C+A">Alexander D&#x27;Amour</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 20 figures, 7 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study the effectiveness of data-balancing for mitigating biases in
contrastive language-image pretraining (CLIP), identifying areas of strength
and limitation. First, we reaffirm prior conclusions that CLIP models can
inadvertently absorb societal stereotypes. To counter this, we present a novel
algorithm, called Multi-Modal Moment Matching (M4), designed to reduce both
representation and association biases (i.e. in first- and second-order
statistics) in multimodal data. We use M4 to conduct an in-depth analysis
taking into account various factors, such as the model, representation, and
data size. Our study also explores the dynamic nature of how CLIP learns and
unlearns biases. In particular, we find that fine-tuning is effective in
countering representation biases, though its impact diminishes for association
biases. Also, data balancing has a mixed impact on quality: it tends to improve
classification but can hurt retrieval. Interestingly, data and architectural
improvements seem to mitigate the negative impact of data balancing on
performance; e.g. applying M4 to SigLIP-B/16 with data quality filters improves
COCO image-to-text retrieval @5 from 86% (without data balancing) to 87% and
ImageNet 0-shot classification from 77% to 77.5%! Finally, we conclude with
recommendations for improving the efficacy of data balancing in multimodal
systems.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04549" title="Abstract">arXiv:2403.04549</a> [<a href="/pdf/2403.04549" title="Download PDF">pdf</a>, <a href="/format/2403.04549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Face Verification via Feature-Guided Gradient  Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zewei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+T">Touradj Ebrahimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent years have witnessed significant advancement in face recognition (FR)
techniques, with their applications widely spread in people's lives and
security-sensitive areas. There is a growing need for reliable interpretations
of decisions of such systems. Existing studies relying on various mechanisms
have investigated the usage of saliency maps as an explanation approach, but
suffer from different limitations. This paper first explores the spatial
relationship between face image and its deep representation via gradient
backpropagation. Then a new explanation approach FGGB has been conceived, which
provides precise and insightful similarity and dissimilarity saliency maps to
explain the "Accept" and "Reject" decision of an FR system. Extensive visual
presentation and quantitative measurement have shown that FGGB achieves
superior performance in both similarity and dissimilarity maps when compared to
current state-of-the-art explainable face verification approaches.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04551" title="Abstract">arXiv:2403.04551</a> [<a href="/pdf/2403.04551" title="Download PDF">pdf</a>, <a href="/format/2403.04551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting Sample Hardness: A Fine-Grained Analysis of Hardness  Characterization Methods for Data-Centric AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seedat%2C+N">Nabeel Seedat</a>, 
<a href="/search/cs?searchtype=author&query=Imrie%2C+F">Fergus Imrie</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at International Conference on Learning Representations (ICLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Characterizing samples that are difficult to learn from is crucial to
developing highly performant ML models. This has led to numerous Hardness
Characterization Methods (HCMs) that aim to identify "hard" samples. However,
there is a lack of consensus regarding the definition and evaluation of
"hardness". Unfortunately, current HCMs have only been evaluated on specific
types of hardness and often only qualitatively or with respect to downstream
performance, overlooking the fundamental quantitative identification task. We
address this gap by presenting a fine-grained taxonomy of hardness types.
Additionally, we propose the Hardness Characterization Analysis Toolkit
(H-CAT), which supports comprehensive and quantitative benchmarking of HCMs
across the hardness taxonomy and can easily be extended to new HCMs, hardness
types, and datasets. We use H-CAT to evaluate 13 different HCMs across 8
hardness types. This comprehensive evaluation encompassing over 14K setups
uncovers strengths and weaknesses of different HCMs, leading to practical tips
to guide HCM selection and future development. Our findings highlight the need
for more comprehensive HCM evaluation, while we hope our hardness taxonomy and
toolkit will advance the principled evaluation and uptake of data-centric AI
methods.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04553" title="Abstract">arXiv:2403.04553</a> [<a href="/pdf/2403.04553" title="Download PDF">pdf</a>, <a href="/format/2403.04553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvements &amp; Evaluations on the MLCommons CloudMask Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chennamsetti%2C+V">Varshitha Chennamsetti</a>, 
<a href="/search/cs?searchtype=author&query=Mehnaz%2C+L">Laiba Mehnaz</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+B">Banani Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Samsonau%2C+S+V">Sergey V. Samsonau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2401.08636">arXiv:2401.08636</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we report the performance benchmarking results of deep
learning models on MLCommons' Science cloud-masking benchmark using a
high-performance computing cluster at New York University (NYU): NYU Greene.
MLCommons is a consortium that develops and maintains several scientific
benchmarks that can benefit from developments in AI. We provide a description
of the cloud-masking benchmark task, updated code, and the best model for this
benchmark when using our selected hyperparameter settings. Our benchmarking
results include the highest accuracy achieved on the NYU system as well as the
average time taken for both training and inference on the benchmark across
several runs/seeds. Our code can be found on GitHub. MLCommons team has been
kept informed about our progress and may use the developed code for their
future work.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04557" title="Abstract">arXiv:2403.04557</a> [<a href="/pdf/2403.04557" title="Download PDF">pdf</a>, <a href="/format/2403.04557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter identification in PDEs by the solution of monotone inclusion  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gautam%2C+P">Pankaj Gautam</a>, 
<a href="/search/math?searchtype=author&query=Grasmair%2C+M">Markus Grasmair</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper we consider a parameter identification problem for a semilinear
parabolic PDE. For the regularized solution of this problem, we introduce a
total variation based regularization method requiring the solution of a
monotone inclusion problem. We show well-posedness in the sense of inverse
problems of the resulting regularization scheme. In addition, we introduce and
analyze a numerical algorithm for the solution of this inclusion problem using
a nested inertial primal dual method. We demonstrate by means of numerical
examples the convergence of both the numerical algorithm and the regularization
method.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04558" title="Abstract">arXiv:2403.04558</a> [<a href="/pdf/2403.04558" title="Download PDF">pdf</a>, <a href="/format/2403.04558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing self-supervised learning complexity improves weakly-supervised  classification performance in computational pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lenz%2C+T">Tim Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Nahhas%2C+O+S+M+E">Omar S. M. El Nahhas</a>, 
<a href="/search/cs?searchtype=author&query=Ligero%2C+M">Marta Ligero</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J+N">Jakob Nikolas Kather</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to MICCAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep Learning models have been successfully utilized to extract clinically
actionable insights from routinely available histology data. Generally, these
models require annotations performed by clinicians, which are scarce and costly
to generate. The emergence of self-supervised learning (SSL) methods remove
this barrier, allowing for large-scale analyses on non-annotated data. However,
recent SSL approaches apply increasingly expansive model architectures and
larger datasets, causing the rapid escalation of data volumes, hardware
prerequisites, and overall expenses, limiting access to these resources to few
institutions. Therefore, we investigated the complexity of contrastive SSL in
computational pathology in relation to classification performance with the
utilization of consumer-grade hardware. Specifically, we analyzed the effects
of adaptations in data volume, architecture, and algorithms on downstream
classification tasks, emphasizing their impact on computational resources. We
trained breast cancer foundation models on a large public patient cohort and
validated them on various downstream classification tasks in a weakly
supervised manner on two external public patient cohorts. Our experiments
demonstrate that we can improve downstream classification performance whilst
reducing SSL training duration by 90%. In summary, we propose a set of
adaptations which enable the utilization of SSL in computational pathology in
non-resource abundant environments.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04562" title="Abstract">arXiv:2403.04562</a> [<a href="/pdf/2403.04562" title="Download PDF">pdf</a>, <a href="/format/2403.04562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of the Room: Generalizing Event-Based Dynamic Motion Segmentation  for Complex Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgoulis%2C+S">Stamatios Georgoulis</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weining Ren</a>, 
<a href="/search/cs?searchtype=author&query=Bochicchio%2C+A">Alfredo Bochicchio</a>, 
<a href="/search/cs?searchtype=author&query=Eckert%2C+D">Daniel Eckert</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanyou Li</a>, 
<a href="/search/cs?searchtype=author&query=Gawel%2C+A">Abel Gawel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3DV 2024, the first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Rapid and reliable identification of dynamic scene parts, also known as
motion segmentation, is a key challenge for mobile sensors. Contemporary RGB
camera-based methods rely on modeling camera and scene properties however, are
often under-constrained and fall short in unknown categories. Event cameras
have the potential to overcome these limitations, but corresponding methods
have only been demonstrated in smaller-scale indoor environments with
simplified dynamic objects. This work presents an event-based method for
class-agnostic motion segmentation that can successfully be deployed across
complex large-scale outdoor environments too. To this end, we introduce a novel
divide-and-conquer pipeline that combines: (a) ego-motion compensated events,
computed via a scene understanding module that predicts monocular depth and
camera pose as auxiliary tasks, and (b) optical flow from a dedicated optical
flow module. These intermediate representations are then fed into a
segmentation module that predicts motion segmentation masks. A novel
transformer-based temporal attention module in the segmentation module builds
correlations across adjacent 'frames' to get temporally consistent segmentation
masks. Our method sets the new state-of-the-art on the classic EV-IMO benchmark
(indoors), where we achieve improvements of 2.19 moving object IoU (2.22 mIoU)
and 4.52 point IoU respectively, as well as on a newly-generated motion
segmentation and tracking benchmark (outdoors) based on the DSEC event dataset,
termed DSEC-MOTS, where we show improvement of 12.91 moving object IoU.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04568" title="Abstract">arXiv:2403.04568</a> [<a href="/pdf/2403.04568" title="Download PDF">pdf</a>, <a href="/format/2403.04568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit  Feedback and Unknown Transition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Long-Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhi-Hua Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study reinforcement learning with linear function approximation, unknown
transition, and adversarial losses in the bandit feedback setting.
Specifically, we focus on linear mixture MDPs whose transition kernel is a
linear mixture model. We propose a new algorithm that attains an
$\widetilde{O}(d\sqrt{HS^3K} + \sqrt{HSAK})$ regret with high probability,
where $d$ is the dimension of feature mappings, $S$ is the size of state space,
$A$ is the size of action space, $H$ is the episode length and $K$ is the
number of episodes. Our result strictly improves the previous best-known
$\widetilde{O}(dS^2 \sqrt{K} + \sqrt{HSAK})$ result in Zhao et al. (2023a)
since $H \leq S$ holds by the layered MDP structure. Our advancements are
primarily attributed to (i) a new least square estimator for the transition
parameter that leverages the visit information of all states, as opposed to
only one state in prior work, and (ii) a new self-normalized concentration
tailored specifically to handle non-independent noises, originally proposed in
the dynamic assortment area and firstly applied in reinforcement learning to
handle correlations between different states.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04570" title="Abstract">arXiv:2403.04570</a> [<a href="/pdf/2403.04570" title="Download PDF">pdf</a>, <a href="/format/2403.04570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShuffleBench: A Benchmark for Large-Scale Data Shuffling Operations with  Distributed Stream Processing Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henning%2C+S">S&#xf6;ren Henning</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+A">Adriano Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Leichtfried%2C+M">Michael Leichtfried</a>, 
<a href="/search/cs?searchtype=author&query=Ertl%2C+O">Otmar Ertl</a>, 
<a href="/search/cs?searchtype=author&query=Rabiser%2C+R">Rick Rabiser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for publication in Proceedings of the 15th ACM/SPEC International Conference on Performance Engineering (ICPE '24), May 7--11, 2024, London, United Kingdom, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Distributed stream processing frameworks help building scalable and reliable
applications that perform transformations and aggregations on continuous data
streams. This paper introduces ShuffleBench, a novel benchmark to evaluate the
performance of modern stream processing frameworks. In contrast to other
benchmarks, it focuses on use cases where stream processing frameworks are
mainly employed for shuffling (i.e., re-distributing) data records to perform
state-local aggregations, while the actual aggregation logic is considered as
black-box software components. ShuffleBench is inspired by requirements for
near real-time analytics of a large cloud observability platform and takes up
benchmarking metrics and methods for latency, throughput, and scalability
established in the performance engineering research community. Although
inspired by a real-world observability use case, it is highly configurable to
allow domain-independent evaluations. ShuffleBench comes as a ready-to-use
open-source software utilizing existing Kubernetes tooling and providing
implementations for four state-of-the-art frameworks. Therefore, we expect
ShuffleBench to be a valuable contribution to both industrial practitioners
building stream processing applications and researchers working on new stream
processing approaches. We complement this paper with an experimental
performance evaluation that employs ShuffleBench with various configurations on
Flink, Hazelcast, Kafka Streams, and Spark in a cloud-native environment. Our
results show that Flink achieves the highest throughput while Hazelcast
processes data streams with the lowest latency.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04571" title="Abstract">arXiv:2403.04571</a> [<a href="/pdf/2403.04571" title="Download PDF">pdf</a>, <a href="/ps/2403.04571" title="Download PostScript">ps</a>, <a href="/format/2403.04571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning and information theory concepts towards an AI  Mathematician
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Bulletin of the AMS, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The current state-of-the-art in artificial intelligence is impressive,
especially in terms of mastery of language, but not so much in terms of
mathematical reasoning. What could be missing? Can we learn something useful
about that gap from how the brains of mathematicians go about their craft? This
essay builds on the idea that current deep learning mostly succeeds at system 1
abilities -- which correspond to our intuition and habitual behaviors -- but
still lacks something important regarding system 2 abilities -- which include
reasoning and robust uncertainty estimation. It takes an
information-theoretical posture to ask questions about what constitutes an
interesting mathematical statement, which could guide future work in crafting
an AI mathematician. The focus is not on proving a given theorem but on
discovering new and interesting conjectures. The central hypothesis is that a
desirable body of theorems better summarizes the set of all provable
statements, for example by having a small description length while at the same
time being close (in terms of number of derivation steps) to many provable
statements.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04574" title="Abstract">arXiv:2403.04574</a> [<a href="/pdf/2403.04574" title="Download PDF">pdf</a>, <a href="/format/2403.04574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Children Age Group Detection based on Human-Computer Interaction and  Time Series Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Garcia%2C+J+C">Juan Carlos Ruiz-Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Hojas%2C+C">Carlos Hojas</a>, 
<a href="/search/cs?searchtype=author&query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="/search/cs?searchtype=author&query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Aythami Morales</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Herreros-Rodriguez%2C+J">Jaime Herreros-Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 6 tables, 32 references
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal on Document Analysis and Recognition
  (IJDAR), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This article proposes a novel Children-Computer Interaction (CCI) approach
for the task of age group detection. This approach focuses on the automatic
analysis of the time series generated from the interaction of the children with
mobile devices. In particular, we extract a set of 25 time series related to
spatial, pressure, and kinematic information of the children interaction while
colouring a tree through a pen stylus tablet, a specific test from the
large-scale public ChildCIdb database.
<br />A complete analysis of the proposed approach is carried out using different
time series selection techniques to choose the most discriminative ones for the
age group detection task: i) a statistical analysis, and ii) an automatic
algorithm called Sequential Forward Search (SFS). In addition, different
classification algorithms such as Dynamic Time Warping Barycenter Averaging
(DBA) and Hidden Markov Models (HMM) are studied. Accuracy results over 85% are
achieved, outperforming previous approaches in the literature and in more
challenging age group conditions. Finally, the approach presented in this study
can benefit many children-related applications, for example, towards an
age-appropriate environment with the technology.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04576" title="Abstract">arXiv:2403.04576</a> [<a href="/pdf/2403.04576" title="Download PDF">pdf</a>, <a href="/format/2403.04576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Model Hierarchy for Predicting the Flow in Stirred Tanks with  Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tr%C3%A1vn%C3%ADkov%C3%A1%2C+V">Veronika Tr&#xe1;vn&#xed;kov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Wolff%2C+D">Daniel Wolff</a>, 
<a href="/search/cs?searchtype=author&query=Dirkes%2C+N">Nico Dirkes</a>, 
<a href="/search/cs?searchtype=author&query=Elgeti%2C+S">Stefanie Elgeti</a>, 
<a href="/search/cs?searchtype=author&query=von+Lieres%2C+E">Eric von Lieres</a>, 
<a href="/search/cs?searchtype=author&query=Behr%2C+M">Marek Behr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper explores the potential of Physics-Informed Neural Networks (PINNs)
to serve as Reduced Order Models (ROMs) for simulating the flow field within
stirred tank reactors (STRs). We solve the two-dimensional stationary
Navier-Stokes equations within a geometrically intricate domain and explore
methodologies that allow us to integrate additional physical insights into the
model. These approaches include imposing the Dirichlet boundary conditions
(BCs) strongly and employing domain decomposition (DD), with both overlapping
and non-overlapping subdomains. We adapt the Extended Physics-Informed Neural
Network (XPINN) approach to solve different sets of equations in distinct
subdomains based on the diverse flow characteristics present in each region.
Our exploration results in a hierarchy of models spanning various levels of
complexity, where the best models exhibit l1 prediction errors of less than 1%
for both pressure and velocity. To illustrate the reproducibility of our
approach, we track the errors over repeated independent training runs of the
best identified model and show its reliability. Subsequently, by incorporating
the stirring rate as a parametric input, we develop a fast-to-evaluate model of
the flow capable of interpolating across a wide range of Reynolds numbers.
Although we exclusively restrict ourselves to STRs in this work, we conclude
that the steps taken to obtain the presented model hierarchy can be transferred
to other applications.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04577" title="Abstract">arXiv:2403.04577</a> [<a href="/pdf/2403.04577" title="Download PDF">pdf</a>, <a href="/format/2403.04577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wiki-TabNER:Advancing Table Interpretation Through Named Entity  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koleva%2C+A">Aneta Koleva</a>, 
<a href="/search/cs?searchtype=author&query=Ringsquandl%2C+M">Martin Ringsquandl</a>, 
<a href="/search/cs?searchtype=author&query=Hatem%2C+A">Ahmed Hatem</a>, 
<a href="/search/cs?searchtype=author&query=Runkler%2C+T">Thomas Runkler</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Web tables contain a large amount of valuable knowledge and have inspired
tabular language models aimed at tackling table interpretation (TI) tasks. In
this paper, we analyse a widely used benchmark dataset for evaluation of TI
tasks, particularly focusing on the entity linking task. Our analysis reveals
that this dataset is overly simplified, potentially reducing its effectiveness
for thorough evaluation and failing to accurately represent tables as they
appear in the real-world. To overcome this drawback, we construct and annotate
a new more challenging dataset. In addition to introducing the new dataset, we
also introduce a novel problem aimed at addressing the entity linking task:
named entity recognition within cells. Finally, we propose a prompting
framework for evaluating the newly developed large language models (LLMs) on
this novel TI task. We conduct experiments on prompting LLMs under various
settings, where we use both random and similarity-based selection to choose the
examples presented to the models. Our ablation study helps us gain insights
into the impact of the few-shot examples. Additionally, we perform qualitative
analysis to gain insights into the challenges encountered by the models and to
understand the limitations of the proposed dataset.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04578" title="Abstract">arXiv:2403.04578</a> [<a href="/pdf/2403.04578" title="Download PDF">pdf</a>, <a href="/format/2403.04578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Power Flow Formulations for Multidimensional Analyses in  Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duque%2C+E+M+S">Edgar Mauricio Salazar Duque</a>, 
<a href="/search/eess?searchtype=author&query=Giraldo%2C+J+S">Juan S. Giraldo</a>, 
<a href="/search/eess?searchtype=author&query=Vergara%2C+P+P">Pedro P. Vergara</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+P+H">Phuong H. Nguyen</a>, Han (J.G.)
<a href="/search/eess?searchtype=author&query=Slootweg">Slootweg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we present two multidimensional power flow formulations based
on a fixed-point iteration (FPI) algorithm to efficiently solve hundreds of
thousands of power flows in distribution systems. The presented algorithms are
the base for a new TensorPowerFlow (TPF) tool and shine for their simplicity,
benefiting from multicore \gls{cpu} and \gls{gpu} parallelization. We also
focus on the mathematical convergence properties of the algorithm, showing that
its unique solution is at the practical operational point, which is the
solution of high-voltage and low-current. The proof is validated using
numerical simulations showing the robustness of the FPI algorithm compared to
the classical \gls{nr} approach. In the case study, a benchmark with different
PF solution methods is performed, showing that for applications requiring a
yearly simulation at 1-minute resolution the computation time is decreased by a
factor of 164, compared to the NR in its sparse formulation.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04580" title="Abstract">arXiv:2403.04580</a> [<a href="/pdf/2403.04580" title="Download PDF">pdf</a>, <a href="/ps/2403.04580" title="Download PostScript">ps</a>, <a href="/format/2403.04580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Major Product Prediction: Reproducing Reaction Mechanisms with  Machine Learning Models Trained on a Large-Scale Mechanistic Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joung%2C+J+F">Joonyoung F. Joung</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+M+H">Mun Hong Fong</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+J">Jihye Roh</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhengkai Tu</a>, 
<a href="/search/cs?searchtype=author&query=Bradshaw%2C+J">John Bradshaw</a>, 
<a href="/search/cs?searchtype=author&query=Coley%2C+C+W">Connor W. Coley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 105 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Mechanistic understanding of organic reactions can facilitate reaction
development, impurity prediction, and in principle, reaction discovery. While
several machine learning models have sought to address the task of predicting
reaction products, their extension to predicting reaction mechanisms has been
impeded by the lack of a corresponding mechanistic dataset. In this study, we
construct such a dataset by imputing intermediates between experimentally
reported reactants and products using expert reaction templates and train
several machine learning models on the resulting dataset of 5,184,184
elementary steps. We explore the performance and capabilities of these models,
focusing on their ability to predict reaction pathways and recapitulate the
roles of catalysts and reagents. Additionally, we demonstrate the potential of
mechanistic models in predicting impurities, often overlooked by conventional
models. We conclude by evaluating the generalizability of mechanistic models to
new reaction types, revealing challenges related to dataset diversity,
consecutive predictions, and violations of atom conservation.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04582" title="Abstract">arXiv:2403.04582</a> [<a href="/pdf/2403.04582" title="Download PDF">pdf</a>, <a href="/ps/2403.04582" title="Download PostScript">ps</a>, <a href="/format/2403.04582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Cannot be Skipped About the Skiplist: A Survey of Skiplists and  Their Applications in Big Data Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vadrevu%2C+V+S+P+K">Venkata Sai Pavan Kumar Vadrevu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+L">Lu Xing</a>, 
<a href="/search/cs?searchtype=author&query=Aref%2C+W+G">Walid G. Aref</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Skiplists have become prevalent in systems. The main advantages of skiplists
are their simplicity and ease of implementation, and the ability to support
operations in the same asymptotic complexities as their tree-based
counterparts. In this survey, we explore skiplists and their many variants. We
highlight many scenarios of how skiplists are useful and fit well in these
usage scenarios. We study several extensions to skiplists to make them fit for
more applications, e.g., their use in the multi-dimensional space, network
overlaying algorithms, as well as serving as indexes in database systems.
Besides, we also discuss systems that adopt the idea of skiplists and apply the
probabilistic skip pattern into their designs.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04583" title="Abstract">arXiv:2403.04583</a> [<a href="/pdf/2403.04583" title="Download PDF">pdf</a>, <a href="/format/2403.04583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Estimator for Distorted Conics in Camera Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaehyeon Song</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jaeho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Myung-Hwan Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">Jongwoo Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Ayoung Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the literature, points and conics have been major features for camera
geometric calibration. Although conics are more informative features than
points, the loss of the conic property under distortion has critically limited
the utility of conic features in camera calibration. Many existing approaches
addressed conic-based calibration by ignoring distortion or introducing 3D
spherical targets to circumvent this limitation. In this paper, we present a
novel formulation for conic-based calibration using moments. Our derivation is
based on the mathematical finding that the first moment can be estimated
without bias even under distortion. This allows us to track moment changes
during projection and distortion, ensuring the preservation of the first moment
of the distorted conic. With an unbiased estimator, the circular patterns can
be accurately detected at the sub-pixel level and can now be fully exploited
for an entire calibration pipeline, resulting in significantly improved
calibration. The entire code is readily available from
github.com/ChaehyeonSong/discocal.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04586" title="Abstract">arXiv:2403.04586</a> [<a href="/pdf/2403.04586" title="Download PDF">pdf</a>, <a href="/format/2403.04586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Agility Adaptation for Flight in Clutter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yeke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission to Robotics and Automation Letter. 8 pages, 11 figures. Project page: <a href="https://learning-agility-adaptation.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Animals learn to adapt agility of their movements to their capabilities and
the environment they operate in. Mobile robots should also demonstrate this
ability to combine agility and safety. The aim of this work is to endow flight
vehicles with the ability of agility adaptation in prior unknown and partially
observable cluttered environments. We propose a hierarchical learning and
planning framework where we utilize both trial and error to comprehensively
learn an agility policy with the vehicle's observation as the input, and
well-established methods of model-based trajectory generation. Technically, we
use online model-free reinforcement learning and a pre-training-fine-tuning
reward scheme to obtain the deployable policy. The statistical results in
simulation demonstrate the advantages of our method over the constant agility
baselines and an alternative method in terms of flight efficiency and safety.
In particular, the policy leads to intelligent behaviors, such as perception
awareness, which distinguish it from other approaches. By deploying the policy
to hardware, we verify that these advantages can be brought to the real world.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04588" title="Abstract">arXiv:2403.04588</a> [<a href="/pdf/2403.04588" title="Download PDF">pdf</a>, <a href="/format/2403.04588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot cross-modal transfer of Reinforcement Learning policies  through a Global Workspace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayti%C3%A9%2C+L">L&#xe9;opold Mayti&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Devillers%2C+B">Benjamin Devillers</a>, 
<a href="/search/cs?searchtype=author&query=Arnold%2C+A">Alexandre Arnold</a>, 
<a href="/search/cs?searchtype=author&query=VanRullen%2C+R">Rufin VanRullen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in a conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Humans perceive the world through multiple senses, enabling them to create a
comprehensive representation of their surroundings and to generalize
information across domains. For instance, when a textual description of a scene
is given, humans can mentally visualize it. In fields like robotics and
Reinforcement Learning (RL), agents can also access information about the
environment through multiple sensors; yet redundancy and complementarity
between sensors is difficult to exploit as a source of robustness (e.g. against
sensor failure) or generalization (e.g. transfer across domains). Prior
research demonstrated that a robust and flexible multimodal representation can
be efficiently constructed based on the cognitive science notion of a 'Global
Workspace': a unique representation trained to combine information across
modalities, and to broadcast its signal back to each modality. Here, we explore
whether such a brain-inspired multimodal representation could be advantageous
for RL agents. First, we train a 'Global Workspace' to exploit information
collected about the environment via two input modalities (a visual input, or an
attribute vector representing the state of the agent and/or its environment).
Then, we train a RL agent policy using this frozen Global Workspace. In two
distinct environments and tasks, our results reveal the model's ability to
perform zero-shot cross-modal transfer between input modalities, i.e. to apply
to image inputs a policy previously trained on attribute vectors (and
vice-versa), without additional training or fine-tuning. Variants and ablations
of the full Global Workspace (including a CLIP-like multimodal representation
trained via contrastive learning) did not display the same generalization
abilities.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04589" title="Abstract">arXiv:2403.04589</a> [<a href="/pdf/2403.04589" title="Download PDF">pdf</a>, <a href="/ps/2403.04589" title="Download PostScript">ps</a>, <a href="/format/2403.04589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms and complexity for path covers of temporal DAGs: when is  Dilworth dynamic?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Dibyayan Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Dailly%2C+A">Antoine Dailly</a>, 
<a href="/search/cs?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/cs?searchtype=author&query=Klasing%2C+R">Ralf Klasing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">In this paper, we study a dynamic analogue of the Path Cover problem, which
can be solved in polynomial-time in directed acyclic graphs. A temporal digraph
has an arc set that changes over discrete time-steps, if the underlying digraph
(the union of all the arc sets) is acyclic, then we have a temporal DAG. A
temporal path is a directed path in the underlying digraph, such that the
time-steps of arcs are strictly increasing along the path. Two temporal paths
are temporally disjoint if they do not occupy any vertex at the same time. A
temporal (resp. temporally disjoint) path cover is a collection of (resp.
temporally disjoint) temporal paths that covers all vertices. In this paper, we
study the computational complexities of the problems of finding a temporal
(disjoint) path cover with minimum cardinality, denoted as Temporal Path Cover
(TPC) and Temporally Disjoint Path Cover (TD-PC). We show that both problems
are NP-hard even when the underlying DAG is planar, bipartite, subcubic, and
there are only two arc-disjoint time-steps. Moreover, TD-PC remains NP-hard
even on temporal oriented trees. In contrast, we show that TPC is
polynomial-time solvable on temporal oriented trees by a reduction to Clique
Cover for (static undirected) weakly chordal graphs (a subclass of perfect
graphs for which Clique Cover admits an efficient algorithm). This highlights
an interesting algorithmic difference between the two problems. Although it is
NP-hard on temporal oriented trees, TD-PC becomes polynomial-time solvable on
temporal oriented lines and temporal rooted directed trees. We also show that
TPC (resp. TD-PC) admits an XP (resp. FPT) time algorithm with respect to
parameter tmax + tw, where tmax is the maximum time-step, and tw is the
treewidth of the underlying static undirected graph.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04593" title="Abstract">arXiv:2403.04593</a> [<a href="/pdf/2403.04593" title="Download PDF">pdf</a>, <a href="/format/2403.04593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embodied Understanding of Driving Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yunsong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Linyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Q">Qingwen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Hang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongzi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Embodied scene understanding serves as the cornerstone for autonomous agents
to perceive, interpret, and respond to open driving scenarios. Such
understanding is typically founded upon Vision-Language Models (VLMs).
Nevertheless, existing VLMs are restricted to the 2D domain, devoid of spatial
awareness and long-horizon extrapolation proficiencies. We revisit the key
aspects of autonomous driving and formulate appropriate rubrics. Hereby, we
introduce the Embodied Language Model (ELM), a comprehensive framework tailored
for agents' understanding of driving scenes with large spatial and temporal
spans. ELM incorporates space-aware pre-training to endow the agent with robust
spatial localization capabilities. Besides, the model employs time-aware token
selection to accurately inquire about temporal cues. We instantiate ELM on the
reformulated multi-faced benchmark, and it surpasses previous state-of-the-art
approaches in all aspects. All code, data, and models will be publicly shared.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04594" title="Abstract">arXiv:2403.04594</a> [<a href="/pdf/2403.04594" title="Download PDF">pdf</a>, <a href="/format/2403.04594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuenan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zeyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, there has been an increasing focus on audio-text cross-modal
learning. However, most of the existing audio-text datasets contain only simple
descriptions of sound events. Compared with classification labels, the
advantages of such descriptions are significantly limited. In this paper, we
first analyze the detailed information that human descriptions of audio may
contain beyond sound event labels. Based on the analysis, we propose an
automatic pipeline for curating audio-text pairs with rich details. Leveraging
the property that sounds can be mixed and concatenated in the time domain, we
control details in four aspects: temporal relationship, loudness, speaker
identity, and occurrence number, in simulating audio mixtures. Corresponding
details are transformed into captions by large language models. Audio-text
pairs with rich details in text descriptions are thereby obtained. We validate
the effectiveness of our pipeline with a small amount of simulated data,
demonstrating that the simulated data enables models to learn detailed audio
captioning.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04598" title="Abstract">arXiv:2403.04598</a> [<a href="/pdf/2403.04598" title="Download PDF">pdf</a>, <a href="/format/2403.04598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Inventory Placement for a Downstream Online Matching Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Epstein%2C+B">Boris Epstein</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Will Ma</a> (Columbia University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the inventory placement problem of splitting $Q$ units of a single
item across warehouses, in advance of a downstream online matching problem that
represents the dynamic fulfillment decisions of an e-commerce retailer. This is
a challenging problem both in theory, because the downstream matching problem
itself is computationally hard, and in practice, because the fulfillment team
is constantly updating its algorithm and the placement team cannot directly
evaluate how a placement decision would perform.
<br />We compare the performance of three placement procedures based on optimizing
surrogate functions that have been studied and applied: Offline, Myopic, and
Fluid placement. On the theory side, we show that optimizing inventory
placement for the Offline surrogate leads to a $(1-(1-1/d)^d)/2$-approximation
for the joint placement and fulfillment problem. We assume $d$ is an upper
bound on how many warehouses can serve any demand location and that stochastic
arrivals satisfy either temporal or spatial independence. The crux of our
theoretical contribution is to use randomized rounding to derive a tight
$(1-(1-1/d)^d)$-approximation for the integer programming problem of optimizing
the Offline surrogate. We use statistical learning to show that rounding after
optimizing a sample-average Offline surrogate, which is necessary due to the
exponentially-sized support, does indeed have vanishing loss.
<br />On the experimental side, we extract real-world sequences of customer orders
from publicly-available JD.com data and evaluate different combinations of
placement and fulfillment procedures. Optimizing the Offline surrogate performs
best overall, even compared to simulation procedures, corroborating our theory.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04599" title="Abstract">arXiv:2403.04599</a> [<a href="/pdf/2403.04599" title="Download PDF">pdf</a>, <a href="/format/2403.04599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Continual Learning with Importance Sampling and  Prototype-Instance Relation Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Azizov%2C+D">Dilshod Azizov</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shangsong Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, because of the high-quality representations of contrastive learning
methods, rehearsal-based contrastive continual learning has been proposed to
explore how to continually learn transferable representation embeddings to
avoid the catastrophic forgetting issue in traditional continual settings.
Based on this framework, we propose Contrastive Continual Learning via
Importance Sampling (CCLIS) to preserve knowledge by recovering previous data
distributions with a new strategy for Replay Buffer Selection (RBS), which
minimize estimated variance to save hard negative samples for representation
learning with high quality. Furthermore, we present the Prototype-instance
Relation Distillation (PRD) loss, a technique designed to maintain the
relationship between prototypes and sample representations using a
self-distillation process. Experiments on standard continual learning
benchmarks reveal that our method notably outperforms existing baselines in
terms of knowledge preservation and thereby effectively counteracts
catastrophic forgetting in online contexts. The code is available at
https://github.com/lijy373/CCLIS.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04600" title="Abstract">arXiv:2403.04600</a> [<a href="/pdf/2403.04600" title="Download PDF">pdf</a>, <a href="/ps/2403.04600" title="Download PostScript">ps</a>, <a href="/format/2403.04600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivalence of constacyclic codes with shift constants of different  orders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dastbasteh%2C+R">Reza Dastbasteh</a>, 
<a href="/search/cs?searchtype=author&query=Padashnick%2C+F">Farzad Padashnick</a>, 
<a href="/search/cs?searchtype=author&query=Crespo%2C+P+M">Pedro M. Crespo</a>, 
<a href="/search/cs?searchtype=author&query=Grassl%2C+M">Markus Grassl</a>, 
<a href="/search/cs?searchtype=author&query=Sharafi%2C+J">Javad Sharafi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Let $a$ and $b$ be two non-zero elements of a finite field $\mathbb{F}_q$,
where $q&gt;2$. It has been shown that if $a$ and $b$ have the same multiplicative
order in $\mathbb{F}_q$, then the families of $a$-constacyclic and
$b$-constacyclic codes over $\mathbb{F}_q$ are monomially equivalent. In this
paper, we investigate the monomial equivalence of $a$-constacyclic and
$b$-constacyclic codes when $a$ and $b$ have distinct multiplicative orders. We
present novel conditions for establishing monomial equivalence in such
constacyclic codes, surpassing previous methods of determining monomially
equivalent constacyclic and cyclic codes. As an application, we use these
results to search for new linear codes more systematically. In particular, we
present more than $70$ new record-breaking linear codes over various finite
fields, as well as new binary quantum codes.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04601" title="Abstract">arXiv:2403.04601</a> [<a href="/pdf/2403.04601" title="Download PDF">pdf</a>, <a href="/ps/2403.04601" title="Download PostScript">ps</a>, <a href="/format/2403.04601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of soft-constrained MPC for Tracking using its  semi-banded problem structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gracia%2C+V">Victor Gracia</a>, 
<a href="/search/eess?searchtype=author&query=Krupa%2C+P">Pablo Krupa</a>, 
<a href="/search/eess?searchtype=author&query=Limon%2C+D">Daniel Limon</a>, 
<a href="/search/eess?searchtype=author&query=Alamo%2C+T">Teodoro Alamo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Model Predictive Control (MPC) is a popular control approach due to its
ability to consider constraints, including input and state restrictions, while
minimizing a cost function. However, in practice, said constraints can result
in feasibility issues, either because the system model is not accurate or due
to the existence of external disturbances. To mitigate this problem, a solution
adopted by the MPC community is the use of soft constraints. In this article,
we consider a not-so-typical methodology to encode soft constraints in a
particular MPC formulation known as MPC for Tracking (MPCT), which has several
advantages when compared to standard MPC formulations. The motivation behind
the proposed encoding is to maintain the semi-banded structure of the
ingredients of a recently proposed solver for the considered MPCT formulation,
thus providing an efficient and fast solver when compared to alternative
approaches from the literature. We show numerical results highlighting the
benefits of the formulation and the computational efficiency of the solver.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04602" title="Abstract">arXiv:2403.04602</a> [<a href="/pdf/2403.04602" title="Download PDF">pdf</a>, <a href="/format/2403.04602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum-Time Planar Paths with up to Two Constant Acceleration Inputs  and $L_2$ Velocity and Acceleration Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baez%2C+V+M">Victor M. Baez</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Abdurahiman%2C+N">Nihal Abdurahiman</a>, 
<a href="/search/cs?searchtype=author&query=Navkar%2C+N+V">Nikhil V. Navkar</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+A+T">Aaron T. Becker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, accepted for presentation at ACC 2024, <a href="https://acc2024.a2c2.org/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Given starting and ending positions and velocities, $L_2$ bounds on the
acceleration and velocity, and the restriction to no more than two constant
control inputs, this paper provides routines to compute the minimal-time path.
Closed form solutions are provided for reaching a position in minimum time with
and without a velocity bound, and for stopping at the goal position.
<br />A numeric solver is used to reach a goal position and velocity with no more
than two constant control inputs. If a cruising phase at the terminal velocity
is needed, this requires solving a non-linear equation with a single parameter.
Code is provided on GitHub at
https://github.com/RoboticSwarmControl/MinTimeL2pathsConstraints.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04605" title="Abstract">arXiv:2403.04605</a> [<a href="/pdf/2403.04605" title="Download PDF">pdf</a>, <a href="/format/2403.04605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-n-Out: Calibrating Graph Neural Networks for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+E">Erik Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Mesquita%2C+D">Diego Mesquita</a>, 
<a href="/search/cs?searchtype=author&query=Kaskio%2C+S">Samuel Kaskio</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+A+H">Amauri H Souza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep neural networks are notoriously miscalibrated, i.e., their outputs do
not reflect the true probability of the event we aim to predict. While networks
for tabular or image data are usually overconfident, recent works have shown
that graph neural networks (GNNs) show the opposite behavior for node-level
classification. But what happens when we are predicting links? We show that, in
this case, GNNs often exhibit a mixed behavior. More specifically, they may be
overconfident in negative predictions while being underconfident in positive
ones. Based on this observation, we propose IN-N-OUT, the first-ever method to
calibrate GNNs for link prediction. IN-N-OUT is based on two simple intuitions:
i) attributing true/false labels to an edge while respecting a GNNs prediction
should cause but small fluctuations in that edge's embedding; and, conversely,
ii) if we label that same edge contradicting our GNN, embeddings should change
more substantially. An extensive experimental campaign shows that IN-N-OUT
significantly improves the calibration of GNNs in link prediction, consistently
outperforming the baselines available -- which are not designed for this
specific task.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04608" title="Abstract">arXiv:2403.04608</a> [<a href="/pdf/2403.04608" title="Download PDF">pdf</a>, <a href="/format/2403.04608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Standardization of Cloth Objects and its Relevance in Robotic  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Camacho%2C+I">Irene Garcia-Camacho</a>, 
<a href="/search/cs?searchtype=author&query=Longhini%2C+A">Alberta Longhini</a>, 
<a href="/search/cs?searchtype=author&query=Welle%2C+M">Michael Welle</a>, 
<a href="/search/cs?searchtype=author&query=Aleny%C3%A0%2C+G">Guillem Aleny&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>, 
<a href="/search/cs?searchtype=author&query=Borr%C3%A0s%2C+J">J&#xfa;lia Borr&#xe0;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 ICRA International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2024 ICRA International Conference on Robotics and Automation
  (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The field of robotics faces inherent challenges in manipulating deformable
objects, particularly in understanding and standardising fabric properties like
elasticity, stiffness, and friction. While the significance of these properties
is evident in the realm of cloth manipulation, accurately categorising and
comprehending them in real-world applications remains elusive. This study sets
out to address two primary objectives: (1) to provide a framework suitable for
robotics applications to characterise cloth objects, and (2) to study how these
properties influence robotic manipulation tasks. Our preliminary results
validate the framework's ability to characterise cloth properties and compare
cloth sets, and reveal the influence that different properties have on the
outcome of five manipulation primitives. We believe that, in general, results
on the manipulation of clothes should be reported along with a better
description of the garments used in the evaluation. This paper proposes a set
of these measures.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04615" title="Abstract">arXiv:2403.04615</a> [<a href="/pdf/2403.04615" title="Download PDF">pdf</a>, <a href="/ps/2403.04615" title="Download PostScript">ps</a>, <a href="/format/2403.04615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rectangular Rotational Invariant Estimator for High-Rank Matrix  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourkamali%2C+F">Farzad Pourkamali</a>, 
<a href="/search/cs?searchtype=author&query=Macris%2C+N">Nicolas Macris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.12264">arXiv:2304.12264</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider estimating a matrix from noisy observations coming from an
arbitrary additive bi-rotational invariant perturbation. We propose an
estimator which is optimal among the class of rectangular rotational invariant
estimators and can be applied irrespective of the prior on the signal. For the
particular case of Gaussian noise, we prove the optimality of the proposed
estimator, and we find an explicit expression for the MMSE in terms of the
limiting singular value distribution of the observation matrix. Moreover, we
prove a formula linking the asymptotic mutual information and the limit of a
log-spherical integral of rectangular matrices. We also provide numerical
checks for our results for general bi-rotational invariant noise, as well as
Gaussian noise, which match our theoretical predictions.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04616" title="Abstract">arXiv:2403.04616</a> [<a href="/pdf/2403.04616" title="Download PDF">pdf</a>, <a href="/format/2403.04616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling reputation-based behavioral biases in school choice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+S">Sigal Oren</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+E">Emily Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Tardos%2C+%C3%89">&#xc9;va Tardos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">A fundamental component in the theoretical school choice literature is the
problem a student faces in deciding which schools to apply to. Recent models
have considered a set of schools of different selectiveness and a student who
is unsure of their strength and can apply to at most $k$ schools. Such models
assume that the student cares solely about maximizing the quality of the school
that they attend, but experience suggests that students' decisions are also
influenced by a set of behavioral biases based on reputational effects: a
subjective reputational benefit when admitted to a selective school, whether or
not they attend; and a subjective loss based on disappointment when rejected.
Guided by these observations, and inspired by recent behavioral economics work
on loss aversion relative to expectations, we propose a behavioral model by
which a student chooses schools to balance these behavioral effects with the
quality of the school they attend.
<br />Our main results show that a student's choices change in dramatic ways when
these reputation-based behavioral biases are taken into account. In particular,
where a rational applicant spreads their applications evenly, a biased student
applies very sparsely to highly selective schools, such that above a certain
threshold they apply to only an absolute constant number of schools even as
their budget of applications grows to infinity. Consequently, a biased student
underperforms a rational student even when the rational student is restricted
to a sufficiently large upper bound on applications and the biased student can
apply to arbitrarily many. Our analysis shows that the reputation-based model
is rich enough to cover a range of different ways that biased students cope
with fear of rejection, including not just targeting less selective schools,
but also occasionally applying to schools that are too selective, compared to
rational students.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04618" title="Abstract">arXiv:2403.04618</a> [<a href="/pdf/2403.04618" title="Download PDF">pdf</a>, <a href="/format/2403.04618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong Priority and Determinacy in Timed CCS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liquori%2C+L">Luigi Liquori</a>, 
<a href="/search/cs?searchtype=author&query=Mendler%2C+M">Michael Mendler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Building on the classical theory of process algebra with priorities, we
identify a new scheduling mechanism, called "sequentially constructive
reduction" which is designed to capture the essence of synchronous programming.
The distinctive property of this evaluation strategy is to achieve
determinism-by-construction for multi-cast concurrent communication. In
particular, it permits us to model shared memory multi-threading with reaction
to absence as it lies at the core of the programming language Esterel. In the
technical setting of CCS extended by clocks and priorities, we prove for a
large class of processes, which we call "structurally coherent" the confluence
property for constructive reductions. We further show that under some syntactic
restrictions, called "pivotable" the operators of prefix, summation, parallel
composition, restriction and hiding preserve structural coherence. This covers
a strictly larger class of processes compared to those that are confluent in
Milner's classical theory of CCS without priorities.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04627" title="Abstract">arXiv:2403.04627</a> [<a href="/pdf/2403.04627" title="Download PDF">pdf</a>, <a href="/format/2403.04627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Multi-objective Optimization in Cyber-Physical Energy  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stark%2C+S">Sanja Stark</a>, 
<a href="/search/cs?searchtype=author&query=Frost%2C+E">Emilie Frost</a>, 
<a href="/search/cs?searchtype=author&query=Nebel-Wenner%2C+M">Marvin Nebel-Wenner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Energy Informatics Review (ACM SIGEnergy)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Managing complex Cyber-Physical Energy Systems (CPES) requires solving
various optimization problems with multiple objectives and constraints. As
distributed control architectures are becoming more popular in CPES for certain
tasks due to their flexibility, robustness, and privacy protection,
multi-objective optimization must also be distributed. For this purpose, we
present MO-COHDA, a fully distributed, agent-based algorithm, for solving
multi-objective optimization problems of CPES. MO-COHDA allows an easy and
flexible adaptation to different use cases and integration of custom
functionality. To evaluate the effectiveness of MO-COHDA, we compare it to a
central NSGA-2 algorithm using multi-objective benchmark functions from the ZDT
problem suite. The results show that MO-COHDA can approximate the reference
front of the benchmark problems well and is suitable for solving
multi-objective optimization problems. In addition, an example use case of
scheduling a group of generation units while optimizing three different
objectives was evaluated to show how MO-COHDA can be easily applied to
real-world optimization problems in CPES.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04629" title="Abstract">arXiv:2403.04629</a> [<a href="/pdf/2403.04629" title="Download PDF">pdf</a>, <a href="/format/2403.04629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodemann%2C+J">Julian Rodemann</a>, 
<a href="/search/cs?searchtype=author&query=Croppi%2C+F">Federico Croppi</a>, 
<a href="/search/cs?searchtype=author&query=Arens%2C+P">Philipp Arens</a>, 
<a href="/search/cs?searchtype=author&query=Sale%2C+Y">Yusuf Sale</a>, 
<a href="/search/cs?searchtype=author&query=Herbinger%2C+J">Julia Herbinger</a>, 
<a href="/search/cs?searchtype=author&query=Bischl%2C+B">Bernd Bischl</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>, 
<a href="/search/cs?searchtype=author&query=Augustin%2C+T">Thomas Augustin</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+C+J">Conor J. Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Casalicchio%2C+G">Giuseppe Casalicchio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Copyright by the authors; 19 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Robotics (cs.RO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Bayesian optimization (BO) with Gaussian processes (GP) has become an
indispensable algorithm for black box optimization problems. Not without a dash
of irony, BO is often considered a black box itself, lacking ways to provide
reasons as to why certain parameters are proposed to be evaluated. This is
particularly relevant in human-in-the-loop applications of BO, such as in
robotics. We address this issue by proposing ShapleyBO, a framework for
interpreting BO's proposals by game-theoretic Shapley values.They quantify each
parameter's contribution to BO's acquisition function. Exploiting the linearity
of Shapley values, we are further able to identify how strongly each parameter
drives BO's exploration and exploitation for additive acquisition functions
like the confidence bound. We also show that ShapleyBO can disentangle the
contributions to exploration into those that explore aleatoric and epistemic
uncertainty. Moreover, our method gives rise to a ShapleyBO-assisted human
machine interface (HMI), allowing users to interfere with BO in case proposals
do not align with human reasoning. We demonstrate this HMI's benefits for the
use case of personalizing wearable robotic devices (assistive back exosuits) by
human-in-the-loop BO. Results suggest human-BO teams with access to ShapleyBO
can achieve lower regret than teams without.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04630" title="Abstract">arXiv:2403.04630</a> [<a href="/pdf/2403.04630" title="Download PDF">pdf</a>, <a href="/ps/2403.04630" title="Download PostScript">ps</a>, <a href="/format/2403.04630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Aware Projections: Truly Node-Private Graph Statistics under  Continual Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Palak Jain</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+A">Adam Smith</a>, 
<a href="/search/cs?searchtype=author&query=Wagaman%2C+C">Connor Wagaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We describe the first algorithms that satisfy the standard notion of
node-differential privacy in the continual release setting (i.e., without an
assumed promise on input streams). Previous work addresses node-private
continual release by assuming an unenforced promise on the maximum degree in a
graph; indeed, the algorithms from these works exhibit blatant privacy
violations when the degree bound is not met. Our algorithms are accurate on
sparse graphs, for several fundamental graph problems: counting edges,
triangles, other subgraphs, and connected components; and releasing degree
histograms. Our unconditionally private algorithms generally have optimal
error, up to polylogarithmic factors and lower-order terms.
<br />We provide general transformations that take a base algorithm for the
continual release setting, which need only be private for streams satisfying a
promised degree bound, and produce an algorithm that is unconditionally private
yet mimics the base algorithm when the stream meets the degree bound (and adds
only linear overhead to the time and space complexity of the base algorithm).
To do so, we design new projection algorithms for graph streams, based on the
batch-model techniques of Day et al. 2016 and Blocki et al. 2013, which modify
the stream to limit its degree. Our main technical innovation is to show that
the projections are stable -- meaning that similar input graphs have similar
projections -- when the input stream satisfies a privately testable safety
condition. Our transformation then follows a novel online variant of the
Propose-Test-Release framework (Dwork and Lei, 2009), privately testing the
safety condition before releasing output at each step.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04633" title="Abstract">arXiv:2403.04633</a> [<a href="/pdf/2403.04633" title="Download PDF">pdf</a>, <a href="/format/2403.04633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message-Observing Sessions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavanagh%2C+R">Ryan Kavanagh</a>, 
<a href="/search/cs?searchtype=author&query=Pientka%2C+B">Brigitte Pientka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We present Most, a process language with message-observing session types.
Message-observing session types extend binary session types with type-level
computation to specify communication protocols that vary based on messages
observed on other channels. Hence, Most allows us to express global invariants
about processes, rather than just local invariants, in a bottom-up,
compositional way. We give Most a semantic foundation using traces with
binding, a semantic approach for compositionally reasoning about traces in the
presence of name generation. We use this semantics to prove type soundness and
compositionality for Most processes. We see this as a significant step towards
capturing message-dependencies and providing more precise guarantees about
processes.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04634" title="Abstract">arXiv:2403.04634</a> [<a href="/pdf/2403.04634" title="Download PDF">pdf</a>, <a href="/format/2403.04634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pix2Gif: Motion-Guided Diffusion for GIF Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kandala%2C+H">Hitesh Kandala</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video)
generation. We tackle this problem differently by formulating the task as an
image translation problem steered by text and motion magnitude prompts, as
shown in teaser fig. To ensure that the model adheres to motion guidance, we
propose a new motion-guided warping module to spatially transform the features
of the source image conditioned on the two types of prompts. Furthermore, we
introduce a perceptual loss to ensure the transformed feature map remains
within the same space as the target image, ensuring content consistency and
coherence. In preparation for the model training, we meticulously curated data
by extracting coherent image frames from the TGIF video-caption dataset, which
provides rich information about the temporal changes of subjects. After
pretraining, we apply our model in a zero-shot manner to a number of video
datasets. Extensive qualitative and quantitative experiments demonstrate the
effectiveness of our model -- it not only captures the semantic prompt from
text but also the spatial ones from motion guidance. We train all our models
using a single node of 16xV100 GPUs. Code, dataset and models are made public
at: https://hiteshk03.github.io/Pix2Gif/.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04635" title="Abstract">arXiv:2403.04635</a> [<a href="/pdf/2403.04635" title="Download PDF">pdf</a>, <a href="/ps/2403.04635" title="Download PostScript">ps</a>, <a href="/format/2403.04635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtuoso: An Open-Source, Comprehensive and Modular Simulation Framework  for Virtual Memory Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+K">Konstantinos Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Sgouras%2C+K">Konstantinos Sgouras</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">Virtual memory is a cornerstone of modern computing systems.Introduced as one
of the earliest instances of hardware-software co-design, VM facilitates
programmer-transparent memory man agement, data sharing, process isolation and
memory protection. Evaluating the efficiency of various virtual memory (VM)
designs is crucial (i) given their significant impact on the system, including
the CPU caches, the main memory, and the storage device and (ii) given that
different system architectures might benefit from various VM techniques. Such
an evaluation is not straightforward, as it heavily hinges on modeling the
interplay between different VM techniques and the interactions of VM with the
system architecture. Modern simulators, however, struggle to keep up with the
rapid VM research developments, lacking the capability to model a wide range of
contemporary VM techniques and their interactions. To this end, we present
Virtuoso, an open-source, comprehensive and modular simulation framework that
models various VM designs to establish a common ground for virtual memory
research. We demonstrate the versatility and the potential of Virtuoso with
four new case studies. Virtuoso is freely open-source and can be found at
https://github.com/CMU-SAFARI/Virtuoso.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04636" title="Abstract">arXiv:2403.04636</a> [<a href="/pdf/2403.04636" title="Download PDF">pdf</a>, <a href="/format/2403.04636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy Aware Message Passing in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazari%2C+P">Philipp Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Lemke%2C+O">Oliver Lemke</a>, 
<a href="/search/cs?searchtype=author&query=Guidobene%2C+D">Davide Guidobene</a>, 
<a href="/search/cs?searchtype=author&query=Gesp%2C+A">Artiom Gesp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep Graph Neural Networks struggle with oversmoothing. This paper introduces
a novel, physics-inspired GNN model designed to mitigate this issue. Our
approach integrates with existing GNN architectures, introducing an
entropy-aware message passing term. This term performs gradient ascent on the
entropy during node aggregation, thereby preserving a certain degree of entropy
in the embeddings. We conduct a comparative analysis of our model against
state-of-the-art GNNs across various common datasets.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04638" title="Abstract">arXiv:2403.04638</a> [<a href="/pdf/2403.04638" title="Download PDF">pdf</a>, <a href="/format/2403.04638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable, Simulation-Guided Compliant Tactile Finger Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuxiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Arpit Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S+Q">Sandra Q. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wenzhen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Adelson%2C+E+H">Edward H. Adelson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Yuxiang Ma, Arpit Agarwal, and Sandra Q. Liu contributed equally to this work. Project video: <a href="https://youtu.be/CnTUTA5cfMw">this https URL</a> . 7 pages, 11 figures, 2024 IEEE International Conference on Soft Robotics (RoboSoft)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Compliant grippers enable robots to work with humans in unstructured
environments. In general, these grippers can improve with tactile sensing to
estimate the state of objects around them to precisely manipulate objects.
However, co-designing compliant structures with high-resolution tactile sensing
is a challenging task. We propose a simulation framework for the end-to-end
forward design of GelSight Fin Ray sensors. Our simulation framework consists
of mechanical simulation using the finite element method (FEM) and optical
simulation including physically based rendering (PBR). To simulate the
fluorescent paint used in these GelSight Fin Rays, we propose an efficient
method that can be directly integrated in PBR. Using the simulation framework,
we investigate design choices available in the compliant grippers, namely gel
pad shapes, illumination conditions, Fin Ray gripper sizes, and Fin Ray
stiffness. This infrastructure enables faster design and prototype time frames
of new Fin Ray sensors that have various sensing areas, ranging from 48 mm
$\times$ \18 mm to 70 mm $\times$ 35 mm. Given the parameters we choose, we can
thus optimize different Fin Ray designs and show their utility in grasping
day-to-day objects.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04639" title="Abstract">arXiv:2403.04639</a> [<a href="/pdf/2403.04639" title="Download PDF">pdf</a>, <a href="/ps/2403.04639" title="Download PostScript">ps</a>, <a href="/format/2403.04639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaCmS: Magahi Code-mixed Dataset for Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rani%2C+P">Priya Rani</a>, 
<a href="/search/cs?searchtype=author&query=Negi%2C+G">Gaurav Negi</a>, 
<a href="/search/cs?searchtype=author&query=Fransen%2C+T">Theodorus Fransen</a>, 
<a href="/search/cs?searchtype=author&query=McCrae%2C+J+P">John P. McCrae</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lrec-Colin 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The present paper introduces new sentiment data, MaCMS, for
Magahi-Hindi-English (MHE) code-mixed language, where Magahi is a
less-resourced minority language. This dataset is the first
Magahi-Hindi-English code-mixed dataset for sentiment analysis tasks. Further,
we also provide a linguistics analysis of the dataset to understand the
structure of code-mixing and a statistical study to understand the language
preferences of speakers with different polarities. With these analyses, we also
train baseline models to evaluate the dataset's quality.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04640" title="Abstract">arXiv:2403.04640</a> [<a href="/pdf/2403.04640" title="Download PDF">pdf</a>, <a href="/format/2403.04640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAT: Enhancing Multimodal Large Language Model to Answer Questions in  Dynamic Audio-Visual Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qilang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zitong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Rui Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xinyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper focuses on the challenge of answering questions in scenarios that
are composed of rich and complex dynamic audio-visual components. Although
existing Multimodal Large Language Models (MLLMs) can respond to audio-visual
content, these responses are sometimes ambiguous and fail to describe specific
audio-visual events. To overcome this limitation, we introduce the CAT, which
enhances MLLM in three ways: 1) besides straightforwardly bridging audio and
video, we design a clue aggregator that aggregates question-related clues in
dynamic audio-visual scenarios to enrich the detailed knowledge required for
large language models. 2) CAT is trained on a mixed multimodal dataset,
allowing direct application in audio-visual scenarios. Notably, we collect an
audio-visual joint instruction dataset named AVinstruct, to further enhance the
capacity of CAT to model cross-semantic correlations. 3) we propose AI-assisted
ambiguity-aware direct preference optimization, a strategy specialized in
retraining the model to favor the non-ambiguity response and improve the
ability to localize specific audio-visual objects. Extensive experimental
results demonstrate that CAT outperforms existing methods on multimodal tasks,
especially in Audio-Visual Question Answering (AVQA) tasks. The codes and the
collected instructions are released at https://github.com/rikeilong/Bay-CAT.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04641" title="Abstract">arXiv:2403.04641</a> [<a href="/pdf/2403.04641" title="Download PDF">pdf</a>, <a href="/ps/2403.04641" title="Download PostScript">ps</a>, <a href="/format/2403.04641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The interdefinability of expansions of Belnap-Dunn logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Middelburg%2C+C+A">C. A. Middelburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages. arXiv admin note: text overlap with <a href="/abs/2301.10555">arXiv:2301.10555</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">Belnap-Dunn logic, also knows as the logic of First-Degree Entailment, is a
logic that can serve as the underlying logic of theories that are inconsistent
or incomplete. For various reasons, different expansions of Belnap-Dunn logic
with non-classical connectives have been studied. This paper investigates the
question whether those expansions are interdefinable with an expansion whose
connectives include only classical connectives. This is worth knowing because
it is difficult to say how close a logic with non-classical connectives is
related to classical logic. The notion of interdefinability of logics used is
based on a general notion of definability of a connective in a logic that seems
to have been forgotten.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04642" title="Abstract">arXiv:2403.04642</a> [<a href="/pdf/2403.04642" title="Download PDF">pdf</a>, <a href="/format/2403.04642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Large Language Models to Reason with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havrilla%2C+A">Alex Havrilla</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Raparthy%2C+S+C">Sharath Chandra Raparthy</a>, 
<a href="/search/cs?searchtype=author&query=Nalmpantis%2C+C">Christoforos Nalmpantis</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi-Yu%2C+J">Jane Dwivedi-Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuravinskyi%2C+M">Maksym Zhuravinskyi</a>, 
<a href="/search/cs?searchtype=author&query=Hambro%2C+E">Eric Hambro</a>, 
<a href="/search/cs?searchtype=author&query=Sukhbaatar%2C+S">Sainbayar Sukhbaatar</a>, 
<a href="/search/cs?searchtype=author&query=Raileanu%2C+R">Roberta Raileanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (\textbf{RLHF}) has emerged as a
dominant approach for aligning LLM outputs with human preferences. Inspired by
the success of RLHF, we study the performance of multiple algorithms that learn
from feedback (Expert Iteration, Proximal Policy Optimization (\textbf{PPO}),
Return-Conditioned RL) on improving LLM reasoning capabilities. We investigate
both sparse and dense rewards provided to the LLM both heuristically and via a
learned reward model. We additionally start from multiple model sizes and
initializations both with and without supervised fine-tuning (\textbf{SFT})
data. Overall, we find all algorithms perform comparably, with Expert Iteration
performing best in most cases. Surprisingly, we find the sample complexity of
Expert Iteration is similar to that of PPO, requiring at most on the order of
$10^6$ samples to converge from a pretrained checkpoint. We investigate why
this is the case, concluding that during RL training models fail to explore
significantly beyond solutions already produced by SFT models. Additionally, we
discuss a trade off between maj@1 and pass@96 metric performance during SFT
training and how conversely RL training improves both simultaneously. We then
conclude by discussing the implications of our findings for RLHF and the future
role of RL in LLM fine-tuning.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04643" title="Abstract">arXiv:2403.04643</a> [<a href="/pdf/2403.04643" title="Download PDF">pdf</a>, <a href="/format/2403.04643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAQ: Quality Adaptive Quantization for LLM KV Cache
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shichen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jiayu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The emergence of LLMs has ignited a fresh surge of breakthroughs in NLP
applications, particularly in domains such as question-answering systems and
text generation. As the need for longer context grows, a significant bottleneck
in model deployment emerges due to the linear expansion of the Key-Value (KV)
cache with the context length. Existing methods primarily rely on various
hypotheses, such as sorting the KV cache based on attention scores for
replacement or eviction, to compress the KV cache and improve model throughput.
However, heuristics used by these strategies may wrongly evict essential KV
cache, which can significantly degrade model performance. In this paper, we
propose QAQ, a Quality Adaptive Quantization scheme for the KV cache. We
theoretically demonstrate that key cache and value cache exhibit distinct
sensitivities to quantization, leading to the formulation of separate
quantization strategies for their non-uniform quantization. Through the
integration of dedicated outlier handling, as well as an improved
attention-aware approach, QAQ achieves up to 10x the compression ratio of the
KV cache size with a neglectable impact on model performance. QAQ significantly
reduces the practical hurdles of deploying LLMs, opening up new possibilities
for longer-context applications. The code is available at
github.com/ClubieDong/KVCacheQuantization.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04650" title="Abstract">arXiv:2403.04650</a> [<a href="/pdf/2403.04650" title="Download PDF">pdf</a>, <a href="/format/2403.04650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Based Multimodal Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faye%2C+B">Bilal Faye</a>, 
<a href="/search/cs?searchtype=author&query=Azzag%2C+H">Hanane Azzag</a>, 
<a href="/search/cs?searchtype=author&query=Lebbah%2C+M">Mustapha Lebbah</a>, 
<a href="/search/cs?searchtype=author&query=Bouchaffra%2C+D">Djamel Bouchaffra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The fusion models, which effectively combine information from different
sources, are widely used in solving multimodal tasks. However, they have
significant limitations related to aligning data distributions across different
modalities. This challenge can lead to inconsistencies and difficulties in
learning robust representations. Alignment models, while specifically
addressing this issue, often require training "from scratch" with large
datasets to achieve optimal results, which can be costly in terms of resources
and time. To overcome these limitations, we propose an innovative model called
Context-Based Multimodal Fusion (CBMF), which combines both modality fusion and
data distribution alignment. In CBMF, each modality is represented by a
specific context vector, fused with the embedding of each modality. This
enables the use of large pre-trained models that can be frozen, reducing the
computational and training data requirements. Additionally, the network learns
to differentiate embeddings of different modalities through fusion with context
and aligns data distributions using a contrastive approach for self-supervised
learning. Thus, CBMF offers an effective and economical solution for solving
complex multimodal tasks.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04651" title="Abstract">arXiv:2403.04651</a> [<a href="/pdf/2403.04651" title="Download PDF">pdf</a>, <a href="/format/2403.04651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cedar: A New Language for Expressive, Fast, Safe, and Analyzable  Authorization (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cutler%2C+J">Joseph Cutler</a>, 
<a href="/search/cs?searchtype=author&query=Disselkoen%2C+C">Craig Disselkoen</a>, 
<a href="/search/cs?searchtype=author&query=Eline%2C+A">Aaron Eline</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shaobo He</a>, 
<a href="/search/cs?searchtype=author&query=Headley%2C+K">Kyle Headley</a>, 
<a href="/search/cs?searchtype=author&query=Hicks%2C+M">Michael Hicks</a>, 
<a href="/search/cs?searchtype=author&query=Hietala%2C+K">Kesha Hietala</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+E">Elefterios Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Kastner%2C+J">John Kastner</a>, 
<a href="/search/cs?searchtype=author&query=Mamat%2C+A">Anwar Mamat</a>, 
<a href="/search/cs?searchtype=author&query=McAdams%2C+D">Darin McAdams</a>, 
<a href="/search/cs?searchtype=author&query=McCutchen%2C+M">Matt McCutchen</a>, 
<a href="/search/cs?searchtype=author&query=Rungta%2C+N">Neha Rungta</a>, 
<a href="/search/cs?searchtype=author&query=Torlak%2C+E">Emina Torlak</a>, 
<a href="/search/cs?searchtype=author&query=Wells%2C+A">Andrew Wells</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Cedar is a new authorization policy language designed to be ergonomic, fast,
safe, and analyzable. Rather than embed authorization logic in an application's
code, developers can write that logic as Cedar policies and delegate access
decisions to Cedar's evaluation engine. Cedar's simple and intuitive syntax
supports common authorization use-cases with readable policies, naturally
leveraging concepts from role-based, attribute-based, and relation-based access
control models. Cedar's policy structure enables access requests to be decided
quickly. Cedar's policy validator leverages optional typing to help policy
writers avoid mistakes, but not get in their way. Cedar's design has been
finely balanced to allow for a sound and complete logical encoding, which
enables precise policy analysis, e.g., to ensure that when refactoring a set of
policies, the authorized permissions do not change. We have modeled Cedar in
the Lean programming language, and used Lean's proof assistant to prove
important properties of Cedar's design. We have implemented Cedar in Rust, and
released it open-source. Comparing Cedar to two open-source languages, OpenFGA
and Rego, we find (subjectively) that Cedar has equally or more readable
policies, but (objectively) performs far better.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04652" title="Abstract">arXiv:2403.04652</a> [<a href="/pdf/2403.04652" title="Download PDF">pdf</a>, <a href="/format/2403.04652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Yi: Open Foundation Models by 01.AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AI%2C+0">01.AI</a>: 
<a href="/search/cs?searchtype=author&query=Young%2C+A">Alex Young</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guanwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiangcheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianqun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jing Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaidong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Shawn Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Senbin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaohui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoyi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xinyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+P">Pengcheng Nie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuchi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yudong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuxuan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhenyu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zonghong Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce the Yi model family, a series of language and multimodal models
that demonstrate strong multi-dimensional capabilities. The Yi model family is
based on 6B and 34B pretrained language models, then we extend them to chat
models, 200K long context models, depth-upscaled models, and vision-language
models. Our base models achieve strong performance on a wide range of
benchmarks like MMLU, and our finetuned chat models deliver strong human
preference rate on major evaluation platforms like AlpacaEval and Chatbot
Arena. Building upon our scalable super-computing infrastructure and the
classical transformer architecture, we attribute the performance of Yi models
primarily to its data quality resulting from our data-engineering efforts. For
pretraining, we construct 3.1 trillion tokens of English and Chinese corpora
using a cascaded data deduplication and quality filtering pipeline. For
finetuning, we polish a small scale (less than 10K) instruction dataset over
multiple iterations such that every single instance has been verified directly
by our machine learning engineers. For vision-language, we combine the chat
language model with a vision transformer encoder and train the model to align
visual representations to the semantic space of the language model. We further
extend the context length to 200K through lightweight continual pretraining and
demonstrate strong needle-in-a-haystack retrieval performance. We show that
extending the depth of the pretrained checkpoint through continual pretraining
further improves performance. We believe that given our current results,
continuing to scale up model parameters using thoroughly optimized data will
lead to even stronger frontier models.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04654" title="Abstract">arXiv:2403.04654</a> [<a href="/pdf/2403.04654" title="Download PDF">pdf</a>, <a href="/format/2403.04654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Person Verification based on Recursive Fusion of Joint  Cross-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Praveen%2C+R+G">R. Gnana Praveen</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+J">Jahangir Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FG2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Person or identity verification has been recently gaining a lot of attention
using audio-visual fusion as faces and voices share close associations with
each other. Conventional approaches based on audio-visual fusion rely on
score-level or early feature-level fusion techniques. Though existing
approaches showed improvement over unimodal systems, the potential of
audio-visual fusion for person verification is not fully exploited. In this
paper, we have investigated the prospect of effectively capturing both the
intra- and inter-modal relationships across audio and visual modalities, which
can play a crucial role in significantly improving the fusion performance over
unimodal systems. In particular, we introduce a recursive fusion of a joint
cross-attentional model, where a joint audio-visual feature representation is
employed in the cross-attention framework in a recursive fashion to
progressively refine the feature representations that can efficiently capture
the intra-and inter-modal relationships. To further enhance the audio-visual
feature representations, we have also explored BLSTMs to improve the temporal
modeling of audio-visual feature representations. Extensive experiments are
conducted on the Voxceleb1 dataset to evaluate the proposed model. Results
indicate that the proposed model shows promising improvement in fusion
performance by adeptly capturing the intra-and inter-modal relationships across
audio and visual modalities.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04655" title="Abstract">arXiv:2403.04655</a> [<a href="/pdf/2403.04655" title="Download PDF">pdf</a>, <a href="/ps/2403.04655" title="Download PostScript">ps</a>, <a href="/format/2403.04655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closed-loop Performance Optimization of Model Predictive Control with  Robustness Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zuliani%2C+R">Riccardo Zuliani</a>, 
<a href="/search/eess?searchtype=author&query=Balta%2C+E+C">Efe C. Balta</a>, 
<a href="/search/eess?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Model mismatch and process noise are two frequently occurring phenomena that
can drastically affect the performance of model predictive control (MPC) in
practical applications. We propose a principled way to tune the cost function
and the constraints of linear MPC schemes to achieve good performance and
robust constraint satisfaction on uncertain nonlinear dynamics with additive
noise. The tuning is performed using a novel MPC tuning algorithm based on
backpropagation developed in our earlier work. Using the scenario approach, we
provide probabilistic bounds on the likelihood of closed-loop constraint
violation over a finite horizon. We showcase the effectiveness of the proposed
method on linear and nonlinear simulation examples.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04656" title="Abstract">arXiv:2403.04656</a> [<a href="/pdf/2403.04656" title="Download PDF">pdf</a>, <a href="/format/2403.04656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Thought Explanation for Dialogue State Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Ningxin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daquan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jinlan Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Dialogue state tracking (DST) aims to record user queries and goals during a
conversational interaction achieved by maintaining a predefined set of slots
and their corresponding values. Current approaches decide slot values opaquely,
while humans usually adopt a more deliberate approach by collecting information
from relevant dialogue turns and then reasoning the appropriate values. In this
work, we focus on the steps needed to figure out slot values by proposing a
model named Chain-of-Thought-Explanation (CoTE) for the DST task. CoTE, which
is built on the generative DST framework, is designed to create detailed
explanations step by step after determining the slot values. This process leads
to more accurate and reliable slot values. More-over, to improve the reasoning
ability of the CoTE, we further construct more fluent and high-quality
explanations with automatic paraphrasing, leading the method CoTE-refined.
Experimental results on three widely recognized DST benchmarks-MultiWOZ 2.2,
WoZ 2.0, and M2M-demonstrate the remarkable effectiveness of the CoTE.
Furthermore, through a meticulous fine-grained analysis, we observe significant
benefits of our CoTE on samples characterized by longer dialogue turns, user
responses, and reasoning steps.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04659" title="Abstract">arXiv:2403.04659</a> [<a href="/pdf/2403.04659" title="Download PDF">pdf</a>, <a href="/format/2403.04659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Did They Consent to That?&quot;: Safer Digital Intimacy via Proactive  Protection Against Image-Based Sexual Abuse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lucy Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hamilton%2C+V">Vaughn Hamilton</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sharon Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aydinalp%2C+Y">Yigit Aydinalp</a>, 
<a href="/search/cs?searchtype=author&query=Scarlett%2C+M">Marin Scarlett</a>, 
<a href="/search/cs?searchtype=author&query=Redmiles%2C+E+M">Elissa M. Redmiles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">As many as 8 in 10 adults share intimate content such as nude or lewd images.
Sharing such content has significant benefits for relationship intimacy and
body image, and can offer employment. However, stigmatizing attitudes and a
lack of technological mitigations put those sharing such content at risk of
sexual violence. An estimated 1 in 3 people have been subjected to image-based
sexual abuse (IBSA), a spectrum of violence that includes the nonconsensual
distribution or threat of distribution of consensually-created intimate content
(also called NDII). In this work, we conducted a rigorous empirical interview
study of 52 European creators of intimate content to examine the threats they
face and how they defend against them, situated in the context of their
different use cases for intimate content sharing and their choice of
technologies for storing and sharing such content. Synthesizing our results
with the limited body of prior work on technological prevention of NDII, we
offer concrete next steps for both platforms and security &amp; privacy researchers
to work toward safer intimate content sharing through proactive protection.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04660" title="Abstract">arXiv:2403.04660</a> [<a href="/pdf/2403.04660" title="Download PDF">pdf</a>, <a href="/format/2403.04660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Design Space of Optical See-through AR Head-Mounted  Displays to Support First Responders in the Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cochran%2C+B">Brianna Cochran</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruijia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hartung%2C+L">Lance Hartung</a>, 
<a href="/search/cs?searchtype=author&query=Sprecher%2C+B">Bryce Sprecher</a>, 
<a href="/search/cs?searchtype=author&query=Tredinnick%2C+R">Ross Tredinnick</a>, 
<a href="/search/cs?searchtype=author&query=Ponto%2C+K">Kevin Ponto</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Suman Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuhang Zhao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">First responders (FRs) navigate hazardous, unfamiliar environments in the
field (e.g., mass-casualty incidents), making life-changing decisions in a
split second. AR head-mounted displays (HMDs) have shown promise in supporting
them due to its capability of recognizing and augmenting the challenging
environments in a hands-free manner. However, the design space have not been
thoroughly explored by involving various FRs who serve different roles (e.g.,
firefighters, law enforcement) but collaborate closely in the field. We
interviewed 26 first responders in the field who experienced a state-of-the-art
optical-see-through AR HMD, as well as its interaction techniques and four
types of AR cues (i.e., overview cues, directional cues, highlighting cues, and
labeling cues), soliciting their first-hand experiences, design ideas, and
concerns. Our study revealed both generic and role-specific preferences and
needs for AR hardware, interactions, and feedback, as well as identifying
desired AR designs tailored to urgent, risky scenarios (e.g., affordance
augmentation to facilitate fast and safe action). While acknowledging the value
of AR HMDs, concerns were also raised around trust, privacy, and proper
integration with other equipment. Finally, we derived comprehensive and
actionable design guidelines to inform future AR systems for in-field FRs.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04661" title="Abstract">arXiv:2403.04661</a> [<a href="/pdf/2403.04661" title="Download PDF">pdf</a>, <a href="/format/2403.04661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Cross Attention for Audio-Visual Person Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Praveen%2C+R+G">R. Gnana Praveen</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+J">Jahangir Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FG2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Although person or identity verification has been predominantly explored
using individual modalities such as face and voice, audio-visual fusion has
recently shown immense potential to outperform unimodal approaches. Audio and
visual modalities are often expected to pose strong complementary
relationships, which plays a crucial role in effective audio-visual fusion.
However, they may not always strongly complement each other, they may also
exhibit weak complementary relationships, resulting in poor audio-visual
feature representations. In this paper, we propose a Dynamic Cross-Attention
(DCA) model that can dynamically select the cross-attended or unattended
features on the fly based on the strong or weak complementary relationships,
respectively, across audio and visual modalities. In particular, a conditional
gating layer is designed to evaluate the contribution of the cross-attention
mechanism and choose cross-attended features only when they exhibit strong
complementary relationships, otherwise unattended features. Extensive
experiments are conducted on the Voxceleb1 dataset to demonstrate the
robustness of the proposed model. Results indicate that the proposed model
consistently improves the performance on multiple variants of cross-attention
while outperforming the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04665" title="Abstract">arXiv:2403.04665</a> [<a href="/pdf/2403.04665" title="Download PDF">pdf</a>, <a href="/format/2403.04665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GreenBytes: Intelligent Energy Estimation for Edge-Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kassai%2C+K">Kasra Kassai</a>, 
<a href="/search/cs?searchtype=author&query=Dagiuklas%2C+T">Tasos Dagiuklas</a>, 
<a href="/search/cs?searchtype=author&query=Bashir%2C+S">Satwat Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+M">Muddesar Iqbal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Emerging Technologies (cs.ET); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This study investigates the application of advanced machine learning models,
specifically Long Short-Term Memory (LSTM) networks and Gradient Booster
models, for accurate energy consumption estimation within a Kubernetes cluster
environment. It aims to enhance sustainable computing practices by providing
precise predictions of energy usage across various computing nodes. Through
meticulous analysis of model performance on both master and worker nodes, the
research reveals the strengths and potential applications of these models in
promoting energy efficiency. The LSTM model demonstrates remarkable predictive
accuracy, particularly in capturing dynamic computing workloads over time,
evidenced by low mean squared error (MSE) rates and the ability to closely
track actual energy consumption trends. Conversely, the Gradient Booster model
showcases robustness and adaptability across different computational
environments, despite slightly higher MSE values. The study underscores the
complementary nature of these models in advancing sustainable computing
practices, suggesting their integration into energy management systems could
significantly enhance environmental sustainability in technology operations.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04666" title="Abstract">arXiv:2403.04666</a> [<a href="/pdf/2403.04666" title="Download PDF">pdf</a>, <a href="/format/2403.04666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Telecom Language Models: Must They Be Large?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piovesan%2C+N">Nicola Piovesan</a>, 
<a href="/search/cs?searchtype=author&query=De+Domenico%2C+A">Antonio De Domenico</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+F">Fadhel Ayed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing interest in Large Language Models (LLMs) within the
telecommunications sector underscores their potential to revolutionize
operational efficiency. However, the deployment of these sophisticated models
is often hampered by their substantial size and computational demands, raising
concerns about their viability in resource-constrained environments. Addressing
this challenge, recent advancements have seen the emergence of small language
models that surprisingly exhibit performance comparable to their larger
counterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a
compact yet powerful model, exemplifies this new wave of efficient small
language models. This paper conducts a comprehensive evaluation of Phi-2's
intrinsic understanding of the telecommunications domain. Recognizing the
scale-related limitations, we enhance Phi-2's capabilities through a
Retrieval-Augmented Generation approach, meticulously integrating an extensive
knowledge base specifically curated with telecom standard specifications. The
enhanced Phi-2 model demonstrates a profound improvement in accuracy, answering
questions about telecom standards with a precision that closely rivals the more
resource-intensive GPT-3.5. The paper further explores the refined capabilities
of Phi-2 in addressing problem-solving scenarios within the telecom sector,
highlighting its potential and limitations.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04667" title="Abstract">arXiv:2403.04667</a> [<a href="/pdf/2403.04667" title="Download PDF">pdf</a>, <a href="/format/2403.04667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Social Impact of Generative AI: An Analysis on ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldassarre%2C+M+T">Maria T. Baldassarre</a>, 
<a href="/search/cs?searchtype=author&query=Caivano%2C+D">Danilo Caivano</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+B+F">Berenice Fernandez Nieto</a>, 
<a href="/search/cs?searchtype=author&query=Gigante%2C+D">Domenico Gigante</a>, 
<a href="/search/cs?searchtype=author&query=Ragone%2C+A">Azzurra Ragone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at GoodIT2023 - ACM Conference on Information Technology for Social Good
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">In recent months, the social impact of Artificial Intelligence (AI) has
gained considerable public interest, driven by the emergence of Generative AI
models, ChatGPT in particular. The rapid development of these models has
sparked heated discussions regarding their benefits, limitations, and
associated risks. Generative models hold immense promise across multiple
domains, such as healthcare, finance, and education, to cite a few, presenting
diverse practical applications. Nevertheless, concerns about potential adverse
effects have elicited divergent perspectives, ranging from privacy risks to
escalating social inequality. This paper adopts a methodology to delve into the
societal implications of Generative AI tools, focusing primarily on the case of
ChatGPT. It evaluates the potential impact on several social sectors and
illustrates the findings of a comprehensive literature review of both positive
and negative effects, emerging trends, and areas of opportunity of Generative
AI models. This analysis aims to facilitate an in-depth discussion by providing
insights that can inspire policy, regulation, and responsible development
practices to foster a human-centered AI.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04670" title="Abstract">arXiv:2403.04670</a> [<a href="/pdf/2403.04670" title="Download PDF">pdf</a>, <a href="/format/2403.04670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Conditional Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chenreddy%2C+A">Abhilash Chenreddy</a>, 
<a href="/search/cs?searchtype=author&query=Delage%2C+E">Erick Delage</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The field of Contextual Optimization (CO) integrates machine learning and
optimization to solve decision making problems under uncertainty. Recently, a
risk sensitive variant of CO, known as Conditional Robust Optimization (CRO),
combines uncertainty quantification with robust optimization in order to
promote safety and reliability in high stake applications. Exploiting modern
differentiable optimization methods, we propose a novel end-to-end approach to
train a CRO model in a way that accounts for both the empirical risk of the
prescribed decisions and the quality of conditional coverage of the contextual
uncertainty set that supports them. While guarantees of success for the latter
objective are impossible to obtain from the point of view of conformal
prediction theory, high quality conditional coverage is achieved empirically by
ingeniously employing a logistic regression differentiable layer within the
calculation of coverage quality in our training loss. We show that the proposed
training algorithms produce decisions that outperform the traditional estimate
then optimize approaches.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04671" title="Abstract">arXiv:2403.04671</a> [<a href="/pdf/2403.04671" title="Download PDF">pdf</a>, <a href="/format/2403.04671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greater than the sum of its parts: The role of minority and majority  status in collaborative problem-solving communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cavazos%2C+J+G">Jacqueline G. Cavazos</a>, 
<a href="/search/cs?searchtype=author&query=Nixon%2C+N">Nia Nixon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Collaborative problem-solving (CPS) is a vital skill used both in the
workplace and in educational environments. CPS is useful in tackling
increasingly complex global, economic, and political issues and is considered a
central 21st century skill. The increasingly connected global community
presents a fruitful opportunity for creative and collaborative problem-solving
interactions and solutions that involve diverse perspectives. Unfortunately,
women and underrepresented minorities (URMs) often face obstacles during
collaborative interactions that hinder their key participation in these
problem-solving conversations. Here, we explored the communication patterns of
minority and non-minority individuals working together in a CPS task. Group
Communication Analysis (GCA), a temporally-sensitive computational linguistic
tool, was used to examine how URM status impacts individuals' sociocognitive
linguistic patterns. Results show differences across racial/ethnic groups in
key sociocognitive features that indicate fruitful collaborative interactions.
We also investigated how the groups' racial/ethnic composition impacts both
individual and group communication patterns. In general, individuals in more
demographically diverse groups displayed more productive communication
behaviors than individuals who were in majority-dominated groups. We discuss
the implications of individual and group diversity on communication patterns
that emerge during CPS and how these patterns can impact collaborative
outcomes.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04672" title="Abstract">arXiv:2403.04672</a> [<a href="/pdf/2403.04672" title="Download PDF">pdf</a>, <a href="/format/2403.04672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular Arithmetic Coding (MAC) for Internet of Bio-Nano Things  (IoBNT)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+M">Melih &#x15e;ahin</a>, 
<a href="/search/cs?searchtype=author&query=Ortlek%2C+B+E">Beyza E. Ortlek</a>, 
<a href="/search/cs?searchtype=author&query=Akan%2C+O+B">Ozgur B. Akan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 24 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Molecular Communication (MC) has emerged as a promising paradigm employing
molecules to transfer information at the nano-scale. Unlike MC channel coding,
MC source coding has remained mostly an unexplored area of research. In a
recent paper, prefix source coding was introduced into the field, through an
MC-adapted version of the Huffman Coding. In the context of MC source coding,
this paper proposes the Molecular Arithmetic Coding (MAC) whose algorithmic
implementation and code-structure is non-arbitrarily different than that of the
widely-known classical arithmetic coding. MAC is designed to mitigate
Inter-Symbol Interference (ISI) for alphabets with known symbol probabilities
through, in a highly efficient way, avoiding consecutive 1-bits. However, due
to bit precision limitations any arithmetic coding method faces, without any
assumption made on the structure of the symbol alphabet, unique-decodability of
MAC is not guaranteed. Accordingly, a uniquely-decodable new coding scheme
named Molecular Arithmetic with Prefix Coding (MAPC) is also introduced. Across
multiple alphabets, we show that MAPC provides a better compression performance
compared to the optimal MC-adapted prefix coding. Simulation results of an
exemplary alphabet demonstrates the superior symbol and word error rate
performance of MAPC compared to the optimal MC-adapted prefix coding and to the
uncoded BCSK schemes.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04675" title="Abstract">arXiv:2403.04675</a> [<a href="/pdf/2403.04675" title="Download PDF">pdf</a>, <a href="/format/2403.04675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Regulation of Detention Ponds via Feedback Control: Balancing  Flood Mitigation and Water Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gomes%2C+M+N">Marcus N&#xf3;brega Gomes Jr</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A+F">Ahmad F. Taha</a>, 
<a href="/search/eess?searchtype=author&query=R%C3%A1pallo%2C+L+M+C">Luis Miguel C. R&#xe1;pallo</a>, 
<a href="/search/eess?searchtype=author&query=Mendiondo%2C+E+M">Eduardo M. Mendiondo</a>, 
<a href="/search/eess?searchtype=author&query=Giacomoni%2C+M+H">Marcio H. Giacomoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Floods in urban areas are becoming more intense due to unplanned urbanization
and more frequent due to climate change. One of the most effective strategies
to alleviate the effects of flooding is the use of flood control reservoirs
such as detention ponds, which attenuate flood waves by storing water and
slowing the release after the storm. Detention ponds can also improve water
quality by allowing the settlement of pollutants inside the reservoir. The
operation of most detention ponds occurs passively, where the outflows are
governed by fixed hydraulic structures such as fully open orifices and weirs.
The operation of detention ponds can be enhanced with active controls: orifices
can be retrofitted with controlled valves, and spillways can have controllable
gates such that their control schedule can be defined in real-time with a model
predictive control (MPC) approach. In this paper, we develop a distributed
quasi-2D hydrologic-hydrodynamic coupled with a reservoir flood routing model
and an optimization approach (MPC) to identify the opening or closing of valves
and movable gates working as spillways. We adapt the optimization problem to
switch from a flood-related cost function to a heuristic function that aims to
increase the detention time when no inflow hydrographs are predicted within a
prediction horizon. The numerical case studies show the potential results of
applying the methods herein developed in a real-world watershed in Sao Paulo,
Brazil. We test the performance of MPC compared to static (i.e., fixed
hydraulic device opening) alternatives with valves either fully or partially
opened. The results indicate that the control algorithm presented in this paper
can achieve greater flood and proxy water quality performance compared to
passive scenarios.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04680" title="Abstract">arXiv:2403.04680</a> [<a href="/pdf/2403.04680" title="Download PDF">pdf</a>, <a href="/format/2403.04680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extensive-Form Game Solving via Blackwell Approachability on Treeplexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+D">Darshan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Grand-Cl%C3%A9ment%2C+J">Julien Grand-Cl&#xe9;ment</a>, 
<a href="/search/cs?searchtype=author&query=Kroer%2C+C">Christian Kroer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In this paper, we introduce the first algorithmic framework for Blackwell
approachability on the sequence-form polytope, the class of convex polytopes
capturing the strategies of players in extensive-form games (EFGs). This leads
to a new class of regret-minimization algorithms that are stepsize-invariant,
in the same sense as the Regret Matching and Regret Matching$^+$ algorithms for
the simplex. Our modular framework can be combined with any existing regret
minimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs
with perfect recall, through the self-play framework. Leveraging predictive
online mirror descent, we introduce Predictive Treeplex Blackwell$^+$
(PTB$^+$), and show a $O(1/\sqrt{T})$ convergence rate to Nash equilibrium in
self-play. We then show how to stabilize PTB$^+$ with a stepsize, resulting in
an algorithm with a state-of-the-art $O(1/T)$ convergence rate. We provide an
extensive set of experiments to compare our framework with several algorithmic
benchmarks, including CFR$^+$ and its predictive variant, and we highlight
interesting connections between practical performance and the
stepsize-dependence or stepsize-invariance properties of classical algorithms.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04690" title="Abstract">arXiv:2403.04690</a> [<a href="/pdf/2403.04690" title="Download PDF">pdf</a>, <a href="/format/2403.04690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self  Attention at the Threadblock Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassani%2C+A">Ali Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Hwu%2C+W">Wen-Mei Hwu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/SHI-Labs/NATTEN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neighborhood attention reduces the cost of self attention by restricting each
token's attention span to its nearest neighbors. This restriction,
parameterized by a window size and dilation factor, draws a spectrum of
possible attention patterns between linear projection and self attention.
Neighborhood attention, and more generally sliding window attention patterns,
have long been bounded by infrastructure, particularly in higher-rank spaces
(2-D and 3-D), calling for the development of custom kernels, which have been
limited in either functionality, or performance, if not both. In this work, we
first show that neighborhood attention can be represented as a batched GEMM
problem, similar to standard attention, and implement it for 1-D and 2-D
neighborhood attention. These kernels on average provide 895% and 272%
improvement in full precision latency compared to existing naive kernels for
1-D and 2-D neighborhood attention respectively. We find certain inherent
inefficiencies in all unfused neighborhood attention kernels that bound their
performance and lower-precision scalability. We also developed fused
neighborhood attention; an adaptation of fused dot-product attention kernels
that allow fine-grained control over attention across different spatial axes.
Known for reducing the quadratic time complexity of self attention to a linear
complexity, neighborhood attention can now enjoy a reduced and constant memory
footprint, and record-breaking half precision latency. We observe that our
fused kernels successfully circumvent some of the unavoidable inefficiencies in
unfused implementations. While our unfused GEMM-based kernels only improve half
precision performance compared to naive kernels by an average of 496% and 113%
in 1-D and 2-D problems respectively, our fused kernels improve naive kernels
by an average of 1607% and 581% in 1-D and 2-D problems respectively.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04692" title="Abstract">arXiv:2403.04692</a> [<a href="/pdf/2403.04692" title="Download PDF">pdf</a>, <a href="/format/2403.04692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PixArt-&#x3a3;: Weak-to-Strong Training of Diffusion Transformer for 4K  Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongdao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://pixart-alpha.github.io/PixArt-sigma-project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce PixArt-\Sigma, a Diffusion Transformer
model~(DiT) capable of directly generating images at 4K resolution.
PixArt-\Sigma represents a significant advancement over its predecessor,
PixArt-\alpha, offering images of markedly higher fidelity and improved
alignment with text prompts. A key feature of PixArt-\Sigma is its training
efficiency. Leveraging the foundational pre-training of PixArt-\alpha, it
evolves from the `weaker' baseline to a `stronger' model via incorporating
higher quality data, a process we term "weak-to-strong training". The
advancements in PixArt-\Sigma are twofold: (1) High-Quality Training Data:
PixArt-\Sigma incorporates superior-quality image data, paired with more
precise and detailed image captions. (2) Efficient Token Compression: we
propose a novel attention module within the DiT framework that compresses both
keys and values, significantly improving efficiency and facilitating
ultra-high-resolution image generation. Thanks to these improvements,
PixArt-\Sigma achieves superior image quality and user prompt adherence
capabilities with significantly smaller model size (0.6B parameters) than
existing text-to-image diffusion models, such as SDXL (2.6B parameters) and SD
Cascade (5.1B parameters). Moreover, PixArt-\Sigma's capability to generate 4K
images supports the creation of high-resolution posters and wallpapers,
efficiently bolstering the production of high-quality visual content in
industries such as film and gaming.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04693" title="Abstract">arXiv:2403.04693</a> [<a href="/pdf/2403.04693" title="Download PDF">pdf</a>, <a href="/format/2403.04693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Systems&#x27; Performance in Natural Language Processing  Competitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nava-Mu%C3%B1oz%2C+S">Sergio Nava-Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Graff%2C+M">Mario Graff</a>, 
<a href="/search/cs?searchtype=author&query=Escalante%2C+H+J">Hugo Jair Escalante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Collaborative competitions have gained popularity in the scientific and
technological fields. These competitions involve defining tasks, selecting
evaluation scores, and devising result verification methods. In the standard
scenario, participants receive a training set and are expected to provide a
solution for a held-out dataset kept by organizers. An essential challenge for
organizers arises when comparing algorithms' performance, assessing multiple
participants, and ranking them. Statistical tools are often used for this
purpose; however, traditional statistical methods often fail to capture
decisive differences between systems' performance. This manuscript describes an
evaluation methodology for statistically analyzing competition results and
competition. The methodology is designed to be universally applicable; however,
it is illustrated using eight natural language competitions as case studies
involving classification and regression problems. The proposed methodology
offers several advantages, including off-the-shell comparisons with correction
mechanisms and the inclusion of confidence intervals. Furthermore, we introduce
metrics that allow organizers to assess the difficulty of competitions. Our
analysis shows the potential usefulness of our methodology for effectively
evaluating competition results.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04694" title="Abstract">arXiv:2403.04694</a> [<a href="/pdf/2403.04694" title="Download PDF">pdf</a>, <a href="/format/2403.04694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $[1,2]$-Domination in Interval and Circle Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meybodi%2C+M+A">Mohsen Alambardar Meybodi</a>, 
<a href="/search/cs?searchtype=author&query=Poureidi%2C+A">Abolfazl Poureidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">A subset $S$ of vertices in a graph $G=(V, E)$ is Dominating Set if each
vertex in $V(G)\setminus S$ is adjacent to at least one vertex in $S$. Chellali
et al. in 2013, by restricting the number of neighbors in $S$ of a vertex
outside $S$, introduced the concept of $[1,j]$-dominating set. A set $D
\subseteq V$ of a graph $G = (V, E)$ is called $[1,j]$-Dominating Set of $G$ if
every vertex not in $D$ has at least one neighbor and at most $j$ neighbors in
$D$. The Minimum $[1,j]$-Domination problem is the problem of finding the
minimum set $D$. Given a positive integer $k$ and a graph $G = (V, E)$, the
$[1,j]$-Domination Decision problem is to decide whether $G$ has
$[1,j]$-dominating set of cardinality at most $k$. A polynomial-time algorithm
was obtained in split graphs for a constant $j$ in contrast to the classic
Dominating Set problem which is NP-hard in split graphs. This result motivates
us to investigate the effect of restriction $j$ on the complexity of
$[1,j]$-domination problem on various classes of graphs. Although for $j\geq
3$, it has been proved that the minimum of classical domination is equal to
minimum $[1,j]$-domination in interval graphs, the complexity of finding the
minimum $[1,2]$-domination in interval graphs is still outstanding. In this
paper, we propose a polynomial-time algorithm for computing a minimum $[1,2]$
on non-proper interval graphs by a dynamic programming technique. Next, on the
negative side, we show that the minimum $[1,2]$-dominating set problem on
circle graphs is $NP$-complete.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04696" title="Abstract">arXiv:2403.04696</a> [<a href="/pdf/2403.04696" title="Download PDF">pdf</a>, <a href="/format/2403.04696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fact-Checking the Output of Large Language Models via Token-Level  Uncertainty Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fadeeva%2C+E">Ekaterina Fadeeva</a>, 
<a href="/search/cs?searchtype=author&query=Rubashevskii%2C+A">Aleksandr Rubashevskii</a>, 
<a href="/search/cs?searchtype=author&query=Shelmanov%2C+A">Artem Shelmanov</a>, 
<a href="/search/cs?searchtype=author&query=Petrakov%2C+S">Sergey Petrakov</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haonan Li</a>, 
<a href="/search/cs?searchtype=author&query=Mubarak%2C+H">Hamdy Mubarak</a>, 
<a href="/search/cs?searchtype=author&query=Tsymbalov%2C+E">Evgenii Tsymbalov</a>, 
<a href="/search/cs?searchtype=author&query=Kuzmin%2C+G">Gleb Kuzmin</a>, 
<a href="/search/cs?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+M">Maxim Panov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are notorious for hallucinating, i.e., producing
erroneous claims in their output. Such hallucinations can be dangerous, as
occasional factual inaccuracies in the generated text might be obscured by the
rest of the output being generally factual, making it extremely hard for the
users to spot them. Current services that leverage LLMs usually do not provide
any means for detecting unreliable generations. Here, we aim to bridge this
gap. In particular, we propose a novel fact-checking and hallucination
detection pipeline based on token-level uncertainty quantification. Uncertainty
scores leverage information encapsulated in the output of a neural network or
its layers to detect unreliable predictions, and we show that they can be used
to fact-check the atomic claims in the LLM output. Moreover, we present a novel
token-level uncertainty quantification method that removes the impact of
uncertainty about what claim to generate on the current step and what surface
form to use. Our method Claim Conditioned Probability (CCP) measures only the
uncertainty of particular claim value expressed by the model. Experiments on
the task of biography generation demonstrate strong improvements for CCP
compared to the baselines for six different LLMs and three languages. Human
evaluation reveals that the fact-checking pipeline based on uncertainty
quantification is competitive with a fact-checking tool that leverages external
knowledge.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04697" title="Abstract">arXiv:2403.04697</a> [<a href="/pdf/2403.04697" title="Download PDF">pdf</a>, <a href="/format/2403.04697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit  Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kaishen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zitong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weicheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Facial Action Units (AU) is a vital concept in the realm of affective
computing, and AU detection has always been a hot research topic. Existing
methods suffer from overfitting issues due to the utilization of a large number
of learnable parameters on scarce AU-annotated datasets or heavy reliance on
substantial additional relevant data. Parameter-Efficient Transfer Learning
(PETL) provides a promising paradigm to address these challenges, whereas its
existing methods lack design for AU characteristics. Therefore, we innovatively
investigate PETL paradigm to AU detection, introducing AUFormer and proposing a
novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual
MoKE specific to a certain AU with minimal learnable parameters first
integrates personalized multi-scale and correlation knowledge. Then the MoKE
collaborates with other MoKEs in the expert group to obtain aggregated
information and inject it into the frozen Vision Transformer (ViT) to achieve
parameter-efficient AU detection. Additionally, we design a Margin-truncated
Difficulty-aware Weighted Asymmetric Loss (MDWA-Loss), which can encourage the
model to focus more on activated AUs, differentiate the difficulty of
unactivated AUs, and discard potential mislabeled samples. Extensive
experiments from various perspectives, including within-domain, cross-domain,
data efficiency, and micro-expression domain, demonstrate AUFormer's
state-of-the-art performance and robust generalization abilities without
relying on additional relevant data. The code for AUFormer is available at
https://github.com/yuankaishen2001/AUFormer.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04699" title="Abstract">arXiv:2403.04699</a> [<a href="/pdf/2403.04699" title="Download PDF">pdf</a>, <a href="/format/2403.04699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete hypocoercivity for a nonlinear kinetic reaction model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bessemoulin-Chatard%2C+M">Marianne Bessemoulin-Chatard</a>, 
<a href="/search/math?searchtype=author&query=Laidin%2C+T">Tino Laidin</a>, 
<a href="/search/math?searchtype=author&query=Rey%2C+T">Thomas Rey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article, we propose a finite volume discretization of a one
dimensional nonlinear reaction kinetic model proposed in [Neumann, Schmeiser,
Kint. Rel. Mod. 2016], which describes a 2-species recombination-generation
process. Specifically, we establish the long-time convergence of approximate
solutions towards equilibrium, at exponential rate. The study is based on an
adaptation for a discretization of the linearized problem of the $L^2$
hypocoercivity method introduced in [Dolbeault, Mouhot, Schmeiser, 2015]. From
this, we can deduce a local result for the discrete nonlinear problem. As in
the continuous framework, this result requires the establishment of a maximum
principle, which necessitates the use of monotone numerical fluxes.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04700" title="Abstract">arXiv:2403.04700</a> [<a href="/pdf/2403.04700" title="Download PDF">pdf</a>, <a href="/format/2403.04700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving into the Trajectory Long-tail Distribution for Muti-object  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sijia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">En Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wenbing Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multiple Object Tracking (MOT) is a critical area within computer vision,
with a broad spectrum of practical implementations. Current research has
primarily focused on the development of tracking algorithms and enhancement of
post-processing techniques. Yet, there has been a lack of thorough examination
concerning the nature of tracking data it self. In this study, we pioneer an
exploration into the distribution patterns of tracking data and identify a
pronounced long-tail distribution issue within existing MOT datasets. We note a
significant imbalance in the distribution of trajectory lengths across
different pedestrians, a phenomenon we refer to as "pedestrians trajectory
long-tail distribution". Addressing this challenge, we introduce a bespoke
strategy designed to mitigate the effects of this skewed distribution.
Specifically, we propose two data augmentation strategies, including Stationary
Camera View Data Augmentation (SVA) and Dynamic Camera View Data Augmentation
(DVA) , designed for viewpoint states and the Group Softmax (GS) module for
Re-ID. SVA is to backtrack and predict the pedestrian trajectory of tail
classes, and DVA is to use diffusion model to change the background of the
scene. GS divides the pedestrians into unrelated groups and performs softmax
operation on each group individually. Our proposed strategies can be integrated
into numerous existing tracking systems, and extensive experimentation
validates the efficacy of our method in reducing the influence of long-tail
distribution on multi-object tracking performance. The code is available at
https://github.com/chen-si-jia/Trajectory-Long-tail-Distribution-for-MOT.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04701" title="Abstract">arXiv:2403.04701</a> [<a href="/pdf/2403.04701" title="Download PDF">pdf</a>, <a href="/format/2403.04701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ObjectCompose: Evaluating Resilience of Vision-Based Models on  Object-to-Background Compositional Changes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malik%2C+H+S">Hashmat Shadab Malik</a>, 
<a href="/search/cs?searchtype=author&query=Huzaifa%2C+M">Muhammad Huzaifa</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given the large-scale multi-modal training of recent vision-based models and
their generalization capabilities, understanding the extent of their robustness
is critical for their real-world deployment. In this work, we evaluate the
resilience of current vision-based models against diverse object-to-background
context variations. The majority of robustness evaluation methods have
introduced synthetic datasets to induce changes to object characteristics
(viewpoints, scale, color) or utilized image transformation techniques
(adversarial changes, common corruptions) on real images to simulate shifts in
distributions. Recent works have explored leveraging large language models and
diffusion models to generate changes in the background. However, these methods
either lack in offering control over the changes to be made or distort the
object semantics, making them unsuitable for the task. Our method, on the other
hand, can induce diverse object-to-background changes while preserving the
original semantics and appearance of the object. To achieve this goal, we
harness the generative capabilities of text-to-image, image-to-text, and
image-to-segment models to automatically generate a broad spectrum of
object-to-background changes. We induce both natural and adversarial background
changes by either modifying the textual prompts or optimizing the latents and
textual embedding of text-to-image models. This allows us to quantify the role
of background context in understanding the robustness and generalization of
deep neural networks. We produce various versions of standard vision datasets
(ImageNet, COCO), incorporating either diverse and realistic backgrounds into
the images or introducing color, texture, and adversarial changes in the
background. We conduct extensive experiment to analyze the robustness of
vision-based models against object-to-background context variations across
diverse tasks.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04702" title="Abstract">arXiv:2403.04702</a> [<a href="/pdf/2403.04702" title="Download PDF">pdf</a>, <a href="/format/2403.04702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of a Ramshaw-Mesina Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=%C3%87ibik%2C+A">Aytekin &#xc7;ibik</a>, 
<a href="/search/math?searchtype=author&query=Layton%2C+W">William Layton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In 1991 Ramshaw and Mesina introduced a clever synthesis of penalty methods
and artificial compression methods. Its form makes it an interesting option to
replace the pressure update in the Uzawa iteration. The result, for the Stokes
problem, is \begin{equation} \left\{ \begin{array} [c]{cc} Step\ 1: &amp;
-\triangle u^{n+1}+\nabla p^{n}=f(x),\ {\rm in}\ \Omega,\
u^{n+1}|_{\partial\Omega}=0,\\ Step\ 2: &amp;
p^{n+1}-p^{n}+\beta\nabla\cdot(u^{n+1}-u^{n})+\alpha ^{2}\nabla\cdot u^{n+1}=0.
\end{array} \right. \end{equation} For saddle point problems, including Stokes,
this iteration converges under a condition similar to the one required for
Uzawa iteration.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04703" title="Abstract">arXiv:2403.04703</a> [<a href="/pdf/2403.04703" title="Download PDF">pdf</a>, <a href="/format/2403.04703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mmPlace: Robust Place Recognition with Intermediate Frequency Signal of  Low-cost Single-chip Millimeter Wave Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chengzhen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yifan Duan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chenming He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Place recognition is crucial for tasks like loop-closure detection and
re-localization. Single-chip millimeter wave radar (single-chip radar in short)
emerges as a low-cost sensor option for place recognition, with the advantage
of insensitivity to degraded visual environments. However, it encounters two
challenges. Firstly, sparse point cloud from single-chip radar leads to poor
performance when using current place recognition methods, which assume much
denser data. Secondly, its performance significantly declines in scenarios
involving rotational and lateral variations, due to limited overlap in its
field of view (FOV). We propose mmPlace, a robust place recognition system to
address these challenges. Specifically, mmPlace transforms intermediate
frequency (IF) signal into range azimuth heatmap and employs a spatial encoder
to extract features. Additionally, to improve the performance in scenarios
involving rotational and lateral variations, mmPlace employs a rotating
platform and concatenates heatmaps in a rotation cycle, effectively expanding
the system's FOV. We evaluate mmPlace's performance on the milliSonic dataset,
which is collected on the University of Science and Technology of China (USTC)
campus, the city roads surrounding the campus, and an underground parking
garage. The results demonstrate that mmPlace outperforms point cloud-based
methods and achieves 87.37% recall@1 in scenarios involving rotational and
lateral variations.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04706" title="Abstract">arXiv:2403.04706</a> [<a href="/pdf/2403.04706" title="Download PDF">pdf</a>, <a href="/format/2403.04706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Common 7B Language Models Already Possess Strong Math Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingcheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yixuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Houwen Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mathematical capabilities were previously believed to emerge in common
language models only at a very large scale or require extensive math-related
pre-training. This paper shows that the LLaMA-2 7B model with common
pre-training already exhibits strong mathematical abilities, as evidenced by
its impressive accuracy of 97.7% and 72.0% on the GSM8K and MATH benchmarks,
respectively, when selecting the best response from 256 random generations. The
primary issue with the current base model is the difficulty in consistently
eliciting its inherent mathematical capabilities. Notably, the accuracy for the
first answer drops to 49.5% and 7.9% on the GSM8K and MATH benchmarks,
respectively. We find that simply scaling up the SFT data can significantly
enhance the reliability of generating correct answers. However, the potential
for extensive scaling is constrained by the scarcity of publicly available math
questions. To overcome this limitation, we employ synthetic data, which proves
to be nearly as effective as real data and shows no clear saturation when
scaled up to approximately one million samples. This straightforward approach
achieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B
models, surpassing previous models by 14.2% and 20.8%, respectively. We also
provide insights into scaling behaviors across different reasoning complexities
and error types.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04708" title="Abstract">arXiv:2403.04708</a> [<a href="/pdf/2403.04708" title="Download PDF">pdf</a>, <a href="/format/2403.04708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QRscript specification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scanzio%2C+S">Stefano Scanzio</a>, 
<a href="/search/cs?searchtype=author&query=Rosani%2C+M">Matteo Rosani</a>, 
<a href="/search/cs?searchtype=author&query=Scamuzzi%2C+M">Mattia Scamuzzi</a>, 
<a href="/search/cs?searchtype=author&query=Cena%2C+G">Gianluca Cena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Specification document, 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Human-Computer Interaction (cs.HC); Programming Languages (cs.PL)

</div>
<p class="mathjax">This specification document specifies the syntax and semantics of QRscript.
The current document only shows the part related to the QRscript header, i.e.,
the first part of the binary code that must be inserted into the QR code. A QR
code containing an executable code is called an executable QR code (eQR code).
QRscript supports different dialects, i.e., sublanguages with implementation
characteristics specific to the application field. The specifications of the
individual dialects will be described in separate documents.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04712" title="Abstract">arXiv:2403.04712</a> [<a href="/pdf/2403.04712" title="Download PDF">pdf</a>, <a href="/format/2403.04712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMKF: Generalized Moment Kalman Filter for Polynomial Systems with  Arbitrary Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+S">Sangli Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Harry Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">David Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jasour%2C+A">Ashkan Jasour</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Carlone%2C+L">Luca Carlone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper develops a new filtering approach for state estimation in
polynomial systems corrupted by arbitrary noise, which commonly arise in
robotics. We first consider a batch setup where we perform state estimation
using all data collected from the initial to the current time. We formulate the
batch state estimation problem as a Polynomial Optimization Problem (POP) and
relax the assumption of Gaussian noise by specifying a finite number of moments
of the noise. We solve the resulting POP using a moment relaxation and prove
that under suitable conditions on the rank of the relaxation, (i) we can
extract a provably optimal estimate from the moment relaxation, and (ii) we can
obtain a belief representation from the dual (sum-of-squares) relaxation. We
then turn our attention to the filtering setup and apply similar insights to
develop a GMKF for recursive state estimation in polynomial systems with
arbitrary noise. The GMKF formulates the prediction and update steps as POPs
and solves them using moment relaxations, carrying over a possibly non-Gaussian
belief. In the linear-Gaussian case, GMKF reduces to the standard Kalman
Filter. We demonstrate that GMKF performs well under highly non-Gaussian noise
and outperforms common alternatives, including the Extended and Unscented
Kalman Filter, and their variants on matrix Lie group.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04714" title="Abstract">arXiv:2403.04714</a> [<a href="/pdf/2403.04714" title="Download PDF">pdf</a>, <a href="/format/2403.04714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parendi: Thousand-Way Parallel RTL Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emami%2C+M">Mahyar Emami</a>, 
<a href="/search/cs?searchtype=author&query=Bourgeat%2C+T">Thomas Bourgeat</a>, 
<a href="/search/cs?searchtype=author&query=Larus%2C+J">James Larus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Hardware development relies on simulations, particularly cycle-accurate RTL
(Register Transfer Level) simulations, which consume significant time. As
single-processor performance grows only slowly, conventional, single-threaded
RTL simulation is becoming less practical for increasingly complex chips and
systems. A solution is parallel RTL simulation, where ideally, simulators could
run on thousands of parallel cores. However, existing simulators can only
exploit tens of cores.
<br />This paper studies the challenges inherent in running parallel RTL simulation
on a multi-thousand-core machine (the Graphcore IPU, a 1472-core machine).
Simulation performance requires balancing three factors: synchronization,
communication, and computation. We experimentally evaluate each metric and
analyze how it affects parallel simulation speed, drawing on contrasts between
the large-scale IPU and smaller but faster x86 systems.
<br />Using this analysis, we build Parendi, an RTL simulator for the IPU. It
distributes RTL simulation across 5888 cores on 4 IPU sockets. Parendi runs
large RTL designs up to 4x faster than a powerful, state-of-the-art x86
multicore system.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04716" title="Abstract">arXiv:2403.04716</a> [<a href="/pdf/2403.04716" title="Download PDF">pdf</a>, <a href="/format/2403.04716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QRtree -- Decision Tree dialect specification of QRscript
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scanzio%2C+S">Stefano Scanzio</a>, 
<a href="/search/cs?searchtype=author&query=Rosani%2C+M">Matteo Rosani</a>, 
<a href="/search/cs?searchtype=author&query=Scamuzzi%2C+M">Mattia Scamuzzi</a>, 
<a href="/search/cs?searchtype=author&query=Cena%2C+G">Gianluca Cena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Specification document, 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Human-Computer Interaction (cs.HC); Programming Languages (cs.PL)

</div>
<p class="mathjax">This specification document specifies the syntax and semantics of QRtree,
which is a specific dialect of QRscript particularly suited to represent
decision trees without chance nodes. The term dialect identifies one of the
possible sub-languages that can be encoded inside of an eQR code via QRscript.
This specification will describe an intermediate representation of QRtree, made
through a language derived by the three-address code. It will then define the
transformation rules from the intermediate representation to a binary code. The
latter is a binary representation called eQRtreebytecode. These rules can also
be applied inversely to transform the eQRtreeBytecode into the intermediate
representation. This specification document will pay particular attention to
the creation of a compact eQRtreebytecode, as the maximum number of bits that
can be stored in a QR code is, at the time of writing, equal to 2953 bytes (in
the case of QR code version 40 with a "low" error correction level).
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04717" title="Abstract">arXiv:2403.04717</a> [<a href="/pdf/2403.04717" title="Download PDF">pdf</a>, <a href="/ps/2403.04717" title="Download PostScript">ps</a>, <a href="/format/2403.04717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Literature Review of Current Sustainability Assessment Frameworks and  Approaches for Organizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farahdel%2C+S">Sarah Farahdel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Awasthi%2C+A">Anjali Awasthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This systematic literature review explores sustainability assessment
frameworks (SAFs) across diverse industries. The review focuses on SAF design
approaches including the methods used for Sustainability Indicator (SI)
selection, relative importance assessment, and interdependency analysis.
Various methods, including literature reviews, stakeholder interviews,
questionnaires, Pareto analysis, SMART approach, and adherence to
sustainability standards, contribute to the complex SI selection process.
Fuzzy-AHP stands out as a robust technique for assessing relative SI
importance. While dynamic sustainability and performance indices are essential,
methods like DEMATEL, VIKOR, correlation analysis, and causal models for
interdependency assessment exhibit static limitations. The review presents
strengths and limitations of SAFs, addressing gaps in design approaches and
contributing to a comprehensive understanding. The insights of this review aim
to benefit policymakers, administrators, leaders, and researchers, fostering
sustainability practices. Future research recommendations include exploring
multi-criteria decision-making models and hybrid approaches, extending
sustainability evaluation across organizational levels and supply chains.
Emphasizing adaptability to industry specifics and dynamic global adjustments
is proposed for holistic sustainability practices, further enhancing
organizational sustainability.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04720" title="Abstract">arXiv:2403.04720</a> [<a href="/pdf/2403.04720" title="Download PDF">pdf</a>, <a href="/format/2403.04720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking of Encoder-based Warm-start Methods in Hyperparameter  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C5%82udowski%2C+D">Dawid P&#x142;udowski</a>, 
<a href="/search/cs?searchtype=author&query=Zajko%2C+A">Antoni Zajko</a>, 
<a href="/search/cs?searchtype=author&query=Kozak%2C+A">Anna Kozak</a>, 
<a href="/search/cs?searchtype=author&query=Wo%C5%BAnica%2C+K">Katarzyna Wo&#x17a;nica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Effectively representing heterogeneous tabular datasets for meta-learning
remains an open problem. Previous approaches rely on predefined meta-features,
for example, statistical measures or landmarkers. Encoder-based models, such as
Dataset2Vec, allow us to extract significant meta-features automatically
without human intervention. This research introduces a novel encoder-based
representation of tabular datasets implemented within the liltab package
available on GitHub https://github.com/azoz01/liltab. Our package is based on
an established model for heterogeneous tabular data proposed in [Iwata and
Kumagai, 2020]. The proposed approach employs a different model for encoding
feature relationships, generating alternative representations compared to
existing methods like Dataset2Vec. Both of them leverage the fundamental
assumption of dataset similarity learning. In this work, we evaluate
Dataset2Vec and liltab on two common meta-tasks - representing entire datasets
and hyperparameter optimization warm-start. However, validation on an
independent metaMIMIC dataset highlights the nuanced challenges in
representation learning. We show that general representations may not suffice
for some meta-tasks where requirements are not explicitly considered during
extraction.
<br />[Iwata and Kumagai, 2020] Tomoharu Iwata and Atsutoshi Kumagai. Meta-learning
from Tasks with Heterogeneous Attribute Spaces. In Advances in Neural
Information Processing Systems, 2020.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04724" title="Abstract">arXiv:2403.04724</a> [<a href="/pdf/2403.04724" title="Download PDF">pdf</a>, <a href="/format/2403.04724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Capsule Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Everett%2C+M">Miles Everett</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Mingjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Leontidis%2C+G">Georgios Leontidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose Masked Capsule Autoencoders (MCAE), the first Capsule Network that
utilises pretraining in a self-supervised manner. Capsule Networks have emerged
as a powerful alternative to Convolutional Neural Networks (CNNs), and have
shown favourable properties when compared to Vision Transformers (ViT), but
have struggled to effectively learn when presented with more complex data,
leading to Capsule Network models that do not scale to modern tasks. Our
proposed MCAE model alleviates this issue by reformulating the Capsule Network
to use masked image modelling as a pretraining stage before finetuning in a
supervised manner. Across several experiments and ablations studies we
demonstrate that similarly to CNNs and ViTs, Capsule Networks can also benefit
from self-supervised pretraining, paving the way for further advancements in
this neural network domain. For instance, pretraining on the Imagenette
dataset, a dataset of 10 classes of Imagenet-sized images, we achieve not only
state-of-the-art results for Capsule Networks but also a 9% improvement
compared to purely supervised training. Thus we propose that Capsule Networks
benefit from and should be trained within a masked image modelling framework,
with a novel capsule decoder, to improve a Capsule Network's performance on
realistic-sized images.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04726" title="Abstract">arXiv:2403.04726</a> [<a href="/pdf/2403.04726" title="Download PDF">pdf</a>, <a href="/format/2403.04726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sub-Quadratic Time Algorithm for Robust Sparse Mean Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pensia%2C+A">Ankit Pensia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the algorithmic problem of sparse mean estimation in the presence of
adversarial outliers. Specifically, the algorithm observes a \emph{corrupted}
set of samples from $\mathcal{N}(\mu,\mathbf{I}_d)$, where the unknown mean
$\mu \in \mathbb{R}^d$ is constrained to be $k$-sparse. A series of prior works
has developed efficient algorithms for robust sparse mean estimation with
sample complexity $\mathrm{poly}(k,\log d, 1/\epsilon)$ and runtime $d^2
\mathrm{poly}(k,\log d,1/\epsilon)$, where $\epsilon$ is the fraction of
contamination. In particular, the fastest runtime of existing algorithms is
quadratic ($\Omega(d^2)$), which can be prohibitive in high dimensions. This
quadratic barrier in the runtime stems from the reliance of these algorithms on
the sample covariance matrix, which is of size $d^2$. Our main contribution is
an algorithm for robust sparse mean estimation which runs in
\emph{subquadratic} time using $\mathrm{poly}(k,\log d,1/\epsilon)$ samples. We
also provide analogous results for robust sparse PCA. Our results build on
algorithmic advances in detecting weak correlations, a generalized version of
the light-bulb problem by Valiant.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04729" title="Abstract">arXiv:2403.04729</a> [<a href="/pdf/2403.04729" title="Download PDF">pdf</a>, <a href="/format/2403.04729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stretchable Pneumatic Sleeve for Adaptable, Low-Displacement Anchoring  in Exosuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaffer%2C+K">Katalin Schaffer</a>, 
<a href="/search/cs?searchtype=author&query=Fallon%2C+U">Ultan Fallon</a>, 
<a href="/search/cs?searchtype=author&query=Coad%2C+M+M">Margaret M. Coad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RoboSoft 2024, 7 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Despite recent advances in wearable technology, interfacing movement
assistance devices with the human body remains challenging. We present a
stretchable pneumatic sleeve that can anchor an exosuit actuator to the human
arm with a low displacement of the actuator's mounting point relative to the
body during operation. Our sleeve has the potential to serve as an adaptable
attachment mechanism for exosuits, since it can adjust its pressure to only
compress the arm as much as needed to transmit the applied exosuit forces
without a large displacement. We discuss the design of our sleeve, which is
made of fabric pneumatic artificial muscle (fPAM) actuators formed into bands.
We quantify the performance of nine fPAM bands of various lengths and widths,
as well as three sleeves (an fPAM sleeve, a series pouch motor (SPM) sleeve as
in previous literature, and an off the shelf hook and loop sleeve), through the
measurement of the compressing force as a function of pressure and the
localized pulling force that can be resisted as a function of both pressure and
mounting point displacement. Our experimental results show that fPAM bands with
smaller resting length and/or larger resting width produce higher forces. Also,
when inflated, an fPAM sleeve that has equivalent dimensions to the SPM sleeve
while fully stretched has similar performance to the SPM sleeve. While
inflated, both pneumatic sleeves decrease the mounting point displacement
compared to the hook and loop sleeve. Compared to the SPM sleeve, the fPAM
sleeve is able to hold larger internal pressure before bursting, increasing its
possible force range. Also, when not inflated, the fPAM sleeve resists the
pulling force well, indicating its ability to provide anchoring when not
actuated.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04732" title="Abstract">arXiv:2403.04732</a> [<a href="/pdf/2403.04732" title="Download PDF">pdf</a>, <a href="/format/2403.04732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Are We from Intelligent Visual Deductive Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">He Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiatao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shuangfei Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J">Josh Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Jaitly%2C+N">Navdeep Jaitly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 AGI workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated
incredible strides on diverse vision language tasks. We dig into vision-based
deductive reasoning, a more sophisticated but less explored realm, and find
previously unexposed blindspots in the current SOTA VLMs. Specifically, we
leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to
perform multi-hop relational and deductive reasoning relying solely on visual
clues. We perform comprehensive evaluations of several popular VLMs employing
standard strategies such as in-context learning, self-consistency, and
Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test,
IntelligenceTest, and RAVEN. The results reveal that despite the impressive
capabilities of LLMs in text-based reasoning, we are still far from achieving
comparable proficiency in visual deductive reasoning. We found that certain
standard strategies that are effective when applied to LLMs do not seamlessly
translate to the challenges presented by visual reasoning tasks. Moreover, a
detailed analysis reveals that VLMs struggle to solve these tasks mainly
because they are unable to perceive and comprehend multiple, confounding
abstract patterns in RPM examples.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04735" title="Abstract">arXiv:2403.04735</a> [<a href="/pdf/2403.04735" title="Download PDF">pdf</a>, <a href="/format/2403.04735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SnapNTell: Enhancing Entity-Centric Visual Question Answering with  Retrieval Augmented Multimodal LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jielin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Madotto%2C+A">Andrea Madotto</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhaojiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Crook%2C+P+A">Paul A. Crook</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y+E">Yifan Ethan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X+L">Xin Luna Dong</a>, 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+C">Christos Faloutsos</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Damavandi%2C+B">Babak Damavandi</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seungwhan Moon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-extended LLMs have made significant strides in Visual Question
Answering (VQA). Despite these advancements, VLLMs still encounter substantial
difficulties in handling queries involving long-tail entities, with a tendency
to produce erroneous or hallucinated responses. In this work, we introduce a
novel evaluative benchmark named \textbf{SnapNTell}, specifically tailored for
entity-centric VQA. This task aims to test the models' capabilities in
identifying entities and providing detailed, entity-specific knowledge. We have
developed the \textbf{SnapNTell Dataset}, distinct from traditional VQA
datasets: (1) It encompasses a wide range of categorized entities, each
represented by images and explicitly named in the answers; (2) It features QA
pairs that require extensive knowledge for accurate responses. The dataset is
organized into 22 major categories, containing 7,568 unique entities in total.
For each entity, we curated 10 illustrative images and crafted 10
knowledge-intensive QA pairs. To address this novel task, we devised a
scalable, efficient, and transparent retrieval-augmented multimodal LLM. Our
approach markedly outperforms existing methods on the SnapNTell dataset,
achieving a 66.5\% improvement in the BELURT score. We will soon make the
dataset and the source code publicly accessible.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04736" title="Abstract">arXiv:2403.04736</a> [<a href="/pdf/2403.04736" title="Download PDF">pdf</a>, <a href="/format/2403.04736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking News Recommendation in the Era of Green AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Quanyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TheWebConf'24 accepted paper. A revised and condensed version of the previous work titled Only Encode Once: Making Content-based News Recommender Greener. While the core ideas and results remain consistent, the presentation scope have been modified for brevity and clarity. For the full details and extended discussions, please refer to the original long paper at <a href="/abs/2308.14155">arXiv:2308.14155</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Over recent years, news recommender systems have gained significant attention
in both academia and industry, emphasizing the need for a standardized
benchmark to evaluate and compare the performance of these systems.
Concurrently, Green AI advocates for reducing the energy consumption and
environmental impact of machine learning. To address these concerns, we
introduce the first Green AI benchmarking framework for news recommendation,
known as GreenRec, and propose a metric for assessing the tradeoff between
recommendation accuracy and efficiency. Our benchmark encompasses 30 base
models and their variants, covering traditional end-to-end training paradigms
as well as our proposed efficient only-encode-once (OLEO) paradigm. Through
experiments consuming 2000 GPU hours, we observe that the OLEO paradigm
achieves competitive accuracy compared to state-of-the-art end-to-end paradigms
and delivers up to a 2992\% improvement in sustainability metrics.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04739" title="Abstract">arXiv:2403.04739</a> [<a href="/pdf/2403.04739" title="Download PDF">pdf</a>, <a href="/format/2403.04739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Can&#x27;t Believe It&#x27;s Not Scene Flow!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khatri%2C+I">Ishan Khatri</a>, 
<a href="/search/cs?searchtype=author&query=Vedder%2C+K">Kyle Vedder</a>, 
<a href="/search/cs?searchtype=author&query=Peri%2C+N">Neehar Peri</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Hays%2C+J">James Hays</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 pages of citations, 2 pages of supplemental
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current scene flow methods broadly fail to describe motion on small objects,
and current scene flow evaluation protocols hide this failure by averaging over
many points, with most drawn larger objects. To fix this evaluation failure, we
propose a new evaluation protocol, Bucket Normalized EPE, which is class-aware
and speed-normalized, enabling contextualized error comparisons between object
types that move at vastly different speeds. To highlight current method
failures, we propose a frustratingly simple supervised scene flow baseline,
TrackFlow, built by bolting a high-quality pretrained detector (trained using
many class rebalancing techniques) onto a simple tracker, that produces
state-of-the-art performance on current standard evaluations and large
improvements over prior art on our new evaluation. Our results make it clear
that all scene flow evaluations must be class and speed aware, and supervised
scene flow methods must address point class imbalances. We release the
evaluation code publicly at
https://github.com/kylevedder/BucketedSceneFlowEval.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04744" title="Abstract">arXiv:2403.04744</a> [<a href="/pdf/2403.04744" title="Download PDF">pdf</a>, <a href="/ps/2403.04744" title="Download PostScript">ps</a>, <a href="/format/2403.04744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SQ Lower Bounds for Non-Gaussian Component Analysis with Weaker  Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+D">Daniel Kane</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Lisheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference version published in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the complexity of Non-Gaussian Component Analysis (NGCA) in the
Statistical Query (SQ) model. Prior work developed a general methodology to
prove SQ lower bounds for this task that have been applicable to a wide range
of contexts. In particular, it was known that for any univariate distribution
$A$ satisfying certain conditions, distinguishing between a standard
multivariate Gaussian and a distribution that behaves like $A$ in a random
hidden direction and like a standard Gaussian in the orthogonal complement, is
SQ-hard. The required conditions were that (1) $A$ matches many low-order
moments with the standard univariate Gaussian, and (2) the chi-squared norm of
$A$ with respect to the standard Gaussian is finite. While the moment-matching
condition is necessary for hardness, the chi-squared condition was only
required for technical reasons. In this work, we establish that the latter
condition is indeed not necessary. In particular, we prove near-optimal SQ
lower bounds for NGCA under the moment-matching condition only. Our result
naturally generalizes to the setting of a hidden subspace. Leveraging our
general SQ lower bound, we obtain near-optimal SQ lower bounds for a range of
concrete estimation tasks where existing techniques provide sub-optimal or even
vacuous guarantees.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04745" title="Abstract">arXiv:2403.04745</a> [<a href="/pdf/2403.04745" title="Download PDF">pdf</a>, <a href="/format/2403.04745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Calibrated Regret Metric for Detecting and Mitigating  Human-Robot Interaction Failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+K">Kensuke Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Ran Tian</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robot decision-making increasingly relies on expressive data-driven human
prediction models when operating around people. While these models are known to
suffer from prediction errors in out-of-distribution interactions, not all
prediction errors equally impact downstream robot performance. We identify that
the mathematical notion of regret precisely characterizes the degree to which
incorrect predictions of future interaction outcomes degraded closed-loop robot
performance. However, canonical regret measures are poorly calibrated across
diverse deployment interactions. We extend the canonical notion of regret by
deriving a calibrated regret metric that generalizes from absolute reward space
to probability space. With this transformation, our metric removes the need for
explicit reward functions to calculate the robot's regret, enables fairer
comparison of interaction anomalies across disparate deployment contexts, and
facilitates targetted dataset construction of "system-level" prediction
failures. We experimentally quantify the value of this high-regret interaction
data for aiding the robot in improving its downstream decision-making. In a
suite of closed-loop autonomous driving simulations, we find that fine-tuning
ego-conditioned behavior predictors exclusively on high-regret human-robot
interaction data can improve the robot's overall re-deployment performance with
significantly (77%) less data.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04746" title="Abstract">arXiv:2403.04746</a> [<a href="/pdf/2403.04746" title="Download PDF">pdf</a>, <a href="/format/2403.04746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boshi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data available at <a href="https://github.com/microsoft/simulated-trial-and-error">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Tools are essential for large language models (LLMs) to acquire up-to-date
information and take consequential actions in external environments. Existing
work on tool-augmented LLMs primarily focuses on the broad coverage of tools
and the flexibility of adding new tools. However, a critical aspect that has
surprisingly been understudied is simply how accurately an LLM uses tools for
which it has been trained. We find that existing LLMs, including GPT-4 and
open-source LLMs specifically fine-tuned for tool use, only reach a correctness
rate in the range of 30% to 60%, far from reliable use in practice. We propose
a biologically inspired method for tool-augmented LLMs, simulated trial and
error (STE), that orchestrates three key mechanisms for successful tool use
behaviors in the biological system: trial and error, imagination, and memory.
Specifically, STE leverages an LLM's 'imagination' to simulate plausible
scenarios for using a tool, after which the LLM interacts with the tool to
learn from its execution feedback. Both short-term and long-term memory are
employed to improve the depth and breadth of the exploration, respectively.
Comprehensive experiments on ToolBench show that STE substantially improves
tool learning for LLMs under both in-context learning and fine-tuning settings,
bringing a boost of 46.7% to Mistral-Instruct-7B and enabling it to outperform
GPT-4. We also show effective continual learning of tools via a simple
experience replay strategy.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04747" title="Abstract">arXiv:2403.04747</a> [<a href="/pdf/2403.04747" title="Download PDF">pdf</a>, <a href="/format/2403.04747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneckenreiter%2C+L">Lisa Schneckenreiter</a>, 
<a href="/search/cs?searchtype=author&query=Freinschlag%2C+R">Richard Freinschlag</a>, 
<a href="/search/cs?searchtype=author&query=Sestak%2C+F">Florian Sestak</a>, 
<a href="/search/cs?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>, 
<a href="/search/cs?searchtype=author&query=Klambauer%2C+G">G&#xfc;nter Klambauer</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+A">Andreas Mayr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024 (Tiny Papers Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Graph neural networks (GNNs), and especially message-passing neural networks,
excel in various domains such as physics, drug discovery, and molecular
modeling. The expressivity of GNNs with respect to their ability to
discriminate non-isomorphic graphs critically depends on the functions employed
for message aggregation and graph-level readout. By applying signal propagation
theory, we propose a variance-preserving aggregation function (VPA) that
maintains expressivity, but yields improved forward and backward dynamics.
Experiments demonstrate that VPA leads to increased predictive performance for
popular GNN architectures as well as improved learning dynamics. Our results
could pave the way towards normalizer-free or self-normalizing GNNs.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04753" title="Abstract">arXiv:2403.04753</a> [<a href="/pdf/2403.04753" title="Download PDF">pdf</a>, <a href="/format/2403.04753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanism for Decision-aware Collaborative Federated Learning: A Pitfall  of Shapley Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Meng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingxi Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This paper investigates mechanism design for decision-aware collaboration via
federated learning (FL) platforms. Our framework consists of a digital platform
and multiple decision-aware agents, each endowed with proprietary data sets.
The platform offers an infrastructure that enables access to the data, creates
incentives for collaborative learning aimed at operational decision-making, and
conducts FL to avoid direct raw data sharing. The computation and communication
efficiency of the FL process is inherently influenced by the agent
participation equilibrium induced by the mechanism. Therefore, assessing the
system's efficiency involves two critical factors: the surplus created by
coalition formation and the communication costs incurred across the coalition
during FL. To evaluate the system efficiency under the intricate interplay
between mechanism design, agent participation, operational decision-making, and
the performance of FL algorithms, we introduce a multi-action collaborative
federated learning (MCFL) framework for decision-aware agents. Under this
framework, we further analyze the equilibrium for the renowned Shapley value
based mechanisms. Specifically, we examine the issue of false-name
manipulation, a form of dishonest behavior where participating agents create
duplicate fake identities to split their original data among these identities.
By solving the agent participation equilibrium, we demonstrate that while
Shapley value effectively maximizes coalition-generated surplus by encouraging
full participation, it inadvertently promotes false-name manipulation. This
further significantly increases the communication costs when the platform
conducts FL. Thus, we highlight a significant pitfall of Shapley value based
mechanisms, which implicitly incentivizes data splitting and identity
duplication, ultimately impairing the overall efficiency in FL systems.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04755" title="Abstract">arXiv:2403.04755</a> [<a href="/pdf/2403.04755" title="Download PDF">pdf</a>, <a href="/format/2403.04755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> That&#x27;s My Point: Compact Object-centric LiDAR Pose Estimation for  Large-scale Outdoor Localisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pramatarov%2C+G">Georgi Pramatarov</a>, 
<a href="/search/cs?searchtype=author&query=Gadd%2C+M">Matthew Gadd</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+P">Paul Newman</a>, 
<a href="/search/cs?searchtype=author&query=De+Martini%2C+D">Daniele De Martini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper is about 3D pose estimation on LiDAR scans with extremely minimal
storage requirements to enable scalable mapping and localisation. We achieve
this by clustering all points of segmented scans into semantic objects and
representing them only with their respective centroid and semantic class. In
this way, each LiDAR scan is reduced to a compact collection of four-number
vectors. This abstracts away important structural information from the scenes,
which is crucial for traditional registration approaches. To mitigate this, we
introduce an object-matching network based on self- and cross-correlation that
captures geometric and semantic relationships between entities. The respective
matches allow us to recover the relative transformation between scans through
weighted Singular Value Decomposition (SVD) and RANdom SAmple Consensus
(RANSAC). We demonstrate that such representation is sufficient for metric
localisation by registering point clouds taken under different viewpoints on
the KITTI dataset, and at different periods of time localising between KITTI
and KITTI-360. We achieve accurate metric estimates comparable with
state-of-the-art methods with almost half the representation size, specifically
1.33 kB on average.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04757" title="Abstract">arXiv:2403.04757</a> [<a href="/pdf/2403.04757" title="Download PDF">pdf</a>, <a href="/format/2403.04757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preliminary Guidelines For Combining Data Integration and Visual Data  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coscia%2C+A">Adam Coscia</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+A">Ashley Suh</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Remco Chang</a>, 
<a href="/search/cs?searchtype=author&query=Endert%2C+A">Alex Endert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TVCG. 13 pages, 5 figures. For a study breakdown video, see <a href="https://youtu.be/NzVxHn-OpqQ">this https URL</a> . The source code, data and analysis are available at <a href="https://github.com/AdamCoscia/Integration-Guidelines-VA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Data integration is often performed to consolidate information from multiple
disparate data sources during visual data analysis. However, integration
operations are usually separate from visual analytics operations such as encode
and filter in both interface design and empirical research. We conducted a
preliminary user study to investigate whether and how data integration should
be incorporated directly into the visual analytics process. We used two
interface alternatives featuring contrasting approaches to the data preparation
and analysis workflow: manual file-based ex-situ integration as a separate step
from visual analytics operations; and automatic UI-based in-situ integration
merged with visual analytics operations. Participants were asked to complete
specific and free-form tasks with each interface, browsing for patterns,
generating insights, and summarizing relationships between attributes
distributed across multiple files. Analyzing participants' interactions and
feedback, we found both task completion time and total interactions to be
similar across interfaces and tasks, as well as unique integration strategies
between interfaces and emergent behaviors related to satisficing and cognitive
bias. Participants' time spent and interactions revealed that in-situ
integration enabled users to spend more time on analysis tasks compared with
ex-situ integration. Participants' integration strategies and analytical
behaviors revealed differences in interface usage for generating and tracking
hypotheses and insights. With these results, we synthesized preliminary
guidelines for designing future visual analytics interfaces that can support
integrating attributes throughout an active analysis process.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04758" title="Abstract">arXiv:2403.04758</a> [<a href="/pdf/2403.04758" title="Download PDF">pdf</a>, <a href="/format/2403.04758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KnowledgeVIS: Interpreting Language Models by Comparing  Fill-in-the-Blank Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coscia%2C+A">Adam Coscia</a>, 
<a href="/search/cs?searchtype=author&query=Endert%2C+A">Alex Endert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TVCG. 20 pages, 10 figures, 1 table. For a demo video, see <a href="https://youtu.be/hBX4rSUMr_I">this https URL</a> . For a live demo, visit <a href="https://adamcoscia.com/papers/knowledgevis/demo/">this https URL</a> . The source code is available at <a href="https://github.com/AdamCoscia/KnowledgeVIS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent growth in the popularity of large language models has led to their
increased usage for summarizing, predicting, and generating text, making it
vital to help researchers and engineers understand how and why they work. We
present KnowledgeVis, a human-in-the-loop visual analytics system for
interpreting language models using fill-in-the-blank sentences as prompts. By
comparing predictions between sentences, KnowledgeVis reveals learned
associations that intuitively connect what language models learn during
training to natural language tasks downstream, helping users create and test
multiple prompt variations, analyze predicted words using a novel semantic
clustering technique, and discover insights using interactive visualizations.
Collectively, these visualizations help users identify the likelihood and
uniqueness of individual predictions, compare sets of predictions between
prompts, and summarize patterns and relationships between predictions across
all prompts. We demonstrate the capabilities of KnowledgeVis with feedback from
six NLP experts as well as three different use cases: (1) probing biomedical
knowledge in two domain-adapted models; and (2) evaluating harmful identity
stereotypes and (3) discovering facts and relationships between three
general-purpose models.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04759" title="Abstract">arXiv:2403.04759</a> [<a href="/pdf/2403.04759" title="Download PDF">pdf</a>, <a href="/format/2403.04759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifelong Intelligence Beyond the Edge using Hyperdimensional Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaofan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+A">Anthony Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+I+G">Ivannia Gomez Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+L">Louis Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Rosing%2C+T">Tajana Rosing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IPSN'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">On-device learning has emerged as a prevailing trend that avoids the slow
response time and costly communication of cloud-based learning. The ability to
learn continuously and indefinitely in a changing environment, and with
resource constraints, is critical for real sensor deployments. However,
existing designs are inadequate for practical scenarios with (i) streaming data
input, (ii) lack of supervision and (iii) limited on-board resources. In this
paper, we design and deploy the first on-device lifelong learning system called
LifeHD for general IoT applications with limited supervision. LifeHD is
designed based on a novel neurally-inspired and lightweight learning paradigm
called Hyperdimensional Computing (HDC). We utilize a two-tier associative
memory organization to intelligently store and manage high-dimensional,
low-precision vectors, which represent the historical patterns as cluster
centroids. We additionally propose two variants of LifeHD to cope with scarce
labeled inputs and power constraints. We implement LifeHD on off-the-shelf edge
platforms and perform extensive evaluations across three scenarios. Our
measurements show that LifeHD improves the unsupervised clustering accuracy by
up to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong
learning baselines with as much as 34.3x better energy efficiency. Our code is
available at https://github.com/Orienfish/LifeHD.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04760" title="Abstract">arXiv:2403.04760</a> [<a href="/pdf/2403.04760" title="Download PDF">pdf</a>, <a href="/format/2403.04760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iScore: Visual Analytics for Interpreting How Language Models  Automatically Score Summaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coscia%2C+A">Adam Coscia</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+L">Langdon Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+W">Wesley Morris</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+S">Joon Suh Choi</a>, 
<a href="/search/cs?searchtype=author&query=Crossley%2C+S">Scott Crossley</a>, 
<a href="/search/cs?searchtype=author&query=Endert%2C+A">Alex Endert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IUI 2024. 16 pages, 5 figures, 1 table. For a demo video, see <a href="https://youtu.be/EYJX-_fQPf0">this https URL</a> . For a live demo, visit <a href="https://adamcoscia.com/papers/iscore/demo/">this https URL</a> . The source code is available at <a href="https://github.com/AdamCoscia/iScore">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent explosion in popularity of large language models (LLMs) has
inspired learning engineers to incorporate them into adaptive educational tools
that automatically score summary writing. Understanding and evaluating LLMs is
vital before deploying them in critical learning environments, yet their
unprecedented size and expanding number of parameters inhibits transparency and
impedes trust when they underperform. Through a collaborative user-centered
design process with several learning engineers building and deploying summary
scoring LLMs, we characterized fundamental design challenges and goals around
interpreting their models, including aggregating large text inputs, tracking
score provenance, and scaling LLM interpretability methods. To address their
concerns, we developed iScore, an interactive visual analytics tool for
learning engineers to upload, score, and compare multiple summaries
simultaneously. Tightly integrated views allow users to iteratively revise the
language in summaries, track changes in the resulting LLM scores, and visualize
model weights at multiple levels of abstraction. To validate our approach, we
deployed iScore with three learning engineers over the course of a month. We
present a case study where interacting with iScore led a learning engineer to
improve their LLM's score accuracy by three percentage points. Finally, we
conducted qualitative interviews with the learning engineers that revealed how
iScore enabled them to understand, evaluate, and build trust in their LLMs
during deployment.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04761" title="Abstract">arXiv:2403.04761</a> [<a href="/pdf/2403.04761" title="Download PDF">pdf</a>, <a href="/format/2403.04761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSee: Multidimensional Visualizations of Seabed Ecosystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coscia%2C+A">Adam Coscia</a>, 
<a href="/search/cs?searchtype=author&query=Sapers%2C+H+M">Haley M. Sapers</a>, 
<a href="/search/cs?searchtype=author&query=Deutsch%2C+N">Noah Deutsch</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+M">Malika Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Magyar%2C+J+S">John S. Magyar</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+S+A">Sergio A. Parra</a>, 
<a href="/search/cs?searchtype=author&query=Utter%2C+D+R">Daniel R. Utter</a>, 
<a href="/search/cs?searchtype=author&query=Wipfler%2C+R+L">Rebecca L. Wipfler</a>, 
<a href="/search/cs?searchtype=author&query=Caress%2C+D+W">David W. Caress</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+E+J">Eric J. Martin</a>, 
<a href="/search/cs?searchtype=author&query=Paduan%2C+J+B">Jennifer B. Paduan</a>, 
<a href="/search/cs?searchtype=author&query=Hendrie%2C+M">Maggie Hendrie</a>, 
<a href="/search/cs?searchtype=author&query=Lombeyda%2C+S">Santiago Lombeyda</a>, 
<a href="/search/cs?searchtype=author&query=Mushkin%2C+H">Hillary Mushkin</a>, 
<a href="/search/cs?searchtype=author&query=Endert%2C+A">Alex Endert</a>, 
<a href="/search/cs?searchtype=author&query=Davidoff%2C+S">Scott Davidoff</a>, 
<a href="/search/cs?searchtype=author&query=Orphan%2C+V+J">Victoria J. Orphan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CHI 2024. 16 pages, 7 figures, 2 tables. For a demo video, see <a href="https://youtu.be/HJ4zbueJ9cs">this https URL</a> . For a live demo, visit <a href="https://www.its.caltech.edu/~datavis/deepsee/">this https URL</a> . The source code is available at <a href="https://github.com/orphanlab/DeepSee">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Scientists studying deep ocean microbial ecosystems use limited numbers of
sediment samples collected from the seafloor to characterize important
life-sustaining biogeochemical cycles in the environment. Yet conducting
fieldwork to sample these extreme remote environments is both expensive and
time consuming, requiring tools that enable scientists to explore the sampling
history of field sites and predict where taking new samples is likely to
maximize scientific return. We conducted a collaborative, user-centered design
study with a team of scientific researchers to develop DeepSee, an interactive
data workspace that visualizes 2D and 3D interpolations of biogeochemical and
microbial processes in context together with sediment sampling history overlaid
on 2D seafloor maps. Based on a field deployment and qualitative interviews, we
found that DeepSee increased the scientific return from limited sample sizes,
catalyzed new research workflows, reduced long-term costs of sharing data, and
supported teamwork and communication between team members with diverse research
goals.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04763" title="Abstract">arXiv:2403.04763</a> [<a href="/pdf/2403.04763" title="Download PDF">pdf</a>, <a href="/format/2403.04763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BloomGML: Graph Machine Learning through the Lens of Bilevel  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+A+Y">Amber Yijia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yixuan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wipf%2C+D">David Wipf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Publication at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Bilevel optimization refers to scenarios whereby the optimal solution of a
lower-level energy function serves as input features to an upper-level
objective of interest. These optimal features typically depend on tunable
parameters of the lower-level energy in such a way that the entire bilevel
pipeline can be trained end-to-end. Although not generally presented as such,
this paper demonstrates how a variety of graph learning techniques can be
recast as special cases of bilevel optimization or simplifications thereof. In
brief, building on prior work we first derive a more flexible class of energy
functions that, when paired with various descent steps (e.g., gradient descent,
proximal methods, momentum, etc.), form graph neural network (GNN)
message-passing layers; critically, we also carefully unpack where any residual
approximation error lies with respect to the underlying constituent
message-passing functions. We then probe several simplifications of this
framework to derive close connections with non-GNN-based graph learning
approaches, including knowledge graph embeddings, various forms of label
propagation, and efficient graph-regularized MLP models. And finally, we
present supporting empirical results that demonstrate the versatility of the
proposed bilevel lens, which we refer to as BloomGML, referencing that BiLevel
Optimization Offers More Graph Machine Learning. Our code is available at
https://github.com/amberyzheng/BloomGML. Let graph ML bloom.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04764" title="Abstract">arXiv:2403.04764</a> [<a href="/pdf/2403.04764" title="Download PDF">pdf</a>, <a href="/format/2403.04764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a  provably efficient algorithm for batch Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaolin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents a new approach for batch Bayesian Optimization (BO),
where the sampling takes place by minimizing a Thompson Sampling approximation
of a regret to uncertainty ratio. Our objective is able to coordinate the
actions chosen in each batch in a way that minimizes redundancy between points
whilst focusing on points with high predictive means or high uncertainty. We
provide high-probability theoretical guarantees on the regret of our algorithm.
Finally, numerically, we demonstrate that our method attains state-of-the-art
performance on a range of nonconvex test functions, where it outperforms
several competitive benchmark batch BO algorithms by an order of magnitude on
average.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04765" title="Abstract">arXiv:2403.04765</a> [<a href="/pdf/2403.04765" title="Download PDF">pdf</a>, <a href="/format/2403.04765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient LoFTR: Semi-Dense Local Feature Matching with Sparse-Like  Speed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingyi He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sida Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+D">Dongli Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024; Project page: <a href="https://zju3dv.github.io/efficientloftr">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel method for efficiently producing semi-dense matches across
images. Previous detector-free matcher LoFTR has shown remarkable matching
capability in handling large-viewpoint change and texture-poor scenarios but
suffers from low efficiency. We revisit its design choices and derive multiple
improvements for both efficiency and accuracy. One key observation is that
performing the transformer over the entire feature map is redundant due to
shared local information, therefore we propose an aggregated attention
mechanism with adaptive token selection for efficiency. Furthermore, we find
spatial variance exists in LoFTR's fine correlation module, which is adverse to
matching accuracy. A novel two-stage correlation layer is proposed to achieve
accurate subpixel correspondences for accuracy improvement. Our efficiency
optimized model is $\sim 2.5\times$ faster than LoFTR which can even surpass
state-of-the-art efficient sparse matching pipeline SuperPoint + LightGlue.
Moreover, extensive experiments show that our method can achieve higher
accuracy compared with competitive semi-dense matchers, with considerable
efficiency benefits. This opens up exciting prospects for large-scale or
latency-sensitive applications such as image retrieval and 3D reconstruction.
Project page: https://zju3dv.github.io/efficientloftr.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri,  8 Mar 24</h3>
<dl>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04593" title="Abstract">arXiv:2307.04593</a> (cross-list from eess.IV) [<a href="/pdf/2307.04593" title="Download PDF">pdf</a>, <a href="/format/2307.04593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DWA: Differential Wavelet Amplifier for Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moser%2C+B+B">Brian B. Moser</a>, 
<a href="/search/eess?searchtype=author&query=Frolov%2C+S">Stanislav Frolov</a>, 
<a href="/search/eess?searchtype=author&query=Raue%2C+F">Federico Raue</a>, 
<a href="/search/eess?searchtype=author&query=Palacio%2C+S">Sebastian Palacio</a>, 
<a href="/search/eess?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces Differential Wavelet Amplifier (DWA), a drop-in module
for wavelet-based image Super-Resolution (SR). DWA invigorates an approach
recently receiving less attention, namely Discrete Wavelet Transformation
(DWT). DWT enables an efficient image representation for SR and reduces the
spatial area of its input by a factor of 4, the overall model size, and
computation cost, framing it as an attractive approach for sustainable ML. Our
proposed DWA model improves wavelet-based SR models by leveraging the
difference between two convolutional filters to refine relevant feature
extraction in the wavelet domain, emphasizing local contrasts and suppressing
common noise in the input signals. We show its effectiveness by integrating it
into existing SR models, e.g., DWSR and MWCNN, and demonstrate a clear
improvement in classical SR tasks. Moreover, DWA enables a direct application
of DWSR and MWCNN to input image space, reducing the DWT representation
channel-wise since it omits traditional DWT.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03960" title="Abstract">arXiv:2403.03960</a> (cross-list from physics.chem-ph) [<a href="/pdf/2403.03960" title="Download PDF">pdf</a>, <a href="/format/2403.03960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Extrapolation Capability of Template-Free Retrosynthesis  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+S">Shuan Chen</a>, 
<a href="/search/physics?searchtype=author&query=Jung%2C+Y">Yousung Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the acknowledged capability of template-free models in exploring
unseen reaction spaces compared to template-based models for retrosynthesis
prediction, their ability to venture beyond established boundaries remains
relatively uncharted. In this study, we empirically assess the extrapolation
capability of state-of-the-art template-free models by meticulously assembling
an extensive set of out-of-distribution (OOD) reactions. Our findings
demonstrate that while template-free models exhibit potential in predicting
precursors with novel synthesis rules, their top-10 exact-match accuracy in OOD
reactions is strikingly modest (&lt; 1%). Furthermore, despite the capability of
generating novel reactions, our investigation highlights a recurring issue
where more than half of the novel reactions predicted by template-free models
are chemically implausible. Consequently, we advocate for the future
development of template-free models that integrate considerations of chemical
feasibility when navigating unexplored regions of reaction space.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03969" title="Abstract">arXiv:2403.03969</a> (cross-list from math.MG) [<a href="/pdf/2403.03969" title="Download PDF">pdf</a>, <a href="/format/2403.03969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Outer Bi-Lipschitz Extensions of Linear Johnson-Lindenstrauss  Embeddings of Subsets of $\mathbb{R}^N$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chiclana%2C+R">Rafael Chiclana</a>, 
<a href="/search/math?searchtype=author&query=Iwen%2C+M+A">Mark A. Iwen</a>, 
<a href="/search/math?searchtype=author&query=Roach%2C+M+P">Mark Philip Roach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures. arXiv admin note: substantial text overlap with <a href="/abs/2206.03376">arXiv:2206.03376</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Data Structures and Algorithms (cs.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">The celebrated Johnson-Lindenstrauss lemma states that for all $\varepsilon
\in (0,1)$ and finite sets $X \subseteq \mathbb{R}^N$ with $n&gt;1$ elements,
there exists a matrix $\Phi \in \mathbb{R}^{m \times N}$ with
$m=\mathcal{O}(\varepsilon^{-2}\log n)$ such that \[ (1 - \varepsilon)
\|x-y\|_2 \leq \|\Phi x-\Phi y\|_2 \leq (1+\varepsilon)\| x- y\|_2 \quad
\forall\, x, y \in X.\] Herein we consider terminal embedding results which
have recently been introduced in the computer science literature as stronger
extensions of the Johnson-Lindenstrauss lemma for finite sets. After a short
survey of this relatively recent line of work, we extend the theory of terminal
embeddings to hold for arbitrary (e.g., infinite) subsets $X \subseteq
\mathbb{R}^N$, and then specialize our generalized results to the case where
$X$ is a low-dimensional compact submanifold of $\mathbb{R}^N$. In particular,
we prove the following generalization of the Johnson-Lindenstrauss lemma: For
all $\varepsilon \in (0,1)$ and $X\subseteq\mathbb{R}^N$, there exists a
terminal embedding $f: \mathbb{R}^N \longrightarrow \mathbb{R}^{m}$ such that
$$(1 - \varepsilon) \| x - y \|_2 \leq \left\| f(x) - f(y) \right\|_2 \leq (1 +
\varepsilon) \| x - y \|_2 \quad \forall \, x \in X ~{\rm and}~ \forall \, y
\in \mathbb{R}^N.$$ Crucially, we show that the dimension $m$ of the range of
$f$ above is optimal up to multiplicative constants, satisfying
$m=\mathcal{O}(\varepsilon^{-2} \omega^2(S_X))$, where $\omega(S_X)$ is the
Gaussian width of the set of unit secants of $X$,
$S_X=\overline{\{(x-y)/\|x-y\|_2 \colon x \neq y \in X\}}$. Furthermore, our
proofs are constructive and yield algorithms for computing a general class of
terminal embeddings $f$, an instance of which is demonstrated herein to allow
for more accurate compressive nearest neighbor classification than standard
linear Johnson-Lindenstrauss embeddings do in practice.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04005" title="Abstract">arXiv:2403.04005</a> (cross-list from stat.ML) [<a href="/pdf/2403.04005" title="Download PDF">pdf</a>, <a href="/format/2403.04005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Efficient Marginalization of Probabilistic Sequence Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Boyd%2C+A">Alex Boyd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-world data often exhibits sequential dependence, across diverse domains
such as human behavior, medicine, finance, and climate modeling. Probabilistic
methods capture the inherent uncertainty associated with prediction in these
contexts, with autoregressive models being especially prominent. This
dissertation focuses on using autoregressive models to answer complex
probabilistic queries that go beyond single-step prediction, such as the timing
of future events or the likelihood of a specific event occurring before
another. In particular, we develop a broad class of novel and efficient
approximation techniques for marginalization in sequential models that are
model-agnostic. These techniques rely solely on access to and sampling from
next-step conditional distributions of a pre-trained autoregressive model,
including both traditional parametric models as well as more recent neural
autoregressive models. Specific approaches are presented for discrete
sequential models, for marked temporal point processes, and for stochastic jump
processes, each tailored to a well-defined class of informative, long-range
probabilistic queries.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04024" title="Abstract">arXiv:2403.04024</a> (cross-list from eess.IV) [<a href="/pdf/2403.04024" title="Download PDF">pdf</a>, <a href="/format/2403.04024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing chest X-ray datasets with privacy-preserving large language  models and multi-type annotations: a data-driven approach for improved  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lanfredi%2C+R+B">Ricardo Bigolin Lanfredi</a>, 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+P">Pritam Mukherjee</a>, 
<a href="/search/eess?searchtype=author&query=Summers%2C+R">Ronald Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data: <a href="https://github.com/rsummers11/CADLab/tree/master/MAPLEZ_LLM_report_labeler/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In chest X-ray (CXR) image analysis, rule-based systems are usually employed
to extract labels from reports, but concerns exist about label quality. These
datasets typically offer only presence labels, sometimes with binary
uncertainty indicators, which limits their usefulness. In this work, we present
MAPLEZ (Medical report Annotations with Privacy-preserving Large language model
using Expeditious Zero shot answers), a novel approach leveraging a locally
executable Large Language Model (LLM) to extract and enhance findings labels on
CXR reports. MAPLEZ extracts not only binary labels indicating the presence or
absence of a finding but also the location, severity, and radiologists'
uncertainty about the finding. Over eight abnormalities from five test sets, we
show that our method can extract these annotations with an increase of 5
percentage points (pp) in F1 score for categorical presence annotations and
more than 30 pp increase in F1 score for the location annotations over
competing labelers. Additionally, using these improved annotations in
classification supervision, we demonstrate substantial advancements in model
quality, with an increase of 1.7 pp in AUROC over models trained with
annotations from the state-of-the-art approach. We share code and annotations.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04043" title="Abstract">arXiv:2403.04043</a> (cross-list from math.LO) [<a href="/pdf/2403.04043" title="Download PDF">pdf</a>, <a href="/ps/2403.04043" title="Download PostScript">ps</a>, <a href="/format/2403.04043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Length Functions and the Dimension of Points in Self-Similar Fractal  Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Porter%2C+C+P">Christopher P. Porter</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, Volume 69, Issue 10,
  October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we study the effective dimension of points in infinite fractal
trees generated recursively by a finite tree over some alphabet. Using unequal
costs coding, we associate a length function with each such fractal tree and
show that the channel capacity of the length function is equal to the
similarity dimension of the fractal tree (up to a multiplicative constant
determined by the size of the alphabet over which our tree is defined). Using
this result, we derive formulas for calculating the effective dimension and
strong effective dimension of points in fractal trees, establishing analogues
of several results due to Lutz and Mayordomo, who studied the effective
dimension of points in self-similar fractals in Euclidean space. Lastly, we
explore the connections between the channel capacity of a length function
derived from a finite tree and the measure of maximum entropy on a related
directed multigraph that encodes the structure of our tree, drawing on work by
Abram and Lagarias on path sets, where a path set is a generalization of the
notion of a sofic shift.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04062" title="Abstract">arXiv:2403.04062</a> (cross-list from math.OC) [<a href="/pdf/2403.04062" title="Download PDF">pdf</a>, <a href="/format/2403.04062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chance-Constrained Control for Safe Spacecraft Autonomy: Convex  Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Oguri%2C+K">Kenshiro Oguri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for 2024 IEEE American Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a robust path-planning framework for safe spacecraft
autonomy under uncertainty and develops a computationally tractable formulation
based on convex programming. We utilize chance-constrained control to formulate
the problem. It provides a mathematical framework to solve for a sequence of
control policies that minimizes a probabilistic cost under probabilistic
constraints with a user-defined confidence level (e.g., safety with 99.9%
confidence). The framework enables the planner to directly control state
distributions under operational uncertainties while ensuring the vehicle
safety. This paper rigorously formulates the safe autonomy problem, gathers and
extends techniques in literature to accommodate key cost/constraint functions
that often arise in spacecraft path planning, and develops a tractable solution
method. The presented framework is demonstrated via two representative
numerical examples: safe autonomous rendezvous and orbit maintenance in
cislunar space, both under uncertainties due to navigation error from Kalman
filter, execution error via Gates model, and imperfect force models.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04083" title="Abstract">arXiv:2403.04083</a> (cross-list from physics.geo-ph) [<a href="/pdf/2403.04083" title="Download PDF">pdf</a>, <a href="/format/2403.04083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-lapse full-waveform permeability inversion: a feasibility study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+Z">Ziyi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Louboutin%2C+M">Mathias Louboutin</a>, 
<a href="/search/physics?searchtype=author&query=M%C3%B8yner%2C+O">Olav M&#xf8;yner</a>, 
<a href="/search/physics?searchtype=author&query=Herrmann%2C+F+J">Felix J. Herrmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Time-lapse seismic monitoring necessitates integrated workflows that combine
seismic and reservoir modeling to enhance reservoir property estimation. We
present a feasibility study of an end-to-end inversion framework that directly
inverts for permeability from prestack time-lapse seismic data. To assess the
method's robustness, we design experiments focusing on its sensitivity to
initial models and potential errors in modeling. Our study leverages the
Compass model to simulate CO2 storage in saline aquifers, which is derived from
well and seismic data from the North Sea, a candidate site for geological
carbon storage.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04084" title="Abstract">arXiv:2403.04084</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.04084" title="Download PDF">pdf</a>, <a href="/format/2403.04084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density and Affinity Dependent Social Segregation and Arbitrage  Equilibrium in a Multi-class Schelling Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Venkatasubramanian%2C+V">Venkat Venkatasubramanian</a>, 
<a href="/search/physics?searchtype=author&query=Shi%2C+J">Jessica Shi</a>, 
<a href="/search/physics?searchtype=author&query=Goldman%2C+L">Leo Goldman</a>, 
<a href="/search/physics?searchtype=author&query=M.%2C+A+S+E">Arun Sankar E.M.</a>, 
<a href="/search/physics?searchtype=author&query=Sivaram%2C+A">Abhishek Sivaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.05765">arXiv:2312.05765</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Contrary to the widely believed hypothesis that larger, denser cities promote
socioeconomic mixing, a recent study (Nilforoshan et al. 2023) reports the
opposite behavior, i.e. more segregation. Here, we present a game-theoretic
model that predicts such a density-dependent segregation outcome in both one-
and two-class systems. The model provides key insights into the analytical
conditions that lead to such behavior. Furthermore, the arbitrage equilibrium
outcome implies the equality of effective utilities among all agents. This
could be interpreted as all agents being equally "happy" in their respective
environments in our ideal society. We believe that our model contributes
towards a deeper mathematical understanding of social dynamics and behavior,
which is important as we strive to develop more harmonious societies.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04100" title="Abstract">arXiv:2403.04100</a> (cross-list from math.AT) [<a href="/pdf/2403.04100" title="Download PDF">pdf</a>, <a href="/format/2403.04100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Representatives of Persistent Homology Generators with a  Double Twist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pham%2C+T">Tuyen Pham</a>, 
<a href="/search/math?searchtype=author&query=Wagner%2C+H">Hubert Wagner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Canadian Conference on Computational Geometry, Volume 35, 283-290
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">With the growing availability of efficient tools, persistent homology is
becoming a useful methodology in a variety of applications. Significant work
has been devoted to implementing tools for persistent homology diagrams;
however, computing representative cycles corresponding to each point in the
diagram can still be inefficient. To circumvent this problem, we extend the
twist algorithm of Chen and Kerber. Our extension is based on a new technique
we call saving, which supplements their existing killing technique. The
resulting two-pass strategy can be realized using an existing matrix reduction
implementation as a black-box and improves the efficiency of computing
representatives of persistent homology generators. We prove the correctness of
the new approach and experimentally show its performance.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04116" title="Abstract">arXiv:2403.04116</a> (cross-list from eess.IV) [<a href="/pdf/2403.04116" title="Download PDF">pdf</a>, <a href="/format/2403.04116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radiative Gaussian Splatting for Efficient X-ray Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+Y">Yuanhao Cai</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+Y">Yixun Liang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiahao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+A">Angtian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Z">Zongwei Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first 3D Gaussian Splatting-based method for X-ray 3D reconstruction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">X-ray is widely applied for transmission imaging due to its stronger
penetration than natural light. When rendering novel view X-ray projections,
existing methods mainly based on NeRF suffer from long training time and slow
inference speed. In this paper, we propose a 3D Gaussian splatting-based
framework, namely X-Gaussian, for X-ray novel view synthesis. Firstly, we
redesign a radiative Gaussian point cloud model inspired by the isotropic
nature of X-ray imaging. Our model excludes the influence of view direction
when learning to predict the radiation intensity of 3D points. Based on this
model, we develop a Differentiable Radiative Rasterization (DRR) with CUDA
implementation. Secondly, we customize an Angle-pose Cuboid Uniform
Initialization (ACUI) strategy that directly uses the parameters of the X-ray
scanner to compute the camera information and then uniformly samples point
positions within a cuboid enclosing the scanned object. Experiments show that
our X-Gaussian outperforms state-of-the-art methods by 6.5 dB while enjoying
less than 15% training time and over 73x inference speed. The application on
sparse-view CT reconstruction also reveals the practical values of our method.
Code and models will be publicly available at
https://github.com/caiyuanhao1998/X-Gaussian . A video demo of the training
process visualization is at https://www.youtube.com/watch?v=gDVf_Ngeghg .
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04126" title="Abstract">arXiv:2403.04126</a> (cross-list from quant-ph) [<a href="/pdf/2403.04126" title="Download PDF">pdf</a>, <a href="/format/2403.04126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Scheduling of Graph States via Path Decompositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Elman%2C+S+J">Samuel J. Elman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gavriel%2C+J">Jason Gavriel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mann%2C+R+L">Ryan L. Mann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study the optimal scheduling of graph states in measurement-based quantum
computation, establishing an equivalence between measurement schedules and path
decompositions of graphs. We define the spatial cost of a measurement schedule
based on the number of simultaneously active qubits and prove that an optimal
measurement schedule corresponds to a path decomposition of minimal width. Our
analysis shows that approximating the spatial cost of a graph is
\textsf{NP}-hard, while for graphs with bounded spatial cost, we establish an
efficient algorithm for computing an optimal measurement schedule.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04142" title="Abstract">arXiv:2403.04142</a> (cross-list from q-bio.TO) [<a href="/pdf/2403.04142" title="Download PDF">pdf</a>, <a href="/ps/2403.04142" title="Download PostScript">ps</a>, <a href="/format/2403.04142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hitchhiker&#x27;s guide to cancer-associated lymphoid aggregates in histology  images: manual and deep learning-based quantification approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Silina%2C+K">Karina Silina</a>, 
<a href="/search/q-bio?searchtype=author&query=Ciompi%2C+F">Francesco Ciompi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures, 1 table, 3 boxes, protocol/guideline
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Quantification of lymphoid aggregates including tertiary lymphoid structures
with germinal centers in histology images of cancer is a promising approach for
developing prognostic and predictive tissue biomarkers. In this article, we
provide recommendations for identifying lymphoid aggregates in tissue sections
from routine pathology workflows such as hematoxylin and eosin staining. To
overcome the intrinsic variability associated with manual image analysis (such
as subjective decision making, attention span), we recently developed a deep
learning-based algorithm called HookNet-TLS to detect lymphoid aggregates and
germinal centers in various tissues. Here, we additionally provide a guideline
for using manually annotated images for training and implementing HookNet-TLS
for automated and objective quantification of lymphoid aggregates in various
cancer types.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04168" title="Abstract">arXiv:2403.04168</a> (cross-list from eess.SP) [<a href="/pdf/2403.04168" title="Download PDF">pdf</a>, <a href="/format/2403.04168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of the Antenna on the Sub-Terahertz Indoor Channel  Characteristics: An Experimental Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sen%2C+P">Priyangshu Sen</a>, 
<a href="/search/eess?searchtype=author&query=Badran%2C+S">Sherif Badran</a>, 
<a href="/search/eess?searchtype=author&query=Petrov%2C+V">Vitaly Petrov</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+A">Arjun Singh</a>, 
<a href="/search/eess?searchtype=author&query=Jornet%2C+J+M">Josep M. Jornet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and to be published in IEEE ICC 2024. Copyright \copyright\ 2024 by the Institute of Electrical and Electronics Engineers (IEEE). Permission to make digital or hard copies of portions of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Terahertz-band (100 GHz-10 THz) communication is a promising radio technology
envisioned to enable ultra-high data rate, reliable and low-latency wireless
connectivity in next-generation wireless systems. However, the low transmission
power of THz transmitters, the need for high gain directional antennas, and the
complex interaction of THz radiation with common objects along the propagation
path make crucial the understanding of the THz channel. In this paper, we
conduct an extensive channel measurement campaign in an indoor setting (i.e., a
conference room) through a channel sounder with 0.1 ns time resolution and 20
GHz bandwidth at 140 GHz. Particularly, the impact of different antenna
directivities (and, thus, beam widths) on the channel characteristics is
extensively studied. The experimentally obtained dataset is processed to
develop the path loss model and, subsequently, derive key channel metrics such
as the path loss exponent, delay spread, and K-factor. The results highlight
the multi-faceted impact of the antenna gain on the channel and, by extension,
the wireless system and, thus, show that an antenna-agnostic channel model
cannot capture the propagation characteristics of the THz channel.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04170" title="Abstract">arXiv:2403.04170</a> (cross-list from quant-ph) [<a href="/pdf/2403.04170" title="Download PDF">pdf</a>, <a href="/ps/2403.04170" title="Download PostScript">ps</a>, <a href="/format/2403.04170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Lorentz Quantum Computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+B">Biao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We demonstrate the superior capabilities of the recently proposed Lorentz
quantum computer (LQC) compared to conventional quantum computers. We introduce
an associated computational complexity class, bounded-error Lorentz quantum
polynomial-time (BLQP), and prove that the complexity class ${\text P}^{\sharp
\text{P}}$ is contained within BLQP. We present LQC algorithms that solve in
polynomial time the problem of maximum independent set and the problems in the
classes of NP, co-NP, PH (polynomial hierarchy), PP (probabilistic
polynomial-time), and ${\text P}^{\sharp \text{P}}$. We show that the quantum
computing with postselection proposed by Aaronson can be simulated efficiently
by LQC, but not vice versa.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04175" title="Abstract">arXiv:2403.04175</a> (cross-list from physics.med-ph) [<a href="/pdf/2403.04175" title="Download PDF">pdf</a>, <a href="/ps/2403.04175" title="Download PostScript">ps</a>, <a href="/format/2403.04175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the PULSAR Effect in Combined Radiotherapy and  Immunotherapy through Attention Mechanisms with a Transformer Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/physics?searchtype=author&query=Moore%2C+C">Casey Moore</a>, 
<a href="/search/physics?searchtype=author&query=Saha%2C+D">Debabrata Saha</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+S">Steve Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Timmerman%2C+R">Robert Timmerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">PULSAR (personalized, ultra-fractionated stereotactic adaptive radiotherapy)
is the adaptation of stereotactic ablative radiotherapy towards personalized
cancer management. For the first time, we applied a transformer-based attention
mechanism to investigate the underlying interactions between combined PULSAR
and PD-L1 blockade immunotherapy based on a murine cancer model (Lewis Lung
Carcinoma, LLC). The proposed approach is able to predict the trend of tumor
volume change semi-quantitatively, and excels in identifying the potential
causal relationships through both self-attention and cross-attention scores.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04187" title="Abstract">arXiv:2403.04187</a> (cross-list from physics.bio-ph) [<a href="/pdf/2403.04187" title="Download PDF">pdf</a>, <a href="/format/2403.04187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference optimization of protein language models as a multi-objective  binder design paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mistani%2C+P">Pouria Mistani</a>, 
<a href="/search/physics?searchtype=author&query=Mysore%2C+V">Venkatesh Mysore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the GEM workshop, ICLR 2024. Generative and Experimental Perspectives for Biomolecular Design (<a href="https://www.gembio.ai/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">We present a multi-objective binder design paradigm based on instruction
fine-tuning and direct preference optimization (DPO) of autoregressive protein
language models (pLMs). Multiple design objectives are encoded in the language
model through direct optimization on expert curated preference sequence
datasets comprising preferred and dispreferred distributions. We show the
proposed alignment strategy enables ProtGPT2 to effectively design binders
conditioned on specified receptors and a drug developability criterion.
Generated binder samples demonstrate median isoelectric point (pI) improvements
by $17\%-60\%$.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04234" title="Abstract">arXiv:2403.04234</a> (cross-list from stat.ML) [<a href="/pdf/2403.04234" title="Download PDF">pdf</a>, <a href="/format/2403.04234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental limits of Non-Linear Low-Rank Matrix Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mergny%2C+P">Pierre Mergny</a>, 
<a href="/search/stat?searchtype=author&query=Ko%2C+J">Justin Ko</a>, 
<a href="/search/stat?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>, 
<a href="/search/stat?searchtype=author&query=Zdeborov%C3%A1%2C+L">Lenka Zdeborov&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the task of estimating a low-rank matrix from non-linear and
noisy observations. We prove a strong universality result showing that
Bayes-optimal performances are characterized by an equivalent Gaussian model
with an effective prior, whose parameters are entirely determined by an
expansion of the non-linear function. In particular, we show that to
reconstruct the signal accurately, one requires a signal-to-noise ratio growing
as $N^{\frac 12 (1-1/k_F)}$, where $k_F$ is the first non-zero Fisher
information coefficient of the function. We provide asymptotic characterization
for the minimal achievable mean squared error (MMSE) and an approximate
message-passing algorithm that reaches the MMSE under conditions analogous to
the linear version of the problem. We also provide asymptotic errors achieved
by methods such as principal component analysis combined with Bayesian
denoising, and compare them with Bayes-optimal MMSE.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04246" title="Abstract">arXiv:2403.04246</a> (cross-list from stat.ML) [<a href="/pdf/2403.04246" title="Download PDF">pdf</a>, <a href="/format/2403.04246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient CNN-LSTM based Parameter Estimation of Levy Driven Stochastic  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+S">Shuaiyu Li</a>, 
<a href="/search/stat?searchtype=author&query=Ruan%2C+Y">Yang Ruan</a>, 
<a href="/search/stat?searchtype=author&query=Long%2C+C">Changzhou Long</a>, 
<a href="/search/stat?searchtype=author&query=Cheng%2C+Y">Yuzhong Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 International Conference on Machine Learning and Applications (ICMLA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study addresses the challenges in parameter estimation of stochastic
differential equations driven by non-Gaussian noises, which are critical in
understanding dynamic phenomena such as price fluctuations and the spread of
infectious diseases. Previous research highlighted the potential of LSTM
networks in estimating parameters of alpha stable Levy driven SDEs but faced
limitations including high time complexity and constraints of the LSTM chaining
property. To mitigate these issues, we introduce the PEnet, a novel
CNN-LSTM-based three-stage model that offers an end to end approach with
superior accuracy and adaptability to varying data structures, enhanced
inference speed for long sequence observations through initial data feature
condensation by CNN, and high generalization capability, allowing its
application to various complex SDE scenarios. Experiments on synthetic datasets
confirm PEnet significant advantage in estimating SDE parameters associated
with noise characteristics, establishing it as a competitive method for SDE
parameter estimation in the presence of Levy noise.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04252" title="Abstract">arXiv:2403.04252</a> (cross-list from physics.comp-ph) [<a href="/pdf/2403.04252" title="Download PDF">pdf</a>, <a href="/format/2403.04252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portable GPU implementation of the WP-CCC ion-atom collisions code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Abdurakhmanov%2C+I+B">I. B. Abdurakhmanov</a>, 
<a href="/search/physics?searchtype=author&query=Antonio%2C+N+W">N. W. Antonio</a>, 
<a href="/search/physics?searchtype=author&query=Cytowski%2C+M">M. Cytowski</a>, 
<a href="/search/physics?searchtype=author&query=Kadyrov%2C+A+S">A. S. Kadyrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We present our experience of porting the code used in the wave-packet
convergent-close-coupling (WP-CCC) approach to run on NVIDIA V100 and AMD
MI250X GPUs. The WP-CCC approach is a method used in the field of ion-atom
collision physics to describe various processes such as elastic scattering,
target excitation and electron-capture by the projectile. It has demonstrated
its effectiveness in modelling collisions involving proton or bare ion
projectiles with various atomic and molecular targets, especially those which
can be considered as one or two-electron systems. Such calculations find their
application in computational atomic physics as well as in the modelling of
fusion plasmas and in hadron therapy for cancer treatment. The main
computational cost of the method lies in the solution of an emerging set of
coupled first-order differential equations. This involves implementing the
standard Runge-Kutta method while varying the projectile position along
multiple straight-line paths. At each projectile position several millions of
matrix elements need to be calculated which is accomplished using the OpenACC
programming model. Once these matrix elements are computed, the subsequent
steps involve matrix inversion and multiplication with another matrix. To
expedite these operations, a GPU-accelerated LAPACK routine, specialised for
solving systems of linear equations, is employed. For AMD GPUs, this routine is
accessible through the hipSOLVER library, while for NVIDIA GPUs, it can be
obtained from the cuSOLVER library. The portability, performance and energy
efficiency of the CPU-only code have been compared with the GPU-accelerated
version running on AMD and NVIDIA GPUs. The implementation of GPU-accelerated
WP-CCC code opens up avenues for exploring more sophisticated collision
processes involving complex projectile and target structures, which were
previously considered infeasible.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04259" title="Abstract">arXiv:2403.04259</a> (cross-list from math.OC) [<a href="/pdf/2403.04259" title="Download PDF">pdf</a>, <a href="/format/2403.04259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized and Equitable Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lau%2C+I">Ivan Lau</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+S">Shiqian Ma</a>, 
<a href="/search/math?searchtype=author&query=Uribe%2C+C+A">C&#xe9;sar A. Uribe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper considers the decentralized (discrete) optimal transport (D-OT)
problem. In this setting, a network of agents seeks to design a transportation
plan jointly, where the cost function is the sum of privately held costs for
each agent. We reformulate the D-OT problem as a constraint-coupled
optimization problem and propose a single-loop decentralized algorithm with an
iteration complexity of O(1/{\epsilon}) that matches existing centralized
first-order approaches. Moreover, we propose the decentralized equitable
optimal transport (DE-OT) problem. In DE-OT, in addition to cooperatively
designing a transportation plan that minimizes transportation costs, agents
seek to ensure equity in their individual costs. The iteration complexity of
the proposed method to solve DE-OT is also O(1/{\epsilon}). This rate improves
existing centralized algorithms, where the best iteration complexity obtained
is O(1/{\epsilon}^2).
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04268" title="Abstract">arXiv:2403.04268</a> (cross-list from quant-ph) [<a href="/pdf/2403.04268" title="Download PDF">pdf</a>, <a href="/ps/2403.04268" title="Download PostScript">ps</a>, <a href="/format/2403.04268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qubit-Wise Architecture Search Method for Variational Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+J">Jialin Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cai%2C+Z">Zhiqiang Cai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cao%2C+W">Wei Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Considering the noise level limit, one crucial aspect for quantum machine
learning is to design a high-performing variational quantum circuit
architecture with small number of quantum gates. As the classical neural
architecture search (NAS), quantum architecture search methods (QAS) employ
methods like reinforcement learning, evolutionary algorithms and supernet
optimiza-tion to improve the search efficiency. In this paper, we propose a
novel qubit-wise architec-ture search (QWAS) method, which progres-sively
search one-qubit configuration per stage, and combine with Monte Carlo Tree
Search al-gorithm to find good quantum architectures by partitioning the search
space into several good and bad subregions. The numerical experimental results
indicate that our proposed method can balance the exploration and exploitation
of cir-cuit performance and size in some real-world tasks, such as MNIST,
Fashion and MOSI. As far as we know, QWAS achieves the state-of-art re-sults of
all tasks in the terms of accuracy and circuit size.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04290" title="Abstract">arXiv:2403.04290</a> (cross-list from eess.IV) [<a href="/pdf/2403.04290" title="Download PDF">pdf</a>, <a href="/format/2403.04290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedM2G: Unifying Medical Multi-Modal Generation via Cross-Guided  Diffusion with Visual Invariant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhan%2C+C">Chenlu Zhan</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical generative models, acknowledged for their high-quality sample
generation ability, have accelerated the fast growth of medical applications.
However, recent works concentrate on separate medical generation models for
distinct medical tasks and are restricted to inadequate medical multi-modal
knowledge, constraining medical comprehensive diagnosis. In this paper, we
propose MedM2G, a Medical Multi-Modal Generative framework, with the key
innovation to align, extract, and generate medical multi-modal within a unified
model. Extending beyond single or two medical modalities, we efficiently align
medical multi-modal through the central alignment approach in the unified
space. Significantly, our framework extracts valuable clinical knowledge by
preserving the medical visual invariant of each imaging modal, thereby
enhancing specific medical information for multi-modal generation. By
conditioning the adaptive cross-guided parameters into the multi-flow diffusion
framework, our model promotes flexible interactions among medical multi-modal
for generation. MedM2G is the first medical generative model that unifies
medical generation tasks of text-to-image, image-to-text, and unified
generation of medical modalities (CT, MRI, X-ray). It performs 5 medical
generation tasks across 10 datasets, consistently outperforming various
state-of-the-art works.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04322" title="Abstract">arXiv:2403.04322</a> (cross-list from math.OC) [<a href="/pdf/2403.04322" title="Download PDF">pdf</a>, <a href="/format/2403.04322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memetic Differential Evolution Methods for Semi-Supervised Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mansueto%2C+P">Pierluigi Mansueto</a>, 
<a href="/search/math?searchtype=author&query=Schoen%2C+F">Fabio Schoen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In this paper, we deal with semi-supervised Minimum Sum-of-Squares Clustering
(MSSC) problems where background knowledge is given in the form of
instance-level constraints. In particular, we take into account "must-link" and
"cannot-link" constraints, each of which indicates if two dataset points should
be associated to the same or to a different cluster. The presence of such
constraints makes the problem at least as hard as its unsupervised version: it
is no more true that each point is associated to its nearest cluster center,
thus requiring some modifications in crucial operations, such as the assignment
step. In this scenario, we propose a novel memetic strategy based on the
Differential Evolution paradigm, directly extending a state-of-the-art
framework recently proposed in the unsupervised clustering literature. As far
as we know, our contribution represents the first attempt to define a memetic
methodology designed to generate a (hopefully) optimal feasible solution for
the semi-supervised MSSC problem. The proposal is compared with some
state-of-the-art algorithms from the literature on a set of well-known
datasets, highlighting its effectiveness and efficiency in finding good quality
clustering solutions.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04348" title="Abstract">arXiv:2403.04348</a> (cross-list from math.OC) [<a href="/pdf/2403.04348" title="Download PDF">pdf</a>, <a href="/format/2403.04348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoCoDL: Communication-Efficient Distributed Learning with Local Training  and Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Condat%2C+L">Laurent Condat</a>, 
<a href="/search/math?searchtype=author&query=Maranjyan%2C+A">Artavazd Maranjyan</a>, 
<a href="/search/math?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In Distributed optimization and Learning, and even more in the modern
framework of federated learning, communication, which is slow and costly, is
critical. We introduce LoCoDL, a communication-efficient algorithm that
leverages the two popular and effective techniques of Local training, which
reduces the communication frequency, and Compression, in which short bitstreams
are sent instead of full-dimensional vectors of floats. LoCoDL works with a
large class of unbiased compressors that includes widely-used sparsification
and quantization methods. LoCoDL provably benefits from local training and
compression and enjoys a doubly-accelerated communication complexity, with
respect to the condition number of the functions and the model dimension, in
the general heterogenous regime with strongly convex functions. This is
confirmed in practice, with LoCoDL outperforming existing algorithms.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04395" title="Abstract">arXiv:2403.04395</a> (cross-list from q-bio.BM) [<a href="/pdf/2403.04395" title="Download PDF">pdf</a>, <a href="/format/2403.04395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGNet: Folding Symmetrical Protein Complex with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Li%2C+Z">Zhaoqun Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Yu%2C+J">Jingcheng Yu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ye%2C+Q">Qiwei Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Deep learning has made significant progress in protein structure prediction,
advancing the development of computational biology. However, despite the high
accuracy achieved in predicting single-chain structures, a significant number
of large homo-oligomeric assemblies exhibit internal symmetry, posing a major
challenge in structure determination. The performances of existing deep
learning methods are limited since the symmetrical protein assembly usually has
a long sequence, making structural computation infeasible. In addition,
multiple identical subunits in symmetrical protein complex cause the issue of
supervision ambiguity in label assignment, requiring a consistent structure
modeling for the training. To tackle these problems, we propose a protein
folding framework called SGNet to model protein-protein interactions in
symmetrical assemblies. SGNet conducts feature extraction on a single subunit
and generates the whole assembly using our proposed symmetry module, which
largely mitigates computational problems caused by sequence length. Thanks to
the elaborate design of modeling symmetry consistently, we can model all global
symmetry types in quaternary protein structure prediction. Extensive
experimental results on a benchmark of symmetrical protein complexes further
demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04405" title="Abstract">arXiv:2403.04405</a> (cross-list from stat.ML) [<a href="/pdf/2403.04405" title="Download PDF">pdf</a>, <a href="/format/2403.04405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signature Isolation Forest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Staerman%2C+G">Guillaume Staerman</a>, 
<a href="/search/stat?searchtype=author&query=Campi%2C+M">Marta Campi</a>, 
<a href="/search/stat?searchtype=author&query=Peters%2C+G+W">Gareth W. Peters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly
Detection (AD) algorithm designed for functional data. It relies on a tree
partition procedure where an abnormality score is computed by projecting each
curve observation on a drawn dictionary through a linear inner product. Such
linear inner product and the dictionary are a priori choices that highly
influence the algorithm's performances and might lead to unreliable results,
particularly with complex datasets. This work addresses these challenges by
introducing \textit{Signature Isolation Forest}, a novel AD algorithm class
leveraging the rough path theory's signature transform. Our objective is to
remove the constraints imposed by FIF through the proposition of two algorithms
which specifically target the linearity of the FIF inner product and the choice
of the dictionary. We provide several numerical experiments, including a
real-world applications benchmark showing the relevance of our methods.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04433" title="Abstract">arXiv:2403.04433</a> (cross-list from eess.AS) [<a href="/pdf/2403.04433" title="Download PDF">pdf</a>, <a href="/ps/2403.04433" title="Download PostScript">ps</a>, <a href="/format/2403.04433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Use of Autoregressive Methods for Audio Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mokr%C3%BD%2C+O">Ond&#x159;ej Mokr&#xfd;</a>, 
<a href="/search/eess?searchtype=author&query=Rajmic%2C+P">Pavel Rajmic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The paper presents an evaluation of popular audio inpainting methods based on
autoregressive modelling, namely, extrapolation-based and Janssen methods. A
novel variant of the Janssen method suitable for gap inpainting is also
proposed. The main differences between the particular popular approaches are
pointed out, and a mid-scale computational experiment is presented. The results
demonstrate the importance of the choice of the AR model estimator and the
suitability of the new gap-wise Janssen method.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04459" title="Abstract">arXiv:2403.04459</a> (cross-list from physics.comp-ph) [<a href="/pdf/2403.04459" title="Download PDF">pdf</a>, <a href="/ps/2403.04459" title="Download PostScript">ps</a>, <a href="/format/2403.04459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient method for calculating resonant modes in biperiodic  photonic structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Lu%2C+Y+Y">Ya Yan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA); Optics (physics.optics)

</div>
<p class="mathjax">Many photonic devices, such as photonic crystal slabs, cross gratings, and
periodic metasurfaces, are biperiodic structures with two independent periodic
directions, and are sandwiched between two homogeneous media. Many applications
of these devices are closely related to resonance phenomena. Therefore,
efficient computation of resonant modes is crucial in device design and
structure analysis. Since resonant modes satisfy outgoing radiation conditions,
perfectly matched layers (PMLs) are usually used to truncate the unbounded
spatial variable perpendicular to the periodic directions. In this paper, we
develop an efficient method without using PMLs to calculate resonant modes in
biperiodic structures. We reduce the original eigenvalue problem to a small
matrix nonlinear eigenvalue problem which is solved by the contour integral
method. Numerical examples show that our method is efficient with respect to
memory usage and CPU time, free of spurious solutions, and determines
degenerate resonant modes without any difficulty.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04478" title="Abstract">arXiv:2403.04478</a> (cross-list from eess.IV) [<a href="/pdf/2403.04478" title="Download PDF">pdf</a>, <a href="/format/2403.04478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Focus on Hard Samples for Lung Nodule Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yujiang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+M">Mei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, lung nodule detection methods based on deep learning have shown
excellent performance in the medical image processing field. Considering that
only a few public lung datasets are available and lung nodules are more
difficult to detect in CT images than in natural images, the existing methods
face many bottlenecks when detecting lung nodules, especially hard ones in CT
images. In order to solve these problems, we plan to enhance the focus of our
network. In this work, we present an improved detection network that pays more
attention to hard samples and datasets to deal with lung nodules by introducing
deformable convolution and self-paced learning. Experiments on the LUNA16
dataset demonstrate the effectiveness of our proposed components and show that
our method has reached competitive performance.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04500" title="Abstract">arXiv:2403.04500</a> (cross-list from physics.med-ph) [<a href="/pdf/2403.04500" title="Download PDF">pdf</a>, <a href="/format/2403.04500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Learnable Prior Improves Inverse Tumor Growth Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Weidner%2C+J">Jonas Weidner</a>, 
<a href="/search/physics?searchtype=author&query=Ezhov%2C+I">Ivan Ezhov</a>, 
<a href="/search/physics?searchtype=author&query=Balcerak%2C+M">Michal Balcerak</a>, 
<a href="/search/physics?searchtype=author&query=Metz%2C+M">Marie-Christin Metz</a>, 
<a href="/search/physics?searchtype=author&query=Litvinov%2C+S">Sergey Litvinov</a>, 
<a href="/search/physics?searchtype=author&query=Kaltenbach%2C+S">Sebastian Kaltenbach</a>, 
<a href="/search/physics?searchtype=author&query=Feiner%2C+L">Leonhard Feiner</a>, 
<a href="/search/physics?searchtype=author&query=Lux%2C+L">Laurin Lux</a>, 
<a href="/search/physics?searchtype=author&query=Kofler%2C+F">Florian Kofler</a>, 
<a href="/search/physics?searchtype=author&query=Lipkova%2C+J">Jana Lipkova</a>, 
<a href="/search/physics?searchtype=author&query=Latz%2C+J">Jonas Latz</a>, 
<a href="/search/physics?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/physics?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>, 
<a href="/search/physics?searchtype=author&query=Wiestler%2C+B">Benedikt Wiestler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Biophysical modeling, particularly involving partial differential equations
(PDEs), offers significant potential for tailoring disease treatment protocols
to individual patients. However, the inverse problem-solving aspect of these
models presents a substantial challenge, either due to the high computational
requirements of model-based approaches or the limited robustness of deep
learning (DL) methods. We propose a novel framework that leverages the unique
strengths of both approaches in a synergistic manner. Our method incorporates a
DL ensemble for initial parameter estimation, facilitating efficient downstream
evolutionary sampling initialized with this DL-based prior. We showcase the
effectiveness of integrating a rapid deep-learning algorithm with a
high-precision evolution strategy in estimating brain tumor cell concentrations
from magnetic resonance images. The DL-Prior plays a pivotal role,
significantly constraining the effective sampling-parameter space. This
reduction results in a fivefold convergence acceleration and a Dice-score of
95%
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04612" title="Abstract">arXiv:2403.04612</a> (cross-list from eess.IV) [<a href="/pdf/2403.04612" title="Download PDF">pdf</a>, <a href="/ps/2403.04612" title="Download PostScript">ps</a>, <a href="/format/2403.04612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Domain Translation Framework with an Adversarial Denoising Diffusion  Model to Generate Synthetic Datasets of Echocardiography Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiago%2C+C">Cristiana Tiago</a>, 
<a href="/search/eess?searchtype=author&query=Snare%2C+S+R">Sten Roar Snare</a>, 
<a href="/search/eess?searchtype=author&query=Sprem%2C+J">Jurica Sprem</a>, 
<a href="/search/eess?searchtype=author&query=McLeod%2C+K">Kristin McLeod</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Currently, medical image domain translation operations show a high demand
from researchers and clinicians. Amongst other capabilities, this task allows
the generation of new medical images with sufficiently high image quality,
making them clinically relevant. Deep Learning (DL) architectures, most
specifically deep generative models, are widely used to generate and translate
images from one domain to another. The proposed framework relies on an
adversarial Denoising Diffusion Model (DDM) to synthesize echocardiography
images and perform domain translation. Contrary to Generative Adversarial
Networks (GANs), DDMs are able to generate high quality image samples with a
large diversity. If a DDM is combined with a GAN, this ability to generate new
data is completed at an even faster sampling time. In this work we trained an
adversarial DDM combined with a GAN to learn the reverse denoising process,
relying on a guide image, making sure relevant anatomical structures of each
echocardiography image were kept and represented on the generated image
samples. For several domain translation operations, the results verified that
such generative model was able to synthesize high quality image samples: MSE:
11.50 +/- 3.69, PSNR (dB): 30.48 +/- 0.09, SSIM: 0.47 +/- 0.03. The proposed
method showed high generalization ability, introducing a framework to create
echocardiography images suitable to be used for clinical research purposes.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04626" title="Abstract">arXiv:2403.04626</a> (cross-list from eess.IV) [<a href="/pdf/2403.04626" title="Download PDF">pdf</a>, <a href="/format/2403.04626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedFLIP: Medical Vision-and-Language Self-supervised Fast Pre-Training  with Masked Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tianfang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xinglin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+B">Bingqi Ma</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yan Luo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Within the domain of medical analysis, extensive research has explored the
potential of mutual learning between Masked Autoencoders(MAEs) and multimodal
data. However, the impact of MAEs on intermodality remains a key challenge. We
introduce MedFLIP, a Fast Language-Image Pre-training method for Medical
analysis. We explore MAEs for zero-shot learning with crossed domains, which
enhances the model ability to learn from limited data, a common scenario in
medical diagnostics. We verify that masking an image does not affect intermodal
learning. Furthermore, we propose the SVD loss to enhance the representation
learning for characteristics of medical images, aiming to improve
classification accuracy by leveraging the structural intricacies of such data.
Lastly, we validate using language will improve the zero-shot performance for
the medical image analysis. MedFLIP scaling of the masking process marks an
advancement in the field, offering a pathway to rapid and precise medical image
analysis without the traditional computational bottlenecks. Through experiments
and validation, MedFLIP demonstrates efficient performance improvements,
setting an explored standard for future research and application in medical
diagnostics.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04648" title="Abstract">arXiv:2403.04648</a> (cross-list from quant-ph) [<a href="/pdf/2403.04648" title="Download PDF">pdf</a>, <a href="/format/2403.04648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Maximum Likelihood Parameter Estimation for  Continuously-Monitored Quantum Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Clausen%2C+H+G">Henrik Glavind Clausen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rouchon%2C+P">Pierre Rouchon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wisniewski%2C+R">Rafal Wisniewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this work, we consider the problem of online (real-time, single-shot)
estimation of static or slow-varying parameters along quantum trajectories in
quantum dynamical systems. Based on the measurement signal of a
continuously-monitored quantum system, we propose a recursive algorithm for
computing the maximum likelihood estimate of unknown parameters using an
approach based on stochastic gradient ascent on the log-likelihood function. We
formulate the algorithm in both discrete-time and continuous-time and
illustrate the performance of the algorithm through simulations of a simple
two-level system undergoing homodyne measurement from which we are able to
track multiple parameters simultaneously.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04723" title="Abstract">arXiv:2403.04723</a> (cross-list from astro-ph.CO) [<a href="/pdf/2403.04723" title="Download PDF">pdf</a>, <a href="/ps/2403.04723" title="Download PostScript">ps</a>, <a href="/format/2403.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing an entropy estimator related to the dynamical state of galaxy  clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Z%C3%BAniga%2C+J+M">J. M. Z&#xfa;niga</a>, 
<a href="/search/astro-ph?searchtype=author&query=Caretta%2C+C+A">C. A. Caretta</a>, 
<a href="/search/astro-ph?searchtype=author&query=Gonz%C3%A1lez%2C+A+P">A. P. Gonz&#xe1;lez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Garc%C3%ADa-Manzan%C3%A1rez%2C+E">E. Garc&#xed;a-Manzan&#xe1;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Information Theory (cs.IT); Dynamical Systems (math.DS); Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)

</div>
<p class="mathjax">We propose the entropy estimator $H_Z$, calculated from global dynamical
parameters, in an attempt to capture the degree of evolution of galaxy systems.
We assume that the observed (spatial and velocity) distributions of member
galaxies in these systems evolve over time towards states of higher dynamical
relaxation (higher entropy), becoming more random and homogeneous in virial
equilibrium. Thus, the $H_Z$-entropy should correspond to the gravitacional
assembly state of the systems. This was tested in a sample of 70 well sampled
clusters in the Local Universe whose gravitational assembly state, classified
from optical and X-ray analysis of substructures, shows clear statistical
correlation with $H_Z$. This estimator was also tested on a sample of clusters
(halos) from the IllustrisTNG simulations, obtaining results in agreement with
the observational ones.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04740" title="Abstract">arXiv:2403.04740</a> (cross-list from quant-ph) [<a href="/pdf/2403.04740" title="Download PDF">pdf</a>, <a href="/ps/2403.04740" title="Download PostScript">ps</a>, <a href="/format/2403.04740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum One-Wayness of the Single-Round Sponge with Invertible  Permutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Carolan%2C+J">Joseph Carolan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Poremba%2C+A">Alexander Poremba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Sponge hashing is a novel class of cryptographic hash algorithms which
underlies the current international hash function standard SHA-3. In a
nutshell, a sponge function takes as input a bit-stream of any length and
processes it via a simple iterative procedure: it repeatedly feeds each block
of the input into a so-called block function, and then produces a short digest
which consists of a subset of the final output bits. While much is known about
the post-quantum security of the sponge construction in the case when the block
function is modeled as a random function or permutation, the case of invertible
permutations, which more accurately models the construction underlying SHA-3,
has so far remained a fundamental open problem.
<br />In this work, we make new progress towards overcoming this barrier and show
several results. First, we prove the "double-sided zero-search" conjecture
proposed by Unruh (eprint' 2021) and show that finding zero-pairs in a random
$2n$-bit permutation requires at least $\Omega(2^{n/2})$ many queries -- and
this is tight due to Grover's algorithm. At the core of our proof lies a novel
"symmetrization argument" which uses insights from the theory of Young
subgroups. Second, we consider more general variants of the double-sided search
problem and show similar query lower bounds for them. As an application, we
prove the quantum one-wayness of the single-round sponge with invertible
permutations in the quantum random oracle model.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.04750" title="Abstract">arXiv:2403.04750</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2403.04750" title="Download PDF">pdf</a>, <a href="/format/2403.04750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JAX-SPH: A Differentiable Smoothed Particle Hydrodynamics Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Toshev%2C+A+P">Artur P. Toshev</a>, 
<a href="/search/physics?searchtype=author&query=Ramachandran%2C+H">Harish Ramachandran</a>, 
<a href="/search/physics?searchtype=author&query=Erbesdobler%2C+J+A">Jonas A. Erbesdobler</a>, 
<a href="/search/physics?searchtype=author&query=Galletti%2C+G">Gianluca Galletti</a>, 
<a href="/search/physics?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>, 
<a href="/search/physics?searchtype=author&query=Adams%2C+N+A">Nikolaus A. Adams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ICLR 2024 Workshop on AI4Differential Equations In Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Particle-based fluid simulations have emerged as a powerful tool for solving
the Navier-Stokes equations, especially in cases that include intricate physics
and free surfaces. The recent addition of machine learning methods to the
toolbox for solving such problems is pushing the boundary of the quality vs.
speed tradeoff of such numerical simulations. In this work, we lead the way to
Lagrangian fluid simulators compatible with deep learning frameworks, and
propose JAX-SPH - a Smoothed Particle Hydrodynamics (SPH) framework implemented
in JAX. JAX-SPH builds on the code for dataset generation from the
LagrangeBench project (Toshev et al., 2023) and extends this code in multiple
ways: (a) integration of further key SPH algorithms, (b) restructuring the code
toward a Python library, (c) verification of the gradients through the solver,
and (d) demonstration of the utility of the gradients for solving inverse
problems as well as a Solver-in-the-Loop application. Our code is available at
https://github.com/tumaer/jax-sph.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri,  8 Mar 24</h3>
<dl>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.06931" title="Abstract">arXiv:1902.06931</a> (replaced) [<a href="/pdf/1902.06931" title="Download PDF">pdf</a>, <a href="/format/1902.06931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the consistency of supervised learning with missing values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Josse%2C+J">Julie Josse</a> (CMAP, XPOP), 
<a href="/search/stat?searchtype=author&query=Chen%2C+J+M">Jacob M. Chen</a>, 
<a href="/search/stat?searchtype=author&query=Prost%2C+N">Nicolas Prost</a> (CMAP, XPOP, PARIETAL), 
<a href="/search/stat?searchtype=author&query=Varoquaux%2C+G">Ga&#xeb;l Varoquaux</a> (PARIETAL), 
<a href="/search/stat?searchtype=author&query=Scornet%2C+E">Erwan Scornet</a> (X, CMAP, SU)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.00379" title="Abstract">arXiv:1908.00379</a> (replaced) [<a href="/pdf/1908.00379" title="Download PDF">pdf</a>, <a href="/format/1908.00379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outstanding: A Multi-Perspective Travel Approach for Virtual Reality  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Krekhov%2C+A">Andrey Krekhov</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1908.03591" title="Abstract">arXiv:1908.03591</a> (replaced) [<a href="/pdf/1908.03591" title="Download PDF">pdf</a>, <a href="/format/1908.03591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a Taxonomy of Inventory Systems for Virtual Reality Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Krekhov%2C+A">Andrey Krekhov</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+A">Ann-Marie M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.08031" title="Abstract">arXiv:2001.08031</a> (replaced) [<a href="/pdf/2001.08031" title="Download PDF">pdf</a>, <a href="/format/2001.08031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> United for Change: Deliberative Coalition Formation to Change the Status  Quo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkind%2C+E">Edith Elkind</a>, 
<a href="/search/cs?searchtype=author&query=Grossi%2C+D">Davide Grossi</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+E">Ehud Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Talmon%2C+N">Nimrod Talmon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version extends a version of the paper that appeared in COMSOC'21. It is the most complete version to date
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.10796" title="Abstract">arXiv:2008.10796</a> (replaced) [<a href="/pdf/2008.10796" title="Download PDF">pdf</a>, <a href="/format/2008.10796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Variational Network Toward Blind Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yue%2C+Z">Zongsheng Yue</a>, 
<a href="/search/eess?searchtype=author&query=Yong%2C+H">Hongwei Yong</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Q">Qian Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+K+K">Kwan-Yen K. Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI@2024. Code: <a href="https://github.com/zsyOAOA/VIRNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.00264" title="Abstract">arXiv:2011.00264</a> (replaced) [<a href="/pdf/2011.00264" title="Download PDF">pdf</a>, <a href="/format/2011.00264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing With Friends -- The Importance of Social Play During the  COVID-19 Pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.12639" title="Abstract">arXiv:2011.12639</a> (replaced) [<a href="/pdf/2011.12639" title="Download PDF">pdf</a>, <a href="/format/2011.12639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of Feedback Control Laws Based on Switched Tracking of  Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fejlek%2C+J">Ji&#x159;&#xed; Fejlek</a>, 
<a href="/search/eess?searchtype=author&query=Ratschan%2C+S">Stefan Ratschan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.14730" title="Abstract">arXiv:2011.14730</a> (replaced) [<a href="/pdf/2011.14730" title="Download PDF">pdf</a>, <a href="/format/2011.14730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isomorphism Testing for Graphs Excluding Small Topological Subgraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neuen%2C+D">Daniel Neuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 3 figures, full version of a paper accepted at SODA 2022; second and third version improve the presentation of the results. arXiv admin note: text overlap with <a href="/abs/2004.07671">arXiv:2004.07671</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.02266" title="Abstract">arXiv:2012.02266</a> (replaced) [<a href="/pdf/2012.02266" title="Download PDF">pdf</a>, <a href="/format/2012.02266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Four spacetime dimensional simulation of rheological waves in solids and  the merits of thermodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pozs%C3%A1r%2C+%C3%81">&#xc1;ron Pozs&#xe1;r</a>, 
<a href="/search/physics?searchtype=author&query=Sz%C3%BCcs%2C+M">M&#xe1;ty&#xe1;s Sz&#xfc;cs</a>, 
<a href="/search/physics?searchtype=author&query=Kov%C3%A1cs%2C+R">R&#xf3;bert Kov&#xe1;cs</a>, 
<a href="/search/physics?searchtype=author&query=F%C3%BCl%C3%B6p%2C+T">Tam&#xe1;s F&#xfc;l&#xf6;p</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 101 figures; v3: 4 typos corrected
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Entropy 2020, 22, 1376
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Physics (physics.class-ph)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.02024" title="Abstract">arXiv:2102.02024</a> (replaced) [<a href="/pdf/2102.02024" title="Download PDF">pdf</a>, <a href="/format/2102.02024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Sneaking as a Playful Input Modality for Virtual Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Krekhov%2C+A">Andrey Krekhov</a>, 
<a href="/search/cs?searchtype=author&query=Zenner%2C+A">Andr&#xe9; Zenner</a>, 
<a href="/search/cs?searchtype=author&query=Kucharski%2C+D">Daniel Kucharski</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.12892" title="Abstract">arXiv:2106.12892</a> (replaced) [<a href="/pdf/2106.12892" title="Download PDF">pdf</a>, <a href="/format/2106.12892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semiring Provenance for B&#xfc;chi Games: Strategy Analysis with Absorptive  Polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%A4del%2C+E">Erich Gr&#xe4;del</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCcking%2C+N">Niels L&#xfc;cking</a>, 
<a href="/search/cs?searchtype=author&query=Naaf%2C+M">Matthias Naaf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.07232" title="Abstract">arXiv:2107.07232</a> (replaced) [<a href="/pdf/2107.07232" title="Download PDF">pdf</a>, <a href="/format/2107.07232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the expressivity of bi-Lipschitz normalizing flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verine%2C+A">Alexandre Verine</a>, 
<a href="/search/cs?searchtype=author&query=Negrevergne%2C+B">Benjamin Negrevergne</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Fabrice Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Chevaleyre%2C+Y">Yann Chevaleyre</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 14th Asian Conference on Machine Learning, PMLR
  189:1054-1069, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.08434" title="Abstract">arXiv:2107.08434</a> (replaced) [<a href="/pdf/2107.08434" title="Download PDF">pdf</a>, <a href="/format/2107.08434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;I Packed My Bag and in It I Put...&quot;: A Taxonomy of Inventory Systems  for Virtual Reality Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Krekhov%2C+A">Andrey Krekhov</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.08439" title="Abstract">arXiv:2107.08439</a> (replaced) [<a href="/pdf/2107.08439" title="Download PDF">pdf</a>, <a href="/format/2107.08439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Task Type and Wall Appearance on Collision Behavior in  Virtual Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.14200" title="Abstract">arXiv:2109.14200</a> (replaced) [<a href="/pdf/2109.14200" title="Download PDF">pdf</a>, <a href="/ps/2109.14200" title="Download PostScript">ps</a>, <a href="/format/2109.14200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can phones, syllables, and words emerge as side-products of  cross-situational audiovisual learning? -- A computational investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khorrami%2C+K">Khazar Khorrami</a>, 
<a href="/search/eess?searchtype=author&query=R%C3%A4s%C3%A4nen%2C+O">Okko R&#xe4;s&#xe4;nen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final manuscript published in Language Development Research under CC BY-NC-SA 4.0. Pre-print redistributed through arXiv with permission. Replaces corrupted PsyArXiv pre-print repository at <a href="https://psyarxiv.com/37zna">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Language Development Research, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04629" title="Abstract">arXiv:2203.04629</a> (replaced) [<a href="/pdf/2203.04629" title="Download PDF">pdf</a>, <a href="/format/2203.04629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparison of variational upwinding schemes for geophysical fluids,  and their application to potential enstrophy conserving discretisations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+D">David Lee</a>, 
<a href="/search/math?searchtype=author&query=Mart%C3%ADn%2C+A+F">Alberto F. Mart&#xed;n</a>, 
<a href="/search/math?searchtype=author&query=Bladwell%2C+C">Christopher Bladwell</a>, 
<a href="/search/math?searchtype=author&query=Badia%2C+S">Santiago Badia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01258" title="Abstract">arXiv:2204.01258</a> (replaced) [<a href="/pdf/2204.01258" title="Download PDF">pdf</a>, <a href="/ps/2204.01258" title="Download PostScript">ps</a>, <a href="/format/2204.01258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homomorphisms of (n,m)-graphs with respect to generalised switch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Sagnik Sen</a>, 
<a href="/search/cs?searchtype=author&query=Sopena%2C+%C3%89">&#xc9;ric Sopena</a>, 
<a href="/search/cs?searchtype=author&query=Taruni%2C+S">S Taruni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04192" title="Abstract">arXiv:2207.04192</a> (replaced) [<a href="/pdf/2207.04192" title="Download PDF">pdf</a>, <a href="/ps/2207.04192" title="Download PostScript">ps</a>, <a href="/format/2207.04192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Stackelberg Strategies for Finitely Repeated Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collina%2C+N">Natalie Collina</a>, 
<a href="/search/cs?searchtype=author&query=Arunachaleswaran%2C+E+R">Eshwar Ram Arunachaleswaran</a>, 
<a href="/search/cs?searchtype=author&query=Kearns%2C+M">Michael Kearns</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07581" title="Abstract">arXiv:2208.07581</a> (replaced) [<a href="/pdf/2208.07581" title="Download PDF">pdf</a>, <a href="/format/2208.07581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regression modelling of spatiotemporal extreme U.S. wildfires via  partially-interpretable neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Richards%2C+J">Jordan Richards</a>, 
<a href="/search/stat?searchtype=author&query=Huser%2C+R">Rapha&#xeb;l Huser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01621" title="Abstract">arXiv:2209.01621</a> (replaced) [<a href="/pdf/2209.01621" title="Download PDF">pdf</a>, <a href="/format/2209.01621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Question Answering Systems: Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biancofiore%2C+G+M">Giovanni Maria Biancofiore</a>, 
<a href="/search/cs?searchtype=author&query=Deldjoo%2C+Y">Yashar Deldjoo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>, 
<a href="/search/cs?searchtype=author&query=Di+Sciascio%2C+E">Eugenio Di Sciascio</a>, 
<a href="/search/cs?searchtype=author&query=Narducci%2C+F">Fedelucio Narducci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 2 Figures, 6 Tables, submitted to ACM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14399" title="Abstract">arXiv:2209.14399</a> (replaced) [<a href="/pdf/2209.14399" title="Download PDF">pdf</a>, <a href="/format/2209.14399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIRE: A Failure-Adaptive Reinforcement Learning Framework for Edge  Computing Migrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siew%2C+M">Marie Siew</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shikhar Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekai Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lorido-Botran%2C+T">Tania Lorido-Botran</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>, 
<a href="/search/cs?searchtype=author&query=Joe-Wong%2C+C">Carlee Joe-Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02680" title="Abstract">arXiv:2211.02680</a> (replaced) [<a href="/pdf/2211.02680" title="Download PDF">pdf</a>, <a href="/format/2211.02680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Climbing Routes Clustering Using Energy-Efficient Accelerometers  Attached to the Quickdraws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moaveninejad%2C+S">Sadaf Moaveninejad</a>, 
<a href="/search/eess?searchtype=author&query=Janes%2C+A">Andrea Janes</a>, 
<a href="/search/eess?searchtype=author&query=Porcaro%2C+C">Camillo Porcaro</a>, 
<a href="/search/eess?searchtype=author&query=Barletta%2C+L">Luca Barletta</a>, 
<a href="/search/eess?searchtype=author&query=Mucchi%2C+L">Lorenzo Mucchi</a>, 
<a href="/search/eess?searchtype=author&query=Pierobon%2C+M">Massimiliano Pierobon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03102" title="Abstract">arXiv:2211.03102</a> (replaced) [<a href="/pdf/2211.03102" title="Download PDF">pdf</a>, <a href="/format/2211.03102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Video Analytics on Distributed Edges with Multiagent Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Guanyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuqi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ran Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09198" title="Abstract">arXiv:2211.09198</a> (replaced) [<a href="/pdf/2211.09198" title="Download PDF">pdf</a>, <a href="/format/2211.09198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfiguration of a 2D Structure Using Spatio-Temporal Planning and  Load Transferring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+J">Javier Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Yannuzzi%2C+M">Michael Yannuzzi</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+P">Peter Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+C">Christian Rieck</a>, 
<a href="/search/cs?searchtype=author&query=Fekete%2C+S+P">S&#xe1;ndor P. Fekete</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+A+T">Aaron T. Becker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> seven pages, eight figures, one table; revised version; to appear in the proceedings of the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09510" title="Abstract">arXiv:2211.09510</a> (replaced) [<a href="/pdf/2211.09510" title="Download PDF">pdf</a>, <a href="/format/2211.09510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Trajectory Representation Learning with Temporal  Regularities and Travel Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+D">Dayan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Houxing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaohan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, Accepted by ICDE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14960" title="Abstract">arXiv:2211.14960</a> (replaced) [<a href="/pdf/2211.14960" title="Download PDF">pdf</a>, <a href="/format/2211.14960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Alignment Regularization for Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imani%2C+E">Ehsan Imani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guojun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Poupart%2C+P">Pascal Poupart</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P+H+S">Philip H.S. Torr</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yangchen Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01551" title="Abstract">arXiv:2212.01551</a> (replaced) [<a href="/pdf/2212.01551" title="Download PDF">pdf</a>, <a href="/format/2212.01551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantify the Causes of Causal Emergence: Critical Conditions of  Uncertainty and Asymmetry in Causal Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+L">Liye Jia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fengyufan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+K+L">Ka Lok Man</a>, 
<a href="/search/cs?searchtype=author&query=Purwanto%2C+E">Erick Purwanto</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+S">Sheng-Uei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jeremy Smith</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yutao Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01716" title="Abstract">arXiv:2301.01716</a> (replaced) [<a href="/pdf/2301.01716" title="Download PDF">pdf</a>, <a href="/ps/2301.01716" title="Download PostScript">ps</a>, <a href="/format/2301.01716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First-order penalty methods for bilevel optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+Z">Zhaosong Lu</a>, 
<a href="/search/math?searchtype=author&query=Mei%2C+S">Sanyou Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIAM Journal on Optimization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03196" title="Abstract">arXiv:2301.03196</a> (replaced) [<a href="/pdf/2301.03196" title="Download PDF">pdf</a>, <a href="/format/2301.03196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-optimal stochastic MIMO signal detection with a mixture of  t-distribution prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagiwara%2C+J">Junichiro Hagiwara</a>, 
<a href="/search/cs?searchtype=author&query=Matsumura%2C+K">Kazushi Matsumura</a>, 
<a href="/search/cs?searchtype=author&query=Asumi%2C+H">Hiroki Asumi</a>, 
<a href="/search/cs?searchtype=author&query=Kasuga%2C+Y">Yukiko Kasuga</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+T">Toshihiko Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+T">Takanori Sato</a>, 
<a href="/search/cs?searchtype=author&query=Ogawa%2C+Y">Yasutaka Ogawa</a>, 
<a href="/search/cs?searchtype=author&query=Ohgane%2C+T">Takeo Ohgane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the 2023 IEEE Global Communications Conference (GLOBECOM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07945" title="Abstract">arXiv:2301.07945</a> (replaced) [<a href="/pdf/2301.07945" title="Download PDF">pdf</a>, <a href="/format/2301.07945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for  Traffic Flow Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chengkai Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, Accepted by AAAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10774" title="Abstract">arXiv:2301.10774</a> (replaced) [<a href="/pdf/2301.10774" title="Download PDF">pdf</a>, <a href="/format/2301.10774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDesign: Hierarchical Data-efficient Representation Learning for  Tertiary Structure-based RNA Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Y">Yijie Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+B">Bozhen Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S">Siyuan Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 28 figures, 16 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13368" title="Abstract">arXiv:2301.13368</a> (replaced) [<a href="/pdf/2301.13368" title="Download PDF">pdf</a>, <a href="/format/2301.13368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misspecification-robust Sequential Neural Likelihood for  Simulation-based Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kelly%2C+R+P">Ryan P. Kelly</a>, 
<a href="/search/stat?searchtype=author&query=Nott%2C+D+J">David J. Nott</a>, 
<a href="/search/stat?searchtype=author&query=Frazier%2C+D+T">David T. Frazier</a>, 
<a href="/search/stat?searchtype=author&query=Warne%2C+D+J">David J. Warne</a>, 
<a href="/search/stat?searchtype=author&query=Drovandi%2C+C">Chris Drovandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02803" title="Abstract">arXiv:2302.02803</a> (replaced) [<a href="/pdf/2302.02803" title="Download PDF">pdf</a>, <a href="/format/2302.02803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never Skip Leg Day Again: Training the Lower Body with Vertical Jumps in  a Virtual Reality Exergame
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cmentowski%2C+S">Sebastian Cmentowski</a>, 
<a href="/search/cs?searchtype=author&query=Karaosmanoglu%2C+S">Sukran Karaosmanoglu</a>, 
<a href="/search/cs?searchtype=author&query=Nacke%2C+L">Lennart Nacke</a>, 
<a href="/search/cs?searchtype=author&query=Steinicke%2C+F">Frank Steinicke</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+J">Jens Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07751" title="Abstract">arXiv:2302.07751</a> (replaced) [<a href="/pdf/2302.07751" title="Download PDF">pdf</a>, <a href="/ps/2302.07751" title="Download PostScript">ps</a>, <a href="/format/2302.07751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Energy-Efficient Randomized Backoff: Slow Feedback Loops Yield  Fast Contention Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bender%2C+M+A">Michael A. Bender</a>, 
<a href="/search/cs?searchtype=author&query=Fineman%2C+J+T">Jeremy T. Fineman</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+S">Seth Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Kuszmaul%2C+J">John Kuszmaul</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+M">Maxwell Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08484" title="Abstract">arXiv:2302.08484</a> (replaced) [<a href="/pdf/2302.08484" title="Download PDF">pdf</a>, <a href="/format/2302.08484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOSI: Hybrid First and Second Order Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivan%2C+H">Hadar Sivan</a>, 
<a href="/search/cs?searchtype=author&query=Gabel%2C+M">Moshe Gabel</a>, 
<a href="/search/cs?searchtype=author&query=Schuster%2C+A">Assaf Schuster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 figures. Accepted as a conference paper to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08585" title="Abstract">arXiv:2302.08585</a> (replaced) [<a href="/pdf/2302.08585" title="Download PDF">pdf</a>, <a href="/format/2302.08585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Nonlinear Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bates%2C+D+J">Daniel J. Bates</a>, 
<a href="/search/math?searchtype=author&query=Breiding%2C+P">Paul Breiding</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tianran Chen</a>, 
<a href="/search/math?searchtype=author&query=Hauenstein%2C+J+D">Jonathan D. Hauenstein</a>, 
<a href="/search/math?searchtype=author&query=Leykin%2C+A">Anton Leykin</a>, 
<a href="/search/math?searchtype=author&query=Sottile%2C+F">Frank Sottile</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14336" title="Abstract">arXiv:2302.14336</a> (replaced) [<a href="/pdf/2302.14336" title="Download PDF">pdf</a>, <a href="/format/2302.14336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beamforming and Device Selection Design in Federated Learning with  Over-the-air Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalarde%2C+F+M">Faeze Moradi Kalarde</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Min Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Ben Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Y+A+E">Yahia A. Eldemerdash Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H+T">Ho Ting Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00047" title="Abstract">arXiv:2303.00047</a> (replaced) [<a href="/pdf/2303.00047" title="Download PDF">pdf</a>, <a href="/format/2303.00047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online On-Demand Multi-Robot Coverage Path Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+R">Ratijit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+I">Indranil Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06321" title="Abstract">arXiv:2303.06321</a> (replaced) [<a href="/pdf/2303.06321" title="Download PDF">pdf</a>, <a href="/format/2303.06321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding large counterexamples by selectively exploring the Pachner graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burton%2C+B+A">Benjamin A. Burton</a>, 
<a href="/search/math?searchtype=author&query=He%2C+A">Alexander He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 28 figures. A short version appeared in the proceedings for SoCG 2023; this full version contains some new results that do not appear in the SoCG version. v2: Minor corrections in sections 3.1 and 3.2, and updates to exposition
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 39th International Symposium on Computational Geometry (SoCG
  2023). Leibniz International Proceedings in Informatics (LIPIcs), Volume 258,
  pp. 21:1-21:16, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06965" title="Abstract">arXiv:2303.06965</a> (replaced) [<a href="/pdf/2303.06965" title="Download PDF">pdf</a>, <a href="/format/2303.06965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap between Chemical Reaction Pretraining and Conditional  Molecule Generation with a Unified Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiang%2C+B">Bo Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ningfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Song Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangren Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07804" title="Abstract">arXiv:2303.07804</a> (replaced) [<a href="/pdf/2303.07804" title="Download PDF">pdf</a>, <a href="/format/2303.07804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Standardized Performance Evaluation of Flow-guided Nanoscale  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+A+B">Arnau Brosa L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Lemic%2C+F">Filip Lemic</a>, 
<a href="/search/cs?searchtype=author&query=Struye%2C+J">Jakob Struye</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+J+T">Jorge Torres G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Municio%2C+E">Esteban Municio</a>, 
<a href="/search/cs?searchtype=author&query=Delgado%2C+C">Carmen Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Bartra%2C+G+C">Gerard Calvo Bartra</a>, 
<a href="/search/cs?searchtype=author&query=Dressler%2C+F">Falko Dressler</a>, 
<a href="/search/cs?searchtype=author&query=Alarc%C3%B3n%2C+E">Eduard Alarc&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Famaey%2C+J">Jeroen Famaey</a>, 
<a href="/search/cs?searchtype=author&query=Abadal%2C+S">Sergi Abadal</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+X+C">Xavier Costa P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 16 references, available at: <a href="https://bitbucket.org/filip_lemic/flow-guided-localization-in-ns3/src/sequential/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Emerging Technologies (cs.ET); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16198" title="Abstract">arXiv:2303.16198</a> (replaced) [<a href="/pdf/2303.16198" title="Download PDF">pdf</a>, <a href="/format/2303.16198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal learning for geospatial vegetation forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benson%2C+V">Vitus Benson</a>, 
<a href="/search/cs?searchtype=author&query=Robin%2C+C">Claire Robin</a>, 
<a href="/search/cs?searchtype=author&query=Requena-Mesa%2C+C">Christian Requena-Mesa</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+L">Lazaro Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Carvalhais%2C+N">Nuno Carvalhais</a>, 
<a href="/search/cs?searchtype=author&query=Cort%C3%A9s%2C+J">Jos&#xe9; Cort&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhihan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Linscheid%2C+N">Nora Linscheid</a>, 
<a href="/search/cs?searchtype=author&query=Weynants%2C+M">M&#xe9;lanie Weynants</a>, 
<a href="/search/cs?searchtype=author&query=Reichstein%2C+M">Markus Reichstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2024. We provide open source code and pre-trained weights to reproduce our experimental results under <a href="https://github.com/vitusbenson/greenearthnet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00742" title="Abstract">arXiv:2304.00742</a> (replaced) [<a href="/pdf/2304.00742" title="Download PDF">pdf</a>, <a href="/ps/2304.00742" title="Download PostScript">ps</a>, <a href="/format/2304.00742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting the minimum number of arcs in an oriented graph having weak  diameter 2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sandip Das</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+K+K">Koushik Kumar Dey</a>, 
<a href="/search/cs?searchtype=author&query=D%2C+P+P">Pavan P D</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Sagnik Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03501" title="Abstract">arXiv:2304.03501</a> (replaced) [<a href="/pdf/2304.03501" title="Download PDF">pdf</a>, <a href="/format/2304.03501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Input Embedding Size Search For Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yunke Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Lizhen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SIGIR'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05364" title="Abstract">arXiv:2304.05364</a> (replaced) [<a href="/pdf/2304.05364" title="Download PDF">pdf</a>, <a href="/format/2304.05364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Constrained Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fishman%2C+N">Nic Fishman</a>, 
<a href="/search/cs?searchtype=author&query=Klarner%2C+L">Leo Klarner</a>, 
<a href="/search/cs?searchtype=author&query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+M">Michael Hutchinson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (07/2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07805" title="Abstract">arXiv:2304.07805</a> (replaced) [<a href="/pdf/2304.07805" title="Download PDF">pdf</a>, <a href="/ps/2304.07805" title="Download PostScript">ps</a>, <a href="/format/2304.07805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and  Dictionary-based Named Entity Recognition from Medical Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ahmed%2C+R">Rafsan Ahmed</a>, 
<a href="/search/q-bio?searchtype=author&query=Berntsson%2C+P">Petter Berntsson</a>, 
<a href="/search/q-bio?searchtype=author&query=Skafte%2C+A">Alexander Skafte</a>, 
<a href="/search/q-bio?searchtype=author&query=Rashed%2C+S+K">Salma Kazemi Rashed</a>, 
<a href="/search/q-bio?searchtype=author&query=Klang%2C+M">Marcus Klang</a>, 
<a href="/search/q-bio?searchtype=author&query=Barvesten%2C+A">Adam Barvesten</a>, 
<a href="/search/q-bio?searchtype=author&query=Olde%2C+O">Ola Olde</a>, 
<a href="/search/q-bio?searchtype=author&query=Lindholm%2C+W">William Lindholm</a>, 
<a href="/search/q-bio?searchtype=author&query=Arrizabalaga%2C+A+L">Antton Lamarca Arrizabalaga</a>, 
<a href="/search/q-bio?searchtype=author&query=Nugues%2C+P">Pierre Nugues</a>, 
<a href="/search/q-bio?searchtype=author&query=Aits%2C+S">Sonja Aits</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11520" title="Abstract">arXiv:2304.11520</a> (replaced) [<a href="/pdf/2304.11520" title="Download PDF">pdf</a>, <a href="/format/2304.11520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Processing Natural Language on Embedded Devices: How Well Do Transformer  Models Perform?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Souvika Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+M+F">Mohammad Fakhruddin Babar</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+M+M">Md Mahadi Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M">Monowar Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Santu%2C+S+K+K">Shubhra Kanti Karmaker Santu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICPE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12461" title="Abstract">arXiv:2304.12461</a> (replaced) [<a href="/pdf/2304.12461" title="Download PDF">pdf</a>, <a href="/format/2304.12461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TensoIR: Tensorial Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+I">Isabella Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peijia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoshuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songfang Han</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+S">Sai Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://haian-jin.github.io/TensoIR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13509" title="Abstract">arXiv:2304.13509</a> (replaced) [<a href="/pdf/2304.13509" title="Download PDF">pdf</a>, <a href="/format/2304.13509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyPortrait -- Face Parsing and Portrait Segmentation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kvanchiani%2C+K">Karina Kvanchiani</a>, 
<a href="/search/cs?searchtype=author&query=Petrova%2C+E">Elizaveta Petrova</a>, 
<a href="/search/cs?searchtype=author&query=Efremyan%2C+K">Karen Efremyan</a>, 
<a href="/search/cs?searchtype=author&query=Sautin%2C+A">Alexander Sautin</a>, 
<a href="/search/cs?searchtype=author&query=Kapitanov%2C+A">Alexander Kapitanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> portrait segmentation, face parsing, image segmentation dataset
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04288" title="Abstract">arXiv:2305.04288</a> (replaced) [<a href="/pdf/2305.04288" title="Download PDF">pdf</a>, <a href="/ps/2305.04288" title="Download PostScript">ps</a>, <a href="/format/2305.04288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Achieving Near-optimal Utility for Privacy-Preserving Federated  Learning via Data Generation and Parameter Distortion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05666" title="Abstract">arXiv:2305.05666</a> (replaced) [<a href="/pdf/2305.05666" title="Download PDF">pdf</a>, <a href="/format/2305.05666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Gradient Methods in the Presence of Symmetries and State  Abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panangaden%2C+P">Prakash Panangaden</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei-Shoshtari%2C+S">Sahand Rezaei-Shoshtari</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rosie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meger%2C+D">David Meger</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the Journal of Machine Learning Research (JMLR). arXiv admin note: text overlap with <a href="/abs/2209.07364">arXiv:2209.07364</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05738" title="Abstract">arXiv:2305.05738</a> (replaced) [<a href="/pdf/2305.05738" title="Download PDF">pdf</a>, <a href="/format/2305.05738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on  Wearable Medical Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chia-Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+N+K">Niraj K. Jha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 13 figures. This work has been submitted to the ACM for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12584" title="Abstract">arXiv:2305.12584</a> (replaced) [<a href="/pdf/2305.12584" title="Download PDF">pdf</a>, <a href="/ps/2305.12584" title="Download PostScript">ps</a>, <a href="/format/2305.12584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Representer Theorems for Learning in Reproducing Kernel Banach  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Y">Yuesheng Xu</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+M">Mingsong Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Functional Analysis (math.FA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13733" title="Abstract">arXiv:2305.13733</a> (replaced) [<a href="/pdf/2305.13733" title="Download PDF">pdf</a>, <a href="/format/2305.13733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Large Language Models Against Inductive Instructions with  Dual-critique Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Boyang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16344" title="Abstract">arXiv:2305.16344</a> (replaced) [<a href="/pdf/2305.16344" title="Download PDF">pdf</a>, <a href="/format/2305.16344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling and Analyzing How to Efficiently Extract Information from  Hybrid Long Documents with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+C">Chongjian Yue</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinrun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yanbing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18761" title="Abstract">arXiv:2305.18761</a> (replaced) [<a href="/pdf/2305.18761" title="Download PDF">pdf</a>, <a href="/format/2305.18761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Spurious Biases Early in Training through the Lens of  Simplicity Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+E">Eric Gan</a>, 
<a href="/search/cs?searchtype=author&query=Dziugaite%2C+G+K">Gintare Karolina Dziugaite</a>, 
<a href="/search/cs?searchtype=author&query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 27th International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2024, Valencia, Spain. PMLR: Volume 238
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19523" title="Abstract">arXiv:2305.19523</a> (replaced) [<a href="/pdf/2305.19523" title="Download PDF">pdf</a>, <a href="/format/2305.19523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Explanations: LLM-to-LM Interpreter for Enhanced  Text-Attributed Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxin He</a>, 
<a href="/search/cs?searchtype=author&query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="/search/cs?searchtype=author&query=Laurent%2C+T">Thomas Laurent</a>, 
<a href="/search/cs?searchtype=author&query=Perold%2C+A">Adam Perold</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01073" title="Abstract">arXiv:2306.01073</a> (replaced) [<a href="/pdf/2306.01073" title="Download PDF">pdf</a>, <a href="/format/2306.01073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithms for Distance Selection and Related Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiming Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version appeared in ESA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06836" title="Abstract">arXiv:2306.06836</a> (replaced) [<a href="/pdf/2306.06836" title="Download PDF">pdf</a>, <a href="/format/2306.06836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function  Approximation: Minimax Optimal and Instance-Dependent Regret Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiayi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L+F">Lin F. Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09251" title="Abstract">arXiv:2306.09251</a> (replaced) [<a href="/pdf/2306.09251" title="Download PDF">pdf</a>, <a href="/ps/2306.09251" title="Download PostScript">ps</a>, <a href="/format/2306.09251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/stat?searchtype=author&query=Wei%2C+Y">Yuting Wei</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/stat?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in part to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12059" title="Abstract">arXiv:2306.12059</a> (replaced) [<a href="/pdf/2306.12059" title="Download PDF">pdf</a>, <a href="/format/2306.12059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EquiformerV2: Improved Equivariant Transformer for Scaling to  Higher-Degree Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yi-Lun Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+B">Brandon Wood</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhishek Das</a>, 
<a href="/search/cs?searchtype=author&query=Smidt%2C+T">Tess Smidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12679" title="Abstract">arXiv:2306.12679</a> (replaced) [<a href="/pdf/2306.12679" title="Download PDF">pdf</a>, <a href="/ps/2306.12679" title="Download PostScript">ps</a>, <a href="/format/2306.12679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Colloquial Dataset for Persian Sentiment Analysis of Social  Microblogs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazoochi%2C+M">Mojtaba Mazoochi</a> (ICT Research Institute, Tehran, Iran), 
<a href="/search/cs?searchtype=author&query=Rabiei%2C+L">Leila Rabiei</a> (Iran Telecommunication Research Center (ITRC), Tehran, Iran), 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+F">Farzaneh Rahmani</a> (Computer Department, Mehralborz University, Tehran, Iran), 
<a href="/search/cs?searchtype=author&query=Rajabi%2C+Z">Zeinab Rajabi</a> (Computer Department, Hazrat-e Masoumeh University, Qom, Iran)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14131" title="Abstract">arXiv:2306.14131</a> (replaced) [<a href="/pdf/2306.14131" title="Download PDF">pdf</a>, <a href="/format/2306.14131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-Critical Scenario Generation Via Reinforcement Learning Based  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haolan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+S+K+S">Siva Kumar Sastry Hari</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jishen Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16384" title="Abstract">arXiv:2306.16384</a> (replaced) [<a href="/pdf/2306.16384" title="Download PDF">pdf</a>, <a href="/format/2306.16384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Sampling and Aggregation Operations in GNN Frameworks with  GPU Initiated Direct Storage Accesses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J+B">Jeongmin Brian Park</a>, 
<a href="/search/cs?searchtype=author&query=Mailthody%2C+V+S">Vikram Sharma Mailthody</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+Z">Zaid Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Hwu%2C+W">Wen-mei Hwu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Submission. Source code: <a href="https://github.com/jeongminpark417/GIDS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01715" title="Abstract">arXiv:2307.01715</a> (replaced) [<a href="/pdf/2307.01715" title="Download PDF">pdf</a>, <a href="/format/2307.01715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align With Purpose: Optimize Desired Properties in CTC Models with a  General Plug-and-Play Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Segev%2C+E">Eliya Segev</a>, 
<a href="/search/cs?searchtype=author&query=Alroy%2C+M">Maya Alroy</a>, 
<a href="/search/cs?searchtype=author&query=Katsir%2C+R">Ronen Katsir</a>, 
<a href="/search/cs?searchtype=author&query=Wies%2C+N">Noam Wies</a>, 
<a href="/search/cs?searchtype=author&query=Shenhav%2C+A">Ayana Shenhav</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Oren%2C+Y">Yael Ben-Oren</a>, 
<a href="/search/cs?searchtype=author&query=Zar%2C+D">David Zar</a>, 
<a href="/search/cs?searchtype=author&query=Tadmor%2C+O">Oren Tadmor</a>, 
<a href="/search/cs?searchtype=author&query=Bitterman%2C+J">Jacob Bitterman</a>, 
<a href="/search/cs?searchtype=author&query=Shashua%2C+A">Amnon Shashua</a>, 
<a href="/search/cs?searchtype=author&query=Rosenwein%2C+T">Tal Rosenwein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04001" title="Abstract">arXiv:2307.04001</a> (replaced) [<a href="/pdf/2307.04001" title="Download PDF">pdf</a>, <a href="/format/2307.04001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Width is Sufficient for Set Representation with  High-dimensional Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shenghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05318" title="Abstract">arXiv:2307.05318</a> (replaced) [<a href="/pdf/2307.05318" title="Download PDF">pdf</a>, <a href="/format/2307.05318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting small molecules solubilities on endpoint devices using deep  ensemble neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ramos%2C+M+C">Mayk Caldas Ramos</a>, 
<a href="/search/physics?searchtype=author&query=White%2C+A+D">Andrew D. White</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05717" title="Abstract">arXiv:2307.05717</a> (replaced) [<a href="/pdf/2307.05717" title="Download PDF">pdf</a>, <a href="/format/2307.05717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Mobility Data Science (Vision Paper)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mokbel%2C+M">Mohamed Mokbel</a> (University of Minnesota, Minneapolis, USA), 
<a href="/search/cs?searchtype=author&query=Sakr%2C+M">Mahmoud Sakr</a> (Universit&#xe9; Libre, Brussels, Belgium), 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Li Xiong</a> (Emory University, Atlanta, USA), 
<a href="/search/cs?searchtype=author&query=Z%C3%BCfle%2C+A">Andreas Z&#xfc;fle</a> (Emory University, Atlanta, USA), 
<a href="/search/cs?searchtype=author&query=Almeida%2C+J">Jussara Almeida</a> (Federal University of Minas Gerais, Belo Horizonte, Brazil), 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Taylor Anderson</a> (George Mason University, Fairfax, USA), 
<a href="/search/cs?searchtype=author&query=Aref%2C+W">Walid Aref</a> (Purdue University, West Lafayette, USA), 
<a href="/search/cs?searchtype=author&query=Andrienko%2C+G">Gennady Andrienko</a> (Fraunhofer IAIS, St. Augustin, Germany), 
<a href="/search/cs?searchtype=author&query=Andrienko%2C+N">Natalia Andrienko</a> (Fraunhofer IAIS, St. Augustin, Germany), 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a> (Kyoto University, Kyoto, Japan), 
<a href="/search/cs?searchtype=author&query=Chawla%2C+S">Sanjay Chawla</a> (Qatar Computing Research Institute, Doha, Qatar), 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Reynold Cheng</a> (University of Hong Kong, Hong Kong, China), 
<a href="/search/cs?searchtype=author&query=Chrysanthis%2C+P">Panos Chrysanthis</a> (University of Pittsburgh, Pennsylvania, USA), 
<a href="/search/cs?searchtype=author&query=Fei%2C+X">Xiqi Fei</a> (George Mason University, Fairfax, USA),  et al. (34 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated to reflect the major revision for ACM Transactions on Spatial Algorithms and Systems (TSAS). This version reflects the final version accepted by ACM TSAS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06212" title="Abstract">arXiv:2307.06212</a> (replaced) [<a href="/pdf/2307.06212" title="Download PDF">pdf</a>, <a href="/format/2307.06212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contract-Based Distributed Synthesis in Two-Objective Parity Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ashwani Anand</a>, 
<a href="/search/cs?searchtype=author&query=Schmuck%2C+A">Anne-Kathrin Schmuck</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+S+P">Satya Prakash Nayak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> HSCC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09064" title="Abstract">arXiv:2307.09064</a> (replaced) [<a href="/pdf/2307.09064" title="Download PDF">pdf</a>, <a href="/format/2307.09064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newtonian Program Analysis of Probabilistic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Reps%2C+T">Thomas Reps</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15237" title="Abstract">arXiv:2307.15237</a> (replaced) [<a href="/pdf/2307.15237" title="Download PDF">pdf</a>, <a href="/format/2307.15237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weather Sensitive High Spatio-Temporal Resolution Transportation  Electric Load Profiles For Multiple Decarbonization Pathways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Acharya%2C+S">Samrat Acharya</a>, 
<a href="/search/eess?searchtype=author&query=Ghosal%2C+M">Malini Ghosal</a>, 
<a href="/search/eess?searchtype=author&query=Thurber%2C+T">Travis Thurber</a>, 
<a href="/search/eess?searchtype=author&query=Burleyson%2C+C+D">Casey D. Burleyson</a>, 
<a href="/search/eess?searchtype=author&query=Ou%2C+Y">Yang Ou</a>, 
<a href="/search/eess?searchtype=author&query=Campbell%2C+A">Allison Campbell</a>, 
<a href="/search/eess?searchtype=author&query=Iyer%2C+G">Gokul Iyer</a>, 
<a href="/search/eess?searchtype=author&query=Voisin%2C+N">Nathalie Voisin</a>, 
<a href="/search/eess?searchtype=author&query=Fuller%2C+J">Jason Fuller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16634" title="Abstract">arXiv:2307.16634</a> (replaced) [<a href="/pdf/2307.16634" title="Download PDF">pdf</a>, <a href="/format/2307.16634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+R">Rabab Abdelfattah</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00014" title="Abstract">arXiv:2308.00014</a> (replaced) [<a href="/pdf/2308.00014" title="Download PDF">pdf</a>, <a href="/ps/2308.00014" title="Download PostScript">ps</a>, <a href="/format/2308.00014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new mapping of technological interdependence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Colladon%2C+A+F">A. Fronzetti Colladon</a>, 
<a href="/search/econ?searchtype=author&query=Guardabascio%2C+B">B. Guardabascio</a>, 
<a href="/search/econ?searchtype=author&query=Venturini%2C+F">F. Venturini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00846" title="Abstract">arXiv:2308.00846</a> (replaced) [<a href="/pdf/2308.00846" title="Download PDF">pdf</a>, <a href="/format/2308.00846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathfinding Future PIM Architectures by Demystifying a Commercial PIM  Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyun%2C+B">Bongjoon Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rhu%2C+M">Minsoo Rhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the 30th IEEE International Symposium on High-Performance Computer Architecture (HPCA-30), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02851" title="Abstract">arXiv:2308.02851</a> (replaced) [<a href="/pdf/2308.02851" title="Download PDF">pdf</a>, <a href="/format/2308.02851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Adversarial Networks for Stain Normalisation in  Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Breen%2C+J">Jack Breen</a>, 
<a href="/search/eess?searchtype=author&query=Zucker%2C+K">Kieran Zucker</a>, 
<a href="/search/eess?searchtype=author&query=Allen%2C+K">Katie Allen</a>, 
<a href="/search/eess?searchtype=author&query=Ravikumar%2C+N">Nishant Ravikumar</a>, 
<a href="/search/eess?searchtype=author&query=Orsi%2C+N+M">Nicolas M. Orsi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated to add link to full publication at <a href="https://doi.org/10.1007/978-3-031-46238-2_11">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05128" title="Abstract">arXiv:2308.05128</a> (replaced) [<a href="/pdf/2308.05128" title="Download PDF">pdf</a>, <a href="/format/2308.05128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Level Parallelism and Nested Features for Dynamic Inference Cost  and Top-Down Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelm%2C+A+P">Andr&#xe9; Peter Kelm</a>, 
<a href="/search/cs?searchtype=author&query=Hannemann%2C+N">Niels Hannemann</a>, 
<a href="/search/cs?searchtype=author&query=Heberle%2C+B">Bruno Heberle</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Lucas Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Rolff%2C+T">Tim Rolff</a>, 
<a href="/search/cs?searchtype=author&query=Wilms%2C+C">Christian Wilms</a>, 
<a href="/search/cs?searchtype=author&query=Yaghoubi%2C+E">Ehsan Yaghoubi</a>, 
<a href="/search/cs?searchtype=author&query=Frintrop%2C+S">Simone Frintrop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This arXiv paper's findings on high-level parallelism and nested features directly contributes to 'Selecting High-Level Features: Efficient Experts from a Hierarchical Classification Network,' accepted at ICLR 2024's Practical ML for Low Resource Settings (PML4LRS) workshop (non-archival)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05564" title="Abstract">arXiv:2308.05564</a> (replaced) [<a href="/pdf/2308.05564" title="Download PDF">pdf</a>, <a href="/format/2308.05564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Skew-t Copula Models and Asymmetric Dependence in Intraday Equity  Returns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Deng%2C+L">Lin Deng</a>, 
<a href="/search/econ?searchtype=author&query=Smith%2C+M+S">Michael Stanley Smith</a>, 
<a href="/search/econ?searchtype=author&query=Maneesoonthorn%2C+W">Worapree Maneesoonthorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Statistical Finance (q-fin.ST); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06528" title="Abstract">arXiv:2308.06528</a> (replaced) [<a href="/pdf/2308.06528" title="Download PDF">pdf</a>, <a href="/format/2308.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Abstract Visual Reasoning via Task Decomposition: A Case Study  in Raven Progressive Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwiatkowski%2C+J">Jakub Kwiatkowski</a>, 
<a href="/search/cs?searchtype=author&query=Krawiec%2C+K">Krzysztof Krawiec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11838" title="Abstract">arXiv:2308.11838</a> (replaced) [<a href="/pdf/2308.11838" title="Download PDF">pdf</a>, <a href="/format/2308.11838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark Study on Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Linwei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Younan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haolan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Minjing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12374" title="Abstract">arXiv:2308.12374</a> (replaced) [<a href="/pdf/2308.12374" title="Download PDF">pdf</a>, <a href="/format/2308.12374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Information Retrieval with Private Noisy Side Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=ZivariFard%2C+H">Hassan ZivariFard</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+R+A">Remi A. Chou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12899" title="Abstract">arXiv:2308.12899</a> (replaced) [<a href="/pdf/2308.12899" title="Download PDF">pdf</a>, <a href="/format/2308.12899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Data Management and Comprehensive Performance Evaluation for  Urban Spatial-Temporal Prediction [Experiment, Analysis &amp; Benchmark]
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chengkai Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures, VLDB under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13174" title="Abstract">arXiv:2308.13174</a> (replaced) [<a href="/pdf/2308.13174" title="Download PDF">pdf</a>, <a href="/ps/2308.13174" title="Download PostScript">ps</a>, <a href="/format/2308.13174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive segmentation in aerial images: a new benchmark and an open  access web-based tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shoukun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Que%2C+X">Xiang Que</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaogang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13662" title="Abstract">arXiv:2308.13662</a> (replaced) [<a href="/pdf/2308.13662" title="Download PDF">pdf</a>, <a href="/format/2308.13662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REFT: Resource-Efficient Federated Training Framework for Heterogeneous  and Resource-Constrained Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Desai%2C+H+A">Humaid Ahmed Desai</a>, 
<a href="/search/cs?searchtype=author&query=Hilal%2C+A">Amr Hilal</a>, 
<a href="/search/cs?searchtype=author&query=Eldardiry%2C+H">Hoda Eldardiry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14785" title="Abstract">arXiv:2308.14785</a> (replaced) [<a href="/pdf/2308.14785" title="Download PDF">pdf</a>, <a href="/format/2308.14785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A correlation-based fuzzy cluster validity index with secondary options  detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wiroonsri%2C+N">Nathakhun Wiroonsri</a>, 
<a href="/search/stat?searchtype=author&query=Preedasawakul%2C+O">Onthada Preedasawakul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00513" title="Abstract">arXiv:2309.00513</a> (replaced) [<a href="/pdf/2309.00513" title="Download PDF">pdf</a>, <a href="/ps/2309.00513" title="Download PostScript">ps</a>, <a href="/format/2309.00513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A normative approach to radicalization in social networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouttier%2C+V">Vincent Bouttier</a>, 
<a href="/search/cs?searchtype=author&query=Leclercq%2C+S">Salom&#xe9; Leclercq</a>, 
<a href="/search/cs?searchtype=author&query=Jardri%2C+R">Renaud Jardri</a>, 
<a href="/search/cs?searchtype=author&query=Deneve%2C+S">Sophie Deneve</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, 1 supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04475" title="Abstract">arXiv:2309.04475</a> (replaced) [<a href="/pdf/2309.04475" title="Download PDF">pdf</a>, <a href="/format/2309.04475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crystal Structure Prediction by Joint Equivariant Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Jiao%2C+R">Rui Jiao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+W">Wenbing Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lin%2C+P">Peijia Lin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Han%2C+J">Jiaqi Han</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+P">Pin Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+Y">Yutong Lu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05196" title="Abstract">arXiv:2309.05196</a> (replaced) [<a href="/pdf/2309.05196" title="Download PDF">pdf</a>, <a href="/format/2309.05196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Writing with Language Models Reduce Content Diversity?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padmakumar%2C+V">Vishakh Padmakumar</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05955" title="Abstract">arXiv:2309.05955</a> (replaced) [<a href="/pdf/2309.05955" title="Download PDF">pdf</a>, <a href="/format/2309.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust-Region Neural Moving Horizon Estimation for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper (not the final version) has been accepted for presentation at the ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06395" title="Abstract">arXiv:2309.06395</a> (replaced) [<a href="/pdf/2309.06395" title="Download PDF">pdf</a>, <a href="/format/2309.06395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centered Autonomy for UAS Target Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ray%2C+H+M">Hunter M. Ray</a>, 
<a href="/search/cs?searchtype=author&query=Laouar%2C+Z">Zakariya Laouar</a>, 
<a href="/search/cs?searchtype=author&query=Sunberg%2C+Z">Zachary Sunberg</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N">Nisar Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024. 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06553" title="Abstract">arXiv:2309.06553</a> (replaced) [<a href="/pdf/2309.06553" title="Download PDF">pdf</a>, <a href="/format/2309.06553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-Dependent Prompt Evaluation and Optimization with Offline Inverse  RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCy%C3%BCk%2C+A">Alihan H&#xfc;y&#xfc;k</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06692" title="Abstract">arXiv:2309.06692</a> (replaced) [<a href="/pdf/2309.06692" title="Download PDF">pdf</a>, <a href="/format/2309.06692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling the Non-IID Issue in Heterogeneous Federated Learning by  Gradient Harmonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06698" title="Abstract">arXiv:2309.06698</a> (replaced) [<a href="/pdf/2309.06698" title="Download PDF">pdf</a>, <a href="/format/2309.06698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Procedural Language Understanding for Low-Resource  Languages: A Case Study on Turkish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uzunoglu%2C+A">Arda Uzunoglu</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+G+G">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07445" title="Abstract">arXiv:2309.07445</a> (replaced) [<a href="/pdf/2309.07445" title="Download PDF">pdf</a>, <a href="/format/2309.07445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIB-200: A Simple, Inclusive, and Big Evaluation Dataset for Topic  Classification in 200+ Languages and Dialects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adelani%2C+D+I">David Ifeoluwa Adelani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hannah Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Vassilyev%2C+N">Nikita Vassilyev</a>, 
<a href="/search/cs?searchtype=author&query=Alabi%2C+J+O">Jesujoba O. Alabi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yanke Mao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haonan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A+E">Annie En-Shiun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EACL 2024 (main conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07736" title="Abstract">arXiv:2309.07736</a> (replaced) [<a href="/pdf/2309.07736" title="Download PDF">pdf</a>, <a href="/format/2309.07736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-Assisted Wireless Link Signatures for Specific Emitter  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+N">Ning Gao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shuchen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cen Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+S">Shengguo Meng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08871" title="Abstract">arXiv:2309.08871</a> (replaced) [<a href="/pdf/2309.08871" title="Download PDF">pdf</a>, <a href="/format/2309.08871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Geometric Motion Planning for High-Dimensional Systems:  Gait-Based Coordinate Optimization and Local Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bass%2C+C">Capprin Bass</a>, 
<a href="/search/cs?searchtype=author&query=Hatton%2C+R+L">Ross L. Hatton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10716" title="Abstract">arXiv:2309.10716</a> (replaced) [<a href="/pdf/2309.10716" title="Download PDF">pdf</a>, <a href="/format/2309.10716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Model Predictive Control with Error Dynamics Regression for  Autonomous Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haoru Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E+L">Edward L. Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dolan%2C+J+M">John M. Dolan</a>, 
<a href="/search/cs?searchtype=author&query=Borrelli%2C+F">Francesco Borrelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11143" title="Abstract">arXiv:2309.11143</a> (replaced) [<a href="/pdf/2309.11143" title="Download PDF">pdf</a>, <a href="/format/2309.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoT-BERT: Enhancing Unsupervised Sentence Representation through  Chain-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kehua Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11645" title="Abstract">arXiv:2309.11645</a> (replaced) [<a href="/pdf/2309.11645" title="Download PDF">pdf</a>, <a href="/format/2309.11645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Supervised Training of Spaceborne Vision during Proximity  Operations using Adaptive Kalman Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+T+H">Tae Ha Park</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amico%2C+S">Simone D&#x27;Amico</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA'2024. Final revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12708" title="Abstract">arXiv:2309.12708</a> (replaced) [<a href="/pdf/2309.12708" title="Download PDF">pdf</a>, <a href="/format/2309.12708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for  Semantic Scene Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuxiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boda Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+J">Jianfei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qinbu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+R">Ru Wan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jian Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA2024, oral &amp; poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12969" title="Abstract">arXiv:2309.12969</a> (replaced) [<a href="/pdf/2309.12969" title="Download PDF">pdf</a>, <a href="/format/2309.12969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detect Everything with Few Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Boularias%2C+A">Abdeslam Boularias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13287" title="Abstract">arXiv:2309.13287</a> (replaced) [<a href="/pdf/2309.13287" title="Download PDF">pdf</a>, <a href="/format/2309.13287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conjunctive Queries on Probabilistic Graphs: The Limits of  Approximability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amarilli%2C+A">Antoine Amarilli</a>, 
<a href="/search/cs?searchtype=author&query=van+Bremen%2C+T">Timothy van Bremen</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. Up to minor changes, this article is identical to the ICDT'24 publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14595" title="Abstract">arXiv:2309.14595</a> (replaced) [<a href="/pdf/2309.14595" title="Download PDF">pdf</a>, <a href="/format/2309.14595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Informed RRT*: Learning-based Path Planning with Point Cloud  State Representations under Admissible Ellipsoidal Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pohovey%2C+J">John Pohovey</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures. Accepted by ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16347" title="Abstract">arXiv:2309.16347</a> (replaced) [<a href="/pdf/2309.16347" title="Download PDF">pdf</a>, <a href="/format/2309.16347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic  Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Triantafyllidis%2C+E">Eleftherios Triantafyllidis</a>, 
<a href="/search/cs?searchtype=author&query=Christianos%2C+F">Filippos Christianos</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the International Conference on Robotics and Automation (ICRA), 2024. The manuscript consists of 10 pages and 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16540" title="Abstract">arXiv:2309.16540</a> (replaced) [<a href="/pdf/2309.16540" title="Download PDF">pdf</a>, <a href="/format/2309.16540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Pretraining for Fact Verification by Language Model  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazaga%2C+A">Adri&#xe1;n Bazaga</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Micklem%2C+G">Gos Micklem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17182" title="Abstract">arXiv:2309.17182</a> (replaced) [<a href="/pdf/2309.17182" title="Download PDF">pdf</a>, <a href="/format/2309.17182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RECOMBINER: Robust and Enhanced Compression with Bayesian Implicit  Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiajun He</a>, 
<a href="/search/cs?searchtype=author&query=Flamich%2C+G">Gergely Flamich</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zongyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 camera-ready version; 27 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00163" title="Abstract">arXiv:2310.00163</a> (replaced) [<a href="/pdf/2310.00163" title="Download PDF">pdf</a>, <a href="/format/2310.00163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cook2LTL: Translating Cooking Recipes to LTL Formulae using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mavrogiannis%2C+A">Angelos Mavrogiannis</a>, 
<a href="/search/cs?searchtype=author&query=Mavrogiannis%2C+C">Christoforos Mavrogiannis</a>, 
<a href="/search/cs?searchtype=author&query=Aloimonos%2C+Y">Yiannis Aloimonos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024 final version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01046" title="Abstract">arXiv:2310.01046</a> (replaced) [<a href="/pdf/2310.01046" title="Download PDF">pdf</a>, <a href="/format/2310.01046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic integration and social segregation of AI in neuroscience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Fontaine%2C+S">Sylvain Fontaine</a>, 
<a href="/search/physics?searchtype=author&query=Gargiulo%2C+F">Floriana Gargiulo</a>, 
<a href="/search/physics?searchtype=author&query=Dubois%2C+M">Michel Dubois</a>, 
<a href="/search/physics?searchtype=author&query=Tubaro%2C+P">Paola Tubaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01678" title="Abstract">arXiv:2310.01678</a> (replaced) [<a href="/pdf/2310.01678" title="Download PDF">pdf</a>, <a href="/format/2310.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score dynamics: scaling molecular dynamics with picoseconds timestep via  conditional diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hsu%2C+T">Tim Hsu</a>, 
<a href="/search/physics?searchtype=author&query=Sadigh%2C+B">Babak Sadigh</a>, 
<a href="/search/physics?searchtype=author&query=Bulatov%2C+V">Vasily Bulatov</a>, 
<a href="/search/physics?searchtype=author&query=Zhou%2C+F">Fei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02396" title="Abstract">arXiv:2310.02396</a> (replaced) [<a href="/pdf/2310.02396" title="Download PDF">pdf</a>, <a href="/format/2310.02396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit regularization of multi-task learning and finetuning in  overparameterized neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindsey%2C+J+W">Jack W. Lindsey</a>, 
<a href="/search/cs?searchtype=author&query=Lippl%2C+S">Samuel Lippl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02477" title="Abstract">arXiv:2310.02477</a> (replaced) [<a href="/pdf/2310.02477" title="Download PDF">pdf</a>, <a href="/format/2310.02477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Like Autonomous Driving on Dense Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+M">Mustafa Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Fallah%2C+S">Saber Fallah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02611" title="Abstract">arXiv:2310.02611</a> (replaced) [<a href="/pdf/2310.02611" title="Download PDF">pdf</a>, <a href="/format/2310.02611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Improving Optimal-Transport-based Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaemoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaewoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Myungjoo Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02612" title="Abstract">arXiv:2310.02612</a> (replaced) [<a href="/pdf/2310.02612" title="Download PDF">pdf</a>, <a href="/format/2310.02612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-k contrast order-preserving pattern mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yufei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingquan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fournier-Viger%2C+P">Philippe Fournier-Viger</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xindong Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02772" title="Abstract">arXiv:2310.02772</a> (replaced) [<a href="/pdf/2310.02772" title="Download PDF">pdf</a>, <a href="/format/2310.02772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spike Accumulation Forwarding for Effective Training of Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saiin%2C+R">Ryuji Saiin</a>, 
<a href="/search/cs?searchtype=author&query=Shirakawa%2C+T">Tomoya Shirakawa</a>, 
<a href="/search/cs?searchtype=author&query=Yoshihara%2C+S">Sota Yoshihara</a>, 
<a href="/search/cs?searchtype=author&query=Sawada%2C+Y">Yoshihide Sawada</a>, 
<a href="/search/cs?searchtype=author&query=Kusumoto%2C+H">Hiroyuki Kusumoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, Appendix:8 pages, 2 figures, v5:We added experimental results and considered the situation the SNN have a feedforward or feedback connection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03400" title="Abstract">arXiv:2310.03400</a> (replaced) [<a href="/pdf/2310.03400" title="Download PDF">pdf</a>, <a href="/format/2310.03400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Large Language Models for Content Moderation: Pitfalls in Data  Engineering and Supervised Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04218" title="Abstract">arXiv:2310.04218</a> (replaced) [<a href="/pdf/2310.04218" title="Download PDF">pdf</a>, <a href="/format/2310.04218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence  Classes with the same Skeleton
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V+S">Vidya Sagar Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages, 2 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05483" title="Abstract">arXiv:2310.05483</a> (replaced) [<a href="/e-print/2310.05483" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Guided Ray Augmentation for Neural Surface Reconstruction with  Sparse Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper have some major revisions, will be resubmitted soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05865" title="Abstract">arXiv:2310.05865</a> (replaced) [<a href="/pdf/2310.05865" title="Download PDF">pdf</a>, <a href="/format/2310.05865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Learning-Based Framework for Safe Human-Robot Collaboration with  Multiple Backup Control Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janwani%2C+N+C">Neil C. Janwani</a>, 
<a href="/search/cs?searchtype=author&query=Da%C5%9F%2C+E">Ersin Da&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Touma%2C+T">Thomas Touma</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S+X">Skylar X. Wei</a>, 
<a href="/search/cs?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/cs?searchtype=author&query=Burdick%2C+J+W">Joel W. Burdick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the International Conference on Robotics and Automation 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07229" title="Abstract">arXiv:2310.07229</a> (replaced) [<a href="/pdf/2310.07229" title="Download PDF">pdf</a>, <a href="/format/2310.07229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProFSA: Self-supervised Pocket Pretraining via Protein  Fragment-Surroundings Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bowen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yinjun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yuanle Mo</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuyan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weiying Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07504" title="Abstract">arXiv:2310.07504</a> (replaced) [<a href="/pdf/2310.07504" title="Download PDF">pdf</a>, <a href="/format/2310.07504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PtychoDV: Vision Transformer-Based Deep Unrolling Network for  Ptychographic Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gan%2C+W">Weijie Gan</a>, 
<a href="/search/eess?searchtype=author&query=Zhai%2C+Q">Qiuchen Zhai</a>, 
<a href="/search/eess?searchtype=author&query=McCann%2C+M+T">Michael Thompson McCann</a>, 
<a href="/search/eess?searchtype=author&query=Cardona%2C+C+G">Cristina Garcia Cardona</a>, 
<a href="/search/eess?searchtype=author&query=Kamilov%2C+U+S">Ulugbek S. Kamilov</a>, 
<a href="/search/eess?searchtype=author&query=Wohlberg%2C+B">Brendt Wohlberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07699" title="Abstract">arXiv:2310.07699</a> (replaced) [<a href="/pdf/2310.07699" title="Download PDF">pdf</a>, <a href="/format/2310.07699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeCLIP: Improving CLIP Training via Visual-enriched Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhengfeng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wentao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haoping Bai</a>, 
<a href="/search/cs?searchtype=author&query=Timofeev%2C+A">Aleksei Timofeev</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xianzhi Du</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jiulong Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chuah%2C+C">Chen-Nee Chuah</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yinfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CV/ML
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07793" title="Abstract">arXiv:2310.07793</a> (replaced) [<a href="/pdf/2310.07793" title="Download PDF">pdf</a>, <a href="/format/2310.07793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenTKG: Generative Forecasting on Temporal Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+R">Ruotong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xu Jia</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunpu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, Spotlight of Temporal Graph Learning @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07842" title="Abstract">arXiv:2310.07842</a> (replaced) [<a href="/pdf/2310.07842" title="Download PDF">pdf</a>, <a href="/format/2310.07842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiPPeR: Diffusion-based 2D Path Planner applied on Legged Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Stamatopoulou%2C+M">Maria Stamatopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+D">Dimitrios Kanoulas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08412" title="Abstract">arXiv:2310.08412</a> (replaced) [<a href="/pdf/2310.08412" title="Download PDF">pdf</a>, <a href="/format/2310.08412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-reducible Modal Transition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basile%2C+D">Davide Basile</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08775" title="Abstract">arXiv:2310.08775</a> (replaced) [<a href="/pdf/2310.08775" title="Download PDF">pdf</a>, <a href="/ps/2310.08775" title="Download PostScript">ps</a>, <a href="/format/2310.08775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Machine Learning Models Leak: An Exploration of Synthetic Training  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slokom%2C+M">Manel Slokom</a>, 
<a href="/search/cs?searchtype=author&query=de+Wolf%2C+P">Peter-Paul de Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+M">Martha Larson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Original paper published at PSD 2022. The paper was subsequently updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10316" title="Abstract">arXiv:2310.10316</a> (replaced) [<a href="/pdf/2310.10316" title="Download PDF">pdf</a>, <a href="/ps/2310.10316" title="Download PostScript">ps</a>, <a href="/format/2310.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral representation of two-sided signals from $\ell_\infty$ and  applications to signal processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dokuchaev%2C+N">Nikolai Dokuchaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10374" title="Abstract">arXiv:2310.10374</a> (replaced) [<a href="/pdf/2310.10374" title="Download PDF">pdf</a>, <a href="/format/2310.10374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Factor Spatio-Temporal Prediction based on Graph Decomposition  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiahao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+Y">Yu Mou</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Cheng Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13134" title="Abstract">arXiv:2310.13134</a> (replaced) [<a href="/pdf/2310.13134" title="Download PDF">pdf</a>, <a href="/format/2310.13134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient, Dynamic Locomotion through Step Placement with Straight Legs  and Rolling Contacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fasano%2C+S">Stefan Fasano</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+J">James Foster</a>, 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+S">Sylvain Bertrand</a>, 
<a href="/search/cs?searchtype=author&query=DeBuys%2C+C">Christian DeBuys</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+R">Robert Griffin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted and accepted to 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14884" title="Abstract">arXiv:2310.14884</a> (replaced) [<a href="/pdf/2310.14884" title="Download PDF">pdf</a>, <a href="/format/2310.14884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Budgeted Embedding Table For Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yunke Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14985" title="Abstract">arXiv:2310.14985</a> (replaced) [<a href="/pdf/2310.14985" title="Download PDF">pdf</a>, <a href="/format/2310.14985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Based Agent Society Investigation: Collaboration and Confrontation  in Avalon Gameplay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yihuai Lan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiqiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Deheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E">Ee-Peng Lim</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16727" title="Abstract">arXiv:2310.16727</a> (replaced) [<a href="/pdf/2310.16727" title="Download PDF">pdf</a>, <a href="/format/2310.16727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Hazard Management: A framework for the systematic management of root  causes for AI risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schnitzer%2C+R">Ronald Schnitzer</a>, 
<a href="/search/cs?searchtype=author&query=Hapfelmeier%2C+A">Andreas Hapfelmeier</a>, 
<a href="/search/cs?searchtype=author&query=Gaube%2C+S">Sven Gaube</a>, 
<a href="/search/cs?searchtype=author&query=Zillner%2C+S">Sonja Zillner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16985" title="Abstract">arXiv:2310.16985</a> (replaced) [<a href="/pdf/2310.16985" title="Download PDF">pdf</a>, <a href="/format/2310.16985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TinyMPC: Model-Predictive Control on Resource-Constrained  Microcontrollers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khai Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Schoedel%2C+S">Sam Schoedel</a>, 
<a href="/search/cs?searchtype=author&query=Alavilli%2C+A">Anoushka Alavilli</a>, 
<a href="/search/cs?searchtype=author&query=Plancher%2C+B">Brian Plancher</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+Z">Zachary Manchester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICRA 2024. Publicly available at <a href="https://tinympc.org">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17872" title="Abstract">arXiv:2310.17872</a> (replaced) [<a href="/pdf/2310.17872" title="Download PDF">pdf</a>, <a href="/format/2310.17872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Association and Resource Allocation in Large Language Model Based  Mobile Edge Computing System over Wireless Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Liangxin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18191" title="Abstract">arXiv:2310.18191</a> (replaced) [<a href="/pdf/2310.18191" title="Download PDF">pdf</a>, <a href="/format/2310.18191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO&#x27;s  4000 TPU Months
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezk%2C+F">Fady Rezk</a>, 
<a href="/search/cs?searchtype=author&query=Antoniou%2C+A">Antreas Antoniou</a>, 
<a href="/search/cs?searchtype=author&query=Gouk%2C+H">Henry Gouk</a>, 
<a href="/search/cs?searchtype=author&query=Hospedales%2C+T">Timothy Hospedales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18293" title="Abstract">arXiv:2310.18293</a> (replaced) [<a href="/pdf/2310.18293" title="Download PDF">pdf</a>, <a href="/format/2310.18293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Always Clear Days: Degradation Type and Severity Aware All-In-One  Adverse Weather Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+S">Soo-Chang Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20091" title="Abstract">arXiv:2310.20091</a> (replaced) [<a href="/pdf/2310.20091" title="Download PDF">pdf</a>, <a href="/format/2310.20091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density-based User Representation using Gaussian Process Regression for  Multi-interest Personalized Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haolun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meshi%2C+O">Ofer Meshi</a>, 
<a href="/search/cs?searchtype=author&query=Zoghi%2C+M">Masrour Zoghi</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+F">Fernando Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Boutilier%2C+C">Craig Boutilier</a>, 
<a href="/search/cs?searchtype=author&query=Karimzadehgan%2C+M">Maryam Karimzadehgan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00176" title="Abstract">arXiv:2311.00176</a> (replaced) [<a href="/pdf/2311.00176" title="Download PDF">pdf</a>, <a href="/format/2311.00176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChipNeMo: Domain-Adapted LLMs for Chip Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ene%2C+T">Teodor-Dumitru Ene</a>, 
<a href="/search/cs?searchtype=author&query=Kirby%2C+R">Robert Kirby</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chris Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Pinckney%2C+N">Nathaniel Pinckney</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Rongjian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Alben%2C+J">Jonah Alben</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+H">Himyanshu Anand</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sanmitra Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Bayraktaroglu%2C+I">Ismet Bayraktaroglu</a>, 
<a href="/search/cs?searchtype=author&query=Bhaskaran%2C+B">Bonita Bhaskaran</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+A">Arjun Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Clay%2C+S">Sharon Clay</a>, 
<a href="/search/cs?searchtype=author&query=Dally%2C+B">Bill Dally</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+L">Laura Dang</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+P">Parikshit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Dhodhi%2C+S">Siddhanth Dhodhi</a>, 
<a href="/search/cs?searchtype=author&query=Halepete%2C+S">Sameer Halepete</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+E">Eric Hill</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiashang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sumit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+A">Ankit Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Khailany%2C+B">Brucek Khailany</a>, 
<a href="/search/cs?searchtype=author&query=Kokai%2C+G">George Kokai</a>, 
<a href="/search/cs?searchtype=author&query=Kunal%2C+K">Kishor Kunal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lind%2C+C">Charley Lind</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Oberman%2C+S">Stuart Oberman</a>, 
<a href="/search/cs?searchtype=author&query=Omar%2C+S">Sujeet Omar</a>, 
<a href="/search/cs?searchtype=author&query=Pratty%2C+S">Sreedhar Pratty</a>, 
<a href="/search/cs?searchtype=author&query=Raiman%2C+J">Jonathan Raiman</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Ambar Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhengjiang Shao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hanfei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Suthar%2C+P+P">Pratik P Suthar</a>, 
<a href="/search/cs?searchtype=author&query=Tej%2C+V">Varun Tej</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+W">Walker Turner</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaizhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Haoxing Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated results for ChipNeMo-70B model
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01534" title="Abstract">arXiv:2311.01534</a> (replaced) [<a href="/pdf/2311.01534" title="Download PDF">pdf</a>, <a href="/format/2311.01534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Multiagent Reinforcement Learning for On-Demand Urban  Mobility Problem on a Large Map (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garces%2C+D">Daniel Garces</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sushmita Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Bertsekas%2C+D">Dimitri Bertsekas</a>, 
<a href="/search/cs?searchtype=author&query=Gil%2C+S">Stephanie Gil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 1 lemma, and 2 theorems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02576" title="Abstract">arXiv:2311.02576</a> (replaced) [<a href="/pdf/2311.02576" title="Download PDF">pdf</a>, <a href="/format/2311.02576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Feasible Dynamic Grasping: Leveraging Gaussian Process Distance  Field, SE(3) Equivariance and Riemannian Mixture Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H+J">Ho Jin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+N">Nadia Figueroa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03655" title="Abstract">arXiv:2311.03655</a> (replaced) [<a href="/pdf/2311.03655" title="Download PDF">pdf</a>, <a href="/format/2311.03655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PUMA: Fully Decentralized Uncertainty-aware Multiagent Trajectory  Planner with Real-time Image Segmentation-based Frame Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kondo%2C+K">Kota Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+C+T">Claudius T. Tewari</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+M+B">Mason B. Peterson</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+A">Annika Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Kinnari%2C+J">Jouko Kinnari</a>, 
<a href="/search/cs?searchtype=author&query=Tagliabue%2C+A">Andrea Tagliabue</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 13 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03845" title="Abstract">arXiv:2311.03845</a> (replaced) [<a href="/pdf/2311.03845" title="Download PDF">pdf</a>, <a href="/format/2311.03845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Matrices over a Polynomial Ring with Restricted Subdeterminants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Celaya%2C+M">Marcel Celaya</a>, 
<a href="/search/math?searchtype=author&query=Kuhlmann%2C+S">Stefan Kuhlmann</a>, 
<a href="/search/math?searchtype=author&query=Weismantel%2C+R">Robert Weismantel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04235" title="Abstract">arXiv:2311.04235</a> (replaced) [<a href="/pdf/2311.04235" title="Download PDF">pdf</a>, <a href="/format/2311.04235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLMs Follow Simple Rules?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+N">Norman Mu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sarah Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karamardian%2C+D">David Karamardian</a>, 
<a href="/search/cs?searchtype=author&query=Aljeraisy%2C+L">Lulwa Aljeraisy</a>, 
<a href="/search/cs?searchtype=author&query=Alomair%2C+B">Basel Alomair</a>, 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">David Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://eecs.berkeley.edu/~normanmu/llm_rules">this https URL</a>; revised content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05479" title="Abstract">arXiv:2311.05479</a> (replaced) [<a href="/pdf/2311.05479" title="Download PDF">pdf</a>, <a href="/format/2311.05479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retinal OCT Synthesis with Denoising Diffusion Probabilistic Models for  Layer Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuli Wu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+W">Weidong He</a>, 
<a href="/search/eess?searchtype=author&query=Eschweiler%2C+D">Dennis Eschweiler</a>, 
<a href="/search/eess?searchtype=author&query=Dou%2C+N">Ningxin Dou</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Z">Zixin Fan</a>, 
<a href="/search/eess?searchtype=author&query=Mi%2C+S">Shengli Mi</a>, 
<a href="/search/eess?searchtype=author&query=Walter%2C+P">Peter Walter</a>, 
<a href="/search/eess?searchtype=author&query=Stegmaier%2C+J">Johannes Stegmaier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07265" title="Abstract">arXiv:2311.07265</a> (replaced) [<a href="/pdf/2311.07265" title="Download PDF">pdf</a>, <a href="/format/2311.07265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quotient Space Quantum Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Xia%2C+J">Jing-Lei Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07619" title="Abstract">arXiv:2311.07619</a> (replaced) [<a href="/pdf/2311.07619" title="Download PDF">pdf</a>, <a href="/format/2311.07619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling User Viewing Flow Using Large Language Models for Article  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zulong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Moufeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shaoyang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WebConf 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08094" title="Abstract">arXiv:2311.08094</a> (replaced) [<a href="/pdf/2311.08094" title="Download PDF">pdf</a>, <a href="/ps/2311.08094" title="Download PostScript">ps</a>, <a href="/format/2311.08094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkelVIT: Consensus of Vision Transformers for a Lightweight  Skeleton-Based Action Recognition System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karadag%2C+O+O">Ozge Oztimur Karadag</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09232" title="Abstract">arXiv:2311.09232</a> (replaced) [<a href="/pdf/2311.09232" title="Download PDF">pdf</a>, <a href="/ps/2311.09232" title="Download PostScript">ps</a>, <a href="/format/2311.09232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Attracts Employees to Work Onsite in Times of Increased Remote  Working?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smite%2C+D">Darja Smite</a>, 
<a href="/search/cs?searchtype=author&query=Klotins%2C+E">Eriks Klotins</a>, 
<a href="/search/cs?searchtype=author&query=Moe%2C+N+B">Nils Brede Moe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 table, 2 figures. Accepted by IEEE Software
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09796" title="Abstract">arXiv:2311.09796</a> (replaced) [<a href="/pdf/2311.09796" title="Download PDF">pdf</a>, <a href="/format/2311.09796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting User Requests in the Context of Natural Language Standing  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghe%2C+N">Nikita Moghe</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+P">Patrick Xia</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Jhamtani%2C+H">Harsh Jhamtani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated with results from LLaMA-2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09939" title="Abstract">arXiv:2311.09939</a> (replaced) [<a href="/pdf/2311.09939" title="Download PDF">pdf</a>, <a href="/format/2311.09939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+S">Stefanos-Iordanis Papadopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Koutlis%2C+C">Christos Koutlis</a>, 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+S">Symeon Papadopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Petrantonakis%2C+P+C">Panagiotis C. Petrantonakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11668" title="Abstract">arXiv:2311.11668</a> (replaced) [<a href="/pdf/2311.11668" title="Download PDF">pdf</a>, <a href="/format/2311.11668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIaaS for ORAN-based 6G Networks: Multi-time Scale Slice Resource  Management with DRL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mhatre%2C+S">Suvidha Mhatre</a>, 
<a href="/search/eess?searchtype=author&query=Adelantado%2C+F">Ferran Adelantado</a>, 
<a href="/search/eess?searchtype=author&query=Ramantas%2C+K">Kostas Ramantas</a>, 
<a href="/search/eess?searchtype=author&query=Verikoukis%2C+C">Christos Verikoukis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12205" title="Abstract">arXiv:2311.12205</a> (replaced) [<a href="/pdf/2311.12205" title="Download PDF">pdf</a>, <a href="/format/2311.12205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDN-Based Dynamic Cybersecurity Framework of IEC-61850 Communications in  Smart Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Girdhar%2C+M">Mansi Girdhar</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junho Hong</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wencong Su</a>, 
<a href="/search/cs?searchtype=author&query=Herath%2C+A">Akila Herath</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen-Ching Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures, 1 table, conference paper, supported by DOE (CESER) program
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12397" title="Abstract">arXiv:2311.12397</a> (replaced) [<a href="/pdf/2311.12397" title="Download PDF">pdf</a>, <a href="/format/2311.12397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PatchCraft: Exploring Texture Patch for Efficient AI-generated Image  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+N">Nan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhenxing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our project: <a href="https://fdmas.github.io/AIGCDetect/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12688" title="Abstract">arXiv:2311.12688</a> (replaced) [<a href="/pdf/2311.12688" title="Download PDF">pdf</a>, <a href="/format/2311.12688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Out-of-Distribution Coverage of Combining Split Conformal  Prediction and Bayesian Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scemama%2C+P">Paul Scemama</a>, 
<a href="/search/cs?searchtype=author&query=Kapusta%2C+A">Ariel Kapusta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12943" title="Abstract">arXiv:2311.12943</a> (replaced) [<a href="/pdf/2311.12943" title="Download PDF">pdf</a>, <a href="/format/2311.12943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InteRACT: Transformer Models for Human Intent Prediction Conditioned on  Robot Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kedia%2C+K">Kushal Kedia</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+A">Atiksh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+P">Prithwish Dan</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We release our code and datasets at <a href="https://portal-cornell.github.io/interact/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12965" title="Abstract">arXiv:2311.12965</a> (replaced) [<a href="/pdf/2311.12965" title="Download PDF">pdf</a>, <a href="/format/2311.12965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrestrial-Satellite Spectrum Sharing in the Upper Mid-Band with  Interference Nulling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kang%2C+S">Seongjoon Kang</a>, 
<a href="/search/eess?searchtype=author&query=Geraci%2C+G">Giovanni Geraci</a>, 
<a href="/search/eess?searchtype=author&query=Mezzavilla%2C+M">Marco Mezzavilla</a>, 
<a href="/search/eess?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13488" title="Abstract">arXiv:2311.13488</a> (replaced) [<a href="/pdf/2311.13488" title="Download PDF">pdf</a>, <a href="/format/2311.13488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning based Post Event Analysis for Cybersecurity of  Cyber-Physical System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+K">Kuchan Park</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+J">Junho Hong</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+W">Wencong Su</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">HyoJong Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 IEEE Power and Energy Society General Meeting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15178" title="Abstract">arXiv:2311.15178</a> (replaced) [<a href="/pdf/2311.15178" title="Download PDF">pdf</a>, <a href="/format/2311.15178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Analysis of Coded Caching Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+R">Ruizhong Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15502" title="Abstract">arXiv:2311.15502</a> (replaced) [<a href="/pdf/2311.15502" title="Download PDF">pdf</a>, <a href="/format/2311.15502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Selected-completely-at-random Complementary Label is a Practical  Weak Supervision for Multi-class Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ishida%2C+T">Takashi Ishida</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu-Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+G">Gang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15783" title="Abstract">arXiv:2311.15783</a> (replaced) [<a href="/pdf/2311.15783" title="Download PDF">pdf</a>, <a href="/format/2311.15783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypernetworks for Generalizable BRDF Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gokbudak%2C+F">Fazilet Gokbudak</a>, 
<a href="/search/cs?searchtype=author&query=Sztrajman%2C+A">Alejandro Sztrajman</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+F">Fangcheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Mantiuk%2C+R">Rafal Mantiuk</a>, 
<a href="/search/cs?searchtype=author&query=Oztireli%2C+C">Cengiz Oztireli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16176" title="Abstract">arXiv:2311.16176</a> (replaced) [<a href="/pdf/2311.16176" title="Download PDF">pdf</a>, <a href="/format/2311.16176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Biases with Diverse Ensembles and Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scimeca%2C+L">Luca Scimeca</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Alexander Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+J">Seong Joon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A+M">Armand Mihai Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.02230">arXiv:2310.02230</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17093" title="Abstract">arXiv:2311.17093</a> (replaced) [<a href="/pdf/2311.17093" title="Download PDF">pdf</a>, <a href="/format/2311.17093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Out-of-Distribution Detection with Prototypical  Semi-Supervised Learning and Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannix%2C+E">Evelyn Mannix</a>, 
<a href="/search/cs?searchtype=author&query=Bondell%2C+H">Howard Bondell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18363" title="Abstract">arXiv:2311.18363</a> (replaced) [<a href="/pdf/2311.18363" title="Download PDF">pdf</a>, <a href="/format/2311.18363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Each Test Image Deserves A Specific Prompt: Continual Test-Time  Adaptation for 2D Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yiwen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Mengkang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yongsheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02196" title="Abstract">arXiv:2312.02196</a> (replaced) [<a href="/pdf/2312.02196" title="Download PDF">pdf</a>, <a href="/format/2312.02196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for  Enhanced Human Pose Estimation with Sparse Inertial Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Songpengcheng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+L">Lei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiarui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+L">Ling Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02625" title="Abstract">arXiv:2312.02625</a> (replaced) [<a href="/pdf/2312.02625" title="Download PDF">pdf</a>, <a href="/format/2312.02625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Noise Feature: Accurate and Fast Generated Image Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03618" title="Abstract">arXiv:2312.03618</a> (replaced) [<a href="/pdf/2312.03618" title="Download PDF">pdf</a>, <a href="/format/2312.03618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond discounted returns: Robust Markov decision processes with average  and Blackwell optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grand-Clement%2C+J">Julien Grand-Clement</a>, 
<a href="/search/math?searchtype=author&query=Petrik%2C+M">Marek Petrik</a>, 
<a href="/search/math?searchtype=author&query=Vieille%2C+N">Nicolas Vieille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05505" title="Abstract">arXiv:2312.05505</a> (replaced) [<a href="/pdf/2312.05505" title="Download PDF">pdf</a>, <a href="/ps/2312.05505" title="Download PostScript">ps</a>, <a href="/format/2312.05505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distinct Shortest Walk Enumeration for RPQs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David%2C+C">Claire David</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+N">Nadime Francis</a>, 
<a href="/search/cs?searchtype=author&query=Marsault%2C+V">Victor Marsault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06681" title="Abstract">arXiv:2312.06681</a> (replaced) [<a href="/pdf/2312.06681" title="Download PDF">pdf</a>, <a href="/format/2312.06681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Llama 2 via Contrastive Activation Addition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimsky%2C+N">Nina Rimsky</a>, 
<a href="/search/cs?searchtype=author&query=Gabrieli%2C+N">Nick Gabrieli</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+J">Julian Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=Hubinger%2C+E">Evan Hubinger</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+A+M">Alexander Matt Turner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08859" title="Abstract">arXiv:2312.08859</a> (replaced) [<a href="/pdf/2312.08859" title="Download PDF">pdf</a>, <a href="/format/2312.08859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BVI-Artefact: An Artefact Detection Benchmark Dataset for Streamed  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Danier%2C+D">Duolikun Danier</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mackin%2C+A">Alex Mackin</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+A">Andy Collins</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by Picture Coding Symposium (PCS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08864" title="Abstract">arXiv:2312.08864</a> (replaced) [<a href="/pdf/2312.08864" title="Download PDF">pdf</a>, <a href="/format/2312.08864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankDVQA-mini: Knowledge Distillation-Driven Deep Video Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/eess?searchtype=author&query=Danier%2C+D">Duolikun Danier</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Vallade%2C+B">Benoit Vallade</a>, 
<a href="/search/eess?searchtype=author&query=Mackin%2C+A">Alex Mackin</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by Picture Coding Symposium (PCS) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09417" title="Abstract">arXiv:2312.09417</a> (replaced) [<a href="/pdf/2312.09417" title="Download PDF">pdf</a>, <a href="/format/2312.09417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTP-Net: Learning to Reconstruct EEG signals in Time-Frequency Domain by  Multi-scale Feature Reuse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pei%2C+Y">Yan Pei</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jiahui Xu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qianhao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chenhao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+F">Feng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lisan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+W">Wei Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Journal of Biomedical and Health Informatics. 2024: 1-12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09838" title="Abstract">arXiv:2312.09838</a> (replaced) [<a href="/pdf/2312.09838" title="Download PDF">pdf</a>, <a href="/format/2312.09838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Approximations and Coresets for (k, l)-Median under Dynamic Time  Warping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conradi%2C+J">Jacobus Conradi</a>, 
<a href="/search/cs?searchtype=author&query=Kolbe%2C+B">Benedikt Kolbe</a>, 
<a href="/search/cs?searchtype=author&query=Psarros%2C+I">Ioannis Psarros</a>, 
<a href="/search/cs?searchtype=author&query=Rohde%2C+D">Dennis Rohde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11126" title="Abstract">arXiv:2312.11126</a> (replaced) [<a href="/pdf/2312.11126" title="Download PDF">pdf</a>, <a href="/format/2312.11126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Inherent Noises for Privacy Preservation in Quantum Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ju%2C+K">Keyi Ju</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhong%2C+H">Hui Zhong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+M">Miao Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+B">Baoling Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11949" title="Abstract">arXiv:2312.11949</a> (replaced) [<a href="/pdf/2312.11949" title="Download PDF">pdf</a>, <a href="/format/2312.11949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CreativeConnect: Supporting Reference Recombination for Graphic Design  Ideation with Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">DaEun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sumin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jeongeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J+J+Y">John Joon Young Chung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12339" title="Abstract">arXiv:2312.12339</a> (replaced) [<a href="/pdf/2312.12339" title="Download PDF">pdf</a>, <a href="/format/2312.12339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value Explicit Pretraining for Learning Transferable Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lekkala%2C+K">Kiran Lekkala</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Henghui Bao</a>, 
<a href="/search/cs?searchtype=author&query=Sontakke%2C+S">Sumedh Sontakke</a>, 
<a href="/search/cs?searchtype=author&query=Itti%2C+L">Laurent Itti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CoRL 2023 Workshop on PRL, Under Review at ICML 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12577" title="Abstract">arXiv:2312.12577</a> (replaced) [<a href="/pdf/2312.12577" title="Download PDF">pdf</a>, <a href="/format/2312.12577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An integrated EOS, pore-crush, strength and damage model framework for  near-field ground-shock
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bennett%2C+K+C">Kane C. Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Stahl%2C+A+M">Alyson M. Stahl</a>, 
<a href="/search/cs?searchtype=author&query=Canfield%2C+T+R">Thomas R. Canfield</a>, 
<a href="/search/cs?searchtype=author&query=Euler%2C+G+G">Garrett G. Euler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14625" title="Abstract">arXiv:2312.14625</a> (replaced) [<a href="/pdf/2312.14625" title="Download PDF">pdf</a>, <a href="/format/2312.14625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning for Assessing False-Data Injection  Attacks on Transportation Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eghtesad%2C+T">Taha Eghtesad</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>, 
<a href="/search/cs?searchtype=author&query=Laszka%2C+A">Aron Laszka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15583" title="Abstract">arXiv:2312.15583</a> (replaced) [<a href="/pdf/2312.15583" title="Download PDF">pdf</a>, <a href="/format/2312.15583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ITEACNet: Inverted Teacher-studEnt seArch Conversation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Licai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16619" title="Abstract">arXiv:2312.16619</a> (replaced) [<a href="/pdf/2312.16619" title="Download PDF">pdf</a>, <a href="/format/2312.16619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the security of CRYSTALS-Dilithium in the quantum random  oracle model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+K+A">Kelsey A. Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+C+A">Carl A. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daochen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages; v2: added description of CRYSTALS-Dilithium, improved analysis of concrete parameters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00110" title="Abstract">arXiv:2401.00110</a> (replaced) [<a href="/pdf/2401.00110" title="Download PDF">pdf</a>, <a href="/format/2401.00110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Model with Perceptual Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shanchuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00230" title="Abstract">arXiv:2401.00230</a> (replaced) [<a href="/pdf/2401.00230" title="Download PDF">pdf</a>, <a href="/format/2401.00230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Multivariate Forecasting: Less is More?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Caesar Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bouvry%2C+P">Pascal Bouvry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01283" title="Abstract">arXiv:2401.01283</a> (replaced) [<a href="/pdf/2401.01283" title="Download PDF">pdf</a>, <a href="/format/2401.01283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality and Quantity of Machine Translation References for Automatic  Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zouhar%2C+V">Vil&#xe9;m Zouhar</a>, 
<a href="/search/cs?searchtype=author&query=Bojar%2C+O">Ond&#x159;ej Bojar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03003" title="Abstract">arXiv:2401.03003</a> (replaced) [<a href="/pdf/2401.03003" title="Download PDF">pdf</a>, <a href="/format/2401.03003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AST-T5: Structure-Aware Pretraining for Code Generation and  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Linyuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+A">Alvin Cheung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03697" title="Abstract">arXiv:2401.03697</a> (replaced) [<a href="/pdf/2401.03697" title="Download PDF">pdf</a>, <a href="/format/2401.03697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An audio-quality-based multi-strategy approach for target speaker  extraction in the MISP 2023 Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Runduo Han</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiaopeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiayao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Quan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Ning Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08095" title="Abstract">arXiv:2401.08095</a> (replaced) [<a href="/pdf/2401.08095" title="Download PDF">pdf</a>, <a href="/format/2401.08095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+H">Hyung-Seok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-Hoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+D">Deok-Hyeon Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08180" title="Abstract">arXiv:2401.08180</a> (replaced) [<a href="/pdf/2401.08180" title="Download PDF">pdf</a>, <a href="/format/2401.08180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-free and efficient integrated photonic neural networks via  hardware-aware training and pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xu%2C+T">Tengji Xu</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+W">Weipeng Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+Z">Zeyu Luo</a>, 
<a href="/search/physics?searchtype=author&query=Xiao%2C+Q">Qiarong Xiao</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+B">Benshan Wang</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+M">Mingcheng Luo</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+X">Xingyuan Xu</a>, 
<a href="/search/physics?searchtype=author&query=Shastri%2C+B+J">Bhavin J. Shastri</a>, 
<a href="/search/physics?searchtype=author&query=Prucnal%2C+P+R">Paul R. Prucnal</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+C">Chaoran Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10220" title="Abstract">arXiv:2401.10220</a> (replaced) [<a href="/pdf/2401.10220" title="Download PDF">pdf</a>, <a href="/format/2401.10220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoFT: Learning an Objective for Robust Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Caroline Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Annie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Allan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Aditi Raghunathan</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10712" title="Abstract">arXiv:2401.10712</a> (replaced) [<a href="/pdf/2401.10712" title="Download PDF">pdf</a>, <a href="/format/2401.10712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q&amp;A Prompts: Discovering Rich Visual Clues through Mining  Question-Answer Prompts for VQA requiring Diverse World Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Weifeng Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12564" title="Abstract">arXiv:2401.12564</a> (replaced) [<a href="/pdf/2401.12564" title="Download PDF">pdf</a>, <a href="/format/2401.12564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Contrastive Invariant Learning from the Causal Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yanhu Mo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shaohua Fan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14362" title="Abstract">arXiv:2401.14362</a> (replaced) [<a href="/pdf/2401.14362" title="Download PDF">pdf</a>, <a href="/ps/2401.14362" title="Download PostScript">ps</a>, <a href="/format/2401.14362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Typing Cure: Experiences with Large Language Model Chatbots for  Mental Health Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+I">Inhwa Song</a>, 
<a href="/search/cs?searchtype=author&query=Pendse%2C+S+R">Sachin R. Pendse</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Neha Kumar</a>, 
<a href="/search/cs?searchtype=author&query=De+Choudhury%2C+M">Munmun De Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work; typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.14512" title="Abstract">arXiv:2401.14512</a> (replaced) [<a href="/pdf/2401.14512" title="Download PDF">pdf</a>, <a href="/format/2401.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Are We Missing? A Principled Approach to Characterizing the  Underrepresented Population
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Parikh%2C+H">Harsh Parikh</a>, 
<a href="/search/stat?searchtype=author&query=Ross%2C+R">Rachael Ross</a>, 
<a href="/search/stat?searchtype=author&query=Stuart%2C+E">Elizabeth Stuart</a>, 
<a href="/search/stat?searchtype=author&query=Rudolph%2C+K">Kara Rudolph</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MOUD results TBD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16235" title="Abstract">arXiv:2401.16235</a> (replaced) [<a href="/pdf/2401.16235" title="Download PDF">pdf</a>, <a href="/ps/2401.16235" title="Download PostScript">ps</a>, <a href="/format/2401.16235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Player Pressure Map -- A Novel Representation of Pressure in Soccer for  Evaluating Player Performance in Different Game Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chaoyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+J">Jiaming Na</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yisheng Pei</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+V">Varuna De Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17435" title="Abstract">arXiv:2401.17435</a> (replaced) [<a href="/pdf/2401.17435" title="Download PDF">pdf</a>, <a href="/format/2401.17435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Replace Economic Choice Prediction Labs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapira%2C+E">Eilam Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Madmon%2C+O">Omer Madmon</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01944" title="Abstract">arXiv:2402.01944</a> (replaced) [<a href="/pdf/2402.01944" title="Download PDF">pdf</a>, <a href="/format/2402.01944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guarantees in Software Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6hme%2C+M">Marcel B&#xf6;hme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages. Pre-print (under submission; single-blind). Feedback appreciated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.01950" title="Abstract">arXiv:2402.01950</a> (replaced) [<a href="/pdf/2402.01950" title="Download PDF">pdf</a>, <a href="/format/2402.01950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConRF: Zero-shot Stylization of 3D Scenes with Conditioned Radiation  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xingyu Miao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoran Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yang Long</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02686" title="Abstract">arXiv:2402.02686</a> (replaced) [<a href="/pdf/2402.02686" title="Download PDF">pdf</a>, <a href="/format/2402.02686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Region Markovian Gaussian Process: An Efficient Method to Discover  Directional Communications Across Multiple Brain Regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Li%2C+W">Weihan Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+C">Chengrui Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yule Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+A">Anqi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02746" title="Abstract">arXiv:2402.02746</a> (replaced) [<a href="/pdf/2402.02746" title="Download PDF">pdf</a>, <a href="/format/2402.02746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Standard Gaussian Process is All You Need for High-Dimensional Bayesian  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhitong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+S">Shandian Zhe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03223" title="Abstract">arXiv:2402.03223</a> (replaced) [<a href="/pdf/2402.03223" title="Download PDF">pdf</a>, <a href="/format/2402.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barei%C3%9F%2C+P">Patrick Barei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Klinger%2C+R">Roman Klinger</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+J">Jeremy Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at the PromptEng workshop at TheWebConf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04154" title="Abstract">arXiv:2402.04154</a> (replaced) [<a href="/pdf/2402.04154" title="Download PDF">pdf</a>, <a href="/format/2402.04154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Read to Play (R2-Play): Decision Transformer with Multimodal Game  Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yonggang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiawei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liuyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Shawn Yue</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+W">Stephen W. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04830" title="Abstract">arXiv:2402.04830</a> (replaced) [<a href="/pdf/2402.04830" title="Download PDF">pdf</a>, <a href="/format/2402.04830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Gap Between SGP4 and High-Precision Propagation via  Differentiable Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acciarini%2C+G">Giacomo Acciarini</a>, 
<a href="/search/cs?searchtype=author&query=Baydin%2C+A+G">At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</a>, 
<a href="/search/cs?searchtype=author&query=Izzo%2C+D">Dario Izzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Earth and Planetary Astrophysics (astro-ph.EP)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05041" title="Abstract">arXiv:2402.05041</a> (replaced) [<a href="/pdf/2402.05041" title="Download PDF">pdf</a>, <a href="/format/2402.05041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-reversible lifts of reversible diffusion processes and relaxation  times
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Eberle%2C+A">Andreas Eberle</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B6rler%2C+F">Francis L&#xf6;rler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed error in Section 5. 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Statistics Theory (math.ST); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05443" title="Abstract">arXiv:2402.05443</a> (replaced) [<a href="/pdf/2402.05443" title="Download PDF">pdf</a>, <a href="/format/2402.05443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Wasserstein Gradient Flow for Generative Modeling through  Unbalanced Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaemoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaewoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Myungjoo Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.05956" title="Abstract">arXiv:2402.05956</a> (replaced) [<a href="/pdf/2402.05956" title="Download PDF">pdf</a>, <a href="/format/2402.05956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathformer: Multi-scale Transformers with Adaptive Pathways for Time  Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yunyao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yang Shu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chenjuan Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 12th International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08957" title="Abstract">arXiv:2402.08957</a> (replaced) [<a href="/pdf/2402.08957" title="Download PDF">pdf</a>, <a href="/format/2402.08957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yinya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaohan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qingxing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+H">Huajian Xin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICLR 2024 spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Formal Languages and Automata Theory (cs.FL); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09565" title="Abstract">arXiv:2402.09565</a> (replaced) [<a href="/pdf/2402.09565" title="Download PDF">pdf</a>, <a href="/format/2402.09565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale  Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Linfeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haoran Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024 (WWW'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09707" title="Abstract">arXiv:2402.09707</a> (replaced) [<a href="/pdf/2402.09707" title="Download PDF">pdf</a>, <a href="/format/2402.09707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the adversarial robustness of Locality-Sensitive Hashing in Hamming  space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapralov%2C+M">Michael Kapralov</a>, 
<a href="/search/cs?searchtype=author&query=Makarov%2C+M">Mikhail Makarov</a>, 
<a href="/search/cs?searchtype=author&query=Sohler%2C+C">Christian Sohler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11517" title="Abstract">arXiv:2402.11517</a> (replaced) [<a href="/pdf/2402.11517" title="Download PDF">pdf</a>, <a href="/format/2402.11517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-to-SQL: Enhancing SQL Generation with Data Expert LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Zijin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.11799" title="Abstract">arXiv:2402.11799</a> (replaced) [<a href="/pdf/2402.11799" title="Download PDF">pdf</a>, <a href="/format/2402.11799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Multi-Robot Navigation for Autonomous Surface Vehicles  with Distributional Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yewei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fanfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Englot%2C+B">Brendan Englot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12226" title="Abstract">arXiv:2402.12226</a> (replaced) [<a href="/pdf/2402.12226" title="Download PDF">pdf</a>, <a href="/format/2402.12226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jun Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Junqi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiasheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yunhua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhigeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yugang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 16 figures, under review, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.12694" title="Abstract">arXiv:2402.12694</a> (replaced) [<a href="/pdf/2402.12694" title="Download PDF">pdf</a>, <a href="/format/2402.12694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revitalizing Multivariate Time Series Forecasting: Learnable  Decomposition with Inter-Series Dependencies and Intra-Series Variations  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaowei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I. Aviles-Rivero</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shujun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13587" title="Abstract">arXiv:2402.13587</a> (replaced) [<a href="/pdf/2402.13587" title="Download PDF">pdf</a>, <a href="/format/2402.13587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multimodal In-Context Tuning Approach for E-Commerce Product  Description Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuxin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13602" title="Abstract">arXiv:2402.13602</a> (replaced) [<a href="/pdf/2402.13602" title="Download PDF">pdf</a>, <a href="/format/2402.13602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Reasoning Based on Large Language Models for Autonomous Car  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azarafza%2C+M">Mehdi Azarafza</a>, 
<a href="/search/cs?searchtype=author&query=Nayyeri%2C+M">Mojtaba Nayyeri</a>, 
<a href="/search/cs?searchtype=author&query=Steinmetz%2C+C">Charles Steinmetz</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>, 
<a href="/search/cs?searchtype=author&query=Rettberg%2C+A">Achim Rettberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13754" title="Abstract">arXiv:2402.13754</a> (replaced) [<a href="/pdf/2402.13754" title="Download PDF">pdf</a>, <a href="/format/2402.13754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement learning-assisted quantum architecture search for  variational quantum algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+A">Akash Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> With 154 pages and 46 figures, here lies my PhD thesis. Typos corrected!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13788" title="Abstract">arXiv:2402.13788</a> (replaced) [<a href="/pdf/2402.13788" title="Download PDF">pdf</a>, <a href="/format/2402.13788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unifying Theory for Runge-Kutta-like Time Integrators: Convergence and  Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Izgin%2C+T">Thomas Izgin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Doctoral thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14860" title="Abstract">arXiv:2402.14860</a> (replaced) [<a href="/pdf/2402.14860" title="Download PDF">pdf</a>, <a href="/format/2402.14860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranking Large Language Models without Ground Truth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhurandhar%2C+A">Amit Dhurandhar</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+R">Rahul Nair</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Moninder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Daly%2C+E">Elizabeth Daly</a>, 
<a href="/search/cs?searchtype=author&query=Ramamurthy%2C+K+N">Karthikeyan Natesan Ramamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15784" title="Abstract">arXiv:2402.15784</a> (replaced) [<a href="/pdf/2402.15784" title="Download PDF">pdf</a>, <a href="/format/2402.15784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRConStyle: Image Restoration Framework Using Contrastive Learning and  Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dongqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+L">Liang Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16374" title="Abstract">arXiv:2402.16374</a> (replaced) [<a href="/pdf/2402.16374" title="Download PDF">pdf</a>, <a href="/format/2402.16374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Learning under Distribution Shifts: A Comprehensive Survey on  Domain Adaptation, Out-of-distribution, and Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Man Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingquan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16896" title="Abstract">arXiv:2402.16896</a> (replaced) [<a href="/pdf/2402.16896" title="Download PDF">pdf</a>, <a href="/format/2402.16896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Trojan Signatures in Large Language Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aftab Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted at the International Conference on Learning Representations 2024 Workshop on Secure and Trustworthy Large Language Models, SeT LLM @ ICLR 2024 (Vienna, Austria)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16899" title="Abstract">arXiv:2402.16899</a> (replaced) [<a href="/pdf/2402.16899" title="Download PDF">pdf</a>, <a href="/format/2402.16899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A priori Estimates for Deep Residual Network in Continuous-time  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shuyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Fei Wen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17002" title="Abstract">arXiv:2402.17002</a> (replaced) [<a href="/pdf/2402.17002" title="Download PDF">pdf</a>, <a href="/format/2402.17002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Symmetry Group Structures via Implicit Orthogonality Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huh%2C+D">Dongsung Huh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Group Theory (math.GR); Representation Theory (math.RT)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17785" title="Abstract">arXiv:2402.17785</a> (replaced) [<a href="/pdf/2402.17785" title="Download PDF">pdf</a>, <a href="/format/2402.17785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ByteComposer: a Human-like Melody Composition Method based on Language  Model Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xia Liang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xingjian Du</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiaju Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+P">Pei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yuan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bilei Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18059" title="Abstract">arXiv:2402.18059</a> (replaced) [<a href="/pdf/2402.18059" title="Download PDF">pdf</a>, <a href="/format/2402.18059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Specific Watermarking with Enhanced Detectability and Semantic  Coherence for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huo%2C+M">Mingjia Huo</a>, 
<a href="/search/cs?searchtype=author&query=Somayajula%2C+S+A">Sai Ashish Somayajula</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengtao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18064" title="Abstract">arXiv:2402.18064</a> (replaced) [<a href="/pdf/2402.18064" title="Download PDF">pdf</a>, <a href="/format/2402.18064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Testing of Spatially-Dependent Environmental Hypotheses  through Active Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harrison%2C+N">Nicholas Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+N">Nathan Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Sukkarieh%2C+S">Salah Sukkarieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication and presentation at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18470" title="Abstract">arXiv:2402.18470</a> (replaced) [<a href="/pdf/2402.18470" title="Download PDF">pdf</a>, <a href="/format/2402.18470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Higher-Order Lens for Social Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Preti%2C+G">Giulia Preti</a>, 
<a href="/search/cs?searchtype=author&query=Fazzone%2C+A">Adriano Fazzone</a>, 
<a href="/search/cs?searchtype=author&query=Petri%2C+G">Giovanni Petri</a>, 
<a href="/search/cs?searchtype=author&query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18699" title="Abstract">arXiv:2402.18699</a> (replaced) [<a href="/pdf/2402.18699" title="Download PDF">pdf</a>, <a href="/format/2402.18699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Articulated Object Manipulation with Coarse-to-fine Affordance for  Mitigating the Effect of Point Cloud Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Suhan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shiguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuzheng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19212" title="Abstract">arXiv:2402.19212</a> (replaced) [<a href="/pdf/2402.19212" title="Download PDF">pdf</a>, <a href="/ps/2402.19212" title="Download PostScript">ps</a>, <a href="/format/2402.19212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning: A Convex Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gattami%2C+A">Ather Gattami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19481" title="Abstract">arXiv:2402.19481</a> (replaced) [<a href="/pdf/2402.19481" title="Download PDF">pdf</a>, <a href="/format/2402.19481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DistriFusion: Distributed Parallel Inference for High-Resolution  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Muyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianle Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiaxin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Han Cai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Junjie Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yangqing Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming-Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 Code: <a href="https://github.com/mit-han-lab/distrifuser">this https URL</a> Website: <a href="https://hanlab.mit.edu/projects/distrifusion">this https URL</a> Blog: <a href="https://hanlab.mit.edu/blog/distrifusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00170" title="Abstract">arXiv:2403.00170</a> (replaced) [<a href="/pdf/2403.00170" title="Download PDF">pdf</a>, <a href="/format/2403.00170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlloyASG: Alloy Predicate Code Representation as a Compact Structurally  Balanced Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+A">Allison Sullivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00326" title="Abstract">arXiv:2403.00326</a> (replaced) [<a href="/pdf/2403.00326" title="Download PDF">pdf</a>, <a href="/format/2403.00326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAMSDet: Dynamic Adaptive Multispectral Detection Transformer with  Competitive Query Selection and Adaptive Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junjie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chenqiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangcen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00489" title="Abstract">arXiv:2403.00489</a> (replaced) [<a href="/pdf/2403.00489" title="Download PDF">pdf</a>, <a href="/format/2403.00489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Ways of Working with Users to Develop Physically Assistive  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nanavati%2C+A">Amal Nanavati</a>, 
<a href="/search/cs?searchtype=author&query=Pascher%2C+M">Max Pascher</a>, 
<a href="/search/cs?searchtype=author&query=Ranganeni%2C+V">Vinitha Ranganeni</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+E+K">Ethan K. Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Faulkner%2C+T+K">Taylor Kessler Faulkner</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+S+S">Siddhartha S. Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Cakmak%2C+M">Maya Cakmak</a>, 
<a href="/search/cs?searchtype=author&query=Alves-Oliveira%2C+P">Patr&#xed;cia Alves-Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J">Jens Gerken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A3DE '24: Workshop on Assistive Applications, Accessibility, and Disability Ethics at the ACM/IEEE International Conference on Human-Robot Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00758" title="Abstract">arXiv:2403.00758</a> (replaced) [<a href="/pdf/2403.00758" title="Download PDF">pdf</a>, <a href="/format/2403.00758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Reversal Curse via Semantic-aware Permutation Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00858" title="Abstract">arXiv:2403.00858</a> (replaced) [<a href="/pdf/2403.00858" title="Download PDF">pdf</a>, <a href="/format/2403.00858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Alignment of Draft Model for Speculative Decoding with  Chat-Fine-Tuned LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+R">Raghavv Goel</a>, 
<a href="/search/cs?searchtype=author&query=Gagrani%2C+M">Mukul Gagrani</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+W">Wonseok Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lott%2C+C">Christopher Lott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, Published at the ICLR 2024 Workshop on Understanding of Foundation Models (ME-FoMo)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00877" title="Abstract">arXiv:2403.00877</a> (replaced) [<a href="/pdf/2403.00877" title="Download PDF">pdf</a>, <a href="/format/2403.00877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disaggregated Multi-Tower: Topology-aware Modeling Technique for  Efficient Large-Scale Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Buyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+M">Michael Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yinbin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Ching-Hsiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yuchen Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarayanan%2C+G">Guna Lakshminarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+E+D">Ellie Dingqiao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jongsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Mudigere%2C+D">Dheevatsa Mudigere</a>, 
<a href="/search/cs?searchtype=author&query=Naumov%2C+M">Maxim Naumov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00986" title="Abstract">arXiv:2403.00986</a> (replaced) [<a href="/pdf/2403.00986" title="Download PDF">pdf</a>, <a href="/format/2403.00986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging Text Transformer Models from Different Initializations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+N">Neha Verma</a>, 
<a href="/search/cs?searchtype=author&query=Elbayad%2C+M">Maha Elbayad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01081" title="Abstract">arXiv:2403.01081</a> (replaced) [<a href="/pdf/2403.01081" title="Download PDF">pdf</a>, <a href="/format/2403.01081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAB: Large-Scale Alignment for ChatBots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudalairaj%2C+S">Shivchander Sudalairaj</a>, 
<a href="/search/cs?searchtype=author&query=Bhandwaldar%2C+A">Abhishek Bhandwaldar</a>, 
<a href="/search/cs?searchtype=author&query=Pareja%2C+A">Aldo Pareja</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+D+D">David D. Cox</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01112" title="Abstract">arXiv:2403.01112</a> (replaced) [<a href="/pdf/2403.01112" title="Download PDF">pdf</a>, <a href="/format/2403.01112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Episodic Memory Utilization of Cooperative Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Na%2C+H">Hyungho Na</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Yunkyeong Seo</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+I">Il-chul Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01428" title="Abstract">arXiv:2403.01428</a> (replaced) [<a href="/pdf/2403.01428" title="Download PDF">pdf</a>, <a href="/format/2403.01428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization matters too: How localization error affects UAV flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Suquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanfan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shu&#x27;ang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qingmin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jincheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01432" title="Abstract">arXiv:2403.01432</a> (replaced) [<a href="/pdf/2403.01432" title="Download PDF">pdf</a>, <a href="/format/2403.01432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine Tuning vs. Retrieval Augmented Generation for Less Popular  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soudani%2C+H">Heydar Soudani</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+E">Evangelos Kanoulas</a>, 
<a href="/search/cs?searchtype=author&query=Hasibi%2C+F">Faegheh Hasibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01609" title="Abstract">arXiv:2403.01609</a> (replaced) [<a href="/pdf/2403.01609" title="Download PDF">pdf</a>, <a href="/ps/2403.01609" title="Download PostScript">ps</a>, <a href="/format/2403.01609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A &quot;User Experience 3.0 (UX 3.0)&quot; Paradigm Framework: User Experience  Design for Human-Centered AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01779" title="Abstract">arXiv:2403.01779</a> (replaced) [<a href="/pdf/2403.01779" title="Download PDF">pdf</a>, <a href="/format/2403.01779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable  Virtual Try-on
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chengcai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01795" title="Abstract">arXiv:2403.01795</a> (replaced) [<a href="/pdf/2403.01795" title="Download PDF">pdf</a>, <a href="/format/2403.01795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankED: Addressing Imbalance and Uncertainty in Edge Detection Using  Ranking-based Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cetinkaya%2C+B">Bedrettin Cetinkaya</a>, 
<a href="/search/cs?searchtype=author&query=Kalkan%2C+S">Sinan Kalkan</a>, 
<a href="/search/cs?searchtype=author&query=Akbas%2C+E">Emre Akbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01971" title="Abstract">arXiv:2403.01971</a> (replaced) [<a href="/pdf/2403.01971" title="Download PDF">pdf</a>, <a href="/format/2403.01971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContrastRepair: Enhancing Conversation-Based Automated Program Repair  via Contrastive Test Case Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+J">Jiaolong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingfei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shangqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoning Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02131" title="Abstract">arXiv:2403.02131</a> (replaced) [<a href="/pdf/2403.02131" title="Download PDF">pdf</a>, <a href="/format/2403.02131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Dynamic Algorithm Selection: A  Proof-of-Principle Study on Differential Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongshu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yining Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zeyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yue-Jiao Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Systems, Man, and Cybernetics: Systems at Thu, Feb 29, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02308" title="Abstract">arXiv:2403.02308</a> (replaced) [<a href="/pdf/2403.02308" title="Download PDF">pdf</a>, <a href="/format/2403.02308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuchen Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02472" title="Abstract">arXiv:2403.02472</a> (replaced) [<a href="/pdf/2403.02472" title="Download PDF">pdf</a>, <a href="/format/2403.02472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OffLanDat: A Community Based Implicit Offensive Language Dataset  Generated by Large Language Model Through Prompt Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amit Das</a>, 
<a href="/search/cs?searchtype=author&query=Rahgouy%2C+M">Mostafa Rahgouy</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dongji Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+T">Tathagata Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Raychawdhary%2C+N">Nilanjana Raychawdhary</a>, 
<a href="/search/cs?searchtype=author&query=Sandage%2C+M">Mary Sandage</a>, 
<a href="/search/cs?searchtype=author&query=Pope%2C+L">Lauramarie Pope</a>, 
<a href="/search/cs?searchtype=author&query=Dozier%2C+G">Gerry Dozier</a>, 
<a href="/search/cs?searchtype=author&query=Seals%2C+C">Cheryl Seals</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02508" title="Abstract">arXiv:2403.02508</a> (replaced) [<a href="/pdf/2403.02508" title="Download PDF">pdf</a>, <a href="/format/2403.02508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance and Geofencing for Fixed-wing Aircraft with Control  Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+S+K">Suresh K. Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+J">James Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Dunlap%2C+K">Kyle Dunlap</a>, 
<a href="/search/cs?searchtype=author&query=Hobbs%2C+K+L">Kerianne L. Hobbs</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Transactions on Control System Technology. 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02639" title="Abstract">arXiv:2403.02639</a> (replaced) [<a href="/e-print/2403.02639" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Positive Sampling-based Data Augmentation for Enhanced 3D Object  Detection Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jiyong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junhaeng Lee</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+W">Woongchan Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+M">Minsang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Sang Hun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There was an error in the experiment settings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02781" title="Abstract">arXiv:2403.02781</a> (replaced) [<a href="/pdf/2403.02781" title="Download PDF">pdf</a>, <a href="/format/2403.02781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptKD: Unsupervised Prompt Distillation for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. Project Page: <a href="https://zhengli97.github.io/PromptKD.">this https URL</a> Code: <a href="https://github.com/zhengli97/PromptKD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03167" title="Abstract">arXiv:2403.03167</a> (replaced) [<a href="/pdf/2403.03167" title="Download PDF">pdf</a>, <a href="/format/2403.03167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARADISE: Evaluating Implicit Planning Skills of Language Models with  Procedural Warnings and Tips Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uzunoglu%2C+A">Arda Uzunoglu</a>, 
<a href="/search/cs?searchtype=author&query=Safa%2C+A+R">Abdalfatah Rashid Safa</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+G+G">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03186" title="Abstract">arXiv:2403.03186</a> (replaced) [<a href="/pdf/2403.03186" title="Download PDF">pdf</a>, <a href="/format/2403.03186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General Computer Control: A Multimodal Agent for Red Dead  Redemption II as a Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weihao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Ziluo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bohan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+J">Junpeng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haochong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiechuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinrun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Y">Yifei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+P">Pengjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karlsson%2C+B+F">B&#xf6;rje F. Karlsson</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03205" title="Abstract">arXiv:2403.03205</a> (replaced) [<a href="/pdf/2403.03205" title="Download PDF">pdf</a>, <a href="/format/2403.03205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Super-spreaders in Network Cascades
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>, 
<a href="/search/math?searchtype=author&query=Sridhar%2C+A">Anirudh Sridhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Social and Information Networks (cs.SI); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03218" title="Abstract">arXiv:2403.03218</a> (replaced) [<a href="/pdf/2403.03218" title="Download PDF">pdf</a>, <a href="/format/2403.03218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nathaniel Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Alexander Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gopal%2C+A">Anjali Gopal</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Summer Yue</a>, 
<a href="/search/cs?searchtype=author&query=Berrios%2C+D">Daniel Berrios</a>, 
<a href="/search/cs?searchtype=author&query=Gatti%2C+A">Alice Gatti</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+D">Justin D. Li</a>, 
<a href="/search/cs?searchtype=author&query=Dombrowski%2C+A">Ann-Kathrin Dombrowski</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Shashwat Goel</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+L">Long Phan</a>, 
<a href="/search/cs?searchtype=author&query=Mukobi%2C+G">Gabriel Mukobi</a>, 
<a href="/search/cs?searchtype=author&query=Helm-Burger%2C+N">Nathan Helm-Burger</a>, 
<a href="/search/cs?searchtype=author&query=Lababidi%2C+R">Rassin Lababidi</a>, 
<a href="/search/cs?searchtype=author&query=Justen%2C+L">Lennart Justen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A+B">Andrew B. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Michael Chen</a>, 
<a href="/search/cs?searchtype=author&query=Barrass%2C+I">Isabelle Barrass</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+O">Oliver Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaoyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tamirisa%2C+R">Rishub Tamirisa</a>, 
<a href="/search/cs?searchtype=author&query=Bharathi%2C+B">Bhrugu Bharathi</a>, 
<a href="/search/cs?searchtype=author&query=Khoja%2C+A">Adam Khoja</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Herbert-Voss%2C+A">Ariel Herbert-Voss</a>, 
<a href="/search/cs?searchtype=author&query=Breuer%2C+C+B">Cort B. Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">Andy Zou</a>, 
<a href="/search/cs?searchtype=author&query=Mazeika%2C+M">Mantas Mazeika</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Oswal%2C+P">Palash Oswal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hunt%2C+A+A">Adam A. Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Tienken-Harder%2C+J">Justin Tienken-Harder</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+K+Y">Kevin Y. Shih</a>, 
<a href="/search/cs?searchtype=author&query=Talley%2C+K">Kemper Talley</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">John Guan</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+R">Russell Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Steneker%2C+I">Ian Steneker</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">David Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Jokubaitis%2C+B">Brad Jokubaitis</a>, 
<a href="/search/cs?searchtype=author&query=Levinson%2C+A">Alex Levinson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jean Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">William Qian</a>, 
<a href="/search/cs?searchtype=author&query=Karmakar%2C+K+K">Kallol Krishna Karmakar</a>, 
<a href="/search/cs?searchtype=author&query=Basart%2C+S">Steven Basart</a>, 
<a href="/search/cs?searchtype=author&query=Fitz%2C+S">Stephen Fitz</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+M">Mindy Levine</a>, 
<a href="/search/cs?searchtype=author&query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>, 
<a href="/search/cs?searchtype=author&query=Tupakula%2C+U">Uday Tupakula</a>, 
<a href="/search/cs?searchtype=author&query=Varadharajan%2C+V">Vijay Varadharajan</a>, 
<a href="/search/cs?searchtype=author&query=Shoshitaishvili%2C+Y">Yan Shoshitaishvili</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jimmy Ba</a>, 
<a href="/search/cs?searchtype=author&query=Esvelt%2C+K+M">Kevin M. Esvelt</a>,  et al. (2 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See the project page at <a href="https://wmdp.ai">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03223" title="Abstract">arXiv:2403.03223</a> (replaced) [<a href="/pdf/2403.03223" title="Download PDF">pdf</a>, <a href="/format/2403.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Enforcement of Temporal Continuity in Sequential Physics-Informed  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Pratanu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Castonguay%2C+S">Stephen Castonguay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03235" title="Abstract">arXiv:2403.03235</a> (replaced) [<a href="/pdf/2403.03235" title="Download PDF">pdf</a>, <a href="/format/2403.03235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful Dynamic Timing Analysis of Digital Circuits Using Continuous  Thresholded Mode-Switched ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ferdowsi%2C+A">Arman Ferdowsi</a>, 
<a href="/search/eess?searchtype=author&query=F%C3%BCgger%2C+M">Matthias F&#xfc;gger</a>, 
<a href="/search/eess?searchtype=author&query=Nowak%2C+T">Thomas Nowak</a>, 
<a href="/search/eess?searchtype=author&query=Drmota%2C+M">Michael Drmota</a>, 
<a href="/search/eess?searchtype=author&query=Schmid%2C+U">Ulrich Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There was a missing author from the last submission. arXiv admin note: substantial text overlap with <a href="/abs/2303.14048">arXiv:2303.14048</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03309" title="Abstract">arXiv:2403.03309</a> (replaced) [<a href="/pdf/2403.03309" title="Download PDF">pdf</a>, <a href="/ps/2403.03309" title="Download PostScript">ps</a>, <a href="/format/2403.03309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Zero-Shot Material States Segmentation, by Implanting Natural  Image Patterns in Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eppel%2C+S">Sagi Eppel</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jolina Li</a>, 
<a href="/search/cs?searchtype=author&query=Drehwald%2C+M">Manuel Drehwald</a>, 
<a href="/search/cs?searchtype=author&query=Aspuru-Guzik%2C+A">Alan Aspuru-Guzik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03391" title="Abstract">arXiv:2403.03391</a> (replaced) [<a href="/pdf/2403.03391" title="Download PDF">pdf</a>, <a href="/format/2403.03391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoRMF: Criticality-Ordered Recurrent Mean Field Ising Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pan%2C+Z">Zhenyu Pan</a>, 
<a href="/search/stat?searchtype=author&query=Gilani%2C+A">Ammar Gilani</a>, 
<a href="/search/stat?searchtype=author&query=Kuo%2C+E">En-Jui Kuo</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+Z">Zhuo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03408" title="Abstract">arXiv:2403.03408</a> (replaced) [<a href="/pdf/2403.03408" title="Download PDF">pdf</a>, <a href="/format/2403.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene Depth Estimation from Traditional Oriental Landscape Paintings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">YeongHyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunkyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Juneho Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03456" title="Abstract">arXiv:2403.03456</a> (replaced) [<a href="/pdf/2403.03456" title="Download PDF">pdf</a>, <a href="/format/2403.03456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DLP-GAN: learning to draw modern Chinese landscape photos with  generative adversarial network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+X">Xiangquan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Computing and Applications, 2023: 1-18
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03542" title="Abstract">arXiv:2403.03542</a> (replaced) [<a href="/pdf/2403.03542" title="Download PDF">pdf</a>, <a href="/format/2403.03542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE  Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhongkai Hao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Berner%2C+J">Julius Berner</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+C">Chengyang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jian Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03576" title="Abstract">arXiv:2403.03576</a> (replaced) [<a href="/pdf/2403.03576" title="Download PDF">pdf</a>, <a href="/format/2403.03576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Incremental Learning with Dual Concept Drift Detection for  Identifying Anomalous Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Malialis%2C+K">Kleanthis Malialis</a>, 
<a href="/search/cs?searchtype=author&query=Polycarpou%2C+M+M">Marios M. Polycarpou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IJCNN2024,under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03602" title="Abstract">arXiv:2403.03602</a> (replaced) [<a href="/pdf/2403.03602" title="Download PDF">pdf</a>, <a href="/format/2403.03602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Based In-Cylinder Pressure Model with Cyclic Variations for  Combustion Control: A RCCI Engine Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vlaswinkel%2C+M">Maarten Vlaswinkel</a>, 
<a href="/search/eess?searchtype=author&query=Willems%2C+F">Frank Willems</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, 7 tables; Submitted to MDPI Energies' special issue on 'Advanced Research in Combustion Energy: Optimization, Applications, and Analysis'
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03622" title="Abstract">arXiv:2403.03622</a> (replaced) [<a href="/pdf/2403.03622" title="Download PDF">pdf</a>, <a href="/format/2403.03622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medial Parametrization of Arbitrary Planar Compact Domains with Dipoles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+V">Vinayak Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03643" title="Abstract">arXiv:2403.03643</a> (replaced) [<a href="/pdf/2403.03643" title="Download PDF">pdf</a>, <a href="/ps/2403.03643" title="Download PostScript">ps</a>, <a href="/format/2403.03643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Applications of Reinforcement Learning in Spatial Resource  Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Moyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mango%2C+J">Joseph Mango</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xianrui Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03669" title="Abstract">arXiv:2403.03669</a> (replaced) [<a href="/pdf/2403.03669" title="Download PDF">pdf</a>, <a href="/format/2403.03669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Algorithms on Manifolds through Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xia%2C+W">Weichun Xia</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+L">Lei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03721" title="Abstract">arXiv:2403.03721</a> (replaced) [<a href="/pdf/2403.03721" title="Download PDF">pdf</a>, <a href="/format/2403.03721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMDA: Cross-Modal and Domain Adversarial Adaptation for LiDAR-Based 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+G">Gyusam Chang</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+W">Wonseok Roh</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+S">Sujin Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongwook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Daehyun Ji</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+G">Gyeongrok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinsun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangpil Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03823" title="Abstract">arXiv:2403.03823</a> (replaced) [<a href="/pdf/2403.03823" title="Download PDF">pdf</a>, <a href="/format/2403.03823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular Approach for Multimodal Summarization of TV Shows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahon%2C+L">Louis Mahon</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03853" title="Abstract">arXiv:2403.03853</a> (replaced) [<a href="/pdf/2403.03853" title="Download PDF">pdf</a>, <a href="/format/2403.03853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShortGPT: Layers in Large Language Models are More Redundant Than You  Expect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Men%2C+X">Xin Men</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaojie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weipeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03857" title="Abstract">arXiv:2403.03857</a> (replaced) [<a href="/pdf/2403.03857" title="Download PDF">pdf</a>, <a href="/format/2403.03857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emojinize: Enriching Any Text with Emoji Translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+L+H">Lars Henning Klein</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+R">Roland Aydin</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03883" title="Abstract">arXiv:2403.03883</a> (replaced) [<a href="/pdf/2403.03883" title="Download PDF">pdf</a>, <a href="/format/2403.03883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SaulLM-7B: A pioneering Large Language Model for Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colombo%2C+P">Pierre Colombo</a>, 
<a href="/search/cs?searchtype=author&query=Pires%2C+T+P">Telmo Pessoa Pires</a>, 
<a href="/search/cs?searchtype=author&query=Boudiaf%2C+M">Malik Boudiaf</a>, 
<a href="/search/cs?searchtype=author&query=Culver%2C+D">Dominic Culver</a>, 
<a href="/search/cs?searchtype=author&query=Melo%2C+R">Rui Melo</a>, 
<a href="/search/cs?searchtype=author&query=Corro%2C+C">Caio Corro</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andre F. T. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+F">Fabrizio Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Raposo%2C+V+L">Vera L&#xfa;cia Raposo</a>, 
<a href="/search/cs?searchtype=author&query=Morgado%2C+S">Sofia Morgado</a>, 
<a href="/search/cs?searchtype=author&query=Desa%2C+M">Michael Desa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03905" title="Abstract">arXiv:2403.03905</a> (replaced) [<a href="/pdf/2403.03905" title="Download PDF">pdf</a>, <a href="/format/2403.03905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jambulapati%2C+A">Arun Jambulapati</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+S">Syamantak Kumar</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jerry Li</a>, 
<a href="/search/math?searchtype=author&query=Pandey%2C+S">Shourya Pandey</a>, 
<a href="/search/math?searchtype=author&query=Pensia%2C+A">Ankit Pensia</a>, 
<a href="/search/math?searchtype=author&query=Tian%2C+K">Kevin Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item360">Cross-lists</a></li>
<li><a href="#item397">Replacements</a></li>
</ul>
<small>[ total of 664 entries:  <b>1-664</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2403">2403</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
