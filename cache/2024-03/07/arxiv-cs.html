<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue  5 Mar 24  to  Wed  6 Mar 24, announced Thu,  7 Mar 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item316">Cross-lists</a></li>
<li><a href="#item376">Replacements</a></li>
</ul>
<small>[ total of 589 entries:  <b>1-589</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu,  7 Mar 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03222" title="Abstract">arXiv:2403.03222</a> [<a href="/pdf/2403.03222" title="Download PDF">pdf</a>, <a href="/format/2403.03222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-guided EEG Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kommineni%2C+A">Aditya Kommineni</a>, 
<a href="/search/cs?searchtype=author&query=Avramidis%2C+K">Kleanthis Avramidis</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+R">Richard Leahy</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S">Shrikanth Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages, 5 figures, Submitted to EMBC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Self-supervised learning has produced impressive results in multimedia
domains of audio, vision and speech. This paradigm is equally, if not more,
relevant for the domain of biosignals, owing to the scarcity of labelled data
in such scenarios. The ability to leverage large-scale unlabelled data to learn
robust representations could help improve the performance of numerous inference
tasks on biosignals. Given the inherent domain differences between multimedia
modalities and biosignals, the established objectives for self-supervised
learning may not translate well to this domain. Hence, there is an unmet need
to adapt these methods to biosignal analysis. In this work we propose a
self-supervised model for EEG, which provides robust performance and remarkable
parameter efficiency by using state space-based deep learning architecture. We
also propose a novel knowledge-guided pre-training objective that accounts for
the idiosyncrasies of the EEG signal. The results indicate improved embedding
representation learning and downstream performance compared to prior works on
exemplary tasks. Also, the proposed objective significantly reduces the amount
of pre-training data required to obtain performance equivalent to prior works.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03223" title="Abstract">arXiv:2403.03223</a> [<a href="/pdf/2403.03223" title="Download PDF">pdf</a>, <a href="/format/2403.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Enforcement of Temporal Continuity in Sequential Physics-Informed  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Pratanu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Castonguay%2C+S">Stephen Castonguay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The use of deep learning methods in scientific computing represents a
potential paradigm shift in engineering problem solving. One of the most
prominent developments is Physics-Informed Neural Networks (PINNs), in which
neural networks are trained to satisfy partial differential equations (PDEs)
and/or observed data. While this method shows promise, the standard version has
been shown to struggle in accurately predicting the dynamic behavior of
time-dependent problems. To address this challenge, methods have been proposed
that decompose the time domain into multiple segments, employing a distinct
neural network in each segment and directly incorporating continuity between
them in the loss function of the minimization problem. In this work we
introduce a method to exactly enforce continuity between successive time
segments via a solution ansatz. This hard constrained sequential PINN
(HCS-PINN) method is simple to implement and eliminates the need for any loss
terms associated with temporal continuity. The method is tested for a number of
benchmark problems involving both linear and non-linear PDEs. Examples include
various first order time dependent problems in which traditional PINNs
struggle, namely advection, Allen-Cahn, and Korteweg-de Vries equations.
Furthermore, second and third order time-dependent problems are demonstrated
via wave and Jerky dynamics examples, respectively. Notably, the Jerky dynamics
problem is chaotic, making the problem especially sensitive to temporal
accuracy. The numerical experiments conducted with the proposed method
demonstrated superior convergence and accuracy over both traditional PINNs and
the soft-constrained counterparts.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03235" title="Abstract">arXiv:2403.03235</a> [<a href="/pdf/2403.03235" title="Download PDF">pdf</a>, <a href="/format/2403.03235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faithful Dynamic Timing Analysis of Digital Circuits Using Continuous  Thresholded Mode-Switched ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ferdowsi%2C+A">Arman Ferdowsi</a>, 
<a href="/search/eess?searchtype=author&query=F%C3%BCgger%2C+M">Matthias F&#xfc;gger</a>, 
<a href="/search/eess?searchtype=author&query=Nowak%2C+T">Thomas Nowak</a>, 
<a href="/search/eess?searchtype=author&query=Drmota%2C+M">Michael Drmota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.14048">arXiv:2303.14048</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Thresholded hybrid systems are restricted dynamical systems, where the
current mode, and hence the ODE system describing its behavior, is solely
determined by externally supplied digital input signals and where the only
output signals are digital ones generated by comparing an internal state
variable to a threshold value. An attractive feature of such systems is easy
composition, which is facilitated by their purely digital interface. A
particularly promising application domain of thresholded hybrid systems is
digital integrated circuits: Modern digital circuit design considers them as a
composition of Millions and even Billions of elementary logic gates, like
inverters, GOR and Gand. Since every such logic gate is eventually implemented
as an electronic circuit, however, which exhibits a behavior that is governed
by some ODE system, thresholded hybrid systems are ideally suited for making
the transition from the analog to the digital world rigorous.
<br />In this paper, we prove that the mapping from digital input signals to
digital output signals is continuous for a large class of thresholded hybrid
systems. Moreover, we show that, under some mild conditions regarding
causality, this continuity also continues to hold for arbitrary compositions,
which in turn guarantees that the composition faithfully captures the analog
reality. By applying our generic results to some recently developed thresholded
hybrid gate models, both for single-input single-output gates like inverters
and for a two-input CMOS NOR gate, we show that they are continuous. Moreover,
we provide a novel thresholded hybrid model for the two-input NOR gate, which
is not only continuous but also, unlike the existing one, faithfully models all
multi-input switching effects.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03241" title="Abstract">arXiv:2403.03241</a> [<a href="/pdf/2403.03241" title="Download PDF">pdf</a>, <a href="/format/2403.03241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Framework for Wireless Radiation Field Reconstruction  and Channel Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haofan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Vattheuer%2C+C">Christopher Vattheuer</a>, 
<a href="/search/cs?searchtype=author&query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>, 
<a href="/search/cs?searchtype=author&query=Abari%2C+O">Omid Abari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We present NeWRF, a deep learning framework for predicting wireless channels.
Wireless channel prediction is a long-standing problem in the wireless
community and is a key technology for improving the coverage of wireless
network deployments. Today, a wireless deployment is evaluated by a site survey
which is a cumbersome process requiring an experienced engineer to perform
extensive channel measurements. To reduce the cost of site surveys, we develop
NeWRF, which is based on recent advances in Neural Radiance Fields (NeRF).
NeWRF trains a neural network model with a sparse set of channel measurements,
and predicts the wireless channel accurately at any location in the site. We
introduce a series of techniques that integrate wireless propagation properties
into the NeRF framework to account for the fundamental differences between the
behavior of light and wireless signals. We conduct extensive evaluations of our
framework and show that our approach can accurately predict channels at
unvisited locations with significantly lower measurement density than prior
state-of-the-art
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03265" title="Abstract">arXiv:2403.03265</a> [<a href="/pdf/2403.03265" title="Download PDF">pdf</a>, <a href="/ps/2403.03265" title="Download PostScript">ps</a>, <a href="/format/2403.03265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an AI-Enhanced Cyber Threat Intelligence Processing Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alevizos%2C+L">Lampis Alevizos</a>, 
<a href="/search/cs?searchtype=author&query=Dekker%2C+M">Martijn Dekker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cyber threats continue to evolve in complexity, thereby traditional Cyber
Threat Intelligence (CTI) methods struggle to keep pace. AI offers a potential
solution, automating and enhancing various tasks, from data ingestion to
resilience verification. This paper explores the potential of integrating
Artificial Intelligence (AI) into CTI. We provide a blueprint of an AI-enhanced
CTI processing pipeline, and detail its components and functionalities. The
pipeline highlights the collaboration of AI and human expertise, which is
necessary to produce timely and high-fidelity cyber threat intelligence. We
also explore the automated generation of mitigation recommendations, harnessing
AI's capabilities to provide real-time, contextual, and predictive insights.
However, the integration of AI into CTI is not without challenges. Thereby, we
discuss ethical dilemmas, potential biases, and the imperative for transparency
in AI-driven decisions. We address the need for data privacy, consent
mechanisms, and the potential misuse of technology. Moreover, we highlights the
importance of addressing biases both during CTI analysis and AI models
warranting their transparency and interpretability. Lastly, our work points out
future research directions such as the exploration of advanced AI models to
augment cyber defences, and the human-AI collaboration optimization.
Ultimately, the fusion of AI with CTI appears to hold significant potential in
cybersecurity domain.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03267" title="Abstract">arXiv:2403.03267</a> [<a href="/pdf/2403.03267" title="Download PDF">pdf</a>, <a href="/format/2403.03267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TTPXHunter: Actionable Threat Intelligence Extraction as TTPs form  Finished Cyber Threat Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rani%2C+N">Nanda Rani</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+B">Bikash Saha</a>, 
<a href="/search/cs?searchtype=author&query=Maurya%2C+V">Vikas Maurya</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+S+K">Sandeep Kumar Shukla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Understanding the modus operandi of adversaries aids organizations in
employing efficient defensive strategies and sharing intelligence in the
community. This knowledge is often present in unstructured natural language
text within threat analysis reports. A translation tool is needed to interpret
the modus operandi explained in the sentences of the threat report and
translate it into a structured format. This research introduces a methodology
named TTPXHunter for the automated extraction of threat intelligence in terms
of Tactics, Techniques, and Procedures (TTPs) from finished cyber threat
reports. It leverages cyber domain-specific state-of-the-art natural language
processing (NLP) to augment sentences for minority class TTPs and refine
pinpointing the TTPs in threat analysis reports significantly. The knowledge of
threat intelligence in terms of TTPs is essential for comprehensively
understanding cyber threats and enhancing detection and mitigation strategies.
We create two datasets: an augmented sentence-TTP dataset of 39,296 samples and
a 149 real-world cyber threat intelligence report-to-TTP dataset. Further, we
evaluate TTPXHunter on the augmented sentence dataset and the cyber threat
reports. The TTPXHunter achieves the highest performance of 92.42% f1-score on
the augmented dataset, and it also outperforms existing state-of-the-art
solutions in TTP extraction by achieving an f1-score of 97.09% when evaluated
over the report dataset. TTPXHunter significantly improves cybersecurity threat
intelligence by offering quick, actionable insights into attacker behaviors.
This advancement automates threat intelligence analysis, providing a crucial
tool for cybersecurity professionals fighting cyber threats.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03268" title="Abstract">arXiv:2403.03268</a> [<a href="/pdf/2403.03268" title="Download PDF">pdf</a>, <a href="/format/2403.03268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transient Thermal Model for Power Electronics Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Padmanabhan%2C+N">Neelakantan Padmanabhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Southeastcon 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">An equation based reduced order model applicable to generalized heat equation
and thermal simulations of power electronics systems developed in commercial
CFD tools, is presented in this work. The model considers the physics of heat
transfer between multiple objects in different mediums and presents a set of
equations that can be applied to a wide range of heat transfer scenarios
including conduction, natural and forced convection problems. A few case
studies including heat transfer in a power electronic system are simulated in
Ansys Icepak and the temperatures from the simulations are compared with the
temperatures predicted by the models. The models are observed to be highly
accurate when compared with the simulations. The predictive model described in
this work reduces large complex simulations down to a few parameters which
tremendously improves the computation speed, uses very low physical disk space
and enables fast evaluation of thermal performance of the system for any
changes in the input parameters.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03269" title="Abstract">arXiv:2403.03269</a> [<a href="/pdf/2403.03269" title="Download PDF">pdf</a>, <a href="/format/2403.03269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Information Gathering for Long-Horizon Navigation Under  Uncertainty by Learning the Value of Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnob%2C+R+I">Raihan Islam Arnob</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+G+J">Gregory J. Stein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted at IROS'24. arXiv admin note: text overlap with <a href="/abs/2307.14501">arXiv:2307.14501</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We address the task of long-horizon navigation in partially mapped
environments for which active gathering of information about faraway unseen
space is essential for good behavior. We present a novel planning strategy
that, at training time, affords tractable computation of the value of
information associated with revealing potentially informative regions of unseen
space, data used to train a graph neural network to predict the goodness of
temporally-extended exploratory actions. Our learning-augmented model-based
planning approach predicts the expected value of information of revealing
unseen space and is capable of using these predictions to actively seek
information and so improve long-horizon navigation. Across two simulated
office-like environments, our planner outperforms competitive learned and
non-learned baseline navigation strategies, achieving improvements of up to
63.76% and 36.68%, demonstrating its capacity to actively seek
performance-critical information.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03270" title="Abstract">arXiv:2403.03270</a> [<a href="/pdf/2403.03270" title="Download PDF">pdf</a>, <a href="/format/2403.03270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-KVIL: Keypoints-based Visual Imitation Learning of Bimanual  Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Jaquier%2C+N">No&#xe9;mie Jaquier</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Visual imitation learning has achieved impressive progress in learning
unimanual manipulation tasks from a small set of visual observations, thanks to
the latest advances in computer vision. However, learning bimanual coordination
strategies and complex object relations from bimanual visual demonstrations, as
well as generalizing them to categorical objects in novel cluttered scenes
remain unsolved challenges. In this paper, we extend our previous work on
keypoints-based visual imitation learning (\mbox{K-VIL})~\cite{gao_kvil_2023}
to bimanual manipulation tasks. The proposed Bi-KVIL jointly extracts so-called
\emph{Hybrid Master-Slave Relationships} (HMSR) among objects and hands,
bimanual coordination strategies, and sub-symbolic task representations. Our
bimanual task representation is object-centric, embodiment-independent, and
viewpoint-invariant, thus generalizing well to categorical objects in novel
scenes. We evaluate our approach in various real-world applications, showcasing
its ability to learn fine-grained bimanual manipulation tasks from a small
number of human demonstration videos. Videos and source code are available at
https://sites.google.com/view/bi-kvil.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03273" title="Abstract">arXiv:2403.03273</a> [<a href="/pdf/2403.03273" title="Download PDF">pdf</a>, <a href="/format/2403.03273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DINOv2 based Self Supervised Learning For Few Shot Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayzenberg%2C+L">Lev Ayzenberg</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>, 
<a href="/search/cs?searchtype=author&query=Greenspan%2C+H">Hayit Greenspan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models have emerged as the cornerstone of medical image
segmentation, but their efficacy hinges on the availability of extensive
manually labeled datasets and their adaptability to unforeseen categories
remains a challenge. Few-shot segmentation (FSS) offers a promising solution by
endowing models with the capacity to learn novel classes from limited labeled
examples. A leading method for FSS is ALPNet, which compares features between
the query image and the few available support segmented images. A key question
about using ALPNet is how to design its features. In this work, we delve into
the potential of using features from DINOv2, which is a foundational
self-supervised learning model in computer vision. Leveraging the strengths of
ALPNet and harnessing the feature extraction capabilities of DINOv2, we present
a novel approach to few-shot segmentation that not only enhances performance
but also paves the way for more robust and adaptable medical image analysis.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03278" title="Abstract">arXiv:2403.03278</a> [<a href="/pdf/2403.03278" title="Download PDF">pdf</a>, <a href="/ps/2403.03278" title="Download PostScript">ps</a>, <a href="/format/2403.03278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Codes for Hyperdimensional Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raviv%2C+N">Netanel Raviv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Author's final version. The article has been accepted for publication in Neural Computation (MIT press)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Hyperdimensional Computing (HDC) is an emerging computational paradigm for
representing compositional information as high-dimensional vectors, and has a
promising potential in applications ranging from machine learning to
neuromorphic computing. One of the long-standing challenges in HDC is factoring
a compositional representation to its constituent factors, also known as the
recovery problem. In this paper we take a novel approach to solve the recovery
problem, and propose the use of random linear codes. These codes are subspaces
over the Boolean field, and are a well-studied topic in information theory with
various applications in digital communication. We begin by showing that
hyperdimensional encoding using random linear codes retains favorable
properties of the prevalent (ordinary) random codes, and hence HD
representations using the two methods have comparable information storage
capabilities. We proceed to show that random linear codes offer a rich subcode
structure that can be used to form key-value stores, which encapsulate most use
cases of HDC. Most importantly, we show that under the framework we develop,
random linear codes admit simple recovery algorithms to factor (either bundled
or bound) compositional representations. The former relies on constructing
certain linear equation systems over the Boolean field, the solution to which
reduces the search space dramatically and strictly outperforms exhaustive
search in many cases. The latter employs the subspace structure of these codes
to achieve provably correct factorization. Both methods are strictly faster
than the state-of-the-art resonator networks, often by an order of magnitude.
We implemented our techniques in Python using a benchmark software library, and
demonstrated promising experimental results.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03281" title="Abstract">arXiv:2403.03281</a> [<a href="/pdf/2403.03281" title="Download PDF">pdf</a>, <a href="/format/2403.03281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
<a href="/search/cs?searchtype=author&query=Tenali%2C+P">Pranuthi Tenali</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+S">Saurabh Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Blasch%2C+E">Erik Blasch</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+S">Sriraam Natarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the problem of late multi-modal fusion for discriminative
learning. Motivated by noisy, multi-source domains that require understanding
the reliability of each data source, we explore the notion of credibility in
the context of multi-modal fusion. We propose a combination function that uses
probabilistic circuits (PCs) to combine predictive distributions over
individual modalities. We also define a probabilistic measure to evaluate the
credibility of each modality via inference queries over the PC. Our
experimental evaluation demonstrates that our fusion method can reliably infer
credibility while maintaining competitive performance with the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03288" title="Abstract">arXiv:2403.03288</a> [<a href="/pdf/2403.03288" title="Download PDF">pdf</a>, <a href="/ps/2403.03288" title="Download PostScript">ps</a>, <a href="/format/2403.03288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should We Fear Large Language Models? A Structural Analysis of the Human  Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens  of Heidegger&#x27;s Philosophy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianqiiu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the rapidly evolving field of Large Language Models (LLMs), there is a
critical need to thoroughly analyze their capabilities and risks. Central to
our investigation are two novel elements. Firstly, it is the innovative
parallels between the statistical patterns of word relationships within LLMs
and Martin Heidegger's concepts of "ready-to-hand" and "present-at-hand," which
encapsulate the utilitarian and scientific altitudes humans employ in
interacting with the world. This comparison lays the groundwork for positioning
LLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding
light on their capacity to emulate certain facets of human reasoning. Secondly,
a structural analysis of human reasoning, viewed through Heidegger's notion of
truth as "unconcealment" is conducted This foundational principle enables us to
map out the inputs and outputs of the reasoning system and divide reasoning
into four distinct categories. Respective cognitive faculties are delineated,
allowing us to place LLMs within the broader schema of human reasoning, thus
clarifying their strengths and inherent limitations. Our findings reveal that
while LLMs possess the capability for Direct Explicative Reasoning and Pseudo
Rational Reasoning, they fall short in authentic rational reasoning and have no
creative reasoning capabilities, due to the current lack of many analogous AI
models such as the Faculty of Judgement. The potential and risks of LLMs when
they are augmented with other AI technologies are also evaluated. The results
indicate that although LLMs have achieved proficiency in some reasoning
abilities, the aspiration to match or exceed human intellectual capabilities is
yet unattained. This research not only enriches our comprehension of LLMs but
also propels forward the discourse on AI's potential and its bounds, paving the
way for future explorations into AI's evolving landscape.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03290" title="Abstract">arXiv:2403.03290</a> [<a href="/pdf/2403.03290" title="Download PDF">pdf</a>, <a href="/ps/2403.03290" title="Download PostScript">ps</a>, <a href="/format/2403.03290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maintaining Light Spanners via Minimal Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khodabandeh%2C+H">Hadi Khodabandeh</a>, 
<a href="/search/cs?searchtype=author&query=Eppstein%2C+D">David Eppstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study the problem of maintaining a lightweight bounded-degree
$(1+\varepsilon)$-spanner of a dynamic point set in a $d$-dimensional Euclidean
space, where $\varepsilon&gt;0$ and $d$ are arbitrary constants. In our
fully-dynamic setting, points are allowed to be inserted as well as deleted,
and our objective is to maintain a $(1+\varepsilon)$-spanner that has constant
bounds on its maximum degree and its lightness (the ratio of its weight to that
of the minimum spanning tree), while minimizing the recourse, which is the
number of edges added or removed by each point insertion or deletion. We
present a fully-dynamic algorithm that handles point insertion with amortized
constant recourse and point deletion with amortized $O(\log\Delta)$ recourse,
where $\Delta$ is the aspect ratio of the point set.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03292" title="Abstract">arXiv:2403.03292</a> [<a href="/pdf/2403.03292" title="Download PDF">pdf</a>, <a href="/format/2403.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Averaging Rate Scheduler for Decentralized Learning on Heterogeneous  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aketi%2C+S+A">Sai Aparna Aketi</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+S">Sakshi Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 4 tables. arXiv admin note: text overlap with <a href="/abs/2305.04792">arXiv:2305.04792</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">State-of-the-art decentralized learning algorithms typically require the data
distribution to be Independent and Identically Distributed (IID). However, in
practical scenarios, the data distribution across the agents can have
significant heterogeneity. In this work, we propose averaging rate scheduling
as a simple yet effective way to reduce the impact of heterogeneity in
decentralized learning. Our experiments illustrate the superiority of the
proposed method (~3% improvement in test accuracy) compared to the conventional
approach of employing a constant averaging rate.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03293" title="Abstract">arXiv:2403.03293</a> [<a href="/pdf/2403.03293" title="Download PDF">pdf</a>, <a href="/format/2403.03293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Insights: A Case Study on Utilizing ChatGPT Intelligence for Research  Paper Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+A">Anjalee De Silva</a>, 
<a href="/search/cs?searchtype=author&query=Wijekoon%2C+J+L">Janaka L. Wijekoon</a>, 
<a href="/search/cs?searchtype=author&query=Liyanarachchi%2C+R">Rashini Liyanarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Panchendrarajan%2C+R">Rrubaa Panchendrarajan</a>, 
<a href="/search/cs?searchtype=author&query=Rajapaksha%2C+W">Weranga Rajapaksha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper discusses the effectiveness of leveraging Chatbot: Generative
Pre-trained Transformer (ChatGPT) versions 3.5 and 4 for analyzing research
papers for effective writing of scientific literature surveys. The study
selected the \textit{Application of Artificial Intelligence in Breast Cancer
Treatment} as the research topic. Research papers related to this topic were
collected from three major publication databases Google Scholar, Pubmed, and
Scopus. ChatGPT models were used to identify the category, scope, and relevant
information from the research papers for automatic identification of relevant
papers related to Breast Cancer Treatment (BCT), organization of papers
according to scope, and identification of key information for survey paper
writing. Evaluations performed using ground truth data annotated using subject
experts reveal, that GPT-4 achieves 77.3\% accuracy in identifying the research
paper categories and 50\% of the papers were correctly identified by GPT-4 for
their scopes. Further, the results demonstrate that GPT-4 can generate reasons
for its decisions with an average of 27\% new words, and 67\% of the reasons
given by the model were completely agreeable to the subject experts.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03296" title="Abstract">arXiv:2403.03296</a> [<a href="/pdf/2403.03296" title="Download PDF">pdf</a>, <a href="/format/2403.03296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CenterDisks: Real-time instance segmentation with disk covering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Litto%2C+K+J">Katia Jodogne-Del Litto</a>, 
<a href="/search/cs?searchtype=author&query=Bilodeau%2C+G">Guillaume-Alexandre Bilodeau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Increasing the accuracy of instance segmentation methods is often done at the
expense of speed. Using coarser representations, we can reduce the number of
parameters and thus obtain real-time masks. In this paper, we take inspiration
from the set cover problem to predict mask approximations. Given ground-truth
binary masks of objects of interest as training input, our method learns to
predict the approximate coverage of these objects by disks without supervision
on their location or radius. Each object is represented by a fixed number of
disks with different radii. In the learning phase, we consider the radius as
proportional to a standard deviation in order to compute the error to propagate
on a set of two-dimensional Gaussian functions rather than disks. We trained
and tested our instance segmentation method on challenging datasets showing
dense urban settings with various road users. Our method achieve state-of-the
art results on the IDD and KITTI dataset with an inference time of 0.040 s on a
single RTX 3090 GPU.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03297" title="Abstract">arXiv:2403.03297</a> [<a href="/pdf/2403.03297" title="Download PDF">pdf</a>, <a href="/format/2403.03297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;It&#x27;s the only thing I can trust&quot;: Envisioning Large Language Model Use  by Autistic Workers for Communication Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">JiWoong Jang</a>, 
<a href="/search/cs?searchtype=author&query=Moharana%2C+S">Sanika Moharana</a>, 
<a href="/search/cs?searchtype=author&query=Carrington%2C+P">Patrick Carrington</a>, 
<a href="/search/cs?searchtype=author&query=Begel%2C+A">Andrew Begel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figure, CHI '24 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Autistic adults often experience stigma and discrimination at work, leading
them to seek social communication support from coworkers, friends, and family
despite emotional risks. Large language models (LLMs) are increasingly
considered an alternative. In this work, we investigate the phenomenon of LLM
use by autistic adults at work and explore opportunities and risks of LLMs as a
source of social communication advice. We asked 11 autistic participants to
present questions about their own workplace-related social difficulties to (1)
a GPT-4-based chatbot and (2) a disguised human confederate. Our evaluation
shows that participants strongly preferred LLM over confederate interactions.
However, a coach specializing in supporting autistic job-seekers raised
concerns that the LLM was dispensing questionable advice. We highlight how this
divergence in participant and practitioner attitudes reflects existing schisms
in HCI on the relative privileging of end-user wants versus normative good and
propose design considerations for LLMs to center autistic experiences.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03304" title="Abstract">arXiv:2403.03304</a> [<a href="/pdf/2403.03304" title="Download PDF">pdf</a>, <a href="/format/2403.03304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event  Argument Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gatto%2C+J">Joseph Gatto</a>, 
<a href="/search/cs?searchtype=author&query=Seegmiller%2C+P">Parker Seegmiller</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+O">Omar Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Preum%2C+S+M">Sarah M. Preum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Document-Level Event Argument Extraction (DocEAE) is an extremely difficult
information extraction problem -- with significant limitations in low-resource
cross-domain settings. To address this problem, we introduce Mad Lib Aug (MLA),
a novel generative DocEAE data augmentation framework. Our approach leverages
the intuition that Mad Libs, which are categorically masked documents used as a
part of a popular game, can be generated and solved by LLMs to produce data for
DocEAE. Using MLA, we achieve a 2.6-point average improvement in overall F1
score. Moreover, this approach achieves a 3.9 and 5.2 point average increase in
zero and few-shot event roles compared to augmentation-free baselines across
all experiments.
<br />To better facilitate analysis of cross-domain DocEAE, we additionally
introduce a new metric, Role-Depth F1 (RDF1), which uses statistical depth to
identify roles in the target domain which are semantic outliers with respect to
roles observed in the source domain. Our experiments show that MLA augmentation
can boost RDF1 performance by an average of 5.85 points compared to
non-augmented datasets.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03305" title="Abstract">arXiv:2403.03305</a> [<a href="/pdf/2403.03305" title="Download PDF">pdf</a>, <a href="/format/2403.03305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach  for Relation Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vacareanu%2C+R">Robert Vacareanu</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+F">Fahmida Alam</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+A">Md Asiful Islam</a>, 
<a href="/search/cs?searchtype=author&query=Riaz%2C+H">Haris Riaz</a>, 
<a href="/search/cs?searchtype=author&query=Surdeanu%2C+M">Mihai Surdeanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a novel neuro-symbolic architecture for relation
classification (RC) that combines rule-based methods with contemporary deep
learning techniques. This approach capitalizes on the strengths of both
paradigms: the adaptability of rule-based systems and the generalization power
of neural networks. Our architecture consists of two components: a declarative
rule-based model for transparent classification and a neural component to
enhance rule generalizability through semantic text matching. Notably, our
semantic matcher is trained in an unsupervised domain-agnostic way, solely with
synthetic data. Further, these components are loosely coupled, allowing for
rule modifications without retraining the semantic matcher. In our evaluation,
we focused on two few-shot relation classification datasets: Few-Shot TACRED
and a Few-Shot version of NYT29. We show that our proposed method outperforms
previous state-of-the-art models in three out of four settings, despite not
seeing any human-annotated training data. Further, we show that our approach
remains modular and pliable, i.e., the corresponding rules can be locally
modified to improve the overall model. Human interventions to the rules for the
TACRED relation \texttt{org:parents} boost the performance on that relation by
as much as 26\% relative improvement, without negatively impacting the other
relations, and without retraining the semantic matching component.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03306" title="Abstract">arXiv:2403.03306</a> [<a href="/pdf/2403.03306" title="Download PDF">pdf</a>, <a href="/format/2403.03306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wrist-bound Guanxi, Jiazu, and Kuolie: Unpacking Chinese Adolescent  Smartwatch-Mediated Socialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lanjing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conditionally Accepted at CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Adolescent peer relationships, essential for their development, are
increasingly mediated by digital technologies. As this trend continues,
wearable devices, especially smartwatches tailored for adolescents, are
reshaping their socialization. In China, smartwatches like XTC have gained wide
popularity, introducing unique features such as "Bump-to-Connect" and exclusive
social platforms. Nonetheless, how these devices influence adolescents' peer
experience remains unknown. Addressing this, we interviewed 18 Chinese
adolescents (age: 11 -- 16), discovering a smartwatch-mediated social
ecosystem. Our findings highlight the ice-breaking role of smartwatches in
friendship initiation and their use for secret messaging with local peers.
Within the online smartwatch community, peer status is determined by likes and
visibility, leading to diverse pursuit activities (i.e., chu guanxi, jiazu,
kuolie) and negative social dynamics. We discuss the core affordances of
smartwatches and Chinese cultural factors that influence adolescent social
behavior and offer implications for designing future wearables that responsibly
and safely support adolescent socialization.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03307" title="Abstract">arXiv:2403.03307</a> [<a href="/pdf/2403.03307" title="Download PDF">pdf</a>, <a href="/format/2403.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Book2Dial: Generating Teacher-Student Interactions from Textbooks for  Cost-Effective Development of Educational Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Macina%2C+J">Jakub Macina</a>, 
<a href="/search/cs?searchtype=author&query=Daheim%2C+N">Nico Daheim</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+P">Sankalan Pal Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 19 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Educational chatbots are a promising tool for assisting student learning.
However, the development of effective chatbots in education has been
challenging, as high-quality data is seldom available in this domain. In this
paper, we propose a framework for generating synthetic teacher-student
interactions grounded in a set of textbooks. Our approaches capture one aspect
of learning interactions where curious students with partial knowledge
interactively ask a teacher questions about the material in the textbook. We
highlight various quality criteria that such dialogues should fulfill and
compare several approaches relying on either prompting or fine-tuning large
language models. We use synthetic dialogues to train educational chatbots and
show benefits of further fine-tuning in different educational domains. However,
human evaluation shows that our best data synthesis method still suffers from
hallucinations and tends to reiterate information from previous conversations.
Our findings offer insights for future efforts in synthesizing conversational
data that strikes a balance between size and quality. We will open-source our
data and code.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03309" title="Abstract">arXiv:2403.03309</a> [<a href="/pdf/2403.03309" title="Download PDF">pdf</a>, <a href="/ps/2403.03309" title="Download PostScript">ps</a>, <a href="/format/2403.03309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Zero-Shot Material States Segmentation, by Implanting Natural  Image Patterns in Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eppel%2C+S">Sagi Eppel</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jolina Li</a>, 
<a href="/search/cs?searchtype=author&query=Drehwald%2C+M">Manuel Drehwald</a>, 
<a href="/search/cs?searchtype=author&query=Aspuru-Guzik%2C+A">Alan Aspuru-Guzik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual understanding and segmentation of materials and their states is
fundamental for understanding the physical world. The infinite textures, shapes
and often blurry boundaries formed by material make this task particularly hard
to generalize. Whether it's identifying wet regions of a surface, minerals in
rocks, infected regions in plants, or pollution in water, each material state
has its own unique form. For neural nets to learn class-agnostic materials
segmentation it is necessary to first collect and annotate data that capture
this complexity. Collecting real-world images and manually annotating is
limited both by the cost and limited precision of manual labor. In contrast,
synthetic data is highly accurate and almost cost-free but fails to replicate
the vast diversity of the material world. In this work, we suggest a method to
bridge this crucial gap, by implanting patterns extracted from real-world
images, in synthetic data. Hence, patterns automatically collected from natural
images are used to map materials into synthetic scenes. This unsupervised
approach allows the generated data to capture the vast complexity of the real
world while maintaining the precision and scale of synthetic data. We also
present the first general benchmark for class-agnostic material state
segmentation. The benchmark images contain a wide range of real-world images of
material states, from cooking, food, rocks, construction, plants, and liquids
each in various states
(wet/dry/stained/cooked/burned/worned/rusted/sediment/foam...). The annotation
includes both partial similarity between regions with similar but not identical
materials, and hard segmentation of only points of the exact same material
state. We show that net trains on MatSeg significantly outperform existing
state-of-the-art methods on this task.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03312" title="Abstract">arXiv:2403.03312</a> [<a href="/pdf/2403.03312" title="Download PDF">pdf</a>, <a href="/format/2403.03312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Dashboard: Investigating Distracted Driver Communication  Preferences for ADAS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Aamir Hasan</a>, 
<a href="/search/cs?searchtype=author&query=McPherson%2C+D+L">D. Livingston McPherson</a>, 
<a href="/search/cs?searchtype=author&query=Miles%2C+M">Melissa Miles</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures. All materials associated with the study can be found at <a href="https://sites.google.com/illinois.edu/driver-preference-for-modes">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Distracted driving is a major cause of road fatalities. With improvements in
driver (in)attention detection, these distracted situations can be caught early
to alert drivers and improve road safety and comfort. However, drivers may have
differing preferences for the modes of such communication based on the driving
scenario and their current distraction state. To this end, we present a user
study (N=147) where videos of simulated driving scenarios were utilized to
learn drivers preferences for modes of communication and their evolution with
the drivers changing attention. The survey queried participants preferred modes
of communication for scenarios such as collisions or stagnation at a green
light. We validate our hypotheses and provide key results that inform the
future of communication between drivers and their vehicles. We showcase the
different driver preferences based on the nature of the driving scenario and
also show that they evolve as the drivers distraction state changes.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03314" title="Abstract">arXiv:2403.03314</a> [<a href="/pdf/2403.03314" title="Download PDF">pdf</a>, <a href="/format/2403.03314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance Verification of Multiagent Systems with Learned  Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dong%2C+Z">Zihao Dong</a>, 
<a href="/search/eess?searchtype=author&query=Omidshafiei%2C+S">Shayegan Omidshafiei</a>, 
<a href="/search/eess?searchtype=author&query=Everett%2C+M">Michael Everett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">For many multiagent control problems, neural networks (NNs) have enabled
promising new capabilities. However, many of these systems lack formal
guarantees (e.g., collision avoidance, robustness), which prevents leveraging
these advances in safety-critical settings. While there is recent work on
formal verification of NN-controlled systems, most existing techniques cannot
handle scenarios with more than one agent. To address this research gap, this
paper presents a backward reachability-based approach for verifying the
collision avoidance properties of Multi-Agent Neural Feedback Loops (MA-NFLs).
Given the dynamics models and trained control policies of each agent, the
proposed algorithm computes relative backprojection sets by solving a series of
Mixed Integer Linear Programs (MILPs) offline for each pair of agents. Our
pair-wise approach is parallelizable and thus scales well with increasing
number of agents, and we account for state measurement uncertainties, making it
well aligned with real-world scenarios. Using those results, the agents can
quickly check for collision avoidance online by solving low-dimensional Linear
Programs (LPs). We demonstrate the proposed algorithm can verify collision-free
properties of a MA-NFL with agents trained to imitate a collision avoidance
algorithm (Reciprocal Velocity Obstacles). We further demonstrate the
computational scalability of the approach on systems with up to 10 agents.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03320" title="Abstract">arXiv:2403.03320</a> [<a href="/pdf/2403.03320" title="Download PDF">pdf</a>, <a href="/format/2403.03320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linearization-based direct reconstruction for EIT using triangular  Zernike decompositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Autio%2C+A">Antti Autio</a>, 
<a href="/search/math?searchtype=author&query=Garde%2C+H">Henrik Garde</a>, 
<a href="/search/math?searchtype=author&query=Hirvensalo%2C+M">Markus Hirvensalo</a>, 
<a href="/search/math?searchtype=author&query=Hyv%C3%B6nen%2C+N">Nuutti Hyv&#xf6;nen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work implements and numerically tests the direct reconstruction
algorithm introduced in [Garde &amp; Hyv\"onen, SIAM J. Math. Anal., 2024] for
two-dimensional linearized electrical impedance tomography. Although the
algorithm was originally designed for a linearized setting, we numerically
demonstrate its functionality when the input data is the corresponding change
in the current-to-voltage boundary operator. Both idealized continuum model and
practical complete electrode model measurements are considered in the numerical
studies, with the examined domain being either the unit disk or a convex
polygon. Special attention is paid to regularizing the algorithm and its
connections to the singular value decomposition of a truncated linearized
forward map, as well as to the explicit triangular structures originating from
the properties of the employed Zernike polynomial basis for the conductivity.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03322" title="Abstract">arXiv:2403.03322</a> [<a href="/pdf/2403.03322" title="Download PDF">pdf</a>, <a href="/format/2403.03322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Configuration Performance Learning: A Systematic Survey and  Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jingzhi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Performance is arguably the most crucial attribute that reflects the behavior
of a configurable software system. However, given the increasing scale and
complexity of modern software, modeling and predicting how various
configurations can impact performance becomes one of the major challenges in
software maintenance. As such, performance is often modeled without having a
thorough knowledge of the software system, but relying mainly on data, which
fits precisely with the purpose of deep learning.
<br />In this paper, we conduct a comprehensive review exclusively on the topic of
deep learning for performance learning of configurable software, covering 948
searched papers spanning six indexing services, based on which 85 primary
papers were extracted and analyzed. Our results summarize the key topics and
statistics on how the configuration data is prepared; how the deep
configuration performance learning model is built; how the model is evaluated
and how they are exploited in different tasks related to software
configuration. We also identify the good practice and the potentially
problematic phenomena from the studies surveyed, together with insights on
future opportunities for the field. To promote open science, all the raw
results of this survey can be accessed at our repository:
https://github.com/ideas-labo/DCPL-SLR.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03323" title="Abstract">arXiv:2403.03323</a> [<a href="/pdf/2403.03323" title="Download PDF">pdf</a>, <a href="/format/2403.03323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Software Verification of Hyperliveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beutner%2C+R">Raven Beutner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TACAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Hyperproperties relate multiple executions of a program and are commonly used
to specify security and information-flow policies. Most existing work has
focused on the verification of $k$-safety properties, i.e., properties that
state that all $k$-tuples of execution traces satisfy a given property. In this
paper, we study the automated verification of richer properties that combine
universal and existential quantification over executions. Concretely, we
consider $\forall^k\exists^l$ properties, which state that for all $k$
executions, there exist $l$ executions that, together, satisfy a property. This
captures important non-$k$-safety requirements, including hyperliveness
properties such as generalized non-interference, opacity, refinement, and
robustness. We design an automated constraint-based algorithm for the
verification of $\forall^k\exists^l$ properties. Our algorithm leverages a
sound-and-complete program logic and a (parameterized) strongest postcondition
computation. We implement our algorithm in a tool called ForEx and report on
encouraging experimental results.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03328" title="Abstract">arXiv:2403.03328</a> [<a href="/pdf/2403.03328" title="Download PDF">pdf</a>, <a href="/ps/2403.03328" title="Download PostScript">ps</a>, <a href="/format/2403.03328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ensemble Framework for Explainable Geospatial Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingbo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Analyzing spatial varying effect is pivotal in geographic analysis. Yet,
accurately capturing and interpreting this variability is challenging due to
the complexity and non-linearity of geospatial data. Herein, we introduce an
integrated framework that merges local spatial weighting scheme, Explainable
Artificial Intelligence (XAI), and cutting-edge machine learning technologies
to bridge the gap between traditional geographic analysis models and general
machine learning approaches. Through tests on synthetic datasets, this
framework is verified to enhance the interpretability and accuracy of
predictions in both geographic regression and classification by elucidating
spatial variability. It significantly boosts prediction precision, offering a
novel approach to understanding spatial phenomena.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03329" title="Abstract">arXiv:2403.03329</a> [<a href="/pdf/2403.03329" title="Download PDF">pdf</a>, <a href="/format/2403.03329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guardrail Baselines for Unlearning in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thaker%2C+P">Pratiksha Thaker</a>, 
<a href="/search/cs?searchtype=author&query=Maurya%2C+Y">Yash Maurya</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary work, accepted to ICLR workshop SeT-LLM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent work has demonstrated that fine-tuning is a promising approach to
`unlearn' concepts from large language models. However, fine-tuning can be
expensive, as it requires both generating a set of examples and running
iterations of fine-tuning to update the model. In this work, we show that
simple guardrail-based approaches such as prompting and filtering can achieve
unlearning results comparable to fine-tuning. We recommend that researchers
investigate these lightweight baselines when evaluating the performance of more
computationally intensive fine-tuning methods. While we do not claim that
methods such as prompting or filtering are universal solutions to the problem
of unlearning, our work suggests the need for evaluation metrics that can
better separate the power of guardrails vs. fine-tuning, and highlights
scenarios where guardrails themselves may be advantageous for unlearning, such
as in generating examples for fine-tuning or unlearning when only API access is
available.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03333" title="Abstract">arXiv:2403.03333</a> [<a href="/pdf/2403.03333" title="Download PDF">pdf</a>, <a href="/format/2403.03333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution Simplex Clustering for Heterogeneous Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grinwald%2C+D">Dennis Grinwald</a>, 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+P">Philipp Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+S">Shinichi Nakajima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We tackle a major challenge in federated learning (FL) -- achieving good
performance under highly heterogeneous client distributions. The difficulty
partially arises from two seemingly contradictory goals: learning a common
model by aggregating the information from clients, and learning local
personalized models that should be adapted to each local distribution. In this
work, we propose Solution Simplex Clustered Federated Learning (SosicFL) for
dissolving such contradiction. Based on the recent ideas of learning solution
simplices, SosicFL assigns a subregion in a simplex to each client, and
performs FL to learn a common solution simplex. This allows the client models
to possess their characteristics within the degrees of freedom in the solution
simplex, and at the same time achieves the goal of learning a global common
model. Our experiments show that SosicFL improves the performance and
accelerates the training process for global and personalized FL with minimal
computational overhead.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03334" title="Abstract">arXiv:2403.03334</a> [<a href="/pdf/2403.03334" title="Download PDF">pdf</a>, <a href="/format/2403.03334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIVERSE: Deciphering Internet Views on the U.S. Military Through Video  Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruickshank%2C+I+J">Iain J. Cruickshank</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper under review for dataset track of ICWSM 2024. 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Stance detection of social media text is a key component of downstream tasks
involving the identification of groups of users with opposing opinions on
contested topics such as vaccination and within arguments. In particular,
stance provides an indication of an opinion towards an entity. This paper
introduces DIVERSE, a dataset of over 173,000 YouTube video comments annotated
for their stance towards videos of the U.S. military. The stance is annotated
through a human-guided, machine-assisted labeling methodology that makes use of
weak signals of tone within the sentence as supporting indicators, as opposed
to using manual annotations by humans. These weak signals consist of the
presence of hate speech and sarcasm, the presence of specific keywords, the
sentiment of the text, and the stance inference from two Large Language Models.
The weak signals are then consolidated using a data programming model before
each comment is annotated with a final stance label. On average, the videos
have 200 comments each, and the stance of the comments skews slightly towards
the "against" characterization for both the U.S. Army and the videos posted on
the channel.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03336" title="Abstract">arXiv:2403.03336</a> [<a href="/pdf/2403.03336" title="Download PDF">pdf</a>, <a href="/format/2403.03336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scope of Large Language Models for Mining Emerging Opinions in Online  Health Discourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gatto%2C+J">Joseph Gatto</a>, 
<a href="/search/cs?searchtype=author&query=Basak%2C+M">Madhusudan Basak</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+Y">Yash Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Bohlman%2C+P">Philip Bohlman</a>, 
<a href="/search/cs?searchtype=author&query=Preum%2C+S+M">Sarah M. Preum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this paper, we develop an LLM-powered framework for the curation and
evaluation of emerging opinion mining in online health communities. We
formulate emerging opinion mining as a pairwise stance detection problem
between (title, comment) pairs sourced from Reddit, where post titles contain
emerging health-related claims on a topic that is not predefined. The claims
are either explicitly or implicitly expressed by the user. We detail (i) a
method of claim identification -- the task of identifying if a post title
contains a claim and (ii) an opinion mining-driven evaluation framework for
stance detection using LLMs.
<br />We facilitate our exploration by releasing a novel test dataset, Long
COVID-Stance, or LC-stance, which can be used to evaluate LLMs on the tasks of
claim identification and stance detection in online health communities. Long
Covid is an emerging post-COVID disorder with uncertain and complex treatment
guidelines, thus making it a suitable use case for our task. LC-Stance contains
long COVID treatment related discourse sourced from a Reddit community. Our
evaluation shows that GPT-4 significantly outperforms prior works on zero-shot
stance detection. We then perform thorough LLM model diagnostics, identifying
the role of claim type (i.e. implicit vs explicit claims) and comment length as
sources of model error.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03337" title="Abstract">arXiv:2403.03337</a> [<a href="/pdf/2403.03337" title="Download PDF">pdf</a>, <a href="/ps/2403.03337" title="Download PostScript">ps</a>, <a href="/format/2403.03337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Privacy Guarantees for Coverage Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Z">George Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages; abstract shortened to fit requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We introduce a new notion of neighboring databases for coverage problems such
as Max Cover and Set Cover under differential privacy. In contrast to the
standard privacy notion for these problems, which is analogous to node-privacy
in graphs, our new definition gives a more fine-grained privacy guarantee,
which is analogous to edge-privacy. We illustrate several scenarios of Set
Cover and Max Cover where our privacy notion is desired one for the
application.
<br />Our main result is an $\epsilon$-edge differentially private algorithm for
Max Cover which obtains an $(1-1/e-\eta,\tilde{O}(k/\epsilon))$-approximation
with high probability. Furthermore, we show that this result is nearly tight:
we give a lower bound show that an additive error of $\Omega(k/\epsilon)$ is
necessary under edge-differential privacy. Via group privacy properties, this
implies a new algorithm for $\epsilon$-node differentially private Max Cover
which obtains an $(1-1/e-\eta,\tilde{O}(fk/\epsilon))$-approximation, where $f$
is the maximum degree of an element in the set system. When $f\ll k$, this
improves over the best known algorithm for Max Cover under pure (node)
differential privacy, which obtains an
$(1-1/e,\tilde{O}(k^2/\epsilon))$-approximation.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03339" title="Abstract">arXiv:2403.03339</a> [<a href="/pdf/2403.03339" title="Download PDF">pdf</a>, <a href="/format/2403.03339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Online Approach to Solving Public Transit Stationing and Dispatch  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Talusan%2C+J+P">Jose Paolo Talusan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chaeeun Han</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Ayan Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Laszka%2C+A">Aron Laszka</a>, 
<a href="/search/cs?searchtype=author&query=Freudberg%2C+D">Dan Freudberg</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Abhishek Dubey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Public bus transit systems provide critical transportation services for large
sections of modern communities. On-time performance and maintaining the
reliable quality of service is therefore very important. Unfortunately,
disruptions caused by overcrowding, vehicular failures, and road accidents
often lead to service performance degradation. Though transit agencies keep a
limited number of vehicles in reserve and dispatch them to relieve the affected
routes during disruptions, the procedure is often ad-hoc and has to rely on
human experience and intuition to allocate resources (vehicles) to affected
trips under uncertainty. In this paper, we describe a principled approach using
non-myopic sequential decision procedures to solve the problem and decide (a)
if it is advantageous to anticipate problems and proactively station transit
buses near areas with high-likelihood of disruptions and (b) decide if and
which vehicle to dispatch to a particular problem. Our approach was developed
in partnership with the Metropolitan Transportation Authority for a mid-sized
city in the USA and models the system as a semi-Markov decision problem (solved
as a Monte-Carlo tree search procedure) and shows that it is possible to obtain
an answer to these two coupled decision problems in a way that maximizes the
overall reward (number of people served). We sample many possible futures from
generative models, each is assigned to a tree and processed using root
parallelization. We validate our approach using 3 years of data from our
partner agency. Our experiments show that the proposed framework serves 2% more
passengers while reducing deadhead miles by 40%.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03344" title="Abstract">arXiv:2403.03344</a> [<a href="/pdf/2403.03344" title="Download PDF">pdf</a>, <a href="/format/2403.03344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn to Code Sustainably: An Empirical Study on LLM-based Green Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vartziotis%2C+T">Tina Vartziotis</a>, 
<a href="/search/cs?searchtype=author&query=Dellatolas%2C+I">Ippolyti Dellatolas</a>, 
<a href="/search/cs?searchtype=author&query=Dasoulas%2C+G">George Dasoulas</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Maximilian Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+F">Florian Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+T">Tim Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Kotsopoulos%2C+S">Sotirios Kotsopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Keckeisen%2C+M">Michael Keckeisen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The increasing use of information technology has led to a significant share
of energy consumption and carbon emissions from data centers. These
contributions are expected to rise with the growing demand for big data
analytics, increasing digitization, and the development of large artificial
intelligence (AI) models. The need to address the environmental impact of
software development has led to increased interest in green (sustainable)
coding and claims that the use of AI models can lead to energy efficiency
gains. Here, we provide an empirical study on green code and an overview of
green coding practices, as well as metrics used to quantify the sustainability
awareness of AI models. In this framework, we evaluate the sustainability of
auto-generated code. The auto-generate codes considered in this study are
produced by generative commercial AI language models, GitHub Copilot, OpenAI
ChatGPT-3, and Amazon CodeWhisperer. Within our methodology, in order to
quantify the sustainability awareness of these AI models, we propose a
definition of the code's "green capacity", based on certain sustainability
metrics. We compare the performance and green capacity of human-generated code
and code generated by the three AI language models in response to easy-to-hard
problem statements. Our findings shed light on the current capacity of AI
models to contribute to sustainable software development.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03346" title="Abstract">arXiv:2403.03346</a> [<a href="/pdf/2403.03346" title="Download PDF">pdf</a>, <a href="/format/2403.03346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Vision-Language Pre-training with Rich Supervisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kunyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Pengkai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Belval%2C+E">Edouard Belval</a>, 
<a href="/search/cs?searchtype=author&query=Nuriel%2C+O">Oren Nuriel</a>, 
<a href="/search/cs?searchtype=author&query=Appalaraju%2C+S">Srikar Appalaraju</a>, 
<a href="/search/cs?searchtype=author&query=Ghadar%2C+S">Shabnam Ghadar</a>, 
<a href="/search/cs?searchtype=author&query=Mahadevan%2C+V">Vijay Mahadevan</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose Strongly Supervised pre-training with ScreenShots (S4) - a novel
pre-training paradigm for Vision-Language Models using data from large-scale
web screenshot rendering. Using web screenshots unlocks a treasure trove of
visual and textual cues that are not present in using image-text pairs. In S4,
we leverage the inherent tree-structured hierarchy of HTML elements and the
spatial localization to carefully design 10 pre-training tasks with large scale
annotated data. These tasks resemble downstream tasks across different domains
and the annotations are cheap to obtain. We demonstrate that, compared to
current screenshot pre-training objectives, our innovative pre-training method
significantly enhances performance of image-to-text model in nine varied and
popular downstream tasks - up to 76.1% improvements on Table Detection, and at
least 1% on Widget Captioning.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03348" title="Abstract">arXiv:2403.03348</a> [<a href="/pdf/2403.03348" title="Download PDF">pdf</a>, <a href="/format/2403.03348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Maximize Mutual Information for Chain-of-Thought  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hanxian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yanjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jishen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Ke Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge distillation, the technique of transferring knowledge from large,
complex models to smaller ones, marks a pivotal step towards efficient AI
deployment. Distilling Step-by-Step (DSS), a novel method utilizing
chain-of-thought (CoT) distillation, has demonstrated promise by imbuing
smaller models with the superior reasoning capabilities of their larger
counterparts. In DSS, the distilled model acquires the ability to generate
rationales and predict labels concurrently through a multi-task learning
framework. However, DSS overlooks the intrinsic relationship between the two
training tasks, leading to ineffective integration of CoT knowledge with the
task of label prediction. To this end, we investigate the mutual relationship
of the two tasks from Information Bottleneck perspective and formulate it as
maximizing the mutual information of the representation features of the two
tasks. We propose a variational approach to solve this optimization problem
using a learning-based method. Our experimental results across four datasets
demonstrate that our method outperforms the state-of-the-art DSS. Our findings
offer insightful guidance for future research on language model distillation as
well as applications involving CoT. Code and models will be released soon.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03357" title="Abstract">arXiv:2403.03357</a> [<a href="/pdf/2403.03357" title="Download PDF">pdf</a>, <a href="/format/2403.03357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism,  AI, and Health in Africa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asiedu%2C+M">Mercy Asiedu</a>, 
<a href="/search/cs?searchtype=author&query=Dieng%2C+A">Awa Dieng</a>, 
<a href="/search/cs?searchtype=author&query=Haykel%2C+A">Alexander Haykel</a>, 
<a href="/search/cs?searchtype=author&query=Rostamzadeh%2C+N">Negar Rostamzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Pfohl%2C+S">Stephen Pfohl</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+C">Chirag Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=Nagawa%2C+M">Maria Nagawa</a>, 
<a href="/search/cs?searchtype=author&query=Oppong%2C+A">Abigail Oppong</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+K">Katherine Heller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures. arXiv admin note: text overlap with <a href="/abs/2304.02190">arXiv:2304.02190</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">With growing application of machine learning (ML) technologies in healthcare,
there have been calls for developing techniques to understand and mitigate
biases these systems may exhibit. Fair-ness considerations in the development
of ML-based solutions for health have particular implications for Africa, which
already faces inequitable power imbalances between the Global North and
South.This paper seeks to explore fairness for global health, with Africa as a
case study. We conduct a scoping review to propose axes of disparities for
fairness consideration in the African context and delineate where they may come
into play in different ML-enabled medical modalities. We then conduct
qualitative research studies with 672 general population study participants and
28 experts inML, health, and policy focused on Africa to obtain corroborative
evidence on the proposed axes of disparities. Our analysis focuses on
colonialism as the attribute of interest and examines the interplay between
artificial intelligence (AI), health, and colonialism. Among the pre-identified
attributes, we found that colonial history, country of origin, and national
income level were specific axes of disparities that participants believed would
cause an AI system to be biased.However, there was also divergence of opinion
between experts and general population participants. Whereas experts generally
expressed a shared view about the relevance of colonial history for the
development and implementation of AI technologies in Africa, the majority of
the general population participants surveyed did not think there was a direct
link between AI and colonialism. Based on these findings, we provide practical
recommendations for developing fairness-aware ML solutions for health in
Africa.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03359" title="Abstract">arXiv:2403.03359</a> [<a href="/pdf/2403.03359" title="Download PDF">pdf</a>, <a href="/format/2403.03359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RACE-SM: Reinforcement Learning Based Autonomous Control for Social  On-Ramp Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poots%2C+J">Jordan Poots</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous parallel-style on-ramp merging in human controlled traffic
continues to be an existing issue for autonomous vehicle control. Existing
non-learning based solutions for vehicle control rely on rules and optimization
primarily. These methods have been seen to present significant challenges.
Recent advancements in Deep Reinforcement Learning have shown promise and have
received significant academic interest however the available learning based
approaches show inadequate attention to other highway vehicles and often rely
on inaccurate road traffic assumptions. In addition, the parallel-style case is
rarely considered. A novel learning based model for acceleration and lane
change decision making that explicitly considers the utility to both the ego
vehicle and its surrounding vehicles which may be cooperative or uncooperative
to produce behaviour that is socially acceptable is proposed. The novel reward
function makes use of Social Value Orientation to weight the vehicle's level of
social cooperation and is divided into ego vehicle and surrounding vehicle
utility which are weighted according to the model's designated Social Value
Orientation. A two-lane highway with an on-ramp divided into a taper-style and
parallel-style section is considered. Simulation results indicated the
importance of considering surrounding vehicles in reward function design and
show that the proposed model matches or surpasses those in literature in terms
of collisions while also introducing socially courteous behaviour avoiding near
misses and anti-social behaviour through direct consideration of the effect of
merging on surrounding vehicles.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03360" title="Abstract">arXiv:2403.03360</a> [<a href="/pdf/2403.03360" title="Download PDF">pdf</a>, <a href="/format/2403.03360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridge the Future: High-Performance Networks in Confidential VMs without  Trusted I/O devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Shashvat Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Mengjia Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Trusted I/O (TIO) is an appealing solution to improve I/O performance for
confidential VMs (CVMs), with the potential to eliminate broad sources of I/O
overhead. However, this paper emphasizes that not all types of I/O can derive
substantial benefits from TIO, particularly network I/O. Given the obligatory
use of encryption protocols for network traffic in CVM's threat model, TIO's
approach of I/O encryption over the PCIe bus becomes redundant. Furthermore,
TIO solutions need to expand the Trusted Computing Base (TCB) to include TIO
devices and are commercially unavailable.
<br />Motivated by these insights, the goal of this paper is to propose a software
solution that helps CVMs immediately benefit from high-performance networks,
while confining trust only to the on-chip CVM. We present FOLIO, a software
solution crafted from a secure and efficient Data Plane Development Kit (DPDK)
extension compatible with the latest version of AMD Secure Encrypted
Virtualization (SEV), a.k.a., Secure Nested Paging (SNP). Our design is
informed by a thorough analysis of all possible factors that impact SNP VM's
network performance. By extensively removing overhead sources, we arrive at a
design that approaches the efficiency of an optimal TIO-based configuration.
Evaluation shows that FOLIO has a performance dip less than 6% relative to the
optimal TIO configuration, while only relying on off-the-shelf CPUs.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03362" title="Abstract">arXiv:2403.03362</a> [<a href="/pdf/2403.03362" title="Download PDF">pdf</a>, <a href="/format/2403.03362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Level Set Teleportation: An Optimization Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishkin%2C+A">Aaron Mishkin</a>, 
<a href="/search/cs?searchtype=author&query=Bietti%2C+A">Alberto Bietti</a>, 
<a href="/search/cs?searchtype=author&query=Gower%2C+R+M">Robert M. Gower</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-five pages including appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We study level set teleportation, an optimization sub-routine which seeks to
accelerate gradient methods by maximizing the gradient norm on a level-set of
the objective function. Since the descent lemma implies that gradient descent
(GD) decreases the objective proportional to the squared norm of the gradient,
level-set teleportation maximizes this one-step progress guarantee. For convex
functions satisfying Hessian stability, we prove that GD with level-set
teleportation obtains a combined sub-linear/linear convergence rate which is
strictly faster than standard GD when the optimality gap is small. This is in
sharp contrast to the standard (strongly) convex setting, where we show
level-set teleportation neither improves nor worsens convergence rates. To
evaluate teleportation in practice, we develop a projected-gradient-type method
requiring only Hessian-vector products. We use this method to show that
gradient methods with access to a teleportation oracle uniformly out-perform
their standard versions on a variety of learning problems.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03368" title="Abstract">arXiv:2403.03368</a> [<a href="/pdf/2403.03368" title="Download PDF">pdf</a>, <a href="/format/2403.03368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Federated Learning for Automatic Detection of Clopidogrel  Treatment Failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Samuel Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M+S">Min Sang Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The effectiveness of clopidogrel, a widely used antiplatelet medication,
varies significantly among individuals, necessitating the development of
precise predictive models to optimize patient care. In this study, we leverage
federated learning strategies to address clopidogrel treatment failure
detection. Our research harnesses the collaborative power of multiple
healthcare institutions, allowing them to jointly train machine learning models
while safeguarding sensitive patient data. Utilizing the UK Biobank dataset,
which encompasses a vast and diverse population, we partitioned the data based
on geographic centers and evaluated the performance of federated learning. Our
results show that while centralized training achieves higher Area Under the
Curve (AUC) values and faster convergence, federated learning approaches can
substantially narrow this performance gap. Our findings underscore the
potential of federated learning in addressing clopidogrel treatment failure
detection, offering a promising avenue for enhancing patient care through
personalized treatment strategies while respecting data privacy. This study
contributes to the growing body of research on federated learning in healthcare
and lays the groundwork for secure and privacy-preserving predictive models for
various medical conditions.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03370" title="Abstract">arXiv:2403.03370</a> [<a href="/pdf/2403.03370" title="Download PDF">pdf</a>, <a href="/format/2403.03370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> F$^3$Loc: Fusion and Filtering for Floorplan Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+C">Christoph Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figure, accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this paper we propose an efficient data-driven solution to
self-localization within a floorplan. Floorplan data is readily available,
long-term persistent and inherently robust to changes in the visual appearance.
Our method does not require retraining per map and location or demand a large
database of images of the area of interest. We propose a novel probabilistic
model consisting of an observation and a novel temporal filtering module.
Operating internally with an efficient ray-based representation, the
observation module consists of a single and a multiview module to predict
horizontal depth from images and fuses their results to benefit from advantages
offered by either methodology. Our method operates on conventional consumer
hardware and overcomes a common limitation of competing methods that often
demand upright images. Our full system meets real-time requirements, while
outperforming the state-of-the-art by a significant margin.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03372" title="Abstract">arXiv:2403.03372</a> [<a href="/pdf/2403.03372" title="Download PDF">pdf</a>, <a href="/format/2403.03372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TartanAviation: Image, Speech, and ADS-B Trajectory Datasets for  Terminal Airspace Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patrikar%2C+J">Jay Patrikar</a>, 
<a href="/search/cs?searchtype=author&query=Dantas%2C+J">Joao Dantas</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+B">Brady Moon</a>, 
<a href="/search/cs?searchtype=author&query=Hamidi%2C+M">Milad Hamidi</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sourish Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Keetha%2C+N">Nikhil Keetha</a>, 
<a href="/search/cs?searchtype=author&query=Higgins%2C+I">Ian Higgins</a>, 
<a href="/search/cs?searchtype=author&query=Chandak%2C+A">Atharva Chandak</a>, 
<a href="/search/cs?searchtype=author&query=Yoneyama%2C+T">Takashi Yoneyama</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce TartanAviation, an open-source multi-modal dataset focused on
terminal-area airspace operations. TartanAviation provides a holistic view of
the airport environment by concurrently collecting image, speech, and ADS-B
trajectory data using setups installed inside airport boundaries. The datasets
were collected at both towered and non-towered airfields across multiple months
to capture diversity in aircraft operations, seasons, aircraft types, and
weather conditions. In total, TartanAviation provides 3.1M images, 3374 hours
of Air Traffic Control speech data, and 661 days of ADS-B trajectory data. The
data was filtered, processed, and validated to create a curated dataset. In
addition to the dataset, we also open-source the code-base used to collect and
pre-process the dataset, further enhancing accessibility and usability. We
believe this dataset has many potential use cases and would be particularly
vital in allowing AI and machine learning technologies to be integrated into
air traffic control systems and advance the adoption of autonomous aircraft in
the airspace.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03375" title="Abstract">arXiv:2403.03375</a> [<a href="/pdf/2403.03375" title="Download PDF">pdf</a>, <a href="/format/2403.03375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity Matters: Dynamics of Feature Learning in the Presence of  Spurious Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">GuanWen Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+D">Da Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Surbhi Goel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code for the project is available at <a href="https://github.com/NayutaQiu/Boolean_Spurious">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Existing research often posits spurious features as "easier" to learn than
core features in neural network optimization, but the impact of their relative
simplicity remains under-explored. Moreover they mainly focus on the end
performance intead of the learning dynamics of feature learning. In this paper,
we propose a theoretical framework and associated synthetic dataset grounded in
boolean function analysis which allows for fine-grained control on the relative
complexity (compared to core features) and correlation strength (with respect
to the label) of spurious features to study the dynamics of feature learning
under spurious correlation. Our setup uncovers several interesting phenomenon:
(1) stronger spurious correlations or simpler spurious features slow down the
rate of learning for the core features, (2) learning phases of spurious
features and core features are not always separable, (3) spurious features are
not forgotten even after core features are fully learned. We show that our
findings justify the success of retraining the last layer to remove spurious
correlation and also identifies limitations of popular debiasing algorithms
that exploit early learning of spurious features. We support our empirical
findings with theoretical analyses for the case of learning XOR features with a
one-hidden-layer ReLU network.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03376" title="Abstract">arXiv:2403.03376</a> [<a href="/pdf/2403.03376" title="Download PDF">pdf</a>, <a href="/format/2403.03376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Network Tomography for Dynamic Spectrum Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madnaik%2C+A">Aadesh Madnaik</a>, 
<a href="/search/cs?searchtype=author&query=Matson%2C+N+C">N. Cameron Matson</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+K">Karthikeyan Sundaresan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE INFOCOM 2024. 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Mobile networks have increased spectral efficiency through advanced
multiplexing strategies that are coordinated by base stations (BS) in licensed
spectrum. However, external interference on clients leads to significant
performance degradation during dynamic (unlicensed) spectrum access (DSA). We
introduce the notion of network tomography for DSA, whereby clients are
transformed into spectrum sensors, whose joint access statistics are measured
and used to account for interfering sources. Albeit promising, performing such
tomography naively incurs an impractical overhead that scales exponentially
with the multiplexing order of the strategies deployed -- which will only
continue to grow with 5G/6G technologies.
<br />To this end, we propose a novel, scalable network tomography framework called
NeTo-X that estimates joint client access statistics with just linear overhead,
and forms a blue-print of the interference, thus enabling efficient DSA for
future networks. NeTo-X's design incorporates intelligent algorithms that
leverage multi-channel diversity and the spatial locality of interference
impact on clients to accurately estimate the desired interference statistics
from just pair-wise measurements of its clients. The merits of its framework
are showcased in the context of resource management and jammer localization
applications, where its performance significantly outperforms baseline
approaches and closely approximates optimal performance at a scalable overhead.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03377" title="Abstract">arXiv:2403.03377</a> [<a href="/pdf/2403.03377" title="Download PDF">pdf</a>, <a href="/format/2403.03377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Junctiond: Extending FaaS Runtimes with Kernel-Bypass
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saurez%2C+E">Enrique Saurez</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+J">Joshua Fried</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhry%2C+G+I">Gohar Irfan Chaudhry</a>, 
<a href="/search/cs?searchtype=author&query=Choukse%2C+E">Esha Choukse</a>, 
<a href="/search/cs?searchtype=author&query=Goiri%2C+%C3%8D">&#xcd;&#xf1;igo Goiri</a>, 
<a href="/search/cs?searchtype=author&query=Elnikety%2C+S">Sameh Elnikety</a>, 
<a href="/search/cs?searchtype=author&query=Belay%2C+A">Adam Belay</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+R">Rodrigo Fonseca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This report explores the use of kernel-bypass networking in FaaS runtimes and
demonstrates how using Junction, a novel kernel-bypass system, as the backend
for executing components in faasd can enhance performance and isolation.
Junction achieves this by reducing network and compute overheads and minimizing
interactions with the host operating system. Junctiond, the integration of
Junction with faasd, reduces median and P99 latency by 37.33% and 63.42%,
respectively, and can handle 5 times more throughput while decreasing latency
by 2x at the median and 3.5 times at the tail.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03380" title="Abstract">arXiv:2403.03380</a> [<a href="/pdf/2403.03380" title="Download PDF">pdf</a>, <a href="/ps/2403.03380" title="Download PostScript">ps</a>, <a href="/format/2403.03380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Monotonicity of Information Aging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shisher%2C+M+K+C">MD Kamran Chowdhury Shisher</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of this work has been accepted by IEEE INFOCOM ASoI Workshop, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we analyze the monotonicity of information aging in a remote
estimation system, where historical observations of a Gaussian autoregressive
AR(p) process are used to predict its future values. We consider two widely
used loss functions in estimation: (i) logarithmic loss function for maximum
likelihood estimation and (ii) quadratic loss function for MMSE estimation. The
estimation error of the AR(p) process is written as a generalized conditional
entropy which has closed-form expressions. By using a new information-theoretic
tool called $\epsilon$-Markov chain, we can evaluate the divergence of the
AR(p) process from being a Markov chain. When the divergence $\epsilon$ is
large, the estimation error of the AR(p) process can be far from a
non-decreasing function of the Age of Information (AoI). Conversely, for small
divergence $\epsilon$, the inference error is close to a non-decreasing AoI
function. Each observation is a short sequence taken from the AR(p) process. As
the observation sequence length increases, the parameter $\epsilon$
progressively reduces to zero, and hence the estimation error becomes a
non-decreasing AoI function. These results underscore a connection between the
monotonicity of information aging and the divergence of from being a Markov
chain.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03382" title="Abstract">arXiv:2403.03382</a> [<a href="/pdf/2403.03382" title="Download PDF">pdf</a>, <a href="/format/2403.03382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Discovering and Merging for Incremental Novel Class Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Peixi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangru Huang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+M">Mengyue Geng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. arXiv admin note: text overlap with <a href="/abs/2207.08605">arXiv:2207.08605</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">One important desideratum of lifelong learning aims to discover novel classes
from unlabelled data in a continuous manner. The central challenge is twofold:
discovering and learning novel classes while mitigating the issue of
catastrophic forgetting of established knowledge. To this end, we introduce a
new paradigm called Adaptive Discovering and Merging (ADM) to discover novel
categories adaptively in the incremental stage and integrate novel knowledge
into the model without affecting the original knowledge. To discover novel
classes adaptively, we decouple representation learning and novel class
discovery, and use Triple Comparison (TC) and Probability Regularization (PR)
to constrain the probability discrepancy and diversity for adaptive category
assignment. To merge the learned novel knowledge adaptively, we propose a
hybrid structure with base and novel branches named Adaptive Model Merging
(AMM), which reduces the interference of the novel branch on the old classes to
preserve the previous knowledge, and merges the novel branch to the base model
without performance loss and parameter growth. Extensive experiments on several
datasets show that ADM significantly outperforms existing class-incremental
Novel Class Discovery (class-iNCD) approaches. Moreover, our AMM also benefits
the class-incremental Learning (class-IL) task by alleviating the catastrophic
forgetting problem.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03390" title="Abstract">arXiv:2403.03390</a> [<a href="/pdf/2403.03390" title="Download PDF">pdf</a>, <a href="/format/2403.03390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Evaluation of Semi-supervised Learning Frameworks for  Multi-Class Weed Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiajia Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunyuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Effective weed control plays a crucial role in optimizing crop yield and
enhancing agricultural product quality. However, the reliance on herbicide
application not only poses a critical threat to the environment but also
promotes the emergence of resistant weeds. Fortunately, recent advances in
precision weed management enabled by ML and DL provide a sustainable
alternative. Despite great progress, existing algorithms are mainly developed
based on supervised learning approaches, which typically demand large-scale
datasets with manual-labeled annotations, which is time-consuming and
labor-intensive. As such, label-efficient learning methods, especially
semi-supervised learning, have gained increased attention in the broader domain
of computer vision and have demonstrated promising performance. These methods
aim to utilize a small number of labeled data samples along with a great number
of unlabeled samples to develop high-performing models comparable to the
supervised learning counterpart trained on a large amount of labeled data
samples. In this study, we assess the effectiveness of a semi-supervised
learning framework for multi-class weed detection, employing two well-known
object detection frameworks, namely FCOS and Faster-RCNN. Specifically, we
evaluate a generalized student-teacher framework with an improved pseudo-label
generation module to produce reliable pseudo-labels for the unlabeled data. To
enhance generalization, an ensemble student network is employed to facilitate
the training process. Experimental results show that the proposed approach is
able to achieve approximately 76\% and 96\% detection accuracy as the
supervised methods with only 10\% of labeled data in CottenWeedDet3 and
CottonWeedDet12, respectively. We offer access to the source code, contributing
a valuable resource for ongoing semi-supervised learning research in weed
detection and beyond.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03394" title="Abstract">arXiv:2403.03394</a> [<a href="/pdf/2403.03394" title="Download PDF">pdf</a>, <a href="/format/2403.03394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Update Particle Filter: Position Estimation by Combining GNSS  Pseudorange and Carrier Phase Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents an efficient method for updating particles in a particle
filter (PF) to address the position estimation problem when dealing with
sharp-peaked likelihood functions derived from multiple observations.
Sharp-peaked likelihood functions commonly arise from millimeter-accurate
distance observations of carrier phases in the global navigation satellite
system (GNSS). However, when such likelihood functions are used for particle
weight updates, the absence of particles within the peaks leads to all particle
weights becoming zero. To overcome this problem, in this study, a
straightforward and effective approach is introduced for updating particles
when dealing with sharp-peaked likelihood functions obtained from multiple
observations. The proposed method, termed as the multiple update PF, leverages
prior knowledge regarding the spread of distribution for each likelihood
function and conducts weight updates and resampling iteratively in the particle
update process, prioritizing the likelihood function spreads. Experimental
results demonstrate the efficacy of our proposed method, particularly when
applied to position estimation utilizing GNSS pseudorange and carrier phase
observations. The multiple update PF exhibits faster convergence with fewer
particles when compared to the conventional PF. Moreover, vehicle position
estimation experiments conducted in urban environments reveal that the proposed
method outperforms conventional GNSS positioning techniques, yielding more
accurate position estimates.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03395" title="Abstract">arXiv:2403.03395</a> [<a href="/pdf/2403.03395" title="Download PDF">pdf</a>, <a href="/format/2403.03395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Melody Generation System for Enhancing the Creativity of  Musicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirawata%2C+S">So Hirawata</a>, 
<a href="/search/cs?searchtype=author&query=Otani%2C+N">Noriko Otani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This study proposes a system designed to enumerate the process of
collaborative composition among humans, using automatic music composition
technology. By integrating multiple Recurrent Neural Network (RNN) models, the
system provides an experience akin to collaborating with several composers,
thereby fostering diverse creativity. Through dynamic adaptation to the user's
creative intentions, based on feedback, the system enhances its capability to
generate melodies that align with user preferences and creative needs. The
system's effectiveness was evaluated through experiments with composers of
varying backgrounds, revealing its potential to facilitate musical creativity
and suggesting avenues for further refinement. The study underscores the
importance of interaction between the composer and AI, aiming to make music
composition more accessible and personalized. This system represents a step
towards integrating AI into the creative process, offering a new tool for
composition support and collaborative artistic exploration.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03396" title="Abstract">arXiv:2403.03396</a> [<a href="/pdf/2403.03396" title="Download PDF">pdf</a>, <a href="/format/2403.03396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Japanese-English Sentence Translation Exercises Dataset for Automatic  Grading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miura%2C+N">Naoki Miura</a>, 
<a href="/search/cs?searchtype=author&query=Funayama%2C+H">Hiroaki Funayama</a>, 
<a href="/search/cs?searchtype=author&query=Kikuchi%2C+S">Seiya Kikuchi</a>, 
<a href="/search/cs?searchtype=author&query=Matsubayashi%2C+Y">Yuichiroh Matsubayashi</a>, 
<a href="/search/cs?searchtype=author&query=Iwase%2C+Y">Yuya Iwase</a>, 
<a href="/search/cs?searchtype=author&query=Inui%2C+K">Kentaro Inui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper proposes the task of automatic assessment of Sentence Translation
Exercises (STEs), that have been used in the early stage of L2 language
learning. We formalize the task as grading student responses for each rubric
criterion pre-specified by the educators. We then create a dataset for STE
between Japanese and English including 21 questions, along with a total of 3,
498 student responses (167 on average). The answer responses were collected
from students and crowd workers. Using this dataset, we demonstrate the
performance of baselines including finetuned BERT and GPT models with few-shot
in-context learning. Experimental results show that the baseline model with
finetuned BERT was able to classify correct responses with approximately 90% in
F1, but only less than 80% for incorrect responses. Furthermore, the GPT models
with few-shot learning show poorer results than finetuned BERT, indicating that
our newly proposed task presents a challenging issue, even for the
stateof-the-art large language models.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03397" title="Abstract">arXiv:2403.03397</a> [<a href="/pdf/2403.03397" title="Download PDF">pdf</a>, <a href="/format/2403.03397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Genetic Programming Trees using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maddigan%2C+P">Paula Maddigan</a>, 
<a href="/search/cs?searchtype=author&query=Lensen%2C+A">Andrew Lensen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bing Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Genetic programming (GP) has the potential to generate explainable results,
especially when used for dimensionality reduction. In this research, we
investigate the potential of leveraging eXplainable AI (XAI) and large language
models (LLMs) like ChatGPT to improve the interpretability of GP-based
non-linear dimensionality reduction. Our study introduces a novel XAI dashboard
named GP4NLDR, the first approach to combine state-of-the-art GP with an
LLM-powered chatbot to provide comprehensive, user-centred explanations. We
showcase the system's ability to provide intuitive and insightful narratives on
high-dimensional data reduction processes through case studies. Our study
highlights the importance of prompt engineering in eliciting accurate and
pertinent responses from LLMs. We also address important considerations around
data privacy, hallucinatory outputs, and the rapid advancements in generative
AI. Our findings demonstrate its potential in advancing the explainability of
GP algorithms. This opens the door for future research into explaining GP
models with LLMs.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03400" title="Abstract">arXiv:2403.03400</a> [<a href="/pdf/2403.03400" title="Download PDF">pdf</a>, <a href="/format/2403.03400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning of Person-independent Representations for Facial  Action Unit Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in Transaction on Image Processing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial action unit (AU) detection, aiming to classify AU present in the
facial image, has long suffered from insufficient AU annotations. In this
paper, we aim to mitigate this data scarcity issue by learning AU
representations from a large number of unlabelled facial videos in a
contrastive learning paradigm. We formulate the self-supervised AU
representation learning signals in two-fold: (1) AU representation should be
frame-wisely discriminative within a short video clip; (2) Facial frames
sampled from different identities but show analogous facial AUs should have
consistent AU representations. As to achieve these goals, we propose to
contrastively learn the AU representation within a video clip and devise a
cross-identity reconstruction mechanism to learn the person-independent
representations. Specially, we adopt a margin-based temporal contrastive
learning paradigm to perceive the temporal AU coherence and evolution
characteristics within a clip that consists of consecutive input facial frames.
Moreover, the cross-identity reconstruction mechanism facilitates pushing the
faces from different identities but show analogous AUs close in the latent
embedding space. Experimental results on three public AU datasets demonstrate
that the learned AU representation is discriminative for AU detection. Our
method outperforms other contrastive learning methods and significantly closes
the performance gap between the self-supervised and supervised AU detection
approaches.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03401" title="Abstract">arXiv:2403.03401</a> [<a href="/pdf/2403.03401" title="Download PDF">pdf</a>, <a href="/format/2403.03401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAIT: Benchmarking (Embedding) Architectures for Interactive  Theorem-Proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamont%2C+S">Sean Lamont</a>, 
<a href="/search/cs?searchtype=author&query=Norrish%2C+M">Michael Norrish</a>, 
<a href="/search/cs?searchtype=author&query=Dezfouli%2C+A">Amir Dezfouli</a>, 
<a href="/search/cs?searchtype=author&query=Walder%2C+C">Christian Walder</a>, 
<a href="/search/cs?searchtype=author&query=Montague%2C+P">Paul Montague</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Artificial Intelligence for Theorem Proving has given rise to a plethora of
benchmarks and methodologies, particularly in Interactive Theorem Proving
(ITP). Research in the area is fragmented, with a diverse set of approaches
being spread across several ITP systems. This presents a significant challenge
to the comparison of methods, which are often complex and difficult to
replicate. Addressing this, we present BAIT, a framework for fair and
streamlined comparison of learning approaches in ITP. We demonstrate BAIT's
capabilities with an in-depth comparison, across several ITP benchmarks, of
state-of-the-art architectures applied to the problem of formula embedding. We
find that Structure Aware Transformers perform particularly well, improving on
techniques associated with the original problem sets. BAIT also allows us to
assess the end-to-end proving performance of systems built on interactive
environments. This unified perspective reveals a novel end-to-end system that
improves on prior work. We also provide a qualitative analysis, illustrating
that improved performance is associated with more semantically-aware
embeddings. By streamlining the implementation and comparison of Machine
Learning algorithms in the ITP context, we anticipate BAIT will be a
springboard for future research.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03405" title="Abstract">arXiv:2403.03405</a> [<a href="/pdf/2403.03405" title="Download PDF">pdf</a>, <a href="/format/2403.03405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality-based Cross-Modal Representation Learning for  Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liuyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongtao He</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+R">Ronghao Dang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengju Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-and-Language Navigation (VLN) has gained significant research interest
in recent years due to its potential applications in real-world scenarios.
However, existing VLN methods struggle with the issue of spurious associations,
resulting in poor generalization with a significant performance gap between
seen and unseen environments. In this paper, we tackle this challenge by
proposing a unified framework CausalVLN based on the causal learning paradigm
to train a robust navigator capable of learning unbiased feature
representations. Specifically, we establish reasonable assumptions about
confounders for vision and language in VLN using the structured causal model
(SCM). Building upon this, we propose an iterative backdoor-based
representation learning (IBRL) method that allows for the adaptive and
effective intervention on confounders. Furthermore, we introduce the visual and
linguistic backdoor causal encoders to enable unbiased feature expression for
multi-modalities during training and validation, enhancing the agent's
capability to generalize across different environments. Experiments on three
VLN datasets (R2R, RxR, and REVERIE) showcase the superiority of our proposed
method over previous state-of-the-art approaches. Moreover, detailed
visualization analysis demonstrates the effectiveness of CausalVLN in
significantly narrowing down the performance gap between seen and unseen
environments, underscoring its strong generalization capability.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03406" title="Abstract">arXiv:2403.03406</a> [<a href="/pdf/2403.03406" title="Download PDF">pdf</a>, <a href="/ps/2403.03406" title="Download PostScript">ps</a>, <a href="/format/2403.03406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An EnKF-LSTM Assimilation Algorithm for Crop Growth Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Ling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinshan Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate and timely prediction of crop growth is of great significance to
ensure crop yields and researchers have developed several crop models for the
prediction of crop growth. However, there are large difference between the
simulation results obtained by the crop models and the actual results, thus in
this paper, we proposed to combine the simulation results with the collected
crop data for data assimilation so that the accuracy of prediction will be
improved. In this paper, an EnKF-LSTM data assimilation method for various
crops is proposed by combining ensemble Kalman filter and LSTM neural network,
which effectively avoids the overfitting problem of existing data assimilation
methods and eliminates the uncertainty of the measured data. The verification
of the proposed EnKF-LSTM method and the comparison of the proposed method with
other data assimilation methods were performed using datasets collected by
sensor equipment deployed on a farm.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03407" title="Abstract">arXiv:2403.03407</a> [<a href="/pdf/2403.03407" title="Download PDF">pdf</a>, <a href="/format/2403.03407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human vs. Machine: Language Models and Wargames
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamparth%2C+M">Max Lamparth</a>, 
<a href="/search/cs?searchtype=author&query=Corso%2C+A">Anthony Corso</a>, 
<a href="/search/cs?searchtype=author&query=Ganz%2C+J">Jacob Ganz</a>, 
<a href="/search/cs?searchtype=author&query=Mastro%2C+O+S">Oriana Skylar Mastro</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jacquelyn Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Trinkunas%2C+H">Harold Trinkunas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Wargames have a long history in the development of military strategy and the
response of nations to threats or attacks. The advent of artificial
intelligence (AI) promises better decision-making and increased military
effectiveness. However, there is still debate about how AI systems, especially
large language models (LLMs), behave as compared to humans. To this end, we use
a wargame experiment with 107 national security expert human players designed
to look at crisis escalation in a fictional US-China scenario and compare human
players to LLM-simulated responses. We find considerable agreement in the LLM
and human responses but also significant quantitative and qualitative
differences between simulated and human players in the wargame, motivating
caution to policymakers before handing over autonomy or following AI-based
strategy recommendations.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03408" title="Abstract">arXiv:2403.03408</a> [<a href="/pdf/2403.03408" title="Download PDF">pdf</a>, <a href="/format/2403.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene Depth Estimation from Traditional Oriental Landscape Paintings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">YeongHyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunkyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Juneho Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene depth estimation from paintings can streamline the process of 3D
sculpture creation so that visually impaired people appreciate the paintings
with tactile sense. However, measuring depth of oriental landscape painting
images is extremely challenging due to its unique method of depicting depth and
poor preservation. To address the problem of scene depth estimation from
oriental landscape painting images, we propose a novel framework that consists
of two-step Image-to-Image translation method with CLIP-based image matching at
the front end to predict the real scene image that best matches with the given
oriental landscape painting image. Then, we employ a pre-trained SOTA depth
estimation model for the generated real scene image. In the first step,
CycleGAN converts an oriental landscape painting image into a pseudo-real scene
image. We utilize CLIP to semantically match landscape photo images with an
oriental landscape painting image for training CycleGAN in an unsupervised
manner. Then, the pseudo-real scene image and oriental landscape painting image
are fed into DiffuseIT to predict a final real scene image in the second step.
Finally, we measure depth of the generated real scene image using a pre-trained
depth estimation model such as MiDaS. Experimental results show that our
approach performs well enough to predict real scene images corresponding to
oriental landscape painting images. To the best of our knowledge, this is the
first study to measure the depth of oriental landscape painting images. Our
research potentially assists visually impaired people in experiencing paintings
in diverse ways. We will release our code and resulting dataset.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03409" title="Abstract">arXiv:2403.03409</a> [<a href="/pdf/2403.03409" title="Download PDF">pdf</a>, <a href="/format/2403.03409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales  for Pruning Recurrent SNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+B">Biswadeep Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Beomseok Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+H">Harshit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+S">Saibal Mukhopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recurrent Spiking Neural Networks (RSNNs) have emerged as a computationally
efficient and brain-inspired learning model. The design of sparse RSNNs with
fewer neurons and synapses helps reduce the computational complexity of RSNNs.
Traditionally, sparse SNNs are obtained by first training a dense and complex
SNN for a target task, and, then, pruning neurons with low activity
(activity-based pruning) while maintaining task performance. In contrast, this
paper presents a task-agnostic methodology for designing sparse RSNNs by
pruning a large randomly initialized model. We introduce a novel Lyapunov Noise
Pruning (LNP) algorithm that uses graph sparsification methods and utilizes
Lyapunov exponents to design a stable sparse RSNN from a randomly initialized
RSNN. We show that the LNP can leverage diversity in neuronal timescales to
design a sparse Heterogeneous RSNN (HRSNN). Further, we show that the same
sparse HRSNN model can be trained for different tasks, such as image
classification and temporal prediction. We experimentally show that, in spite
of being task-agnostic, LNP increases computational efficiency (fewer neurons
and synapses) and prediction performance of RSNNs compared to traditional
activity-based pruning of trained dense models.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03410" title="Abstract">arXiv:2403.03410</a> [<a href="/pdf/2403.03410" title="Download PDF">pdf</a>, <a href="/ps/2403.03410" title="Download PostScript">ps</a>, <a href="/format/2403.03410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction Of Cryptocurrency Prices Using LSTM, SVM And Polynomial  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giffary%2C+N+F+A">Novan Fauzi Al Giffary</a>, 
<a href="/search/cs?searchtype=author&query=Sulianta%2C+F">Feri Sulianta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Asian Journal of Engineering, Social and Health Volume 3, No. 2 February 2024 (308-319)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">The rapid development of information technology, especially the Internet, has
facilitated users with a quick and easy way to seek information. With these
convenience offered by internet services, many individuals who initially
invested in gold and precious metals are now shifting into digital investments
in form of cryptocurrencies. However, investments in crypto coins are filled
with uncertainties and fluctuation in daily basis. This risk posed as
significant challenges for coin investors that could result in substantial
investment losses. The uncertainty of the value of these crypto coins is a
critical issue in the field of coin investment. Forecasting, is one of the
methods used to predict the future value of these crypto coins. By utilizing
the models of Long Short Term Memory, Support Vector Machine, and Polynomial
Regression algorithm for forecasting, a performance comparison is conducted to
determine which algorithm model is most suitable for predicting crypto currency
prices. The mean square error is employed as a benchmark for the comparison. By
applying those three constructed algorithm models, the Support Vector Machine
uses a linear kernel to produce the smallest mean square error compared to the
Long Short Term Memory and Polynomial Regression algorithm models, with a mean
square error value of 0.02. Keywords: Cryptocurrency, Forecasting, Long Short
Term Memory, Mean Square Error, Polynomial Regression, Support Vector Machine
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03411" title="Abstract">arXiv:2403.03411</a> [<a href="/pdf/2403.03411" title="Download PDF">pdf</a>, <a href="/format/2403.03411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossNet: Leveraging Global, Cross-Band, Narrow-Band, and Positional  Encoding for Single- and Multi-Channel Speaker Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalkhorani%2C+V+A">Vahid Ahmadi Kalkhorani</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">DeLiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce CrossNet, a complex spectral mapping approach to speaker
separation and enhancement in reverberant and noisy conditions. The proposed
architecture comprises an encoder layer, a global multi-head self-attention
module, a cross-band module, a narrow-band module, and an output layer.
CrossNet captures global, cross-band, and narrow-band correlations in the
time-frequency domain. To address performance degradation in long utterances,
we introduce a random chunk positional encoding. Experimental results on
multiple datasets demonstrate the effectiveness and robustness of CrossNet,
achieving state-of-the-art performance in tasks including reverberant and
noisy-reverberant speaker separation. Furthermore, CrossNet exhibits faster and
more stable training in comparison to recent baselines. Additionally,
CrossNet's high performance extends to multi-microphone conditions,
demonstrating its versatility in various acoustic scenarios.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03412" title="Abstract">arXiv:2403.03412</a> [<a href="/pdf/2403.03412" title="Download PDF">pdf</a>, <a href="/format/2403.03412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Out-of-Distribution Detection through Data Purification and  Dynamic Activation Function Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yingrui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhigang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiansheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yunlong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingbo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the dynamic realms of machine learning and deep learning, the robustness
and reliability of models are paramount, especially in critical real-world
applications. A fundamental challenge in this sphere is managing
Out-of-Distribution (OOD) samples, significantly increasing the risks of model
misclassification and uncertainty. Our work addresses this challenge by
enhancing the detection and management of OOD samples in neural networks. We
introduce OOD-R (Out-of-Distribution-Rectified), a meticulously curated
collection of open-source datasets with enhanced noise reduction properties.
In-Distribution (ID) noise in existing OOD datasets can lead to inaccurate
evaluation of detection algorithms. Recognizing this, OOD-R incorporates noise
filtering technologies to refine the datasets, ensuring a more accurate and
reliable evaluation of OOD detection algorithms. This approach not only
improves the overall quality of data but also aids in better distinguishing
between OOD and ID samples, resulting in up to a 2.5\% improvement in model
accuracy and a minimum 3.2\% reduction in false positives. Furthermore, we
present ActFun, an innovative method that fine-tunes the model's response to
diverse inputs, thereby improving the stability of feature extraction and
minimizing specificity issues. ActFun addresses the common problem of model
overconfidence in OOD detection by strategically reducing the influence of
hidden units, which enhances the model's capability to estimate OOD uncertainty
more accurately. Implementing ActFun in the OOD-R dataset has led to
significant performance enhancements, including an 18.42\% increase in AUROC of
the GradNorm method and a 16.93\% decrease in FPR95 of the Energy method.
Overall, our research not only advances the methodologies in OOD detection but
also emphasizes the importance of dataset integrity for accurate algorithm
evaluation.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03414" title="Abstract">arXiv:2403.03414</a> [<a href="/pdf/2403.03414" title="Download PDF">pdf</a>, <a href="/format/2403.03414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging The Finite States of Emotion Processing to Study Late-Life  Mental Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuanzhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Faruque%2C+S">Saurab Faruque</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mizuno%2C+A">Akiko Mizuno</a>, 
<a href="/search/cs?searchtype=author&query=Diniz%2C+E">Eduardo Diniz</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaolin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Stetten%2C+G+D">George Dewitt Stetten</a>, 
<a href="/search/cs?searchtype=author&query=Schweitzer%2C+N">Noah Schweitzer</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hecheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linghai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aizenstein%2C+H+J">Howard J. Aizenstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Traditional approaches in mental health research apply General Linear Models
(GLM) to describe the longitudinal dynamics of observed psycho-behavioral
measurements (questionnaire summary scores). Similarly, GLMs are also applied
to characterize relationships between neurobiological measurements (regional
fMRI signals) and perceptual stimuli or other regional signals. While these
methods are useful for exploring linear correlations among the isolated signals
of those constructs (i.e., summary scores or fMRI signals), these classical
frameworks fall short in providing insights into the comprehensive system-level
dynamics underlying observable changes. Hidden Markov Models (HMM) are a
statistical model that enable us to describe the sequential relations among
multiple observable constructs, and when applied through the lens of Finite
State Automata (FSA), can provide a more integrated and intuitive framework for
modeling and understanding the underlying controller (the prescription for how
to respond to inputs) that fundamentally defines any system, as opposed to
linearly correlating output signals produced by the controller. We present a
simple and intuitive HMM processing pipeline vcHMM (See Preliminary Data) that
highlights FSA theory and is applicable for both behavioral analysis of
questionnaire data and fMRI data. HMMs offer theoretic promise as they are
computationally equivalent to the FSA, the control processor of a Turing
Machine (TM) The dynamic programming Viterbi algorithm is used to leverage the
HMM model. It efficiently identifies the most likely sequence of hidden states.
The vcHMM pipeline leverages this grammar to understand how behavior and neural
activity relate to depression.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03416" title="Abstract">arXiv:2403.03416</a> [<a href="/pdf/2403.03416" title="Download PDF">pdf</a>, <a href="/format/2403.03416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On discrete-time polynomial dynamical systems on hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+S">Shaoxuan Cui</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jardon-Kojakhmetov%2C+H">Hildeberto Jardon-Kojakhmetov</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2401.03652">arXiv:2401.03652</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the stability of discrete-time polynomial dynamical
systems on hypergraphs by utilizing the Perron-Frobenius theorem for
nonnegative tensors with respect to the tensors' Z-eigenvalues and
Z-eigenvectors. First of all, for a multilinear polynomial system on a uniform
hypergraph, we study the stability of the origin of the corresponding systems.
Afterward, we extend our results to non-homogeneous polynomial systems on
non-uniform hypergraphs. We confirm that the local stability of any
discrete-time polynomial system is in general dominated by pairwise terms. In
particular, given the origin is locally stable, we construct a conservative
(but explicit) region of attraction from the system parameters. Finally, we
validate our results via some numerical examples.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03418" title="Abstract">arXiv:2403.03418</a> [<a href="/pdf/2403.03418" title="Download PDF">pdf</a>, <a href="/format/2403.03418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An arbitrarily high order unfitted finite element method for elliptic  interface problems with automatic mesh generation, Part II. Piecewise-smooth  interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zhiming Chen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the reliable implementation of an adaptive high-order unfitted
finite element method on Cartesian meshes for solving elliptic interface
problems with geometrically curved singularities. We extend our previous work
on the reliable cell merging algorithm for smooth interfaces to automatically
generate the induced mesh for piecewise smooth interfaces. An $hp$ a posteriori
error estimate is derived for a new unfitted finite element method whose finite
element functions are conforming in each subdomain. Numerical examples
illustrate the competitive performance of the method.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03419" title="Abstract">arXiv:2403.03419</a> [<a href="/pdf/2403.03419" title="Download PDF">pdf</a>, <a href="/format/2403.03419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negating Negatives: Alignment without Human Positive Samples via  Distributional Dispreference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shitong Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have revolutionized the role of AI, yet also
pose potential risks of propagating unethical content. Alignment technologies
have been introduced to steer LLMs towards human preference, gaining increasing
attention. Despite notable breakthroughs in this direction, existing methods
heavily rely on high-quality positive-negative training pairs, suffering from
noisy labels and the marginal distinction between preferred and dispreferred
response data. Given recent LLMs' proficiency in generating helpful responses,
this work pivots towards a new research focus: achieving alignment using solely
human-annotated negative samples, preserving helpfulness while reducing
harmfulness. For this purpose, we propose Distributional Dispreference
Optimization (D$^2$O), which maximizes the discrepancy between the generated
responses and the dispreferred ones to effectively eschew harmful information.
We theoretically demonstrate that D$^2$O is equivalent to learning a
distributional instead of instance-level preference model reflecting human
dispreference against the distribution of negative responses. Besides, D$^2$O
integrates an implicit Jeffrey Divergence regularization to balance the
exploitation and exploration of reference policies and converges to a
non-negative one during training. Extensive experiments demonstrate that our
method achieves comparable generation quality and surpasses the latest
baselines in producing less harmful and more informative responses with better
training stability and faster convergence.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03421" title="Abstract">arXiv:2403.03421</a> [<a href="/pdf/2403.03421" title="Download PDF">pdf</a>, <a href="/format/2403.03421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEAD: Learning Decomposition for Source-free Universal Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Sanqing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+T">Tianpei Zou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lianghua He</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6hrbein%2C+F">Florian R&#xf6;hrbein</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Universal Domain Adaptation (UniDA) targets knowledge transfer in the
presence of both covariate and label shifts. Recently, Source-free Universal
Domain Adaptation (SF-UniDA) has emerged to achieve UniDA without access to
source data, which tends to be more practical due to data protection policies.
The main challenge lies in determining whether covariate-shifted samples belong
to target-private unknown categories. Existing methods tackle this either
through hand-crafted thresholding or by developing time-consuming iterative
clustering strategies. In this paper, we propose a new idea of LEArning
Decomposition (LEAD), which decouples features into source-known and -unknown
components to identify target-private data. Technically, LEAD initially
leverages the orthogonal decomposition analysis for feature decomposition.
Then, LEAD builds instance-level decision boundaries to adaptively identify
target-private data. Extensive experiments across various UniDA scenarios have
demonstrated the effectiveness and superiority of LEAD. Notably, in the OPDA
scenario on VisDA dataset, LEAD outperforms GLC by 3.5% overall H-score and
reduces 75% time to derive pseudo-labeling decision boundaries. Besides, LEAD
is also appealing in that it is complementary to most existing methods. The
code is available at https://github.com/ispc-lab/LEAD.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03424" title="Abstract">arXiv:2403.03424</a> [<a href="/pdf/2403.03424" title="Download PDF">pdf</a>, <a href="/format/2403.03424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative News Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiabao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Q">Quan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhitao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Most existing news recommendation methods tackle this task by conducting
semantic matching between candidate news and user representation produced by
historical clicked news. However, they overlook the high-level connections
among different news articles and also ignore the profound relationship between
these news articles and users. And the definition of these methods dictates
that they can only deliver news articles as-is. On the contrary, integrating
several relevant news articles into a coherent narrative would assist users in
gaining a quicker and more comprehensive understanding of events. In this
paper, we propose a novel generative news recommendation paradigm that includes
two steps: (1) Leveraging the internal knowledge and reasoning capabilities of
the Large Language Model (LLM) to perform high-level matching between candidate
news and user representation; (2) Generating a coherent and logically
structured narrative based on the associations between related news and user
interests, thus engaging users in further reading of the news. Specifically, we
propose GNR to implement the generative news recommendation paradigm. First, we
compose the dual-level representation of news and users by leveraging LLM to
generate theme-level representations and combine them with semantic-level
representations. Next, in order to generate a coherent narrative, we explore
the news relation and filter the related news according to the user preference.
Finally, we propose a novel training method named UIFT to train the LLM to fuse
multiple news articles in a coherent narrative. Extensive experiments show that
GNR can improve recommendation accuracy and eventually generate more
personalized and factually consistent narratives.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03425" title="Abstract">arXiv:2403.03425</a> [<a href="/pdf/2403.03425" title="Download PDF">pdf</a>, <a href="/format/2403.03425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sculpting Molecules in 3D: A Flexible Substructure Aware Framework for  Text-Oriented Molecular Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yange Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guangcheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuxiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=wang%2C+B">Bo wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weitao Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">The integration of deep learning, particularly AI-Generated Content, with
high-quality data derived from ab initio calculations has emerged as a
promising avenue for transforming the landscape of scientific research.
However, the challenge of designing molecular drugs or materials that
incorporate multi-modality prior knowledge remains a critical and complex
undertaking. Specifically, achieving a practical molecular design necessitates
not only meeting the diversity requirements but also addressing structural and
textural constraints with various symmetries outlined by domain experts. In
this article, we present an innovative approach to tackle this inverse design
problem by formulating it as a multi-modality guidance generation/optimization
task. Our proposed solution involves a textural-structure alignment symmetric
diffusion framework for the implementation of molecular generation/optimization
tasks, namely 3DToMolo. 3DToMolo aims to harmonize diverse modalities, aligning
them seamlessly to produce molecular structures adhere to specified symmetric
structural and textural constraints by experts in the field. Experimental
trials across three guidance generation settings have shown a superior hit
generation performance compared to state-of-the-art methodologies. Moreover,
3DToMolo demonstrates the capability to generate novel molecules, incorporating
specified target substructures, without the need for prior knowledge. This work
not only holds general significance for the advancement of deep learning
methodologies but also paves the way for a transformative shift in molecular
design strategies. 3DToMolo creates opportunities for a more nuanced and
effective exploration of the vast chemical space, opening new frontiers in the
development of molecular entities with tailored properties and functionalities.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03429" title="Abstract">arXiv:2403.03429</a> [<a href="/pdf/2403.03429" title="Download PDF">pdf</a>, <a href="/format/2403.03429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Explanations for Program Synthesizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazari%2C+A">Amirmohammad Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+S">Souti Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Swayamdipta%2C+S">Swabha Swayamdipta</a>, 
<a href="/search/cs?searchtype=author&query=Raghothaman%2C+M">Mukund Raghothaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Despite great advances in program synthesis techniques, they remain
algorithmic black boxes. Although they guarantee that when synthesis is
successful, the implementation satisfies the specification, they provide no
additional information regarding how the implementation works or the manner in
which the specification is realized. One possibility to answer these questions
is to use large language models (LLMs) to construct human-readable
explanations. Unfortunately, experiments reveal that LLMs frequently produce
nonsensical or misleading explanations when applied to the unidiomatic code
produced by program synthesizers.
<br />In this paper, we develop an approach to reliably augment the implementation
with explanatory names. We recover fine-grained input-output data from the
synthesis algorithm to enhance the prompt supplied to the LLM, and use a
combination of a program verifier and a second language model to validate the
proposed explanations before presenting them to the user. Together, these
techniques massively improve the accuracy of the proposed names, from 24% to
79% respectively. Through a pair of small user studies, we find that users
significantly prefer the explanations produced by our technique (76% of
responses indicating the appropriateness of the presenting names) to the
baseline (with only 2% of responses approving of the suggestions), and that the
proposed names measurably help users in understanding the synthesized
implementation.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03431" title="Abstract">arXiv:2403.03431</a> [<a href="/pdf/2403.03431" title="Download PDF">pdf</a>, <a href="/format/2403.03431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding Cross and Self-Attention in Stable Diffusion for  Text-Guided Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tingfeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Text-to-Image Synthesis (TIS) models such as Stable Diffusion have
recently gained significant popularity for creative Text-to-image generation.
Yet, for domain-specific scenarios, tuning-free Text-guided Image Editing (TIE)
is of greater importance for application developers, which modify objects or
object properties in images by manipulating feature components in attention
layers during the generation process. However, little is known about what
semantic meanings these attention layers have learned and which parts of the
attention maps contribute to the success of image editing. In this paper, we
conduct an in-depth probing analysis and demonstrate that cross-attention maps
in Stable Diffusion often contain object attribution information that can
result in editing failures. In contrast, self-attention maps play a crucial
role in preserving the geometric and shape details of the source image during
the transformation to the target image. Our analysis offers valuable insights
into understanding cross and self-attention maps in diffusion models. Moreover,
based on our findings, we simplify popular image editing methods and propose a
more straightforward yet more stable and efficient tuning-free procedure that
only modifies self-attention maps of the specified attention layers during the
denoising process. Experimental results show that our simplified method
consistently surpasses the performance of popular approaches on multiple
datasets.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03432" title="Abstract">arXiv:2403.03432</a> [<a href="/pdf/2403.03432" title="Download PDF">pdf</a>, <a href="/format/2403.03432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wenfeng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Chuzhan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuewei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, COLING24 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instruction Tuning has the potential to stimulate or enhance specific
capabilities of large language models (LLMs). However, achieving the right
balance of data is crucial to prevent catastrophic forgetting and interference
between tasks. To address these limitations and enhance training flexibility,
we propose the Mixture-of-LoRAs (MoA) architecture which is a novel and
parameter-efficient tuning method designed for multi-task learning with LLMs.
In this paper, we start by individually training multiple domain-specific LoRA
modules using corresponding supervised corpus data. These LoRA modules can be
aligned with the expert design principles observed in Mixture-of-Experts (MoE).
Subsequently, we combine the multiple LoRAs using an explicit routing strategy
and introduce domain labels to facilitate multi-task learning, which help
prevent interference between tasks and ultimately enhances the performance of
each individual task. Furthermore, each LoRA model can be iteratively adapted
to a new domain, allowing for quick domain-specific adaptation. Experiments on
diverse tasks demonstrate superior and robust performance, which can further
promote the wide application of domain-specific LLMs.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03433" title="Abstract">arXiv:2403.03433</a> [<a href="/pdf/2403.03433" title="Download PDF">pdf</a>, <a href="/format/2403.03433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I3DE: An IDE for Inspecting Inconsistencies in PL/SQL Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiangshan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In 2024 First IDE Workshop (IDE' 24), April 20, 2024, Lisbon, Portugal. ACM, New York, NY, USA, 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In this paper, we introduce I3DE (Inconsistency Inspecting IDE) - an IDE
plugin to inspect inconsistencies in PL/SQL code. We first observed the
potential issues, e.g., misuses or bugs, that are introduced by the
inconsistent understanding of PL/SQL semantics by PL/SQL programmers and DBMS
developers, and propose a metamorphic testing-based approach for inspecting
such inconsistencies in PL/SQL code. We design and implement our approach in
I3DE, a widely usable plugin for the IntelliJ Platform. We conducted a
comparative user study involving 16 participants, and the findings indicate
that I3DE is consistently effective and efficient in helping programmers
identify and avoid inconsistencies across different programming difficulties
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03434" title="Abstract">arXiv:2403.03434</a> [<a href="/pdf/2403.03434" title="Download PDF">pdf</a>, <a href="/ps/2403.03434" title="Download PostScript">ps</a>, <a href="/format/2403.03434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI-enabled Agent-Based Model and Its Application in Measles Outbreak  Simulation for New Zealand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sijin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Orsi%2C+A">Alvaro Orsi</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+R">Richard Dean</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R">Rachel Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiawei Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Agent Based Models (ABMs) have emerged as a powerful tool for investigating
complex social interactions, particularly in the context of public health and
infectious disease investigation. In an effort to enhance the conventional ABM,
enabling automated model calibration and reducing the computational resources
needed for scaling up the model, we have developed a tensorized and
differentiable agent-based model by coupling Graph Neural Network (GNN) and
Long Short-Term Memory (LSTM) network. The model was employed to investigate
the 2019 measles outbreak occurred in New Zealand, demonstrating a promising
ability to accurately simulate the outbreak dynamics, particularly during the
peak period of repeated cases. This paper shows that by leveraging the latest
Artificial Intelligence (AI) technology and the capabilities of traditional
ABMs, we gain deeper insights into the dynamics of infectious disease
outbreaks. This, in turn, helps us make more informed decision when developing
effective strategies that strike a balance between managing outbreaks and
minimizing disruptions to everyday life.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03435" title="Abstract">arXiv:2403.03435</a> [<a href="/pdf/2403.03435" title="Download PDF">pdf</a>, <a href="/ps/2403.03435" title="Download PostScript">ps</a>, <a href="/format/2403.03435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLSP 2023 -- LTER: A Summary of the Challenge on Legal Textual  Entailment Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+V">Vu Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha-Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+T">Trung Vo</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+S+T">Son T. Luu</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+H">Hoang-Anh Dang</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngoc-Cam Le</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Thi-Thuy Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh-Tien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Truong-Son Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L">Le-Minh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this new era of rapid AI development, especially in language processing,
the demand for AI in the legal domain is increasingly critical. In the context
where research in other languages such as English, Japanese, and Chinese has
been well-established, we introduce the first fundamental research for the
Vietnamese language in the legal domain: legal textual entailment recognition
through the Vietnamese Language and Speech Processing workshop. In analyzing
participants' results, we discuss certain linguistic aspects critical in the
legal domain that pose challenges that need to be addressed.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03440" title="Abstract">arXiv:2403.03440</a> [<a href="/pdf/2403.03440" title="Download PDF">pdf</a>, <a href="/format/2403.03440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A component-splitting implicit time integration for multicomponent  reacting flows simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Jingchao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Cai%2C+J">Jinsheng Cai</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+S">Shucheng Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">A component-splitting method is proposed to improve convergence
characteristics for implicit time integration of compressible multicomponent
reactive flows. The characteristic decomposition of flux jacobian of
multicomponent Navier-Stokes equations yields a large sparse eigensystem,
presenting challenges of slow convergence and high computational costs for
implicit methods. To addresses this issue, the component-splitting method
segregates the implicit operator into two parts: one for the flow equations
(density/momentum/energy) and the other for the component equations. Each
part's implicit operator employs flux-vector splitting based on their
respective spectral radii to achieve accelerated convergence. This approach
improves the computational efficiency of implicit iteration, mitigating the
quadratic increase in time cost with the number of species. Two consistence
corrections are developed to reduce the introduced component-splitting error
and ensure the numerical consistency of mass fraction. Importantly, the impact
of component-splitting method on accuracy is minimal as the residual approaches
convergence. The accuracy, efficiency, and robustness of component-splitting
method are thoroughly investigated and compared with the coupled implicit
scheme through several numerical cases involving thermo-chemical nonequilibrium
hypersonic flows. The results demonstrate that the component-splitting method
decreases the required number of iteration steps for convergence of residual
and wall heat flux, decreases the computation time per iteration step, and
diminishes the residual to lower magnitude. The acceleration efficiency is
enhanced with increases in CFL number and number of species.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03442" title="Abstract">arXiv:2403.03442</a> [<a href="/pdf/2403.03442" title="Download PDF">pdf</a>, <a href="/format/2403.03442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMASim: A Comprehensive Simulation Framework for Content-Addressable  Memory based Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sharifi%2C+M+M">Mohammad Mehdi Sharifi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">X. Sharon Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Content addressable memory (CAM) stands out as an efficient hardware solution
for memory-intensive search operations by supporting parallel computation in
memory. However, developing a CAM-based accelerator architecture that achieves
acceptable accuracy, while minimizing hardware cost and catering to both exact
and approximate search, still presents a significant challenge especially when
considering a broader spectrum of applications. This complexity stems from
CAM's rapid evolution across multiple levels--algorithms, architectures,
circuits, and underlying devices. This paper introduces CAMASim, a first
comprehensive CAM accelerator simulation framework, emphasizing modularity,
flexibility, and generality. CAMASim establishes the detailed design space for
CAM-based accelerators, incorporates automated functional simulation for
accuracy, and enables hardware performance prediction, by leveraging a
circuit-level CAM modeling tool. This work streamlines the design space
exploration for CAM-based accelerator, aiding researchers in developing
effective CAM-based accelerators for various search-intensive applications.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03444" title="Abstract">arXiv:2403.03444</a> [<a href="/pdf/2403.03444" title="Download PDF">pdf</a>, <a href="/format/2403.03444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification for deeponets with ensemble kalman inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pensoneault%2C+A">Andrew Pensoneault</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xueyu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">In recent years, operator learning, particularly the DeepONet, has received
much attention for efficiently learning complex mappings between input and
output functions across diverse fields. However, in practical scenarios with
limited and noisy data, accessing the uncertainty in DeepONet predictions
becomes essential, especially in mission-critical or safety-critical
applications. Existing methods, either computationally intensive or yielding
unsatisfactory uncertainty quantification, leave room for developing efficient
and informative uncertainty quantification (UQ) techniques tailored for
DeepONets. In this work, we proposed a novel inference approach for efficient
UQ for operator learning by harnessing the power of the Ensemble Kalman
Inversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and
highly parallelizable feature, has demonstrated its advantages for UQ for
physics-informed neural networks [28]. Our innovative application of EKI
enables us to efficiently train ensembles of DeepONets while obtaining
informative uncertainty estimates for the output of interest. We deploy a
mini-batch variant of EKI to accommodate larger datasets, mitigating the
computational demand due to large datasets during the training stage.
Furthermore, we introduce a heuristic method to estimate the artificial
dynamics covariance, thereby improving our uncertainty estimates. Finally, we
demonstrate the effectiveness and versatility of our proposed methodology
across various benchmark problems, showcasing its potential to address the
pressing challenges of uncertainty quantification in DeepONets, especially for
practical applications with limited and noisy data.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03447" title="Abstract">arXiv:2403.03447</a> [<a href="/pdf/2403.03447" title="Download PDF">pdf</a>, <a href="/format/2403.03447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HDRFlow: Real-Time HDR Video Reconstruction with Large Motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinwei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024; Project website: <a href="https://openimaginglab.github.io/HDRFlow/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing High Dynamic Range (HDR) video from image sequences captured
with alternating exposures is challenging, especially in the presence of large
camera or object motion. Existing methods typically align low dynamic range
sequences using optical flow or attention mechanism for deghosting. However,
they often struggle to handle large complex motions and are computationally
expensive. To address these challenges, we propose a robust and efficient flow
estimator tailored for real-time HDR video reconstruction, named HDRFlow.
HDRFlow has three novel designs: an HDR-domain alignment loss (HALoss), an
efficient flow network with a multi-size large kernel (MLK), and a new HDR flow
training scheme. The HALoss supervises our flow network to learn an
HDR-oriented flow for accurate alignment in saturated and dark regions. The MLK
can effectively model large motions at a negligible cost. In addition, we
incorporate synthetic data, Sintel, into our training dataset, utilizing both
its provided forward flow and backward flow generated by us to supervise our
flow network, enhancing our performance in large motion regions. Extensive
experiments demonstrate that our HDRFlow outperforms previous methods on
standard benchmarks. To the best of our knowledge, HDRFlow is the first
real-time HDR video reconstruction method for video sequences captured with
alternating exposures, capable of processing 720p resolution inputs at 25ms.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03448" title="Abstract">arXiv:2403.03448</a> [<a href="/pdf/2403.03448" title="Download PDF">pdf</a>, <a href="/ps/2403.03448" title="Download PostScript">ps</a>, <a href="/format/2403.03448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Correlation-Dissimilarity for Multiple Kernel k-Means Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+R">Rina Su</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Caiying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qiyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages. This paper was accepted by Pattern Recognition on January 31, 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition, 2024, 150:110307
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The main objective of the Multiple Kernel k-Means (MKKM) algorithm is to
extract non-linear information and achieve optimal clustering by optimizing
base kernel matrices. Current methods enhance information diversity and reduce
redundancy by exploiting interdependencies among multiple kernels based on
correlations or dissimilarities. Nevertheless, relying solely on a single
metric, such as correlation or dissimilarity, to define kernel relationships
introduces bias and incomplete characterization. Consequently, this limitation
hinders efficient information extraction, ultimately compromising clustering
performance. To tackle this challenge, we introduce a novel method that
systematically integrates both kernel correlation and dissimilarity. Our
approach comprehensively captures kernel relationships, facilitating more
efficient classification information extraction and improving clustering
performance. By emphasizing the coherence between kernel correlation and
dissimilarity, our method offers a more objective and transparent strategy for
extracting non-linear information and significantly improving clustering
precision, supported by theoretical rationale. We assess the performance of our
algorithm on 13 challenging benchmark datasets, demonstrating its superiority
over contemporary state-of-the-art MKKM techniques.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03449" title="Abstract">arXiv:2403.03449</a> [<a href="/pdf/2403.03449" title="Download PDF">pdf</a>, <a href="/format/2403.03449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SalienTime: User-driven Selection of Salient Time Steps for Large-Scale  Geospatial Data Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Juntong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haiwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Huayuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changbo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI'24), May 11-16, 2024, Honolulu, HI, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The voluminous nature of geospatial temporal data from physical monitors and
simulation models poses challenges to efficient data access, often resulting in
cumbersome temporal selection experiences in web-based data portals. Thus,
selecting a subset of time steps for prioritized visualization and pre-loading
is highly desirable. Addressing this issue, this paper establishes a
multifaceted definition of salient time steps via extensive need-finding
studies with domain experts to understand their workflows. Building on this, we
propose a novel approach that leverages autoencoders and dynamic programming to
facilitate user-driven temporal selections. Structural features, statistical
variations, and distance penalties are incorporated to make more flexible
selections. User-specified priorities, spatial regions, and aggregations are
used to combine different perspectives. We design and implement a web-based
interface to enable efficient and context-aware selection of time steps and
evaluate its efficacy and usability through case studies, quantitative
evaluations, and expert interviews.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03452" title="Abstract">arXiv:2403.03452</a> [<a href="/pdf/2403.03452" title="Download PDF">pdf</a>, <a href="/format/2403.03452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D4C glove-train: solving the RPM and Bongard-logo problem by  distributing and Circumscribing concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruizhuo Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Beiming Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 14 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents significant advancements in the field of abstract
reasoning, particularly for Raven's Progressive Matrices (RPM) and Bongard-Logo
problems. We first introduce D2C, a method that redefines concept boundaries in
these domains and bridges the gap between high-level concepts and their
low-dimensional representations. Leveraging this foundation, we propose D3C, a
novel approach for tackling Bongard-Logo problems. D3C estimates the
distributions of image representations and measures their Sinkhorn distance to
achieve remarkable reasoning accuracy. This innovative method provides new
insights into the relationships between images and advances the
state-of-the-art in abstract reasoning. To further enhance computational
efficiency without sacrificing performance, we introduce D3C-cos. This variant
of D3C constrains distribution distances, offering a more computationally
efficient solution for RPM problems while maintaining high accuracy.
Additionally, we present Lico-Net, a baseline network for RPM that integrates
D3C and D3C-cos. By estimating and constraining the distributions of regularity
representations, Lico-Net addresses both problem-solving and interpretability
challenges, achieving state-of-the-art performance. Finally, we extend our
methodology with D4C, an adversarial approach that further refines concept
boundaries compared to D2C. Tailored for RPM and Bongard-Logo problems, D4C
demonstrates significant improvements in addressing the challenges of abstract
reasoning. Overall, our contributions advance the field of abstract reasoning,
providing new perspectives and practical solutions to long-standing problems.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03454" title="Abstract">arXiv:2403.03454</a> [<a href="/pdf/2403.03454" title="Download PDF">pdf</a>, <a href="/format/2403.03454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Constrained Optimization with Deep Augmented Lagrangian Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotary%2C+J">James Kotary</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Learning to Optimize (LtO) is a problem setting in which a machine learning
(ML) model is trained to emulate a constrained optimization solver. Learning to
produce optimal and feasible solutions subject to complex constraints is a
difficult task, but is often made possible by restricting the input space to a
limited distribution of related problems. Most LtO methods focus on directly
learning solutions to the primal problem, and applying correction schemes or
loss function penalties to encourage feasibility. This paper proposes an
alternative approach, in which the ML model is trained instead to predict dual
solution estimates directly, from which primal estimates are constructed to
form dual-feasible solution pairs. This enables an end-to-end training scheme
is which the dual objective is maximized as a loss function, and solution
estimates iterate toward primal feasibility, emulating a Dual Ascent method.
First it is shown that the poor convergence properties of classical Dual Ascent
are reflected in poor convergence of the proposed training scheme. Then, by
incorporating techniques from practical Augmented Lagrangian methods, we show
how the training scheme can be improved to learn highly accurate constrained
optimization solvers, for both convex and nonconvex problems.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03456" title="Abstract">arXiv:2403.03456</a> [<a href="/pdf/2403.03456" title="Download PDF">pdf</a>, <a href="/format/2403.03456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with  Generative Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+X">Xiangquan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Computing and Applications, 2023: 1-18
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Chinese landscape painting has a unique and artistic style, and its drawing
technique is highly abstract in both the use of color and the realistic
representation of objects. Previous methods focus on transferring from modern
photos to ancient ink paintings. However, little attention has been paid to
translating landscape paintings into modern photos. To solve such problems, in
this paper, we (1) propose DLP-GAN (\textbf{D}raw Modern Chinese
\textbf{L}andscape \textbf{P}hotos with \textbf{G}enerative
\textbf{A}dversarial \textbf{N}etwork), an unsupervised cross-domain image
translation framework with a novel asymmetric cycle mapping, and (2) introduce
a generator based on a dense-fusion module to match different translation
directions. Moreover, a dual-consistency loss is proposed to balance the
realism and abstraction of model painting. In this way, our model can draw
landscape photos and sketches in the modern sense. Finally, based on our
collection of modern landscape and sketch datasets, we compare the images
generated by our model with other benchmarks. Extensive experiments including
user studies show that our model outperforms state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03458" title="Abstract">arXiv:2403.03458</a> [<a href="/pdf/2403.03458" title="Download PDF">pdf</a>, <a href="/format/2403.03458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slot Abstractors: Toward Scalable Abstract Visual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S+S">Shanka Subhra Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+D">Jonathan D. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+T+W">Taylor W. Webb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Abstract visual reasoning is a characteristically human ability, allowing the
identification of relational patterns that are abstracted away from object
features, and the systematic generalization of those patterns to unseen
problems. Recent work has demonstrated strong systematic generalization in
visual reasoning tasks involving multi-object inputs, through the integration
of slot-based methods used for extracting object-centric representations
coupled with strong inductive biases for relational abstraction. However, this
approach was limited to problems containing a single rule, and was not scalable
to visual reasoning problems containing a large number of objects. Other recent
work proposed Abstractors, an extension of Transformers that incorporates
strong relational inductive biases, thereby inheriting the Transformer's
scalability and multi-head architecture, but it has yet to be demonstrated how
this approach might be applied to multi-object visual inputs. Here we combine
the strengths of the above approaches and propose Slot Abstractors, an approach
to abstract visual reasoning that can be scaled to problems involving a large
number of objects and multiple relations among them. The approach displays
state-of-the-art performance across four abstract visual reasoning tasks.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03459" title="Abstract">arXiv:2403.03459</a> [<a href="/pdf/2403.03459" title="Download PDF">pdf</a>, <a href="/format/2403.03459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TGPT-PINN: Nonlinear model reduction with transformed GPT-PINNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yanlai Chen</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+Y">Yajie Ji</a>, 
<a href="/search/math?searchtype=author&query=Narayan%2C+A">Akil Narayan</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Z">Zhenli Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce the Transformed Generative Pre-Trained Physics-Informed Neural
Networks (TGPT-PINN) for accomplishing nonlinear model order reduction (MOR) of
transport-dominated partial differential equations in an MOR-integrating PINNs
framework. Building on the recent development of the GPT-PINN that is a
network-of-networks design achieving snapshot-based model reduction, we design
and test a novel paradigm for nonlinear model reduction that can effectively
tackle problems with parameter-dependent discontinuities. Through incorporation
of a shock-capturing loss function component as well as a parameter-dependent
transform layer, the TGPT-PINN overcomes the limitations of linear model
reduction in the transport-dominated regime. We demonstrate this new capability
for nonlinear model reduction in the PINNs framework by several nontrivial
parametric partial differential equations.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03460" title="Abstract">arXiv:2403.03460</a> [<a href="/pdf/2403.03460" title="Download PDF">pdf</a>, <a href="/ps/2403.03460" title="Download PostScript">ps</a>, <a href="/format/2403.03460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foot Shape-Dependent Resistive Force Model for Bipedal Walkers on  Granular Terrains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xunjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Anikode%2C+A">Aditya Anikode</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robots have demonstrated high efficiency and effectiveness in
unstructured and dynamic environments. However, it is still challenging for
legged robots to achieve rapid and efficient locomotion on deformable, yielding
substrates, such as granular terrains. We present an enhanced resistive force
model for bipedal walkers on soft granular terrains by introducing effective
intrusion depth correction. The enhanced force model captures fundamental
kinetic results considering the robot foot shape, walking gait speed variation,
and energy expense. The model is validated by extensive foot intrusion
experiments with a bipedal robot. The results confirm the model accuracy on the
given type of granular terrains. The model can be further integrated with the
motion control of bipedal robotic walkers.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03461" title="Abstract">arXiv:2403.03461</a> [<a href="/pdf/2403.03461" title="Download PDF">pdf</a>, <a href="/format/2403.03461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Density-Guided Temporal Attention Transformer for Indiscernible Object  Counting in Underwater Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hsiang-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+F">Farron Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024 (IEEE International Conference on Acoustics, Speech, and Signal Processing)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dense object counting or crowd counting has come a long way thanks to the
recent development in the vision community. However, indiscernible object
counting, which aims to count the number of targets that are blended with
respect to their surroundings, has been a challenge. Image-based object
counting datasets have been the mainstream of the current publicly available
datasets. Therefore, we propose a large-scale dataset called YoutubeFish-35,
which contains a total of 35 sequences of high-definition videos with high
frame-per-second and more than 150,000 annotated center points across a
selected variety of scenes. For benchmarking purposes, we select three
mainstream methods for dense object counting and carefully evaluate them on the
newly collected dataset. We propose TransVidCount, a new strong baseline that
combines density and regression branches along the temporal domain in a unified
framework and can effectively tackle indiscernible object counting with
state-of-the-art performance on YoutubeFish-35 dataset.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03462" title="Abstract">arXiv:2403.03462</a> [<a href="/pdf/2403.03462" title="Download PDF">pdf</a>, <a href="/format/2403.03462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Continual Learning Architecture for Long-Term  Personalization of Home Service Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayub%2C+A">Ali Ayub</a>, 
<a href="/search/cs?searchtype=author&query=Nehaniv%2C+C">Chrystopher Nehaniv</a>, 
<a href="/search/cs?searchtype=author&query=Dautenhahn%2C+K">Kerstin Dautenhahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE International Conference on Robotics and Automation (ICRA), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">For robots to perform assistive tasks in unstructured home environments, they
must learn and reason on the semantic knowledge of the environments. Despite a
resurgence in the development of semantic reasoning architectures, these
methods assume that all the training data is available a priori. However, each
user's environment is unique and can continue to change over time, which makes
these methods unsuitable for personalized home service robots. Although
research in continual learning develops methods that can learn and adapt over
time, most of these methods are tested in the narrow context of object
classification on static image datasets. In this paper, we combine ideas from
continual learning, semantic reasoning, and interactive machine learning
literature and develop a novel interactive continual learning architecture for
continual learning of semantic knowledge in a home environment through
human-robot interaction. The architecture builds on core cognitive principles
of learning and memory for efficient and real-time learning of new knowledge
from humans. We integrate our architecture with a physical mobile manipulator
robot and perform extensive system evaluations in a laboratory environment over
two months. Our results demonstrate the effectiveness of our architecture to
allow a physical robot to continually adapt to the changes in the environment
from limited data provided by the users (experimenters), and use the learned
knowledge to perform object fetching tasks.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03463" title="Abstract">arXiv:2403.03463</a> [<a href="/pdf/2403.03463" title="Download PDF">pdf</a>, <a href="/format/2403.03463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLAME Diffuser: Grounded Wildfire Image Synthesis using Mask Guided  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Boroujeni%2C+S+P+H">Sayed Pedram Haeri Boroujeni</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bastola%2C+A">Ashish Bastola</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Razi%2C+A">Abolfazl Razi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The rise of machine learning in recent years has brought benefits to various
research fields such as wide fire detection. Nevertheless, small object
detection and rare object detection remain a challenge. To address this
problem, we present a dataset automata that can generate ground truth paired
datasets using diffusion models. Specifically, we introduce a mask-guided
diffusion framework that can fusion the wildfire into the existing images while
the flame position and size can be precisely controlled. In advance, to fill
the gap that the dataset of wildfire images in specific scenarios is missing,
we vary the background of synthesized images by controlling both the text
prompt and input image. Furthermore, to solve the color tint problem or the
well-known domain shift issue, we apply the CLIP model to filter the generated
massive dataset to preserve quality. Thus, our proposed framework can generate
a massive dataset of that images are high-quality and ground truth-paired,
which well addresses the needs of the annotated datasets in specific tasks.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03465" title="Abstract">arXiv:2403.03465</a> [<a href="/pdf/2403.03465" title="Download PDF">pdf</a>, <a href="/format/2403.03465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Attention Empowered Graph Convolutional Network for Structure  Learning and Node Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mengying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guizhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuanchao Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinliang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages,6 figures,9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In representation learning on graph-structured data, many popular graph
neural networks (GNNs) fail to capture long-range dependencies, leading to
performance degradation. Furthermore, this weakness is magnified when the
concerned graph is characterized by heterophily (low homophily). To solve this
issue, this paper proposes a novel graph learning framework called the graph
convolutional network with self-attention (GCN-SA). The proposed scheme
exhibits an exceptional generalization capability in node-level representation
learning. The proposed GCN-SA contains two enhancements corresponding to edges
and node features. For edges, we utilize a self-attention mechanism to design a
stable and effective graph-structure-learning module that can capture the
internal correlation between any pair of nodes. This graph-structure-learning
module can identify reliable neighbors for each node from the entire graph.
Regarding the node features, we modify the transformer block to make it more
applicable to enable GCN to fuse valuable information from the entire graph.
These two enhancements work in distinct ways to help our GCN-SA capture
long-range dependencies, enabling it to perform representation learning on
graphs with varying levels of homophily. The experimental results on benchmark
datasets demonstrate the effectiveness of the proposed GCN-SA. Compared to
other outstanding GNN counterparts, the proposed GCN-SA is competitive.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03468" title="Abstract">arXiv:2403.03468</a> [<a href="/pdf/2403.03468" title="Download PDF">pdf</a>, <a href="/format/2403.03468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Learning for Real-time Autonomous Driving Leveraging  Task-adaptive Attention Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+W">Wonhyeok Choi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Mingyu Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyukzae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaehoon Cho</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaehyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sunghoon Im</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time processing is crucial in autonomous driving systems due to the
imperative of instantaneous decision-making and rapid response. In real-world
scenarios, autonomous vehicles are continuously tasked with interpreting their
surroundings, analyzing intricate sensor data, and making decisions within
split seconds to ensure safety through numerous computer vision tasks. In this
paper, we present a new real-time multi-task network adept at three vital
autonomous driving tasks: monocular 3D object detection, semantic segmentation,
and dense depth estimation. To counter the challenge of negative transfer,
which is the prevalent issue in multi-task learning, we introduce a
task-adaptive attention generator. This generator is designed to automatically
discern interrelations across the three tasks and arrange the task-sharing
pattern, all while leveraging the efficiency of the hard-parameter sharing
approach. To the best of our knowledge, the proposed model is pioneering in its
capability to concurrently handle multiple tasks, notably 3D object detection,
while maintaining real-time processing speeds. Our rigorously optimized
network, when tested on the Cityscapes-3D datasets, consistently outperforms
various baseline models. Moreover, an in-depth ablation study substantiates the
efficacy of the methodologies integrated into our framework.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03472" title="Abstract">arXiv:2403.03472</a> [<a href="/pdf/2403.03472" title="Download PDF">pdf</a>, <a href="/format/2403.03472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Meta-Training with Base Class Information for Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weihao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guodong Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Di He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, submitted to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Few-shot learning, a challenging task in machine learning, aims to learn a
classifier adaptable to recognize new, unseen classes with limited labeled
examples. Meta-learning has emerged as a prominent framework for few-shot
learning. Its training framework is originally a task-level learning method,
such as Model-Agnostic Meta-Learning (MAML) and Prototypical Networks. And a
recently proposed training paradigm called Meta-Baseline, which consists of
sequential pre-training and meta-training stages, gains state-of-the-art
performance. However, as a non-end-to-end training method, indicating the
meta-training stage can only begin after the completion of pre-training,
Meta-Baseline suffers from higher training cost and suboptimal performance due
to the inherent conflicts of the two training stages. To address these
limitations, we propose an end-to-end training paradigm consisting of two
alternative loops. In the outer loop, we calculate cross entropy loss on the
entire training set while updating only the final linear layer. In the inner
loop, we employ the original meta-learning training mode to calculate the loss
and incorporate gradients from the outer loss to guide the parameter updates.
This training paradigm not only converges quickly but also outperforms existing
baselines, indicating that information from the overall training set and the
meta-learning training paradigm could mutually reinforce one another. Moreover,
being model-agnostic, our framework achieves significant performance gains,
surpassing the baseline systems by approximate 1%.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03473" title="Abstract">arXiv:2403.03473</a> [<a href="/pdf/2403.03473" title="Download PDF">pdf</a>, <a href="/format/2403.03473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse-Free Fast Natural Gradient Descent Method for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou%2C+X">Xinwei Ou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Ce Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yipeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Second-order methods can converge much faster than first-order methods by
incorporating second-order derivates or statistics, but they are far less
prevalent in deep learning due to their computational inefficiency. To handle
this, many of the existing solutions focus on reducing the size of the matrix
to be inverted. However, it is still needed to perform the inverse operator in
each iteration. In this paper, we present a fast natural gradient descent
(FNGD) method, which only requires computing the inverse during the first
epoch. Firstly, we reformulate the gradient preconditioning formula in the
natural gradient descent (NGD) as a weighted sum of per-sample gradients using
the Sherman-Morrison-Woodbury formula. Building upon this, to avoid the
iterative inverse operation involved in computing coefficients, the weighted
coefficients are shared across epochs without affecting the empirical
performance.
<br />FNGD approximates the NGD as a fixed-coefficient weighted sum, akin to the
average sum in first-order methods. Consequently, the computational complexity
of FNGD can approach that of first-order methods. To demonstrate the efficiency
of the proposed FNGD, we perform empirical evaluations on image classification
and machine translation tasks. For training ResNet-18 on the CIFAR-100 dataset,
FNGD can achieve a speedup of 2.05$\times$ compared with KFAC. For training
Transformer on Multi30K, FNGD outperforms AdamW by 24 BLEU score while
requiring almost the same training time.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03477" title="Abstract">arXiv:2403.03477</a> [<a href="/pdf/2403.03477" title="Download PDF">pdf</a>, <a href="/format/2403.03477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Segmentation with Disentangled Objectness Learning and Class  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yizheng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Siyue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jimin Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most continual segmentation methods tackle the problem as a per-pixel
classification task. However, such a paradigm is very challenging, and we find
query-based segmenters with built-in objectness have inherent advantages
compared with per-pixel ones, as objectness has strong transfer ability and
forgetting resistance. Based on these findings, we propose CoMasTRe by
disentangling continual segmentation into two stages: forgetting-resistant
continual objectness learning and well-researched continual classification.
CoMasTRe uses a two-stage segmenter learning class-agnostic mask proposals at
the first stage and leaving recognition to the second stage. During continual
learning, a simple but effective distillation is adopted to strengthen
objectness. To further mitigate the forgetting of old classes, we design a
multi-label class distillation strategy suited for segmentation. We assess the
effectiveness of CoMasTRe on PASCAL VOC and ADE20K. Extensive experiments show
that our method outperforms per-pixel and query-based methods on both datasets.
Code will be available at https://github.com/jordangong/CoMasTRe.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03481" title="Abstract">arXiv:2403.03481</a> [<a href="/pdf/2403.03481" title="Download PDF">pdf</a>, <a href="/format/2403.03481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Magic Markup: Maintaining Document-External Markup with an LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misback%2C+E">Edward Misback</a>, 
<a href="/search/cs?searchtype=author&query=Tatlock%2C+Z">Zachary Tatlock</a>, 
<a href="/search/cs?searchtype=author&query=Tanimoto%2C+S+L">Steven L. Tanimoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages; 2 figures; to be published in the &amp;lt;Programming&amp;gt; 2024 Conference Companion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text documents, including programs, typically have human-readable semantic
structure. Historically, programmatic access to these semantics has required
explicit in-document tagging. Especially in systems where the text has an
execution semantics, this means it is an opt-in feature that is hard to support
properly. Today, language models offer a new method: metadata can be bound to
entities in changing text using a model's human-like understanding of
semantics, with no requirements on the document structure. This method expands
the applications of document annotation, a fundamental operation in program
writing, debugging, maintenance, and presentation. We contribute a system that
employs an intelligent agent to re-tag modified programs, enabling rich
annotations to automatically follow code as it evolves. We also contribute a
formal problem definition, an empirical synthetic benchmark suite, and our
benchmark generator. Our system achieves an accuracy of 90% on our benchmarks
and can replace a document's tags in parallel at a rate of 5 seconds per tag.
While there remains significant room for improvement, we find performance
reliable enough to justify further exploration of applications.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03483" title="Abstract">arXiv:2403.03483</a> [<a href="/pdf/2403.03483" title="Download PDF">pdf</a>, <a href="/format/2403.03483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Teacher-Free Graph Knowledge Distillation Framework with Dual  Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lirong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haitao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guojiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.02097">arXiv:2210.02097</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent years have witnessed great success in handling graph-related tasks
with Graph Neural Networks (GNNs). Despite their great academic success,
Multi-Layer Perceptrons (MLPs) remain the primary workhorse for practical
industrial applications. One reason for such an academic-industry gap is the
neighborhood-fetching latency incurred by data dependency in GNNs. To reduce
their gaps, Graph Knowledge Distillation (GKD) is proposed, usually based on a
standard teacher-student architecture, to distill knowledge from a large
teacher GNN into a lightweight student GNN or MLP. However, we found in this
paper that neither teachers nor GNNs are necessary for graph knowledge
distillation. We propose a Teacher-Free Graph Self-Distillation (TGS) framework
that does not require any teacher model or GNNs during both training and
inference. More importantly, the proposed TGS framework is purely based on
MLPs, where structural information is only implicitly used to guide dual
knowledge self-distillation between the target node and its neighborhood. As a
result, TGS enjoys the benefits of graph topology awareness in training but is
free from data dependency in inference. Extensive experiments have shown that
the performance of vanilla MLPs can be greatly improved with dual
self-distillation, e.g., TGS improves over vanilla MLPs by 15.54% on average
and outperforms state-of-the-art GKD algorithms on six real-world datasets. In
terms of inference speed, TGS infers 75X-89X faster than existing GNNs and
16X-25X faster than classical inference acceleration methods.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03485" title="Abstract">arXiv:2403.03485</a> [<a href="/pdf/2403.03485" title="Download PDF">pdf</a>, <a href="/format/2403.03485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on  Noise Cropping and Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shirakawa%2C+T">Takahiro Shirakawa</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+S">Seiichi Uchida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Layout-aware text-to-image generation is a task to generate multi-object
images that reflect layout conditions in addition to text conditions. The
current layout-aware text-to-image diffusion models still have several issues,
including mismatches between the text and layout conditions and quality
degradation of generated images. This paper proposes a novel layout-aware
text-to-image diffusion model called NoiseCollage to tackle these issues.
During the denoising process, NoiseCollage independently estimates noises for
individual objects and then crops and merges them into a single noise. This
operation helps avoid condition mismatches; in other words, it can put the
right objects in the right places. Qualitative and quantitative evaluations
show that NoiseCollage outperforms several state-of-the-art models. These
successful results indicate that the crop-and-merge operation of noises is a
reasonable strategy to control image generation. We also show that NoiseCollage
can be integrated with ControlNet to use edges, sketches, and pose skeletons as
additional conditions. Experimental results show that this integration boosts
the layout accuracy of ControlNet. The code is available at
https://github.com/univ-esuty/noisecollage.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03486" title="Abstract">arXiv:2403.03486</a> [<a href="/pdf/2403.03486" title="Download PDF">pdf</a>, <a href="/format/2403.03486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhenoAuth: A Novel PUF-Phenotype-based Authentication Protocol for IoT  Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hongming Fei</a>, 
<a href="/search/cs?searchtype=author&query=Millwood%2C+O">Owen Millwood</a>, 
<a href="/search/cs?searchtype=author&query=Prosanta%2C+G">Gope Prosanta</a>, 
<a href="/search/cs?searchtype=author&query=Miskelly%2C+J">Jack Miskelly</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+B">Biplab Sikdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Physical Unclonable Functions (PUFs) have been shown to be a highly promising
solution for enabling high security systems tailored for low-power devices.
Commonly, PUFs are utilised to generate cryptographic keys on-the-fly,
replacing the need to store keys in vulnerable, non-volatile memories. Due to
the physical nature of PUFs, environmental variations cause noise, manifesting
themselves as errors which are apparent in the initial PUF measurements. This
necessitates expensive active error correction techniques which can run counter
to the goal of lightweight security. ML-based techniques for authenticating
noisy PUF measurements were explored as an alternative to error correction
techniques, bringing about the concept of a PUF Phenotype, where PUF identity
is considered as a structure agnostic representation of the PUF, with relevant
noise encoding. This work proposes a full noise-tolerant authentication
protocol based on the PUF Phenotype concept and methodology for an
Internet-of-Things (IoT) network, demonstrating mutual authentication and
forward secrecy in a setting suitable for device-to-device communication. Upon
conducting security and performance analyses, it is evident that our proposed
scheme demonstrates resilience against various attacks compared to the
currently existing PUF protocols.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03489" title="Abstract">arXiv:2403.03489</a> [<a href="/pdf/2403.03489" title="Download PDF">pdf</a>, <a href="/format/2403.03489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Geolocated Realtime Data of Interfleet Urban Transit Bus Idling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kunz%2C+N">Nicholas Kunz</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+H+O">H. Oliver Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 12 figures, 36 tables, 100 data sources (including links), 128 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Urban transit bus idling is a contributor to ecological stress, economic
inefficiency, and medically hazardous health outcomes due to emissions. The
global accumulation of this frequent pattern of undesirable driving behavior is
enormous. In order to measure its scale, we propose GRD-TRT- BUF-4I (Ground
Truth Buffer for Idling) an extensible, realtime detection system that records
the geolocation and idling duration of urban transit bus fleets
internationally. Using live vehicle locations from General Transit Feed
Specification (GTFS) Realtime, the system detects approximately 200,000 idling
events per day from over 50 cities across North America, Europe, Oceania, and
Asia. This realtime data was created to dynamically serve operational
decision-making and fleet management to reduce the frequency and duration of
idling events as they occur, as well as to capture its accumulative effects.
Civil and Transportation Engineers, Urban Planners, Epidemiologists,
Policymakers, and other stakeholders might find this useful for emissions
modeling, traffic management, route planning, and other urban sustainability
efforts at a variety of geographic and temporal scales.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03492" title="Abstract">arXiv:2403.03492</a> [<a href="/pdf/2403.03492" title="Download PDF">pdf</a>, <a href="/format/2403.03492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint User Association and Resource Allocation for Tailored QoS  Provisioning in 6G HetNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yongqin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The proliferation of wireless-enabled applications with divergent quality of
service (QoS) requirements necessitates tailored QoS provisioning. With the
growing complexity of wireless infrastructures, application-specific QoS
perceived by a user equipment (UE) is jointly determined by its association
with the supporting base station in heterogeneous networks (HetNets) and the
amount of resource allocated to it. However, conventional application-agnostic
objective-based user association and resource allocation often ignore the
differences among applications' specific requirements for resources, inevitably
preventing tailored QoS provisioning. Hence, in this paper, the problem of
joint user association and resource allocation with application-specific
objectives is investigated for achieving tailored QoS provisioning in 6G
HetNets. This problem is intrinsically difficult to solve directly due to the
extremely large solution space and the combination of discrete and continuous
variables. Therefore, we decompose the original problem into two subproblems,
i.e. user association and resource allocation, and propose an interactive
optimization algorithm (IOA) to solve them iteratively in an interactive way
until convergence is achieved. Specifically, matching theory is utilized to
solve resource allocation and user association is solved heuristically.
Extensive experimental results confirm that IOA algorithm outperforms several
baseline algorithms in terms of both average utility and UE satisfaction ratio.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03493" title="Abstract">arXiv:2403.03493</a> [<a href="/pdf/2403.03493" title="Download PDF">pdf</a>, <a href="/format/2403.03493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VastTrack: Vast Category Visual Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shaohua Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Libo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech. report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel benchmark, dubbed VastTrack, towards
facilitating the development of more general visual tracking via encompassing
abundant classes and videos. VastTrack possesses several attractive properties:
(1) Vast Object Category. In particular, it covers target objects from 2,115
classes, largely surpassing object categories of existing popular benchmarks
(e.g., GOT-10k with 563 classes and LaSOT with 70 categories). With such vast
object classes, we expect to learn more general object tracking. (2) Larger
scale. Compared with current benchmarks, VastTrack offers 50,610 sequences with
4.2 million frames, which makes it to date the largest benchmark regarding the
number of videos, and thus could benefit training even more powerful visual
trackers in the deep learning era. (3) Rich Annotation. Besides conventional
bounding box annotations, VastTrack also provides linguistic descriptions for
the videos. The rich annotations of VastTrack enables development of both the
vision-only and the vision-language tracking. To ensure precise annotation, all
videos are manually labeled with multiple rounds of careful inspection and
refinement. To understand performance of existing trackers and to provide
baselines for future comparison, we extensively assess 25 representative
trackers. The results, not surprisingly, show significant drops compared to
those on current datasets due to lack of abundant categories and videos from
diverse scenarios for training, and more efforts are required to improve
general tracking. Our VastTrack and all the evaluation results will be made
publicly available https://github.com/HengLan/VastTrack.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03494" title="Abstract">arXiv:2403.03494</a> [<a href="/pdf/2403.03494" title="Download PDF">pdf</a>, <a href="/format/2403.03494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable ATLAS pMSSM computational workflows using containerised REANA  reusable analysis platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donadoni%2C+M">Marco Donadoni</a>, 
<a href="/search/cs?searchtype=author&query=Feickert%2C+M">Matthew Feickert</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+L">Lukas Heinrich</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Me%C4%8Dionis%2C+A">Audrius Me&#x10d;ionis</a>, 
<a href="/search/cs?searchtype=author&query=Moisieienkov%2C+V">Vladyslav Moisieienkov</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0imko%2C+T">Tibor &#x160;imko</a>, 
<a href="/search/cs?searchtype=author&query=Stark%2C+G">Giordon Stark</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+M+V">Marco Vidal Garc&#xed;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures. Contribution to the Proceedings of the 26th International Conference on Computing In High Energy and Nuclear Physics (CHEP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">In this paper we describe the development of a streamlined framework for
large-scale ATLAS pMSSM reinterpretations of LHC Run-2 analyses using
containerised computational workflows. The project is looking to assess the
global coverage of BSM physics and requires running O(5k) computational
workflows representing pMSSM model points. Following ATLAS Analysis
Preservation policies, many analyses have been preserved as containerised
Yadage workflows, and after validation were added to a curated selection for
the pMSSM study. To run the workflows at scale, we utilised the REANA reusable
analysis platform. We describe how the REANA platform was enhanced to ensure
the best concurrent throughput by internal service scheduling changes. We
discuss the scalability of the approach on Kubernetes clusters from 500 to 5000
cores. Finally, we demonstrate a possibility of using additional ad-hoc public
cloud infrastructure resources by running the same workflows on the Google
Cloud Platform.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03496" title="Abstract">arXiv:2403.03496</a> [<a href="/pdf/2403.03496" title="Download PDF">pdf</a>, <a href="/ps/2403.03496" title="Download PostScript">ps</a>, <a href="/format/2403.03496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangci Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lifeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+H">Haitao Mi</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jessica Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge-based, open-domain dialogue generation aims to build chit-chat
systems that talk to humans using mined support knowledge. Many types and
sources of knowledge have previously been shown to be useful as support
knowledge. Even in the era of large language models, response generation
grounded in knowledge retrieved from additional up-to-date sources remains a
practically important approach. While prior work using single-source knowledge
has shown a clear positive correlation between the performances of knowledge
selection and response generation, there are no existing multi-source datasets
for evaluating support knowledge retrieval. Further, prior work has assumed
that the knowledge sources available at test time are the same as during
training. This unrealistic assumption unnecessarily handicaps models, as new
knowledge sources can become available after a model is trained. In this paper,
we present a high-quality benchmark named multi-source Wizard of Wikipedia
(Ms.WoW) for evaluating multi-source dialogue knowledge selection and response
generation. Unlike existing datasets, it contains clean support knowledge,
grounded at the utterance level and partitioned into multiple knowledge
sources. We further propose a new challenge, dialogue knowledge plug-and-play,
which aims to test an already trained dialogue model on using new support
knowledge from previously unseen sources in a zero-shot fashion.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03497" title="Abstract">arXiv:2403.03497</a> [<a href="/pdf/2403.03497" title="Download PDF">pdf</a>, <a href="/format/2403.03497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive coordination promotes collective cooperation in repeated social  dilemmas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Te Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Long Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Direct reciprocity based on the repeated prisoner's dilemma has been
intensively studied. Most theoretical investigations have concentrated on
memory-$1$ strategies, a class of elementary strategies just reacting to the
previous-round outcomes. Though the properties of "All-or-None" strategies
($AoN_K$) have been discovered, simulations just confirmed the good performance
of $AoN_K$ of very short memory lengths. It remains unclear how $AoN_K$
strategies would fare when players have access to longer rounds of history
information. We construct a theoretical model to investigate the performance of
the class of $AoN_K$ strategies of varying memory length $K$. We rigorously
derive the payoffs and show that $AoN_K$ strategies of intermediate memory
length $K$ are most prevalent, while strategies of larger memory lengths are
less competent. Larger memory lengths make it hard for $AoN_K$ strategies to
coordinate, and thus inhibiting their mutual reciprocity. We then propose the
adaptive coordination strategy combining tolerance and $AoN_K$' coordination
rule. This strategy behaves like $AoN_K$ strategy when coordination is not
sufficient, and tolerates opponents' occasional deviations by still cooperating
when coordination is sufficient. We found that the adaptive coordination
strategy wins over other classic memory-$1$ strategies in various typical
competition environments, and stabilizes the population at high levels of
cooperation, suggesting the effectiveness of high level adaptability in
resolving social dilemmas. Our work may offer a theoretical framework for
exploring complex strategies using history information, which are different
from traditional memory-$n$ strategies.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03499" title="Abstract">arXiv:2403.03499</a> [<a href="/pdf/2403.03499" title="Download PDF">pdf</a>, <a href="/format/2403.03499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNN-based End-to-End Adaptive Controller with Stability Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ryu%2C+M">Myeongseok Ryu</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+K">Kyunghwan Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, Submitted to IEEE L-CSS with CDC Option
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This letter proposes a convolutional neural network (CNN)-based adaptive
controller wtih three notable features: 1) it determines control input directly
from historical sensor data (in an end-to-end process); 2) it learns the
desired control policy during real-time implementation without using a
pretrained network (in an online adaptive manner); and 3) the asymptotic
tracking error convergence is proven during the learning process (to deliver a
stability guarantee). An adaptive law for learning the desired control policy
is derived using the gradient descent optimization method, and its stability is
analyzed based on the Lyapunov approach. A simulation study using a
control-affine nonlinear system demonstrated that the proposed controller
exhibits these features, and its performance can be tuned by manipulating the
design parameters. In addition, it is shown that the proposed controller has a
superior tracking performance to that of a deep neural network (DNN)-based
adaptive controller.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03501" title="Abstract">arXiv:2403.03501</a> [<a href="/pdf/2403.03501" title="Download PDF">pdf</a>, <a href="/format/2403.03501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Exponential Lower Bound for Telephone Broadcast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tale%2C+P">Prafullkumar Tale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Consider the Telephone Broadcast problem in which an input is a connected
graph $G$ on $n$ vertices, a source vertex $s \in V(G)$, and a positive integer
$t$. The objective is to decide whether there is a broadcast protocol from $s$
that ensures that all the vertices of $G$ get the message in at most $t$
rounds. We consider the broadcast protocol where, in a round, any node aware of
the message can forward it to at most one of its neighbors. As the number of
nodes aware of the message can at most double at each round, for a non-trivial
instance we have $n \le 2^t$. Hence, the brute force algorithm that checks all
the permutations of the vertices runs in time $2^{2^{\calO(t)}} \cdot
n^{\calO(1)}$. As our first result, we prove this simple algorithm is the best
possible in the following sense.
<br />Telephone Broadcast does not admit an algorithm running in time $2^{2^{o(t)}}
\cdot n^{\calO(1)}$, unless the \ETH\ fails.
<br />To the best of our knowledge, this is only the fourth example of \NP-Complete
problem that admits a double exponential lower bound when parameterized by the
solution size. It also resolves the question by Fomin, Fraigniaud, and Golovach
[WG 2023]. In the same article, the authors asked whether the problem is \FPT\
when parameterized by the feedback vertex set number of the graph. We answer
this question in the negative.
<br />Telephone Broadcast, when restricted to graphs of the feedback vertex number
one, and hence treewidth of two, is \NP-\complete.
<br />We find this a relatively rare example of problems that admit a
polynomial-time algorithm on trees but is \NP-\complete\ on graphs of treewidth
two.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03504" title="Abstract">arXiv:2403.03504</a> [<a href="/pdf/2403.03504" title="Download PDF">pdf</a>, <a href="/format/2403.03504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Visualization for Blockchain Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dietl%2C+M">Marcell Dietl</a>, 
<a href="/search/cs?searchtype=author&query=Gem%C3%BCnd%2C+A">Andre Gem&#xfc;nd</a>, 
<a href="/search/cs?searchtype=author&query=Oeltz%2C+D">Daniel Oeltz</a>, 
<a href="/search/cs?searchtype=author&query=Thiele%2C+F+M">Felix M. Thiele</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+C">Christian Werner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this report, we introduce a novel approach to visualize extremely large
graphs efficiently. Our method combines two force-directed algorithms,
Kamada-Kawai and ForceAtlas2, to handle different graph components based on
their node count. Additionally, we suggest utilizing the Fast Multipole method
to enhance the speed of ForceAtlas2. Although initially designed for analyzing
bitcoin transaction graphs, for which we present results here, this algorithm
can also be applied to other crypto currency transaction graphs or graphs from
diverse domains.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03505" title="Abstract">arXiv:2403.03505</a> [<a href="/pdf/2403.03505" title="Download PDF">pdf</a>, <a href="/format/2403.03505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Complete Variant of Spherical Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigatu%2C+H">Hassen Nigatu</a>, 
<a href="/search/cs?searchtype=author&query=Jihao%2C+L">Li Jihao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Gaokun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guodong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Huixu Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This study presents a systematic enumeration of spherical ($SO(3)$) type
parallel robots' variants using an analytical velocity-level approach. These
robots are known for their ability to perform arbitrary rotations around a
fixed point, making them suitable for numerous applications. Despite their
architectural diversity, existing research has predominantly approached them on
a case-by-case basis. This approach hinders the exploration of all possible
variants, thereby limiting the benefits derived from architectural diversity.
By employing a generalized analytical approach through the reciprocal screw
method, we systematically explore all the kinematic conditions for limbs
yielding $SO(3)$ motion.Consequently, all 73 possible types of non-redundant
limbs suitable for generating the target $SO(3)$ motion are identified. The
approach involves performing an in-depth algebraic motion-constraint analysis
and identifying common characteristics among different variants. This leads us
to systematically explore all 73 symmetric and 5256 asymmetric variants, which
in turn become a total of 5329, each potentially having different workspace
capability, stiffness performance, and dynamics. Hence, having all these
variants can facilitate the innovation of novel spherical robots and help us
easily find the best and optimal ones for our specific applications.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03506" title="Abstract">arXiv:2403.03506</a> [<a href="/pdf/2403.03506" title="Download PDF">pdf</a>, <a href="/format/2403.03506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid  Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zijie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+L">Lele Sha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sannyuya Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanliang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review; 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study explores the challenge of sentence-level AI-generated text
detection within human-AI collaborative hybrid texts. Existing studies of
AI-generated text detection for hybrid texts often rely on synthetic datasets.
These typically involve hybrid texts with a limited number of boundaries. We
contend that studies of detecting AI-generated content within hybrid texts
should cover different types of hybrid texts generated in realistic settings to
better inform real-world applications. Therefore, our study utilizes the
CoAuthor dataset, which includes diverse, realistic hybrid texts generated
through the collaboration between human writers and an intelligent writing
system in multi-turn interactions. We adopt a two-step, segmentation-based
pipeline: (i) detect segments within a given hybrid text where each segment
contains sentences of consistent authorship, and (ii) classify the authorship
of each identified segment. Our empirical findings highlight (1) detecting
AI-generated sentences in hybrid texts is overall a challenging task because
(1.1) human writers' selecting and even editing AI-generated sentences based on
personal preferences adds difficulty in identifying the authorship of segments;
(1.2) the frequent change of authorship between neighboring sentences within
the hybrid text creates difficulties for segment detectors in identifying
authorship-consistent segments; (1.3) the short length of text segments within
hybrid texts provides limited stylistic cues for reliable authorship
determination; (2) before embarking on the detection process, it is beneficial
to assess the average length of segments within the hybrid text. This
assessment aids in deciding whether (2.1) to employ a text segmentation-based
strategy for hybrid texts with longer segments, or (2.2) to adopt a direct
sentence-by-sentence classification strategy for those with shorter segments.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03507" title="Abstract">arXiv:2403.03507</a> [<a href="/pdf/2403.03507" title="Download PDF">pdf</a>, <a href="/format/2403.03507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiawei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Training Large Language Models (LLMs) presents significant memory challenges,
predominantly due to the growing size of weights and optimizer states. Common
memory-reduction approaches, such as low-rank adaptation (LoRA), add a
trainable low-rank matrix to the frozen pre-trained weight in each layer,
reducing trainable parameters and optimizer states. However, such approaches
typically underperform training with full-rank weights in both pre-training and
fine-tuning stages since they limit the parameter search to a low-rank subspace
and alter the training dynamics, and further, may require full-rank warm start.
In this work, we propose Gradient Low-Rank Projection (GaLore), a training
strategy that allows full-parameter learning but is more memory-efficient than
common low-rank adaptation methods such as LoRA. Our approach reduces memory
usage by up to 65.5% in optimizer states while maintaining both efficiency and
performance for pre-training on LLaMA 1B and 7B architectures with C4 dataset
with up to 19.7B tokens, and on fine-tuning RoBERTa on GLUE tasks. Our 8-bit
GaLore further reduces optimizer memory by up to 82.5% and total training
memory by 63.3%, compared to a BF16 baseline. Notably, we demonstrate, for the
first time, the feasibility of pre-training a 7B model on consumer GPUs with
24GB memory (e.g., NVIDIA RTX 4090) without model parallel, checkpointing, or
offloading strategies.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03508" title="Abstract">arXiv:2403.03508</a> [<a href="/pdf/2403.03508" title="Download PDF">pdf</a>, <a href="/format/2403.03508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing the Robustness of Time-series Forecasting Models with  CounterfacTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kj%C3%A6rnli%2C+H+H">H&#xe5;kon Hanisch Kj&#xe6;rnli</a>, 
<a href="/search/cs?searchtype=author&query=Mas-Ribas%2C+L">Lluis Mas-Ribas</a>, 
<a href="/search/cs?searchtype=author&query=Ashrafi%2C+A">Aida Ashrafi</a>, 
<a href="/search/cs?searchtype=author&query=Sizov%2C+G">Gleb Sizov</a>, 
<a href="/search/cs?searchtype=author&query=Langseth%2C+H">Helge Langseth</a>, 
<a href="/search/cs?searchtype=author&query=Gundersen%2C+O+E">Odd Erik Gundersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted. Code publicly available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A common issue for machine learning models applied to time-series forecasting
is the temporal evolution of the data distributions (i.e., concept drift).
Because most of the training data does not reflect such changes, the models
present poor performance on the new out-of-distribution scenarios and,
therefore, the impact of such events cannot be reliably anticipated ahead of
time. We present and publicly release CounterfacTS, a tool to probe the
robustness of deep learning models in time-series forecasting tasks via
counterfactuals. CounterfacTS has a user-friendly interface that allows the
user to visualize, compare and quantify time series data and their forecasts,
for a number of datasets and deep learning models. Furthermore, the user can
apply various transformations to the time series and explore the resulting
changes in the forecasts in an interpretable manner. Through example cases, we
illustrate how CounterfacTS can be used to i) identify the main features
characterizing and differentiating sets of time series, ii) assess how the
model performance depends on these characateristics, and iii) guide
transformations of the original time series to create counterfactuals with
desired properties for training and increasing the forecasting performance in
new regions of the data distribution. We discuss the importance of visualizing
and considering the location of the data in a projected feature space to
transform time-series and create effective counterfactuals for training the
models. Overall, CounterfacTS aids at creating counterfactuals to efficiently
explore the impact of hypothetical scenarios not covered by the original data
in time-series forecasting tasks.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03510" title="Abstract">arXiv:2403.03510</a> [<a href="/pdf/2403.03510" title="Download PDF">pdf</a>, <a href="/format/2403.03510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> METAMAT 01: A semi-analytic Solution for Benchmarking Wave Propagation  Simulations of homogeneous Absorbers in 1D/3D and 2D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schoder%2C+S">Stefan Schoder</a>, 
<a href="/search/cs?searchtype=author&query=Maurerlehner%2C+P">Paul Maurerlehner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Classical Physics (physics.class-ph)

</div>
<p class="mathjax">The development of acoustic simulation workflows in the time-domain
description is essential for predicting the sound of aeroacoustic or other
transient acoustic effects. A common practice for noise mitigation is using
absorbers. The modeling of these acoustic absorbers is typically provided in
the frequency domain. Several, methods established bridging this gap,
investigating methods to model absorber in the time domain. Therefore, this
short article, describes the analytic solution in time-domain for benchmarking
absorber simulations with infinite 1D, 2D, and 3D domains. Connected to the
analytic solution, a Matlab script is provided to easily obtain the reference
solution. The reference codes are provided as benchmark solution in the EAA
TCCA Benchmarking database as METAMAT 01.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03512" title="Abstract">arXiv:2403.03512</a> [<a href="/pdf/2403.03512" title="Download PDF">pdf</a>, <a href="/ps/2403.03512" title="Download PostScript">ps</a>, <a href="/format/2403.03512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dcl-Net: Dual Contrastive Learning Network for Semi-Supervised  Multi-Organ Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhenghao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yun Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiliu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised learning is a sound measure to relieve the strict demand of
abundant annotated datasets, especially for challenging multi-organ
segmentation . However, most existing SSL methods predict pixels in a single
image independently, ignoring the relations among images and categories. In
this paper, we propose a two-stage Dual Contrastive Learning Network for
semi-supervised MoS, which utilizes global and local contrastive learning to
strengthen the relations among images and classes. Concretely, in Stage 1, we
develop a similarity-guided global contrastive learning to explore the implicit
continuity and similarity among images and learn global context. Then, in Stage
2, we present an organ-aware local contrastive learning to further attract the
class representations. To ease the computation burden, we introduce a mask
center computation algorithm to compress the category representations for local
contrastive learning. Experiments conducted on the public 2017 ACDC dataset and
an in-house RC-OARs dataset has demonstrated the superior performance of our
method.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03514" title="Abstract">arXiv:2403.03514</a> [<a href="/pdf/2403.03514" title="Download PDF">pdf</a>, <a href="/format/2403.03514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLongEval: A Chinese Benchmark for Evaluating Long-Context Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zexuan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shijue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wanjun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Developing Large Language Models (LLMs) with robust long-context capabilities
has been the recent research focus, resulting in the emergence of long-context
LLMs proficient in Chinese. However, the evaluation of these models remains
underdeveloped due to a lack of benchmarks. To address this gap, we present
CLongEval, a comprehensive Chinese benchmark for evaluating long-context LLMs.
CLongEval is characterized by three key features: (1) Sufficient data volume,
comprising 7 distinct tasks and 7,267 examples; (2) Broad applicability,
accommodating to models with context windows size from 1K to 100K; (3) High
quality, with over 2,000 manually annotated question-answer pairs in addition
to the automatically constructed labels. With CLongEval, we undertake a
comprehensive assessment of 6 open-source long-context LLMs and 2 leading
commercial counterparts that feature both long-context abilities and
proficiency in Chinese. We also provide in-depth analysis based on the
empirical results, trying to shed light on the critical capabilities that
present challenges in long-context settings. The dataset, evaluation scripts,
and model outputs will be released.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03516" title="Abstract">arXiv:2403.03516</a> [<a href="/pdf/2403.03516" title="Download PDF">pdf</a>, <a href="/format/2403.03516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen-An Li</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+T">Tsu-Yuan Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chen-Yu Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun-Nung Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Dense retrieval methods have demonstrated promising performance in
multilingual information retrieval, where queries and documents can be in
different languages. However, dense retrievers typically require a substantial
amount of paired data, which poses even greater challenges in multilingual
scenarios. This paper introduces UMR, an Unsupervised Multilingual dense
Retriever trained without any paired data. Our approach leverages the sequence
likelihood estimation capabilities of multilingual language models to acquire
pseudo labels for training dense retrievers. We propose a two-stage framework
which iteratively improves the performance of multilingual dense retrievers.
Experimental results on two benchmark datasets show that UMR outperforms
supervised baselines, showcasing the potential of training multilingual
retrievers without paired data, thereby enhancing their practicality. Our
source code, data, and models are publicly available at
https://github.com/MiuLab/UMR
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03517" title="Abstract">arXiv:2403.03517</a> [<a href="/pdf/2403.03517" title="Download PDF">pdf</a>, <a href="/format/2403.03517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IB-Net: Initial Branch Network for Variable Decision in Boolean  Satisfiability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+T+H">Tsz Ho Chan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wenyi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junhua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+H">Huiling Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+G">Guangji Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingxuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Boolean Satisfiability problems are vital components in Electronic Design
Automation, particularly within the Logic Equivalence Checking process.
Currently, SAT solvers are employed for these problems and neural network is
tried as assistance to solvers. However, as SAT problems in the LEC context are
distinctive due to their predominantly unsatisfiability nature and a
substantial proportion of UNSAT-core variables, existing neural network
assistance has proven unsuccessful in this specialized domain. To tackle this
challenge, we propose IB-Net, an innovative framework utilizing graph neural
networks and novel graph encoding techniques to model unsatisfiable problems
and interact with state-of-the-art solvers. Extensive evaluations across
solvers and datasets demonstrate IB-Net's acceleration, achieving an average
runtime speedup of 5.0% on industrial data and 8.3% on SAT competition data
empirically. This breakthrough advances efficient solving in LEC workflows.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03521" title="Abstract">arXiv:2403.03521</a> [<a href="/pdf/2403.03521" title="Download PDF">pdf</a>, <a href="/format/2403.03521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherf%2C+C">Carinne Cherf</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural machine translation (NMT) has progressed rapidly in the past few
years, promising improvements and quality translations for different languages.
Evaluation of this task is crucial to determine the quality of the translation.
Overall, insufficient emphasis is placed on the actual sense of the translation
in traditional methods. We propose a bidirectional semantic-based evaluation
method designed to assess the sense distance of the translation from the source
text. This approach employs the comprehensive multilingual encyclopedic
dictionary BabelNet. Through the calculation of the semantic distance between
the source and its back translation of the output, our method introduces a
quantifiable approach that empowers sentence comparison on the same linguistic
level. Factual analysis shows a strong correlation between the average
evaluation scores generated by our method and the human assessments across
various machine translation systems for English-German language pair. Finally,
our method proposes a new multilingual approach to rank MT systems without the
need for parallel corpora.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03522" title="Abstract">arXiv:2403.03522</a> [<a href="/pdf/2403.03522" title="Download PDF">pdf</a>, <a href="/format/2403.03522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-verbal information in spontaneous speech - towards a new framework  of analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biron%2C+T">Tirza Biron</a>, 
<a href="/search/cs?searchtype=author&query=Barboy%2C+M">Moshe Barboy</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Artzy%2C+E">Eran Ben-Artzy</a>, 
<a href="/search/cs?searchtype=author&query=Golubchik%2C+A">Alona Golubchik</a>, 
<a href="/search/cs?searchtype=author&query=Marmor%2C+Y">Yanir Marmor</a>, 
<a href="/search/cs?searchtype=author&query=Szekely%2C+S">Smadar Szekely</a>, 
<a href="/search/cs?searchtype=author&query=Winter%2C+Y">Yaron Winter</a>, 
<a href="/search/cs?searchtype=author&query=Harel%2C+D">David Harel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Non-verbal signals in speech are encoded by prosody and carry information
that ranges from conversation action to attitude and emotion. Despite its
importance, the principles that govern prosodic structure are not yet
adequately understood. This paper offers an analytical schema and a
technological proof-of-concept for the categorization of prosodic signals and
their association with meaning. The schema interprets surface-representations
of multi-layered prosodic events. As a first step towards implementation, we
present a classification process that disentangles prosodic phenomena of three
orders. It relies on fine-tuning a pre-trained speech recognition model,
enabling the simultaneous multi-class/multi-label detection. It generalizes
over a large variety of spontaneous data, performing on a par with, or superior
to, human annotation. In addition to a standardized formalization of prosody,
disentangling prosodic patterns can direct a theory of communication and speech
organization. A welcome by-product is an interpretation of prosody that will
enhance speech- and language-related technologies.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03525" title="Abstract">arXiv:2403.03525</a> [<a href="/pdf/2403.03525" title="Download PDF">pdf</a>, <a href="/ps/2403.03525" title="Download PostScript">ps</a>, <a href="/format/2403.03525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploratory Factory Analysis of the Centrality Metrics for Complex  Real-World Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meghanathan%2C+N">Natarajan Meghanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Exploratory factor analysis (EFA) is useful to identify the number and
mapping of the hidden factors that could dominantly represent the features in
the dataset. Principal component analysis (PCA) is the first step as part of
the two-step procedure to conduct EFA, with the number of dominant principal
components being the number of hidden factors and the entries for the features
in the corresponding Eigenvectors serve as the initial values of the factor
loadings. In this paper, we conduct EFA on a suite of 80 complex network
datasets to identify the number and mapping of the hidden factors (expected to
be less than four) that could dominantly represent the values incurred by the
vertices with respect to the four major centrality metrics (degree: DEG,
eigenvector: EVC, betweenness: BWC and closeness: CLC).
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03530" title="Abstract">arXiv:2403.03530</a> [<a href="/pdf/2403.03530" title="Download PDF">pdf</a>, <a href="/format/2403.03530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average-case deterministic query complexity of boolean functions with  fixed weight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haowei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We explore the $\textit{average-case deterministic query complexity}$ of
boolean functions under the $\textit{uniform distribution}$, denoted by
$\mathrm{D}_\mathrm{ave}(f)$, the minimum average depth of zero-error decision
tree computing a boolean function $f$. This measure found several applications
across diverse fields. We study $\mathrm{D}_\mathrm{ave}(f)$ of several common
functions, including penalty shoot-out functions, symmetric functions, linear
threshold functions and tribes functions. Let $\mathrm{wt}(f)$ denote the
number of the inputs on which $f$ outputs $1$. We prove that
$\mathrm{D}_\mathrm{ave}(f) \le \log \frac{\mathrm{wt}(f)}{\log n} +
O\left(\log \log \frac{\mathrm{wt}(f)}{\log n}\right)$ when $\mathrm{wt}(f) \ge
4 \log n$ (otherwise, $\mathrm{D}_\mathrm{ave}(f) = O(1)$), and that for almost
all fixed-weight functions, $\mathrm{D}_\mathrm{ave}(f) \geq \log
\frac{\mathrm{wt}(f)}{\log n} - O\left( \log \log \frac{\mathrm{wt}(f)}{\log
n}\right)$, which implies the tightness of the upper bound up to an additive
logarithmic term. We also study $\mathrm{D}_\mathrm{ave}(f)$ of circuits. Using
H\r{a}stad's switching lemma or Rossman's switching lemma [Comput. Complexity
Conf. 137, 2019], one can derive upper bounds $\mathrm{D}_\mathrm{ave}(f) \leq
n\left(1 - \frac{1}{O(k)}\right)$ for width-$k$ CNFs/DNFs and
$\mathrm{D}_\mathrm{ave}(f) \leq n\left(1 - \frac{1}{O(\log s)}\right)$ for
size-$s$ CNFs/DNFs, respectively. For any $w \ge 1.1 \log n$, we prove the
existence of some width-$w$ size-$(2^w/w)$ DNF formula with
$\mathrm{D}_\mathrm{ave} (f) = n \left(1 - \frac{\log n}{\Theta(w)}\right)$,
providing evidence on the tightness of the switching lemmas.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03532" title="Abstract">arXiv:2403.03532</a> [<a href="/pdf/2403.03532" title="Download PDF">pdf</a>, <a href="/format/2403.03532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extend Your Own Correspondences: Unsupervised Distant Point Cloud  Registration by Progressive Distance Extension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Quan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongzi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yunsong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minyi Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Registration of point clouds collected from a pair of distant vehicles
provides a comprehensive and accurate 3D view of the driving scenario, which is
vital for driving safety related applications, yet existing literature suffers
from the expensive pose label acquisition and the deficiency to generalize to
new data distributions. In this paper, we propose EYOC, an unsupervised distant
point cloud registration method that adapts to new point cloud distributions on
the fly, requiring no global pose labels. The core idea of EYOC is to train a
feature extractor in a progressive fashion, where in each round, the feature
extractor, trained with near point cloud pairs, can label slightly farther
point cloud pairs, enabling self-supervision on such far point cloud pairs.
This process continues until the derived extractor can be used to register
distant point clouds. Particularly, to enable high-fidelity correspondence
label generation, we devise an effective spatial filtering scheme to select the
most representative correspondences to register a point cloud pair, and then
utilize the aligned point clouds to discover more correct correspondences.
Experiments show that EYOC can achieve comparable performance with
state-of-the-art supervised methods at a lower training cost. Moreover, it
outwits supervised methods regarding generalization performance on new data
distributions.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03535" title="Abstract">arXiv:2403.03535</a> [<a href="/pdf/2403.03535" title="Download PDF">pdf</a>, <a href="/format/2403.03535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Attribute Distance for Few-Shot Learning: Theoretical Analysis and  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Minyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Bingpeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguan Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xilin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Few-shot learning (FSL) aims to learn novel tasks with very few labeled
samples by leveraging experience from \emph{related} training tasks. In this
paper, we try to understand FSL by delving into two key questions: (1) How to
quantify the relationship between \emph{training} and \emph{novel} tasks? (2)
How does the relationship affect the \emph{adaptation difficulty} on novel
tasks for different models? To answer the two questions, we introduce Task
Attribute Distance (TAD) built upon attributes as a metric to quantify the task
relatedness. Unlike many existing metrics, TAD is model-agnostic, making it
applicable to different FSL models. Then, we utilize TAD metric to establish a
theoretical connection between task relatedness and task adaptation difficulty.
By deriving the generalization error bound on a novel task, we discover how TAD
measures the adaptation difficulty on novel tasks for FSL models. To validate
our TAD metric and theoretical findings, we conduct experiments on three
benchmarks. Our experimental results confirm that TAD metric effectively
quantifies the task relatedness and reflects the adaptation difficulty on novel
tasks for various FSL methods, even if some of them do not learn attributes
explicitly or human-annotated attributes are not available. Finally, we present
two applications of the proposed TAD metric: data augmentation and test-time
intervention, which further verify its effectiveness and general applicability.
The source code is available at https://github.com/hu-my/TaskAttributeDistance.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03536" title="Abstract">arXiv:2403.03536</a> [<a href="/pdf/2403.03536" title="Download PDF">pdf</a>, <a href="/format/2403.03536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Effective Unlearning of Large Language Models for  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The significant advancements in large language models (LLMs) give rise to a
promising research direction, i.e., leveraging LLMs as recommenders (LLMRec).
The efficacy of LLMRec arises from the open-world knowledge and reasoning
capabilities inherent in LLMs. LLMRec acquires the recommendation capabilities
through instruction tuning based on user interaction data. However, in order to
protect user privacy and optimize utility, it is also crucial for LLMRec to
intentionally forget specific user data, which is generally referred to as
recommendation unlearning. In the era of LLMs, recommendation unlearning poses
new challenges for LLMRec in terms of \textit{inefficiency} and
\textit{ineffectiveness}. Existing unlearning methods require updating billions
of parameters in LLMRec, which is costly and time-consuming. Besides, they
always impact the model utility during the unlearning process. To this end, we
propose \textbf{E2URec}, the first \underline{E}fficient and
\underline{E}ffective \underline{U}nlearning method for LLM\underline{Rec}. Our
proposed E2URec enhances the unlearning efficiency by updating only a few
additional LoRA parameters, and improves the unlearning effectiveness by
employing a teacher-student framework, where we maintain multiple teacher
networks to guide the unlearning process. Extensive experiments show that
E2URec outperforms state-of-the-art baselines on two real-world datasets.
Specifically, E2URec can efficiently forget specific data without affecting
recommendation performance. The source code is at
\url{https://github.com/justarter/E2URec}.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03537" title="Abstract">arXiv:2403.03537</a> [<a href="/pdf/2403.03537" title="Download PDF">pdf</a>, <a href="/format/2403.03537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Second-Order Asymptotics of the Hoeffding Test and Other  Divergence Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harsha%2C+K+V">K. V. Harsha</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+J">Jithin Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+T">Tobias Koch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Consider a binary statistical hypothesis testing problem, where $n$
independent and identically distributed random variables $Z^n$ are either
distributed according to the null hypothesis $P$ or the alternative hypothesis
$Q$, and only $P$ is known. A well-known test that is suitable for this case is
the so-called Hoeffding test, which accepts $P$ if the Kullback-Leibler (KL)
divergence between the empirical distribution of $Z^n$ and $P$ is below some
threshold. This work characterizes the first and second-order terms of the
type-II error probability for a fixed type-I error probability for the
Hoeffding test as well as for divergence tests, where the KL divergence is
replaced by a general divergence. It is demonstrated that, irrespective of the
divergence, divergence tests achieve the first-order term of the Neyman-Pearson
test, which is the optimal test when both $P$ and $Q$ are known. In contrast,
the second-order term of divergence tests is strictly worse than that of the
Neyman-Pearson test. It is further demonstrated that divergence tests with an
invariant divergence achieve the same second-order term as the Hoeffding test,
but divergence tests with a non-invariant divergence may outperform the
Hoeffding test for some alternative hypotheses $Q$. Potentially, this behavior
could be exploited by a composite hypothesis test with partial knowledge of the
alternative hypothesis $Q$ by tailoring the divergence of the divergence test
to the set of possible alternative hypotheses.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03538" title="Abstract">arXiv:2403.03538</a> [<a href="/pdf/2403.03538" title="Download PDF">pdf</a>, <a href="/format/2403.03538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RADIA -- Radio Advertisement Detection with Intelligent Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%81lvarez%2C+J">Jorge &#xc1;lvarez</a>, 
<a href="/search/cs?searchtype=author&query=Armenteros%2C+J+C">Juan Carlos Armenteros</a>, 
<a href="/search/cs?searchtype=author&query=Torr%C3%B3n%2C+C">Camilo Torr&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Ortega-Mart%C3%ADn%2C+M">Miguel Ortega-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Ardoiz%2C+A">Alfonso Ardoiz</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+%C3%93">&#xd3;scar Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Arranz%2C+I">Ignacio Arranz</a>, 
<a href="/search/cs?searchtype=author&query=Galdeano%2C+%C3%8D">&#xcd;&#xf1;igo Galdeano</a>, 
<a href="/search/cs?searchtype=author&query=Garrido%2C+I">Ignacio Garrido</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+A">Adri&#xe1;n Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Bay%C3%B3n%2C+F">Fernando Bay&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Vorontsov%2C+O">Oleg Vorontsov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Radio advertising remains an integral part of modern marketing strategies,
with its appeal and potential for targeted reach undeniably effective. However,
the dynamic nature of radio airtime and the rising trend of multiple radio
spots necessitates an efficient system for monitoring advertisement broadcasts.
This study investigates a novel automated radio advertisement detection
technique incorporating advanced speech recognition and text classification
algorithms. RadIA's approach surpasses traditional methods by eliminating the
need for prior knowledge of the broadcast content. This contribution allows for
detecting impromptu and newly introduced advertisements, providing a
comprehensive solution for advertisement detection in radio broadcasting.
Experimental results show that the resulting model, trained on carefully
segmented and tagged text data, achieves an F1-macro score of 87.76 against a
theoretical maximum of 89.33. This paper provides insights into the choice of
hyperparameters and their impact on the model's performance. This study
demonstrates its potential to ensure compliance with advertising broadcast
contracts and offer competitive surveillance. This groundbreaking research
could fundamentally change how radio advertising is monitored and open new
doors for marketing optimization.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03541" title="Abstract">arXiv:2403.03541</a> [<a href="/pdf/2403.03541" title="Download PDF">pdf</a>, <a href="/format/2403.03541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seamless Virtual Reality with Integrated Synchronizer and Synthesizer  for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">He Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Ruihua Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Q">Qi Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Virtual reality (VR) is a promising data engine for autonomous driving (AD).
However, data fidelity in this paradigm is often degraded by VR inconsistency,
for which the existing VR approaches become ineffective, as they ignore the
inter-dependency between low-level VR synchronizer designs (i.e., data
collector) and high-level VR synthesizer designs (i.e., data processor). This
paper presents a seamless virtual reality SVR platform for AD, which mitigates
such inconsistency, enabling VR agents to interact with each other in a shared
symbiotic world. The crux to SVR is an integrated synchronizer and synthesizer
IS2 design, which consists of a drift-aware lidar-inertial synchronizer for VR
colocation and a motion-aware deep visual synthesis network for augmented
reality image generation. We implement SVR on car-like robots in two sandbox
platforms, achieving a cm-level VR colocalization accuracy and 3.2% VR image
deviation, thereby avoiding missed collisions or model clippings. Experiments
show that the proposed SVR reduces the intervention times, missed turns, and
failure rates compared to other benchmarks. The SVR-trained neural network can
handle unseen situations in real-world environments, by leveraging its
knowledge learnt from the VR space.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03542" title="Abstract">arXiv:2403.03542</a> [<a href="/pdf/2403.03542" title="Download PDF">pdf</a>, <a href="/format/2403.03542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE  Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhongkai Hao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Berner%2C+J">Julius Berner</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+C">Chengyang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jian Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Pre-training has been investigated to improve the efficiency and performance
of training neural operators in data-scarce settings. However, it is largely in
its infancy due to the inherent complexity and diversity, such as long
trajectories, multiple scales and varying dimensions of partial differential
equations (PDEs) data. In this paper, we present a new auto-regressive
denoising pre-training strategy, which allows for more stable and efficient
pre-training on PDE data and generalizes to various downstream tasks. Moreover,
by designing a flexible and scalable model architecture based on Fourier
attention, we can easily scale up the model for large-scale pre-training. We
train our PDE foundation model with up to 0.5B parameters on 10+ PDE datasets
with more than 100k trajectories. Extensive experiments show that we achieve
SOTA on these benchmarks and validate the strong generalizability of our model
to significantly enhance performance on diverse downstream PDE tasks like 3D
data. Code is available at \url{https://github.com/thu-ml/DPOT}.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03544" title="Abstract">arXiv:2403.03544</a> [<a href="/pdf/2403.03544" title="Download PDF">pdf</a>, <a href="/format/2403.03544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Mining for Language-based Human Mobility Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tianye Tang</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With the advancement of large language models, language-based forecasting has
recently emerged as an innovative approach for predicting human mobility
patterns. The core idea is to use prompts to transform the raw mobility data
given as numerical values into natural language sentences so that the language
models can be leveraged to generate the description for future observations.
However, previous studies have only employed fixed and manually designed
templates to transform numerical values into sentences. Since the forecasting
performance of language models heavily relies on prompts, using fixed templates
for prompting may limit the forecasting capability of language models. In this
paper, we propose a novel framework for prompt mining in language-based
mobility forecasting, aiming to explore diverse prompt design strategies.
Specifically, the framework includes a prompt generation stage based on the
information entropy of prompts and a prompt refinement stage to integrate
mechanisms such as the chain of thought. Experimental results on real-world
large-scale data demonstrate the superiority of generated prompts from our
prompt mining pipeline. Additionally, the comparison of different prompt
variants shows that the proposed prompt refinement process is effective. Our
study presents a promising direction for further advancing language-based
mobility forecasting.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03550" title="Abstract">arXiv:2403.03550</a> [<a href="/pdf/2403.03550" title="Download PDF">pdf</a>, <a href="/ps/2403.03550" title="Download PostScript">ps</a>, <a href="/format/2403.03550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotional Manipulation Through Prompt Engineering Amplifies  Disinformation Generation in AI Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vinay%2C+R">Rasita Vinay</a>, 
<a href="/search/cs?searchtype=author&query=Spitale%2C+G">Giovanni Spitale</a>, 
<a href="/search/cs?searchtype=author&query=Biller-Andorno%2C+N">Nikola Biller-Andorno</a>, 
<a href="/search/cs?searchtype=author&query=Germani%2C+F">Federico Germani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This study investigates the generation of synthetic disinformation by
OpenAI's Large Language Models (LLMs) through prompt engineering and explores
their responsiveness to emotional prompting. Leveraging various LLM iterations
using davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed
experiments to assess their success in producing disinformation. Our findings,
based on a corpus of 19,800 synthetic disinformation social media posts, reveal
that all LLMs by OpenAI can successfully produce disinformation, and that they
effectively respond to emotional prompting, indicating their nuanced
understanding of emotional cues in text generation. When prompted politely, all
examined LLMs consistently generate disinformation at a high frequency.
Conversely, when prompted impolitely, the frequency of disinformation
production diminishes, as the models often refuse to generate disinformation
and instead caution users that the tool is not intended for such purposes. This
research contributes to the ongoing discourse surrounding responsible
development and application of AI technologies, particularly in mitigating the
spread of disinformation and promoting transparency in AI-generated content.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03552" title="Abstract">arXiv:2403.03552</a> [<a href="/pdf/2403.03552" title="Download PDF">pdf</a>, <a href="/format/2403.03552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Population-aware Online Mirror Descent for Mean-Field Games by Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zida Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lauriere%2C+M">Mathieu Lauriere</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+S+J+C">Samuel Jia Cong Chua</a>, 
<a href="/search/cs?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/cs?searchtype=author&query=Pietquin%2C+O">Olivier Pietquin</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Ankur Mehta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">Mean Field Games (MFGs) have the ability to handle large-scale multi-agent
systems, but learning Nash equilibria in MFGs remains a challenging task. In
this paper, we propose a deep reinforcement learning (DRL) algorithm that
achieves population-dependent Nash equilibrium without the need for averaging
or sampling from history, inspired by Munchausen RL and Online Mirror Descent.
Through the design of an additional inner-loop replay buffer, the agents can
effectively learn to achieve Nash equilibrium from any distribution, mitigating
catastrophic forgetting. The resulting policy can be applied to various initial
distributions. Numerical experiments on four canonical examples demonstrate our
algorithm has better convergence properties than SOTA algorithms, in particular
a DRL version of Fictitious Play for population-dependent policies.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03555" title="Abstract">arXiv:2403.03555</a> [<a href="/pdf/2403.03555" title="Download PDF">pdf</a>, <a href="/ps/2403.03555" title="Download PostScript">ps</a>, <a href="/format/2403.03555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Nash equilibrium for developing an optimal forest  harvesting strategy in Toru&#x144; Forest District
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotlarz%2C+J">Jan Kotlarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This study investigates the application of Nash equilibrium strategies in
optimizing forest harvesting decisions, focusing on multiple management
objectives in forestry. Through simulation-based analysis, the research
explores the evolution of various indicators during the game: 1) the mass of
CO2 sequestration, 2) forest stands biodiversity, 3) the harvested wood volume,
4) native species fraction, and 5) protective functions. The results underscore
the importance of considering diverse objectives and balancing competing
interests in forestry decision processes. The forest stands designated for
harvesting in the Toru\'n Forest District were defined as the initial strategy,
and indicators for all objectives were calculated accordingly. A Nash
equilibrium was identified through a game involving five players representing
individual objectives with partially conflicting aims. The final strategy was
obtained by modifying specific forest stands designated for harvesting, thereby
maintaining the planned wood volume extraction while simultaneously reducing
biodiversity loss by nearly 40%, preserving protective functions across over
600 hectares of forested areas, enhancing decadal carbon sequestration in the
forest district by 100,000 tons, and additionally improving species suitability
by nearly 10%. The findings suggest the potential for further research and
refinement of Nash equilibrium-based optimization approaches to enhance the
effectiveness and sustainability of forest management practices.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03557" title="Abstract">arXiv:2403.03557</a> [<a href="/pdf/2403.03557" title="Download PDF">pdf</a>, <a href="/format/2403.03557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An IDE Plugin for Gamified Continuous Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straubinger%2C+P">Philipp Straubinger</a>, 
<a href="/search/cs?searchtype=author&query=Fraser%2C+G">Gordon Fraser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Interruptions and context switches resulting from meetings, urgent tasks,
emails, and queries from colleagues contribute to productivity losses in
developers' daily routines. This is particularly challenging for tasks like
software testing, which are already perceived as less enjoyable, prompting
developers to seek distractions. To mitigate this, applying gamification to
testing activities can enhance motivation for test writing. One such
gamification tool is Gamekins, which integrates challenges, quests,
achievements, and leaderboards into the Jenkins CI (continuous integration)
platform. However, as Gamekins is typically accessed through a browser, it
introduces a context switch. This paper presents an IntelliJ plugin designed to
seamlessly integrate Gamekins' gamification elements into the IDE, aiming to
minimize context switches and boost developer motivation for test writing.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03558" title="Abstract">arXiv:2403.03558</a> [<a href="/pdf/2403.03558" title="Download PDF">pdf</a>, <a href="/format/2403.03558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Hallucination in Large Language Models based on  Unanswerable Math Word Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuhong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qipeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiawen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, accepted by LREC-Coling 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are highly effective in various natural language
processing (NLP) tasks. However, they are susceptible to producing unreliable
conjectures in ambiguous contexts called hallucination. This paper presents a
new method for evaluating LLM hallucination in Question Answering (QA) based on
the unanswerable math word problem (MWP). To support this approach, we
innovatively develop a dataset called Unanswerable Math Word Problem (UMWP)
which comprises 5200 questions across five categories. We developed an
evaluation methodology combining text similarity and mathematical expression
detection to determine whether LLM considers the question unanswerable. The
results of extensive experiments conducted on 31 LLMs, including GPT-3,
InstructGPT, LLaMA, and Claude, demonstrate that in-context learning and
reinforcement learning with human feedback (RLHF) training significantly
enhance the model's ability to avoid hallucination. We show that utilizing MWP
is a reliable and effective approach to assess hallucination. Our code and data
are available at https://github.com/Yuki-Asuuna/UMWP.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03561" title="Abstract">arXiv:2403.03561</a> [<a href="/pdf/2403.03561" title="Download PDF">pdf</a>, <a href="/ps/2403.03561" title="Download PostScript">ps</a>, <a href="/format/2403.03561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HMD-Poser: On-Device Real-time Human Motion Tracking from Scalable  Sparse Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+P">Peng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianyuan Du</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaozheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR2024 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It is especially challenging to achieve real-time human motion tracking on a
standalone VR Head-Mounted Display (HMD) such as Meta Quest and PICO. In this
paper, we propose HMD-Poser, the first unified approach to recover full-body
motions using scalable sparse observations from HMD and body-worn IMUs. In
particular, it can support a variety of input scenarios, such as HMD,
HMD+2IMUs, HMD+3IMUs, etc. The scalability of inputs may accommodate users'
choices for both high tracking accuracy and easy-to-wear. A lightweight
temporal-spatial feature learning network is proposed in HMD-Poser to guarantee
that the model runs in real-time on HMDs. Furthermore, HMD-Poser presents
online body shape estimation to improve the position accuracy of body joints.
Extensive experimental results on the challenging AMASS dataset show that
HMD-Poser achieves new state-of-the-art results in both accuracy and real-time
performance. We also build a new free-dancing motion dataset to evaluate
HMD-Poser's on-device performance and investigate the performance gap between
synthetic data and real-captured sensor data. Finally, we demonstrate our
HMD-Poser with a real-time Avatar-driving application on a commercial HMD. Our
code and free-dancing motion dataset are available
https://pico-ai-team.github.io/hmd-poser
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03562" title="Abstract">arXiv:2403.03562</a> [<a href="/pdf/2403.03562" title="Download PDF">pdf</a>, <a href="/format/2403.03562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithms for Empirical Group Distributional Robust  Optimization and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dingzhi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yunuo Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We investigate the empirical counterpart of group distributionally robust
optimization (GDRO), which aims to minimize the maximal empirical risk across
$m$ distinct groups. We formulate empirical GDRO as a $\textit{two-level}$
finite-sum convex-concave minimax optimization problem and develop a stochastic
variance reduced mirror prox algorithm. Unlike existing methods, we construct
the stochastic gradient by per-group sampling technique and perform variance
reduction for all groups, which fully exploits the $\textit{two-level}$
finite-sum structure of empirical GDRO. Furthermore, we compute the snapshot
and mirror snapshot point by a one-index-shifted weighted average, which
distinguishes us from the naive ergodic average. Our algorithm also supports
non-constant learning rates, which is different from existing literature. We
establish convergence guarantees both in expectation and with high probability,
demonstrating a complexity of
$\mathcal{O}\left(\frac{m\sqrt{\bar{n}\ln{m}}}{\varepsilon}\right)$, where
$\bar n$ is the average number of samples among $m$ groups. Remarkably, our
approach outperforms the state-of-the-art method by a factor of $\sqrt{m}$.
Furthermore, we extend our methodology to deal with the empirical minimax
excess risk optimization (MERO) problem and manage to give the expectation
bound and the high probability bound, accordingly. The complexity of our
empirical MERO algorithm matches that of empirical GDRO at
$\mathcal{O}\left(\frac{m\sqrt{\bar{n}\ln{m}}}{\varepsilon}\right)$,
significantly surpassing the bounds of existing methods.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03563" title="Abstract">arXiv:2403.03563</a> [<a href="/pdf/2403.03563" title="Download PDF">pdf</a>, <a href="/format/2403.03563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Anomaly Detection based on Deep Auto-Encoder for Object Slip  Perception of Mobile Manipulation Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+Y">Youngjae Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chung-Yeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Byoung-Tak Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Object slip perception is essential for mobile manipulation robots to perform
manipulation tasks reliably in the dynamic real-world. Traditional approaches
to robot arms' slip perception use tactile or vision sensors. However, mobile
robots still have to deal with noise in their sensor signals caused by the
robot's movement in a changing environment. To solve this problem, we present
an anomaly detection method that utilizes multisensory data based on a deep
autoencoder model. The proposed framework integrates heterogeneous data streams
collected from various robot sensors, including RGB and depth cameras, a
microphone, and a force-torque sensor. The integrated data is used to train a
deep autoencoder to construct latent representations of the multisensory data
that indicate the normal status. Anomalies can then be identified by error
scores measured by the difference between the trained encoder's latent values
and the latent values of reconstructed input data. In order to evaluate the
proposed framework, we conducted an experiment that mimics an object slip by a
mobile service robot operating in a real-world environment with diverse
household objects and different moving patterns. The experimental results
verified that the proposed framework reliably detects anomalies in object slip
situations despite various object types and robot behaviors, and visual and
auditory noise in the environment.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03565" title="Abstract">arXiv:2403.03565</a> [<a href="/pdf/2403.03565" title="Download PDF">pdf</a>, <a href="/format/2403.03565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IntelliGame in Action: An Experience Report on Gamifying JavaScript Unit  Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straubinger%2C+P">Philipp Straubinger</a>, 
<a href="/search/cs?searchtype=author&query=Fulcini%2C+T">Tommaso Fulcini</a>, 
<a href="/search/cs?searchtype=author&query=Fraser%2C+G">Gordon Fraser</a>, 
<a href="/search/cs?searchtype=author&query=Torchiano%2C+M">Marco Torchiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper investigates the integration and assessment of IntelliGame, a
gamification plugin initially designed for Java development, within the realm
of JavaScript unit testing. We aim to verify the generalizability of
IntelliGame to JavaScript development and to provide valuable insights into the
experiment's design. For this, we first customize IntelliGame for JavaScript,
and then conduct a controlled experiment involving 152 participants utilizing
the Jest testing framework, and finally examine its influence on testing
behavior and the overall developer experience. The findings from this study
provide valuable insights for improving JavaScript testing methodologies
through the incorporation of gamification.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03569" title="Abstract">arXiv:2403.03569</a> [<a href="/pdf/2403.03569" title="Download PDF">pdf</a>, <a href="/format/2403.03569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Transfer in Classification: How Well do Subsets of Classes  Generalize?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baena%2C+R">Raphael Baena</a>, 
<a href="/search/cs?searchtype=author&query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="/search/cs?searchtype=author&query=Gripon%2C+V">Vincent Gripon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In classification, it is usual to observe that models trained on a given set
of classes can generalize to previously unseen ones, suggesting the ability to
learn beyond the initial task. This ability is often leveraged in the context
of transfer learning where a pretrained model can be used to process new
classes, with or without fine tuning. Surprisingly, there are a few papers
looking at the theoretical roots beyond this phenomenon. In this work, we are
interested in laying the foundations of such a theoretical framework for
transferability between sets of classes. Namely, we establish a partially
ordered set of subsets of classes. This tool allows to represent which subset
of classes can generalize to others. In a more practical setting, we explore
the ability of our framework to predict which subset of classes can lead to the
best performance when testing on all of them. We also explore few-shot
learning, where transfer is the golden standard. Our work contributes to better
understanding of transfer mechanics and model generalization.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03573" title="Abstract">arXiv:2403.03573</a> [<a href="/pdf/2403.03573" title="Download PDF">pdf</a>, <a href="/format/2403.03573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-optimal Point-to-point Motion Planning: A Two-stage Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Swevers%2C+J">Jan Swevers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper proposes a two-stage approach to formulate the time-optimal
point-to-point motion planning problem, involving a first stage with a fixed
time grid and a second stage with a variable time grid. The proposed approach
brings benefits through its straightforward optimal control problem formulation
with a fixed and low number of control steps for manageable computational
complexity and the avoidance of interpolation errors associated with time
scaling, especially when aiming to reach a distant goal. Additionally, an
asynchronous nonlinear model predictive control (NMPC) update scheme is
integrated with this two-stage approach to address delayed and fluctuating
computation times, facilitating online replanning. The effectiveness of the
proposed two-stage approach and NMPC implementation is demonstrated through
numerical examples centered on autonomous navigation with collision avoidance.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03575" title="Abstract">arXiv:2403.03575</a> [<a href="/pdf/2403.03575" title="Download PDF">pdf</a>, <a href="/format/2403.03575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> gaHealth: An English-Irish Bilingual Corpus of Health Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Loinsigh%2C+%C3%93+N">&#xd3;rla N&#xed; Loinsigh</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2403.02367">arXiv:2403.02367</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the Thirteenth Language Resources and Evaluation
  Conference, pages 6753-6758, Marseille, France. European Language Resources
  Association, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine Translation is a mature technology for many high-resource language
pairs. However in the context of low-resource languages, there is a paucity of
parallel data datasets available for developing translation models.
Furthermore, the development of datasets for low-resource languages often
focuses on simply creating the largest possible dataset for generic
translation. The benefits and development of smaller in-domain datasets can
easily be overlooked. To assess the merits of using in-domain data, a dataset
for the specific domain of health was developed for the low-resource English to
Irish language pair. Our study outlines the process used in developing the
corpus and empirically demonstrates the benefits of using an in-domain dataset
for the health domain. In the context of translating health-related data,
models developed using the gaHealth corpus demonstrated a maximum BLEU score
improvement of 22.2 points (40%) when compared with top performing models from
the LoResMT2021 Shared Task. Furthermore, we define linguistic guidelines for
developing gaHealth, the first bilingual corpus of health data for the Irish
language, which we hope will be of use to other creators of low-resource data
sets. gaHealth is now freely available online and is ready to be explored for
further research.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03576" title="Abstract">arXiv:2403.03576</a> [<a href="/pdf/2403.03576" title="Download PDF">pdf</a>, <a href="/format/2403.03576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Incremental Learning with Dual Concept Drift Detection for  Identifying Anomalous Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Malialis%2C+K">Kleanthis Malialis</a>, 
<a href="/search/cs?searchtype=author&query=Polycarpou%2C+M+M">Marios M. Polycarpou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IJCNN2024,under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In the contemporary digital landscape, the continuous generation of extensive
streaming data across diverse domains has become pervasive. Yet, a significant
portion of this data remains unlabeled, posing a challenge in identifying
infrequent events such as anomalies. This challenge is further amplified in
non-stationary environments, where the performance of models can degrade over
time due to concept drift. To address these challenges, this paper introduces a
new method referred to as VAE4AS (Variational Autoencoder for Anomalous
Sequences). VAE4AS integrates incremental learning with dual drift detection
mechanisms, employing both a statistical test and a distance-based test. The
anomaly detection is facilitated by a Variational Autoencoder. To gauge the
effectiveness of VAE4AS, a comprehensive experimental study is conducted using
real-world and synthetic datasets characterized by anomalous rates below 10\%
and recurrent drift. The results show that the proposed method surpasses both
robust baselines and state-of-the-art techniques, providing compelling evidence
for their efficacy in effectively addressing some of the challenges associated
with anomalous sequence detection in non-stationary streaming data.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03577" title="Abstract">arXiv:2403.03577</a> [<a href="/pdf/2403.03577" title="Download PDF">pdf</a>, <a href="/ps/2403.03577" title="Download PostScript">ps</a>, <a href="/format/2403.03577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deployable polyhedrons with one-DOF radial transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuanqing Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deployable polyhedrons can transform between Platonic and Archimedean
polyhedrons to meet the demands of various engineering applications. However,
the existing design solutions are often with multiple degrees of freedom and
complicated mechanism links and joints, which greatly limited their potential
in practice. Combining the fundamentals of solid geometry and mechanism
kinematics, this paper proposes a family of kirigami Archimedean polyhedrons
based on the N-fold-symmetric loops of spatial 7R linkage, which perform
one-DOF radial transformation following tetrahedral, octahedral, or icosahedral
symmetry. Moreover, in each symmetric polyhedral group, three different
transforming paths can be achieved from one identical deployed configuration.
We also demonstrated that such design strategy can be readily applied to
polyhedral tessellation. This work provides a family of rich solutions for
deployable polyhedrons to facilitate their applications in aerospace
exploration, architecture, metamaterials and so on.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03578" title="Abstract">arXiv:2403.03578</a> [<a href="/pdf/2403.03578" title="Download PDF">pdf</a>, <a href="/format/2403.03578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Disentanglement for Regulating Social Influence Bias in Social  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quangui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yunxiao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Social recommendation systems face the problem of social influence bias,
which can lead to an overemphasis on recommending items that friends have
interacted with. Addressing this problem is crucial, and existing methods often
rely on techniques such as weight adjustment or leveraging unbiased data to
eliminate this bias. However, we argue that not all biases are detrimental,
i.e., some items recommended by friends may align with the user's interests.
Blindly eliminating such biases could undermine these positive effects,
potentially diminishing recommendation accuracy. In this paper, we propose a
Causal Disentanglement-based framework for Regulating Social influence Bias in
social recommendation, named CDRSB, to improve recommendation performance. From
the perspective of causal inference, we find that the user social network could
be regarded as a confounder between the user and item embeddings (treatment)
and ratings (outcome). Due to the presence of this social network confounder,
two paths exist from user and item embeddings to ratings: a non-causal social
influence path and a causal interest path. Building upon this insight, we
propose a disentangled encoder that focuses on disentangling user and item
embeddings into interest and social influence embeddings. Mutual
information-based objectives are designed to enhance the distinctiveness of
these disentangled embeddings, eliminating redundant information. Additionally,
a regulatory decoder that employs a weight calculation module to dynamically
learn the weights of social influence embeddings for effectively regulating
social influence bias has been designed. Experimental results on four
large-scale real-world datasets Ciao, Epinions, Dianping, and Douban book
demonstrate the effectiveness of CDRSB compared to state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03581" title="Abstract">arXiv:2403.03581</a> [<a href="/pdf/2403.03581" title="Download PDF">pdf</a>, <a href="/ps/2403.03581" title="Download PostScript">ps</a>, <a href="/format/2403.03581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing ASD detection accuracy: a combined approach of machine  learning and deep learning models with natural language processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubio-Mart%C3%ADn%2C+S">Sergio Rubio-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Ord%C3%A1s%2C+M+T">Mar&#xed;a Teresa Garc&#xed;a-Ord&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Bay%C3%B3n-Guti%C3%A9rrez%2C+M">Mart&#xed;n Bay&#xf3;n-Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Prieto-Fern%C3%A1ndez%2C+N">Natalia Prieto-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Ben%C3%ADtez-Andrades%2C+J+A">Jos&#xe9; Alberto Ben&#xed;tez-Andrades</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Health Inf Sci Syst 12, 20 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Purpose: Our study explored the use of artificial intelligence (AI) to
diagnose autism spectrum disorder (ASD). It focused on machine learning (ML)
and deep learning (DL) to detect ASD from text inputs on social media,
addressing challenges in traditional ASD diagnosis.
<br />Methods: We used natural language processing (NLP), ML, and DL models
(including decision trees, XGB, KNN, RNN, LSTM, Bi-LSTM, BERT, and BERTweet) to
analyze 404,627 tweets, classifying them based on ASD or non-ASD authors. A
subset of 90,000 tweets was used for model training and testing.
<br />Results: Our AI models showed high accuracy, with an 88% success rate in
identifying texts from individuals with ASD.
<br />Conclusion: The study demonstrates AI's potential in improving ASD diagnosis,
especially in children, highlighting the importance of early detection.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03582" title="Abstract">arXiv:2403.03582</a> [<a href="/pdf/2403.03582" title="Download PDF">pdf</a>, <a href="/format/2403.03582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of an Open-Source Architecture for Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Afli%2C+H">Haithem Afli</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2403.02367">arXiv:2403.02367</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 1st Workshop on Open Community-Driven
  Machine Translation, pages 15-20, Tampere, Finland. European Association for
  Machine Translation, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">adaptNMT is an open-source application that offers a streamlined approach to
the development and deployment of Recurrent Neural Networks and Transformer
models. This application is built upon the widely-adopted OpenNMT ecosystem,
and is particularly useful for new entrants to the field, as it simplifies the
setup of the development environment and creation of train, validation, and
test splits. The application offers a graphing feature that illustrates the
progress of model training, and employs SentencePiece for creating subword
segmentation models. Furthermore, the application provides an intuitive user
interface that facilitates hyperparameter customization. Notably, a
single-click model development approach has been implemented, and models
developed by adaptNMT can be evaluated using a range of metrics. To encourage
eco-friendly research, adaptNMT incorporates a green report that flags the
power consumption and kgCO${_2}$ emissions generated during model development.
The application is freely available.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03585" title="Abstract">arXiv:2403.03585</a> [<a href="/pdf/2403.03585" title="Download PDF">pdf</a>, <a href="/format/2403.03585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RouteExplainer: An Explanation Framework for Vehicle Routing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kikuta%2C+D">Daisuke Kikuta</a>, 
<a href="/search/cs?searchtype=author&query=Ikeuchi%2C+H">Hiroki Ikeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Tajiri%2C+K">Kengo Tajiri</a>, 
<a href="/search/cs?searchtype=author&query=Nakano%2C+Y">Yuusuke Nakano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PAKDD 2024. This extended version includes more comprehensive explanations and appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">The Vehicle Routing Problem (VRP) is a widely studied combinatorial
optimization problem and has been applied to various practical problems. While
the explainability for VRP is significant for improving the reliability and
interactivity in practical VRP applications, it remains unexplored. In this
paper, we propose RouteExplainer, a post-hoc explanation framework that
explains the influence of each edge in a generated route. Our framework
realizes this by rethinking a route as the sequence of actions and extending
counterfactual explanations based on the action influence model to VRP. To
enhance the explanation, we additionally propose an edge classifier that infers
the intentions of each edge, a loss function to train the edge classifier, and
explanation-text generation by Large Language Models (LLMs). We quantitatively
evaluate our edge classifier on four different VRPs. The results demonstrate
its rapid computation while maintaining reasonable accuracy, thereby
highlighting its potential for deployment in practical applications. Moreover,
on the subject of a tourist route, we qualitatively evaluate explanations
generated by our framework. This evaluation not only validates our framework
but also shows the synergy between explanation frameworks and LLMs. See
https://ntt-dkiku.github.io/xai-vrp for our code, datasets, models, and demo.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03590" title="Abstract">arXiv:2403.03590</a> [<a href="/pdf/2403.03590" title="Download PDF">pdf</a>, <a href="/format/2403.03590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepEclipse: How to Break White-Box DNN-Watermarking Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pegoraro%2C+A">Alessandro Pegoraro</a>, 
<a href="/search/cs?searchtype=author&query=Segna%2C+C">Carlotta Segna</a>, 
<a href="/search/cs?searchtype=author&query=Kumari%2C+K">Kavita Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 33rd USENIX Security Symposium, August 2024, Philadelphia, PA, USA. 18 pages, 7 figures, 4 tables, 5 algorithms, 13 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Learning (DL) models have become crucial in digital transformation, thus
raising concerns about their intellectual property rights. Different
watermarking techniques have been developed to protect Deep Neural Networks
(DNNs) from IP infringement, creating a competitive field for DNN watermarking
and removal methods. The predominant watermarking schemes use white-box
techniques, which involve modifying weights by adding a unique signature to
specific DNN layers. On the other hand, existing attacks on white-box
watermarking usually require knowledge of the specific deployed watermarking
scheme or access to the underlying data for further training and fine-tuning.
We propose DeepEclipse, a novel and unified framework designed to remove
white-box watermarks. We present obfuscation techniques that significantly
differ from the existing white-box watermarking removal schemes. DeepEclipse
can evade watermark detection without prior knowledge of the underlying
watermarking scheme, additional data, or training and fine-tuning. Our
evaluation reveals that DeepEclipse excels in breaking multiple white-box
watermarking schemes, reducing watermark detection to random guessing while
maintaining a similar model accuracy as the original one. Our framework
showcases a promising solution to address the ongoing DNN watermark protection
and removal challenges.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03592" title="Abstract">arXiv:2403.03592</a> [<a href="/pdf/2403.03592" title="Download PDF">pdf</a>, <a href="/format/2403.03592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wildest Dreams: Reproducible Research in Privacy-preserving Neural  Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+T">Tanveer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Budzys%2C+M">Mindaugas Budzys</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Michalas%2C+A">Antonis Michalas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine Learning (ML), addresses a multitude of complex issues in multiple
disciplines, including social sciences, finance, and medical research. ML
models require substantial computing power and are only as powerful as the data
utilized. Due to high computational cost of ML methods, data scientists
frequently use Machine Learning-as-a-Service (MLaaS) to outsource computation
to external servers. However, when working with private information, like
financial data or health records, outsourcing the computation might result in
privacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have
enabled ML training and inference over protected data through the use of
Privacy-Preserving Machine Learning (PPML). However, these techniques are still
at a preliminary stage and their application in real-world situations is
demanding. In order to comprehend discrepancy between theoretical research
suggestions and actual applications, this work examines the past and present of
PPML, focusing on Homomorphic Encryption (HE) and Secure Multi-party
Computation (SMPC) applied to ML. This work primarily focuses on the ML model's
training phase, where maintaining user data privacy is of utmost importance. We
provide a solid theoretical background that eases the understanding of current
approaches and their limitations. In addition, we present a SoK of the most
recent PPML frameworks for model training and provide a comprehensive
comparison in terms of the unique properties and performances on standard
benchmarks. Also, we reproduce the results for some of the papers and examine
at what level existing works in the field provide support for open science. We
believe our work serves as a valuable contribution by raising awareness about
the current gap between theoretical advancements and real-world applications in
PPML, specifically regarding open-source availability, reproducibility, and
usability.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03593" title="Abstract">arXiv:2403.03593</a> [<a href="/pdf/2403.03593" title="Download PDF">pdf</a>, <a href="/format/2403.03593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do You Trust Your Model? Emerging Malware Threats in the Deep Learning  Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hitaj%2C+D">Dorjan Hitaj</a>, 
<a href="/search/cs?searchtype=author&query=Pagnotta%2C+G">Giulio Pagnotta</a>, 
<a href="/search/cs?searchtype=author&query=De+Gaspari%2C+F">Fabio De Gaspari</a>, 
<a href="/search/cs?searchtype=author&query=Ruko%2C+S">Sediola Ruko</a>, 
<a href="/search/cs?searchtype=author&query=Hitaj%2C+B">Briland Hitaj</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+L+V">Luigi V. Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Cruz%2C+F">Fernando Perez-Cruz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training high-quality deep learning models is a challenging task due to
computational and technical requirements. A growing number of individuals,
institutions, and companies increasingly rely on pre-trained, third-party
models made available in public repositories. These models are often used
directly or integrated in product pipelines with no particular precautions,
since they are effectively just data in tensor form and considered safe. In
this paper, we raise awareness of a new machine learning supply chain threat
targeting neural networks. We introduce MaleficNet 2.0, a novel technique to
embed self-extracting, self-executing malware in neural networks. MaleficNet
2.0 uses spread-spectrum channel coding combined with error correction
techniques to inject malicious payloads in the parameters of deep neural
networks. MaleficNet 2.0 injection technique is stealthy, does not degrade the
performance of the model, and is robust against removal techniques. We design
our approach to work both in traditional and distributed learning settings such
as Federated Learning, and demonstrate that it is effective even when a reduced
number of bits is used for the model parameters. Finally, we implement a
proof-of-concept self-extracting neural network malware using MaleficNet 2.0,
demonstrating the practicality of the attack against a widely adopted machine
learning framework. Our aim with this work is to raise awareness against these
new, dangerous attacks both in the research community and industry, and we hope
to encourage further research in mitigation techniques against such threats.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03594" title="Abstract">arXiv:2403.03594</a> [<a href="/pdf/2403.03594" title="Download PDF">pdf</a>, <a href="/format/2403.03594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision:  Insights from Group and Individual Assessments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abe%2C+Y">Yoshia Abe</a>, 
<a href="/search/cs?searchtype=author&query=Daikoku%2C+T">Tatsuya Daikoku</a>, 
<a href="/search/cs?searchtype=author&query=Kuniyoshi%2C+Y">Yasuo Kuniyoshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, submitted to The 38th Annual Conference of the Japanese Society for Artificial Intelligence, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recently, it has been recognized that large language models demonstrate high
performance on various intellectual tasks. However, few studies have
investigated alignment with humans in behaviors that involve sensibility, such
as aesthetic evaluation. This study investigates the performance of GPT-4 with
Vision, a state-of-the-art language model that can handle image input, on the
task of aesthetic evaluation of images. We employ two tasks, prediction of the
average evaluation values of a group and an individual's evaluation values. We
investigate the performance of GPT-4 with Vision by exploring prompts and
analyzing prediction behaviors. Experimental results reveal GPT-4 with Vision's
superior performance in predicting aesthetic evaluations and the nature of
different responses to beauty and ugliness. Finally, we discuss developing an
AI system for aesthetic evaluation based on scientific knowledge of the human
perception of beauty, employing agent technologies that integrate traditional
deep learning models with large language models.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03599" title="Abstract">arXiv:2403.03599</a> [<a href="/pdf/2403.03599" title="Download PDF">pdf</a>, <a href="/format/2403.03599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Invariant Representations of Graph Neural Networks via Cluster  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+D">Donglin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have become increasingly popular in modeling
graph-structured data due to their ability to learn node representations by
aggregating local structure information. However, it is widely acknowledged
that the test graph structure may differ from the training graph structure,
resulting in a structure shift. In this paper, we experimentally find that the
performance of GNNs drops significantly when the structure shift happens,
suggesting that the learned models may be biased towards specific structure
patterns. To address this challenge, we propose the Cluster Information
Transfer (CIT) mechanism (Code available at
https://github.com/BUPT-GAMMA/CITGNN), which can learn invariant
representations for GNNs, thereby improving their generalization ability to
various and unknown test graphs with structure shift. The CIT mechanism
achieves this by combining different cluster information with the nodes while
preserving their cluster-independent information. By generating nodes across
different clusters, the mechanism significantly enhances the diversity of the
nodes and helps GNNs learn the invariant representations. We provide a
theoretical analysis of the CIT mechanism, showing that the impact of changing
clusters during structure shift can be mitigated after transfer. Additionally,
the proposed mechanism is a plug-in that can be easily used to improve existing
GNNs. We comprehensively evaluate our proposed method on three typical
structure shift scenarios, demonstrating its effectiveness in enhancing GNNs'
performance.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03600" title="Abstract">arXiv:2403.03600</a> [<a href="/pdf/2403.03600" title="Download PDF">pdf</a>, <a href="/format/2403.03600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+L">Lei Sang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quangui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Cross-domain recommendation (CDR) aims to enhance recommendation accuracy in
a target domain with sparse data by leveraging rich information in a source
domain, thereby addressing the data-sparsity problem. Some existing CDR methods
highlight the advantages of extracting domain-common and domain-specific
features to learn comprehensive user and item representations. However, these
methods can't effectively disentangle these components as they often rely on
simple user-item historical interaction information (such as ratings, clicks,
and browsing), neglecting the rich multi-modal features. Additionally, they
don't protect user-sensitive data from potential leakage during knowledge
transfer between domains. To address these challenges, we propose a
Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain
Recommendation, called P2M2-CDR. Specifically, we first design a multi-modal
disentangled encoder that utilizes multi-modal information to disentangle more
informative domain-common and domain-specific embeddings. Furthermore, we
introduce a privacy-preserving decoder to mitigate user privacy leakage during
knowledge transfer. Local differential privacy (LDP) is utilized to obfuscate
the disentangled embeddings before inter-domain exchange, thereby enhancing
privacy protection. To ensure both consistency and differentiation among these
obfuscated disentangled embeddings, we incorporate contrastive learning-based
domain-inter and domain-intra losses. Extensive Experiments conducted on four
real-world datasets demonstrate that P2M2-CDR outperforms other
state-of-the-art single-domain and cross-domain baselines.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03602" title="Abstract">arXiv:2403.03602</a> [<a href="/pdf/2403.03602" title="Download PDF">pdf</a>, <a href="/format/2403.03602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Based In-Cylinder Pressure Model with Cyclic Variations for  Combustion Control: A RCCI Engine Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vlaswinkel%2C+M">Maarten Vlaswinkel</a>, 
<a href="/search/eess?searchtype=author&query=Willems%2C+F">Frank Willems</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Cylinder pressure-based control is a key enabler for advanced pre-mixed
combustion concepts. Besides guaranteeing robust and safe operation, it allows
for cylinder pressure and heat release shaping. This requires fast
control-oriented combustion models. Over the years, mean-value models have been
proposed that can predict combustion measures (e.g., Gross Indicated Mean
Effective Pressure, or the crank angle where 50% of the total heat is released)
or models that predict the full in-cylinder pressure. However, these models are
not able to capture cyclic variations. This is important in the control design
for combustion concepts, like Reactivity Controlled Compression Ignition, that
can suffer from large cyclic variations. In this study, the in-cylinder
pressure and cyclic variation are modelled using a data-based approach. The
model combines Principle Component Decomposition and Gaussian Process
Regression. A detailed study is performed on the effects of the different
hyperparameters and kernel choices. The approach is applicable to any
combustion concept, but most valuable for advance combustion concepts with
large cyclic variation. The potential of the proposed approach is demonstrated
for an Reactivity Controlled Compression Ignition engine running on Diesel and
E85. The prediction quality of the evaluated combustion measures has an overall
accuracy of 13.5% and 65.5% in mean behaviour and standard deviation,
respectively. The peak-pressure rise-rate is traditionally hard to predict, in
the proposed model it has an accuracy of 22.7% and 96.4% in mean behaviour and
standard deviation, respectively. This Principle Component Decomposition-based
approach is an important step towards in-cylinder pressure shaping. The use of
Gaussian Process Regression provides important information on cyclic variation
and provides next-cycle controls information on safety and performance
criteria.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03605" title="Abstract">arXiv:2403.03605</a> [<a href="/pdf/2403.03605" title="Download PDF">pdf</a>, <a href="/format/2403.03605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-time-step coupling of peridynamics and classical continuum  mechanics for dynamic brittle fracture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiandong%2C+Z">Zhong Jiandong</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Han Fei</a>, 
<a href="/search/cs?searchtype=author&query=Zongliang%2C+D">Du Zongliang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 17 figures, 81 conferences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Peridynamics (PD), as a nonlocal theory, is well-suited for solving problems
with discontinuities, such as cracks. However, the nonlocal effect of
peridynamics makes it computationally expensive for dynamic fracture problems
in large-scale engineering applications. As an alternative, this study proposes
a multi-time-step (MTS) coupling model of PD and classical continuum mechanics
(CCM) based on the Arlequin framework. Peridynamics is applied to the fracture
domain of the structure, while continuum mechanics is applied to the rest of
the structure. The MTS method enables the peridynamic model to be solved at a
small time step and the continuum mechanical model is solved at a larger time
step. Consequently, higher computational efficiency is achieved for the
fracture domain of the structure while ensuring computational accuracy, and
this coupling method can be easily applied to large-scale engineering fracture
problems.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03607" title="Abstract">arXiv:2403.03607</a> [<a href="/pdf/2403.03607" title="Download PDF">pdf</a>, <a href="/format/2403.03607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Geometric Structure of Topic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirth%2C+J">Johannes Hirth</a>, 
<a href="/search/cs?searchtype=author&query=Hanika%2C+T">Tom Hanika</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Topic models are a popular tool for clustering and analyzing textual data.
They allow texts to be classified on the basis of their affiliation to the
previously calculated topics. Despite their widespread use in research and
application, an in-depth analysis of topic models is still an open research
topic. State-of-the-art methods for interpreting topic models are based on
simple visualizations, such as similarity matrices, top-term lists or
embeddings, which are limited to a maximum of three dimensions. In this paper,
we propose an incidence-geometric method for deriving an ordinal structure from
flat topic models, such as non-negative matrix factorization. These enable the
analysis of the topic model in a higher (order) dimension and the possibility
of extracting conceptual relationships between several topics at once. Due to
the use of conceptual scaling, our approach does not introduce any artificial
topical relationships, such as artifacts of feature compression. Based on our
findings, we present a new visualization paradigm for concept hierarchies based
on ordinal motifs. These allow for a top-down view on topic spaces. We
introduce and demonstrate the applicability of our approach based on a topic
model derived from a corpus of scientific papers taken from 32 top machine
learning venues.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03608" title="Abstract">arXiv:2403.03608</a> [<a href="/pdf/2403.03608" title="Download PDF">pdf</a>, <a href="/format/2403.03608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D  Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+Z">Zi-Ting Chou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sheng-Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+I">I-Jieh Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance
Fields (NeRF) have emerged as a popular research topic in 3D vision. In this
work, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF),
which uniquely takes image semantics into the synthesis process so that both
novel view images and the associated semantic maps can be produced for unseen
scenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and
Depth-Guided Visual rendering. The former is able to observe multi-view image
inputs to extract semantic and geometry features from a scene. Guided by the
resulting image geometry information, the latter performs both image and
semantic rendering with improved performances. Our experiments not only confirm
that GSNeRF performs favorably against prior works on both novel-view image and
semantic segmentation synthesis but the effectiveness of our sampling strategy
for visual rendering is further verified.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03617" title="Abstract">arXiv:2403.03617</a> [<a href="/pdf/2403.03617" title="Download PDF">pdf</a>, <a href="/format/2403.03617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum Occupancy Detection Supported by Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%C5%82acz%2C+%C5%81">&#x141;ukasz Ku&#x142;acz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Dynamic spectrum access is essential for radiocommunication and its limited
spectrum resources. The key element of dynamic spectrum access systems is
effective spectrum occupancy detection. In many cases, machine learning
algorithms improve detection effectiveness. Because of the recent trend of
using federated learning, a federated learning algorithm is presented in the
context of distributed spectrum occupancy detection. The results of the work
presented in the paper are based on actual signal samples collected in the
laboratory. The proposed algorithm is effective, especially in the context of a
set of sensors with faulty sensors.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03618" title="Abstract">arXiv:2403.03618</a> [<a href="/pdf/2403.03618" title="Download PDF">pdf</a>, <a href="/format/2403.03618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;My lollipop dropped...&quot;-Probing Design Opportunities for SEL Agents  through Children&#x27;s Peer Co-Creation of Social-Emotional Stories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanqing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nikolova%2C+A">Anastasia Nikolova</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+P">Pengcheng An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in CHI EA '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This Late-Breaking Work explores the significance of socio-emotional learning
(SEL) and the challenges inherent in designing child-appropriate technologies,
namely storytelling agents, to support SEL. We aim to probe their needs and
preferences regarding agents for SEL by conducting co-design which involves
children co-creating characters and social-emotional stories. We conducted
collaborative story-making activities with children aged four to six years old.
Our findings could inform the design of both verbal and nonverbal interactions
of agents, which are to be aligned with children's understanding and interest.
Based on the child-led peer co-design, our work enhances the understanding of
SEL agent designs and behaviors tailored to children's socio-emotional needs,
thereby offering practical implications for more effective SEL tools in future
HCI research and practice.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03622" title="Abstract">arXiv:2403.03622</a> [<a href="/pdf/2403.03622" title="Download PDF">pdf</a>, <a href="/format/2403.03622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medial Parametrization of Arbitrary Planar Compact Domains with Dipoles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+V">Vinayak Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">We present medial parametrization, a new approach to parameterizing any
compact planar domain bounded by simple closed curves. The basic premise behind
our proposed approach is to use two close Voronoi sites, which we call dipoles,
to construct and reconstruct an approximate piecewise-linear version of the
original boundary and medial axis through Voronoi tessellation. The boundaries
and medial axes of such planar compact domains offer a natural way to describe
the domain's interior. Any compact planar domain is homeomorphic to a compact
unit circular disk admits a natural parameterization isomorphic to the polar
parametrization of the disk. Specifically, the medial axis and the boundary
generalize the radial and angular parameters, respectively. In this paper, we
present a simple algorithm that puts these principles into practice. The
algorithm is based on the simultaneous re-creation of the boundaries of the
domain and its medial axis using Voronoi tessellation. This simultaneous
re-creation provides partitions of the domain into a set of "skinny" convex
polygons wherein each polygon is essentially a subset of the medial edges
(which we call the spine) connected to the boundary through exactly two
straight edges (which we call limbs). This unique structure enables us to
convert the original Voronoi tessellation into quadrilaterals and triangles (at
the poles of the medial axis) neatly ordered along the domain boundary, thereby
allowing proper parametrization of the domain. Our approach is agnostic to the
number of holes and disconnected components bounding the domain. We investigate
the efficacy of our concept and algorithm through several examples.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03627" title="Abstract">arXiv:2403.03627</a> [<a href="/pdf/2403.03627" title="Download PDF">pdf</a>, <a href="/format/2403.03627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Large Language Models to Support Real-World Fact-Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+J">Jiahui Geng</a>, 
<a href="/search/cs?searchtype=author&query=Kementchedjhieva%2C+Y">Yova Kementchedjhieva</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal large language models (MLLMs) carry the potential to support
humans in processing vast amounts of information. While MLLMs are already being
used as a fact-checking tool, their abilities and limitations in this regard
are understudied. Here is aim to bridge this gap. In particular, we propose a
framework for systematically assessing the capacity of current multimodal
models to facilitate real-world fact-checking. Our methodology is
evidence-free, leveraging only these models' intrinsic knowledge and reasoning
capabilities. By designing prompts that extract models' predictions,
explanations, and confidence levels, we delve into research questions
concerning model accuracy, robustness, and reasons for failure. We empirically
find that (1) GPT-4V exhibits superior performance in identifying malicious and
misleading multimodal claims, with the ability to explain the unreasonable
aspects and underlying motives, and (2) existing open-source models exhibit
strong biases and are highly sensitive to the prompt. Our study offers insights
into combating false multimodal information and building secure, trustworthy
multimodal models. To the best of our knowledge, we are the first to evaluate
MLLMs for real-world fact-checking.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03628" title="Abstract">arXiv:2403.03628</a> [<a href="/pdf/2403.03628" title="Download PDF">pdf</a>, <a href="/format/2403.03628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPTopic: Dynamic and Interactive Topic Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reuter%2C+A">Arik Reuter</a>, 
<a href="/search/cs?searchtype=author&query=Thielmann%2C+A">Anton Thielmann</a>, 
<a href="/search/cs?searchtype=author&query=Weisser%2C+C">Christoph Weisser</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+S">Sebastian Fischer</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A4fken%2C+B">Benjamin S&#xe4;fken</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Topic modeling seems to be almost synonymous with generating lists of top
words to represent topics within large text corpora. However, deducing a topic
from such list of individual terms can require substantial expertise and
experience, making topic modelling less accessible to people unfamiliar with
the particularities and pitfalls of top-word interpretation. A topic
representation limited to top-words might further fall short of offering a
comprehensive and easily accessible characterization of the various aspects,
facets and nuances a topic might have. To address these challenges, we
introduce GPTopic, a software package that leverages Large Language Models
(LLMs) to create dynamic, interactive topic representations. GPTopic provides
an intuitive chat interface for users to explore, analyze, and refine topics
interactively, making topic modeling more accessible and comprehensive. The
corresponding code is available here: https://github. com/05ec6602be/GPTopic.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03631" title="Abstract">arXiv:2403.03631</a> [<a href="/pdf/2403.03631" title="Download PDF">pdf</a>, <a href="/format/2403.03631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Missing Values in Probabilistic Wind Power Forecasting: A  Generative Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Honglin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Pinson%2C+P">Pierre Pinson</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijian Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, to be presented at Power Systems Computation Conference (PSCC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Machine learning techniques have been successfully used in probabilistic wind
power forecasting. However, the issue of missing values within datasets due to
sensor failure, for instance, has been overlooked for a long time. Although it
is natural to consider addressing this issue by imputing missing values before
model estimation and forecasting, we suggest treating missing values and
forecasting targets indifferently and predicting all unknown values
simultaneously based on observations. In this paper, we offer an efficient
probabilistic forecasting approach by estimating the joint distribution of
features and targets based on a generative model. It is free of preprocessing,
and thus avoids introducing potential errors. Compared with the traditional
"impute, then predict" pipeline, the proposed approach achieves better
performance in terms of continuous ranked probability score.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03633" title="Abstract">arXiv:2403.03633</a> [<a href="/pdf/2403.03633" title="Download PDF">pdf</a>, <a href="/format/2403.03633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hybrid dynamical system approach to the impulsive control of  spacecraft rendezvous (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Seuret%2C+A">Alexandre Seuret</a>, 
<a href="/search/eess?searchtype=author&query=Vazquez%2C+R">Rafael Vazquez</a>, 
<a href="/search/eess?searchtype=author&query=Zaccarian%2C+L">Luca Zaccarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of ECC24 article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper introduces a hybrid dynamical system methodology for managing
impulsive control in spacecraft rendezvous and proximity operations under the
Hill-Clohessy-Wiltshire model. We address the control design problem by
isolating the out-of-plane from the in-plane dynamics and present a feedback
control law for each of them. This law is based on a Lyapunov function tailored
to each of the dynamics, capable of addressing thruster saturation and also a
minimum impulse bit. These Lyapunov functions were found by reformulating the
system's dynamics into coordinates that more intuitively represent their
physical behavior. The effectiveness of our control laws is then shown through
numerical simulation. This is an extended version of an ECC24 article of the
same name, which includes the proofs omitted for lack of space.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03635" title="Abstract">arXiv:2403.03635</a> [<a href="/pdf/2403.03635" title="Download PDF">pdf</a>, <a href="/format/2403.03635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Processing Load Allocation of On-Board Multi-User Detection for  Payload-Constrained Satellite Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+S">Sirui Miao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+N">Neng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peisen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+Q">Qiaolin Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The rapid advance of mega-constellation facilitates the booming of
direct-to-satellite massive access, where multi-user detection is critical to
alleviate the induced inter-user interference. While centralized implementation
of on-board detection induces unaffordable complexity for a single satellite,
this paper proposes to allocate the processing load among cooperative
satellites for finest exploitation of distributed processing power. Observing
the inherent disparities among users, we first excavate the closed-form
trade-offs between achievable sum-rate and the processing load corresponding to
the satellite-user matchings, which leads to a system sum-rate maximization
problem under stringent payload constraints. To address the non-trivial integer
matching, we develop a quadratic transformation to the original problem, and
prove it an equivalent conversion. The problem is further simplified into a
series of subproblems employing successive lower bound approximation which
obtains polynomial-time complexity and converges within a few iterations.
Numerical results show remarkably complexity reduction compared with
centralized processing, as well as around 20\% sum-rate gain compared with
other allocation methods.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03636" title="Abstract">arXiv:2403.03636</a> [<a href="/pdf/2403.03636" title="Download PDF">pdf</a>, <a href="/format/2403.03636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SheetAgent: A Generalist Agent for Spreadsheet Reasoning and  Manipulation via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yibin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yifu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+F">Fei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spreadsheet manipulation is widely existing in most daily works and
significantly improves working efficiency. Large language model (LLM) has been
recently attempted for automatic spreadsheet manipulation but has not yet been
investigated in complicated and realistic tasks where reasoning challenges
exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous
requirements). To bridge the gap with the real-world requirements, we introduce
$\textbf{SheetRM}$, a benchmark featuring long-horizon and multi-category tasks
with reasoning-dependent manipulation caused by real-life challenges. To
mitigate the above challenges, we further propose $\textbf{SheetAgent}$, a
novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of
three collaborative modules: $\textit{Planner}$, $\textit{Informer}$, and
$\textit{Retriever}$, achieving both advanced reasoning and accurate
manipulation over spreadsheets without human interaction through iterative task
reasoning and reflection. Extensive experiments demonstrate that SheetAgent
delivers 20-30% pass rate improvements on multiple benchmarks over baselines,
achieving enhanced precision in spreadsheet manipulation and demonstrating
superior table reasoning abilities. More details and visualizations are
available at https://sheetagent.github.io.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03639" title="Abstract">arXiv:2403.03639</a> [<a href="/pdf/2403.03639" title="Download PDF">pdf</a>, <a href="/format/2403.03639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Search and Learning for Agile Locomotion on Stepping Stones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ravi%2C+A+K+C">Adithya Kumar Chinnakkonda Ravi</a>, 
<a href="/search/cs?searchtype=author&query=Dh%C3%A9din%2C+V">Victor Dh&#xe9;din</a>, 
<a href="/search/cs?searchtype=author&query=Jordana%2C+A">Armand Jordana</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huaijiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Meduri%2C+A">Avadesh Meduri</a>, 
<a href="/search/cs?searchtype=author&query=Righetti%2C+L">Ludovic Righetti</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Khadiv%2C+M">Majid Khadiv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robots have become capable of performing highly dynamic maneuvers in
the past few years. However, agile locomotion in highly constrained
environments such as stepping stones is still a challenge. In this paper, we
propose a combination of model-based control, search, and learning to design
efficient control policies for agile locomotion on stepping stones. In our
framework, we use nonlinear model predictive control (NMPC) to generate
whole-body motions for a given contact plan. To efficiently search for an
optimal contact plan, we propose to use Monte Carlo tree search (MCTS). While
the combination of MCTS and NMPC can quickly find a feasible plan for a given
environment (a few seconds), it is not yet suitable to be used as a reactive
policy. Hence, we generate a dataset for optimal goal-conditioned policy for a
given scene and learn it through supervised learning. In particular, we
leverage the power of diffusion models in handling multi-modality in the
dataset. We test our proposed framework on a scenario where our quadruped robot
Solo12 successfully jumps to different goals in a highly constrained
environment.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03640" title="Abstract">arXiv:2403.03640</a> [<a href="/pdf/2403.03640" title="Download PDF">pdf</a>, <a href="/format/2403.03640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Apollo: Lightweight Multilingual Medical LLMs towards Democratizing  Medical AI to 6B People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+A">Anningzhe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the vast repository of global medical knowledge predominantly being
in English, local languages are crucial for delivering tailored healthcare
services, particularly in areas with limited medical resources. To extend the
reach of medical AI advancements to a broader population, we aim to develop
medical LLMs across the six most widely spoken languages, encompassing a global
population of 6.1 billion. This effort culminates in the creation of the
ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the
multilingual medical benchmark, the released Apollo models, at various
relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best
performance among models of equivalent size. Especially, Apollo-7B is the
state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite
models could be used to improve the multi-lingual medical capabilities of
larger models without fine-tuning in a proxy-tuning fashion. We will
open-source training corpora, code, model weights and evaluation benchmark.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03641" title="Abstract">arXiv:2403.03641</a> [<a href="/pdf/2403.03641" title="Download PDF">pdf</a>, <a href="/format/2403.03641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Photon Guiding with 3D Gaussians for Caustics Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+H">Hajime Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Kitamura%2C+Y">Yoshifumi Kitamura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In production rendering systems, caustics are typically rendered via photon
mapping and gathering, a process often hindered by insufficient photon density.
In this paper, we propose a novel photon guiding method to improve the photon
density and overall quality for caustic rendering. The key insight of our
approach is the application of a global 3D Gaussian mixture model, used in
conjunction with an adaptive light sampler. This combination effectively guides
photon emission in expansive 3D scenes with multiple light sources. By
employing a global 3D Gaussian mixture, our method precisely models the
distribution of the points of interest. To sample emission directions from the
distribution at any observation point, we introduce a novel directional
transform of the 3D Gaussian, which ensures accurate photon emission guiding.
Furthermore, our method integrates a global light cluster tree, which models
the contribution distribution of light sources to the image, facilitating
effective light source selection. We conduct experiments demonstrating that our
approach robustly outperforms existing photon guiding techniques across a
variety of scenarios, significantly advancing the quality of caustic rendering.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03643" title="Abstract">arXiv:2403.03643</a> [<a href="/pdf/2403.03643" title="Download PDF">pdf</a>, <a href="/ps/2403.03643" title="Download PostScript">ps</a>, <a href="/format/2403.03643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Applications of Reinforcement Learning in Spatial Resource  Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Moyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mango%2C+J">Joseph Mango</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The challenge of spatial resource allocation is pervasive across various
domains such as transportation, industry, and daily life. As the scale of
real-world issues continues to expand and demands for real-time solutions
increase, traditional algorithms face significant computational pressures,
struggling to achieve optimal efficiency and real-time capabilities. In recent
years, with the escalating computational power of computers, the remarkable
achievements of reinforcement learning in domains like Go and robotics have
demonstrated its robust learning and sequential decision-making capabilities.
Given these advancements, there has been a surge in novel methods employing
reinforcement learning to tackle spatial resource allocation problems. These
methods exhibit advantages such as rapid solution convergence and strong model
generalization abilities, offering a new perspective on resolving spatial
resource allocation problems. Therefore, this paper aims to summarize and
review recent theoretical methods and applied research utilizing reinforcement
learning to address spatial resource allocation problems. It provides a summary
and comprehensive overview of its fundamental principles, related
methodologies, and applied research. Additionally, it highlights several
unresolved issues that urgently require attention in this direction for the
future.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03645" title="Abstract">arXiv:2403.03645</a> [<a href="/pdf/2403.03645" title="Download PDF">pdf</a>, <a href="/format/2403.03645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation  Learning in Multivariate Time-Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yucheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ruibing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lihua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghua Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Sourced from various sensors and organized chronologically, Multivariate
Time-Series (MTS) data involves crucial spatial-temporal dependencies, e.g.,
correlations among sensors. To capture these dependencies, Graph Neural
Networks (GNNs) have emerged as powerful tools, yet their effectiveness is
restricted by the quality of graph construction from MTS data. Typically,
existing approaches construct graphs solely from MTS signals, which may
introduce bias due to a small training dataset and may not accurately represent
underlying dependencies. To address this challenge, we propose a novel
framework named K-Link, leveraging Large Language Models (LLMs) to encode
extensive general knowledge and thereby providing effective solutions to reduce
the bias. Leveraging the knowledge embedded in LLMs, such as physical
principles, we extract a \textit{Knowledge-Link graph}, capturing vast semantic
knowledge of sensors and the linkage of the sensor-level knowledge. To harness
the potential of the knowledge-link graph in enhancing the graph derived from
MTS data, we propose a graph alignment module, facilitating the transfer of
semantic knowledge within the knowledge-link graph into the MTS-derived graph.
By doing so, we can improve the graph quality, ensuring effective
representation learning with GNNs for MTS data. Extensive experiments
demonstrate the efficacy of our approach for superior performance across
various MTS-related downstream tasks.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03648" title="Abstract">arXiv:2403.03648</a> [<a href="/pdf/2403.03648" title="Download PDF">pdf</a>, <a href="/format/2403.03648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Connector for Integrating NGSI-LD Data into Open Data Portals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn%2C+L">Laura Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Lanza%2C+J">Jorge Lanza</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+V">V&#xed;ctor Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Santana%2C+J+R">Juan Ram&#xf3;n Santana</a>, 
<a href="/search/cs?searchtype=author&query=Sotres%2C+P">Pablo Sotres</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+L">Luis S&#xe1;nchez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work belongs to the Special Issue Data Engineering in the Internet of Things of MDPI Sensors. This work has been partially supported by the project SALTED from the European Union's Connecting Europe Facility program under Action Number 2020-EU-IA-0274, and by the project SITED under Grant Agreement No. PID2021-125725OB-I00 funded by MCIN/AEI/10.13039/501100011033 and the European Union FEDER
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 2024, 24, 1695
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Nowadays, there are plenty of data sources generating massive amounts of
information that, combined with novel data analytics frameworks, are meant to
support optimisation in many application domains. Nonetheless, there are still
shortcomings in terms of data discoverability, accessibility and
interoperability. Open Data portals have emerged as a shift towards openness
and discoverability. However, they do not impose any condition to the data
itself, just stipulate how datasets have to be described. Alternatively, the
NGSI-LD standard pursues harmonisation in terms of data modelling and
accessibility. This paper presents a solution that bridges these two domains
(i.e., Open Data portals and NGSI-LD-based data) in order to keep benefiting
from the structured description of datasets offered by Open Data portals, while
ensuring the interoperability provided by the NGSI-LD standard. Our solution
aggregates the data into coherent datasets and generate high-quality
descriptions, ensuring comprehensiveness, interoperability and accessibility.
The proposed solution has been validated through a real-world implementation
that exposes IoT data in NGSI-LD format through the European Data Portal (EDP).
Moreover, the results from the Metadata Quality Assessment that the EDP
implements, show that the datasets' descriptions generated achieve excellent
ranking in terms of the Findability, Accessibility, Interoperability and
Reusability (FAIR) data principles.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03651" title="Abstract">arXiv:2403.03651</a> [<a href="/pdf/2403.03651" title="Download PDF">pdf</a>, <a href="/ps/2403.03651" title="Download PostScript">ps</a>, <a href="/format/2403.03651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximally Extendable Sheaf Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panteleev%2C+P">Pavel Panteleev</a>, 
<a href="/search/cs?searchtype=author&query=Kalachev%2C+G">Gleb Kalachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computational Complexity (cs.CC); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We study sheaf codes, a type of linear codes with a fixed hierarchical
collection of local codes, viewed as a sheaf of vector spaces on a finite
topological space we call coded space. Many existing codes, such as tensor
product codes, Sipser-Spielman codes, and their more recent high-dimensional
analogs, can be naturally represented as sheaf codes on simplicial and cubical
complexes, considered as coded spaces. We introduce a new property of a sheaf
code, called maximal extendibility, which ensures that within a class of codes
on the same coded space, we encounter as few obstructions as possible when
extending local sections globally. We show that in every class of sheaf codes
defined on the same space and parameterized by parity-check matrices with
polynomial entries, there always exists a maximally extendable sheaf code. Such
codes are very interesting since it is possible to show that maximally
extendable tensor product codes are good coboundary expanders, which
potentially could be used to attack the qLTC conjecture.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03654" title="Abstract">arXiv:2403.03654</a> [<a href="/pdf/2403.03654" title="Download PDF">pdf</a>, <a href="/ps/2403.03654" title="Download PostScript">ps</a>, <a href="/format/2403.03654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrity-protecting block cipher modes -- Untangling a tangled web
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+C+J">Chris J Mitchell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This paper re-examines the security of three related block cipher modes of
operation designed to provide authenticated encryption. These modes, known as
PES-PCBC, IOBC and EPBC, were all proposed in the mid-1990s. However, analyses
of security of the latter two modes were published more recently. In each case
one or more papers describing security issues with the schemes were eventually
published, although a flaw in one of these analyses (of EPBC) was subsequently
discovered - this means that until now EPBC had no known major issues. This
paper establishes that, despite this, all three schemes possess defects which
should prevent their use - especially as there are a number of efficient
alternative schemes possessing proofs of security.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03655" title="Abstract">arXiv:2403.03655</a> [<a href="/pdf/2403.03655" title="Download PDF">pdf</a>, <a href="/format/2403.03655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kronos: A Robust Sharding Blockchain Consensus with Optimal  Communication Overhead
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Andi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhuocheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Sharding enhances blockchain scalability by dividing the network into shards,
each managing specific unspent transaction outputs or accounts. Cross-shard
transactions pose a critical challenge to the security and efficiency of
sharding blockchains. Current solutions, however, either prioritize security
with assumptions and substantial investments, or focus on reducing overhead and
overlooking security considerations.
<br />In this paper, we present Kronos, a generic and efficient sharding blockchain
consensus ensuring robust security. We introduce a buffer mechanism for atomic
cross-shard transaction processing. Shard members collectively maintain a
buffer to manage cross-shard inputs, ensuring that a transaction is committed
only if all inputs are available, and no fund is transferred for invalid
requests. While ensuring security, Kronos processes transactions with optimal
intra-shard communication overhead. Additionally, we propose a reduction for
transaction invalidity proof generation to simple and fast multicasting,
leading to atomic rejection without executing full-fledged Byzantine fault
tolerance protocol in optimistic scenarios. Moreover, Kronos adopts a newly
designed batch mechanism, reducing inter-shard message complexity to
$O((m$log$m/b)\lambda)$.
<br />Kronos operates without dependence on any time or client honesty assumption,
serving as a plug-in sharding blockchain consensus supporting applications in
diverse network environments including asynchronous ones. We implement Kronos
using two prominent BFT protocols: Speeding Dumbo and HotStuff. Extensive
experiments demonstrate Kronos achieving a substantial throughput of
68.6ktx/sec with 1.7sec latency. Compared with state-of-the-art solutions,
Kronos outperforms in all cases, achieving up to a 42x improvement in
throughput and a 50% reduction in latency when cross-shard transactions
dominate the workload.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03657" title="Abstract">arXiv:2403.03657</a> [<a href="/pdf/2403.03657" title="Download PDF">pdf</a>, <a href="/ps/2403.03657" title="Download PostScript">ps</a>, <a href="/format/2403.03657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-Printed Dielectric Image Lines towards Chip-to-Chip Interconnects for  subTHz-Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hahn%2C+L">Leonhard Hahn</a>, 
<a href="/search/eess?searchtype=author&query=Pfahler%2C+T">Tim Pfahler</a>, 
<a href="/search/eess?searchtype=author&query=Bader%2C+T">Tobias Bader</a>, 
<a href="/search/eess?searchtype=author&query=Gold%2C+G">Gerald Gold</a>, 
<a href="/search/eess?searchtype=author&query=Vossiek%2C+M">Martin Vossiek</a>, 
<a href="/search/eess?searchtype=author&query=Carlowitz%2C+C">Christian Carlowitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper reports on 3D-printed dielectric image lines for low-loss subTHz
applications between 140 and 220 GHz. In contrast to conventional dielectric
waveguides, a conductive copper substrate is used to achieve robust routing and
increased mechanical stability. For easy integration and characterization of
the dielectric image line within a waveguide measurement setup, a low-loss
mode-converter for flexible mounting is further designed. The characterized
overall system exhibits a broadband match of at least 20 dB over the entire
frequency band, with minimal losses of below 0.35 dB/cm. Furthermore,
multi-line characterization is performed for de-embedding the propagation
parameters {\alpha} and \b{eta} of both the dielectric transmission line and
the mode-converter, and finally, the influence of discontinuities such as
bending radii on the transmission behavior is evaluated. Due to the simplicity
of the underlying 3D-printing technology, the proposed concept features
extremely low cost and complexity, yet offers high flexibility and outperforms
the losses of conventional transmission lines.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03658" title="Abstract">arXiv:2403.03658</a> [<a href="/pdf/2403.03658" title="Download PDF">pdf</a>, <a href="/format/2403.03658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite elements for Mat&#xe9;rn-type random fields: Uncertainty in  computational mechanics and design optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duswald%2C+T">Tobias Duswald</a>, 
<a href="/search/cs?searchtype=author&query=Keith%2C+B">Brendan Keith</a>, 
<a href="/search/cs?searchtype=author&query=Lazarov%2C+B">Boyan Lazarov</a>, 
<a href="/search/cs?searchtype=author&query=Petrides%2C+S">Socratis Petrides</a>, 
<a href="/search/cs?searchtype=author&query=Wohlmuth%2C+B">Barbara Wohlmuth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work highlights an approach for incorporating realistic uncertainties
into scientific computing workflows based on finite elements, focusing on
applications in computational mechanics and design optimization. We leverage
Mat\'ern-type Gaussian random fields (GRFs) generated using the SPDE method to
model aleatoric uncertainties, including environmental influences, variating
material properties, and geometric ambiguities. Our focus lies on delivering
practical GRF realizations that accurately capture imperfections and variations
and understanding how they impact the predictions of computational models and
the topology of optimized designs. We describe a numerical algorithm based on
solving a generalized SPDE to sample GRFs on arbitrary meshed domains. The
algorithm leverages established techniques and integrates seamlessly with the
open-source finite element library MFEM and associated scientific computing
workflows, like those found in industrial and national laboratory settings. Our
solver scales efficiently for large-scale problems and supports various domain
types, including surfaces and embedded manifolds. We showcase its versatility
through biomechanics and topology optimization applications. The flexibility
and efficiency of SPDE-based GRF generation empower us to run large-scale
optimization problems on 2D and 3D domains, including finding optimized designs
on embedded surfaces, and to generate topologies beyond the reach of
conventional techniques. Moreover, these capabilities allow us to model
geometric uncertainties of reconstructed submanifolds, such as the surfaces of
cerebral aneurysms. In addition to offering benefits in these specific domains,
the proposed techniques transcend specific applications and generalize to
arbitrary forward and backward problems in uncertainty quantification involving
finite elements.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03659" title="Abstract">arXiv:2403.03659</a> [<a href="/pdf/2403.03659" title="Download PDF">pdf</a>, <a href="/format/2403.03659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Graph Structure Learning under Heterophily
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuanting Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenyu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph is a fundamental mathematical structure in characterizing relations
between different objects and has been widely used on various learning tasks.
Most methods implicitly assume a given graph to be accurate and complete.
However, real data is inevitably noisy and sparse, which will lead to inferior
results. Despite the remarkable success of recent graph representation learning
methods, they inherently presume that the graph is homophilic, and largely
overlook heterophily, where most connected nodes are from different classes. In
this regard, we propose a novel robust graph structure learning method to
achieve a high-quality graph from heterophilic data for downstream tasks. We
first apply a high-pass filter to make each node more distinctive from its
neighbors by encoding structure information into the node features. Then, we
learn a robust graph with an adaptive norm characterizing different levels of
noise. Afterwards, we propose a novel regularizer to further refine the graph
structure. Clustering and semi-supervised classification experiments on
heterophilic graphs verify the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03661" title="Abstract">arXiv:2403.03661</a> [<a href="/pdf/2403.03661" title="Download PDF">pdf</a>, <a href="/ps/2403.03661" title="Download PostScript">ps</a>, <a href="/format/2403.03661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and evaluation of Artificial Intelligence techniques for IoT  data quality assessment and curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn%2C+L">Laura Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+L">Luis S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Lanza%2C+J">Jorge Lanza</a>, 
<a href="/search/cs?searchtype=author&query=Sotres%2C+P">Pablo Sotres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is published in Elsevier Internet of Things. This work was supported by the European Commission CEF Programme by means of the project SALTED under the Action Number 2020-EU-IA-0274 and by the Spanish State Research Agency (AEI) by means of the project SITED under Grant Agreement No. PID2021-125725OB-I00
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Internet of Things, Volume 22, July 2023, 100779
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Nowadays, data is becoming the new fuel for economic wealth and creation of
novel and profitable business models. Multitude of technologies are
contributing to an abundance of information sources which are already the
baseline for multi-millionaire services and applications. Internet of Things
(IoT), is probably the most representative one. However, for an economy of data
to actually flourish there are still several critical challenges that have to
be overcome. Among them, data quality can become an issue when data come from
heterogeneous sources or have different formats, standards and scale. Improving
data quality is of utmost importance for any domain since data are the basis
for any decision-making system and decisions will not be accurate if they are
based on inadequate low-quality data. In this paper we are presenting a
solution for assessing several quality dimensions of IoT data streams as they
are generated. Additionally, the solution described in the paper actually
improves the quality of data streams by curating them through the application
of Artificial Intelligence techniques. The approach followed in our work has
been to append data quality information as metadata linked to each individual
piece of curated data. We have leveraged linked-data principles and integrated
the developed AI-based IoT data curation mechanisms within a Data Enrichment
Toolchain (DET) that employs the NGSI-LD standard to harmonize and enrich
heterogeneous data sources. Furthermore, we have evaluated our design under
experimental research conditions, achieving a robust compromise between
functionality and overhead. Besides, it demonstrates a stable and scalable
performance.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03662" title="Abstract">arXiv:2403.03662</a> [<a href="/pdf/2403.03662" title="Download PDF">pdf</a>, <a href="/format/2403.03662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Meta-Learning for Improving Full-Frame Video Stabilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M+K">Muhammad Kashif Ali</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+E+W">Eun Woo Im</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T+H">Tae Hyun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video stabilization is a longstanding computer vision problem, particularly
pixel-level synthesis solutions for video stabilization which synthesize full
frames add to the complexity of this task. These techniques aim to stabilize
videos by synthesizing full frames while enhancing the stability of the
considered video. This intensifies the complexity of the task due to the
distinct mix of unique motion profiles and visual content present in each video
sequence, making robust generalization with fixed parameters difficult. In our
study, we introduce a novel approach to enhance the performance of pixel-level
synthesis solutions for video stabilization by adapting these models to
individual input video sequences. The proposed adaptation exploits low-level
visual cues accessible during test-time to improve both the stability and
quality of resulting videos. We highlight the efficacy of our methodology of
"test-time adaptation" through simple fine-tuning of one of these models,
followed by significant stability gain via the integration of meta-learning
techniques. Notably, significant improvement is achieved with only a single
adaptation step. The versatility of the proposed algorithm is demonstrated by
consistently improving the performance of various pixel-level synthesis models
for video stabilization in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03663" title="Abstract">arXiv:2403.03663</a> [<a href="/pdf/2403.03663" title="Download PDF">pdf</a>, <a href="/format/2403.03663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Safety-Critical Control for Systems with Sporadic Measurements  and Dwell Time Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Breeden%2C+J">Joseph Breeden</a>, 
<a href="/search/eess?searchtype=author&query=Zaccarian%2C+L">Luca Zaccarian</a>, 
<a href="/search/eess?searchtype=author&query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version contains additional commentary and the proofs to Lemma 1 and Lemma 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents extensions of control barrier function (CBF) theory to
systems with disturbances wherein a controller only receives measurements
infrequently and operates open-loop between measurements, while still
satisfying state constraints. The paper considers both impulsive and continuous
actuators, and models the actuators, measurements, disturbances, and timing
constraints as a hybrid dynamical system. We then design an open-loop observer
that bounds the worst-case uncertainty between measurements. We develop
definitions of CBFs for both actuation cases, and corresponding conditions on
the control input to guarantee satisfaction of the state constraints. We apply
these conditions to simulations of a satellite rendezvous in an elliptical
orbit and autonomous orbit stationkeeping.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03665" title="Abstract">arXiv:2403.03665</a> [<a href="/pdf/2403.03665" title="Download PDF">pdf</a>, <a href="/format/2403.03665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust radial basis function interpolation based on geodesic distance  for the numerical coupling of multiphysics problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bucelli%2C+M">Michele Bucelli</a>, 
<a href="/search/math?searchtype=author&query=Regazzoni%2C+F">Francesco Regazzoni</a>, 
<a href="/search/math?searchtype=author&query=Dede%27%2C+L">Luca Dede&#x27;</a>, 
<a href="/search/math?searchtype=author&query=Quarteroni%2C+A">Alfio Quarteroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Multiphysics simulations frequently require transferring solution fields
between subproblems with non-matching spatial discretizations, typically using
interpolation techniques. Standard methods are usually based on measuring the
closeness between points by means of the Euclidean distance, which does not
account for curvature, cuts, cavities or other non-trivial geometrical or
topological features of the domain. This may lead to spurious oscillations in
the interpolant in proximity to these features. To overcome this issue, we
propose a modification to rescaled localized radial basis function (RL-RBF)
interpolation to account for the geometry of the interpolation domain, by
yielding conformity and fidelity to geometrical and topological features. The
proposed method, referred to as RL-RBF-G, relies on measuring the geodesic
distance between data points. RL-RBF-G removes spurious oscillations appearing
in the RL-RBF interpolant, resulting in increased accuracy in domains with
complex geometries. We demonstrate the effectiveness of RL-RBF-G interpolation
through a convergence study in an idealized setting. Furthermore, we discuss
the algorithmic aspects and the implementation of RL-RBF-G interpolation in a
distributed-memory parallel framework, and present the results of a strong
scalability test yielding nearly ideal results. Finally, we show the
effectiveness of RL-RBF-G interpolation in multiphysics simulations by
considering an application to a whole-heart cardiac electromecanics model.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03666" title="Abstract">arXiv:2403.03666</a> [<a href="/pdf/2403.03666" title="Download PDF">pdf</a>, <a href="/format/2403.03666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Filter for Real-world Graph Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuanting Xie</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+E">Erlin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph clustering, an important unsupervised problem, has been shown to be
more resistant to advances in Graph Neural Networks (GNNs). In addition, almost
all clustering methods focus on homophilic graphs and ignore heterophily. This
significantly limits their applicability in practice, since real-world graphs
exhibit a structural disparity and cannot simply be classified as homophily and
heterophily. Thus, a principled way to handle practical graphs is urgently
needed. To fill this gap, we provide a novel solution with theoretical support.
Interestingly, we find that most homophilic and heterophilic edges can be
correctly identified on the basis of neighbor information. Motivated by this
finding, we construct two graphs that are highly homophilic and heterophilic,
respectively. They are used to build low-pass and high-pass filters to capture
holistic information. Important features are further enhanced by the
squeeze-and-excitation block. We validate our approach through extensive
experiments on both homophilic and heterophilic graphs. Empirical results
demonstrate the superiority of our method compared to state-of-the-art
clustering methods.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03670" title="Abstract">arXiv:2403.03670</a> [<a href="/pdf/2403.03670" title="Download PDF">pdf</a>, <a href="/format/2403.03670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDC: A Simple Framework for Complex Data Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuanting Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+E">Erlin Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In today's data-driven digital era, the amount as well as complexity, such as
multi-view, non-Euclidean, and multi-relational, of the collected data are
growing exponentially or even faster. Clustering, which unsupervisely extracts
valid knowledge from data, is extremely useful in practice. However, existing
methods are independently developed to handle one particular challenge at the
expense of the others. In this work, we propose a simple but effective
framework for complex data clustering (CDC) that can efficiently process
different types of data with linear complexity. We first utilize graph
filtering to fuse geometry structure and attribute information. We then reduce
the complexity with high-quality anchors that are adaptively learned via a
novel similarity-preserving regularizer. We illustrate the cluster-ability of
our proposed method theoretically and experimentally. In particular, we deploy
CDC to graph data of size 111M.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03671" title="Abstract">arXiv:2403.03671</a> [<a href="/pdf/2403.03671" title="Download PDF">pdf</a>, <a href="/format/2403.03671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portraying the Need for Temporal Data in Flood Detection via Sentinel-1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bou%2C+X">Xavier Bou</a>, 
<a href="/search/cs?searchtype=author&query=Ehret%2C+T">Thibaud Ehret</a>, 
<a href="/search/cs?searchtype=author&query=von+Gioi%2C+R+G">Rafael Grompone von Gioi</a>, 
<a href="/search/cs?searchtype=author&query=Anger%2C+J">Jeremy Anger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Identifying flood affected areas in remote sensing data is a critical problem
in earth observation to analyze flood impact and drive responses. While a
number of methods have been proposed in the literature, there are two main
limitations in available flood detection datasets: (1) a lack of region
variability is commonly observed and/or (2) they require to distinguish
permanent water bodies from flooded areas from a single image, which becomes an
ill-posed setup. Consequently, we extend the globally diverse MMFlood dataset
to multi-date by providing one year of Sentinel-1 observations around each
flood event. To our surprise, we notice that the definition of flooded pixels
in MMFlood is inconsistent when observing the entire image sequence. Hence, we
re-frame the flood detection task as a temporal anomaly detection problem,
where anomalous water bodies are segmented from a Sentinel-1 temporal sequence.
From this definition, we provide a simple method inspired by the popular video
change detector ViBe, results of which quantitatively align with the SAR image
time series, providing a reasonable baseline for future works.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03672" title="Abstract">arXiv:2403.03672</a> [<a href="/pdf/2403.03672" title="Download PDF">pdf</a>, <a href="/ps/2403.03672" title="Download PostScript">ps</a>, <a href="/format/2403.03672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Adversarial MDPs with Stochastic Hard Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stradi%2C+F+E">Francesco Emanuele Stradi</a>, 
<a href="/search/cs?searchtype=author&query=Castiglioni%2C+M">Matteo Castiglioni</a>, 
<a href="/search/cs?searchtype=author&query=Marchesi%2C+A">Alberto Marchesi</a>, 
<a href="/search/cs?searchtype=author&query=Gatti%2C+N">Nicola Gatti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study online learning problems in constrained Markov decision processes
(CMDPs) with adversarial losses and stochastic hard constraints. We consider
two different scenarios. In the first one, we address general CMDPs, where we
design an algorithm that attains sublinear regret and cumulative positive
constraints violation. In the second scenario, under the mild assumption that a
policy strictly satisfying the constraints exists and is known to the learner,
we design an algorithm that achieves sublinear regret while ensuring that the
constraints are satisfied at every episode with high probability. To the best
of our knowledge, our work is the first to study CMDPs involving both
adversarial losses and hard constraints. Indeed, previous works either focus on
much weaker soft constraints--allowing for positive violation to cancel out
negative ones--or are restricted to stochastic losses. Thus, our algorithms can
deal with general non-stationary environments subject to requirements much
stricter than those manageable with state-of-the-art algorithms. This enables
their adoption in a much wider range of real-world applications, ranging from
autonomous driving to online advertising and recommender systems.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03674" title="Abstract">arXiv:2403.03674</a> [<a href="/pdf/2403.03674" title="Download PDF">pdf</a>, <a href="/format/2403.03674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Infrared Geometry: Using Geometry to Perform Adversarial  Attack against Infrared Pedestrian Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiliwalidi%2C+K">Kalibinuer Tiliwalidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.14217">arXiv:2312.14217</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Currently, infrared imaging technology enjoys widespread usage, with infrared
object detection technology experiencing a surge in prominence. While previous
studies have delved into physical attacks on infrared object detectors, the
implementation of these techniques remains complex. For instance, some
approaches entail the use of bulb boards or infrared QR suits as perturbations
to execute attacks, which entail costly optimization and cumbersome deployment
processes. Other methodologies involve the utilization of irregular aerogel as
physical perturbations for infrared attacks, albeit at the expense of
optimization expenses and perceptibility issues. In this study, we propose a
novel infrared physical attack termed Adversarial Infrared Geometry
(\textbf{AdvIG}), which facilitates efficient black-box query attacks by
modeling diverse geometric shapes (lines, triangles, ellipses) and optimizing
their physical parameters using Particle Swarm Optimization (PSO). Extensive
experiments are conducted to evaluate the effectiveness, stealthiness, and
robustness of AdvIG. In digital attack experiments, line, triangle, and ellipse
patterns achieve attack success rates of 93.1\%, 86.8\%, and 100.0\%,
respectively, with average query times of 71.7, 113.1, and 2.57, respectively,
thereby confirming the efficiency of AdvIG. Physical attack experiments are
conducted to assess the attack success rate of AdvIG at different distances. On
average, the line, triangle, and ellipse achieve attack success rates of
61.1\%, 61.2\%, and 96.2\%, respectively. Further experiments are conducted to
comprehensively analyze AdvIG, including ablation experiments, transfer attack
experiments, and adversarial defense mechanisms. Given the superior performance
of our method as a simple and efficient black-box adversarial attack in both
digital and physical environments, we advocate for widespread attention to
AdvIG.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03675" title="Abstract">arXiv:2403.03675</a> [<a href="/pdf/2403.03675" title="Download PDF">pdf</a>, <a href="/format/2403.03675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZF Beamforming Tensor Compression for Massive MIMO Fronthaul
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Libin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+M">Minru Bai</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhenjie Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the rapidly evolving landscape of 5G and beyond 5G (B5G) mobile cellular
communications, efficient data compression and reconstruction strategies become
paramount, especially in massive multiple-input multiple-output (MIMO) systems.
A critical challenge in these systems is the capacity-limited fronthaul,
particularly in the context of the Ethernet-based common public radio interface
(eCPRI) connecting baseband units (BBUs) and remote radio units (RRUs). This
capacity limitation hinders the effective handling of increased traffic and
data flows. We propose a novel two-stage compression approach to address this
bottleneck. The first stage employs sparse Tucker decomposition, targeting the
weight tensor's low-rank components for compression. The second stage further
compresses these components using complex givens decomposition and run-length
encoding, substantially improving the compression ratio. Our approach
specifically targets the Zero-Forcing (ZF) beamforming weights in BBUs. By
reconstructing these weights in RRUs, we significantly alleviate the burden on
eCPRI traffic, enabling a higher number of concurrent streams in the radio
access network (RAN). Through comprehensive evaluations, we demonstrate the
superior effectiveness of our method in Channel State Information (CSI)
compression, paving the way for more efficient 5G/B5G fronthaul links.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03676" title="Abstract">arXiv:2403.03676</a> [<a href="/pdf/2403.03676" title="Download PDF">pdf</a>, <a href="/format/2403.03676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplified PCNet with Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuanting Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+H">Haoxiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Ruiyi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have garnered significant attention for their
success in learning the representation of homophilic or heterophilic graphs.
However, they cannot generalize well to real-world graphs with different levels
of homophily. In response, the Possion-Charlier Network (PCNet)
\cite{li2024pc}, the previous work, allows graph representation to be learned
from heterophily to homophily. Although PCNet alleviates the heterophily issue,
there remain some challenges in further improving the efficacy and efficiency.
In this paper, we simplify PCNet and enhance its robustness. We first extend
the filter order to continuous values and reduce its parameters. Two variants
with adaptive neighborhood sizes are implemented. Theoretical analysis shows
our model's robustness to graph structure perturbations or adversarial attacks.
We validate our approach through semi-supervised learning tasks on various
datasets representing both homophilic and heterophilic graphs.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03677" title="Abstract">arXiv:2403.03677</a> [<a href="/pdf/2403.03677" title="Download PDF">pdf</a>, <a href="/format/2403.03677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Bi-modal Question Title Generation for Stack Overflow with  Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaoyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Ke Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chi Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Empirical Software Engineering 2024 (EMSE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">When drafting question posts for Stack Overflow, developers may not
accurately summarize the core problems in the question titles, which can cause
these questions to not get timely help. Therefore, improving the quality of
question titles has attracted the wide attention of researchers. An initial
study aimed to automatically generate the titles by only analyzing the code
snippets in the question body. However, this study ignored the helpful
information in their corresponding problem descriptions. Therefore, we propose
an approach SOTitle+ by considering bi-modal information (i.e., the code
snippets and the problem descriptions) in the question body. Then we formalize
the title generation for different programming languages as separate but
related tasks and utilize multi-task learning to solve these tasks. Later we
fine-tune the pre-trained language model CodeT5 to automatically generate the
titles. Unfortunately, the inconsistent inputs and optimization objectives
between the pre-training task and our investigated task may make fine-tuning
hard to fully explore the knowledge of the pre-trained model. To solve this
issue, SOTitle+ further prompt-tunes CodeT5 with hybrid prompts (i.e., mixture
of hard and soft prompts). To verify the effectiveness of SOTitle+, we
construct a large-scale high-quality corpus from recent data dumps shared by
Stack Overflow. Our corpus includes 179,119 high-quality question posts for six
popular programming languages. Experimental results show that SOTitle+ can
significantly outperform four state-of-the-art baselines in both automatic
evaluation and human evaluation. Our work indicates that considering bi-modal
information and prompt learning in Stack Overflow title generation is a
promising exploration direction.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03678" title="Abstract">arXiv:2403.03678</a> [<a href="/pdf/2403.03678" title="Download PDF">pdf</a>, <a href="/format/2403.03678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Deep Learning Reduced-Order Modeling for Single-Phase  Flow in Faulted Porous Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ballini%2C+E">Enrico Ballini</a>, 
<a href="/search/math?searchtype=author&query=Formaggia%2C+L">Luca Formaggia</a>, 
<a href="/search/math?searchtype=author&query=Fumagalli%2C+A">Alessio Fumagalli</a>, 
<a href="/search/math?searchtype=author&query=Scotti%2C+A">Anna Scotti</a>, 
<a href="/search/math?searchtype=author&query=Zunino%2C+P">Paolo Zunino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We apply reduced-order modeling (ROM) techniques to single-phase flow in
faulted porous media, accounting for changing rock properties and fault
geometry variations using a radial basis function mesh deformation method. This
approach benefits from a mixed-dimensional framework that effectively manages
the resulting non-conforming mesh. To streamline complex and repetitive
calculations such as sensitivity analysis and solution of inverse problems, we
utilize the Deep Learning Reduced Order Model (DL-ROM). This non-intrusive
neural network-based technique is evaluated against the traditional Proper
Orthogonal Decomposition (POD) method across various scenarios, demonstrating
DL-ROM's capacity to expedite complex analyses with promising accuracy and
efficiency.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03680" title="Abstract">arXiv:2403.03680</a> [<a href="/pdf/2403.03680" title="Download PDF">pdf</a>, <a href="/format/2403.03680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A field- and time-normalized Bayesian approach to measuring the impact  of a publication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-D%C3%A9niz%2C+E">Emilio G&#xf3;mez-D&#xe9;niz</a>, 
<a href="/search/cs?searchtype=author&query=Dorta-Gonz%C3%A1lez%2C+P">Pablo Dorta-Gonz&#xe1;lez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Applications (stat.AP); Computation (stat.CO)

</div>
<p class="mathjax">Measuring the impact of a publication in a fair way is a significant
challenge in bibliometrics, as it must not introduce biases between fields and
should enable comparison of the impact of publications from different years. In
this paper, we propose a Bayesian approach to tackle this problem, motivated by
empirical data demonstrating heterogeneity in citation distributions. The
approach uses the a priori distribution of citations in each field to estimate
the expected a posteriori distribution in that field. This distribution is then
employed to normalize the citations received by a publication in that field.
Our main contribution is the Bayesian Impact Score, a measure of the impact of
a publication. This score is increasing and concave with the number of
citations received and decreasing and convex with the age of the publication.
This means that the marginal score of an additional citation decreases as the
cumulative number of citations increases and increases as the time since
publication of the document grows. Finally, we present an empirical application
of our approach in eight subject categories using the Scopus database and a
comparison with the normalized impact indicator Field Citation Ratio from the
Dimensions AI database.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03681" title="Abstract">arXiv:2403.03681</a> [<a href="/pdf/2403.03681" title="Download PDF">pdf</a>, <a href="/format/2403.03681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Object Visibility Prediction in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chuanyu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Nuo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ren Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haipeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Aoli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the rapid advancement of hardware and software technologies, research in
autonomous driving has seen significant growth. The prevailing framework for
multi-sensor autonomous driving encompasses sensor installation, perception,
path planning, decision-making, and motion control. At the perception phase, a
common approach involves utilizing neural networks to infer 3D bounding box
(Bbox) attributes from raw sensor data, including classification, size, and
orientation. In this paper, we present a novel attribute and its corresponding
algorithm: 3D object visibility. By incorporating multi-task learning, the
introduction of this attribute, visibility, negligibly affects the model's
effectiveness and efficiency. Our proposal of this attribute and its
computational strategy aims to expand the capabilities for downstream tasks,
thereby enhancing the safety and reliability of real-time autonomous driving in
real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03683" title="Abstract">arXiv:2403.03683</a> [<a href="/pdf/2403.03683" title="Download PDF">pdf</a>, <a href="/format/2403.03683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Visual Debugger: Past, Present, and Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4uter%2C+T">Tim Kr&#xe4;uter</a>, 
<a href="/search/cs?searchtype=author&query=St%C3%BCnkel%2C+P">Patrick St&#xfc;nkel</a>, 
<a href="/search/cs?searchtype=author&query=Rutle%2C+A">Adrian Rutle</a>, 
<a href="/search/cs?searchtype=author&query=Lamo%2C+Y">Yngve Lamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 First IDE Workshop (IDE '24), April 20, 2024, Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The Visual Debugger is an IntelliJ IDEA plugin that presents debug
information as an object diagram to enhance program understanding. Reflecting
on our past development, we detail the lessons learned and roadblocks we have
experienced while implementing and integrating the Visual Debugger into the
IntelliJ IDEA. Furthermore, we describe recent improvements to the Visual
Debugger, greatly enhancing the plugin in the present. Looking into the future,
we propose solutions to overcome the roadblocks encountered while developing
the plugin and further plans for the Visual Debugger.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03684" title="Abstract">arXiv:2403.03684</a> [<a href="/pdf/2403.03684" title="Download PDF">pdf</a>, <a href="/format/2403.03684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Media Influence on Covid-19 Mask-Wearing Beliefs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rabb%2C+N">Nicholas Rabb</a>, 
<a href="/search/cs?searchtype=author&query=Nadgir%2C+N">Nitya Nadgir</a>, 
<a href="/search/cs?searchtype=author&query=de+Ruiter%2C+J+P">Jan P. de Ruiter</a>, 
<a href="/search/cs?searchtype=author&query=Cowen%2C+L">Lenore Cowen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">How political beliefs change in accordance with media exposure is a
complicated matter. Some studies have been able to demonstrate that groups with
different media diets in the aggregate (e.g., U.S. media consumers ingesting
partisan news) arrive at different beliefs about policy issues, but proving
this from data at a granular level -- at the level of attitudes expressed in
news stories -- remains difficult. In contrast to existing opinion formation
models that describe granular detail but are not data-driven, or data-driven
studies that rely on simple keyword detection and miss linguistic nuances,
being able to identify complicated attitudes in news text and use this data to
drive models would enable more nuanced empirical study of opinion formation
from media messaging. This study contributes a dataset as well as an analysis
that allows the mapping of attitudes from individual news stories to aggregate
changes of opinion over time for an important public health topic where opinion
differed in the U.S. by partisan media diet: Covid mask-wearing beliefs. By
gathering a dataset of U.S. news media stories, from April 6 to June 8, 2020,
annotated according to Howard 2020's Face Mask Perception Scale for their
statements regarding Covid-19 mask-wearing, we demonstrate fine-grained
correlations between media messaging and empirical opinion polling data from a
Gallup survey conducted during the same period. We also demonstrate that the
data can be used for quantitative analysis of pro- and anti-mask sentiment
throughout the period, identifying major events that drove opinion changes.
This dataset is made publicly available and can be used by other researchers
seeking to evaluate how mask-wearing attitudes were driven by news media
content. Additionally, we hope that its general method can be used to enable
other media researchers to conduct more detailed analyses of media effects on
opinion.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03689" title="Abstract">arXiv:2403.03689</a> [<a href="/pdf/2403.03689" title="Download PDF">pdf</a>, <a href="/format/2403.03689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General2Specialized LLMs Translation for E-commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Ben Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dehong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huangyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+W">Wei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shanqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Libin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaoyan Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, WWW2024 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing Neural Machine Translation (NMT) models mainly handle translation in
the general domain, while overlooking domains with special writing formulas,
such as e-commerce and legal documents. Taking e-commerce as an example, the
texts usually include amounts of domain-related words and have more grammar
problems, which leads to inferior performances of current NMT methods. To
address these problems, we collect two domain-related resources, including a
set of term pairs (aligned Chinese-English bilingual terms) and a parallel
corpus annotated for the e-commerce domain. Furthermore, we propose a two-step
fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to
transfer one general NMT model to the specialized NMT model for e-commerce. The
paradigm can be used for the NMT models based on Large language models (LLMs).
Extensive evaluations on real e-commerce titles demonstrate the superior
translation quality and robustness of our G2ST approach, as compared with
state-of-the-art NMT models such as LLaMA, Qwen, GPT-3.5, and even GPT-4.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03690" title="Abstract">arXiv:2403.03690</a> [<a href="/pdf/2403.03690" title="Download PDF">pdf</a>, <a href="/ps/2403.03690" title="Download PostScript">ps</a>, <a href="/format/2403.03690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapidly Developing High-quality Instruction Data and Evaluation  Benchmark for Large Language Models with Minimal Human Effort: A Case Study  on Japanese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yikun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ueda%2C+N">Nobuhiro Ueda</a>, 
<a href="/search/cs?searchtype=author&query=Yahata%2C+S">Sakiko Yahata</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Fei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chenhui Chu</a>, 
<a href="/search/cs?searchtype=author&query=Kurohashi%2C+S">Sadao Kurohashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COLING 2024. Our code are available here: \href{<a href="https://github.com/hitoshizuku7/awesome-Ja-self-instruct">this https URL</a>}{self-instruct data} and \href{<a href="https://github.com/ku-nlp/ja-vicuna-qa-benchmark">this https URL</a>}{evaluation benchmark}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The creation of instruction data and evaluation benchmarks for serving Large
language models often involves enormous human annotation. This issue becomes
particularly pronounced when rapidly developing such resources for a
non-English language like Japanese. Instead of following the popular practice
of directly translating existing English resources into Japanese (e.g.,
Japanese-Alpaca), we propose an efficient self-instruct method based on GPT-4.
We first translate a small amount of English instructions into Japanese and
post-edit them to obtain native-level quality. GPT-4 then utilizes them as
demonstrations to automatically generate Japanese instruction data. We also
construct an evaluation benchmark containing 80 questions across 8 categories,
using GPT-4 to automatically assess the response quality of LLMs without human
references. The empirical results suggest that the models fine-tuned on our
GPT-4 self-instruct data significantly outperformed the Japanese-Alpaca across
all three base pre-trained models. Our GPT-4 self-instruct data allowed the
LLaMA 13B model to defeat GPT-3.5 (Davinci-003) with a 54.37\% win-rate. The
human evaluation exhibits the consistency between GPT-4's assessments and human
preference. Our high-quality instruction data and evaluation benchmark have
been released here.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03691" title="Abstract">arXiv:2403.03691</a> [<a href="/pdf/2403.03691" title="Download PDF">pdf</a>, <a href="/format/2403.03691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolNexTR: A Generalized Deep Learning Model for Molecular Image  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+C+T">Ching Ting Leung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hanyu Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Journal of Cheminformatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of chemical structure recognition, the task of converting
molecular images into graph structures and SMILES string stands as a
significant challenge, primarily due to the varied drawing styles and
conventions prevalent in chemical literature. To bridge this gap, we proposed
MolNexTR, a novel image-to-graph deep learning model that collaborates to fuse
the strengths of ConvNext, a powerful Convolutional Neural Network variant, and
Vision-TRansformer. This integration facilitates a more nuanced extraction of
both local and global features from molecular images. MolNexTR can predict
atoms and bonds simultaneously and understand their layout rules. It also
excels at flexibly integrating symbolic chemistry principles to discern
chirality and decipher abbreviated structures. We further incorporate a series
of advanced algorithms, including improved data augmentation module, image
contamination module, and a post-processing module to get the final SMILES
output. These modules synergistically enhance the model's robustness against
the diverse styles of molecular imagery found in real literature. In our test
sets, MolNexTR has demonstrated superior performance, achieving an accuracy
rate of 81-97%, marking a significant advancement in the domain of molecular
structure recognition. Scientific contribution: MolNexTR is a novel
image-to-graph model that incorporates a unique dual-stream encoder to extract
complex molecular image features, and combines chemical rules to predict atoms
and bonds while understanding atom and bond layout rules. In addition, it
employs a series of novel augmentation algorithms to significantly enhance the
robustness and performance of the model.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03696" title="Abstract">arXiv:2403.03696</a> [<a href="/pdf/2403.03696" title="Download PDF">pdf</a>, <a href="/ps/2403.03696" title="Download PostScript">ps</a>, <a href="/format/2403.03696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Largest common subgraph of two forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rautenbach%2C+D">Dieter Rautenbach</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+F">Florian Werner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">A common subgraph of two graphs $G_1$ and $G_2$ is a graph that is isomorphic
to subgraphs of $G_1$ and $G_2$. In the largest common subgraph problem the
task is to determine a common subgraph for two given graphs $G_1$ and $G_2$
that is of maximum possible size ${\rm lcs}(G_1,G_2)$. This natural problem
generalizes the well-studied graph isomorphism problem, has many applications,
and remains NP-hard even restricted to unions of paths. We present a simple
$4$-approximation algorithm for forests, and, for every fixed $\epsilon\in
(0,1)$, we show that, for two given forests $F_1$ and $F_2$ of order at most
$n$, one can determine in polynomial time a common subgraph $F$ of $F_1$ and
$F_2$ with at least ${\rm lcs}(F_1,F_2)-\epsilon n$ edges. Restricted to
instances with ${\rm lcs}(F_1,F_2)\geq cn$ for some fixed positive $c$, this
yields a polynomial time approximation scheme. Our approach relies on the
approximation of the given forests by structurally simpler forests that are
composed of copies of only $O(\log (n))$ different starlike rooted trees and
iterative quantizations of the options for the solutions.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03698" title="Abstract">arXiv:2403.03698</a> [<a href="/pdf/2403.03698" title="Download PDF">pdf</a>, <a href="/format/2403.03698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Controllable Time Series Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yifan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Ang%2C+Y">Yihao Ang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+A+K+H">Anthony K. H. Tung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyong Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures, and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
<p class="mathjax">Time Series Generation (TSG) has emerged as a pivotal technique in
synthesizing data that accurately mirrors real-world time series, becoming
indispensable in numerous applications. Despite significant advancements in
TSG, its efficacy frequently hinges on having large training datasets. This
dependency presents a substantial challenge in data-scarce scenarios,
especially when dealing with rare or unique conditions. To confront these
challenges, we explore a new problem of Controllable Time Series Generation
(CTSG), aiming to produce synthetic time series that can adapt to various
external conditions, thereby tackling the data scarcity issue.
<br />In this paper, we propose \textbf{C}ontrollable \textbf{T}ime \textbf{S}eries
(\textsf{CTS}), an innovative VAE-agnostic framework tailored for CTSG. A key
feature of \textsf{CTS} is that it decouples the mapping process from standard
VAE training, enabling precise learning of a complex interplay between latent
features and external conditions. Moreover, we develop a comprehensive
evaluation scheme for CTSG. Extensive experiments across three real-world time
series datasets showcase \textsf{CTS}'s exceptional capabilities in generating
high-quality, controllable outputs. This underscores its adeptness in
seamlessly integrating latent features with external conditions. Extending
\textsf{CTS} to the image domain highlights its remarkable potential for
explainability and further reinforces its versatility across different
modalities.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03699" title="Abstract">arXiv:2403.03699</a> [<a href="/pdf/2403.03699" title="Download PDF">pdf</a>, <a href="/format/2403.03699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Parallelism on Distributed Infrastructure: A Literature Review  from Theory to LLM Case-Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brakel%2C+F">Felix Brakel</a>, 
<a href="/search/cs?searchtype=author&query=Odyurt%2C+U">Uraz Odyurt</a>, 
<a href="/search/cs?searchtype=author&query=Varbanescu%2C+A">Ana-Lucia Varbanescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural networks have become a cornerstone of machine learning. As the trend
for these to get more and more complex continues, so does the underlying
hardware and software infrastructure for training and deployment. In this
survey we answer three research questions: "What types of model parallelism
exist?", "What are the challenges of model parallelism?", and "What is a modern
use-case of model parallelism?" We answer the first question by looking at how
neural networks can be parallelised and expressing these as operator graphs
while exploring the available dimensions. The dimensions along which neural
networks can be parallelised are intra-operator and inter-operator. We answer
the second question by collecting and listing both implementation challenges
for the types of parallelism, as well as the problem of optimally partitioning
the operator graph. We answer the last question by collecting and listing how
parallelism is applied in modern multi-billion parameter transformer networks,
to the extend that this is possible with the limited information shared about
these networks.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03701" title="Abstract">arXiv:2403.03701</a> [<a href="/pdf/2403.03701" title="Download PDF">pdf</a>, <a href="/format/2403.03701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Testing of RESTful APIs With Test Case Mutation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salva%2C+S">Sebastien Salva</a>, 
<a href="/search/cs?searchtype=author&query=Sue%2C+J">Jarod Sue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The focus of this paper is on automating the security testing of RESTful
APIs. The testing stage of this specific kind of components is often performed
manually, and this is yet considered as a long and difficult activity. This
paper proposes an automated approach to help developers generate test cases for
experimenting with each service in isolation. This approach is based upon the
notion of test case mutation, which automatically generates new test cases from
an original test case set. Test case mutation operators perform slight test
case modifications to mimic possible failures or to test the component under
test with new interactions. In this paper, we examine test case mutation
operators for RESTful APIs and define 17 operators specialised in security
testing. Then, we present our test case mutation algorithm. We evaluate its
effectiveness and performance on four web service compositions.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03704" title="Abstract">arXiv:2403.03704</a> [<a href="/pdf/2403.03704" title="Download PDF">pdf</a>, <a href="/ps/2403.03704" title="Download PostScript">ps</a>, <a href="/format/2403.03704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Prototype-inspired Contrast Adaptation for Unsupervised Domain  Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Ya Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Geng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Liang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures and 7 tables, submitted to IEEE Transactions on Geoscience and Remote Sensing, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation of high-resolution remote sensing imagery (HRSI)
suffers from the domain shift, resulting in poor performance of the model in
another unseen domain. Unsupervised domain adaptive (UDA) semantic segmentation
aims to adapt the semantic segmentation model trained on the labeled source
domain to an unlabeled target domain. However, the existing UDA semantic
segmentation models tend to align pixels or features based on statistical
information related to labels in source and target domain data, and make
predictions accordingly, which leads to uncertainty and fragility of prediction
results. In this paper, we propose a causal prototype-inspired contrast
adaptation (CPCA) method to explore the invariant causal mechanisms between
different HRSIs domains and their semantic labels. It firstly disentangles
causal features and bias features from the source and target domain images
through a causal feature disentanglement module. Then, a causal prototypical
contrast module is used to learn domain invariant causal features. To further
de-correlate causal and bias features, a causal intervention module is
introduced to intervene on the bias features to generate counterfactual
unbiased samples. By forcing the causal features to meet the principles of
separability, invariance and intervention, CPCA can simulate the causal factors
of source and target domains, and make decisions on the target domain based on
the causal features, which can observe improved generalization ability.
Extensive experiments under three cross-domain tasks indicate that CPCA is
remarkably superior to the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03707" title="Abstract">arXiv:2403.03707</a> [<a href="/pdf/2403.03707" title="Download PDF">pdf</a>, <a href="/format/2403.03707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Grained Cross-modal Alignment for Learning Open-vocabulary  Semantic Segmentation from Text Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yajie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+P">Pu Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, learning open-vocabulary semantic segmentation from text
supervision has achieved promising downstream performance. Nevertheless,
current approaches encounter an alignment granularity gap owing to the absence
of dense annotations, wherein they learn coarse image/region-text alignment
during training yet perform group/pixel-level predictions at inference. Such
discrepancy leads to suboptimal learning efficiency and inferior zero-shot
segmentation results. In this paper, we introduce a Multi-Grained Cross-modal
Alignment (MGCA) framework, which explicitly learns pixel-level alignment along
with object- and region-level alignment to bridge the granularity gap without
any dense annotations. Specifically, MGCA ingeniously constructs pseudo
multi-granular semantic correspondences upon image-text pairs and collaborates
with hard sampling strategies to facilitate fine-grained cross-modal
contrastive learning. Further, we point out the defects of existing group and
pixel prediction units in downstream segmentation and develop an adaptive
semantic unit which effectively mitigates their dilemmas including under- and
over-segmentation. Training solely on CC3M, our method achieves significant
advancements over state-of-the-art methods, demonstrating its effectiveness and
efficiency.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03709" title="Abstract">arXiv:2403.03709</a> [<a href="/pdf/2403.03709" title="Download PDF">pdf</a>, <a href="/format/2403.03709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portable, heterogeneous ensemble workflows at scale using libEnsemble
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hudson%2C+S">Stephen Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+J">Jeffrey Larson</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+J">John-Luke Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Wild%2C+S+M">Stefan M. Wild</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">libEnsemble is a Python-based toolkit for running dynamic ensembles,
developed as part of the DOE Exascale Computing Project. The toolkit utilizes a
unique generator--simulator--allocator paradigm, where generators produce input
for simulators, simulators evaluate those inputs, and allocators decide whether
and when a simulator or generator should be called. The generator steers the
ensemble based on simulation results.
<br />libEnsemble communicates between a manager and workers. Flexibility is
provided through multiple manager--worker communication substrates each of
which has different benefits. These include Python's multiprocessing, mpi4py,
and TCP. Multisite ensembles are supported using Balsam or Globus Compute.
<br />We overview the unique characteristics of libEnsemble as well as current and
potential interoperability with other packages in the workflow ecosystem. We
highlight libEnsemble's dynamic resource features: libEnsemble can detect
system resources (nodes, cores, and GPUs) and assign these in a portable way.
These features allow users to specify resources required for each simulation
automatically on a range of systems, including Frontier, Aurora, and
Perlmutter. Such ensembles can include multiple simulation types, some using
GPUs and others using only CPUs, sharing nodes for maximum efficiency.
<br />We demonstrate libEnsemble's capabilities, scalability, and scientific impact
via a Gaussian process surrogate training problem for the longitudinal density
profile at the exit of a plasma accelerator stage using Wake-T and WarpX
simulations. We also describe the benefits of libEnsemble's
generator--simulator coupling, which easily exposes to the user the ability to
cancel, and portably kill, running simulations. Such control can be directed
from the generator or allocator based on models that are updated with
intermediate simulation output.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03712" title="Abstract">arXiv:2403.03712</a> [<a href="/pdf/2403.03712" title="Download PDF">pdf</a>, <a href="/ps/2403.03712" title="Download PostScript">ps</a>, <a href="/format/2403.03712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturating Sorting without Sorts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+P">Pamina Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Hajdu%2C+M">M&#xe1;rton Hajdu</a>, 
<a href="/search/cs?searchtype=author&query=Kov%C3%A1cs%2C+L">Laura Kov&#xe1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">We present a first-order theorem proving framework for establishing the
correctness of functional programs implementing sorting algorithms with
recursive data structures.
<br />We formalize the semantics of recursive programs in many-sorted first-order
logic and integrate sortedness/permutation properties within our first-order
formalization. Rather than focusing on sorting lists of elements of specific
first-order theories, such as integer arithmetic, our list formalization relies
on a sort parameter abstracting (arithmetic) theories and hence concrete sorts.
We formalize the permutation property of lists in first-order logic so that we
automatically prove verification conditions of such algorithms purely by
superpositon-based first-order reasoning. Doing so, we adjust recent efforts
for automating inducion in saturation. We advocate a compositional approach for
automating proofs by induction required to verify functional programs
implementing and preserving sorting and permutation properties over
parameterized list structures. Our work turns saturation-based first-order
theorem proving into an automated verification engine by (i) guiding automated
inductive reasoning with manual proof splits and (ii) fully automating
inductive reasoning in saturation. We showcase the applicability of our
framework over recursive sorting algorithms, including Mergesort and Quicksort.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03714" title="Abstract">arXiv:2403.03714</a> [<a href="/pdf/2403.03714" title="Download PDF">pdf</a>, <a href="/format/2403.03714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intent-aware Recommendation via Disentangled Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiangzhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengdi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zirui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCAI 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> [C]//Proceedings of the 32th international joint conference on
  artificial intelligence. 2023: 2343-2351
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Graph neural network (GNN) based recommender systems have become one of the
mainstream trends due to the powerful learning ability from user behavior data.
Understanding the user intents from behavior data is the key to recommender
systems, which poses two basic requirements for GNN-based recommender systems.
One is how to learn complex and diverse intents especially when the user
behavior is usually inadequate in reality. The other is different behaviors
have different intent distributions, so how to establish their relations for a
more explainable recommender system. In this paper, we present the Intent-aware
Recommendation via Disentangled Graph Contrastive Learning (IDCL), which
simultaneously learns interpretable intents and behavior distributions over
those intents. Specifically, we first model the user behavior data as a
user-item-concept graph, and design a GNN based behavior disentangling module
to learn the different intents. Then we propose the intent-wise contrastive
learning to enhance the intent disentangling and meanwhile infer the behavior
distributions. Finally, the coding rate reduction regularization is introduced
to make the behaviors of different intents orthogonal. Extensive experiments
demonstrate the effectiveness of IDCL in terms of substantial improvement and
the interpretability.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03715" title="Abstract">arXiv:2403.03715</a> [<a href="/pdf/2403.03715" title="Download PDF">pdf</a>, <a href="/format/2403.03715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeaCap: Memory-Augmented Zero-shot Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zequn Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengjue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot image captioning (IC) without well-paired image-text data can be
divided into two categories, training-free and text-only-training. Generally,
these two types of methods realize zero-shot IC by integrating pretrained
vision-language models like CLIP for image-text similarity evaluation and a
pre-trained language model (LM) for caption generation. The main difference
between them is whether using a textual corpus to train the LM. Though
achieving attractive performance w.r.t. some metrics, existing methods often
exhibit some common drawbacks. Training-free methods tend to produce
hallucinations, while text-only-training often lose generalization capability.
To move forward, in this paper, we propose a novel Memory-Augmented zero-shot
image Captioning framework (MeaCap). Specifically, equipped with a textual
memory, we introduce a retrieve-then-filter module to get key concepts that are
highly related to the image. By deploying our proposed memory-augmented
visual-related fusion score in a keywords-to-sentence LM, MeaCap can generate
concept-centered captions that keep high consistency with the image with fewer
hallucinations and more world-knowledge. The framework of MeaCap achieves the
state-of-the-art performance on a series of zero-shot IC settings. Our code is
available at https://github.com/joeyz0z/MeaCap.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03719" title="Abstract">arXiv:2403.03719</a> [<a href="/pdf/2403.03719" title="Download PDF">pdf</a>, <a href="/format/2403.03719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Transformer for Comics Text-Cloze
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vivoli%2C+E">Emanuele Vivoli</a>, 
<a href="/search/cs?searchtype=author&query=Baeza%2C+J+L">Joan Lafuente Baeza</a>, 
<a href="/search/cs?searchtype=author&query=Llobet%2C+E+V">Ernest Valveny Llobet</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work explores a closure task in comics, a medium where visual and
textual elements are intricately intertwined. Specifically, Text-cloze refers
to the task of selecting the correct text to use in a comic panel, given its
neighboring panels. Traditional methods based on recurrent neural networks have
struggled with this task due to limited OCR accuracy and inherent model
limitations. We introduce a novel Multimodal Large Language Model
(Multimodal-LLM) architecture, specifically designed for Text-cloze, achieving
a 10% improvement over existing state-of-the-art models in both its easy and
hard variants. Central to our approach is a Domain-Adapted ResNet-50 based
visual encoder, fine-tuned to the comics domain in a self-supervised manner
using SimCLR. This encoder delivers comparable results to more complex models
with just one-fifth of the parameters. Additionally, we release new OCR
annotations for this dataset, enhancing model input quality and resulting in
another 1% improvement. Finally, we extend the task to a generative format,
establishing new baselines and expanding the research possibilities in the
field of comics analysis.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03721" title="Abstract">arXiv:2403.03721</a> [<a href="/pdf/2403.03721" title="Download PDF">pdf</a>, <a href="/format/2403.03721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CMDA: Cross-Modal and Domain Adversarial Adaptation for LiDAR-Based 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+G">Gyusam Chang</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+W">Wonseok Roh</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+S">Sujin Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongwook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Daehyun Ji</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+G">Gyeongrok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinsun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangpil Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent LiDAR-based 3D Object Detection (3DOD) methods show promising results,
but they often do not generalize well to target domains outside the source (or
training) data distribution. To reduce such domain gaps and thus to make 3DOD
models more generalizable, we introduce a novel unsupervised domain adaptation
(UDA) method, called CMDA, which (i) leverages visual semantic cues from an
image modality (i.e., camera images) as an effective semantic bridge to close
the domain gap in the cross-modal Bird's Eye View (BEV) representations.
Further, (ii) we also introduce a self-training-based learning strategy,
wherein a model is adversarially trained to generate domain-invariant features,
which disrupt the discrimination of whether a feature instance comes from a
source or an unseen target domain. Overall, our CMDA framework guides the 3DOD
model to generate highly informative and domain-adaptive features for novel
data distributions. In our extensive experiments with large-scale benchmarks,
such as nuScenes, Waymo, and KITTI, those mentioned above provide significant
performance gains for UDA tasks, achieving state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03724" title="Abstract">arXiv:2403.03724</a> [<a href="/pdf/2403.03724" title="Download PDF">pdf</a>, <a href="/format/2403.03724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In the Search of Optimal Tree Networks: Hardness and Heuristics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buzdalov%2C+M">Maxim Buzdalov</a>, 
<a href="/search/cs?searchtype=author&query=Martynov%2C+P">Pavel Martynov</a>, 
<a href="/search/cs?searchtype=author&query=Pankratov%2C+S">Sergey Pankratov</a>, 
<a href="/search/cs?searchtype=author&query=Aksenov%2C+V">Vitaly Aksenov</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Demand-aware communication networks are networks whose topology is optimized
toward the traffic they need to serve. These networks have recently been
enabled by novel optical communication technologies and are investigated
intensively in the context of datacenters. In this work, we consider networks
with one of the most common topologies~ -- a binary tree.
<br />We show that finding an optimal demand-aware binary tree network is NP-hard.
Then, we propose optimization algorithms that generate efficient binary tree
networks on real-life and synthetic workloads.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03725" title="Abstract">arXiv:2403.03725</a> [<a href="/pdf/2403.03725" title="Download PDF">pdf</a>, <a href="/format/2403.03725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Trust or Not to Trust: Assignment Mechanisms with Predictions in the  Private Graph Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colini-Baldeschi%2C+R">Riccardo Colini-Baldeschi</a>, 
<a href="/search/cs?searchtype=author&query=Klumper%2C+S">Sophie Klumper</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+G">Guido Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Tsikiridis%2C+A">Artem Tsikiridis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The realm of algorithms with predictions has led to the development of
several new algorithms that leverage (potentially erroneous) predictions to
enhance their performance guarantees. The challenge is to devise algorithms
that achieve optimal approximation guarantees as the prediction quality varies
from perfect (consistency) to imperfect (robustness). This framework is
particularly appealing in mechanism design contexts, where predictions might
convey private information about the agents. In this paper, we design
strategyproof mechanisms that leverage predictions to achieve improved
approximation guarantees for several variants of the Generalized Assignment
Problem (GAP) in the private graph model. In this model, first introduced by
Dughmi &amp; Ghosh (2010), the set of resources that an agent is compatible with is
private information. For the Bipartite Matching Problem (BMP), we give a
deterministic group-strategyproof (GSP) mechanism that is $(1
+1/\gamma)$-consistent and $(1 + \gamma)$-robust, where $\gamma \ge 1$ is some
confidence parameter. We also prove that this is best possible. Remarkably, our
mechanism draws inspiration from the renowned Gale-Shapley algorithm,
incorporating predictions as a crucial element. Additionally, we give a
randomized mechanism that is universally GSP and improves on the guarantees in
expectation. The other GAP variants that we consider all make use of a unified
greedy mechanism that adds edges to the assignment according to a specific
order. Our universally GSP mechanism randomizes over the greedy mechanism, our
mechanism for BMP and the predicted assignment, leading to
$(1+3/\gamma)$-consistency and $(3+\gamma)$-robustness in expectation. All our
mechanisms also provide more fine-grained approximation guarantees that
interpolate between the consistency and the robustness, depending on some
natural error measure of the prediction.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03726" title="Abstract">arXiv:2403.03726</a> [<a href="/pdf/2403.03726" title="Download PDF">pdf</a>, <a href="/format/2403.03726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion on language model embeddings for protein sequence generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meshchaninov%2C+V">Viacheslav Meshchaninov</a>, 
<a href="/search/cs?searchtype=author&query=Strashnov%2C+P">Pavel Strashnov</a>, 
<a href="/search/cs?searchtype=author&query=Shevtsov%2C+A">Andrey Shevtsov</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaev%2C+F">Fedor Nikolaev</a>, 
<a href="/search/cs?searchtype=author&query=Ivanisenko%2C+N">Nikita Ivanisenko</a>, 
<a href="/search/cs?searchtype=author&query=Kardymon%2C+O">Olga Kardymon</a>, 
<a href="/search/cs?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Protein design requires a deep understanding of the inherent complexities of
the protein universe. While many efforts lean towards conditional generation or
focus on specific families of proteins, the foundational task of unconditional
generation remains underexplored and undervalued. Here, we explore this pivotal
domain, introducing DiMA, a model that leverages continuous diffusion on
embeddings derived from the protein language model, ESM-2, to generate amino
acid sequences. DiMA surpasses leading solutions, including autoregressive
transformer-based and discrete diffusion models, and we quantitatively
illustrate the impact of the design choices that lead to its superior
performance. We extensively evaluate the quality, diversity, distribution
similarity, and biological relevance of the generated sequences using multiple
metrics across various modalities. Our approach consistently produces novel,
diverse protein sequences that accurately reflect the inherent structural and
functional diversity of the protein space. This work advances the field of
protein design and sets the stage for conditional models by providing a robust
framework for scalable and high-quality protein sequence generation.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03727" title="Abstract">arXiv:2403.03727</a> [<a href="/pdf/2403.03727" title="Download PDF">pdf</a>, <a href="/format/2403.03727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust MITL planning under uncertain navigation times
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Linard%2C+A">Alexis Linard</a>, 
<a href="/search/cs?searchtype=author&query=Gautier%2C+A">Anna Gautier</a>, 
<a href="/search/cs?searchtype=author&query=Duberg%2C+D">Daniel Duberg</a>, 
<a href="/search/cs?searchtype=author&query=Tumova%2C+J">Jana Tumova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">In environments like offices, the duration of a robot's navigation between
two locations may vary over time. For instance, reaching a kitchen may take
more time during lunchtime since the corridors are crowded with people heading
the same way. In this work, we address the problem of routing in such
environments with tasks expressed in Metric Interval Temporal Logic (MITL) - a
rich robot task specification language that allows us to capture explicit time
requirements. Our objective is to find a strategy that maximizes the temporal
robustness of the robot's MITL task. As the first step towards a solution, we
define a Mixed-integer linear programming approach to solving the task planning
problem over a Varying Weighted Transition System, where navigation durations
are deterministic but vary depending on the time of day. Then, we apply this
planner to optimize for MITL temporal robustness in Markov Decision Processes,
where the navigation durations between physical locations are uncertain, but
the time-dependent distribution over possible delays is known. Finally, we
develop a receding horizon planner for Markov Decision Processes that preserves
guarantees over MITL temporal robustness. We show the scalability of our
planning algorithms in simulations of robotic tasks.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03728" title="Abstract">arXiv:2403.03728</a> [<a href="/pdf/2403.03728" title="Download PDF">pdf</a>, <a href="/format/2403.03728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Diversity and Uncertainty in Active learning with  Self-Supervised Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doucet%2C+P">Paul Doucet</a>, 
<a href="/search/cs?searchtype=author&query=Estermann%2C+B">Benjamin Estermann</a>, 
<a href="/search/cs?searchtype=author&query=Aczel%2C+T">Till Aczel</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low Resource Settings (PML4LRS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study addresses the integration of diversity-based and uncertainty-based
sampling strategies in active learning, particularly within the context of
self-supervised pre-trained models. We introduce a straightforward heuristic
called TCM that mitigates the cold start problem while maintaining strong
performance across various data levels. By initially applying TypiClust for
diversity sampling and subsequently transitioning to uncertainty sampling with
Margin, our approach effectively combines the strengths of both strategies. Our
experiments demonstrate that TCM consistently outperforms existing methods
across various datasets in both low and high data regimes.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03730" title="Abstract">arXiv:2403.03730</a> [<a href="/pdf/2403.03730" title="Download PDF">pdf</a>, <a href="/format/2403.03730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning 3D object-centric representation through prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Day%2C+J">John Day</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+T">Tushar Arora</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+E">Li Erran Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M+B">Ming Bo Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures. Project webpage can be found at <a href="https://jday54.github.io/opple_site/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As part of human core knowledge, the representation of objects is the
building block of mental representation that supports high-level concepts and
symbolic reasoning. While humans develop the ability of perceiving objects
situated in 3D environments without supervision, models that learn the same set
of abilities with similar constraints faced by human infants are lacking.
Towards this end, we developed a novel network architecture that simultaneously
learns to 1) segment objects from discrete images, 2) infer their 3D locations,
and 3) perceive depth, all while using only information directly available to
the brain as training data, namely: sequences of images and self-motion. The
core idea is treating objects as latent causes of visual input which the brain
uses to make efficient predictions of future scenes. This results in object
representations being learned as an essential byproduct of learning to predict.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03736" title="Abstract">arXiv:2403.03736</a> [<a href="/pdf/2403.03736" title="Download PDF">pdf</a>, <a href="/format/2403.03736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Generation and Compression: Ultra-low bitrate Image Coding Via  Multi-stage Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+N">Naifu Xue</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siwei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent progress in generative compression technology has significantly
improved the perceptual quality of compressed data. However, these advancements
primarily focus on producing high-frequency details, often overlooking the
ability of generative models to capture the prior distribution of image
content, thus impeding further bitrate reduction in extreme compression
scenarios (&lt;0.05 bpp). Motivated by the capabilities of predictive language
models for lossless compression, this paper introduces a novel Unified Image
Generation-Compression (UIGC) paradigm, merging the processes of generation and
compression. A key feature of the UIGC framework is the adoption of
vector-quantized (VQ) image models for tokenization, alongside a multi-stage
transformer designed to exploit spatial contextual information for modeling the
prior distribution. As such, the dual-purpose framework effectively utilizes
the learned prior for entropy estimation and assists in the regeneration of
lost tokens. Extensive experiments demonstrate the superiority of the proposed
UIGC framework over existing codecs in perceptual quality and human perception,
particularly in ultra-low bitrate scenarios (&lt;=0.03 bpp), pioneering a new
direction in generative compression.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03737" title="Abstract">arXiv:2403.03737</a> [<a href="/pdf/2403.03737" title="Download PDF">pdf</a>, <a href="/format/2403.03737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Topic Modelling with Transformer Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reuter%2C+A">Arik Reuter</a>, 
<a href="/search/cs?searchtype=author&query=Thielmann%2C+A">Anton Thielmann</a>, 
<a href="/search/cs?searchtype=author&query=Weisser%2C+C">Christoph Weisser</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A4fken%2C+B">Benjamin S&#xe4;fken</a>, 
<a href="/search/cs?searchtype=author&query=Kneib%2C+T">Thomas Kneib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Topic modelling was mostly dominated by Bayesian graphical models during the
last decade. With the rise of transformers in Natural Language Processing,
however, several successful models that rely on straightforward clustering
approaches in transformer-based embedding spaces have emerged and consolidated
the notion of topics as clusters of embedding vectors. We propose the
Transformer-Representation Neural Topic Model (TNTM), which combines the
benefits of topic representations in transformer-based embedding spaces and
probabilistic modelling. Therefore, this approach unifies the powerful and
versatile notion of topics based on transformer embeddings with fully
probabilistic modelling, as in models such as Latent Dirichlet Allocation
(LDA). We utilize the variational autoencoder (VAE) framework for improved
inference speed and modelling flexibility. Experimental results show that our
proposed model achieves results on par with various state-of-the-art approaches
in terms of embedding coherence while maintaining almost perfect topic
diversity. The corresponding source code is available at
https://github.com/ArikReuter/TNTM.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03739" title="Abstract">arXiv:2403.03739</a> [<a href="/pdf/2403.03739" title="Download PDF">pdf</a>, <a href="/format/2403.03739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A&amp;B BNN: Add&amp;Bit-Operation-Only Hardware-Friendly Binary Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruichen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+G">Guanchao Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Liwei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+N">Ning Ning</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shaogang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Binary neural networks utilize 1-bit quantized weights and activations to
reduce both the model's storage demands and computational burden. However,
advanced binary architectures still incorporate millions of inefficient and
nonhardware-friendly full-precision multiplication operations. A&amp;B BNN is
proposed to directly remove part of the multiplication operations in a
traditional BNN and replace the rest with an equal number of bit operations,
introducing the mask layer and the quantized RPReLU structure based on the
normalizer-free network architecture. The mask layer can be removed during
inference by leveraging the intrinsic characteristics of BNN with
straightforward mathematical transformations to avoid the associated
multiplication operations. The quantized RPReLU structure enables more
efficient bit operations by constraining its slope to be integer powers of 2.
Experimental results achieved 92.30%, 69.35%, and 66.89% on the CIFAR-10,
CIFAR-100, and ImageNet datasets, respectively, which are competitive with the
state-of-the-art. Ablation studies have verified the efficacy of the quantized
RPReLU structure, leading to a 1.14% enhancement on the ImageNet compared to
using a fixed slope RLeakyReLU. The proposed add&amp;bit-operation-only BNN offers
an innovative approach for hardware-friendly network architecture.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03740" title="Abstract">arXiv:2403.03740</a> [<a href="/pdf/2403.03740" title="Download PDF">pdf</a>, <a href="/format/2403.03740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Photographic Image Layout Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhaoran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xujun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenhao Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In the domain of image layout representation learning, the critical process
of translating image layouts into succinct vector forms is increasingly
significant across diverse applications, such as image retrieval, manipulation,
and generation. Most approaches in this area heavily rely on costly labeled
datasets and notably lack in adapting their modeling and learning methods to
the specific nuances of photographic image layouts. This shortfall makes the
learning process for photographic image layouts suboptimal. In our research, we
directly address these challenges. We innovate by defining basic layout
primitives that encapsulate various levels of layout information and by mapping
these, along with their interconnections, onto a heterogeneous graph structure.
This graph is meticulously engineered to capture the intricate layout
information within the pixel domain explicitly. Advancing further, we introduce
novel pretext tasks coupled with customized loss functions, strategically
designed for effective self-supervised learning of these layout graphs.
Building on this foundation, we develop an autoencoder-based network
architecture skilled in compressing these heterogeneous layout graphs into
precise, dimensionally-reduced layout representations. Additionally, we
introduce the LODB dataset, which features a broader range of layout categories
and richer semantics, serving as a comprehensive benchmark for evaluating the
effectiveness of layout representation learning methods. Our extensive
experimentation on this dataset demonstrates the superior performance of our
approach in the realm of photographic image layout representation learning.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03741" title="Abstract">arXiv:2403.03741</a> [<a href="/pdf/2403.03741" title="Download PDF">pdf</a>, <a href="/format/2403.03741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUPClust: Active Learning at the Boundaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ono%2C+Y">Yuta Ono</a>, 
<a href="/search/cs?searchtype=author&query=Aczel%2C+T">Till Aczel</a>, 
<a href="/search/cs?searchtype=author&query=Estermann%2C+B">Benjamin Estermann</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024 Workshop on Practical Machine Learning for Low Resource Settings (PML4LRS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Active learning is a machine learning paradigm designed to optimize model
performance in a setting where labeled data is expensive to acquire. In this
work, we propose a novel active learning method called SUPClust that seeks to
identify points at the decision boundary between classes. By targeting these
points, SUPClust aims to gather information that is most informative for
refining the model's prediction of complex decision regions. We demonstrate
experimentally that labeling these points leads to strong model performance.
This improvement is observed even in scenarios characterized by strong class
imbalance.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03742" title="Abstract">arXiv:2403.03742</a> [<a href="/pdf/2403.03742" title="Download PDF">pdf</a>, <a href="/format/2403.03742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Ageism through Virtual Reality: Intergenerational  Collaborative Escape Room Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+R">Ruotong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shuyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tianqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+P">Peinuan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yi-Chieh Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">As virtual reality (VR) becomes more popular for intergenerational
collaboration, there is still a significant gap in research regarding
understanding the potential for reducing ageism. Our study aims to address this
gap by analyzing ageism levels before and after VR escape room collaborative
experiences. We recruited 28 participants to collaborate with an older player
in a challenging VR escape room game. To ensure consistent and reliable
performance data of older players, our experimenters simulated older
participants following specific guidelines. After completing the game, we found
a significant reduction in ageism among younger participants. Furthermore, we
introduce a new game mechanism that encourages intergenerational collaboration.
Our research highlights the potential of VR collaborative games as a practical
tool for mitigating ageism. It provides valuable insights for designing
immersive VR experiences that foster enhanced intergenerational collaboration.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03744" title="Abstract">arXiv:2403.03744</a> [<a href="/pdf/2403.03744" title="Download PDF">pdf</a>, <a href="/format/2403.03744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe and Aligned Large Language Models for Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tessa Han</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aounon Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The capabilities of large language models (LLMs) have been progressing at a
breathtaking speed, leaving even their own developers grappling with the depth
of their potential and risks. While initial steps have been taken to evaluate
the safety and alignment of general-knowledge LLMs, exposing some weaknesses,
to our knowledge, the safety and alignment of medical LLMs has not been
evaluated despite their risks for personal health and safety, public health and
safety, and human rights. To this end, we carry out the first safety evaluation
for medical LLMs. Specifically, we set forth a definition of medical safety and
alignment for medical artificial intelligence systems, develop a dataset of
harmful medical questions to evaluate the medical safety and alignment of an
LLM, evaluate both general and medical safety and alignment of medical LLMs,
demonstrate fine-tuning as an effective mitigation strategy, and discuss
broader, large-scale approaches used by the machine learning community to
develop safe and aligned LLMs. We hope that this work casts light on the safety
and alignment of medical LLMs and motivates future work to study it and develop
additional mitigation strategies, minimizing the risks of harm of LLMs in
medicine.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03746" title="Abstract">arXiv:2403.03746</a> [<a href="/pdf/2403.03746" title="Download PDF">pdf</a>, <a href="/format/2403.03746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotional Tandem Robots: How Different Robot Behaviors Affect Human  Perception While Controlling a Mobile Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaduk%2C+J">Julian Kaduk</a>, 
<a href="/search/cs?searchtype=author&query=Weilbeer%2C+F">Friederike Weilbeer</a>, 
<a href="/search/cs?searchtype=author&query=Hamann%2C+H">Heiko Hamann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In human-robot interaction (HRI), we study how humans interact with robots,
but also the effects of robot behavior on human perception and well-being.
Especially, the influence on humans by tandem robots with one human controlled
and one autonomous robot or even semi-autonomous multi-robot systems is not yet
fully understood. Here, we focus on a leader-follower scenario and study how
emotionally expressive motion patterns of a small, mobile follower robot affect
the perception of a human operator controlling the leading robot. We examined
three distinct emotional behaviors for the follower compared to a neutral
condition: angry, happy and sad. We analyzed how participants maneuvered the
leader robot along a set path while experiencing each follower behavior in a
randomized order. We identified a significant shift in attention toward the
follower with emotionally expressive behaviors compared to the neutral
condition. For example, the angry behavior significantly heightened participant
stress levels and was considered the least preferred behavior. The happy
behavior was the most preferred and associated with increased excitement by the
participants. Integrating the proposed behaviors in robots can profoundly
influence the human operator's attention, emotional state, and overall
experience. These insights are valuable for future HRI tandem robot designs.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03750" title="Abstract">arXiv:2403.03750</a> [<a href="/pdf/2403.03750" title="Download PDF">pdf</a>, <a href="/format/2403.03750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> German also Hallucinates! Inconsistency Detection in News Summaries with  the Absinth Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mascarell%2C+L">Laura Mascarell</a>, 
<a href="/search/cs?searchtype=author&query=Chalumattu%2C+R">Ribin Chalumattu</a>, 
<a href="/search/cs?searchtype=author&query=Rios%2C+A">Annette Rios</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, 7 tables, conference: Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), Turin, Italy, May 20-25, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of Large Language Models (LLMs) has led to remarkable progress on
a wide range of natural language processing tasks. Despite the advances, these
large-sized models still suffer from hallucinating information in their output,
which poses a major issue in automatic text summarization, as we must guarantee
that the generated summary is consistent with the content of the source
document. Previous research addresses the challenging task of detecting
hallucinations in the output (i.e. inconsistency detection) in order to
evaluate the faithfulness of the generated summaries. However, these works
primarily focus on English and recent multilingual approaches lack German data.
This work presents absinth, a manually annotated dataset for hallucination
detection in German news summarization and explores the capabilities of novel
open-source LLMs on this task in both fine-tuning and in-context learning
settings. We open-source and release the absinth dataset to foster further
research on hallucination detection in German.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03751" title="Abstract">arXiv:2403.03751</a> [<a href="/pdf/2403.03751" title="Download PDF">pdf</a>, <a href="/format/2403.03751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trigram-Based Persistent IDE Indices with Quick Startup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iakovlev%2C+Z">Zakhar Iakovlev</a>, 
<a href="/search/cs?searchtype=author&query=Chulkov%2C+A">Alexey Chulkov</a>, 
<a href="/search/cs?searchtype=author&query=Golikov%2C+N">Nikita Golikov</a>, 
<a href="/search/cs?searchtype=author&query=Lukianov%2C+V">Vyacheslav Lukianov</a>, 
<a href="/search/cs?searchtype=author&query=Zinoviev%2C+N">Nikita Zinoviev</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+D">Dmitry Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Aksenov%2C+V">Vitaly Aksenov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">One common way to speed up the find operation within a set of text files
involves a trigram index. This structure is merely a map from a trigram
(sequence consisting of three characters) to a set of files which contain it.
When searching for a pattern, potential file locations are identified by
intersecting the sets related to the trigrams in the pattern. Then, the search
proceeds only in these files.
<br />However, in a code repository, the trigram index evolves across different
versions. Upon checking out a new version, this index is typically built from
scratch, which is a time-consuming task, while we want our index to have almost
zero-time startup.
<br />Thus, we explore the persistent version of a trigram index for full-text and
key word patterns search. Our approach just uses the current version of the
trigram index and applies only the changes between versions during checkout,
significantly enhancing performance. Furthermore, we extend our data structure
to accommodate CamelHump search for class and function names.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03768" title="Abstract">arXiv:2403.03768</a> [<a href="/pdf/2403.03768" title="Download PDF">pdf</a>, <a href="/format/2403.03768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCRE: Revolutionizing Drug R&amp;D with Cutting-Edge Computational Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yushuai Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The field of pharmaceutical development and therapeutic application both face
substantial challenges. Therapeutic domain calls for more treatment
alternatives while numerous promising pre-clinical drugs fail in clinical
trails. One of the reasons is the inadequacy of Cross-drug Response Evaluation
(CRE) during the late stage of drug development. Although in-silico CRE models
offer a solution to this problem, existing methodologies are either limited to
early development stages or lack the capacity for a comprehensive CRE analysis.
Herein, we introduce a novel computational model named DeepCRE and present the
potential of DeepCRE in advancing therapeutic discovery and development.
DeepCRE outperforms the existing best models by achieving an average
performance improvement of 17.7\% in patient-level CRE, and a 5-fold increase
in indication-level CRE. Furthermore, DeepCRE has identified six drug
candidates that show significantly greater effectiveness than a comparator set
of two approved drug in 5/8 colorectal cancer (CRC) organoids. This highlights
DeepCRE's ability to identify a collection of drug candidates with superior
therapeutic effects, underscoring its potential to revolutionize the field of
therapeutic development.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03772" title="Abstract">arXiv:2403.03772</a> [<a href="/pdf/2403.03772" title="Download PDF">pdf</a>, <a href="/format/2403.03772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AcceleratedLiNGAM: Learning Causal DAGs at the speed of GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akinwande%2C+V">Victor Akinwande</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MLGenX @ ICLR 2024. Open source at <a href="https://github.com/Viktour19/culingam">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Existing causal discovery methods based on combinatorial optimization or
search are slow, prohibiting their application on large-scale datasets. In
response, more recent methods attempt to address this limitation by formulating
causal discovery as structure learning with continuous optimization but such
approaches thus far provide no statistical guarantees. In this paper, we show
that by efficiently parallelizing existing causal discovery methods, we can in
fact scale them to thousands of dimensions, making them practical for
substantially larger-scale problems. In particular, we parallelize the LiNGAM
method, which is quadratic in the number of variables, obtaining up to a
32-fold speed-up on benchmark datasets when compared with existing sequential
implementations. Specifically, we focus on the causal ordering subprocedure in
DirectLiNGAM and implement GPU kernels to accelerate it. This allows us to
apply DirectLiNGAM to causal inference on large-scale gene expression data with
genetic interventions yielding competitive results compared with specialized
continuous optimization methods, and Var-LiNGAM for causal discovery on U.S.
stock data.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03773" title="Abstract">arXiv:2403.03773</a> [<a href="/pdf/2403.03773" title="Download PDF">pdf</a>, <a href="/format/2403.03773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verified Training for Counterfactual Explanation Robustness under Data  Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+A+P">Anna P. Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Albarghouthi%2C+A">Aws Albarghouthi</a>, 
<a href="/search/cs?searchtype=author&query=D%27Antoni%2C+L">Loris D&#x27;Antoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures. Accepted at DMLR workshop at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Counterfactual explanations (CEs) enhance the interpretability of machine
learning models by describing what changes to an input are necessary to change
its prediction to a desired class. These explanations are commonly used to
guide users' actions, e.g., by describing how a user whose loan application was
denied can be approved for a loan in the future. Existing approaches generate
CEs by focusing on a single, fixed model, and do not provide any formal
guarantees on the CEs' future validity. When models are updated periodically to
account for data shift, if the generated CEs are not robust to the shifts,
users' actions may no longer have the desired impacts on their predictions.
This paper introduces VeriTraCER, an approach that jointly trains a classifier
and an explainer to explicitly consider the robustness of the generated CEs to
small model shifts. VeriTraCER optimizes over a carefully designed loss
function that ensures the verifiable robustness of CEs to local model updates,
thus providing deterministic guarantees to CE validity. Our empirical
evaluation demonstrates that VeriTraCER generates CEs that (1) are verifiably
robust to small model updates and (2) display competitive robustness to
state-of-the-art approaches in handling empirical model updates including
random initialization, leave-one-out, and distribution shifts.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03777" title="Abstract">arXiv:2403.03777</a> [<a href="/pdf/2403.03777" title="Download PDF">pdf</a>, <a href="/format/2403.03777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ENOT: Expectile Regularization for Fast and Accurate Training of Neural  Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buzun%2C+N">Nazar Buzun</a>, 
<a href="/search/cs?searchtype=author&query=Bobrin%2C+M">Maksim Bobrin</a>, 
<a href="/search/cs?searchtype=author&query=Dylov%2C+D+V">Dmitry V. Dylov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a new extension for Neural Optimal Transport (NOT) training
procedure, capable of accurately and efficiently estimating optimal
transportation plan via specific regularisation on conjugate potentials. The
main bottleneck of existing NOT solvers is associated with the procedure of
finding a near-exact approximation of the conjugate operator (i.e., the
c-transform), which is done either by optimizing over maximin objectives or by
the computationally-intensive fine-tuning of the initial approximated
prediction. We resolve both issues by proposing a new, theoretically justified
loss in the form of expectile regularization that enforces binding conditions
on the learning dual potentials. Such a regularization provides the upper bound
estimation over the distribution of possible conjugate potentials and makes the
learning stable, eliminating the need for additional extensive finetuning. We
formally justify the efficiency of our method, called Expectile-Regularised
Neural Optimal Transport (ENOT). ENOT outperforms previous state-of-the-art
approaches on the Wasserstein-2 benchmark tasks by a large margin (up to a
3-fold improvement in quality and up to a 10-fold improvement in runtime).
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03781" title="Abstract">arXiv:2403.03781</a> [<a href="/pdf/2403.03781" title="Download PDF">pdf</a>, <a href="/format/2403.03781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Architecture Search using Particle Swarm and Ant Colony  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lankford%2C+S">S&#xe9;amus Lankford</a>, 
<a href="/search/cs?searchtype=author&query=Grimes%2C+D">Diarmuid Grimes</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 28th Irish Conference on Artificial
  Intelligence and Cognitive Science. 2771. CEUR-WS, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural network models have a number of hyperparameters that must be chosen
along with their architecture. This can be a heavy burden on a novice user,
choosing which architecture and what values to assign to parameters. In most
cases, default hyperparameters and architectures are used. Significant
improvements to model accuracy can be achieved through the evaluation of
multiple architectures. A process known as Neural Architecture Search (NAS) may
be applied to automatically evaluate a large number of such architectures. A
system integrating open source tools for Neural Architecture Search (OpenNAS),
in the classification of images, has been developed as part of this research.
OpenNAS takes any dataset of grayscale, or RBG images, and generates
Convolutional Neural Network (CNN) architectures based on a range of
metaheuristics using either an AutoKeras, a transfer learning or a Swarm
Intelligence (SI) approach. Particle Swarm Optimization (PSO) and Ant Colony
Optimization (ACO) are used as the SI algorithms. Furthermore, models developed
through such metaheuristics may be combined using stacking ensembles. In the
context of this paper, we focus on training and optimizing CNNs using the Swarm
Intelligence (SI) components of OpenNAS. Two major types of SI algorithms,
namely PSO and ACO, are compared to see which is more effective in generating
higher model accuracies. It is shown, with our experimental design, that the
PSO algorithm performs better than ACO. The performance improvement of PSO is
most notable with a more complex dataset. As a baseline, the performance of
fine-tuned pre-trained models is also evaluated.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03782" title="Abstract">arXiv:2403.03782</a> [<a href="/pdf/2403.03782" title="Download PDF">pdf</a>, <a href="/format/2403.03782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Injectivity Radius of the Stiefel Manifold: Numerical  investigations and an explicit construction of a cut point at short distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stoye%2C+J">Jakob Stoye</a>, 
<a href="/search/math?searchtype=author&query=Zimmermann%2C+R">Ralf Zimmermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Arguably, geodesics are the most important geometric objects on a
differentiable manifold. They describe candidates for shortest paths and are
guaranteed to be unique shortest paths when the starting velocity stays within
the so-called injectivity radius of the manifold. In this work, we investigate
the injectivity radius of the Stiefel manifold under the canonical metric. The
Stiefel manifold $St(n,p)$ is the set of rectangular matrices of dimension
$n$-by-$p$ with orthogonal columns, sometimes also called the space of
orthogonal $p$-frames in $\mathbb{R}^n$. Using a standard curvature argument,
Rentmeesters has shown in 2013 that the injectivity radius of the Stiefel
manifold is bounded by $\sqrt{\frac{4}{5}}\pi$. It is an open question, whether
this bound is sharp. With the definition of the injectivity radius via cut
points of geodesics, we gain access to the information of the injectivity
radius by investigating geodesics. More precisely, we consider the behavior of
special variations of geodesics, called Jacobi fields. By doing so, we are able
to present an explicit example of a cut point. In addition, since the
theoretical analysis of geodesics for cut points and especially conjugate
points as a type of cut points is difficult, we investigate the question of the
sharpness of the bound by means of numerical experiments.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03785" title="Abstract">arXiv:2403.03785</a> [<a href="/pdf/2403.03785" title="Download PDF">pdf</a>, <a href="/ps/2403.03785" title="Download PostScript">ps</a>, <a href="/format/2403.03785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A machine learning workflow to address credit default prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+R">Rambod Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Parola%2C+M">Marco Parola</a>, 
<a href="/search/cs?searchtype=author&query=Cimino%2C+M+G+C+A">Mario G.C.A. Cimino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Risk Management (q-fin.RM)

</div>
<p class="mathjax">Due to the recent increase in interest in Financial Technology (FinTech),
applications like credit default prediction (CDP) are gaining significant
industrial and academic attention. In this regard, CDP plays a crucial role in
assessing the creditworthiness of individuals and businesses, enabling lenders
to make informed decisions regarding loan approvals and risk management. In
this paper, we propose a workflow-based approach to improve CDP, which refers
to the task of assessing the probability that a borrower will default on his or
her credit obligations. The workflow consists of multiple steps, each designed
to leverage the strengths of different techniques featured in machine learning
pipelines and, thus best solve the CDP task. We employ a comprehensive and
systematic approach starting with data preprocessing using Weight of Evidence
encoding, a technique that ensures in a single-shot data scaling by removing
outliers, handling missing values, and making data uniform for models working
with different data types. Next, we train several families of learning models,
introducing ensemble techniques to build more robust models and hyperparameter
optimization via multi-objective genetic algorithms to consider both predictive
accuracy and financial aspects. Our research aims at contributing to the
FinTech industry in providing a tool to move toward more accurate and reliable
credit risk assessment, benefiting both lenders and borrowers.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03788" title="Abstract">arXiv:2403.03788</a> [<a href="/pdf/2403.03788" title="Download PDF">pdf</a>, <a href="/format/2403.03788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPTC-R benchmark: Towards Evaluating the Robustness of Large Language  Models for PowerPoint Task Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zekai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiduo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LLM evaluation, Multi-turn, Multi-language, Multi-modal benchmark
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The growing dependence on Large Language Models (LLMs) for finishing user
instructions necessitates a comprehensive understanding of their robustness to
complex task completion in real-world situations. To address this critical
need, we propose the PowerPoint Task Completion Robustness benchmark (PPTC-R)
to measure LLMs' robustness to the user PPT task instruction and software
version. Specifically, we construct adversarial user instructions by attacking
user instructions at sentence, semantic, and multi-language levels. To assess
the robustness of Language Models to software versions, we vary the number of
provided APIs to simulate both the newest version and earlier version settings.
Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark
that incorporates these robustness settings, aiming to evaluate how deviations
impact LLMs' API calls for task completion. We find that GPT-4 exhibits the
highest performance and strong robustness in our benchmark, particularly in the
version update and the multilingual settings. However, we find that all LLMs
lose their robustness when confronted with multiple challenges (e.g.,
multi-turn) simultaneously, leading to significant performance drops. We
further analyze the robustness behavior and error reasons of LLMs in our
benchmark, which provide valuable insights for researchers to understand the
LLM's robustness in task completion and develop more robust LLMs and agents. We
release the code and data at \url{https://github.com/ZekaiGalaxy/PPTCR}.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03790" title="Abstract">arXiv:2403.03790</a> [<a href="/pdf/2403.03790" title="Download PDF">pdf</a>, <a href="/format/2403.03790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection  from Remote Sensing Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Miaoxin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+G">Guoqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xuerui Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ship detection needs to identify ship locations from remote sensing (RS)
scenes. However, due to different imaging payloads, various appearances of
ships, and complicated background interference from the bird's eye view, it is
difficult to set up a unified paradigm for achieving multi-source ship
detection. Therefore, in this article, considering that the large language
models (LLMs) emerge the powerful generalization ability, a novel unified
visual-language model called Popeye is proposed for multi-source ship detection
from RS imagery. First, to bridge the interpretation gap between multi-source
images for ship detection, a novel image-instruction-answer way is designed to
integrate the various ship detection ways (e.g., horizontal bounding box (HBB),
oriented bounding box (OBB)) into a unified labeling paradigm. Then, in view of
this, a cross-modal image interpretation method is developed for the proposed
Popeye to enhance interactive comprehension ability between visual and language
content, which can be easily migrated into any multi-source ship detection
task. Subsequently, owing to objective domain differences, a knowledge adaption
mechanism is designed to adapt the pre-trained visual-language knowledge from
the nature scene into the RS domain for multi-source ship detection. In
addition, the segment anything model (SAM) is also seamlessly integrated into
the proposed Popeye to achieve pixel-level ship segmentation without additional
training costs. Finally, extensive experiments are conducted on the newly
constructed instruction dataset named MMShip, and the results indicate that the
proposed Popeye outperforms current specialist, open-vocabulary, and other
visual-language models for zero-shot multi-source ship detection.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03791" title="Abstract">arXiv:2403.03791</a> [<a href="/pdf/2403.03791" title="Download PDF">pdf</a>, <a href="/format/2403.03791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing  Patient Data with Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruoqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Treatment effect estimation (TEE) is the task of determining the impact of
various treatments on patient outcomes. Current TEE methods fall short due to
reliance on limited labeled data and challenges posed by sparse and
high-dimensional observational patient data. To address the challenges, we
introduce a novel pre-training and fine-tuning framework, KG-TREAT, which
synergizes large-scale observational patient data with biomedical knowledge
graphs (KGs) to enhance TEE. Unlike previous approaches, KG-TREAT constructs
dual-focus KGs and integrates a deep bi-level attention synergy method for
in-depth information fusion, enabling distinct encoding of treatment-covariate
and outcome-covariate relationships. KG-TREAT also incorporates two
pre-training tasks to ensure a thorough grounding and contextualization of
patient data and KGs. Evaluation on four downstream TEE tasks shows KG-TREAT's
superiority over existing methods, with an average improvement of 7% in Area
under the ROC Curve (AUC) and 9% in Influence Function-based Precision of
Estimating Heterogeneous Effects (IF-PEHE). The effectiveness of our estimated
treatment effects is further affirmed by alignment with established randomized
clinical trial findings.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03792" title="Abstract">arXiv:2403.03792</a> [<a href="/pdf/2403.03792" title="Download PDF">pdf</a>, <a href="/format/2403.03792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Exec: Learning (and Learning from) Execution Triggers for Prompt  Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasquini%2C+D">Dario Pasquini</a>, 
<a href="/search/cs?searchtype=author&query=Strohmeier%2C+M">Martin Strohmeier</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+C">Carmela Troncoso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v0.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a new family of prompt injection attacks, termed Neural Exec.
Unlike known attacks that rely on handcrafted strings (e.g., "Ignore previous
instructions and..."), we show that it is possible to conceptualize the
creation of execution triggers as a differentiable search problem and use
learning-based methods to autonomously generate them.
<br />Our results demonstrate that a motivated adversary can forge triggers that
are not only drastically more effective than current handcrafted ones but also
exhibit inherent flexibility in shape, properties, and functionality. In this
direction, we show that an attacker can design and generate Neural Execs
capable of persisting through multi-stage preprocessing pipelines, such as in
the case of Retrieval-Augmented Generation (RAG)-based applications. More
critically, our findings show that attackers can produce triggers that deviate
markedly in form and shape from any known attack, sidestepping existing
blacklist-based detection and sanitation approaches.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03801" title="Abstract">arXiv:2403.03801</a> [<a href="/pdf/2403.03801" title="Download PDF">pdf</a>, <a href="/format/2403.03801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realizability of Rectangular Euler Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%BCrrschnabel%2C+D">Dominik D&#xfc;rrschnabel</a>, 
<a href="/search/cs?searchtype=author&query=Priss%2C+U">Uta Priss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, 2 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Euler diagrams are a tool for the graphical representation of set relations.
Due to their simple way of visualizing elements in the sets by geometric
containment, they are easily readable by an inexperienced reader. Euler
diagrams where the sets are visualized as aligned rectangles are of special
interest. In this work, we link the existence of such rectangular Euler
diagrams to the order dimension of an associated order relation. For this, we
consider Euler diagrams in one and two dimensions. In the one-dimensional case,
this correspondence provides us with a polynomial-time algorithm to compute the
Euler diagrams, while the two-dimensional case results in an exponential-time
algorithm.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03806" title="Abstract">arXiv:2403.03806</a> [<a href="/pdf/2403.03806" title="Download PDF">pdf</a>, <a href="/format/2403.03806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Precision Drone Landing System using Visual and IR Fiducial Markers  and a Multi-Payload Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Springer%2C+J">Joshua Springer</a>, 
<a href="/search/cs?searchtype=author&query=Gu%C3%B0mundsson%2C+G+%C3%9E">Gylfi &#xde;&#xf3;r Gu&#xf0;mundsson</a>, 
<a href="/search/cs?searchtype=author&query=Kyas%2C+M">Marcel Kyas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We propose a method for autonomous precision drone landing with fiducial
markers and a gimbal-mounted, multi-payload camera with wide-angle, zoom, and
IR sensors. The method has minimal data requirements; it depends primarily on
the direction from the drone to the landing pad, enabling it to switch
dynamically between the camera's different sensors and zoom factors, and
minimizing auxiliary sensor requirements. It eliminates the need for data such
as altitude above ground level, straight-line distance to the landing pad,
fiducial marker size, and 6 DoF marker pose (of which the orientation is
problematic). We leverage the zoom and wide-angle cameras, as well as visual
April Tag fiducial markers to conduct successful precision landings from much
longer distances than in previous work (168m horizontal distance, 102m
altitude). We use two types of April Tags in the IR spectrum - active and
passive - for precision landing both at daytime and nighttime, instead of
simple IR beacons used in most previous work. The active IR landing pad is
heated; the novel, passive one is unpowered, at ambient temperature, and
depends on its high reflectivity and an IR differential between the ground and
the sky. Finally, we propose a high-level control policy to manage initial
search for the landing pad and subsequent searches if it is lost - not
addressed in previous work. The method demonstrates successful landings with
the landing skids at least touching the landing pad, achieving an average error
of 0.19m. It also demonstrates successful recovery and landing when the landing
pad is temporarily obscured.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03808" title="Abstract">arXiv:2403.03808</a> [<a href="/pdf/2403.03808" title="Download PDF">pdf</a>, <a href="/format/2403.03808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence-Aware Decision-Making and Control for Tool Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meera%2C+A+A">Ajith Anil Meera</a>, 
<a href="/search/cs?searchtype=author&query=Lanillos%2C+P">Pablo Lanillos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Self-reflecting about our performance (e.g., how confident we are) before
doing a task is essential for decision making, such as selecting the most
suitable tool or choosing the best route to drive. While this form of awareness
-- thinking about our performance or metacognitive performance -- is well-known
in humans, robots still lack this cognitive ability. This reflective monitoring
can enhance their embodied decision power, robustness and safety. Here, we take
a step in this direction by introducing a mathematical framework that allows
robots to use their control self-confidence to make better-informed decisions.
We derive a mathematical closed-form expression for control confidence for
dynamic systems (i.e., the posterior inverse covariance of the control action).
This control confidence seamlessly integrates within an objective function for
decision making, that balances the: i) performance for task completion, ii)
control effort, and iii) self-confidence. To evaluate our theoretical account,
we framed the decision-making within the tool selection problem, where the
agent has to select the best robot arm for a particular control task. The
statistical analysis of the numerical simulations with randomized 2DOF arms
shows that using control confidence during tool selection improves both real
task performance, and the reliability of the tool for performance under
unmodelled perturbations (e.g., external forces). Furthermore, our results
indicate that control confidence is an early indicator of performance and thus,
it can be used as a heuristic for making decisions when computation power is
restricted or decision-making is intractable. Overall, we show the advantages
of using confidence-aware decision-making and control scheme for dynamic
systems.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03810" title="Abstract">arXiv:2403.03810</a> [<a href="/pdf/2403.03810" title="Download PDF">pdf</a>, <a href="/format/2403.03810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative estimates: How well does the discrete Fourier transform  approximate the Fourier transform on $\mathbb{R}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ehler%2C+M">Martin Ehler</a>, 
<a href="/search/math?searchtype=author&query=Gr%C3%B6chenig%2C+K">Karlheinz Gr&#xf6;chenig</a>, 
<a href="/search/math?searchtype=author&query=Klotz%2C+A">Andreas Klotz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In order to compute the Fourier transform of a function $f$ on the real line
numerically, one samples $f$ on a grid and then takes the discrete Fourier
transform. We derive exact error estimates for this procedure in terms of the
decay and smoothness of $f$. The analysis provides a new recipe of how to
relate the number of samples, the sampling interval, and the grid size.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03812" title="Abstract">arXiv:2403.03812</a> [<a href="/pdf/2403.03812" title="Download PDF">pdf</a>, <a href="/format/2403.03812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madhusudhanan%2C+K">Kiran Madhusudhanan</a>, 
<a href="/search/cs?searchtype=author&query=Behrens%2C+G">Gunnar Behrens</a>, 
<a href="/search/cs?searchtype=author&query=Stubbemann%2C+M">Maximilian Stubbemann</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Used car pricing is a critical aspect of the automotive industry, influenced
by many economic factors and market dynamics. With the recent surge in online
marketplaces and increased demand for used cars, accurate pricing would benefit
both buyers and sellers by ensuring fair transactions. However, the transition
towards automated pricing algorithms using machine learning necessitates the
comprehension of model uncertainties, specifically the ability to flag
predictions that the model is unsure about. Although recent literature proposes
the use of boosting algorithms or nearest neighbor-based approaches for swift
and precise price predictions, encapsulating model uncertainties with such
algorithms presents a complex challenge. We introduce ProbSAINT, a model that
offers a principled approach for uncertainty quantification of its price
predictions, along with accurate point predictions that are comparable to
state-of-the-art boosting techniques. Furthermore, acknowledging that the
business prefers pricing used cars based on the number of days the vehicle was
listed for sale, we show how ProbSAINT can be used as a dynamic forecasting
model for predicting price probabilities for different expected offer duration.
Our experiments further indicate that ProbSAINT is especially accurate on
instances where it is highly certain. This proves the applicability of its
probabilistic predictions in real-world scenarios where trustworthiness is
crucial.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03814" title="Abstract">arXiv:2403.03814</a> [<a href="/pdf/2403.03814" title="Download PDF">pdf</a>, <a href="/format/2403.03814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Elementary Multilingual Capabilities of Large Language  Models with MultiQ
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holtermann%2C+C">Carolin Holtermann</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6ttger%2C+P">Paul R&#xf6;ttger</a>, 
<a href="/search/cs?searchtype=author&query=Dill%2C+T">Timm Dill</a>, 
<a href="/search/cs?searchtype=author&query=Lauscher%2C+A">Anne Lauscher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) need to serve everyone, including a global
majority of non-English speakers. However, most LLMs today, and open LLMs in
particular, are often intended for use in just English (e.g. Llama2, Mistral)
or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent
research shows that, despite limits in their intended use, people prompt LLMs
in many different languages. Therefore, in this paper, we investigate the basic
multilingual capabilities of state-of-the-art open LLMs beyond their intended
use. For this purpose, we introduce MultiQ, a new silver standard benchmark for
basic open-ended question answering with 27.4k test questions across a
typologically diverse set of 137 languages. With MultiQ, we evaluate language
fidelity, i.e.\ whether models respond in the prompted language, and question
answering accuracy. All LLMs we test respond faithfully and/or accurately for
at least some languages beyond their intended use. Most models are more
accurate when they respond faithfully. However, differences across models are
large, and there is a long tail of languages where models are neither accurate
nor faithful. We explore differences in tokenization as a potential explanation
for our findings, identifying possible correlations that warrant further
investigation.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03819" title="Abstract">arXiv:2403.03819</a> [<a href="/pdf/2403.03819" title="Download PDF">pdf</a>, <a href="/format/2403.03819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Documentation Matter? An Empirical Study of Practitioners&#x27;  Perspective on Open-Source Software Adoption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imani%2C+A">Aaron Imani</a>, 
<a href="/search/cs?searchtype=author&query=Radmanesh%2C+S">Shiva Radmanesh</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Iftekhar Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Moshirpour%2C+M">Mohammad Moshirpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In recent years, open-source software (OSS) has become increasingly prevalent
in developing software products. While OSS documentation is the primary source
of information provided by the developers' community about a product, its role
in the industry's adoption process has yet to be examined. We conducted
semi-structured interviews and an online survey to provide insight into this
area. Based on interviews and survey insights, we developed a topic model to
collect relevant information from OSS documentation automatically.
Additionally, according to our survey responses regarding challenges associated
with OSS documentation, we propose a novel information augmentation approach,
DocMentor, by combining OSS documentation corpus TF-IDF scores and ChatGPT.
Through explaining technical terms and providing examples and references, our
approach enhances the documentation context and improves practitioners'
understanding. Our tool's effectiveness is assessed by surveying practitioners.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03822" title="Abstract">arXiv:2403.03822</a> [<a href="/pdf/2403.03822" title="Download PDF">pdf</a>, <a href="/format/2403.03822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoLens: A Visual Analytics Design for Higher-order Movement Modeling and  Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zezheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianing Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">ShuangHua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Huamin Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 18 figures, is accepted by computational visual media journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Higher-order patterns reveal sequential multistep state transitions, which
are usually superior to origin-destination analysis, which depicts only
first-order geospatial movement patterns. Conventional methods for higher-order
movement modeling first construct a directed acyclic graph (DAG) of movements,
then extract higher-order patterns from the DAG. However, DAG-based methods
heavily rely on the identification of movement keypoints that are challenging
for sparse movements and fail to consider the temporal variants that are
critical for movements in urban environments. To overcome the limitations, we
propose HoLens, a novel approach for modeling and visualizing higher-order
movement patterns in the context of an urban environment. HoLens mainly makes
twofold contributions: first, we design an auto-adaptive movement aggregation
algorithm that self-organizes movements hierarchically by considering spatial
proximity, contextual information, and temporal variability; second, we develop
an interactive visual analytics interface consisting of well-established
visualization techniques, including the H-Flow for visualizing the higher-order
patterns on the map and the higher-order state sequence chart for representing
the higher-order state transitions. Two real-world case studies manifest that
the method can adaptively aggregate the data and exhibit the process of how to
explore the higher-order patterns by HoLens. We also demonstrate our approach's
feasibility, usability, and effectiveness through an expert interview with
three domain experts.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03823" title="Abstract">arXiv:2403.03823</a> [<a href="/pdf/2403.03823" title="Download PDF">pdf</a>, <a href="/format/2403.03823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular Approach for Multimodal Summarization of TV Shows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahon%2C+L">Louis Mahon</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper we address the task of summarizing television shows, which
touches key areas in AI research: complex reasoning, multiple modalities, and
long narratives. We present a modular approach where separate components
perform specialized sub-tasks which we argue affords greater flexibility
compared to end-to-end methods. Our modules involve detecting scene boundaries,
reordering scenes so as to minimize the number of cuts between different
events, converting visual information to text, summarizing the dialogue in each
scene, and fusing the scene summaries into a final summary for the entire
episode. We also present a new metric, PREFS (\textbf{P}recision and
\textbf{R}ecall \textbf{E}valuation of Summary \textbf{F}act\textbf{s}), to
measure both precision and recall of generated summaries, which we decompose
into atomic facts. Tested on the recently released SummScreen3D dataset
Papalampidi and Lapata (2023), our method produces higher quality summaries
than comparison models, as measured with ROUGE and our new fact-based metric.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03825" title="Abstract">arXiv:2403.03825</a> [<a href="/pdf/2403.03825" title="Download PDF">pdf</a>, <a href="/format/2403.03825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Enhanced Floating Car Observers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerner%2C+J">Jeremias Gerner</a>, 
<a href="/search/cs?searchtype=author&query=Bogenberger%2C+K">Klaus Bogenberger</a>, 
<a href="/search/cs?searchtype=author&query=Schmidtner%2C+S">Stefanie Schmidtner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Floating Car Observers (FCOs) are an innovative method to collect traffic
data by deploying sensor-equipped vehicles to detect and locate other vehicles.
We demonstrate that even a small penetration rate of FCOs can identify a
significant amount of vehicles at a given intersection. This is achieved
through the emulation of detection within a microscopic traffic simulation.
Additionally, leveraging data from previous moments can enhance the detection
of vehicles in the current frame. Our findings indicate that, with a 20-second
observation window, it is possible to recover up to 20\% of vehicles that are
not visible by FCOs in the current timestep. To exploit this, we developed a
data-driven strategy, utilizing sequences of Bird's Eye View (BEV)
representations of detected vehicles and deep learning models. This approach
aims to bring currently undetected vehicles into view in the present moment,
enhancing the currently detected vehicles. Results of different spatiotemporal
architectures show that up to 41\% of the vehicles can be recovered into the
current timestep at their current position. This enhancement enriches the
information initially available by the FCO, allowing an improved estimation of
traffic states and metrics (e.g. density and queue length) for improved
implementation of traffic management strategies.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03827" title="Abstract">arXiv:2403.03827</a> [<a href="/pdf/2403.03827" title="Download PDF">pdf</a>, <a href="/format/2403.03827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear and nonlinear system identification under $\ell_1$- and  group-Lasso regularization via L-BFGS-B
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bemporad%2C+A">Alberto Bemporad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we propose an approach for identifying linear and nonlinear
discrete-time state-space models, possibly under $\ell_1$- and group-Lasso
regularization, based on the L-BFGS-B algorithm. For the identification of
linear models, we show that, compared to classical linear subspace methods, the
approach often provides better results, is much more general in terms of the
loss and regularization terms used, and is also more stable from a numerical
point of view. The proposed method not only enriches the existing set of linear
system identification tools but can be also applied to identifying a very broad
class of parametric nonlinear state-space models, including recurrent neural
networks. We illustrate the approach on synthetic and experimental datasets and
apply it to solve the challenging industrial robot benchmark for nonlinear
multi-input/multi-output system identification proposed by Weigand et al.
(2022). A Python implementation of the proposed identification method is
available in the package \texttt{jax-sysid}, available at
\url{https://github.com/bemporad/jax-sysid}.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03828" title="Abstract">arXiv:2403.03828</a> [<a href="/pdf/2403.03828" title="Download PDF">pdf</a>, <a href="/ps/2403.03828" title="Download PostScript">ps</a>, <a href="/format/2403.03828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Clicks to Security: Investigating Continuous Authentication via  Mouse Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+R">Rushit Dave</a>, 
<a href="/search/cs?searchtype=author&query=Handoko%2C+M">Marcho Handoko</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+A">Ali Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Schoenbauer%2C+C">Cole Schoenbauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the realm of computer security, the importance of efficient and reliable
user authentication methods has become increasingly critical. This paper
examines the potential of mouse movement dynamics as a consistent metric for
continuous authentication. By analyzing user mouse movement patterns in two
contrasting gaming scenarios, "Team Fortress" and Poly Bridge we investigate
the distinctive behavioral patterns inherent in high-intensity and
low-intensity UI interactions. The study extends beyond conventional
methodologies by employing a range of machine learning models. These models are
carefully selected to assess their effectiveness in capturing and interpreting
the subtleties of user behavior as reflected in their mouse movements. This
multifaceted approach allows for a more nuanced and comprehensive understanding
of user interaction patterns. Our findings reveal that mouse movement dynamics
can serve as a reliable indicator for continuous user authentication. The
diverse machine learning models employed in this study demonstrate competent
performance in user verification, marking an improvement over previous methods
used in this field. This research contributes to the ongoing efforts to enhance
computer security and highlights the potential of leveraging user behavior,
specifically mouse dynamics, in developing robust authentication systems.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03830" title="Abstract">arXiv:2403.03830</a> [<a href="/pdf/2403.03830" title="Download PDF">pdf</a>, <a href="/format/2403.03830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Algorithms for Balanced Cluster Edge Modification Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madathil%2C+J">Jayakrishnan Madathil</a>, 
<a href="/search/cs?searchtype=author&query=Meeks%2C+K">Kitty Meeks</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We introduce Cluster Edge Modification problems with constraints on the size
of the clusters and study their complexity. A graph $G$ is a cluster graph if
every connected component of $G$ is a clique. In a typical Cluster Edge
Modification problem such as the widely studied Cluster Editing, we are given a
graph $G$ and a non-negative integer $k$ as input, and we have to decide if we
can turn $G$ into a cluster graph by way of at most $k$ edge modifications --
that is, by adding or deleting edges. In this paper, we study the parameterized
complexity of such problems, but with an additional constraint: The size
difference between any two connected components of the resulting cluster graph
should not exceed a given threshold. Depending on which modifications are
permissible -- only adding edges, only deleting edges, both adding and deleting
edges -- we have three different computational problems. We show that all three
problems, when parameterized by $k$, admit single-exponential time FPT
algorithms and polynomial kernels. Our problems may be thought of as the
size-constrained or balanced counterparts of the typical Cluster Edge
Modification problems, similar to the well-studied size-constrained or balanced
counterparts of other clustering problems such as $k$-Means Clustering.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03832" title="Abstract">arXiv:2403.03832</a> [<a href="/pdf/2403.03832" title="Download PDF">pdf</a>, <a href="/ps/2403.03832" title="Download PostScript">ps</a>, <a href="/format/2403.03832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your device may know you better than you know yourself -- continuous  authentication on novel dataset using machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+P+G+d">Pedro Gomes do Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Witiak%2C+P">Pidge Witiak</a>, 
<a href="/search/cs?searchtype=author&query=MacCallum%2C+T">Tucker MacCallum</a>, 
<a href="/search/cs?searchtype=author&query=Winterfeldt%2C+Z">Zachary Winterfeldt</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+R">Rushit Dave</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This research aims to further understanding in the field of continuous
authentication using behavioral biometrics. We are contributing a novel dataset
that encompasses the gesture data of 15 users playing Minecraft with a Samsung
Tablet, each for a duration of 15 minutes. Utilizing this dataset, we employed
machine learning (ML) binary classifiers, being Random Forest (RF), K-Nearest
Neighbors (KNN), and Support Vector Classifier (SVC), to determine the
authenticity of specific user actions. Our most robust model was SVC, which
achieved an average accuracy of approximately 90%, demonstrating that touch
dynamics can effectively distinguish users. However, further studies are needed
to make it viable option for authentication systems
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03835" title="Abstract">arXiv:2403.03835</a> [<a href="/pdf/2403.03835" title="Download PDF">pdf</a>, <a href="/format/2403.03835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cobweb: An Incremental and Hierarchical Model of Human-Like Category  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xin Lian</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+S">Sashank Varma</a>, 
<a href="/search/cs?searchtype=author&query=MacLellan%2C+C+J">Christopher J. MacLellan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Cobweb, a human like category learning system, differs from other incremental
categorization models in constructing hierarchically organized cognitive
tree-like structures using the category utility measure. Prior studies have
shown that Cobweb can capture psychological effects such as the basic level,
typicality, and fan effects. However, a broader evaluation of Cobweb as a model
of human categorization remains lacking. The current study addresses this gap.
It establishes Cobweb's alignment with classical human category learning
effects. It also explores Cobweb's flexibility to exhibit both exemplar and
prototype like learning within a single model. These findings set the stage for
future research on Cobweb as a comprehensive model of human category learning.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03838" title="Abstract">arXiv:2403.03838</a> [<a href="/pdf/2403.03838" title="Download PDF">pdf</a>, <a href="/format/2403.03838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Selection as Deep Sequential Generative Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+W">Wangyang Ying</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Feature selection aims to identify the most pattern-discriminative feature
subset. In prior literature, filter (e.g., backward elimination) and embedded
(e.g., Lasso) methods have hyperparameters (e.g., top-K, score thresholding)
and tie to specific models, thus, hard to generalize; wrapper methods search a
feature subset in a huge discrete space and is computationally costly. To
transform the way of feature selection, we regard a selected feature subset as
a selection decision token sequence and reformulate feature selection as a deep
sequential generative learning task that distills feature knowledge and
generates decision sequences. Our method includes three steps: (1) We develop a
deep variational transformer model over a joint of sequential reconstruction,
variational, and performance evaluator losses. Our model can distill feature
selection knowledge and learn a continuous embedding space to map feature
selection decision sequences into embedding vectors associated with utility
scores. (2) We leverage the trained feature subset utility evaluator as a
gradient provider to guide the identification of the optimal feature subset
embedding;(3) We decode the optimal feature subset embedding to
autoregressively generate the best feature selection decision sequence with
autostop. Extensive experimental results show this generative perspective is
effective and generic, without large discrete search space and expert-specific
hyperparameters.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03842" title="Abstract">arXiv:2403.03842</a> [<a href="/pdf/2403.03842" title="Download PDF">pdf</a>, <a href="/ps/2403.03842" title="Download PostScript">ps</a>, <a href="/format/2403.03842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Political polarisation in turbulent times: Tracking polarisation trends  and partisan news link sharing on Finnish Twitter, 2015-2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gronow%2C+A">Antti Gronow</a>, 
<a href="/search/cs?searchtype=author&query=Malkam%C3%A4ki%2C+A">Arttu Malkam&#xe4;ki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Finish language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The study analyses polarisation on Finnish social media with data from the
platform X, which was known as Twitter during the time of data collection
(during the Sipil\"a and Marin governments, 2015-2023). The users were
clustered into three different ideological groups - the Conservative Right, the
Moderate Right, and the Liberal Left - based on their retweeting of tweets
referring to the different political parties in Finland. Trends in polarisation
of several topics encompassing the most recent political crises - immigration,
climate change, COVID-19, and security policy - between these ideological
groups is analysed using network methods. To what extent the polarisation of
each topic aligns with the polarisation of the other topics is also studied. In
addition, the sharing of news links is examined in relation to the ideological
groups of the users as well as to the sentiment and the virality of the tweets
in which news links are shared.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03844" title="Abstract">arXiv:2403.03844</a> [<a href="/pdf/2403.03844" title="Download PDF">pdf</a>, <a href="/format/2403.03844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electromagnetic inverse wave scattering in anisotropic media via reduced  order modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Borcea%2C+L">Liliana Borcea</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yiyang Liu</a>, 
<a href="/search/math?searchtype=author&query=Zimmerling%2C+J">J&#xf6;rn Zimmerling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The inverse wave scattering problem seeks to estimate a heterogeneous,
inaccessible medium, modeled by unknown variable coefficients in wave
equations, from transient recordings of waves generated by probing signals. It
is a widely studied inverse problem with important applications, that is
typically formulated as a nonlinear least squares data fit optimization. For
typical measurement setups and band-limited probing signals, the least squares
objective function has spurious local minima far and near the true solution, so
Newton-type optimization methods fail. We introduce a different approach, for
electromagnetic inverse wave scattering in lossless, anisotropic media. Our
reduced order model (ROM) is an algebraic, discrete time dynamical system
derived from Maxwell's equations with four important properties: (1) It is data
driven, without knowledge of the medium. (2) The data to ROM mapping is
nonlinear and yet the ROM can be obtained in a non-iterative fashion. (3) It
has a special algebraic structure that captures the causal Wave propagation.
(4) The ROM interpolates the data on a uniform time grid. We show how to obtain
from the ROM an estimate of the wave field at inaccessible points inside the
unknown medium. The use of this wave is twofold: First, it defines a
computationally inexpensive imaging function designed to estimate the support
of reflective structures in the medium, modeled by jump discontinuities of the
matrix valued dielectric permittivity. Second, it gives an objective function
for quantitative estimation of the dielectric permittivity, that has better
behavior than the least squares data fitting objective function. The
methodology introduced in this paper applies to Maxwell's equations in three
dimensions. To avoid high computational costs, we limit the study to a
cylindrical domain filled with an orthotropic medium, so the problem becomes
two dimensional.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03846" title="Abstract">arXiv:2403.03846</a> [<a href="/pdf/2403.03846" title="Download PDF">pdf</a>, <a href="/format/2403.03846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Distillation in Mitigating Backdoors in  Pre-trained Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tingxu Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shenghan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Ziqi Ding</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yebo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hanwei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we study a defense against poisoned encoders in SSL called
distillation, which is a defense used in supervised learning originally.
Distillation aims to distill knowledge from a given model (a.k.a the teacher
net) and transfer it to another (a.k.a the student net). Now, we use it to
distill benign knowledge from poisoned pre-trained encoders and transfer it to
a new encoder, resulting in a clean pre-trained encoder. In particular, we
conduct an empirical study on the effectiveness and performance of distillation
against poisoned encoders. Using two state-of-the-art backdoor attacks against
pre-trained image encoders and four commonly used image classification
datasets, our experimental results show that distillation can reduce attack
success rate from 80.87% to 27.51% while suffering a 6.35% loss in accuracy.
Moreover, we investigate the impact of three core components of distillation on
performance: teacher net, student net, and distillation loss. By comparing 4
different teacher nets, 3 student nets, and 6 distillation losses, we find that
fine-tuned teacher nets, warm-up-training-based student nets, and
attention-based distillation loss perform best, respectively.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03848" title="Abstract">arXiv:2403.03848</a> [<a href="/pdf/2403.03848" title="Download PDF">pdf</a>, <a href="/format/2403.03848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dexterous Legged Locomotion in Confined 3D Spaces with Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+A+H">Amir Hossain Raj</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances of locomotion controllers utilizing deep reinforcement
learning (RL) have yielded impressive results in terms of achieving rapid and
robust locomotion across challenging terrain, such as rugged rocks, non-rigid
ground, and slippery surfaces. However, while these controllers primarily
address challenges underneath the robot, relatively little research has
investigated legged mobility through confined 3D spaces, such as narrow tunnels
or irregular voids, which impose all-around constraints. The cyclic gait
patterns resulted from existing RL-based methods to learn parameterized
locomotion skills characterized by motion parameters, such as velocity and body
height, may not be adequate to navigate robots through challenging confined 3D
spaces, requiring both agile 3D obstacle avoidance and robust legged
locomotion. Instead, we propose to learn locomotion skills end-to-end from
goal-oriented navigation in confined 3D spaces. To address the inefficiency of
tracking distant navigation goals, we introduce a hierarchical locomotion
controller that combines a classical planner tasked with planning waypoints to
reach a faraway global goal location, and an RL-based policy trained to follow
these waypoints by generating low-level motion commands. This approach allows
the policy to explore its own locomotion skills within the entire solution
space and facilitates smooth transitions between local goals, enabling
long-term navigation towards distant goals. In simulation, our hierarchical
approach succeeds at navigating through demanding confined 3D environments,
outperforming both pure end-to-end learning approaches and parameterized
locomotion skills. We further demonstrate the successful real-world deployment
of our simulation-trained controller on a real robot.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03852" title="Abstract">arXiv:2403.03852</a> [<a href="/pdf/2403.03852" title="Download PDF">pdf</a>, <a href="/format/2403.03852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Convergence of Score-Based Diffusion Models, Provably
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Efimov%2C+T">Timofey Efimov</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuting Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Score-based diffusion models, while achieving remarkable empirical
performance, often suffer from low sampling speed, due to extensive function
evaluations needed during the sampling phase. Despite a flurry of recent
activities towards speeding up diffusion generative modeling in practice,
theoretical underpinnings for acceleration techniques remain severely limited.
In this paper, we design novel training-free algorithms to accelerate popular
deterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Our
accelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ the
number of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and our
accelerated stochastic sampler converges at a rate $O(1/T)$, outperforming the
rate $O(1/\sqrt{T})$ for the DDPM sampler. The design of our algorithms
leverages insights from higher-order approximation, and shares similar
intuitions as popular high-order ODE solvers like the DPM-Solver-2. Our theory
accommodates $\ell_2$-accurate score estimates, and does not require
log-concavity or smoothness on the target distribution.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03853" title="Abstract">arXiv:2403.03853</a> [<a href="/pdf/2403.03853" title="Download PDF">pdf</a>, <a href="/format/2403.03853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShortGPT: Layers in Large Language Models are More Redundant Than You  Expect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Men%2C+X">Xin Men</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaojie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weipeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As Large Language Models (LLMs) continue to advance in performance, their
size has escalated significantly, with current LLMs containing billions or even
trillions of parameters. However, in this study, we discovered that many layers
of LLMs exhibit high similarity, and some layers play a negligible role in
network functionality. Based on this observation, we define a metric called
Block Influence (BI) to gauge the significance of each layer in LLMs. We then
propose a straightforward pruning approach: layer removal, in which we directly
delete the redundant layers in LLMs based on their BI scores. Experiments
demonstrate that our method, which we call ShortGPT, significantly outperforms
previous state-of-the-art (SOTA) methods in model pruning. Moreover, ShortGPT
is orthogonal to quantization-like methods, enabling further reduction in
parameters and computation. The ability to achieve better results through
simple layer removal, as opposed to more complex pruning techniques, suggests a
high degree of redundancy in the model architecture.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03854" title="Abstract">arXiv:2403.03854</a> [<a href="/pdf/2403.03854" title="Download PDF">pdf</a>, <a href="/format/2403.03854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECAP: Extensive Cut-and-Paste Augmentation for Unsupervised Domain  Adaptive Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brorsson%2C+E">Erik Brorsson</a>, 
<a href="/search/cs?searchtype=author&query=%C3%85kesson%2C+K">Knut &#xc5;kesson</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+L">Lennart Svensson</a>, 
<a href="/search/cs?searchtype=author&query=Bengtsson%2C+K">Kristofer Bengtsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We consider unsupervised domain adaptation (UDA) for semantic segmentation in
which the model is trained on a labeled source dataset and adapted to an
unlabeled target dataset. Unfortunately, current self-training methods are
susceptible to misclassified pseudo-labels resulting from erroneous
predictions. Since certain classes are typically associated with less reliable
predictions in UDA, reducing the impact of such pseudo-labels without skewing
the training towards some classes is notoriously difficult. To this end, we
propose an extensive cut-and-paste strategy (ECAP) to leverage reliable
pseudo-labels through data augmentation. Specifically, ECAP maintains a memory
bank of pseudo-labeled target samples throughout training and cut-and-pastes
the most confident ones onto the current training batch. We implement ECAP on
top of the recent method MIC and boost its performance on two synthetic-to-real
domain adaptation benchmarks. Notably, MIC+ECAP reaches an unprecedented
performance of 69.1 mIoU on the Synthia-&gt;Cityscapes benchmark. Our code is
available at https://github.com/ErikBrorsson/ECAP.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03856" title="Abstract">arXiv:2403.03856</a> [<a href="/pdf/2403.03856" title="Download PDF">pdf</a>, <a href="/ps/2403.03856" title="Download PostScript">ps</a>, <a href="/format/2403.03856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Public-data Assisted Private Stochastic Optimization: Power and  Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ullah%2C+E">Enayat Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Menart%2C+M">Michael Menart</a>, 
<a href="/search/cs?searchtype=author&query=Bassily%2C+R">Raef Bassily</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n%2C+C">Crist&#xf3;bal Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+R">Raman Arora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the limits and capability of public-data assisted differentially
private (PA-DP) algorithms. Specifically, we focus on the problem of stochastic
convex optimization (SCO) with either labeled or unlabeled public data. For
complete/labeled public data, we show that any $(\epsilon,\delta)$-PA-DP has
excess risk
$\tilde{\Omega}\big(\min\big\{\frac{1}{\sqrt{n_{\text{pub}}}},\frac{1}{\sqrt{n}}+\frac{\sqrt{d}}{n\epsilon}
\big\} \big)$, where $d$ is the dimension, ${n_{\text{pub}}}$ is the number of
public samples, ${n_{\text{priv}}}$ is the number of private samples, and
$n={n_{\text{pub}}}+{n_{\text{priv}}}$. These lower bounds are established via
our new lower bounds for PA-DP mean estimation, which are of a similar form. Up
to constant factors, these lower bounds show that the simple strategy of either
treating all data as private or discarding the private data, is optimal. We
also study PA-DP supervised learning with \textit{unlabeled} public samples. In
contrast to our previous result, we here show novel methods for leveraging
public data in private supervised learning. For generalized linear models (GLM)
with unlabeled public data, we show an efficient algorithm which, given
$\tilde{O}({n_{\text{priv}}}\epsilon)$ unlabeled public samples, achieves the
dimension independent rate $\tilde{O}\big(\frac{1}{\sqrt{{n_{\text{priv}}}}} +
\frac{1}{\sqrt{{n_{\text{priv}}}\epsilon}}\big)$. We develop new lower bounds
for this setting which shows that this rate cannot be improved with more public
samples, and any fewer public samples leads to a worse rate. Finally, we
provide extensions of this result to general hypothesis classes with finite
fat-shattering dimension with applications to neural networks and non-Euclidean
geometries.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03857" title="Abstract">arXiv:2403.03857</a> [<a href="/pdf/2403.03857" title="Download PDF">pdf</a>, <a href="/format/2403.03857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emojinize : Enriching Any Text with Emoji Translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+L+H">Lars Henning Klein</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+R">Roland Aydin</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Emoji have become ubiquitous in written communication, on the Web and beyond.
They can emphasize or clarify emotions, add details to conversations, or simply
serve decorative purposes. This casual use, however, barely scratches the
surface of the expressive power of emoji. To further unleash this power, we
present Emojinize, a method for translating arbitrary text phrases into
sequences of one or more emoji without requiring human input. By leveraging the
power of large language models, Emojinize can choose appropriate emoji by
disambiguating based on context (eg, cricket-bat vs bat) and can express
complex concepts compositionally by combining multiple emoji (eq, ''Emojinize''
is translated to input-latin-letters right-arrow grinning-face). In a cloze
test--based user study, we show that Emojinize's emoji translations increase
the human guessability of masked words by 55%, whereas human-picked emoji
translations do so by only 29%. These results suggest that emoji provide a
sufficiently rich vocabulary to accurately translate a wide variety of words.
Moreover, annotating words and phrases with Emojinize's emoji translations
opens the door to numerous downstream applications, including children learning
how to read, adults learning foreign languages, and text understanding for
people with learning disabilities.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03858" title="Abstract">arXiv:2403.03858</a> [<a href="/pdf/2403.03858" title="Download PDF">pdf</a>, <a href="/format/2403.03858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Jamming and Hijacking Attacks for Micro Aerial Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mekdad%2C+Y">Yassine Mekdad</a>, 
<a href="/search/cs?searchtype=author&query=Acar%2C+A">Abbas Acar</a>, 
<a href="/search/cs?searchtype=author&query=Aris%2C+A">Ahmet Aris</a>, 
<a href="/search/cs?searchtype=author&query=Fergougui%2C+A+E">Abdeslam El Fergougui</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>, 
<a href="/search/cs?searchtype=author&query=Lazzeretti%2C+R">Riccardo Lazzeretti</a>, 
<a href="/search/cs?searchtype=author&query=Uluagac%2C+S">Selcuk Uluagac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recent advancements in drone technology have shown that commercial
off-the-shelf Micro Aerial Drones are more effective than large-sized drones
for performing flight missions in narrow environments, such as swarming, indoor
navigation, and inspection of hazardous locations. Due to their deployments in
many civilian and military applications, safe and reliable communication of
these drones throughout the mission is critical. The Crazyflie ecosystem is one
of the most popular Micro Aerial Drones and has the potential to be deployed
worldwide. In this paper, we empirically investigate two interference attacks
against the Crazy Real Time Protocol (CRTP) implemented within the Crazyflie
drones. In particular, we explore the feasibility of experimenting two attack
vectors that can disrupt an ongoing flight mission: the jamming attack, and the
hijacking attack. Our experimental results demonstrate the effectiveness of
such attacks in both autonomous and non-autonomous flight modes on a Crazyflie
2.1 drone. Finally, we suggest potential shielding strategies that guarantee a
safe and secure flight mission. To the best of our knowledge, this is the first
work investigating jamming and hijacking attacks against Micro Aerial Drones,
both in autonomous and non-autonomous modes.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03861" title="Abstract">arXiv:2403.03861</a> [<a href="/pdf/2403.03861" title="Download PDF">pdf</a>, <a href="/format/2403.03861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Informative Metrics for Few-Shot Example Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adiga%2C+R">Rishabh Adiga</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+L">Lakshminarayanan Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+V">Varun Chandrasekaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Pretrained language models (PLMs) have shown remarkable few-shot learning
capabilities when provided with properly formatted examples. However, selecting
the "best" examples remains an open challenge. We propose a complexity-based
prompt selection approach for sequence tagging tasks. This approach avoids the
training of a dedicated model for selection of examples, and instead uses
certain metrics to align the syntactico-semantic complexity of test sentences
and examples. We use both sentence- and word-level metrics to match the
complexity of examples to the (test) sentence being considered. Our results
demonstrate that our approach extracts greater performance from PLMs: it
achieves state-of-the-art performance on few-shot NER, achieving a 5% absolute
improvement in F1 score on the CoNLL2003 dataset for GPT-4. We also see large
gains of upto 28.85 points (F1/Acc.) in smaller models like GPT-j-6B.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03863" title="Abstract">arXiv:2403.03863</a> [<a href="/pdf/2403.03863" title="Download PDF">pdf</a>, <a href="/format/2403.03863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot  Learning Simultaneously in Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanzi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+S">Slobodan Vucetic</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, few-shot and zero-shot learning, which learn to predict
labels with limited annotated instances, have garnered significant attention.
Traditional approaches often treat frequent-shot (freq-shot; labels with
abundant instances), few-shot, and zero-shot learning as distinct challenges,
optimizing systems for just one of these scenarios. Yet, in real-world
settings, label occurrences vary greatly. Some of them might appear thousands
of times, while others might only appear sporadically or not at all. For
practical deployment, it is crucial that a system can adapt to any label
occurrence. We introduce a novel classification challenge: X-shot, reflecting a
real-world context where freq-shot, few-shot, and zero-shot labels co-occur
without predefined limits. Here, X can span from 0 to positive infinity. The
crux of X-shot centers on open-domain generalization and devising a system
versatile enough to manage various label scenarios. To solve X-shot, we propose
BinBin (Binary INference Based on INstruction following) that leverages the
Indirect Supervision from a large collection of NLP tasks via instruction
following, bolstered by Weak Supervision provided by large language models.
BinBin surpasses previous state-of-the-art techniques on three benchmark
datasets across multiple domains. To our knowledge, this is the first work
addressing X-shot learning, where X remains variable.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03864" title="Abstract">arXiv:2403.03864</a> [<a href="/pdf/2403.03864" title="Download PDF">pdf</a>, <a href="/format/2403.03864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious  Challenges in Multimodal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosal%2C+D">Deepanway Ghosal</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+V+T+Y">Vernon Toh Yan Han</a>, 
<a href="/search/cs?searchtype=author&query=Ken%2C+C+Y">Chia Yew Ken</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces the novel task of multimodal puzzle solving, framed
within the context of visual question-answering. We present a new dataset,
AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal
language models in solving algorithmic puzzles that necessitate both visual
understanding, language understanding, and complex algorithmic reasoning. We
create the puzzles to encompass a diverse array of mathematical and algorithmic
topics such as boolean logic, combinatorics, graph theory, optimization,
search, etc., aiming to evaluate the gap between visual data interpretation and
algorithmic problem-solving skills. The dataset is generated automatically from
code authored by humans. All our puzzles have exact solutions that can be found
from the algorithm without tedious human calculations. It ensures that our
dataset can be scaled up arbitrarily in terms of reasoning complexity and
dataset size. Our investigation reveals that large language models (LLMs) such
as GPT4V and Gemini exhibit limited performance in puzzle-solving tasks. We
find that their performance is near random in a multi-choice question-answering
setup for a significant number of puzzles. The findings emphasize the
challenges of integrating visual, language, and algorithmic knowledge for
solving complex reasoning problems.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03865" title="Abstract">arXiv:2403.03865</a> [<a href="/pdf/2403.03865" title="Download PDF">pdf</a>, <a href="/format/2403.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain and Carbon Markets: Standards Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baiz%2C+P">Pedro Baiz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The increasing significance of sustainability considerations within both
public spheres (such as policies and regulations) and private sectors
(including voluntary commitments by major multinational corporations)
underscores the imperative to harness cutting-edge technological advancements.
This is essential to ensure that the momentum of this trend translates into
tangible outcomes, thwarting phenomena like greenwashing and upholding high
standards of integrity, all while expediting progress through automation. This
paper focuses specifically on carbon markets, which, after enduring years of
confusion and controversy, may finally be on the brink of converging toward
internationally recognized minimum standards. Beginning with an introduction to
fundamental concepts pertaining to carbon markets and Distributed Ledger
Technologies (DLTs), the paper proceeds to dissect the challenges and
opportunities within this burgeoning field. Its primary contribution lies in
offering a comprehensive overview of recent developments across various
initiatives (such as ICVCM, IETA/WorldBank/CAD Trust, IEEE/ISO) and providing a
layered analysis of the entire ecosystem. This framework aids in understanding
and prioritising future endeavours. Ultimately, the paper furnishes a set of
recommendations aimed at bolstering scalability and fostering widespread
adoption of best practices within international markets.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03866" title="Abstract">arXiv:2403.03866</a> [<a href="/pdf/2403.03866" title="Download PDF">pdf</a>, <a href="/format/2403.03866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KIWI: A Dataset of Knowledge-Intensive Writing Instructions for  Answering Research Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fangyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Kuehl%2C+B">Bailey Kuehl</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunsol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wadden%2C+D">David Wadden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) adapted to follow user instructions are now
widely deployed as conversational agents. In this work, we examine one
increasingly common instruction-following task: providing writing assistance to
compose a long-form answer. To evaluate the capabilities of current LLMs on
this task, we construct KIWI, a dataset of knowledge-intensive writing
instructions in the scientific domain. Given a research question, an initial
model-generated answer and a set of relevant papers, an expert annotator
iteratively issues instructions for the model to revise and improve its answer.
We collect 1,260 interaction turns from 234 interaction sessions with three
state-of-the-art LLMs. Each turn includes a user instruction, a model response,
and a human evaluation of the model response. Through a detailed analysis of
the collected responses, we find that all models struggle to incorporate new
information into an existing answer, and to perform precise and unambiguous
edits. Further, we find that models struggle to judge whether their outputs
successfully followed user instructions, with accuracy at least 10 points short
of human agreement. Our findings indicate that KIWI will be a valuable resource
to measure progress and improve LLMs' instruction-following capabilities for
knowledge intensive writing tasks.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03867" title="Abstract">arXiv:2403.03867</a> [<a href="/pdf/2403.03867" title="Download PDF">pdf</a>, <a href="/format/2403.03867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Origins of Linear Representations in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yibo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+G">Goutham Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>, 
<a href="/search/cs?searchtype=author&query=Aragam%2C+B">Bryon Aragam</a>, 
<a href="/search/cs?searchtype=author&query=Veitch%2C+V">Victor Veitch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent works have argued that high-level semantic concepts are encoded
"linearly" in the representation space of large language models. In this work,
we study the origins of such linear representations. To that end, we introduce
a simple latent variable model to abstract and formalize the concept dynamics
of the next token prediction. We use this formalism to show that the next token
prediction objective (softmax with cross-entropy) and the implicit bias of
gradient descent together promote the linear representation of concepts.
Experiments show that linear representations emerge when learning from data
matching the latent variable model, confirming that this simple structure
already suffices to yield linear representations. We additionally confirm some
predictions of the theory using the LLaMA-2 large language model, giving
evidence that the simplified model yields generalizable insights.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03869" title="Abstract">arXiv:2403.03869</a> [<a href="/pdf/2403.03869" title="Download PDF">pdf</a>, <a href="/ps/2403.03869" title="Download PostScript">ps</a>, <a href="/format/2403.03869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digitality as a &quot;longue dur&#xe8;e&quot; historical phenomenon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spina%2C+S">Salvatore Spina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The digital age introduced the Digital Ecological Niche (DEN),
revolutionizing human interactions. The advent of Digital History (DHy) has
marked a methodological shift in historical studies, tracing its roots to
Babbage and Lovelace's 19th-century work on "coding" as a foundational
communication process, fostering a new interaction paradigm between humans and
machines, termed "person2persons2machines." This evolution, through
digitization and informatization, builds upon ancient coding practices but was
significantly advanced by Babbage and Lovelace's contributions to mathematical
linguistic systems, laying the groundwork for Computer Science. This field,
central to 20th-century mainframe interaction through programming languages and
formalization, situates Digital History within a broader historical context.
Here, coding and mathematical methodologies empower historians with advanced
technologies for historical data preservation and analysis. Nonetheless, the
extent to which computation and Turing machines can fully understand and
interpret history remains a subject of debate.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03870" title="Abstract">arXiv:2403.03870</a> [<a href="/pdf/2403.03870" title="Download PDF">pdf</a>, <a href="/format/2403.03870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Decode Collaboratively with Multiple Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+S+Z">Shannon Zejiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+H">Hunter Lang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sontag%2C+D">David Sontag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a method to teach multiple large language models (LLM) to
collaborate by interleaving their generations at the token level. We model the
decision of which LLM generates the next token as a latent variable. By
optimizing the marginal likelihood of a training set under our latent variable
model, the base LLM automatically learns when to generate itself and when to
call on one of the ``assistant'' language models to generate, all without
direct supervision. Token-level collaboration during decoding allows for a
fusion of each model's expertise in a manner tailored to the specific task at
hand. Our collaborative decoding is especially useful in cross-domain settings
where a generalist base LLM learns to invoke domain expert models. On
instruction-following, domain-specific QA, and reasoning tasks, we show that
the performance of the joint system exceeds that of the individual models.
Through qualitative analysis of the learned latent decisions, we show models
trained with our method exhibit several interesting collaboration patterns,
e.g., template-filling. Our code is available at
https://github.com/clinicalml/co-llm.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03871" title="Abstract">arXiv:2403.03871</a> [<a href="/pdf/2403.03871" title="Download PDF">pdf</a>, <a href="/format/2403.03871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupled Vertical Federated Learning for Practical Training on  Vertically Partitioned Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amalanshu%2C+A">Avi Amalanshu</a>, 
<a href="/search/cs?searchtype=author&query=Sirvi%2C+Y">Yash Sirvi</a>, 
<a href="/search/cs?searchtype=author&query=Inouye%2C+D+I">David I. Inouye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures (excluding appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Vertical Federated Learning (VFL) is an emergent distributed machine learning
paradigm wherein owners of disjoint features of a common set of entities
collaborate to learn a global model without sharing data. In VFL, a host client
owns data labels for each entity and learns a final representation based on
intermediate local representations from all guest clients. Therefore, the host
is a single point of failure and label feedback can be used by malicious guest
clients to infer private features. Requiring all participants to remain active
and trustworthy throughout the entire training process is generally impractical
and altogether infeasible outside of controlled environments. We propose
Decoupled VFL (DVFL), a blockwise learning approach to VFL. By training each
model on its own objective, DVFL allows for decentralized aggregation and
isolation between feature learning and label supervision. With these
properties, DVFL is fault tolerant and secure. We implement DVFL to train split
neural networks and show that model performance is comparable to VFL on a
variety of classification datasets.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03874" title="Abstract">arXiv:2403.03874</a> [<a href="/pdf/2403.03874" title="Download PDF">pdf</a>, <a href="/ps/2403.03874" title="Download PostScript">ps</a>, <a href="/format/2403.03874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impoverished Language Technology: The Lack of (Social) Class in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Curry%2C+A+C">Amanda Cercas Curry</a>, 
<a href="/search/cs?searchtype=author&query=Talat%2C+Z">Zeerak Talat</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to LREC-COLING 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Since Labov's (1964) foundational work on the social stratification of
language, linguistics has dedicated concerted efforts towards understanding the
relationships between socio-demographic factors and language production and
perception. Despite the large body of evidence identifying significant
relationships between socio-demographic factors and language production,
relatively few of these factors have been investigated in the context of NLP
technology. While age and gender are well covered, Labov's initial target,
socio-economic class, is largely absent. We survey the existing Natural
Language Processing (NLP) literature and find that only 20 papers even mention
socio-economic status. However, the majority of those papers do not engage with
class beyond collecting information of annotator-demographics. Given this
research lacuna, we provide a definition of class that can be operationalised
by NLP researchers, and argue for including socio-economic class in future
language technologies.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03875" title="Abstract">arXiv:2403.03875</a> [<a href="/pdf/2403.03875" title="Download PDF">pdf</a>, <a href="/format/2403.03875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting reality to diminish distractions for cognitive enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">JangHyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+L+H">Lawrence H. Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Smartphones are integral to modern life, yet research highlights the
cognitive drawbacks associated even with their mere presence. Physically
removing them from sight is a solution, but it is sometimes impractical and may
increase anxiety due to fear of missing out. In response, we introduce a simple
but effective use of augmented reality (AR) head-mounted displays, focusing not
on augmenting reality with virtual objects, but on diminishing reality by
selectively removing or occluding distracting objects, from the user's field of
view. We compared cognitive task performance across four conditions: the
smartphone being physically nearby, physically remote, visually removed and
visually occluded via AR. Our findings reveal that using AR to visually cancel
out smartphones significantly mitigates cognitive distractions caused by their
presence. Specifically, the AR interventions had effects similar to physically
removing the phone. These results suggest potential for novel AR applications
designed to diminish reality, thereby enhancing cognitive performance.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03876" title="Abstract">arXiv:2403.03876</a> [<a href="/pdf/2403.03876" title="Download PDF">pdf</a>, <a href="/format/2403.03876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Adversarial Contention Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banicescu%2C+I">Ioana Banicescu</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Trisha Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+S">Seth Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+M">Maxwell Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Contention resolution addresses the challenge of coordinating access by
multiple processes to a shared resource such as memory, disk storage, or a
communication channel. Originally spurred by challenges in database systems and
bus networks, contention resolution has endured as an important abstraction for
resource sharing, despite decades of technological change. Here, we survey the
literature on resolving worst-case contention, where the number of processes
and the time at which each process may start seeking access to the resource is
dictated by an adversary. We highlight the evolution of contention resolution,
where new concerns -- such as security, quality of service, and energy
efficiency -- are motivated by modern systems. These efforts have yielded
insights into the limits of randomized and deterministic approaches, as well as
the impact of different model assumptions such as global clock synchronization,
knowledge of the number of processors, feedback from access attempts, and
attacks on the availability of the shared resource.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03879" title="Abstract">arXiv:2403.03879</a> [<a href="/pdf/2403.03879" title="Download PDF">pdf</a>, <a href="/format/2403.03879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining cystoscopy with ai: bladder cancer diagnosis using an  efficient hybrid cnn-transformer model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amaouche%2C+M">Meryem Amaouche</a>, 
<a href="/search/cs?searchtype=author&query=Karrakchou%2C+O">Ouassim Karrakchou</a>, 
<a href="/search/cs?searchtype=author&query=Ghogho%2C+M">Mounir Ghogho</a>, 
<a href="/search/cs?searchtype=author&query=Ghazzaly%2C+A+E">Anouar El Ghazzaly</a>, 
<a href="/search/cs?searchtype=author&query=Alami%2C+M">Mohamed Alami</a>, 
<a href="/search/cs?searchtype=author&query=Ameur%2C+A">Ahmed Ameur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Bladder cancer ranks within the top 10 most diagnosed cancers worldwide and
is among the most expensive cancers to treat due to the high recurrence rates
which require lifetime follow-ups. The primary tool for diagnosis is
cystoscopy, which heavily relies on doctors' expertise and interpretation.
Therefore, annually, numerous cases are either undiagnosed or misdiagnosed and
treated as urinary infections. To address this, we suggest a deep learning
approach for bladder cancer detection and segmentation which combines CNNs with
a lightweight positional-encoding-free transformer and dual attention gates
that fuse self and spatial attention for feature enhancement. The architecture
suggested in this paper is efficient making it suitable for medical scenarios
that require real time inference. Experiments have proven that this model
addresses the critical need for a balance between computational efficiency and
diagnostic accuracy in cystoscopic imaging as despite its small size it rivals
large models in performance.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03880" title="Abstract">arXiv:2403.03880</a> [<a href="/pdf/2403.03880" title="Download PDF">pdf</a>, <a href="/format/2403.03880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph neural network outputs are almost surely asymptotically constant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adam-Day%2C+S">Sam Adam-Day</a>, 
<a href="/search/cs?searchtype=author&query=Benedikt%2C+M">Michael Benedikt</a>, 
<a href="/search/cs?searchtype=author&query=Ceylan%2C+%C4%B0+%C4%B0">&#x130;smail &#x130;lkan Ceylan</a>, 
<a href="/search/cs?searchtype=author&query=Finkelshtein%2C+B">Ben Finkelshtein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 body pages, 23 appendix pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Graph neural networks (GNNs) are the predominant architectures for a variety
of learning tasks on graphs. We present a new angle on the expressive power of
GNNs by studying how the predictions of a GNN probabilistic classifier evolve
as we apply it on larger graphs drawn from some random graph model. We show
that the output converges to a constant function, which upper-bounds what these
classifiers can express uniformly. This convergence phenomenon applies to a
very wide class of GNNs, including state of the art models, with aggregates
including mean and the attention-based mechanism of graph transformers. Our
results apply to a broad class of random graph models, including the (sparse)
Erd\H{o}s-R\'enyi model and the stochastic block model. We empirically validate
these findings, observing that the convergence phenomenon already manifests
itself on graphs of relatively modest size.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03881" title="Abstract">arXiv:2403.03881</a> [<a href="/pdf/2403.03881" title="Download PDF">pdf</a>, <a href="/format/2403.03881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Dataset Distillation with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moser%2C+B+B">Brian B. Moser</a>, 
<a href="/search/cs?searchtype=author&query=Raue%2C+F">Federico Raue</a>, 
<a href="/search/cs?searchtype=author&query=Palacio%2C+S">Sebastian Palacio</a>, 
<a href="/search/cs?searchtype=author&query=Frolov%2C+S">Stanislav Frolov</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The efficacy of machine learning has traditionally relied on the availability
of increasingly larger datasets. However, large datasets pose storage
challenges and contain non-influential samples, which could be ignored during
training without impacting the final accuracy of the model. In response to
these limitations, the concept of distilling the information on a dataset into
a condensed set of (synthetic) samples, namely a distilled dataset, emerged.
One crucial aspect is the selected architecture (usually ConvNet) for linking
the original and synthetic datasets. However, the final accuracy is lower if
the employed model architecture differs from the model used during
distillation. Another challenge is the generation of high-resolution images,
e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation
with Diffusion Models (LD3M) that combine diffusion in latent space with
dataset distillation to tackle both challenges. LD3M incorporates a novel
diffusion process tailored for dataset distillation, which improves the
gradient norms for learning synthetic images. By adjusting the number of
diffusion steps, LD3M also offers a straightforward way of controlling the
trade-off between speed and accuracy. We evaluate our approach in several
ImageNet subsets and for high-resolution images (128x128 and 256x256). As a
result, LD3M consistently outperforms state-of-the-art distillation techniques
by up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03882" title="Abstract">arXiv:2403.03882</a> [<a href="/pdf/2403.03882" title="Download PDF">pdf</a>, <a href="/ps/2403.03882" title="Download PostScript">ps</a>, <a href="/format/2403.03882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self and Mixed Supervision to Improve Training Labels for Multi-Class  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Parnell%2C+C">Christopher Parnell</a>, 
<a href="/search/cs?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages, 3 figures, SPIE Medical Imaging 2024, Computer-aided diagnosis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate training labels are a key component for multi-class medical image
segmentation. Their annotation is costly and time-consuming because it requires
domain expertise. This work aims to develop a dual-branch network and
automatically improve training labels for multi-class image segmentation.
Transfer learning is used to train the network and improve inaccurate weak
labels sequentially. The dual-branch network is first trained by weak labels
alone to initialize model parameters. After the network is stabilized, the
shared encoder is frozen, and strong and weak decoders are fine-tuned by strong
and weak labels together. The accuracy of weak labels is iteratively improved
in the fine-tuning process. The proposed method was applied to a three-class
segmentation of muscle, subcutaneous and visceral adipose tissue on abdominal
CT scans. Validation results on 11 patients showed that the accuracy of
training labels was statistically significantly improved, with the Dice
similarity coefficient of muscle, subcutaneous and visceral adipose tissue
increased from 74.2% to 91.5%, 91.2% to 95.6%, and 77.6% to 88.5%, respectively
(p&lt;0.05). In comparison with our earlier method, the label accuracy was also
significantly improved (p&lt;0.05). These experimental results suggested that the
combination of the dual-branch network and transfer learning is an efficient
means to improve training labels for multi-class segmentation.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03883" title="Abstract">arXiv:2403.03883</a> [<a href="/pdf/2403.03883" title="Download PDF">pdf</a>, <a href="/format/2403.03883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SaulLM-7B: A pioneering Large Language Model for Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colombo%2C+P">Pierre Colombo</a>, 
<a href="/search/cs?searchtype=author&query=Pires%2C+T+P">Telmo Pessoa Pires</a>, 
<a href="/search/cs?searchtype=author&query=Boudiaf%2C+M">Malik Boudiaf</a>, 
<a href="/search/cs?searchtype=author&query=Culver%2C+D">Dominic Culver</a>, 
<a href="/search/cs?searchtype=author&query=Melo%2C+R">Rui Melo</a>, 
<a href="/search/cs?searchtype=author&query=Corro%2C+C">Caio Corro</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andre F. T. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+F">Fabrizio Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Raposo%2C+V+L">Vera L&#xfa;cia Raposo</a>, 
<a href="/search/cs?searchtype=author&query=Morgado%2C+S">Sofia Morgado</a>, 
<a href="/search/cs?searchtype=author&query=Desa%2C+M">Michael Desa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we introduce SaulLM-7B, a large language model (LLM) tailored
for the legal domain. With 7 billion parameters, SaulLM-7B is the first LLM
designed explicitly for legal text comprehension and generation. Leveraging the
Mistral 7B architecture as its foundation, SaulLM-7B is trained on an English
legal corpus of over 30 billion tokens. SaulLM-7B exhibits state-of-the-art
proficiency in understanding and processing legal documents. Additionally, we
present a novel instructional fine-tuning method that leverages legal datasets
to further enhance SaulLM-7B's performance in legal tasks. SaulLM-7B is
released under the CC-BY-SA-4.0 License.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03886" title="Abstract">arXiv:2403.03886</a> [<a href="/pdf/2403.03886" title="Download PDF">pdf</a>, <a href="/format/2403.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Virtual Element method for non-Newtonian fluid flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">P. F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=da+Veiga%2C+L+B">L. Beirao da Veiga</a>, 
<a href="/search/math?searchtype=author&query=Botti%2C+M">M. Botti</a>, 
<a href="/search/math?searchtype=author&query=Vacca%2C+G">G. Vacca</a>, 
<a href="/search/math?searchtype=author&query=Verani%2C+M">M. Verani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we design and analyze a Virtual Element discretization for the
steady motion of non-Newtonian, incompressible fluids. A specific
stabilization, tailored to mimic the monotonicity and boundedness properties of
the continuous operator, is introduced and theoretically investigated. The
proposed method has several appealing features, including the exact enforcement
of the divergence free condition and the possibility of making use of fully
general polygonal meshes. A complete well-posedness and convergence analysis of
the proposed method is presented under mild assumptions on the non-linear laws,
encompassing common examples such as the Carreau--Yasuda model. Numerical
experiments validating the theoretical bounds as well as demonstrating the
practical capabilities of the proposed formulation are presented.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03888" title="Abstract">arXiv:2403.03888</a> [<a href="/pdf/2403.03888" title="Download PDF">pdf</a>, <a href="/format/2403.03888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaaF: Facts as a Function for the evaluation of RAG systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katranidis%2C+V">Vasileios Katranidis</a>, 
<a href="/search/cs?searchtype=author&query=Barany%2C+G">Gabor Barany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Factual recall from a reference source is crucial for evaluating the
performance of Retrieval Augmented Generation (RAG) systems, as it directly
probes into the quality of both retrieval and generation. However, it still
remains a challenge to perform this evaluation reliably and efficiently. Recent
work has focused on fact verification via prompting language model (LM)
evaluators, however we demonstrate that these methods are unreliable in the
presence of incomplete or inaccurate information. We introduce Facts as a
Function (FaaF), a new approach to fact verification that utilizes the function
calling abilities of LMs and a framework for RAG factual recall evaluation.
FaaF substantially improves the ability of LMs to identify unsupported facts in
text with incomplete information whilst improving efficiency and lowering cost
by several times, compared to prompt-based approaches.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03890" title="Abstract">arXiv:2403.03890</a> [<a href="/pdf/2403.03890" title="Download PDF">pdf</a>, <a href="/format/2403.03890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Patidar%2C+S">Sumit Patidar</a>, 
<a href="/search/cs?searchtype=author&query=Haughton%2C+I">Iain Haughton</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Stephen James</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2024). Videos and code: <a href="https://yusufma03.github.io/projects/hdp/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces Hierarchical Diffusion Policy (HDP), a hierarchical
agent for multi-task robotic manipulation. HDP factorises a manipulation policy
into a hierarchical structure: a high-level task-planning agent which predicts
a distant next-best end-effector pose (NBP), and a low-level goal-conditioned
diffusion policy which generates optimal motion trajectories. The factorised
policy representation allows HDP to tackle both long-horizon task planning
while generating fine-grained low-level actions. To generate context-aware
motion trajectories while satisfying robot kinematics constraints, we present a
novel kinematics-aware goal-conditioned control agent, Robot Kinematics
Diffuser (RK-Diffuser). Specifically, RK-Diffuser learns to generate both the
end-effector pose and joint position trajectories, and distill the accurate but
kinematics-unaware end-effector pose diffuser to the kinematics-aware but less
accurate joint position diffuser via differentiable kinematics. Empirically, we
show that HDP achieves a significantly higher success rate than the
state-of-the-art methods in both simulation and real-world.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03893" title="Abstract">arXiv:2403.03893</a> [<a href="/pdf/2403.03893" title="Download PDF">pdf</a>, <a href="/format/2403.03893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From One to Many: Expanding the Scope of Toxicity Mitigation in Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pozzobon%2C+L">Luiza Pozzobon</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+P">Patrick Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Ermis%2C+B">Beyza Ermis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">To date, toxicity mitigation in language models has almost entirely been
focused on single-language settings. As language models embrace multilingual
capabilities, it's crucial our safety measures keep pace. Recognizing this
research gap, our approach expands the scope of conventional toxicity
mitigation to address the complexities presented by multiple languages. In the
absence of sufficient annotated datasets across languages, we employ translated
data to evaluate and enhance our mitigation techniques. We also compare
finetuning mitigation approaches against retrieval-augmented techniques under
both static and continual toxicity mitigation scenarios. This allows us to
examine the effects of translation quality and the cross-lingual transfer on
toxicity mitigation. We also explore how model size and data quantity affect
the success of these mitigation efforts. Covering nine languages, our study
represents a broad array of linguistic families and levels of resource
availability, ranging from high to mid-resource languages. Through
comprehensive experiments, we provide insights into the complexities of
multilingual toxicity mitigation, offering valuable insights and paving the way
for future research in this increasingly important field. Code and data are
available at https://github.com/for-ai/goodtriever.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03894" title="Abstract">arXiv:2403.03894</a> [<a href="/pdf/2403.03894" title="Download PDF">pdf</a>, <a href="/format/2403.03894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRCoder: Intermediate Representations Make Language Models Robust  Multilingual Code Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+I">Indraneil Paul</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Glava%C5%A1%2C+G">Goran Glava&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">Code understanding and generation have fast become some of the most popular
applications of language models (LMs). Nonetheless, research on multilingual
aspects of Code-LMs (i.e., LMs for code generation) such as cross-lingual
transfer between different programming languages, language-specific data
augmentation, and post-hoc LM adaptation, alongside exploitation of data
sources other than the original textual content, has been much sparser than for
their natural language counterparts. In particular, most mainstream Code-LMs
have been pre-trained on source code files alone. In this work, we investigate
the prospect of leveraging readily available compiler intermediate
representations - shared across programming languages - to improve the
multilingual capabilities of Code-LMs and facilitate cross-lingual transfer.
<br />To this end, we first compile SLTrans, a parallel dataset consisting of
nearly 4M self-contained source code files coupled with respective intermediate
representations. Next, starting from various base Code-LMs (ranging in size
from 1.1B to 7.3B parameters), we carry out continued causal language modelling
training on SLTrans, forcing the Code-LMs to (1) learn the IR language and (2)
align the IR constructs with respective constructs of various programming
languages. Our resulting models, dubbed IRCoder, display sizeable and
consistent gains across a wide variety of code generation tasks and metrics,
including prompt robustness, multilingual code completion, code understanding,
and instruction following.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03895" title="Abstract">arXiv:2403.03895</a> [<a href="/pdf/2403.03895" title="Download PDF">pdf</a>, <a href="/format/2403.03895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Lanczos Tau Framework for Time-Delay Systems: Pad&#xe9; Approximation  and Collocation Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Provoost%2C+E">Evert Provoost</a>, 
<a href="/search/math?searchtype=author&query=Michiels%2C+W">Wim Michiels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We reformulate the Lanczos tau method for the discretization of time-delay
systems in terms of a pencil of operators, allowing for new insights into this
approach. As a first main result, we show that, for the choice of a shifted
Legendre basis, this method is equivalent to Pad\'e approximation in the
frequency domain. We illustrate that Lanczos tau methods straightforwardly give
rise to sparse, self nesting discretizations. Equivalence is also demonstrated
with pseudospectral collocation, where the non-zero collocation points are
chosen as the zeroes of orthogonal polynomials. The importance of such a choice
manifests itself in the approximation of the $H^2$-norm, where, under mild
conditions, super-geometric convergence is observed and, for a special case,
super convergence is proved; both significantly faster than the algebraic
convergence reported in previous work.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03896" title="Abstract">arXiv:2403.03896</a> [<a href="/pdf/2403.03896" title="Download PDF">pdf</a>, <a href="/format/2403.03896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DART: Implicit Doppler Tomography for Radar Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianshu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+J">John Miller</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakara%2C+A">Akarsh Prabhakara</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Tao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Laroia%2C+T">Tarana Laroia</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+Z">Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Rowe%2C+A">Anthony Rowe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CVPR 2024; see <a href="https://wiselabcmu.github.io/dart/">this https URL</a> for our project site
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Simulation is an invaluable tool for radio-frequency system designers that
enables rapid prototyping of various algorithms for imaging, target detection,
classification, and tracking. However, simulating realistic radar scans is a
challenging task that requires an accurate model of the scene, radio frequency
material properties, and a corresponding radar synthesis function. Rather than
specifying these models explicitly, we propose DART - Doppler Aided Radar
Tomography, a Neural Radiance Field-inspired method which uses radar-specific
physics to create a reflectance and transmittance-based rendering pipeline for
range-Doppler images. We then evaluate DART by constructing a custom data
collection platform and collecting a novel radar dataset together with accurate
position and instantaneous velocity measurements from lidar-based localization.
In comparison to state-of-the-art baselines, DART synthesizes superior radar
range-Doppler images from novel views across all datasets and additionally can
be used to generate high quality tomographic images.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03897" title="Abstract">arXiv:2403.03897</a> [<a href="/pdf/2403.03897" title="Download PDF">pdf</a>, <a href="/format/2403.03897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug  Unearthing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asmita">Asmita</a>, 
<a href="/search/cs?searchtype=author&query=Oliinyk%2C+Y">Yaroslav Oliinyk</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+M">Michael Scott</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+R">Ryan Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chongzhou Fang</a>, 
<a href="/search/cs?searchtype=author&query=Homayoun%2C+H">Houman Homayoun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">BusyBox, an open-source software bundling over 300 essential Linux commands
into a single executable, is ubiquitous in Linux-based embedded devices.
Vulnerabilities in BusyBox can have far-reaching consequences, affecting a wide
array of devices. This research, driven by the extensive use of BusyBox, delved
into its analysis. The study revealed the prevalence of older BusyBox versions
in real-world embedded products, prompting us to conduct fuzz testing on
BusyBox. Fuzzing, a pivotal software testing method, aims to induce crashes
that are subsequently scrutinized to uncover vulnerabilities. Within this
study, we introduce two techniques to fortify software testing. The first
technique enhances fuzzing by leveraging Large Language Models (LLM) to
generate target-specific initial seeds. Our study showed a substantial increase
in crashes when using LLM-generated initial seeds, highlighting the potential
of LLM to efficiently tackle the typically labor-intensive task of generating
target-specific initial seeds. The second technique involves repurposing
previously acquired crash data from similar fuzzed targets before initiating
fuzzing on a new target. This approach streamlines the time-consuming fuzz
testing process by providing crash data directly to the new target before
commencing fuzzing. We successfully identified crashes in the latest BusyBox
target without conducting traditional fuzzing, emphasizing the effectiveness of
LLM and crash reuse techniques in enhancing software testing and improving
vulnerability detection in embedded systems. Additionally, manual triaging was
performed to identify the nature of crashes in the latest BusyBox.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03898" title="Abstract">arXiv:2403.03898</a> [<a href="/pdf/2403.03898" title="Download PDF">pdf</a>, <a href="/ps/2403.03898" title="Download PostScript">ps</a>, <a href="/format/2403.03898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electrical Load Forecasting Model Using Hybrid LSTM Neural Networks with  Online Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+N">Nan Lu</a>, 
<a href="/search/eess?searchtype=author&query=Ouyang%2C+Q">Quan Ouyang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+C">Changfu Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Accurate electrical load forecasting is of great importance for the efficient
operation and control of modern power systems. In this work, a hybrid long
short-term memory (LSTM)-based model with online correction is developed for
day-ahead electrical load forecasting. Firstly, four types of features are
extracted from the original electrical load dataset, including the historical
time series, time index features, historical statistical features, and
similarity features. Then, a hybrid LSTM-based electrical load forecasting
model is designed, where an LSTM neural network block and a fully-connected
neural network block are integrated that can model both temporal features
(historical time series) and non-temporal features (the rest features). A
gradient regularization-based offline training algorithm and an output layer
parameter fine-tuning-based online model correction method are developed to
enhance the model's capabilities to defend against disturbance and adapt to the
latest load data distribution, thus improving the forecasting accuracy. At
last, extensive experiments are carried out to validate the effectiveness of
the proposed electrical load forecasting strategy with superior accuracy
compared with commonly used forecasting models.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03900" title="Abstract">arXiv:2403.03900</a> [<a href="/pdf/2403.03900" title="Download PDF">pdf</a>, <a href="/format/2403.03900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mamba4Rec: Towards Efficient Sequential Recommendation with Selective  State Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengkai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanzhou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Caverlee%2C+J">James Caverlee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommendation aims to estimate the dynamic user preferences and
sequential dependencies among historical user behaviors. Although
Transformer-based models have proven to be effective for sequential
recommendation, they suffer from the inference inefficiency problem stemming
from the quadratic computational complexity of attention operators, especially
for long-range behavior sequences. Inspired by the recent success of state
space models (SSMs), we propose Mamba4Rec, which is the first work to explore
the potential of selective SSMs for efficient sequential recommendation. Built
upon the basic Mamba block which is a selective SSM with an efficient
hardware-aware parallel algorithm, we incorporate a series of sequential
modeling techniques to further promote the model performance and meanwhile
maintain the inference efficiency. Experiments on two public datasets
demonstrate that Mamba4Rec is able to well address the effectiveness-efficiency
dilemma, and defeat both RNN- and attention-based baselines in terms of both
effectiveness and efficiency.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03903" title="Abstract">arXiv:2403.03903</a> [<a href="/pdf/2403.03903" title="Download PDF">pdf</a>, <a href="/format/2403.03903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges of Processing Data Clumps within Plugin Architectures of  Integrated Development Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumgartner%2C+N">Nils Baumgartner</a>, 
<a href="/search/cs?searchtype=author&query=Pulverm%C3%BCller%2C+E">Elke Pulverm&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In this study, we explore advanced strategies for enhancing software quality
by detecting and refactoring data clumps, special types of code smells. Our
approach transcends the capabilities of integrated development environments,
utilizing a novel method that separates the detection of data clumps from the
source access. This method facilitates data clump processing. We introduce a
command-line interface plugin to support this novel method of processing data
clumps. This research highlights the efficacy of modularized algorithms and
advocates their integration into continuous workflows, promising enhanced code
quality and efficient project management across various programming and
integrated development environments.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03905" title="Abstract">arXiv:2403.03905</a> [<a href="/pdf/2403.03905" title="Download PDF">pdf</a>, <a href="/format/2403.03905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jambulapati%2C+A">Arun Jambulapati</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+S">Syamantak Kumar</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jerry Li</a>, 
<a href="/search/math?searchtype=author&query=Pandey%2C+S">Shourya Pandey</a>, 
<a href="/search/math?searchtype=author&query=Pensia%2C+A">Ankit Pensia</a>, 
<a href="/search/math?searchtype=author&query=Tian%2C+K">Kevin Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">The $k$-principal component analysis ($k$-PCA) problem is a fundamental
algorithmic primitive that is widely-used in data analysis and dimensionality
reduction applications. In statistical settings, the goal of $k$-PCA is to
identify a top eigenspace of the covariance matrix of a distribution, which we
only have implicit access to via samples. Motivated by these implicit settings,
we analyze black-box deflation methods as a framework for designing $k$-PCA
algorithms, where we model access to the unknown target matrix via a black-box
$1$-PCA oracle which returns an approximate top eigenvector, under two popular
notions of approximation. Despite being arguably the most natural
reduction-based approach to $k$-PCA algorithm design, such black-box methods,
which recursively call a $1$-PCA oracle $k$ times, were previously
poorly-understood.
<br />Our main contribution is significantly sharper bounds on the approximation
parameter degradation of deflation methods for $k$-PCA. For a quadratic form
notion of approximation we term ePCA (energy PCA), we show deflation methods
suffer no parameter loss. For an alternative well-studied approximation notion
we term cPCA (correlation PCA), we tightly characterize the parameter regimes
where deflation methods are feasible. Moreover, we show that in all feasible
regimes, $k$-cPCA deflation algorithms suffer no asymptotic parameter loss for
any constant $k$. We apply our framework to obtain state-of-the-art $k$-PCA
algorithms robust to dataset contamination, improving prior work both in sample
complexity and approximation quality.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03906" title="Abstract">arXiv:2403.03906</a> [<a href="/pdf/2403.03906" title="Download PDF">pdf</a>, <a href="/format/2403.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On HTLC-Based Protocols for Multi-Party Cross-Chain Swaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+E">Emily Clark</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+C">Chloe Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+K">Katelyn Poon</a>, 
<a href="/search/cs?searchtype=author&query=Chrobak%2C+M">Marek Chrobak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In his 2018 paper, Herlihy introduced an atomic protocol for multi-party
asset swaps across different blockchains. His model represents an asset swap by
a directed graph whose nodes are the participating parties and edges represent
asset transfers, and rational behavior of the participants is captured by a
preference relation between a protocol's outcomes. Asset transfers between
parties are achieved using smart contracts. These smart contracts are quite
involved and they require storage and processing of a large number of paths in
the swap digraph, limiting practical significance of his protocol. His paper
also describes a different protocol that uses only standard hash time-lock
contracts (HTLC's), but this simpler protocol applies only to some special
types of digraphs. He left open the question whether there is a simple and
efficient protocol for cross-chain asset swaps in arbitrary digraphs. Motivated
by this open problem, we conducted a comprehensive study of \emph{HTLC-based
protocols}, in which all asset transfers are implemented with HTLCs. Our main
contribution is a full characterization of swap digraphs that have such
protocols.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03909" title="Abstract">arXiv:2403.03909</a> [<a href="/pdf/2403.03909" title="Download PDF">pdf</a>, <a href="/format/2403.03909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Measure for Transparent Comparison of Linguistic Diversity in  Multilingual NLP Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samardzic%2C+T">Tanja Samardzic</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+X">Ximena Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Bentz%2C+C">Christian Bentz</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Steven Moran</a>, 
<a href="/search/cs?searchtype=author&query=Pelloni%2C+O">Olga Pelloni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Typologically diverse benchmarks are increasingly created to track the
progress achieved in multilingual NLP. Linguistic diversity of these data sets
is typically measured as the number of languages or language families included
in the sample, but such measures do not consider structural properties of the
included languages. In this paper, we propose assessing linguistic diversity of
a data set against a reference language sample as a means of maximising
linguistic diversity in the long run. We represent languages as sets of
features and apply a version of the Jaccard index suitable for comparing sets
of measures. In addition to the features extracted from typological data bases,
we propose an automatic text-based measure, which can be used as a means of
overcoming the well-known problem of data sparsity in manually collected
features. Our diversity score is interpretable in terms of linguistic features
and can identify the types of languages that are not represented in a data set.
Using our method, we analyse a range of popular multilingual data sets (UD,
Bible100, mBERT, XTREME, XGLUE, XNLI, XCOPA, TyDiQA, XQuAD). In addition to
ranking these data sets, we find, for example, that (poly)synthetic languages
are missing in almost all of them.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03910" title="Abstract">arXiv:2403.03910</a> [<a href="/pdf/2403.03910" title="Download PDF">pdf</a>, <a href="/ps/2403.03910" title="Download PostScript">ps</a>, <a href="/format/2403.03910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Model for Active Battery Equalization Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ouyang%2C+Q">Quan Ouyang</a>, 
<a href="/search/eess?searchtype=author&query=Ghaeminezhad%2C+N">Nourallah Ghaeminezhad</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Wik%2C+T">Torsten Wik</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+C">Changfu Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Lithium-ion battery packs demand effective active equalization systems to
enhance their usable capacity and lifetime. Despite numerous topologies and
control schemes proposed in the literature, conducting quantitative analyses,
comprehensive comparisons, and systematic optimization of their performance
remains challenging due to the absence of a unified mathematical model at the
pack level. To address this gap, we introduce a novel, hypergraph-based
approach to establish the first unified model for various active battery
equalization systems. This model reveals the intrinsic relationship between
battery cells and equalizers by representing them as the vertices and
hyperedges of hypergraphs, respectively. With the developed model, we identify
the necessary condition for all equalization systems to achieve balance through
controllability analysis, offering valuable insights for selecting the number
of equalizers. Moreover, we prove that the battery equalization time is
inversely correlated with the second smallest eigenvalue of the hypergraph's
Laplacian matrix of each equalization system. This significantly simplifies the
selection and optimized design of equalization systems, obviating the need for
extensive experiments or simulations to derive the equalization time.
Illustrative results demonstrate the efficiency of the proposed model and
validate our findings.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03913" title="Abstract">arXiv:2403.03913</a> [<a href="/pdf/2403.03913" title="Download PDF">pdf</a>, <a href="/format/2403.03913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multipolar opinion evolution in biased networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bakovi%C4%87%2C+L">Luka Bakovi&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Ohlin%2C+D">David Ohlin</a>, 
<a href="/search/eess?searchtype=author&query=Como%2C+G">Giacomo Como</a>, 
<a href="/search/eess?searchtype=author&query=Tegling%2C+E">Emma Tegling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Motivated by empirical research on bias and opinion formation, we introduce a
novel multidimensional nonlinear opinion dynamical model where agents have
individual biases, which are fixed, as well as opinions, which evolve. The
dimensions are coupled through a normalization step, which is also the source
of the nonlinearity, so that the state describes an agent's relative opinion of
various options. This can capture, for example, an individual's relative trust
in different media. In special cases including where biases are uniform across
agents our model achieves consensus, but in general, behaviors are richer and
capture multipolar opinion distributions. We examine general fixed points of
the system, as well as special cases such as zero biases toward certain options
or partitioned decision sets. Lastly, we demonstrate that our model exhibits
polarization when biases are spatially correlated across the network, while, as
empirical research suggests, a mixed community can mediate biases.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03920" title="Abstract">arXiv:2403.03920</a> [<a href="/pdf/2403.03920" title="Download PDF">pdf</a>, <a href="/format/2403.03920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Instructional Quality: Leveraging Computer-Assisted Textual  Analysis to Generate In-Depth Insights from Educational Artifacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zewei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Alex Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Shawon Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper explores the transformative potential of computer-assisted textual
analysis in enhancing instructional quality through in-depth insights from
educational artifacts. We integrate Richard Elmore's Instructional Core
Framework to examine how artificial intelligence (AI) and machine learning (ML)
methods, particularly natural language processing (NLP), can analyze
educational content, teacher discourse, and student responses to foster
instructional improvement. Through a comprehensive review and case studies
within the Instructional Core Framework, we identify key areas where AI/ML
integration offers significant advantages, including teacher coaching, student
support, and content development. We unveil patterns that indicate AI/ML not
only streamlines administrative tasks but also introduces novel pathways for
personalized learning, providing actionable feedback for educators and
contributing to a richer understanding of instructional dynamics. This paper
emphasizes the importance of aligning AI/ML technologies with pedagogical goals
to realize their full potential in educational settings, advocating for a
balanced approach that considers ethical considerations, data quality, and the
integration of human expertise.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03923" title="Abstract">arXiv:2403.03923</a> [<a href="/pdf/2403.03923" title="Download PDF">pdf</a>, <a href="/format/2403.03923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Did Translation Models Get More Robust Without Anyone Even Noticing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peters%2C+B">Ben Peters</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+A+F+T">Andr&#xe9; F.T. Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural machine translation (MT) models achieve strong results across a
variety of settings, but it is widely believed that they are highly sensitive
to "noisy" inputs, such as spelling errors, abbreviations, and other formatting
issues. In this paper, we revisit this insight in light of recent multilingual
MT models and large language models (LLMs) applied to machine translation.
Somewhat surprisingly, we show through controlled experiments that these models
are far more robust to many kinds of noise than previous models, even when they
perform similarly on clean data. This is notable because, even though LLMs have
more parameters and more complex training processes than past models, none of
the open ones we consider use any techniques specifically designed to encourage
robustness. Next, we show that similar trends hold for social media translation
experiments -- LLMs are more robust to social media text. We include an
analysis of the circumstances in which source correction techniques can be used
to mitigate the effects of noise. Altogether, we show that robustness to many
types of noise has increased.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03929" title="Abstract">arXiv:2403.03929</a> [<a href="/pdf/2403.03929" title="Download PDF">pdf</a>, <a href="/format/2403.03929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extreme Precipitation Nowcasting using Transformer-based Generative  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meo%2C+C">Cristian Meo</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Ankush Roy</a>, 
<a href="/search/cs?searchtype=author&query=Lic%C4%83%2C+M">Mircea Lic&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junzhe Yin</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z+B">Zeineb Bou Che</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Imhoff%2C+R">Ruben Imhoff</a>, 
<a href="/search/cs?searchtype=author&query=Uijlenhoet%2C+R">Remko Uijlenhoet</a>, 
<a href="/search/cs?searchtype=author&query=Dauwels%2C+J">Justin Dauwels</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an innovative approach to extreme precipitation
nowcasting by employing Transformer-based generative models, namely
NowcastingGPT with Extreme Value Loss (EVL) regularization. Leveraging a
comprehensive dataset from the Royal Netherlands Meteorological Institute
(KNMI), our study focuses on predicting short-term precipitation with high
accuracy. We introduce a novel method for computing EVL without assuming fixed
extreme representations, addressing the limitations of current models in
capturing extreme weather events. We present both qualitative and quantitative
analyses, demonstrating the superior performance of the proposed
NowcastingGPT-EVL in generating accurate precipitation forecasts, especially
when dealing with extreme precipitation events. The code is available at
\url{https://github.com/Cmeo97/NowcastingGPT}.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03933" title="Abstract">arXiv:2403.03933</a> [<a href="/pdf/2403.03933" title="Download PDF">pdf</a>, <a href="/ps/2403.03933" title="Download PostScript">ps</a>, <a href="/format/2403.03933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Calculus sizes over the Boolean and Fourier bases are  incomparable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mouli%2C+S">Sasank Mouli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic (math.LO)

</div>
<p class="mathjax">For every $n &gt;0$, we show the existence of a CNF tautology over $O(n^2)$
variables of width $O(\log n)$ such that it has a Polynomial Calculus
Resolution refutation over $\{0,1\}$ variables of size $O(n^3polylog(n))$ but
any Polynomial Calculus refutation over $\{+1,-1\}$ variables requires size
$2^{\Omega(n)}$. This shows that Polynomial Calculus sizes over the $\{0,1\}$
and $\{+1,-1\}$ bases are incomparable (since Tseitin tautologies show a
separation in the other direction) and answers an open problem posed by Sokolov
[Sok20] and Razborov.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03934" title="Abstract">arXiv:2403.03934</a> [<a href="/pdf/2403.03934" title="Download PDF">pdf</a>, <a href="/format/2403.03934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Categorical Treatment of Open Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+D">Dario Stein</a>, 
<a href="/search/cs?searchtype=author&query=Samuelson%2C+R">Richard Samuelson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Probability (math.PR)

</div>
<p class="mathjax">An open stochastic system \`a la Willems is a system affected two
qualitatively different kinds of uncertainty -- one is probabilistic
fluctuation, and the other one is nondeterminism caused by lack of information.
We give a formalization of open stochastic systems in the language of category
theory. A new construction, which we term copartiality, is needed to model the
propagating lack of information (which corresponds to varying sigma-algebras).
<br />As a concrete example, we discuss extended Gaussian distributions, which
combine Gaussian probability with nondeterminism and correspond precisely to
Willems' notion of Gaussian linear systems. We describe them both as
measure-theoretic and abstract categorical entities, which enables us to
rigorously describe a variety of phenomena like noisy physical laws and
uninformative priors in Bayesian statistics. The category of extended Gaussian
maps can be seen as a mutual generalization of Gaussian probability and linear
relations, which connects the literature on categorical probability with ideas
from control theory like signal-flow diagrams.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03935" title="Abstract">arXiv:2403.03935</a> [<a href="/pdf/2403.03935" title="Download PDF">pdf</a>, <a href="/ps/2403.03935" title="Download PostScript">ps</a>, <a href="/format/2403.03935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demographic Dynamics and Artificial Intelligence: Challenges and  Opportunities in Europe and Africa for 2050
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louadi%2C+M+E">Mohamed El Louadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has not been peer reviewed yet
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper explores the complex relationship between demographics and
artificial intelligence (AI) advances in Europe and Africa, projecting into the
year 2050. The advancement of AI technologies has occurred at diverse rates,
with Africa lagging behind Europe. Moreover, the imminent economic consequences
of demographic shifts require a more careful examination of immigration
patterns, with Africa emerging as a viable labor pool for European countries.
However, within these dynamics, questions are raised about the differences in
AI proficiency between African immigrants and Europeans by 2050. This paper
examines demographic trends and AI developments to unravel insights into the
multifaceted challenges and opportunities that lie ahead in the realms of
technology, the economy, and society as we look ahead to 2050.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03937" title="Abstract">arXiv:2403.03937</a> [<a href="/pdf/2403.03937" title="Download PDF">pdf</a>, <a href="/ps/2403.03937" title="Download PostScript">ps</a>, <a href="/format/2403.03937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Settling the Competition Complexity of Additive Buyers over Independent  Items
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derakhshan%2C+M">Mahsa Derakhshan</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+E">Emily Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Weinberg%2C+S+M">S. Matthew Weinberg</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+E">Eric Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The competition complexity of an auction setting is the number of additional
bidders needed such that the simple mechanism of selling items separately (with
additional bidders) achieves greater revenue than the optimal but complex
(randomized, prior-dependent, Bayesian-truthful) optimal mechanism without the
additional bidders. Our main result settles the competition complexity of $n$
bidders with additive values over $m &lt; n$ independent items at
$\Theta(\sqrt{nm})$. The $O(\sqrt{nm})$ upper bound is due to [BW19], and our
main result improves the prior lower bound of $\Omega(\ln n)$ to
$\Omega(\sqrt{nm})$.
<br />Our main result follows from an explicit construction of a Bayesian IC
auction for $n$ bidders with additive values over $m&lt;n$ independent items drawn
from the Equal Revenue curve truncated at $\sqrt{nm}$ ($\mathcal{ER}_{\le
\sqrt{nm}}$), which achieves revenue that exceeds
$\text{SRev}_{n+\sqrt{nm}}(\mathcal{ER}_{\le \sqrt{nm}}^m)$.
<br />Along the way, we show that the competition complexity of $n$ bidders with
additive values over $m$ independent items is exactly equal to the minimum $c$
such that $\text{SRev}_{n+c}(\mathcal{ER}_{\le p}^m) \geq
\text{Rev}_n(\mathcal{ER}_{\le p}^m)$ for all $p$ (that is, some truncated
Equal Revenue witnesses the worst-case competition complexity). Interestingly,
we also show that the untruncated Equal Revenue curve does not witness the
worst-case competition complexity when $n &gt; m$: $\text{SRev}_n(\mathcal{ER}^m)
= nm+O_m(\ln (n)) \leq \text{SRev}_{n+O_m(\ln (n))}(\mathcal{ER}^m)$, and
therefore our result can only follow by considering all possible truncations.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03938" title="Abstract">arXiv:2403.03938</a> [<a href="/pdf/2403.03938" title="Download PDF">pdf</a>, <a href="/format/2403.03938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GUIDE: Guidance-based Incremental Learning with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cywi%C5%84ski%2C+B">Bartosz Cywi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Deja%2C+K">Kamil Deja</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>, 
<a href="/search/cs?searchtype=author&query=Kuci%C5%84ski%2C+%C5%81">&#x141;ukasz Kuci&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce GUIDE, a novel continual learning approach that directs
diffusion models to rehearse samples at risk of being forgotten. Existing
generative strategies combat catastrophic forgetting by randomly sampling
rehearsal examples from a generative model. Such an approach contradicts
buffer-based approaches where sampling strategy plays an important role. We
propose to bridge this gap by integrating diffusion models with classifier
guidance techniques to produce rehearsal examples specifically targeting
information forgotten by a continuously trained model. This approach enables
the generation of samples from preceding task distributions, which are more
likely to be misclassified in the context of recently encountered classes. Our
experimental results show that GUIDE significantly reduces catastrophic
forgetting, outperforming conventional random sampling approaches and
surpassing recent state-of-the-art methods in continual learning with
generative replay.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03942" title="Abstract">arXiv:2403.03942</a> [<a href="/pdf/2403.03942" title="Download PDF">pdf</a>, <a href="/format/2403.03942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Heuristic Core: Understanding Subnetwork Generalization in  Pretrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhaskar%2C+A">Adithya Bhaskar</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+D">Dan Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at <a href="https://github.com/princeton-nlp/Heuristic-Core">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Prior work has found that pretrained language models (LMs) fine-tuned with
different random seeds can achieve similar in-domain performance but generalize
differently on tests of syntactic generalization. In this work, we show that,
even within a single model, we can find multiple subnetworks that perform
similarly in-domain, but generalize vastly differently. To better understand
these phenomena, we investigate if they can be understood in terms of
"competing subnetworks": the model initially represents a variety of distinct
algorithms, corresponding to different subnetworks, and generalization occurs
when it ultimately converges to one. This explanation has been used to account
for generalization in simple algorithmic tasks. Instead of finding competing
subnetworks, we find that all subnetworks -- whether they generalize or not --
share a set of attention heads, which we refer to as the heuristic core.
Further analysis suggests that these attention heads emerge early in training
and compute shallow, non-generalizing features. The model learns to generalize
by incorporating additional attention heads, which depend on the outputs of the
"heuristic" heads to compute higher-level features. Overall, our results offer
a more detailed picture of the mechanisms for syntactic generalization in
pretrained LMs.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03945" title="Abstract">arXiv:2403.03945</a> [<a href="/pdf/2403.03945" title="Download PDF">pdf</a>, <a href="/format/2403.03945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEAR:Exact Gradient Inversion of Batches in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D+I">Dimitar I. Dimitrov</a>, 
<a href="/search/cs?searchtype=author&query=Baader%2C+M">Maximilian Baader</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M+N">Mark Niklas M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning is a popular framework for collaborative machine learning
where multiple clients only share gradient updates on their local data with the
server and not the actual data. Unfortunately, it was recently shown that
gradient inversion attacks can reconstruct this data from these shared
gradients. Existing attacks enable exact reconstruction only for a batch size
of $b=1$ in the important honest-but-curious setting, with larger batches
permitting only approximate reconstruction. In this work, we propose \emph{the
first algorithm reconstructing whole batches with $b &gt;1$ exactly}. This
approach combines mathematical insights into the explicit low-rank structure of
gradients with a sampling-based algorithm. Crucially, we leverage ReLU-induced
gradient sparsity to precisely filter out large numbers of incorrect samples,
making a final reconstruction step tractable. We provide an efficient GPU
implementation for fully connected networks and show that it recovers batches
of $b \lesssim 25$ elements exactly while being tractable for large network
widths and depths.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03947" title="Abstract">arXiv:2403.03947</a> [<a href="/pdf/2403.03947" title="Download PDF">pdf</a>, <a href="/format/2403.03947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Audio Reveal Music Performance Difficulty? Insights from the Piano  Syllabus Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramoneda%2C+P">Pedro Ramoneda</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minhee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+D">Dasaem Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Valero-Mas%2C+J+J">J.J. Valero-Mas</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+X">Xavier Serra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automatically estimating the performance difficulty of a music piece
represents a key process in music education to create tailored curricula
according to the individual needs of the students. Given its relevance, the
Music Information Retrieval (MIR) field depicts some proof-of-concept works
addressing this task that mainly focuses on high-level music abstractions such
as machine-readable scores or music sheet images. In this regard, the potential
of directly analyzing audio recordings has been generally neglected, which
prevents students from exploring diverse music pieces that may not have a
formal symbolic-level transcription. This work pioneers in the automatic
estimation of performance difficulty of music pieces on audio recordings with
two precise contributions: (i) the first audio-based difficulty estimation
dataset -- namely, Piano Syllabus (PSyllabus) dataset -- featuring 7,901 piano
pieces across 11 difficulty levels from 1,233 composers; and (ii) a recognition
framework capable of managing different input representations -- both unimodal
and multimodal manners -- directly derived from audio to perform the difficulty
estimation task. The comprehensive experimentation comprising different
pre-training schemes, input modalities, and multi-task scenarios prove the
validity of the proposal and establishes PSyllabus as a reference dataset for
audio-based difficulty estimation in the MIR field. The dataset as well as the
developed code and trained models are publicly shared to promote further
research in the field.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03949" title="Abstract">arXiv:2403.03949</a> [<a href="/pdf/2403.03949" title="Download PDF">pdf</a>, <a href="/format/2403.03949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach  for Robust Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torne%2C+M">Marcel Torne</a>, 
<a href="/search/cs?searchtype=author&query=Simeonov%2C+A">Anthony Simeonov</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zechu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">April Chan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://real-to-sim-to-real.github.io/RialTo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning methods need significant human supervision to learn
policies robust to changes in object poses, physical disturbances, and visual
distractors. Reinforcement learning, on the other hand, can explore the
environment autonomously to learn robust behaviors but may require impractical
amounts of unsafe real-world data collection. To learn performant, robust
policies without the burden of unsafe real-world data collection or extensive
human supervision, we propose RialTo, a system for robustifying real-world
imitation learning policies via reinforcement learning in "digital twin"
simulation environments constructed on the fly from small amounts of real-world
data. To enable this real-to-sim-to-real pipeline, RialTo proposes an
easy-to-use interface for quickly scanning and constructing digital twins of
real-world environments. We also introduce a novel "inverse distillation"
procedure for bringing real-world demonstrations into simulated environments
for efficient fine-tuning, with minimal human intervention and engineering
required. We evaluate RialTo across a variety of robotic manipulation problems
in the real world, such as robustly stacking dishes on a rack, placing books on
a shelf, and six other tasks. RialTo increases (over 67%) in policy robustness
without requiring extensive human data collection. Project website and videos
at https://real-to-sim-to-real.github.io/RialTo/
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03950" title="Abstract">arXiv:2403.03950</a> [<a href="/pdf/2403.03950" title="Download PDF">pdf</a>, <a href="/format/2403.03950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stop Regressing: Training Value Functions via Classification for  Scalable Deep RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farebrother%2C+J">Jesse Farebrother</a>, 
<a href="/search/cs?searchtype=author&query=Orbay%2C+J">Jordi Orbay</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Ta%C3%AFga%2C+A+A">Adrien Ali Ta&#xef;ga</a>, 
<a href="/search/cs?searchtype=author&query=Chebotar%2C+Y">Yevgen Chebotar</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Irpan%2C+A">Alex Irpan</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>, 
<a href="/search/cs?searchtype=author&query=Faust%2C+A">Aleksandra Faust</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aviral Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Value functions are a central component of deep reinforcement learning (RL).
These functions, parameterized by neural networks, are trained using a mean
squared error regression objective to match bootstrapped target values.
However, scaling value-based RL methods that use regression to large networks,
such as high-capacity Transformers, has proven challenging. This difficulty is
in stark contrast to supervised learning: by leveraging a cross-entropy
classification loss, supervised methods have scaled reliably to massive
networks. Observing this discrepancy, in this paper, we investigate whether the
scalability of deep RL can also be improved simply by using classification in
place of regression for training value functions. We demonstrate that value
functions trained with categorical cross-entropy significantly improves
performance and scalability in a variety of domains. These include: single-task
RL on Atari 2600 games with SoftMoEs, multi-task RL on Atari with large-scale
ResNets, robotic manipulation with Q-transformers, playing Chess without
search, and a language-agent Wordle task with high-capacity Transformers,
achieving state-of-the-art results on these domains. Through careful analysis,
we show that the benefits of categorical cross-entropy primarily stem from its
ability to mitigate issues inherent to value-based RL, such as noisy targets
and non-stationarity. Overall, we argue that a simple shift to training value
functions with categorical cross-entropy can yield substantial improvements in
the scalability of deep RL at little-to-no cost.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03952" title="Abstract">arXiv:2403.03952</a> [<a href="/pdf/2403.03952" title="Download PDF">pdf</a>, <a href="/format/2403.03952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Language and Items for Retrieval and Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yupeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhankui He</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+A">An Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiusi Chen</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper introduces BLaIR, a series of pretrained sentence embedding models
specialized for recommendation scenarios. BLaIR is trained to learn
correlations between item metadata and potential natural language context,
which is useful for retrieving and recommending items. To pretrain BLaIR, we
collect Amazon Reviews 2023, a new dataset comprising over 570 million reviews
and 48 million items from 33 categories, significantly expanding beyond the
scope of previous versions. We evaluate the generalization ability of BLaIR
across multiple domains and tasks, including a new task named complex product
search, referring to retrieving relevant items given long, complex natural
language contexts. Leveraging large language models like ChatGPT, we
correspondingly construct a semi-synthetic evaluation set, Amazon-C4. Empirical
results on the new task, as well as conventional retrieval and recommendation
tasks, demonstrate that BLaIR exhibit strong text and item representation
capacity. Our datasets, code, and checkpoints are available at:
https://github.com/hyp1231/AmazonReviews2023.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03954" title="Abstract">arXiv:2403.03954</a> [<a href="/pdf/2403.03954" title="Download PDF">pdf</a>, <a href="/format/2403.03954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Diffusion Policy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chenyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Muhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Videos, code, and data: <a href="https://3d-diffusion-policy.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning provides an efficient way to teach robots dexterous
skills; however, learning complex skills robustly and generalizablely usually
consumes large amounts of human demonstrations. To tackle this challenging
problem, we present 3D Diffusion Policy (DP3), a novel visual imitation
learning approach that incorporates the power of 3D visual representations into
diffusion policies, a class of conditional action generative models. The core
design of DP3 is the utilization of a compact 3D visual representation,
extracted from sparse point clouds with an efficient point encoder. In our
experiments involving 72 simulation tasks, DP3 successfully handles most tasks
with just 10 demonstrations and surpasses baselines with a 55.3% relative
improvement. In 4 real robot tasks, DP3 demonstrates precise control with a
high success rate of 85%, given only 40 demonstrations of each task, and shows
excellent generalization abilities in diverse aspects, including space,
viewpoint, appearance, and instance. Interestingly, in real robot experiments,
DP3 rarely violates safety requirements, in contrast to baseline methods which
frequently do, necessitating human intervention. Our extensive evaluation
highlights the critical importance of 3D representations in real-world robot
learning. Videos, code, and data are available on
https://3d-diffusion-policy.github.io .
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03956" title="Abstract">arXiv:2403.03956</a> [<a href="/pdf/2403.03956" title="Download PDF">pdf</a>, <a href="/format/2403.03956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backtracing: Retrieving the Cause of the Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R+E">Rose E. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wirawarn%2C+P">Pawan Wirawarn</a>, 
<a href="/search/cs?searchtype=author&query=Khattab%2C+O">Omar Khattab</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N">Noah Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Demszky%2C+D">Dorottya Demszky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/rosewang2008/backtracing">this https URL</a>; EACL 2024 Findings, Long Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Many online content portals allow users to ask questions to supplement their
understanding (e.g., of lectures). While information retrieval (IR) systems may
provide answers for such user queries, they do not directly assist content
creators -- such as lecturers who want to improve their content -- identify
segments that _caused_ a user to ask those questions. We introduce the task of
backtracing, in which systems retrieve the text segment that most likely caused
a user query. We formalize three real-world domains for which backtracing is
important in improving content delivery and communication: understanding the
cause of (a) student confusion in the Lecture domain, (b) reader curiosity in
the News Article domain, and (c) user emotion in the Conversation domain. We
evaluate the zero-shot performance of popular information retrieval methods and
language modeling methods, including bi-encoder, re-ranking and
likelihood-based methods and ChatGPT. While traditional IR systems retrieve
semantically relevant information (e.g., details on "projection matrices" for a
query "does projecting multiple times still lead to the same point?"), they
often miss the causally relevant context (e.g., the lecturer states "projecting
twice gets me the same answer as one projection"). Our results show that there
is room for improvement on backtracing and it requires new retrieval
approaches. We hope our benchmark serves to improve future retrieval systems
for backtracing, spawning systems that refine content generation and identify
linguistic triggers influencing user queries. Our code and data are
open-sourced: https://github.com/rosewang2008/backtracing.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu,  7 Mar 24</h3>
<dl>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03224" title="Abstract">arXiv:2403.03224</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.03224" title="Download PDF">pdf</a>, <a href="/format/2403.03224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tapiavala%2C+V">Vedant Tapiavala</a>, 
<a href="/search/physics?searchtype=author&query=Piesner%2C+J">Joshua Piesner</a>, 
<a href="/search/physics?searchtype=author&query=Barman%2C+S">Sourjyamoy Barman</a>, 
<a href="/search/physics?searchtype=author&query=Fu%2C+F">Feng Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Live performances of music are always charming, with the unpredictability of
improvisation due to the dynamic between musicians and interactions with the
audience. Jazz improvisation is a particularly noteworthy example for further
investigation from a theoretical perspective. Here, we introduce a novel
mathematical game theory model for jazz improvisation, providing a framework
for studying music theory and improvisational methodologies. We use
computational modeling, mainly reinforcement learning, to explore diverse
stochastic improvisational strategies and their paired performance on
improvisation. We find that the most effective strategy pair is a strategy that
reacts to the most recent payoff (Stepwise Changes) with a reinforcement
learning strategy limited to notes in the given chord (Chord-Following
Reinforcement Learning). Conversely, a strategy that reacts to the partner's
last note and attempts to harmonize with it (Harmony Prediction) strategy pair
yields the lowest non-control payoff and highest standard deviation, indicating
that picking notes based on immediate reactions to the partner player can yield
inconsistent outcomes. On average, the Chord-Following Reinforcement Learning
strategy demonstrates the highest mean payoff, while Harmony Prediction
exhibits the lowest. Our work lays the foundation for promising applications
beyond jazz: including the use of artificial intelligence (AI) models to
extract data from audio clips to refine musical reward systems, and training
machine learning (ML) models on existing jazz solos to further refine
strategies within the game.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03229" title="Abstract">arXiv:2403.03229</a> (cross-list from q-bio.TO) [<a href="/pdf/2403.03229" title="Download PDF">pdf</a>, <a href="/format/2403.03229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embracing Uncertainty Flexibility: Harnessing a Supervised Tree Kernel  to Empower Ensemble Modelling for 2D Echocardiography-Based Prediction of  Right Ventricular Volume
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bohoran%2C+T+A">Tuan A. Bohoran</a>, 
<a href="/search/q-bio?searchtype=author&query=Kampaktsis%2C+P+N">Polydoros N. Kampaktsis</a>, 
<a href="/search/q-bio?searchtype=author&query=McLaughlin%2C+L">Laura McLaughlin</a>, 
<a href="/search/q-bio?searchtype=author&query=Leb%2C+J">Jay Leb</a>, 
<a href="/search/q-bio?searchtype=author&query=McCann%2C+G+P">Gerry P. McCann</a>, 
<a href="/search/q-bio?searchtype=author&query=Giannakidis%2C+A">Archontis Giannakidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, ICMV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">The right ventricular (RV) function deterioration strongly predicts clinical
outcomes in numerous circumstances. To boost the clinical deployment of
ensemble regression methods that quantify RV volumes using tabular data from
the widely available two-dimensional echocardiography (2DE), we propose to
complement the volume predictions with uncertainty scores. To this end, we
employ an instance-based method which uses the learned tree structure to
identify the nearest training samples to a target instance and then uses a
number of distribution types to more flexibly model the output. The
probabilistic and point-prediction performances of the proposed framework are
evaluated on a relatively small-scale dataset, comprising 100 end-diastolic and
end-systolic RV volumes. The reference values for point performance were
obtained from MRI. The results demonstrate that our flexible approach yields
improved probabilistic and point performances over other state-of-the-art
methods. The appropriateness of the proposed framework is showcased by
providing exemplar cases. The estimated uncertainty embodies both aleatoric and
epistemic types. This work aligns with trustworthy artificial intelligence
since it can be used to enhance the decision-making process and reduce risks.
The feature importance scores of our framework can be exploited to reduce the
number of required 2DE views which could enhance the proposed pipeline's
clinical application.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03230" title="Abstract">arXiv:2403.03230</a> (cross-list from q-bio.NC) [<a href="/pdf/2403.03230" title="Download PDF">pdf</a>, <a href="/format/2403.03230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large language models surpass human experts in predicting neuroscience  results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Luo%2C+X">Xiaoliang Luo</a>, 
<a href="/search/q-bio?searchtype=author&query=Rechardt%2C+A">Akilles Rechardt</a>, 
<a href="/search/q-bio?searchtype=author&query=Sun%2C+G">Guangzhi Sun</a>, 
<a href="/search/q-bio?searchtype=author&query=Nejad%2C+K+K">Kevin K. Nejad</a>, 
<a href="/search/q-bio?searchtype=author&query=Y%C3%A1%C3%B1ez%2C+F">Felipe Y&#xe1;&#xf1;ez</a>, 
<a href="/search/q-bio?searchtype=author&query=Yilmaz%2C+B">Bati Yilmaz</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+K">Kangjoo Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Cohen%2C+A+O">Alexandra O. Cohen</a>, 
<a href="/search/q-bio?searchtype=author&query=Borghesani%2C+V">Valentina Borghesani</a>, 
<a href="/search/q-bio?searchtype=author&query=Pashkov%2C+A">Anton Pashkov</a>, 
<a href="/search/q-bio?searchtype=author&query=Marinazzo%2C+D">Daniele Marinazzo</a>, 
<a href="/search/q-bio?searchtype=author&query=Nicholas%2C+J">Jonathan Nicholas</a>, 
<a href="/search/q-bio?searchtype=author&query=Salatiello%2C+A">Alessandro Salatiello</a>, 
<a href="/search/q-bio?searchtype=author&query=Sucholutsky%2C+I">Ilia Sucholutsky</a>, 
<a href="/search/q-bio?searchtype=author&query=Minervini%2C+P">Pasquale Minervini</a>, 
<a href="/search/q-bio?searchtype=author&query=Razavi%2C+S">Sepehr Razavi</a>, 
<a href="/search/q-bio?searchtype=author&query=Rocca%2C+R">Roberta Rocca</a>, 
<a href="/search/q-bio?searchtype=author&query=Yusifov%2C+E">Elkhan Yusifov</a>, 
<a href="/search/q-bio?searchtype=author&query=Okalova%2C+T">Tereza Okalova</a>, 
<a href="/search/q-bio?searchtype=author&query=Gu%2C+N">Nianlong Gu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ferianc%2C+M">Martin Ferianc</a>, 
<a href="/search/q-bio?searchtype=author&query=Khona%2C+M">Mikail Khona</a>, 
<a href="/search/q-bio?searchtype=author&query=Patil%2C+K+R">Kaustubh R. Patil</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+P">Pui-Shee Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Mata%2C+R">Rui Mata</a>, 
<a href="/search/q-bio?searchtype=author&query=Myers%2C+N+E">Nicholas E. Myers</a>, 
<a href="/search/q-bio?searchtype=author&query=Bizley%2C+J+K">Jennifer K Bizley</a>, 
<a href="/search/q-bio?searchtype=author&query=Musslick%2C+S">Sebastian Musslick</a>, 
<a href="/search/q-bio?searchtype=author&query=Bilgin%2C+I+P">Isil Poyraz Bilgin</a>, 
<a href="/search/q-bio?searchtype=author&query=Niso%2C+G">Guiomar Niso</a>, 
<a href="/search/q-bio?searchtype=author&query=Ales%2C+J+M">Justin M. Ales</a>, 
<a href="/search/q-bio?searchtype=author&query=Gaebler%2C+M">Michael Gaebler</a>, 
<a href="/search/q-bio?searchtype=author&query=Murty%2C+N+A+R">N Apurva Ratan Murty</a>, 
<a href="/search/q-bio?searchtype=author&query=Hall%2C+C+M">Chloe M. Hall</a>, 
<a href="/search/q-bio?searchtype=author&query=Dafflon%2C+J">Jessica Dafflon</a>, 
<a href="/search/q-bio?searchtype=author&query=Bao%2C+S+D">Sherry Dongqi Bao</a>, 
<a href="/search/q-bio?searchtype=author&query=Love%2C+B+C">Bradley C. Love</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Scientific discoveries often hinge on synthesizing decades of research, a
task that potentially outstrips human information processing capacities. Large
language models (LLMs) offer a solution. LLMs trained on the vast scientific
literature could potentially integrate noisy yet interrelated findings to
forecast novel results better than human experts. To evaluate this possibility,
we created BrainBench, a forward-looking benchmark for predicting neuroscience
results. We find that LLMs surpass experts in predicting experimental outcomes.
BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet.
Like human experts, when LLMs were confident in their predictions, they were
more likely to be correct, which presages a future where humans and LLMs team
together to make discoveries. Our approach is not neuroscience-specific and is
transferable to other knowledge-intensive endeavors.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03231" title="Abstract">arXiv:2403.03231</a> (cross-list from q-bio.GN) [<a href="/pdf/2403.03231" title="Download PDF">pdf</a>, <a href="/ps/2403.03231" title="Download PostScript">ps</a>, <a href="/format/2403.03231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine and deep learning methods for predicting 3D genome organization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wall%2C+B+P+G">Brydon P. G. Wall</a>, 
<a href="/search/q-bio?searchtype=author&query=Nguyen%2C+M">My Nguyen</a>, 
<a href="/search/q-bio?searchtype=author&query=Harrell%2C+J+C">J. Chuck Harrell</a>, 
<a href="/search/q-bio?searchtype=author&query=Dozmorov%2C+M+G">Mikhail G. Dozmorov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Systematic review, one figure, three tables, 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Three-Dimensional (3D) chromatin interactions, such as enhancer-promoter
interactions (EPIs), loops, Topologically Associating Domains (TADs), and A/B
compartments play critical roles in a wide range of cellular processes by
regulating gene expression. Recent development of chromatin conformation
capture technologies has enabled genome-wide profiling of various 3D
structures, even with single cells. However, current catalogs of 3D structures
remain incomplete and unreliable due to differences in technology, tools, and
low data resolution. Machine learning methods have emerged as an alternative to
obtain missing 3D interactions and/or improve resolution. Such methods
frequently use genome annotation data (ChIP-seq, DNAse-seq, etc.), DNA
sequencing information (k-mers, Transcription Factor Binding Site (TFBS)
motifs), and other genomic properties to learn the associations between genomic
features and chromatin interactions. In this review, we discuss computational
tools for predicting three types of 3D interactions (EPIs, chromatin
interactions, TAD boundaries) and analyze their pros and cons. We also point
out obstacles of computational prediction of 3D interactions and suggest future
research directions.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03233" title="Abstract">arXiv:2403.03233</a> (cross-list from stat.ML) [<a href="/pdf/2403.03233" title="Download PDF">pdf</a>, <a href="/format/2403.03233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Displacements to Distributions: A Machine-Learning Enabled  Framework for Quantifying Uncertainties in Parameters of Computational Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Roper%2C+T">Taylor Roper</a>, 
<a href="/search/stat?searchtype=author&query=Hakula%2C+H">Harri Hakula</a>, 
<a href="/search/stat?searchtype=author&query=Butler%2C+T">Troy Butler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work presents novel extensions for combining two frameworks for
quantifying both aleatoric (i.e., irreducible) and epistemic (i.e., reducible)
sources of uncertainties in the modeling of engineered systems. The
data-consistent (DC) framework poses an inverse problem and solution for
quantifying aleatoric uncertainties in terms of pullback and push-forward
measures for a given Quantity of Interest (QoI) map. Unfortunately, a
pre-specified QoI map is not always available a priori to the collection of
data associated with system outputs. The data themselves are often polluted
with measurement errors (i.e., epistemic uncertainties), which complicates the
process of specifying a useful QoI. The Learning Uncertain Quantities (LUQ)
framework defines a formal three-step machine-learning enabled process for
transforming noisy datasets into samples of a learned QoI map to enable
DC-based inversion. We develop a robust filtering step in LUQ that can learn
the most useful quantitative information present in spatio-temporal datasets.
The learned QoI map transforms simulated and observed datasets into
distributions to perform DC-based inversion. We also develop a DC-based
inversion scheme that iterates over time as new spatial datasets are obtained
and utilizes quantitative diagnostics to identify both the quality and impact
of inversion at each iteration. Reproducing Kernel Hilbert Space theory is
leveraged to mathematically analyze the learned QoI map and develop a
quantitative sufficiency test for evaluating the filtered data. An illustrative
example is utilized throughout while the final two examples involve the
manufacturing of shells of revolution to demonstrate various aspects of the
presented frameworks.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03234" title="Abstract">arXiv:2403.03234</a> (cross-list from q-bio.GN) [<a href="/pdf/2403.03234" title="Download PDF">pdf</a>, <a href="/format/2403.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Schiff%2C+Y">Yair Schiff</a>, 
<a href="/search/q-bio?searchtype=author&query=Kao%2C+C">Chia-Hsiang Kao</a>, 
<a href="/search/q-bio?searchtype=author&query=Gokaslan%2C+A">Aaron Gokaslan</a>, 
<a href="/search/q-bio?searchtype=author&query=Dao%2C+T">Tri Dao</a>, 
<a href="/search/q-bio?searchtype=author&query=Gu%2C+A">Albert Gu</a>, 
<a href="/search/q-bio?searchtype=author&query=Kuleshov%2C+V">Volodymyr Kuleshov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code to reproduce our experiments is available at <a href="https://github.com/kuleshov-group/caduceus">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale sequence modeling has sparked rapid advances that now extend into
biology and genomics. However, modeling genomic sequences introduces challenges
such as the need to model long-range token interactions, the effects of
upstream and downstream regions of the genome, and the reverse complementarity
(RC) of DNA. Here, we propose an architecture motivated by these challenges
that builds off the long-range Mamba block, and extends it to a BiMamba
component that supports bi-directionality, and to a MambaDNA block that
additionally supports RC equivariance. We use MambaDNA as the basis of
Caduceus, the first family of RC equivariant bi-directional long-range DNA
language models, and we introduce pre-training and fine-tuning strategies that
yield Caduceus DNA foundation models. Caduceus outperforms previous long-range
models on downstream benchmarks; on a challenging long-range variant effect
prediction task, Caduceus exceeds the performance of 10x larger models that do
not leverage bi-directionality or equivariance.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03237" title="Abstract">arXiv:2403.03237</a> (cross-list from quant-ph) [<a href="/pdf/2403.03237" title="Download PDF">pdf</a>, <a href="/format/2403.03237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiency of k-Local Quantum Search and its Adiabatic Variant on Random  k-SAT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+M">Mingyou Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">The computational complexity of random $k$-SAT problem is contingent on the
clause number $m$. In classical computing, a satisfiability threshold is
identified at $m=r_k n$, marking the transition of random $k$-SAT from
solubility to insolubility. However, beyond this established threshold,
comprehending the complexity remains challenging. On quantum computers, direct
application of Grover's unstructured quantum search still yields exponential
time requirements due to oversight of structural information. This paper
introduces a family of structured quantum search algorithms, termed $k$-local
quantum search, designed to address the $k$-SAT problem. Because search
algorithm necessitates the presence of a target, our focus is specifically on
the satisfiable side of $k$-SAT, i.e., max-$k$-SAT on satisfiable instances,
denoted as max-$k$-SSAT, with a small $k \ge 3$. For random instances with
$m=\Omega(n^{2+\epsilon})$, general exponential acceleration is proven for any
small $\epsilon&gt;0$ and sufficiently large $n$. Furthermore, adiabatic $k$-local
quantum search improves the bound of general efficiency to
$m=\Omega(n^{1+\epsilon})$, within an evolution time of $\mathcal{O}(n^2)$.
Specifically, for $m=\Theta(n^{1+\delta+\epsilon})$, the efficiency is
guaranteed in a probability of $1-\mathcal{O}(\mathrm{erfc}(n^{\delta/2}))$. By
modifying this algorithm capable of solving all instances, we prove that the
max-$k$-SSAT is polynomial on average if $m=\Omega(n^{2+\epsilon})$ based on
the average-case complexity theory.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03239" title="Abstract">arXiv:2403.03239</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.03239" title="Download PDF">pdf</a>, <a href="/ps/2403.03239" title="Download PostScript">ps</a>, <a href="/format/2403.03239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon  Resonance, in the Context of Brewster&#x27;s Angle and the Drude Model for Fake  News Adsorption in Incomplete Information Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tellurium Nanoparticles, Snell's Law, Soliton Solution, Anamorphic Surfaces, Nonlinear Dynamics, Fake News Adsorption, User Behavior Modeling, Health Improvement Strategies, Plasmonic Sensors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This note explores the innovative application of soliton theory and plasmonic
phenomena in modeling user behavior and engagement within digital health
platforms. By introducing the concept of soliton solutions, we present a novel
approach to understanding stable patterns of health improvement behaviors over
time. Additionally, we delve into the role of tellurium nanoparticles and their
plasmonic properties in adsorbing fake news, thereby influencing user
interactions and engagement levels. Through a theoretical framework that
combines nonlinear dynamics with the unique characteristics of tellurium
nanoparticles, we aim to provide new insights into the dynamics of user
engagement in digital health environments. Our analysis highlights the
potential of soliton theory in capturing the complex, nonlinear dynamics of
user behavior, while the application of plasmonic phenomena offers a promising
avenue for enhancing the sensitivity and effectiveness of digital health
platforms. This research ventures into an uncharted territory where optical
phenomena such as Brewster's Angle and Snell's Law, along with the concept of
spin solitons, are metaphorically applied to address the challenge of fake news
dissemination. By exploring the analogy between light refraction, reflection,
and the propagation of information in digital platforms, we unveil a novel
perspective on how the 'angle' at which information is presented can
significantly affect its acceptance and spread. Additionally, we propose the
use of tellurium nanoparticles to manage 'information waves' through mechanisms
akin to plasmonic resonance and soliton dynamics. This theoretical exploration
aims to bridge the gap between physical sciences and digital communication,
offering insights into the development of strategies for mitigating
misinformation.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03240" title="Abstract">arXiv:2403.03240</a> (cross-list from stat.ME) [<a href="/pdf/2403.03240" title="Download PDF">pdf</a>, <a href="/ps/2403.03240" title="Download PostScript">ps</a>, <a href="/format/2403.03240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triple/Debiased Lasso for Statistical Inference of Conditional Average  Treatment Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kato%2C+M">Masahiro Kato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
<p class="mathjax">This study investigates the estimation and the statistical inference about
Conditional Average Treatment Effects (CATEs), which have garnered attention as
a metric representing individualized causal effects. In our data-generating
process, we assume linear models for the outcomes associated with binary
treatments and define the CATE as a difference between the expected outcomes of
these linear models. This study allows the linear models to be
high-dimensional, and our interest lies in consistent estimation and
statistical inference for the CATE. In high-dimensional linear regression, one
typical approach is to assume sparsity. However, in our study, we do not assume
sparsity directly. Instead, we consider sparsity only in the difference of the
linear models. We first use a doubly robust estimator to approximate this
difference and then regress the difference on covariates with Lasso
regularization. Although this regression estimator is consistent for the CATE,
we further reduce the bias using the techniques in double/debiased machine
learning (DML) and debiased Lasso, leading to $\sqrt{n}$-consistency and
confidence intervals. We refer to the debiased estimator as the triple/debiased
Lasso (TDL), applying both DML and debiased Lasso techniques. We confirm the
soundness of our proposed method through simulation studies.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03245" title="Abstract">arXiv:2403.03245</a> (cross-list from hep-th) [<a href="/pdf/2403.03245" title="Download PDF">pdf</a>, <a href="/format/2403.03245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Learning and Quantum Gravity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-th?searchtype=author&query=Lanza%2C+S">Stefano Lanza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Theory (hep-th)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The landscape of low-energy effective field theories stemming from string
theory is too vast for a systematic exploration. However, the meadows of the
string landscape may be fertile ground for the application of machine learning
techniques. Employing neural network learning may allow for inferring novel,
undiscovered properties that consistent theories in the landscape should
possess, or checking conjectural statements about alleged characteristics
thereof. The aim of this work is to describe to what extent the string
landscape can be explored with neural network-based learning. Our analysis is
motivated by recent studies that show that the string landscape is
characterized by finiteness properties, emerging from its underlying tame,
o-minimal structures. Indeed, employing these results, we illustrate that any
low-energy effective theory of string theory is endowed with certain
statistical learnability properties. Consequently, several learning problems
therein formulated, including interpolations and multi-class classification
problems, can be concretely addressed with machine learning, delivering results
with sufficiently high accuracy.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03271" title="Abstract">arXiv:2403.03271</a> (cross-list from eess.SP) [<a href="/pdf/2403.03271" title="Download PDF">pdf</a>, <a href="/ps/2403.03271" title="Download PostScript">ps</a>, <a href="/format/2403.03271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Linear Decoupling of Users for Uplink Massive MU-MIMO  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sowmya%2C+S">S. Sowmya</a>, 
<a href="/search/eess?searchtype=author&query=Muthukrishnan%2C+G">Gokularam Muthukrishnan</a>, 
<a href="/search/eess?searchtype=author&query=Giridhar%2C+K">K. Giridhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Multi-user massive MIMO is a promising candidate for future wireless
communication systems. It enables users with different requirements to be
connected to the same base station (BS) on the same set of resources. In uplink
massive MU-MIMO, while users with different requirements are served, decoupled
signal detection helps in using a user-specific detection scheme for every
user. In this paper, we propose a low-complexity linear decoupling scheme
called Sequential Decoupler (SD), which aids in the parallel detection of each
user's data streams. The proposed algorithm shows significant complexity
reduction, particularly when the number of users in the system increases. In
the numerical simulations, it has been observed that the complexity of the
proposed scheme is only 0.15% of the conventional Singular Value Decomposition
(SVD) based decoupling and 47% to the pseudo-inverse based decoupling schemes
when 80 users with two antennas each are served by the BS.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03274" title="Abstract">arXiv:2403.03274</a> (cross-list from q-bio.QM) [<a href="/pdf/2403.03274" title="Download PDF">pdf</a>, <a href="/format/2403.03274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Noise to Signal: Unveiling Treatment Effects from Digital Health  Data through Pharmacology-Informed Neural-SDE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pakravan%2C+S">Samira Pakravan</a>, 
<a href="/search/q-bio?searchtype=author&query=Evangelou%2C+N">Nikolaos Evangelou</a>, 
<a href="/search/q-bio?searchtype=author&query=Usdin%2C+M">Maxime Usdin</a>, 
<a href="/search/q-bio?searchtype=author&query=Brooks%2C+L">Logan Brooks</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+J">James Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Digital health technologies (DHT), such as wearable devices, provide
personalized, continuous, and real-time monitoring of patient. These
technologies are contributing to the development of novel therapies and
personalized medicine. Gaining insight from these technologies requires
appropriate modeling techniques to capture clinically-relevant changes in
disease state. The data generated from these devices is characterized by being
stochastic in nature, may have missing elements, and exhibits considerable
inter-individual variability - thereby making it difficult to analyze using
traditional longitudinal modeling techniques. We present a novel
pharmacology-informed neural stochastic differential equation (SDE) model
capable of addressing these challenges. Using synthetic data, we demonstrate
that our approach is effective in identifying treatment effects and learning
causal relationships from stochastic data, thereby enabling counterfactual
simulation.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03276" title="Abstract">arXiv:2403.03276</a> (cross-list from eess.SP) [<a href="/pdf/2403.03276" title="Download PDF">pdf</a>, <a href="/format/2403.03276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals  to Identify Epileptic Seizures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rukhsar%2C+S">Salim Rukhsar</a>, 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+A+K">Anil Kumar Tiwari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, Journal Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We proposed an Attentive Recurrent Neural Network (ARNN), which recurrently
applies attention layers along a sequence and has linear complexity with
respect to the sequence length. The proposed model operates on multi-channel
EEG signals rather than single channel signals and leverages parallel
computation. In this cell, the attention layer is a computational unit that
efficiently applies self-attention and cross-attention mechanisms to compute a
recurrent function over a wide number of state vectors and input signals. Our
architecture is inspired in part by the attention layer and long short-term
memory (LSTM) cells, and it uses long-short style gates, but it scales this
typical cell up by several orders to parallelize for multi-channel EEG signals.
It inherits the advantages of attention layers and LSTM gate while avoiding
their respective drawbacks. We evaluated the model effectiveness through
extensive experiments with heterogeneous datasets, including the CHB-MIT and
UPenn and Mayos Clinic, CHB-MIT datasets. The empirical findings suggest that
the ARNN model outperforms baseline methods such as LSTM, Vision Transformer
(ViT), Compact Convolution Transformer (CCT), and R-Transformer (RT),
showcasing superior performance and faster processing capabilities across a
wide range of tasks. The code has been made publicly accessible at
\url{https://github.com/Salim-Lysiun/ARNN}.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03295" title="Abstract">arXiv:2403.03295</a> (cross-list from quant-ph) [<a href="/pdf/2403.03295" title="Download PDF">pdf</a>, <a href="/ps/2403.03295" title="Download PostScript">ps</a>, <a href="/format/2403.03295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proper vs Improper Quantum PAC learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+P">Pulkit Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
<p class="mathjax">A basic question in the PAC model of learning is whether proper learning is
harder than improper learning. In the classical case, there are examples of
concept classes with VC dimension $d$ that have sample complexity
$\Omega\left(\frac d\epsilon\log\frac1\epsilon\right)$ for proper learning with
error $\epsilon$, while the complexity for improper learning is O$\!\left(\frac
d\epsilon\right)$. One such example arises from the Coupon Collector problem.
<br />Motivated by the efficiency of proper versus improper learning with quantum
samples, Arunachalam, Belovs, Childs, Kothari, Rosmanis, and de Wolf (TQC 2020)
studied an analogue, the Quantum Coupon Collector problem. Curiously, they
discovered that for learning size $k$ subsets of $[n]$ the problem has sample
complexity $\Theta(k\log\min\{k,n-k+1\})$, in contrast with the complexity of
$\Theta(k\log k)$ for Coupon Collector. This effectively negates the
possibility of a separation between the two modes of learning via the quantum
problem, and Arunachalam et al.\ posed the possibility of such a separation as
an open question.
<br />In this work, we first present an algorithm for the Quantum Coupon Collector
problem with sample complexity that matches the sharper lower bound of
$(1-o_k(1))k\ln\min\{k,n-k+1\}$ shown recently by Bab Hadiashar, Nayak, and
Sinha (IEEE TIT 2024), for the entire range of the parameter $k$. Next, we
devise a variant of the problem, the Quantum Padded Coupon Collector. We prove
that its sample complexity matches that of the classical Coupon Collector
problem for both modes of learning, thereby exhibiting the same asymptotic
separation between proper and improper quantum learning as mentioned above. The
techniques we develop in the process can be directly applied to any form of
padded quantum data. We hope that padding can more generally lift other forms
of classical learning behaviour to the quantum setting.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03310" title="Abstract">arXiv:2403.03310</a> (cross-list from quant-ph) [<a href="/pdf/2403.03310" title="Download PDF">pdf</a>, <a href="/format/2403.03310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Learning for Parameter Prediction of Quantum Approximate  Optimization Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liang%2C+Z">Zhiding Liang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+G">Gang Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Z">Zheyuan Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cheng%2C+J">Jinglei Cheng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hao%2C+T">Tianyi Hao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+K">Kecheng Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ren%2C+H">Hang Ren</a>, 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+Z">Zhixin Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ye%2C+F">Fanny Ye</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, quantum computing has emerged as a transformative force in
the field of combinatorial optimization, offering novel approaches to tackling
complex problems that have long challenged classical computational methods.
Among these, the Quantum Approximate Optimization Algorithm (QAOA) stands out
for its potential to efficiently solve the Max-Cut problem, a quintessential
example of combinatorial optimization. However, practical application faces
challenges due to current limitations on quantum computational resource. Our
work optimizes QAOA initialization, using Graph Neural Networks (GNN) as a
warm-start technique. This sacrifices affordable computational resource on
classical computer to reduce quantum computational resource overhead, enhancing
QAOA's effectiveness. Experiments with various GNN architectures demonstrate
the adaptability and stability of our framework, highlighting the synergy
between quantum algorithms and machine learning. Our findings show GNN's
potential in improving QAOA performance, opening new avenues for hybrid
quantum-classical approaches in quantum computing and contributing to practical
applications.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03326" title="Abstract">arXiv:2403.03326</a> (cross-list from eess.IV) [<a href="/pdf/2403.03326" title="Download PDF">pdf</a>, <a href="/format/2403.03326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnatoMix: Anatomy-aware Data Augmentation for Multi-organ Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+F">Fuxin Fan</a>, 
<a href="/search/eess?searchtype=author&query=Schwarz%2C+A">Annette Schwarz</a>, 
<a href="/search/eess?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-organ segmentation in medical images is a widely researched task and
can save much manual efforts of clinicians in daily routines. Automating the
organ segmentation process using deep learning (DL) is a promising solution and
state-of-the-art segmentation models are achieving promising accuracy. In this
work, We proposed a novel data augmentation strategy for increasing the
generalizibility of multi-organ segmentation datasets, namely AnatoMix. By
object-level matching and manipulation, our method is able to generate new
images with correct anatomy, i.e. organ segmentation mask, exponentially
increasing the size of the segmentation dataset. Initial experiments have been
done to investigate the segmentation performance influenced by our method on a
public CT dataset. Our augmentation method can lead to mean dice of 76.1,
compared with 74.8 of the baseline method.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03330" title="Abstract">arXiv:2403.03330</a> (cross-list from math.OC) [<a href="/pdf/2403.03330" title="Download PDF">pdf</a>, <a href="/ps/2403.03330" title="Download PostScript">ps</a>, <a href="/format/2403.03330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assortment Optimization For Conference Goodies With Indifferent  Attendees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guti%C3%A9rrez%2C+F">Fernanda Guti&#xe9;rrez</a>, 
<a href="/search/math?searchtype=author&query=Subercaseaux%2C+B">Bernardo Subercaseaux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Conferences such as FUN with Algorithms routinely buy goodies (e.g.,
t-shirts, coffee mugs, etc) for their attendees. Often, said goodies come in
different types, varying by color or design, and organizers need to decide how
many goodies of each type to buy. We study the problem of buying optimal
amounts of each type under a simple model of preferences by the attendees: they
are indifferent to the types but want to be able to choose between more than
one type of goodies at the time of their arrival. The indifference of attendees
suggests that the optimal policy is to buy roughly equal amounts for every
goodie type. Despite how intuitive this conjecture sounds, we show that this
simple model of assortment optimization is quite rich, and even though we make
progress towards proving the conjecture (e.g., we succeed when the number of
goodie types is 2 or 3), the general case with K types remains open. We also
present asymptotic results and computer simulations, and finally, to motivate
further progress, we offer a reward of $100usd for a full proof.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03349" title="Abstract">arXiv:2403.03349</a> (cross-list from stat.ME) [<a href="/pdf/2403.03349" title="Download PDF">pdf</a>, <a href="/format/2403.03349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A consensus-constrained parsimonious Gaussian mixture model for  clustering hyperspectral images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Babu%2C+G">Ganesh Babu</a>, 
<a href="/search/stat?searchtype=author&query=Gowen%2C+A">Aoife Gowen</a>, 
<a href="/search/stat?searchtype=author&query=Fop%2C+M">Michael Fop</a>, 
<a href="/search/stat?searchtype=author&query=Gormley%2C+I+C">Isobel Claire Gormley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The use of hyperspectral imaging to investigate food samples has grown due to
the improved performance and lower cost of spectroscopy instrumentation. Food
engineers use hyperspectral images to classify the type and quality of a food
sample, typically using classification methods. In order to train these
methods, every pixel in each training image needs to be labelled. Typically,
computationally cheap threshold-based approaches are used to label the pixels,
and classification methods are trained based on those labels. However,
threshold-based approaches are subjective and cannot be generalized across
hyperspectral images taken in different conditions and of different foods. Here
a consensus-constrained parsimonious Gaussian mixture model (ccPGMM) is
proposed to label pixels in hyperspectral images using a model-based clustering
approach. The ccPGMM utilizes available information on the labels of a small
number of pixels and the relationship between those pixels and neighbouring
pixels as constraints when clustering the rest of the pixels in the image. A
latent variable model is used to represent the high-dimensional data in terms
of a small number of underlying latent factors. To ensure computational
feasibility, a consensus clustering approach is employed, where the data are
divided into multiple randomly selected subsets of variables and constrained
clustering is applied to each data subset; the clustering results are then
consolidated across all data subsets to provide a consensus clustering
solution. The ccPGMM approach is applied to simulated datasets and real
hyperspectral images of three types of puffed cereal, corn, rice, and wheat.
Improved clustering performance and computational efficiency are demonstrated
when compared to other current state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03353" title="Abstract">arXiv:2403.03353</a> (cross-list from stat.ML) [<a href="/pdf/2403.03353" title="Download PDF">pdf</a>, <a href="/ps/2403.03353" title="Download PostScript">ps</a>, <a href="/format/2403.03353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypothesis Spaces for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+Y">Yuesheng Xu</a>, 
<a href="/search/stat?searchtype=author&query=Yan%2C+M">Mingsong Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA)

</div>
<p class="mathjax">This paper introduces a hypothesis space for deep learning that employs deep
neural networks (DNNs). By treating a DNN as a function of two variables, the
physical variable and parameter variable, we consider the primitive set of the
DNNs for the parameter variable located in a set of the weight matrices and
biases determined by a prescribed depth and widths of the DNNs. We then
complete the linear span of the primitive DNN set in a weak* topology to
construct a Banach space of functions of the physical variable. We prove that
the Banach space so constructed is a reproducing kernel Banach space (RKBS) and
construct its reproducing kernel. We investigate two learning models,
regularized learning and minimum interpolation problem in the resulting RKBS,
by establishing representer theorems for solutions of the learning models. The
representer theorems unfold that solutions of these learning models can be
expressed as linear combination of a finite number of kernel sessions
determined by given data and the reproducing kernel.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03355" title="Abstract">arXiv:2403.03355</a> (cross-list from math.OC) [<a href="/pdf/2403.03355" title="Download PDF">pdf</a>, <a href="/format/2403.03355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The vehicle routing problem with synchronization constraints and support  vehicle-dependent service times
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wittwer%2C+D">David Wittwer</a>, 
<a href="/search/math?searchtype=author&query=Tamke%2C+F">Felix Tamke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Many production processes require the cooperation of various resources.
Especially when using expensive machines, their utilization plays a decisive
role in efficient production. In agricultural production or civil construction
processes, e.g., harvesting or road building, the machines are typically
mobile, and synchronization of different machine types is required to perform
operations. In addition, the productivity of one type often depends on the
availability of another type. In this paper, we consider two types of vehicles,
called primary and support vehicles. Primary vehicles perform operations and
are assisted by at least one support vehicle, with more support vehicles
resulting in faster service times for primary vehicles. We call this practical
problem the vehicle routing and scheduling problem with support
vehicle-dependent service times and introduce two mixed-integer linear
programming models. The first represents each support vehicle individually with
binary decision variables, while the second considers the cumulative flow of
support vehicles with integer decision variables. Furthermore, the models are
defined on a graph that allows easy transformation into multiple variants.
These variants are based on allowing or prohibiting switching support vehicles
between primary vehicles and splitting services among primary vehicles. We show
in our extensive computational experiments that: i) the integer representation
of support vehicles is superior to the binary representation, ii) the benefit
of additional vehicles is subject to saturation effects and depends on the
ratio of support and primary vehicles, and iii) switching and splitting lead to
problems that are more difficult to solve, but also result in better solutions
with higher primary vehicle utilization.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03361" title="Abstract">arXiv:2403.03361</a> (cross-list from stat.ML) [<a href="/pdf/2403.03361" title="Download PDF">pdf</a>, <a href="/ps/2403.03361" title="Download PostScript">ps</a>, <a href="/format/2403.03361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chained Information-Theoretic bounds and Tight Regret Rate for Linear  Bandit Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gouverneur%2C+A">Amaury Gouverneur</a>, 
<a href="/search/stat?searchtype=author&query=Rodr%C3%ADguez-G%C3%A1lvez%2C+B">Borja Rodr&#xed;guez-G&#xe1;lvez</a>, 
<a href="/search/stat?searchtype=author&query=Oechtering%2C+T+J">Tobias J. Oechtering</a>, 
<a href="/search/stat?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages: 8 of main text and 7 of appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper studies the Bayesian regret of a variant of the Thompson-Sampling
algorithm for bandit problems. It builds upon the information-theoretic
framework of [Russo and Van Roy, 2015] and, more specifically, on the
rate-distortion analysis from [Dong and Van Roy, 2020], where they proved a
bound with regret rate of $O(d\sqrt{T \log(T)})$ for the $d$-dimensional linear
bandit setting. We focus on bandit problems with a metric action space and,
using a chaining argument, we establish new bounds that depend on the metric
entropy of the action space for a variant of Thompson-Sampling.
<br />Under suitable continuity assumption of the rewards, our bound offers a tight
rate of $O(d\sqrt{T})$ for $d$-dimensional linear bandit problems.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03367" title="Abstract">arXiv:2403.03367</a> (cross-list from q-fin.TR) [<a href="/pdf/2403.03367" title="Download PDF">pdf</a>, <a href="/ps/2403.03367" title="Download PostScript">ps</a>, <a href="/format/2403.03367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> am-AMM: An Auction-Managed Automated Market Maker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Adams%2C+A">Austin Adams</a>, 
<a href="/search/q-fin?searchtype=author&query=Moallemi%2C+C">Ciamac Moallemi</a>, 
<a href="/search/q-fin?searchtype=author&query=Reynolds%2C+S">Sara Reynolds</a>, 
<a href="/search/q-fin?searchtype=author&query=Robinson%2C+D">Dan Robinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC); Mathematical Finance (q-fin.MF)

</div>
<p class="mathjax">Automated market makers (AMMs) have emerged as the dominant market mechanism
for trading on decentralized exchanges implemented on blockchains. This paper
presents a single mechanism that targets two important unsolved problems for
AMMs: reducing losses to informed orderflow, and maximizing revenue from
uninformed orderflow. The "auction-managed AMM" works by running a
censorship-resistant onchain auction for the right to temporarily act as "pool
manager" for a constant-product AMM. The pool manager sets the swap fee rate on
the pool, and also receives the accrued fees from swaps. The pool manager can
exclusively capture some arbitrage by trading against the pool in response to
small price movements, and also can set swap fees incorporating price
sensitivity of retail orderflow and adapting to changing market conditions,
with the benefits from both ultimately accruing to liquidity providers.
Liquidity providers can enter and exit the pool freely in response to changing
rent, though they must pay a small fee on withdrawal. We prove that under
certain assumptions, this AMM should have higher liquidity in equilibrium than
any standard, fixed-fee AMM.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03385" title="Abstract">arXiv:2403.03385</a> (cross-list from eess.IV) [<a href="/pdf/2403.03385" title="Download PDF">pdf</a>, <a href="/format/2403.03385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuhua%2C+C">Chen Yuhua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This article investigates deep learning methodologies for single-modality
clinical data analysis, as a crucial precursor to multi-modal medical research.
Building on Guo JingYuan's work, the study refines clinical data processing
through Compact Convolutional Transformer (CCT), Patch Up, and the innovative
CamCenterLoss technique, establishing a foundation for future multimodal
investigations. The proposed methodology demonstrates improved prediction
accuracy and at tentiveness to critically ill patients compared to Guo
JingYuan's ResNet and StageNet approaches. Novelty that using image-pretrained
vision transformer backbone to perform transfer learning time-series clinical
data.The study highlights the potential of CCT, Patch Up, and novel
CamCenterLoss in processing single modality clinical data within deep learning
frameworks, paving the way for future multimodal medical research and promoting
precision and personalized healthcare
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03391" title="Abstract">arXiv:2403.03391</a> (cross-list from stat.ML) [<a href="/pdf/2403.03391" title="Download PDF">pdf</a>, <a href="/format/2403.03391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoRMF: Criticality-Ordered Recurrent Mean Field Ising Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pan%2C+Z">Zhenyu Pan</a>, 
<a href="/search/stat?searchtype=author&query=Gilani%2C+A">Ammar Gilani</a>, 
<a href="/search/stat?searchtype=author&query=Kuo%2C+E">En-Jui Kuo</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+Z">Zhuo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose an RNN-based efficient Ising model solver, the Criticality-ordered
Recurrent Mean Field (CoRMF), for forward Ising problems. In its core, a
criticality-ordered spin sequence of an $N$-spin Ising model is introduced by
sorting mission-critical edges with greedy algorithm, such that an
autoregressive mean-field factorization can be utilized and optimized with
Recurrent Neural Networks (RNNs). Our method has two notable characteristics:
(i) by leveraging the approximated tree structure of the underlying Ising
graph, the newly-obtained criticality order enables the unification between
variational mean-field and RNN, allowing the generally intractable Ising model
to be efficiently probed with probabilistic inference; (ii) it is
well-modulized, model-independent while at the same time expressive enough, and
hence fully applicable to any forward Ising inference problems with minimal
effort. Computationally, by using a variance-reduced Monte Carlo gradient
estimator, CoRFM solves the Ising problems in a self-train fashion without
data/evidence, and the inference tasks can be executed by directly sampling
from RNN. Theoretically, we establish a provably tighter error bound than naive
mean-field by using the matrix cut decomposition machineries. Numerically, we
demonstrate the utility of this framework on a series of Ising datasets.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03404" title="Abstract">arXiv:2403.03404</a> (cross-list from math.CO) [<a href="/pdf/2403.03404" title="Download PDF">pdf</a>, <a href="/format/2403.03404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Total Domination Number in Maximal Outerplanar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aita%2C+Y">Yasufumi Aita</a>, 
<a href="/search/math?searchtype=author&query=Araki%2C+T">Toru Araki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A subset $S$ of vertices in a graph $G$ is a secure total dominating set of
$G$ if $S$ is a total dominating set of $G$ and, for each vertex $u \not\in S$,
there is a vertex $v \in S$ such that $uv$ is an edge and $(S \setminus \{v\})
\cup \{u\}$ is also a total dominating set of $G$. We show that if $G$ is a
maximal outerplanar graph of order $n$, then $G$ has a total secure dominating
set of size at most $\lfloor 2n/3 \rfloor$. Moreover, if an outerplanar graph
$G$ of order $n$, then each secure total dominating set has at least $\lceil
(n+2)/3 \rceil$ vertices. We show that these bounds are best possible.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03427" title="Abstract">arXiv:2403.03427</a> (cross-list from astro-ph.EP) [<a href="/pdf/2403.03427" title="Download PDF">pdf</a>, <a href="/format/2403.03427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Transit Detection In Kepler With Machine Learning And Onboard  Spacecraft Diagnostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Hansen%2C+M+T">Matthew T. Hansen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dittmann%2C+J+A">Jason A. Dittmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 23 figures, submitted to AJ
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Exoplanet discovery at long orbital periods requires reliably detecting
individual transits without additional information about the system. Techniques
like phase-folding of light curves and periodogram analysis of radial velocity
data are more sensitive to planets with shorter orbital periods, leaving a
dearth of planet discoveries at long periods. We present a novel technique
using an ensemble of Convolutional Neural Networks incorporating the onboard
spacecraft diagnostics of \emph{Kepler} to classify transits within a light
curve. We create a pipeline to recover the location of individual transits, and
the period of the orbiting planet, which maintains $&gt;80\%$ transit recovery
sensitivity out to an 800-day orbital period. Our neural network pipeline has
the potential to discover additional planets in the \emph{Kepler} dataset, and
crucially, within the $\eta$-Earth regime. We report our first candidate from
this pipeline, KOI 1271.02. KOI 1271.01 is known to exhibit strong Transit
Timing Variations (TTVs), and so we jointly model the TTVs and transits of both
transiting planets to constrain the orbital configuration and planetary
parameters and conclude with a series of potential parameters for KOI 1271.02,
as there is not enough data currently to uniquely constrain the system. We
conclude that KOI 1271.02 has a radius of 5.32 $\pm$ 0.20 $R_{\oplus}$ and a
mass of $28.94^{0.23}_{-0.47}$ $M_{\oplus}$. Future constraints on the nature
of KOI 1271.02 require measuring additional TTVs of KOI 1271.01 or observing a
second transit of KOI 1271.02.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03455" title="Abstract">arXiv:2403.03455</a> (cross-list from math.OC) [<a href="/pdf/2403.03455" title="Download PDF">pdf</a>, <a href="/format/2403.03455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Control Lyapunov-Value Functions for Nonlinear Disturbed Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gong%2C+Z">Zheng Gong</a>, 
<a href="/search/math?searchtype=author&query=Herbert%2C+S">Sylvia Herbert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Control Lyapunov Functions (CLFs) have been extensively used in the control
community. A well-known drawback is the absence of a systematic way to
construct CLFs for general nonlinear systems, and the problem can become more
complex with input or state constraints. Our preliminary work on constructing
Control Lyapunov Value Functions (CLVFs) using Hamilton-Jacobi (HJ)
reachability analysis provides a method for finding a non-smooth CLF. In this
paper, we extend our work on CLVFs to systems with bounded disturbance and
define the Robust CLVF (R-CLVF). The R-CLVF naturally inherits all properties
of the CLVF; i.e., it first identifies the "smallest robust control invariant
set (SRCIS)" and stabilizes the system to it with a user-specified exponential
rate. The region from which the exponential rate can be met is called the
"region of exponential stabilizability (ROES)." We provide clearer definitions
of the SRCIS and more rigorous proofs of several important theorems. Since the
computation of the R-CLVF suffers from the "curse of dimensionality," we also
provide two techniques (warmstart and system decomposition) that solve it,
along with necessary proofs. Three numerical examples are provided, validating
our definition of SRCIS, illustrating the trade-off between a faster decay rate
and a smaller ROES, and demonstrating the efficiency of computation using
warmstart and decomposition.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03488" title="Abstract">arXiv:2403.03488</a> (cross-list from eess.IV) [<a href="/pdf/2403.03488" title="Download PDF">pdf</a>, <a href="/format/2403.03488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast, nonlocal and neural: a lightweight high quality solution to image  denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yu Guo</a>, 
<a href="/search/eess?searchtype=author&query=Davy%2C+A">Axel Davy</a>, 
<a href="/search/eess?searchtype=author&query=Facciolo%2C+G">Gabriele Facciolo</a>, 
<a href="/search/eess?searchtype=author&query=Morel%2C+J">Jean-Michel Morel</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Q">Qiyu Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages. This paper was accepted by IEEE Signal Processing Letters on July 1, 2021
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Signal Processing Letters, 2021, 28:1515-1519
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the widespread application of convolutional neural networks (CNNs), the
traditional model based denoising algorithms are now outperformed. However,
CNNs face two problems. First, they are computationally demanding, which makes
their deployment especially difficult for mobile terminals. Second,
experimental evidence shows that CNNs often over-smooth regular textures
present in images, in contrast to traditional non-local models. In this letter,
we propose a solution to both issues by combining a nonlocal algorithm with a
lightweight residual CNN. This solution gives full latitude to the advantages
of both models. We apply this framework to two GPU implementations of classic
nonlocal algorithms (NLM and BM3D) and observe a substantial gain in both
cases, performing better than the state-of-the-art with low computational
requirements. Our solution is between 10 and 20 times faster than CNNs with
equivalent performance and attains higher PSNR. In addition the final method
shows a notable gain on images containing complex textures like the ones of the
MIT Moire dataset.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03511" title="Abstract">arXiv:2403.03511</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2403.03511" title="Download PDF">pdf</a>, <a href="/format/2403.03511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Illuminating the property space in crystal structure prediction using  Quality-Diversity algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Wolinska%2C+M">Marta Wolinska</a>, 
<a href="/search/cond-mat?searchtype=author&query=Walsh%2C+A">Aron Walsh</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cully%2C+A">Antoine Cully</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The identification of materials with exceptional properties is an essential
objective to enable technological progress. We propose the application of
\textit{Quality-Diversity} algorithms to the field of crystal structure
prediction. The objective of these algorithms is to identify a diverse set of
high-performing solutions, which has been successful in a range of fields such
as robotics, architecture and aeronautical engineering. As these methods rely
on a high number of evaluations, we employ machine-learning surrogate models to
compute the interatomic potential and material properties that are used to
guide optimisation. Consequently, we also show the value of using neural
networks to model crystal properties and enable the identification of novel
composition--structure combinations. In this work, we specifically study the
application of the MAP-Elites algorithm to predict polymorphs of TiO$_2$. We
rediscover the known ground state, in addition to a set of other polymorphs
with distinct properties. We validate our method for C, SiO$_2$ and SiC
systems, where we show that the algorithm can uncover multiple local minima
with distinct electronic and mechanical properties.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03526" title="Abstract">arXiv:2403.03526</a> (cross-list from eess.SP) [<a href="/pdf/2403.03526" title="Download PDF">pdf</a>, <a href="/format/2403.03526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FingerNet: EEG Decoding of A Fine Motor Imagery with Finger-tapping Task  Based on A Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Go%2C+Y">Young-Min Go</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+S">Seong-Hyun Yu</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+H">Hyeong-Yeong Park</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+M">Minji Lee</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+J">Ji-Hoon Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,5 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Brain-computer interface (BCI) technology facilitates communication between
the human brain and computers, primarily utilizing electroencephalography (EEG)
signals to discern human intentions. Although EEG-based BCI systems have been
developed for paralysis individuals, ongoing studies explore systems for speech
imagery and motor imagery (MI). This study introduces FingerNet, a specialized
network for fine MI classification, departing from conventional gross MI
studies. The proposed FingerNet could extract spatial and temporal features
from EEG signals, improving classification accuracy within the same hand. The
experimental results demonstrated that performance showed significantly higher
accuracy in classifying five finger-tapping tasks, encompassing thumb, index,
middle, ring, and little finger movements. FingerNet demonstrated dominant
performance compared to the conventional baseline models, EEGNet and
DeepConvNet. The average accuracy for FingerNet was 0.3049, whereas EEGNet and
DeepConvNet exhibited lower accuracies of 0.2196 and 0.2533, respectively.
Statistical validation also demonstrates the predominance of FingerNet over
baseline networks. For biased predictions, particularly for thumb and index
classes, we led to the implementation of weighted cross-entropy and also
adapted the weighted cross-entropy, a method conventionally employed to
mitigate class imbalance. The proposed FingerNet involves optimizing network
structure, improving performance, and exploring applications beyond fine MI.
Moreover, the weighted Cross Entropy approach employed to address such biased
predictions appears to have broader applicability and relevance across various
domains involving multi-class classification tasks. We believe that effective
execution of motor imagery can be achieved not only for fine MI, but also for
local muscle MI
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03539" title="Abstract">arXiv:2403.03539</a> (cross-list from eess.IV) [<a href="/pdf/2403.03539" title="Download PDF">pdf</a>, <a href="/format/2403.03539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gadolinium dose reduction for brain MRI using conditional deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pinetz%2C+T">Thomas Pinetz</a>, 
<a href="/search/eess?searchtype=author&query=Kobler%2C+E">Erich Kobler</a>, 
<a href="/search/eess?searchtype=author&query=Haase%2C+R">Robert Haase</a>, 
<a href="/search/eess?searchtype=author&query=Luetkens%2C+J+A">Julian A. Luetkens</a>, 
<a href="/search/eess?searchtype=author&query=Meetschen%2C+M">Mathias Meetschen</a>, 
<a href="/search/eess?searchtype=author&query=Haubold%2C+J">Johannes Haubold</a>, 
<a href="/search/eess?searchtype=author&query=Deuschl%2C+C">Cornelius Deuschl</a>, 
<a href="/search/eess?searchtype=author&query=Radbruch%2C+A">Alexander Radbruch</a>, 
<a href="/search/eess?searchtype=author&query=Deike%2C+K">Katerina Deike</a>, 
<a href="/search/eess?searchtype=author&query=Effland%2C+A">Alexander Effland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, deep learning (DL)-based methods have been proposed for the
computational reduction of gadolinium-based contrast agents (GBCAs) to mitigate
adverse side effects while preserving diagnostic value. Currently, the two main
challenges for these approaches are the accurate prediction of contrast
enhancement and the synthesis of realistic images. In this work, we address
both challenges by utilizing the contrast signal encoded in the subtraction
images of pre-contrast and post-contrast image pairs. To avoid the synthesis of
any noise or artifacts and solely focus on contrast signal extraction and
enhancement from low-dose subtraction images, we train our DL model using
noise-free standard-dose subtraction images as targets. As a result, our model
predicts the contrast enhancement signal only; thereby enabling synthesization
of images beyond the standard dose. Furthermore, we adapt the embedding idea of
recent diffusion-based models to condition our model on physical parameters
affecting the contrast enhancement behavior. We demonstrate the effectiveness
of our approach on synthetic and real datasets using various scanners, field
strengths, and contrast agents.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03545" title="Abstract">arXiv:2403.03545</a> (cross-list from eess.SP) [<a href="/pdf/2403.03545" title="Download PDF">pdf</a>, <a href="/format/2403.03545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Generative Prior for Low-Complexity MIMO Channel  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fesl%2C+B">Benedikt Fesl</a>, 
<a href="/search/eess?searchtype=author&query=Baur%2C+M">Michael Baur</a>, 
<a href="/search/eess?searchtype=author&query=Strasser%2C+F">Florian Strasser</a>, 
<a href="/search/eess?searchtype=author&query=Joham%2C+M">Michael Joham</a>, 
<a href="/search/eess?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work proposes a novel channel estimator based on diffusion models (DMs),
one of the currently top-rated generative models. Contrary to related works
utilizing generative priors, a lightweight convolutional neural network (CNN)
with positional embedding of the signal-to-noise ratio (SNR) information is
designed by learning the channel distribution in the sparse angular domain.
Combined with an estimation strategy that avoids stochastic resampling and
truncates reverse diffusion steps that account for lower SNR than the given
pilot observation, the resulting DM estimator has both low complexity and
memory overhead. Numerical results exhibit better performance than
state-of-the-art channel estimators utilizing generative priors.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03551" title="Abstract">arXiv:2403.03551</a> (cross-list from eess.IV) [<a href="/pdf/2403.03551" title="Download PDF">pdf</a>, <a href="/format/2403.03551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Dose CT Image Reconstruction by Fine-Tuning a UNet Pretrained for  Gaussian Denoising for the Downstream Task of Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Selig%2C+T">Tim Selig</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A4rz%2C+T">Thomas M&#xe4;rz</a>, 
<a href="/search/eess?searchtype=author&query=Storath%2C+M">Martin Storath</a>, 
<a href="/search/eess?searchtype=author&query=Weinmann%2C+A">Andreas Weinmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Computed Tomography (CT) is a widely used medical imaging modality, and as it
is based on ionizing radiation, it is desirable to minimize the radiation dose.
However, a reduced radiation dose comes with reduced image quality, and
reconstruction from low-dose CT (LDCT) data is still a challenging task which
is subject to research. According to the LoDoPaB-CT benchmark, a benchmark for
LDCT reconstruction, many state-of-the-art methods use pipelines involving
UNet-type architectures. Specifically the top ranking method, ItNet, employs a
three-stage process involving filtered backprojection (FBP), a UNet trained on
CT data, and an iterative refinement step. In this paper, we propose a less
complex two-stage method. The first stage also employs FBP, while the novelty
lies in the training strategy for the second stage, characterized as the CT
image enhancement stage. The crucial point of our approach is that the neural
network is pretrained on a distinctly different pretraining task with non-CT
data, namely Gaussian noise removal on a variety of natural grayscale images
(photographs). We then fine-tune this network for the downstream task of CT
image enhancement using pairs of LDCT images and corresponding normal-dose CT
images (NDCT). Despite being notably simpler than the state-of-the-art, as the
pretraining did not depend on domain-specific CT data and no further iterative
refinement step was necessary, the proposed two-stage method achieves
competitive results. The proposed method achieves a shared top ranking in the
LoDoPaB-CT challenge and a first position with respect to the SSIM metric.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03589" title="Abstract">arXiv:2403.03589</a> (cross-list from stat.ME) [<a href="/pdf/2403.03589" title="Download PDF">pdf</a>, <a href="/format/2403.03589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Adaptive Experimental Design for Treatment Effect Estimation with  Covariate Choices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kato%2C+M">Masahiro Kato</a>, 
<a href="/search/stat?searchtype=author&query=Oga%2C+A">Akihiro Oga</a>, 
<a href="/search/stat?searchtype=author&query=Komatsubara%2C+W">Wataru Komatsubara</a>, 
<a href="/search/stat?searchtype=author&query=Inokuchi%2C+R">Ryo Inokuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was submitted to ICML 2024 on February 1st, 2024, and is currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
<p class="mathjax">This study designs an adaptive experiment for efficiently estimating average
treatment effect (ATEs). We consider an adaptive experiment where an
experimenter sequentially samples an experimental unit from a covariate density
decided by the experimenter and assigns a treatment. After assigning a
treatment, the experimenter observes the corresponding outcome immediately. At
the end of the experiment, the experimenter estimates an ATE using gathered
samples. The objective of the experimenter is to estimate the ATE with a
smaller asymptotic variance. Existing studies have designed experiments that
adaptively optimize the propensity score (treatment-assignment probability). As
a generalization of such an approach, we propose a framework under which an
experimenter optimizes the covariate density, as well as the propensity score,
and find that optimizing both covariate density and propensity score reduces
the asymptotic variance more than optimizing only the propensity score. Based
on this idea, in each round of our experiment, the experimenter optimizes the
covariate density and propensity score based on past observations. To design an
adaptive experiment, we first derive the efficient covariate density and
propensity score that minimizes the semiparametric efficiency bound, a lower
bound for the asymptotic variance given a fixed covariate density and a fixed
propensity score. Next, we design an adaptive experiment using the efficient
covariate density and propensity score sequentially estimated during the
experiment. Lastly, we propose an ATE estimator whose asymptotic variance
aligns with the minimized semiparametric efficiency bound.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03597" title="Abstract">arXiv:2403.03597</a> (cross-list from econ.GN) [<a href="/pdf/2403.03597" title="Download PDF">pdf</a>, <a href="/format/2403.03597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The &#x27;Must Stock&#x27; Challenge in Academic Publishing: Pricing Implications  of Transformative Agreements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Schmal%2C+W+B">W. Benedikt Schmal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 3 figures, unreviewed preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">The high relevance of top-notch academic journals turns them into 'must
stock' products that assign its often commercial owners with extraordinary
market power. Intended to tackle this, university consortia around the globe
negotiate so-called 'transformative agreements' with many publishing houses. It
shall pave the way towards standard open-access publishing. While several
contract designs exist, the 'publish-and-read' (PAR) scheme is the one that
comes closest to the ideal of an entirely open access environment: Publishers
are paid a fixed case-by-case rate for each publication, which includes a fee
for their extensive libraries. In turn, all subscription payments are waived. I
theoretically derive that this contract design benefits the included publishers
regardless of whether the number of publications in these publishers' journals
grows or declines. Consequently, widespread PAR contracts are likely to raise
entry barriers for new (open-access) competitors even further. Intending to
lower costs for the universities, their libraries, and, ultimately, the
taxpayers, this PAR fee contract design of transformative agreements might
cause the opposite.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03606" title="Abstract">arXiv:2403.03606</a> (cross-list from q-fin.CP) [<a href="/pdf/2403.03606" title="Download PDF">pdf</a>, <a href="/ps/2403.03606" title="Download PostScript">ps</a>, <a href="/format/2403.03606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Price Prediction in Cryptocurrency Using Transformer Neural  Network and Technical Indicators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Khaniki%2C+M+A+L">Mohammad Ali Labbaf Khaniki</a>, 
<a href="/search/q-fin?searchtype=author&query=Manthouri%2C+M">Mohammad Manthouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents an innovative approach for predicting cryptocurrency time
series, specifically focusing on Bitcoin, Ethereum, and Litecoin. The
methodology integrates the use of technical indicators, a Performer neural
network, and BiLSTM (Bidirectional Long Short-Term Memory) to capture temporal
dynamics and extract significant features from raw cryptocurrency data. The
application of technical indicators, such facilitates the extraction of
intricate patterns, momentum, volatility, and trends. The Performer neural
network, employing Fast Attention Via positive Orthogonal Random features
(FAVOR+), has demonstrated superior computational efficiency and scalability
compared to the traditional Multi-head attention mechanism in Transformer
models. Additionally, the integration of BiLSTM in the feedforward network
enhances the model's capacity to capture temporal dynamics in the data,
processing it in both forward and backward directions. This is particularly
advantageous for time series data where past and future data points can
influence the current state. The proposed method has been applied to the hourly
and daily timeframes of the major cryptocurrencies and its performance has been
benchmarked against other methods documented in the literature. The results
underscore the potential of the proposed method to outperform existing models,
marking a significant progression in the field of cryptocurrency price
prediction.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03611" title="Abstract">arXiv:2403.03611</a> (cross-list from eess.AS) [<a href="/pdf/2403.03611" title="Download PDF">pdf</a>, <a href="/ps/2403.03611" title="Download PostScript">ps</a>, <a href="/format/2403.03611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison Performance of Spectrogram and Scalogram as Input of Acoustic  Recognition Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Phan%2C+D+T">Dang Thoai Phan</a>, 
<a href="/search/eess?searchtype=author&query=Jakob%2C+A">Andre Jakob</a>, 
<a href="/search/eess?searchtype=author&query=Purat%2C+M">Marcus Purat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Acoustic recognition is a common task for deep learning in recent researches,
with the employment of spectral feature extraction such as Short-time Fourier
transform and Wavelet transform. However, not many researches have found that
discuss the advantages and drawbacks, as well as performance comparison amongst
spectral feature extractors. In this consideration, this paper aims to
comparing the attributes of these two transform types, called spectrogram and
scalogram. A Convolutional Neural Networks for acoustic faults recognition is
implemented, then the performance of these two types of spectral extractor is
recorded for comparison. A latest research on the same audio database is
considered for benchmarking to see how good the designed spectrogram and
scalogram is. The advantages and limitations of them are also analyzed. By
doing so, the results of this paper provide indications for application
scenarios of spectrogram and scalogram, as well as potential further research
directions in acoustic recognition.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03624" title="Abstract">arXiv:2403.03624</a> (cross-list from math.OC) [<a href="/pdf/2403.03624" title="Download PDF">pdf</a>, <a href="/ps/2403.03624" title="Download PostScript">ps</a>, <a href="/format/2403.03624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Superstabilizing Control under Quadratically-Bounded  Errors-in-Variables Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miller%2C+J">Jared Miller</a>, 
<a href="/search/math?searchtype=author&query=Dai%2C+T">Tianyu Dai</a>, 
<a href="/search/math?searchtype=author&query=Sznaier%2C+M">Mario Sznaier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Error-in-Variables model of system identification/control involves
nontrivial input and measurement corruption of observed data, resulting in
generically nonconvex optimization problems. This paper performs
full-state-feedback stabilizing control of all discrete-time linear systems
that are consistent with observed data for which the input and measurement
noise obey quadratic bounds. Instances of such quadratic bounds include
elementwise norm bounds (at each time sample), energy bounds (across the entire
signal), and chance constraints arising from (sub)gaussian noise.
Superstabilizing controllers are generated through the solution of a
sum-of-squares hierarchy of semidefinite programs. A theorem of alternatives is
employed to eliminate the input and measurement noise process, thus improving
tractability. Effectiveness of the scheme is generated on an example system in
the chance-constrained set-membership setting where the input and
state-measurement noise are i.i.d. normally distributed.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03632" title="Abstract">arXiv:2403.03632</a> (cross-list from math.AP) [<a href="/pdf/2403.03632" title="Download PDF">pdf</a>, <a href="/ps/2403.03632" title="Download PostScript">ps</a>, <a href="/format/2403.03632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A reduced-order modeling of pattern formations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hausenblas%2C+E">Erika Hausenblas</a>, 
<a href="/search/math?searchtype=author&query=Randrianasolo%2C+T+A">Tsiry Avisoa Randrianasolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Chemical and biochemical reactions can exhibit surprisingly different
behaviours from multiple steady-state solutions to oscillatory solutions and
chaotic behaviours. Such behaviour has been of great interest to researchers
for many decades. The Briggs-Rauscher, Belousov-Zhabotinskii and
Bray-Liebhafsky reactions, for which periodic variations in concentrations can
be visualized by changes in colour, are experimental examples of oscillating
behaviour in chemical systems. These type of systems are modelled by a system
of partial differential equations coupled by a nonlinearity.
<br />However, analysing the pattern, one may suspect that the dynamic is only
generated by a finite number of spatial Fourier modes. In fluid dynamics, it is
shown that for large times, the solution is determined by a finite number of
spatial Fourier modes, called determining modes. In the article, we first
introduce the concept of determining modes and show that, indeed, it is
sufficient to characterise the dynamic by only a finite number of spatial
Fourier modes.
<br />In particular, we analyse the exact number of the determining modes of $u$
and $v$, where the couple $(u,v)$ solves the following stochastic system
<br />\begin{equation*}
<br />\partial_t{u}(t) = r_1\Delta u(t) -\alpha_1u(t)- \gamma_1u(t)v^2(t) + f(1 -
u(t)) + g(t),\quad
<br />\partial_t{v}(t) = r_2\Delta v(t) -\alpha_2v(t) + \gamma_2 u(t)v^2(t) +
h(t),\quad
<br />u(0) = u_0,\;v(0) = v_0,
<br />\end{equation*}
<br />where $r_1,r_2,\gamma_1,\gamma_2&gt;0$, $\alpha_1,\alpha_2 \ge 0$ and $g,h$ are
time depending mappings specified later.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03637" title="Abstract">arXiv:2403.03637</a> (cross-list from math.OC) [<a href="/pdf/2403.03637" title="Download PDF">pdf</a>, <a href="/ps/2403.03637" title="Download PostScript">ps</a>, <a href="/format/2403.03637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact objectives of random linear programs and mean widths of random  polyhedrons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider \emph{random linear programs} (rlps) as a subclass of
\emph{random optimization problems} (rops) and study their typical behavior.
Our particular focus is on appropriate linear objectives which connect the rlps
to the mean widths of random polyhedrons/polytopes. Utilizing the powerful
machinery of \emph{random duality theory} (RDT) \cite{StojnicRegRndDlt10}, we
obtain, in a large dimensional context, the exact characterizations of the
program's objectives. In particular, for any
$\alpha=\lim_{n\rightarrow\infty}\frac{m}{n}\in(0,\infty)$, any unit vector
$\mathbf{c}\in{\mathbb R}^n$, any fixed $\mathbf{a}\in{\mathbb R}^n$, and $A\in
{\mathbb R}^{m\times n}$ with iid standard normal entries, we have
<br />\begin{eqnarray*}
<br />\lim_{n\rightarrow\infty}{\mathbb P}_{A} \left ( (1-\epsilon)
\xi_{opt}(\alpha;\mathbf{a})
<br />\leq \min_{A\mathbf{x}\leq \mathbf{a}}\mathbf{c}^T\mathbf{x} \leq
(1+\epsilon) \xi_{opt}(\alpha;\mathbf{a}) \right ) \longrightarrow 1,
\end{eqnarray*}
<br />where
<br />\begin{equation*} \xi_{opt}(\alpha;\mathbf{a}) \triangleq \min_{x&gt;0}
\sqrt{x^2- x^2 \lim_{n\rightarrow\infty} \frac{\sum_{i=1}^{m} \left (
\frac{1}{2} \left (\left ( \frac{\mathbf{a}_i}{x}\right )^2 + 1\right )
\mbox{erfc}\left( \frac{\mathbf{a}_i}{x\sqrt{2}}\right ) -
\frac{\mathbf{a}_i}{x} \frac{e^{-\frac{\mathbf{a}_i^2}{2x^2}}}{\sqrt{2\pi}}
\right )
<br />}{n} }. \end{equation*}
<br />For example, for $\mathbf{a}=\mathbf{1}$, one uncovers
<br />\begin{equation*}
<br />\xi_{opt}(\alpha)
<br />=
<br />\min_{x&gt;0} \sqrt{x^2- x^2 \alpha \left ( \frac{1}{2} \left ( \frac{1}{x^2} +
1\right ) \mbox{erfc} \left ( \frac{1}{x\sqrt{2}}\right ) - \frac{1}{x}
\frac{e^{-\frac{1}{2x^2}}}{\sqrt{2\pi}} \right ) }. \end{equation*}
<br />Moreover, $2 \xi_{opt}(\alpha)$ is precisely the concentrating point of the
mean width of the polyhedron $\{\mathbf{x}|A\mathbf{x} \leq \mathbf{1}\}$.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03642" title="Abstract">arXiv:2403.03642</a> (cross-list from eess.IV) [<a href="/pdf/2403.03642" title="Download PDF">pdf</a>, <a href="/format/2403.03642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Active Learning with Variational Autoencoder for Radiology  Data Generation in Veterinary Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+I">In-Gyu Lee</a>, 
<a href="/search/eess?searchtype=author&query=Oh%2C+J">Jun-Young Oh</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hee-Jung Yu</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jae-Hwan Kim</a>, 
<a href="/search/eess?searchtype=author&query=Eom%2C+K">Ki-Dong Eom</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+J">Ji-Hoon Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, with increasing interest in pet healthcare, the demand for
computer-aided diagnosis (CAD) systems in veterinary medicine has increased.
The development of veterinary CAD has stagnated due to a lack of sufficient
radiology data. To overcome the challenge, we propose a generative active
learning framework based on a variational autoencoder. This approach aims to
alleviate the scarcity of reliable data for CAD systems in veterinary medicine.
This study utilizes datasets comprising cardiomegaly radiograph data. After
removing annotations and standardizing images, we employed a framework for data
augmentation, which consists of a data generation phase and a query phase for
filtering the generated data. The experimental results revealed that as the
data generated through this framework was added to the training data of the
generative model, the frechet inception distance consistently decreased from
84.14 to 50.75 on the radiograph. Subsequently, when the generated data were
incorporated into the training of the classification model, the false positive
of the confusion matrix also improved from 0.16 to 0.66 on the radiograph. The
proposed framework has the potential to address the challenges of data scarcity
in medical CAD, contributing to its advancement.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03652" title="Abstract">arXiv:2403.03652</a> (cross-list from physics.optics) [<a href="/pdf/2403.03652" title="Download PDF">pdf</a>, <a href="/ps/2403.03652" title="Download PostScript">ps</a>, <a href="/format/2403.03652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Printed Waveguide for Augmented Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sun%2C+D">Dechuan Sun</a>, 
<a href="/search/physics?searchtype=author&query=Tanyi%2C+G">Gregory Tanyi</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+A">Alan Lee</a>, 
<a href="/search/physics?searchtype=author&query=French%2C+C">Chris French</a>, 
<a href="/search/physics?searchtype=author&query=Liang%2C+Y">Younger Liang</a>, 
<a href="/search/physics?searchtype=author&query=Lim%2C+C">Christina Lim</a>, 
<a href="/search/physics?searchtype=author&query=Unnithan%2C+R+R">Ranjith R Unnithan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Human-Computer Interaction (cs.HC); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Mass production of augmented reality (AR) waveguides has been challenging due
to the intricate nature of the fabrication technique and the high precision
required for its optical characteristics. In this paper, we have presented a
novel and low-cost approach for fabricating geometric optical waveguides
designed for AR applications utilizing 3D printing techniques. To strike a
balance between optical performance and fabrication feasibility, we have
optimized the conventional geometric waveguide design to facilitate easier
fabrication. It is worth noting that our proposed method does not require
molding, dicing, and post-surface polishing after printing. A prototype based
on this method has been successfully fabricated, showing the immersion between
the virtual image and the real-world scene. The proposed method has great
potential for adaptation to mass production in various AR applications.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03664" title="Abstract">arXiv:2403.03664</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.03664" title="Download PDF">pdf</a>, <a href="/format/2403.03664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Environmental Insights: Democratizing Access to Ambient Air Pollution  Data and Predictive Analytics with an Open-Source Python Package
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Berrisford%2C+L+J">Liam J Berrisford</a>, 
<a href="/search/physics?searchtype=author&query=Menezes%2C+R">Ronaldo Menezes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ambient air pollution is a pervasive issue with wide-ranging effects on human
health, ecosystem vitality, and economic structures. Utilizing data on ambient
air pollution concentrations, researchers can perform comprehensive analyses to
uncover the multifaceted impacts of air pollution across society. To this end,
we introduce Environmental Insights, an open-source Python package designed to
democratize access to air pollution concentration data. This tool enables users
to easily retrieve historical air pollution data and employ a Machine Learning
model for forecasting potential future conditions. Moreover, Environmental
Insights includes a suite of tools aimed at facilitating the dissemination of
analytical findings and enhancing user engagement through dynamic
visualizations. This comprehensive approach ensures that the package caters to
the diverse needs of individuals looking to explore and understand air
pollution trends and their implications.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03668" title="Abstract">arXiv:2403.03668</a> (cross-list from math.CO) [<a href="/pdf/2403.03668" title="Download PDF">pdf</a>, <a href="/format/2403.03668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Structure of Hamiltonian Graphs with Small Independence Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jedli%C4%8Dkov%C3%A1%2C+N">Nikola Jedli&#x10d;kov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Kratochv%C3%ADl%2C+J">Jan Kratochv&#xed;l</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.09228">arXiv:2309.09228</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">A Hamiltonian path (cycle) in a graph is a path (cycle, respectively) which
passes through all of its vertices. The problems of deciding the existence of a
Hamiltonian cycle (path) in an input graph are well known to be NP-complete,
and restricted classes of graphs which allow for their polynomial-time
solutions are intensively investigated. Until very recently the complexity was
open even for graphs of independence number at most 3. So far unpublished
result of Jedli\v{c}kov\'{a} and Kratochv\'{\i}l [<a href="/abs/2309.09228">arXiv:2309.09228</a>] shows that
for every integer $k$, Hamiltonian path and cycle are polynomial-time solvable
in graphs of independence number bounded by $k$. As a companion structural
result, we determine explicit obstacles for the existence of a Hamiltonian path
for small values of $k$, namely for graphs of independence number 2, 3, and 4.
Identifying these obstacles in an input graph yields alternative
polynomial-time algorithms for Hamiltonian path and cycle with no large hidden
multiplicative constants.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03669" title="Abstract">arXiv:2403.03669</a> (cross-list from stat.ML) [<a href="/pdf/2403.03669" title="Download PDF">pdf</a>, <a href="/format/2403.03669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Algorithms on Manifolds through Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xia%2C+W">Weichun Xia</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+L">Lei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The existing research on spectral algorithms, applied within a Reproducing
Kernel Hilbert Space (RKHS), has primarily focused on general kernel functions,
often neglecting the inherent structure of the input feature space. Our paper
introduces a new perspective, asserting that input data are situated within a
low-dimensional manifold embedded in a higher-dimensional Euclidean space. We
study the convergence performance of spectral algorithms in the RKHSs,
specifically those generated by the heat kernels, known as diffusion spaces.
Incorporating the manifold structure of the input, we employ integral operator
techniques to derive tight convergence upper bounds concerning generalized
norms, which indicates that the estimators converge to the target function in
strong sense, entailing the simultaneous convergence of the function itself and
its derivatives. These bounds offer two significant advantages: firstly, they
are exclusively contingent on the intrinsic dimension of the input manifolds,
thereby providing a more focused analysis. Secondly, they enable the efficient
derivation of convergence rates for derivatives of any k-th order, all of which
can be accomplished within the ambit of the same spectral algorithms.
Furthermore, we establish minimax lower bounds to demonstrate the asymptotic
optimality of these conclusions in specific contexts. Our study confirms that
the spectral algorithms are practically significant in the broader context of
high-dimensional approximation.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03695" title="Abstract">arXiv:2403.03695</a> (cross-list from stat.ML) [<a href="/pdf/2403.03695" title="Download PDF">pdf</a>, <a href="/format/2403.03695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Phase Transition and Optimal PCA in Block-Structured Spiked  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mergny%2C+P">Pierre Mergny</a>, 
<a href="/search/stat?searchtype=author&query=Ko%2C+J">Justin Ko</a>, 
<a href="/search/stat?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">We discuss the inhomogeneous spiked Wigner model, a theoretical framework
recently introduced to study structured noise in various learning scenarios,
through the prism of random matrix theory, with a specific focus on its
spectral properties. Our primary objective is to find an optimal spectral
method and to extend the celebrated \cite{BBP} (BBP) phase transition criterion
-- well-known in the homogeneous case -- to our inhomogeneous,
block-structured, Wigner model. We provide a thorough rigorous analysis of a
transformed matrix and show that the transition for the appearance of 1) an
outlier outside the bulk of the limiting spectral distribution and 2) a
positive overlap between the associated eigenvector and the signal, occurs
precisely at the optimal threshold, making the proposed spectral method optimal
within the class of iterative methods for the inhomogeneous Wigner problem.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03702" title="Abstract">arXiv:2403.03702</a> (cross-list from stat.ML) [<a href="/pdf/2403.03702" title="Download PDF">pdf</a>, <a href="/format/2403.03702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online model error correction with neural networks: application to the  Integrated Forecasting System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Farchi%2C+A">Alban Farchi</a>, 
<a href="/search/stat?searchtype=author&query=Chrust%2C+M">Marcin Chrust</a>, 
<a href="/search/stat?searchtype=author&query=Bocquet%2C+M">Marc Bocquet</a>, 
<a href="/search/stat?searchtype=author&query=Bonavita%2C+M">Massimo Bonavita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, there has been significant progress in the development of
fully data-driven global numerical weather prediction models. These machine
learning weather prediction models have their strength, notably accuracy and
low computational requirements, but also their weakness: they struggle to
represent fundamental dynamical balances, and they are far from being suitable
for data assimilation experiments. Hybrid modelling emerges as a promising
approach to address these limitations. Hybrid models integrate a physics-based
core component with a statistical component, typically a neural network, to
enhance prediction capabilities. In this article, we propose to develop a model
error correction for the operational Integrated Forecasting System (IFS) of the
European Centre for Medium-Range Weather Forecasts using a neural network. The
neural network is initially pre-trained offline using a large dataset of
operational analyses and analysis increments. Subsequently, the trained network
is integrated into the IFS within the Object-Oriented Prediction System (OOPS)
so as to be used in data assimilation and forecast experiments. It is then
further trained online using a recently developed variant of weak-constraint
4D-Var. The results show that the pre-trained neural network already provides a
reliable model error correction, which translates into reduced forecast errors
in many conditions and that the online training further improves the accuracy
of the hybrid model in many conditions.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03720" title="Abstract">arXiv:2403.03720</a> (cross-list from physics.soc-ph) [<a href="/pdf/2403.03720" title="Download PDF">pdf</a>, <a href="/format/2403.03720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Criminal organizations exhibit hysteresis, resilience, and robustness by  balancing security and efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=van+Elteren%2C+C">Casper van Elteren</a>, 
<a href="/search/physics?searchtype=author&query=Vasconcelos%2C+V+V">V&#xed;tor V. Vasconcelos</a>, 
<a href="/search/physics?searchtype=author&query=Lees%2C+M">Mike Lees</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The interplay between criminal organizations and law enforcement disruption
strategies is crucial in criminology. Criminal enterprises, like legitimate
businesses, balance visibility and security to thrive. This study uses
evolutionary game theory to analyze criminal networks' dynamics, resilience to
interventions, and responses to external conditions. We find strong hysteresis
effects, challenging traditional deterrence-focused strategies. Optimal
thresholds for organization formation or dissolution are defined by these
effects. Stricter punishment doesn't always deter organized crime linearly.
Network structure, particularly link density and skill assortativity,
significantly influences organization formation and stability. These insights
advocate for adaptive policy-making and strategic law enforcement to
effectively disrupt criminal networks.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03761" title="Abstract">arXiv:2403.03761</a> (cross-list from quant-ph) [<a href="/pdf/2403.03761" title="Download PDF">pdf</a>, <a href="/format/2403.03761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized quantum comb and simpler circuits for reversing unknown  qubit-unitary operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Mo%2C+Y">Yin Mo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yu-Ao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yingjian Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+T">Tengxiang Lin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages including appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum comb is an essential tool for characterizing complex quantum
protocols in quantum information processing. In this work, we introduce PQComb,
a framework leveraging parameterized quantum circuits to explore the
capabilities of quantum combs for general quantum process transformation tasks
and beyond. By optimizing PQComb for time-reversal simulations of unknown
unitary evolutions, we develop a simpler protocol for unknown qubit unitary
inversion that reduces the ancilla qubit overhead from 6 to 3 compared to the
existing method in [Yoshida, Soeda, Murao, PRL 131, 120602, 2023]. This
demonstrates the utility of quantum comb structures and showcases PQComb's
potential for solving complex quantum tasks. Our results pave the way for
broader PQComb applications in quantum computing and quantum information,
emphasizing its versatility for tackling diverse problems in quantum machine
learning.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03767" title="Abstract">arXiv:2403.03767</a> (cross-list from physics.chem-ph) [<a href="/pdf/2403.03767" title="Download PDF">pdf</a>, <a href="/format/2403.03767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the Temperature Dependence of Surfactant CMCs Using Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Brozos%2C+C">Christoforos Brozos</a>, 
<a href="/search/physics?searchtype=author&query=Rittig%2C+J+G">Jan G. Rittig</a>, 
<a href="/search/physics?searchtype=author&query=Bhattacharya%2C+S">Sandip Bhattacharya</a>, 
<a href="/search/physics?searchtype=author&query=Akanny%2C+E">Elie Akanny</a>, 
<a href="/search/physics?searchtype=author&query=Kohlmann%2C+C">Christina Kohlmann</a>, 
<a href="/search/physics?searchtype=author&query=Mitsos%2C+A">Alexander Mitsos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The critical micelle concentration (CMC) of surfactant molecules is an
essential property for surfactant applications in industry. Recently, classical
QSPR and Graph Neural Networks (GNNs), a deep learning technique, have been
successfully applied to predict the CMC of surfactants at room temperature.
However, these models have not yet considered the temperature dependency of the
CMC, which is highly relevant for practical applications. We herein develop a
GNN model for temperature-dependent CMC prediction of surfactants. We collect
about 1400 data points from public sources for all surfactant classes, i.e.,
ionic, nonionic, and zwitterionic, at multiple temperatures. We test the
predictive quality of the model for following scenarios: i) when CMC data for
surfactants are present in the training of the model in at least one different
temperature, and ii) CMC data for surfactants are not present in the training,
i.e., generalizing to unseen surfactants. In both test scenarios, our model
exhibits a high predictive performance of R$^2 \geq $ 0.94 on test data. We
also find that the model performance varies by surfactant class. Finally, we
evaluate the model for sugar-based surfactants with complex molecular
structures, as these represent a more sustainable alternative to synthetic
surfactants and are therefore of great interest for future applications in the
personal and home care industries.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03771" title="Abstract">arXiv:2403.03771</a> (cross-list from eess.SP) [<a href="/pdf/2403.03771" title="Download PDF">pdf</a>, <a href="/format/2403.03771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Sparsity Pattern Learning Based Channel Estimation for Massive  MIMO-OTFS Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+K">Kuo Meng</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+S">Shaoshi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiao-Yang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Bu%2C+Y">Yan Bu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yurong Tang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jianhua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, accepted to appear on IEEE Transactions on Vehicular Technology, Mar. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a channel estimation scheme based on joint sparsity pattern
learning (JSPL) for massive multi-input multi-output (MIMO) orthogonal
time-frequency-space (OTFS) modulation aided systems. By exploiting the
potential joint sparsity of the delay-Doppler-angle (DDA) domain channel, the
channel estimation problem is transformed into a sparse recovery problem. To
solve it, we first apply the spike and slab prior model to iteratively estimate
the support set of the channel matrix, and a higher-accuracy parameter update
rule relying on the identified support set is introduced into the iteration.
Then the specific values of the channel elements corresponding to the support
set are estimated by the orthogonal matching pursuit (OMP) method. Both our
simulation results and analysis demonstrate that the proposed JSPL channel
estimation scheme achieves an improved performance over the representative
state-of-the-art baseline schemes, despite its reduced pilot overhead.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03775" title="Abstract">arXiv:2403.03775</a> (cross-list from physics.optics) [<a href="/pdf/2403.03775" title="Download PDF">pdf</a>, <a href="/ps/2403.03775" title="Download PostScript">ps</a>, <a href="/format/2403.03775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photonic-electronic spiking neuron with multi-modal and multi-wavelength  excitatory and inhibitory operation for high-speed neuromorphic sensing and  computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+W">Weikang Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Hejda%2C+M">Mat&#x11b;j Hejda</a>, 
<a href="/search/physics?searchtype=author&query=Al-Taai%2C+Q+R+A">Qusay Raghib Ali Al-Taai</a>, 
<a href="/search/physics?searchtype=author&query=Owen-Newns%2C+D">Dafydd Owen-Newns</a>, 
<a href="/search/physics?searchtype=author&query=Romeira%2C+B">Bruno Romeira</a>, 
<a href="/search/physics?searchtype=author&query=Figueiredo%2C+J+M+L">Jos&#xe9; M. L. Figueiredo</a>, 
<a href="/search/physics?searchtype=author&query=Robertson%2C+J">Joshua Robertson</a>, 
<a href="/search/physics?searchtype=author&query=Wasige%2C+E">Edward Wasige</a>, 
<a href="/search/physics?searchtype=author&query=Hurtado%2C+A">Antonio Hurtado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We report a multi-modal spiking neuron that allows optical and electronic
input and control, and wavelength-multiplexing operation, for use in novel
high-speed neuromorphic sensing and computing functionalities. The
photonic-electronic neuron is built with a micro-scale, nanostructure resonant
tunnelling diode (RTD) with photodetection (PD) capability. Leveraging the
advantageous intrinsic properties of this RTD-PD system, namely highly
nonlinear characteristics, photo-sensitivity, light-induced I-V curve shift,
and the ability to deliver excitable responses under electrical and optical
inputs, we successfully achieve flexible neuromorphic spike activation and
inhibition regimes through photonic-electrical control. We also demonstrate the
ability of this RTD-PD spiking sensing-processing neuron to operate under the
simultaneous arrival of multiple wavelength-multiplexed optical signals, due to
its large photodetection spectral window (covering the 1310 and 1550 nm telecom
wavelength bands). Our results highlight the potential of RTD
photonic-electronic neurons to reproduce multiple key excitatory and inhibitory
spiking regimes, at high speed (ns-rate spiking responses, with faster sub-ns
regimes theoretically predicted) and low energy (requiring only ~10 mV and ~150
microW, electrical and optical input amplitudes, respectively), similar in
nature to those commonly found in the biological neurons of the visual system
and the brain. This work offers a highly promising approach for the realisation
of high-speed, energy-efficient photonic-electronic spiking neurons and spiking
neural networks, enabling multi-modal and multi-wavelength operation for
sensing and information processing tasks. This work therefore paves the way for
innovative high-speed, photonic-electronic, and spike-based neuromorphic
sensing and computing systems and artificial intelligence hardware.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03811" title="Abstract">arXiv:2403.03811</a> (cross-list from stat.ML) [<a href="/pdf/2403.03811" title="Download PDF">pdf</a>, <a href="/format/2403.03811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentivized Learning in Principal-Agent Bandit Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Scheid%2C+A">Antoine Scheid</a>, 
<a href="/search/stat?searchtype=author&query=Tiapkin%2C+D">Daniil Tiapkin</a>, 
<a href="/search/stat?searchtype=author&query=Boursier%2C+E">Etienne Boursier</a>, 
<a href="/search/stat?searchtype=author&query=Capitaine%2C+A">Aymeric Capitaine</a>, 
<a href="/search/stat?searchtype=author&query=Mhamdi%2C+E+M+E">El Mahdi El Mhamdi</a>, 
<a href="/search/stat?searchtype=author&query=Moulines%2C+E">Eric Moulines</a>, 
<a href="/search/stat?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>, 
<a href="/search/stat?searchtype=author&query=Durmus%2C+A">Alain Durmus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work considers a repeated principal-agent bandit game, where the
principal can only interact with her environment through the agent. The
principal and the agent have misaligned objectives and the choice of action is
only left to the agent. However, the principal can influence the agent's
decisions by offering incentives which add up to his rewards. The principal
aims to iteratively learn an incentive policy to maximize her own total
utility. This framework extends usual bandit problems and is motivated by
several practical applications, such as healthcare or ecological taxation,
where traditionally used mechanism design theories often overlook the learning
aspect of the problem. We present nearly optimal (with respect to a horizon
$T$) learning algorithms for the principal's regret in both multi-armed and
linear contextual settings. Finally, we support our theoretical guarantees
through numerical experiments.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03816" title="Abstract">arXiv:2403.03816</a> (cross-list from stat.ML) [<a href="/pdf/2403.03816" title="Download PDF">pdf</a>, <a href="/format/2403.03816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Variance Reduction: Robust Bayesian Optimization of Black-Box  Simulators with Noise Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Miller%2C+J+J">John Joshua Miller</a>, 
<a href="/search/stat?searchtype=author&query=Mak%2C+S">Simon Mak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The optimization of a black-box simulator over control parameters
$\mathbf{x}$ arises in a myriad of scientific applications. In such
applications, the simulator often takes the form
$f(\mathbf{x},\boldsymbol{\theta})$, where $\boldsymbol{\theta}$ are parameters
that are uncertain in practice. Robust optimization aims to optimize the
objective $\mathbb{E}[f(\mathbf{x},\boldsymbol{\Theta})]$, where
$\boldsymbol{\Theta} \sim \mathcal{P}$ is a random variable that models
uncertainty on $\boldsymbol{\theta}$. For this, existing black-box methods
typically employ a two-stage approach for selecting the next point
$(\mathbf{x},\boldsymbol{\theta})$, where $\mathbf{x}$ and
$\boldsymbol{\theta}$ are optimized separately via different acquisition
functions. As such, these approaches do not employ a joint acquisition over
$(\mathbf{x},\boldsymbol{\theta})$, and thus may fail to fully exploit
control-to-noise interactions for effective robust optimization. To address
this, we propose a new Bayesian optimization method called Targeted Variance
Reduction (TVR). The TVR leverages a novel joint acquisition function over
$(\mathbf{x},\boldsymbol{\theta})$, which targets variance reduction on the
objective within the desired region of improvement. Under a Gaussian process
surrogate on $f$, the TVR acquisition can be evaluated in closed form, and
reveals an insightful exploration-exploitation-precision trade-off for robust
black-box optimization. The TVR can further accommodate a broad class of
non-Gaussian distributions on $\mathcal{P}$ via a careful integration of
normalizing flows. We demonstrate the improved performance of TVR over the
state-of-the-art in a suite of numerical experiments and an application to the
robust design of automobile brake discs under operational uncertainty.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03826" title="Abstract">arXiv:2403.03826</a> (cross-list from quant-ph) [<a href="/pdf/2403.03826" title="Download PDF">pdf</a>, <a href="/format/2403.03826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Gradient Descent in Variational Quantum Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Simon%2C+L">Lars Simon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eble%2C+H">Holger Eble</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kowalski%2C+H">Hagen-Henrik Kowalski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Radons%2C+M">Manuel Radons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this article we introduce an algorithm for mitigating the adverse effects
of noise on gradient descent in variational quantum algorithms. This is
accomplished by computing a {\emph{regularized}} local classical approximation
to the objective function at every gradient descent step. The computational
overhead of our algorithm is entirely classical, i.e., the number of circuit
evaluations is exactly the same as when carrying out gradient descent using the
parameter-shift rules. We empirically demonstrate the advantages offered by our
algorithm on randomized parametrized quantum circuits.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03849" title="Abstract">arXiv:2403.03849</a> (cross-list from eess.IV) [<a href="/pdf/2403.03849" title="Download PDF">pdf</a>, <a href="/format/2403.03849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedMamba: Vision Mamba for Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yue%2C+Y">Yubiao Yue</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhenzhang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical image classification is a very fundamental and crucial task in the
field of computer vision. These years, CNN-based and Transformer-based models
are widely used in classifying various medical images. Unfortunately, The
limitation of CNNs in long-range modeling capabilities prevent them from
effectively extracting fine-grained features in medical images , while
Transformers are hampered by their quadratic computational complexity. Recent
research has shown that the state space model (SSM) represented by Mamba can
efficiently model long-range interactions while maintaining linear
computational complexity. Inspired by this, we propose Vision Mamba for medical
image classification (MedMamba). More specifically, we introduce a novel
Conv-SSM module, which combines the local feature extraction ability of
convolutional layers with the ability of SSM to capture long-range dependency.
To demonstrate the potential of MedMamba, we conduct extensive experiments
using three publicly available medical datasets with different imaging
techniques (i.e., Kvasir (endoscopic images), FETAL_PLANES_DB (ultrasound
images) and Covid19-Pneumonia-Normal Chest X-Ray (X-ray images)) and two
private datasets built by ourselves. Experimental results show that the
proposed MedMamba performs well in detecting lesions in various medical images.
To the best of our knowledge, this is the first Vision Mamba tailored for
medical image classification. The purpose of this work is to establish a new
baseline for medical image classification tasks and provide valuable insights
for the future development of more efficient and effective SSM-based artificial
intelligence algorithms and application systems in the medical. Source code has
been available at https://github.com/YubiaoYue/MedMamba.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03850" title="Abstract">arXiv:2403.03850</a> (cross-list from stat.ML) [<a href="/pdf/2403.03850" title="Download PDF">pdf</a>, <a href="/format/2403.03850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal prediction for multi-dimensional time series by ellipsoidal  sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+H">Hanyang Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Conformal prediction (CP) has been a popular method for uncertainty
quantification because it is distribution-free, model-agnostic, and
theoretically sound. For forecasting problems in supervised learning, most CP
methods focus on building prediction intervals for univariate responses. In
this work, we develop a sequential CP method called $\texttt{MultiDimSPCI}$
that builds prediction regions for a multivariate response, especially in the
context of multivariate time series, which are not exchangeable. Theoretically,
we estimate finite-sample high-probability bounds on the conditional coverage
gap. Empirically, we demonstrate that $\texttt{MultiDimSPCI}$ maintains valid
coverage on a wide range of multivariate time series while producing smaller
prediction regions than CP and non-CP baselines.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03891" title="Abstract">arXiv:2403.03891</a> (cross-list from eess.IV) [<a href="/pdf/2403.03891" title="Download PDF">pdf</a>, <a href="/format/2403.03891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint multi-task learning improves weakly-supervised biomarker  prediction in computational pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nahhas%2C+O+S+M+E">Omar S. M. El Nahhas</a>, 
<a href="/search/eess?searchtype=author&query=W%C3%B6lflein%2C+G">Georg W&#xf6;lflein</a>, 
<a href="/search/eess?searchtype=author&query=Ligero%2C+M">Marta Ligero</a>, 
<a href="/search/eess?searchtype=author&query=Lenz%2C+T">Tim Lenz</a>, 
<a href="/search/eess?searchtype=author&query=van+Treeck%2C+M">Marko van Treeck</a>, 
<a href="/search/eess?searchtype=author&query=Khader%2C+F">Firas Khader</a>, 
<a href="/search/eess?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/eess?searchtype=author&query=Kather%2C+J+N">Jakob Nikolas Kather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Learning (DL) can predict biomarkers directly from digitized cancer
histology in a weakly-supervised setting. Recently, the prediction of
continuous biomarkers through regression-based DL has seen an increasing
interest. Nonetheless, clinical decision making often requires a categorical
outcome. Consequently, we developed a weakly-supervised joint multi-task
Transformer architecture which has been trained and evaluated on four public
patient cohorts for the prediction of two key predictive biomarkers,
microsatellite instability (MSI) and homologous recombination deficiency (HRD),
trained with auxiliary regression tasks related to the tumor microenvironment.
Moreover, we perform a comprehensive benchmark of 16 approaches of task
balancing for weakly-supervised joint multi-task learning in computational
pathology. Using our novel approach, we improve over the state-of-the-art area
under the receiver operating characteristic by +7.7% and +4.1%, as well as
yielding better clustering of latent embeddings by +8% and +5% for the
prediction of MSI and HRD in external cohorts, respectively.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03915" title="Abstract">arXiv:2403.03915</a> (cross-list from math.OC) [<a href="/pdf/2403.03915" title="Download PDF">pdf</a>, <a href="/format/2403.03915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Sensitive Mean Field Games with Common Noise: A Theoretical Study  with Applications to Interbank Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ren%2C+X+Y">Xin Yue Ren</a>, 
<a href="/search/math?searchtype=author&query=Firoozi%2C+D">Dena Firoozi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Probability (math.PR); Mathematical Finance (q-fin.MF); Risk Management (q-fin.RM)

</div>
<p class="mathjax">In this paper, we address linear-quadratic-Gaussian (LQG) risk-sensitive mean
field games (MFGs) with common noise. In this framework agents are exposed to a
common noise and aim to minimize an exponential cost functional that reflects
their risk sensitivity. We leverage the convex analysis method to derive the
optimal strategies of agents in the limit as the number of agents goes to
infinity. These strategies yield a Nash equilibrium for the limiting model. The
model is then applied to interbank markets, focusing on optimizing lending and
borrowing activities to assess systemic and individual bank risks when reserves
drop below a critical threshold. We employ Fokker-Planck equations and the
first hitting time method to formulate the overall probability of a bank or
market default. We observe that the risk-averse behavior of agents reduces the
probability of individual defaults and systemic risk, enhancing the resilience
of the financial system. Adopting a similar approach based on stochastic
Fokker-Planck equations, we further expand our analysis to investigate the
conditional probabilities of individual default under specific trajectories of
the common market shock.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03925" title="Abstract">arXiv:2403.03925</a> (cross-list from q-bio.NC) [<a href="/pdf/2403.03925" title="Download PDF">pdf</a>, <a href="/ps/2403.03925" title="Download PostScript">ps</a>, <a href="/format/2403.03925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consciousness qua Mortal Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kleiner%2C+J">Johannes Kleiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Computational functionalism posits that consciousness is a computation. Here
we show, perhaps surprisingly, that it cannot be a Turing computation. Rather,
computational functionalism implies that consciousness is a novel type of
computation that has recently been proposed by Geoffrey Hinton, called mortal
computation.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu,  7 Mar 24</h3>
<dl>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.13509" title="Abstract">arXiv:2107.13509</a> (replaced) [<a href="/pdf/2107.13509" title="Download PDF">pdf</a>, <a href="/format/2107.13509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Who in XAI: How AI Background Shapes Perceptions of AI Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehsan%2C+U">Upol Ehsan</a>, 
<a href="/search/cs?searchtype=author&query=Passi%2C+S">Samir Passi</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q+V">Q. Vera Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+L">Larry Chan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">I-Hsiang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+M">Michael Muller</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M+O">Mark O. Riedl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM CHI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.01002" title="Abstract">arXiv:2109.01002</a> (replaced) [<a href="/pdf/2109.01002" title="Download PDF">pdf</a>, <a href="/format/2109.01002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocTer: Documentation Guided Fuzzing for Testing Deep Learning API  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+D">Danning Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yitong Li</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mijung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+V">Hung Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Lin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+M+W">Michael W. Godfrey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA) in 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11155" title="Abstract">arXiv:2203.11155</a> (replaced) [<a href="/pdf/2203.11155" title="Download PDF">pdf</a>, <a href="/ps/2203.11155" title="Download PostScript">ps</a>, <a href="/format/2203.11155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Neural Network with Density Matrix for Question Answering and  Classical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X+Q">X. Q. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T+L">T. L. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03014" title="Abstract">arXiv:2205.03014</a> (replaced) [<a href="/pdf/2205.03014" title="Download PDF">pdf</a>, <a href="/ps/2205.03014" title="Download PostScript">ps</a>, <a href="/format/2205.03014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Generalized Linear Models Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+R">Raman Arora</a>, 
<a href="/search/cs?searchtype=author&query=Bassily%2C+R">Raef Bassily</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n%2C+C">Crist&#xf3;bal Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Menart%2C+M">Michael Menart</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+E">Enayat Ullah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01726" title="Abstract">arXiv:2206.01726</a> (replaced) [<a href="/pdf/2206.01726" title="Download PDF">pdf</a>, <a href="/ps/2206.01726" title="Download PostScript">ps</a>, <a href="/format/2206.01726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average-case analysis of the Gaussian Elimination with Partial Pivoting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/math?searchtype=author&query=Tikhomirov%2C+K">Konstantin Tikhomirov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> a revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09618" title="Abstract">arXiv:2206.09618</a> (replaced) [<a href="/pdf/2206.09618" title="Download PDF">pdf</a>, <a href="/format/2206.09618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A reduced order model for domain decompositions with non-conforming  interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zappon%2C+E">Elena Zappon</a>, 
<a href="/search/math?searchtype=author&query=Manzoni%2C+A">Andrea Manzoni</a>, 
<a href="/search/math?searchtype=author&query=Gervasio%2C+P">Paola Gervasio</a>, 
<a href="/search/math?searchtype=author&query=Quarteroni%2C+A">Alfio Quarteroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 28 figures, 2 tables, 4 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10223" title="Abstract">arXiv:2207.10223</a> (replaced) [<a href="/pdf/2207.10223" title="Download PDF">pdf</a>, <a href="/format/2207.10223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness Testing: A Comprehensive Survey and Analysis of Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenpeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hort%2C+M">Max Hort</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Software Engineering and Methodology (TOSEM 2024). Please include TOSEM in any citations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00225" title="Abstract">arXiv:2209.00225</a> (replaced) [<a href="/pdf/2209.00225" title="Download PDF">pdf</a>, <a href="/format/2209.00225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STDEN: Towards Physics-Guided Neural Networks for Traffic Flow  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiahao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36th AAAI Conference on Artificial Intelligence (AAAI 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00381" title="Abstract">arXiv:2209.00381</a> (replaced) [<a href="/pdf/2209.00381" title="Download PDF">pdf</a>, <a href="/format/2209.00381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemSegDepth: A Combined Model for Semantic Segmentation and Depth  Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lagos%2C+J+P">Juan Pablo Lagos</a>, 
<a href="/search/cs?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 17th VISIGRAPP 2022 - Volume 5: VISAPP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07714" title="Abstract">arXiv:2209.07714</a> (replaced) [<a href="/pdf/2209.07714" title="Download PDF">pdf</a>, <a href="/format/2209.07714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational quantum algorithm for measurement extraction from the  Navier-Stokes, Einstein, Maxwell, B-type, Lin-Tsien, Camassa-Holm, DSW, H-S,  KdV-B, non-homogeneous KdV, generalized KdV, KdV, translational KdV, sKdV,  B-L and Airy equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Rigas%2C+P">Pete Rigas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 185 pages, v4: modified wording on Page 3; removed a few plots of solutions and quantum circuit diagrams; reformatted computations throughout entire paper. Presentations discussing this work are available at <a href="https://www.youtube.com/watch?v=bFSI6PIt6xI">this https URL</a>, <a href="https://www.youtube.com/watch?v=_YxFLMFZdPA">this https URL</a>, <a href="https://www.youtube.com/watch?v=4uhOTIPJwrU">this https URL</a>, and <a href="https://www.youtube.com/watch?v=p0t4gWVaPs4">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Numerical Analysis (math.NA); Optimization and Control (math.OC); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08349" title="Abstract">arXiv:2209.08349</a> (replaced) [<a href="/pdf/2209.08349" title="Download PDF">pdf</a>, <a href="/format/2209.08349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unguided Self-exploration in Narrow Spaces with Safety Region Enhanced  Reinforcement Learning for Ackermann-steering Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhaofeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weisong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13797" title="Abstract">arXiv:2209.13797</a> (replaced) [<a href="/pdf/2209.13797" title="Download PDF">pdf</a>, <a href="/format/2209.13797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCB-RandNet: Rethinking Random Sampling for LIDAR Semantic Segmentation  in Autonomous Driving Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">XianFeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Huixian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dehong He</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guoqiang Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2024. Code: <a href="https://github.com/huixiancheng/PCB-RandNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00212" title="Abstract">arXiv:2210.00212</a> (replaced) [<a href="/pdf/2210.00212" title="Download PDF">pdf</a>, <a href="/format/2210.00212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantum Agnostic Improper Learning of Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chatterjee%2C+S">Sagnik Chatterjee</a>, 
<a href="/search/quant-ph?searchtype=author&query=SAPV%2C+T">Tharrmashastha SAPV</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bera%2C+D">Debajyoti Bera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01988" title="Abstract">arXiv:2210.01988</a> (replaced) [<a href="/pdf/2210.01988" title="Download PDF">pdf</a>, <a href="/ps/2210.01988" title="Download PostScript">ps</a>, <a href="/format/2210.01988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bicoptor: Two-round Secure Three-party Non-linear Computation without  Preprocessing for Privacy-preserving Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lijing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hongrui Cui</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qingrui Song</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 44th IEEE Symposium on Security and Privacy (S&amp;P 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09475" title="Abstract">arXiv:2210.09475</a> (replaced) [<a href="/pdf/2210.09475" title="Download PDF">pdf</a>, <a href="/format/2210.09475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIMP: Foundation Model-Informed Message Passing for Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+A">Syed Asad Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Haoran Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+B">Benjamin Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Caro%2C+J+O">Josue Ortega Caro</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+A+H+O">Antonio H. O. Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Zappala%2C+E">Emanuele Zappala</a>, 
<a href="/search/cs?searchtype=author&query=Bagherian%2C+M">Maryam Bagherian</a>, 
<a href="/search/cs?searchtype=author&query=Averill%2C+C">Christopher Averill</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+C+G">Chadi G. Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Karbasi%2C+A">Amin Karbasi</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=Brbic%2C+M">Maria Brbic</a>, 
<a href="/search/cs?searchtype=author&query=Dhodapkar%2C+R+M">Rahul Madhav Dhodapkar</a>, 
<a href="/search/cs?searchtype=author&query=van+Dijk%2C+D">David van Dijk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages (11 + 5 pages appendix). 5 figures and 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10971" title="Abstract">arXiv:2210.10971</a> (replaced) [<a href="/pdf/2210.10971" title="Download PDF">pdf</a>, <a href="/ps/2210.10971" title="Download PostScript">ps</a>, <a href="/format/2210.10971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Settings for Cryptocurrency Trading Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhou%2C+Y">Youzhou Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12776" title="Abstract">arXiv:2210.12776</a> (replaced) [<a href="/pdf/2210.12776" title="Download PDF">pdf</a>, <a href="/format/2210.12776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metadata Privacy Beyond Tunneling for Instant Messaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nelson%2C+B">Boel Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Pagnin%2C+E">Elena Pagnin</a>, 
<a href="/search/cs?searchtype=author&query=Askarov%2C+A">Aslan Askarov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at the 9th IEEE European Symposium on Security and Privacy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06753" title="Abstract">arXiv:2211.06753</a> (replaced) [<a href="/pdf/2211.06753" title="Download PDF">pdf</a>, <a href="/format/2211.06753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seamful XAI: Operationalizing Seamful Design in Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehsan%2C+U">Upol Ehsan</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q+V">Q. Vera Liao</a>, 
<a href="/search/cs?searchtype=author&query=Passi%2C+S">Samir Passi</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M+O">Mark O. Riedl</a>, 
<a href="/search/cs?searchtype=author&query=Daume%2C+H">Hal Daume III</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11940" title="Abstract">arXiv:2211.11940</a> (replaced) [<a href="/pdf/2211.11940" title="Download PDF">pdf</a>, <a href="/format/2211.11940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision-making with Speculative Opponent Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 27 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13093" title="Abstract">arXiv:2211.13093</a> (replaced) [<a href="/pdf/2211.13093" title="Download PDF">pdf</a>, <a href="/format/2211.13093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Marker-less Rapid Aerial Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+E">Erik Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Cangan%2C+B+G">Barnabas Gavin Cangan</a>, 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023. Video <a href="https://www.youtube.com/watch?v=6hbhAT4l90w">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), Detroit, MI, USA, 2023, pp. 6395-6402
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04475" title="Abstract">arXiv:2212.04475</a> (replaced) [<a href="/pdf/2212.04475" title="Download PDF">pdf</a>, <a href="/format/2212.04475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiahao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Boren Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th AAAI Conference on Artificial Intelligence (AAAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14180" title="Abstract">arXiv:2212.14180</a> (replaced) [<a href="/pdf/2212.14180" title="Download PDF">pdf</a>, <a href="/format/2212.14180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanDepth: Joint Panoptic Segmentation and Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lagos%2C+J">Juan Lagos</a>, 
<a href="/search/cs?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00406" title="Abstract">arXiv:2301.00406</a> (replaced) [<a href="/pdf/2301.00406" title="Download PDF">pdf</a>, <a href="/format/2301.00406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curvature regularization for Non-line-of-sight Imaging from  Under-sampled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Rui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Juntian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feihu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuping Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04456" title="Abstract">arXiv:2301.04456</a> (replaced) [<a href="/pdf/2301.04456" title="Download PDF">pdf</a>, <a href="/format/2301.04456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterization for a generic construction of bent functions and its  consequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jinjie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+H">Haibin Kan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jie Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lijing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changhui Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10369" title="Abstract">arXiv:2301.10369</a> (replaced) [<a href="/pdf/2301.10369" title="Download PDF">pdf</a>, <a href="/format/2301.10369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Fractional Inference via Re-Parametrization &amp; Interpolation  between Tree-Re-Weighted- and Belief Propagation- Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behjoo%2C+H">Hamidreza Behjoo</a>, 
<a href="/search/cs?searchtype=author&query=Chertkov%2C+M">Michael Chertkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11146" title="Abstract">arXiv:2301.11146</a> (replaced) [<a href="/pdf/2301.11146" title="Download PDF">pdf</a>, <a href="/format/2301.11146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-step interpretable modeling of Intensive Care Acquired Infections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lancia%2C+G">Giacomo Lancia</a>, 
<a href="/search/stat?searchtype=author&query=Varkila%2C+M">Meri Varkila</a>, 
<a href="/search/stat?searchtype=author&query=Cremer%2C+O">Olaf Cremer</a>, 
<a href="/search/stat?searchtype=author&query=Spitoni%2C+C">Cristian Spitoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01477" title="Abstract">arXiv:2302.01477</a> (replaced) [<a href="/pdf/2302.01477" title="Download PDF">pdf</a>, <a href="/ps/2302.01477" title="Download PostScript">ps</a>, <a href="/format/2302.01477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reduction-based Framework for Sequential Decision Making with Delayed  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunchang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neurips 2023. arXiv admin note: text overlap with <a href="/abs/2110.14555">arXiv:2110.14555</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01815" title="Abstract">arXiv:2302.01815</a> (replaced) [<a href="/pdf/2302.01815" title="Download PDF">pdf</a>, <a href="/ps/2302.01815" title="Download PostScript">ps</a>, <a href="/format/2302.01815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Capacity Modification for Many-To-One Matching Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiehua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cs%C3%A1ji%2C+G">Gergely Cs&#xe1;ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended abstract accepted at AAMAS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03658" title="Abstract">arXiv:2302.03658</a> (replaced) [<a href="/pdf/2302.03658" title="Download PDF">pdf</a>, <a href="/ps/2302.03658" title="Download PostScript">ps</a>, <a href="/format/2302.03658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planted Bipartite Graph Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rotenberg%2C+A">Asaf Rotenberg</a>, 
<a href="/search/cs?searchtype=author&query=Huleihel%2C+W">Wasim Huleihel</a>, 
<a href="/search/cs?searchtype=author&query=Shayevitz%2C+O">Ofer Shayevitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07649" title="Abstract">arXiv:2302.07649</a> (replaced) [<a href="/pdf/2302.07649" title="Download PDF">pdf</a>, <a href="/ps/2302.07649" title="Download PostScript">ps</a>, <a href="/format/2302.07649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Independence Postulate, the Many Worlds Theory, and Constructor  Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Epstein%2C+S">Samuel Epstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08545" title="Abstract">arXiv:2302.08545</a> (replaced) [<a href="/pdf/2302.08545" title="Download PDF">pdf</a>, <a href="/format/2302.08545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghao Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Basat%2C+R+B">Ran Ben Basat</a> (2), 
<a href="/search/cs?searchtype=author&query=Vargaftik%2C+S">Shay Vargaftik</a> (3), 
<a href="/search/cs?searchtype=author&query=Lao%2C+C">ChonLam Lao</a> (1), 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kevin Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Mitzenmacher%2C+M">Michael Mitzenmacher</a> (1), 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Minlan Yu</a> (1) ((1) Harvard University, (2) University College London, (3) VMware Research)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages body, 21 pages total
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13616" title="Abstract">arXiv:2302.13616</a> (replaced) [<a href="/pdf/2302.13616" title="Download PDF">pdf</a>, <a href="/format/2302.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ResQPASS: an algorithm for bounded variable linear least squares with  asymptotic Krylov convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Symoens%2C+B">Bas Symoens</a>, 
<a href="/search/math?searchtype=author&query=Vanroose%2C+W">Wim Vanroose</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14595" title="Abstract">arXiv:2302.14595</a> (replaced) [<a href="/pdf/2302.14595" title="Download PDF">pdf</a>, <a href="/format/2302.14595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MateRobot: Material Recognition in Wearable Robotics for People with  Visual Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICRA 2024. The source code is publicly available at <a href="https://junweizheng93.github.io/publications/MATERobot/MATERobot.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00286" title="Abstract">arXiv:2303.00286</a> (replaced) [<a href="/pdf/2303.00286" title="Download PDF">pdf</a>, <a href="/ps/2303.00286" title="Download PostScript">ps</a>, <a href="/format/2303.00286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treat Different Negatives Differently: Enriching Loss Functions with  Domain and Range Constraints for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubert%2C+N">Nicolas Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+A">Armelle Brun</a>, 
<a href="/search/cs?searchtype=author&query=Monticolo%2C+D">Davy Monticolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ESWC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05076" title="Abstract">arXiv:2303.05076</a> (replaced) [<a href="/pdf/2303.05076" title="Download PDF">pdf</a>, <a href="/format/2303.05076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pedestrian Attribute Editing for Gait Recognition and Anonymization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jingzhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dingqiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08763" title="Abstract">arXiv:2303.08763</a> (replaced) [<a href="/pdf/2303.08763" title="Download PDF">pdf</a>, <a href="/format/2303.08763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convergent Numerical Algorithm for $&#x3b1;$-Dissipative Solutions of  the Hunter--Saxton Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Christiansen%2C+T">Thomas Christiansen</a>, 
<a href="/search/math?searchtype=author&query=Grunert%2C+K">Katrin Grunert</a>, 
<a href="/search/math?searchtype=author&query=Nordli%2C+A">Anders Nordli</a>, 
<a href="/search/math?searchtype=author&query=Solem%2C+S">Susanne Solem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 9 figures. Added a new figure, some minor changes to the text, and corrected some typos
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Sci. Comput. 99, 44 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11525" title="Abstract">arXiv:2303.11525</a> (replaced) [<a href="/pdf/2303.11525" title="Download PDF">pdf</a>, <a href="/format/2303.11525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse-IFT: Sparse Iso-FLOP Transformations for Maximizing Training  Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thangarasa%2C+V">Vithursan Thangarasa</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Shreyas Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Lie%2C+S">Sean Lie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures (Main Paper) + 9 pages (Supplementary Material)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14718" title="Abstract">arXiv:2303.14718</a> (replaced) [<a href="/pdf/2303.14718" title="Download PDF">pdf</a>, <a href="/format/2303.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Control of a Small Humanoid Equipped with Flight Unit and  Wheels for Multimodal Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sugihara%2C+K">Kazuki Sugihara</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Moju Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nishio%2C+T">Takuzumi Nishio</a>, 
<a href="/search/cs?searchtype=author&query=Makabe%2C+T">Tasuku Makabe</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 17 figures. Accepted by IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01343" title="Abstract">arXiv:2304.01343</a> (replaced) [<a href="/pdf/2304.01343" title="Download PDF">pdf</a>, <a href="/format/2304.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A study of distributionally robust mixed-integer programming with  Wasserstein metric: on the value of incomplete data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ketkov%2C+S+S">Sergey S. Ketkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages; minor mistakes are fixed in Definition 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09697" title="Abstract">arXiv:2304.09697</a> (replaced) [<a href="/pdf/2304.09697" title="Download PDF">pdf</a>, <a href="/ps/2304.09697" title="Download PostScript">ps</a>, <a href="/format/2304.09697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Calculus for Scoped Effects &amp; Handlers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosman%2C+R">Roger Bosman</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Berg%2C+B">Birthe van den Berg</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Schrijvers%2C+T">Tom Schrijvers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09949" title="Abstract">arXiv:2304.09949</a> (replaced) [<a href="/pdf/2304.09949" title="Download PDF">pdf</a>, <a href="/format/2304.09949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Temporal Distribution and Spatial Correlation for Universal  Moving Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanfang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenqiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xichen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Anup Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13670" title="Abstract">arXiv:2304.13670</a> (replaced) [<a href="/pdf/2304.13670" title="Download PDF">pdf</a>, <a href="/format/2304.13670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgery Scheduling in Flexible Operating Rooms by using a Convex  Surrogate Model of Second-Stage Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Almoghrabi%2C+M+M">Mohammed Majthoub Almoghrabi</a>, 
<a href="/search/math?searchtype=author&query=Sagnol%2C+G">Guillaume Sagnol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14185" title="Abstract">arXiv:2304.14185</a> (replaced) [<a href="/pdf/2304.14185" title="Download PDF">pdf</a>, <a href="/format/2304.14185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterNet: A Perception-Based Clustering Model for Scattered Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartwig%2C+S">Sebastian Hartwig</a>, 
<a href="/search/cs?searchtype=author&query=van+Onzenoodt%2C+C">Christian van Onzenoodt</a>, 
<a href="/search/cs?searchtype=author&query=Engel%2C+D">Dominik Engel</a>, 
<a href="/search/cs?searchtype=author&query=Hermosilla%2C+P">Pedro Hermosilla</a>, 
<a href="/search/cs?searchtype=author&query=Ropinski%2C+T">Timo Ropinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently, this manuscript is under revision at CGF
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01883" title="Abstract">arXiv:2305.01883</a> (replaced) [<a href="/pdf/2305.01883" title="Download PDF">pdf</a>, <a href="/format/2305.01883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight CNN-Transformer Model for Learning Traveling Salesman  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Minseop Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeseung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jibum Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05338" title="Abstract">arXiv:2305.05338</a> (replaced) [<a href="/pdf/2305.05338" title="Download PDF">pdf</a>, <a href="/format/2305.05338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Cyber-Resiliency of DER-based SmartGrid: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengxiang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhenyong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+P">Pudong Ge</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+R">Ruilong Deng</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jiming Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09329" title="Abstract">arXiv:2305.09329</a> (replaced) [<a href="/pdf/2305.09329" title="Download PDF">pdf</a>, <a href="/format/2305.09329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CWTM: Leveraging Contextualized Word Embeddings from BERT for Neural  Topic Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>, 
<a href="/search/cs?searchtype=author&query=Procter%2C+R">Rob Procter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted to appear at the LREC-COLING 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11290" title="Abstract">arXiv:2305.11290</a> (replaced) [<a href="/pdf/2305.11290" title="Download PDF">pdf</a>, <a href="/format/2305.11290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Massively Scalable Inverse Reinforcement Learning in Google Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barnes%2C+M">Matt Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Abueg%2C+M">Matthew Abueg</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+O+F">Oliver F. Lange</a>, 
<a href="/search/cs?searchtype=author&query=Deeds%2C+M">Matt Deeds</a>, 
<a href="/search/cs?searchtype=author&query=Trader%2C+J">Jason Trader</a>, 
<a href="/search/cs?searchtype=author&query=Molitor%2C+D">Denali Molitor</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>, 
<a href="/search/cs?searchtype=author&query=O%27Banion%2C+S">Shawn O&#x27;Banion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16793" title="Abstract">arXiv:2305.16793</a> (replaced) [<a href="/pdf/2305.16793" title="Download PDF">pdf</a>, <a href="/format/2305.16793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive Mechanism for Uncertain Tasks under Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xikun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+C">Chenhao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCdder%2C+B">Boris D&#xfc;dder</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiqin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haiming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18231" title="Abstract">arXiv:2305.18231</a> (replaced) [<a href="/pdf/2305.18231" title="Download PDF">pdf</a>, <a href="/format/2305.18231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity Image Compression with Score-based Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hoogeboom%2C+E">Emiel Hoogeboom</a>, 
<a href="/search/eess?searchtype=author&query=Agustsson%2C+E">Eirikur Agustsson</a>, 
<a href="/search/eess?searchtype=author&query=Mentzer%2C+F">Fabian Mentzer</a>, 
<a href="/search/eess?searchtype=author&query=Versari%2C+L">Luca Versari</a>, 
<a href="/search/eess?searchtype=author&query=Toderici%2C+G">George Toderici</a>, 
<a href="/search/eess?searchtype=author&query=Theis%2C+L">Lucas Theis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18647" title="Abstract">arXiv:2305.18647</a> (replaced) [<a href="/pdf/2305.18647" title="Download PDF">pdf</a>, <a href="/ps/2305.18647" title="Download PostScript">ps</a>, <a href="/format/2305.18647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Alternate Proof of Near-Optimal Light Spanners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SOSA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00266" title="Abstract">arXiv:2306.00266</a> (replaced) [<a href="/pdf/2306.00266" title="Download PDF">pdf</a>, <a href="/format/2306.00266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A polynomial-time iterative algorithm for random graph matching with  non-vanishing correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhangsong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00292" title="Abstract">arXiv:2306.00292</a> (replaced) [<a href="/pdf/2306.00292" title="Download PDF">pdf</a>, <a href="/ps/2306.00292" title="Download PostScript">ps</a>, <a href="/format/2306.00292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainable AI Regulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hacker%2C+P">Philipp Hacker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Privacy Law Scholars Conference 2023; Common Market Law Review (forthcoming)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02280" title="Abstract">arXiv:2306.02280</a> (replaced) [<a href="/pdf/2306.02280" title="Download PDF">pdf</a>, <a href="/ps/2306.02280" title="Download PostScript">ps</a>, <a href="/format/2306.02280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degree-$M$ Bethe and Sinkhorn Permanent Based Bounds on the Permanent of  a Non-negative Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+Y">Yuwen Huang</a>, 
<a href="/search/math?searchtype=author&query=Kashyap%2C+N">Navin Kashyap</a>, 
<a href="/search/math?searchtype=author&query=Vontobel%2C+P+O">Pascal O. Vontobel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by the IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03487" title="Abstract">arXiv:2306.03487</a> (replaced) [<a href="/pdf/2306.03487" title="Download PDF">pdf</a>, <a href="/format/2306.03487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compiling Quantum Circuits for Dynamically Field-Programmable Neutral  Atoms Array Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Tan%2C+D+B">Daniel Bochen Tan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bluvstein%2C+D">Dolev Bluvstein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lukin%2C+M+D">Mikhail D. Lukin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cong%2C+J">Jason Cong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version accepted by Quantum. 21 pages, 9 figures, 7 tables. An extended abstract was presented at the 41st International Conference on Computer-Aided Design (ICCAD '22)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05366" title="Abstract">arXiv:2306.05366</a> (replaced) [<a href="/pdf/2306.05366" title="Download PDF">pdf</a>, <a href="/format/2306.05366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ordinal Potential-based Player Rating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vadori%2C+N">Nelson Vadori</a>, 
<a href="/search/cs?searchtype=author&query=Savani%2C+R">Rahul Savani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07272" title="Abstract">arXiv:2306.07272</a> (replaced) [<a href="/pdf/2306.07272" title="Download PDF">pdf</a>, <a href="/format/2306.07272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Composed Text-Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12698" title="Abstract">arXiv:2306.12698</a> (replaced) [<a href="/pdf/2306.12698" title="Download PDF">pdf</a>, <a href="/format/2306.12698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interferometric lensless imaging: rank-one projections of image  frequencies with speckle illuminations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leblanc%2C+O">Olivier Leblanc</a>, 
<a href="/search/eess?searchtype=author&query=Hofer%2C+M">Mathias Hofer</a>, 
<a href="/search/eess?searchtype=author&query=Sivankutty%2C+S">Siddharth Sivankutty</a>, 
<a href="/search/eess?searchtype=author&query=Rigneault%2C+H">Herv&#xe9; Rigneault</a>, 
<a href="/search/eess?searchtype=author&query=Jacques%2C+L">Laurent Jacques</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, keywords: lensless imaging, rank-one projections, interferometric matrix, inverse problem, computational imaging, single-pixel
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Computational Imaging, vol. 10, pp. 208-222,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Information Theory (cs.IT); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17486" title="Abstract">arXiv:2306.17486</a> (replaced) [<a href="/pdf/2306.17486" title="Download PDF">pdf</a>, <a href="/format/2306.17486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multigrid-Augmented Deep Learning Preconditioners for the Helmholtz  Equation using Compact Implicit Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lerer%2C+B">Bar Lerer</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Yair%2C+I">Ido Ben-Yair</a>, 
<a href="/search/cs?searchtype=author&query=Treister%2C+E">Eran Treister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in SIAM Journal on Scientific Computing Copper Mountain Special Section on Multigrid Methods 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01174" title="Abstract">arXiv:2307.01174</a> (replaced) [<a href="/pdf/2307.01174" title="Download PDF">pdf</a>, <a href="/ps/2307.01174" title="Download PostScript">ps</a>, <a href="/format/2307.01174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymous and Copy-Robust Delegations for Liquid Democracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Utke%2C+M">Markus Utke</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Kraepelin%2C+U">Ulrike Schmidt-Kraepelin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06894" title="Abstract">arXiv:2307.06894</a> (replaced) [<a href="/pdf/2307.06894" title="Download PDF">pdf</a>, <a href="/ps/2307.06894" title="Download PostScript">ps</a>, <a href="/format/2307.06894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a resolution of the spin alignment problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Alhejji%2C+M+A">Mohammad A. Alhejji</a>, 
<a href="/search/quant-ph?searchtype=author&query=Knill%2C+E">Emanuel Knill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v1: 36 pages. v2: includes a no-conflict of interest statement. v3: 39 pages, a revision with streamlined proofs, accepted for publication in Communications in Mathematical Physics. arXiv admin note: substantial text overlap with <a href="/abs/2304.13771">arXiv:2304.13771</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08424" title="Abstract">arXiv:2307.08424</a> (replaced) [<a href="/pdf/2307.08424" title="Download PDF">pdf</a>, <a href="/format/2307.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rongke Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yizhi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kaitian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Q">Qianqian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaolei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10043" title="Abstract">arXiv:2307.10043</a> (replaced) [<a href="/pdf/2307.10043" title="Download PDF">pdf</a>, <a href="/format/2307.10043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A moment approach for entropy solutions of parameter-dependent  hyperbolic conservation laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cardoen%2C+C">Cl&#xe9;ment Cardoen</a>, 
<a href="/search/math?searchtype=author&query=Marx%2C+S">Swann Marx</a>, 
<a href="/search/math?searchtype=author&query=Nouy%2C+A">Anthony Nouy</a>, 
<a href="/search/math?searchtype=author&query=Seguin%2C+N">Nicolas Seguin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14223" title="Abstract">arXiv:2307.14223</a> (replaced) [<a href="/pdf/2307.14223" title="Download PDF">pdf</a>, <a href="/format/2307.14223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewriting and Completeness of Sum-Over-Paths in Dyadic Fragments of  Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vilmart%2C+R">Renaud Vilmart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2205.02600">arXiv:2205.02600</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00071" title="Abstract">arXiv:2308.00071</a> (replaced) [<a href="/pdf/2308.00071" title="Download PDF">pdf</a>, <a href="/format/2308.00071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Stereotype Identification through Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jacob-Junqi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Dige%2C+O">Omkar Dige</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+D">David Emerson</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+F+K">Faiza Khan Khattak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01154" title="Abstract">arXiv:2308.01154</a> (replaced) [<a href="/pdf/2308.01154" title="Download PDF">pdf</a>, <a href="/format/2308.01154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic with Language Models: from Memorization to Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maltoni%2C+D">Davide Maltoni</a>, 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+M">Matteo Ferrara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02117" title="Abstract">arXiv:2308.02117</a> (replaced) [<a href="/pdf/2308.02117" title="Download PDF">pdf</a>, <a href="/format/2308.02117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQGraph: Rethinking Graph Representation Space for Bridging GNNs and  MLPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Ling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Ye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Shenda Hong</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+W">Wei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. Code: <a href="https://github.com/YangLing0818/VQGraph">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03417" title="Abstract">arXiv:2308.03417</a> (replaced) [<a href="/pdf/2308.03417" title="Download PDF">pdf</a>, <a href="/format/2308.03417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PURL: Safe and Effective Sanitization of Link Decoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munir%2C+S">Shaoor Munir</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+P">Patrick Lee</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Shafiq%2C+Z">Zubair Shafiq</a>, 
<a href="/search/cs?searchtype=author&query=Siby%2C+S">Sandra Siby</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03686" title="Abstract">arXiv:2308.03686</a> (replaced) [<a href="/pdf/2308.03686" title="Download PDF">pdf</a>, <a href="/format/2308.03686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Benton%2C+J">Joe Benton</a>, 
<a href="/search/stat?searchtype=author&query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
<a href="/search/stat?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>, 
<a href="/search/stat?searchtype=author&query=Deligiannidis%2C+G">George Deligiannidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04100" title="Abstract">arXiv:2308.04100</a> (replaced) [<a href="/pdf/2308.04100" title="Download PDF">pdf</a>, <a href="/format/2308.04100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Still Secret Ballot: The Limited Privacy Cost of Transparent  Election Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuriwaki%2C+S">Shiro Kuriwaki</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+J+B">Jeffrey B. Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Morse%2C+M">Michael Morse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version with new analyses and terminology of local revelation. 50 pages, 14 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04921" title="Abstract">arXiv:2308.04921</a> (replaced) [<a href="/pdf/2308.04921" title="Download PDF">pdf</a>, <a href="/format/2308.04921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to induce regularization in linear models: A guide to  reparametrizing gradient flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chou%2C+H">Hung-Hsu Chou</a>, 
<a href="/search/math?searchtype=author&query=Maly%2C+J">Johannes Maly</a>, 
<a href="/search/math?searchtype=author&query=St%C3%B6ger%2C+D">Dominik St&#xf6;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05027" title="Abstract">arXiv:2308.05027</a> (replaced) [<a href="/pdf/2308.05027" title="Download PDF">pdf</a>, <a href="/format/2308.05027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AbDiffuser: Full-Atom Generation of in vitro Functioning Antibodies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Martinkus%2C+K">Karolis Martinkus</a>, 
<a href="/search/q-bio?searchtype=author&query=Ludwiczak%2C+J">Jan Ludwiczak</a>, 
<a href="/search/q-bio?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/q-bio?searchtype=author&query=Liang%2C+W">Wei-Ching Liang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lafrance-Vanasse%2C+J">Julien Lafrance-Vanasse</a>, 
<a href="/search/q-bio?searchtype=author&query=Hotzel%2C+I">Isidro Hotzel</a>, 
<a href="/search/q-bio?searchtype=author&query=Rajpal%2C+A">Arvind Rajpal</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+Y">Yan Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=Bonneau%2C+R">Richard Bonneau</a>, 
<a href="/search/q-bio?searchtype=author&query=Gligorijevic%2C+V">Vladimir Gligorijevic</a>, 
<a href="/search/q-bio?searchtype=author&query=Loukas%2C+A">Andreas Loukas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09778" title="Abstract">arXiv:2308.09778</a> (replaced) [<a href="/pdf/2308.09778" title="Download PDF">pdf</a>, <a href="/format/2308.09778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajabi%2C+N">Navid Rajabi</a>, 
<a href="/search/cs?searchtype=author&query=Kosecka%2C+J">Jana Kosecka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to DMLR @ ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11155" title="Abstract">arXiv:2308.11155</a> (replaced) [<a href="/pdf/2308.11155" title="Download PDF">pdf</a>, <a href="/format/2308.11155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond MD17: the reactive xxMD dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pengmei%2C+Z">Zihan Pengmei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yinan Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, many figures. Data available at <a href="https://github.com/zpengmei/xxMD">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Data 11, 222 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12061" title="Abstract">arXiv:2308.12061</a> (replaced) [<a href="/pdf/2308.12061" title="Download PDF">pdf</a>, <a href="/format/2308.12061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HarvestNet: A Dataset for Detecting Smallholder Farming Activity Using  Harvest Piles and Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jonathan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Elmustafa%2C+A">Amna Elmustafa</a>, 
<a href="/search/cs?searchtype=author&query=Weldegebriel%2C+L">Liya Weldegebriel</a>, 
<a href="/search/cs?searchtype=author&query=Negash%2C+E">Emnet Negash</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Richard Lee</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chenlin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Lobell%2C+D">David Lobell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16761" title="Abstract">arXiv:2308.16761</a> (replaced) [<a href="/pdf/2308.16761" title="Download PDF">pdf</a>, <a href="/format/2308.16761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Category Trees for ID-Based Recommendation: Exploring the Power  of Differentiable Vector Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiaren Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TheWebConf 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01243" title="Abstract">arXiv:2309.01243</a> (replaced) [<a href="/pdf/2309.01243" title="Download PDF">pdf</a>, <a href="/format/2309.01243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Normal Distributions Indistinguishability Spectrum and its  Application to Privacy-Preserving Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Magdon-Ismail%2C+M">Malik Magdon-Ismail</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zikas%2C+V">Vassilis Zikas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02585" title="Abstract">arXiv:2309.02585</a> (replaced) [<a href="/pdf/2309.02585" title="Download PDF">pdf</a>, <a href="/format/2309.02585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structurally Informed Data Assimilation Approach for Nonlinear Partial  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+T">Tongtong Li</a>, 
<a href="/search/math?searchtype=author&query=Gelb%2C+A">Anne Gelb</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+Y">Yoonsang Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03493" title="Abstract">arXiv:2309.03493</a> (replaced) [<a href="/pdf/2309.03493" title="Download PDF">pdf</a>, <a href="/format/2309.03493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM3D: Segment Anything Model in Volumetric Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/eess?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/eess?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+B">Brijesh Patel</a>, 
<a href="/search/eess?searchtype=author&query=Choudhary%2C+A">Arabinda Choudhary</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03685" title="Abstract">arXiv:2309.03685</a> (replaced) [<a href="/pdf/2309.03685" title="Download PDF">pdf</a>, <a href="/format/2309.03685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyGraft: Configurable Generation of Synthetic Schemas and Knowledge  Graphs at Your Fingertips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubert%2C+N">Nicolas Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=d%27Aquin%2C+M">Mathieu d&#x27;Aquin</a>, 
<a href="/search/cs?searchtype=author&query=Monticolo%2C+D">Davy Monticolo</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+A">Armelle Brun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ESWC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04909" title="Abstract">arXiv:2309.04909</a> (replaced) [<a href="/pdf/2309.04909" title="Download PDF">pdf</a>, <a href="/ps/2309.04909" title="Download PostScript">ps</a>, <a href="/format/2309.04909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bicoptor 2.0: Addressing Challenges in Probabilistic Truncation for  Enhanced Privacy-Preserving Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lijing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qingrui Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Su Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianggui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05317" title="Abstract">arXiv:2309.05317</a> (replaced) [<a href="/pdf/2309.05317" title="Download PDF">pdf</a>, <a href="/format/2309.05317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Koopman prior for data assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frion%2C+A">Anthony Frion</a>, 
<a href="/search/cs?searchtype=author&query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="/search/cs?searchtype=author&query=Mura%2C+M+D">Mauro Dalla Mura</a>, 
<a href="/search/cs?searchtype=author&query=Tochon%2C+G">Guillaume Tochon</a>, 
<a href="/search/cs?searchtype=author&query=Bey%2C+A+A+E">Abdeldjalil A&#xef;ssa El Bey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07579" title="Abstract">arXiv:2309.07579</a> (replaced) [<a href="/pdf/2309.07579" title="Download PDF">pdf</a>, <a href="/format/2309.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Preserving Transformers for Sequences of SPD Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seraphim%2C+M">Mathieu Seraphim</a>, 
<a href="/search/cs?searchtype=author&query=Lechervy%2C+A">Alexis Lechervy</a>, 
<a href="/search/cs?searchtype=author&query=Yger%2C+F">Florian Yger</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+L">Luc Brun</a>, 
<a href="/search/cs?searchtype=author&query=Etard%2C+O">Olivier Etard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New year, new version! (updated template, minimal additions - including two new references)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08776" title="Abstract">arXiv:2309.08776</a> (replaced) [<a href="/pdf/2309.08776" title="Download PDF">pdf</a>, <a href="/format/2309.08776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected Task-Specific Layers for Multi-Task Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J+S">Josselin Somerville Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09553" title="Abstract">arXiv:2309.09553</a> (replaced) [<a href="/pdf/2309.09553" title="Download PDF">pdf</a>, <a href="/format/2309.09553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal-Story: Local Causal Attention Utilizing Parameter-Efficient  Tuning For Visual Story Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tianyi Song</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiuxin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 International Conference on Acoustics, Speech and Signal Processing(ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10323" title="Abstract">arXiv:2309.10323</a> (replaced) [<a href="/pdf/2309.10323" title="Download PDF">pdf</a>, <a href="/format/2309.10323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Exposed Passwords on Honeyword Efficacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zonghao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+L">Lujo Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Reiter%2C+M+K">Michael K. Reiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The full paper of "The Impact of Exposed Passwords on Honeyword Efficacy" accepted by the 33rd USENIX Security Symposium, August 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11238" title="Abstract">arXiv:2309.11238</a> (replaced) [<a href="/pdf/2309.11238" title="Download PDF">pdf</a>, <a href="/ps/2309.11238" title="Download PostScript">ps</a>, <a href="/format/2309.11238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample- and computationally efficient data-driven predictive control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alsalti%2C+M">Mohammad Alsalti</a>, 
<a href="/search/eess?searchtype=author&query=Barkey%2C+M">Manuel Barkey</a>, 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted for presentation at the 22nd European Control Conference (ECC) in Stockholm, Sweden
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12251" title="Abstract">arXiv:2309.12251</a> (replaced) [<a href="/pdf/2309.12251" title="Download PDF">pdf</a>, <a href="/format/2309.12251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Planning Optimal Trajectories for Mobile Manipulators under End-effector  Trajectory Continuity Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang-Nam Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12380" title="Abstract">arXiv:2309.12380</a> (replaced) [<a href="/pdf/2309.12380" title="Download PDF">pdf</a>, <a href="/ps/2309.12380" title="Download PostScript">ps</a>, <a href="/format/2309.12380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods for generating and evaluating synthetic longitudinal patient  data: a systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Perkonoja%2C+K">Katariina Perkonoja</a>, 
<a href="/search/stat?searchtype=author&query=Auranen%2C+K">Kari Auranen</a>, 
<a href="/search/stat?searchtype=author&query=Virta%2C+J">Joni Virta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12543" title="Abstract">arXiv:2309.12543</a> (replaced) [<a href="/pdf/2309.12543" title="Download PDF">pdf</a>, <a href="/format/2309.12543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Batched Distance Computation for Time-Optimal Safe Path  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+S">Shohei Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages. Accepted to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13297" title="Abstract">arXiv:2309.13297</a> (replaced) [<a href="/pdf/2309.13297" title="Download PDF">pdf</a>, <a href="/format/2309.13297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for  Aspect-Based Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chebolu%2C+S+U+S">Siva Uday Sampreeth Chebolu</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>, 
<a href="/search/cs?searchtype=author&query=Lipka%2C+N">Nedim Lipka</a>, 
<a href="/search/cs?searchtype=author&query=Solorio%2C+T">Thamar Solorio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in COLING/LREC-2024. Camera Ready submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13734" title="Abstract">arXiv:2309.13734</a> (replaced) [<a href="/pdf/2309.13734" title="Download PDF">pdf</a>, <a href="/format/2309.13734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruickshank%2C+I+J">Iain J. Cruickshank</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ACM Transactions on Intelligent Systems and Technology, Special Issue on Evaluations of Large Language Models. 28 Pages, 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13786" title="Abstract">arXiv:2309.13786</a> (replaced) [<a href="/pdf/2309.13786" title="Download PDF">pdf</a>, <a href="/format/2309.13786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Free Statistical Dispersion Control for Societal  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zollo%2C+T+P">Thomas P. Zollo</a>, 
<a href="/search/cs?searchtype=author&query=Snell%2C+J+C">Jake C. Snell</a>, 
<a href="/search/cs?searchtype=author&query=Pitassi%2C+T">Toniann Pitassi</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS as spotlight (top 3% among submissions)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14209" title="Abstract">arXiv:2309.14209</a> (replaced) [<a href="/pdf/2309.14209" title="Download PDF">pdf</a>, <a href="/format/2309.14209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Driving Policy Optimization with Closed-Loop Individualized  Curricula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Haoyi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yizhou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xingjian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianming Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14872" title="Abstract">arXiv:2309.14872</a> (replaced) [<a href="/pdf/2309.14872" title="Download PDF">pdf</a>, <a href="/format/2309.14872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directional Texture Editing for 3D Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingnan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiangjing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://shengqiliu1.github.io/ITEM3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16219" title="Abstract">arXiv:2309.16219</a> (replaced) [<a href="/pdf/2309.16219" title="Download PDF">pdf</a>, <a href="/format/2309.16219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensorless Estimation of Contact Using Deep-Learning for Human-Robot  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shilin Shan</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version accepted to ICRA 2024, 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16960" title="Abstract">arXiv:2309.16960</a> (replaced) [<a href="/pdf/2309.16960" title="Download PDF">pdf</a>, <a href="/format/2309.16960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Generating Explanations for Reinforcement Learning Policies: An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuasa%2C+M">Mikihisa Yuasa</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H+T">Huy T. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Sreenivas%2C+R+S">Ramavarapu S. Sreenivas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00194" title="Abstract">arXiv:2310.00194</a> (replaced) [<a href="/pdf/2310.00194" title="Download PDF">pdf</a>, <a href="/format/2310.00194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Prefrontal Cortex-inspired Architecture for Planning in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Webb%2C+T">Taylor Webb</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S+S">Shanka Subhra Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Krabach%2C+B">Brian Krabach</a>, 
<a href="/search/cs?searchtype=author&query=Momennejad%2C+I">Ida Momennejad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00354" title="Abstract">arXiv:2310.00354</a> (replaced) [<a href="/pdf/2310.00354" title="Download PDF">pdf</a>, <a href="/format/2310.00354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Dentify: Deep learning for proximal caries detection on bitewing  x-ray -- HUNT4 Oral Health Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Frutos%2C+J+P">Javier P&#xe9;rez de Frutos</a>, 
<a href="/search/cs?searchtype=author&query=Helland%2C+R+H">Ragnhild Holden Helland</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+S">Shreya Desai</a>, 
<a href="/search/cs?searchtype=author&query=Nymoen%2C+L+C">Line Cathrine Nymoen</a>, 
<a href="/search/cs?searchtype=author&query=Lang%C3%B8%2C+T">Thomas Lang&#xf8;</a>, 
<a href="/search/cs?searchtype=author&query=Remman%2C+T">Theodor Remman</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+A">Abhijit Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figure, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01986" title="Abstract">arXiv:2310.01986</a> (replaced) [<a href="/pdf/2310.01986" title="Download PDF">pdf</a>, <a href="/ps/2310.01986" title="Download PostScript">ps</a>, <a href="/format/2310.01986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Vision-Based Tactile Sensing System for Multimodal Contact Information  Perception via Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guoyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanzhi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhibin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiali Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinming Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03379" title="Abstract">arXiv:2310.03379</a> (replaced) [<a href="/pdf/2310.03379" title="Download PDF">pdf</a>, <a href="/format/2310.03379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Reinforcement Learning via Hierarchical Adaptive Chance-Constraint  Safeguards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaorun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuokai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tairan He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Binhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuhao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Liang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03572" title="Abstract">arXiv:2310.03572</a> (replaced) [<a href="/pdf/2310.03572" title="Download PDF">pdf</a>, <a href="/format/2310.03572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Multi-Fidelity Neural Network Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davis%2C+O">Owen Davis</a>, 
<a href="/search/cs?searchtype=author&query=Motamed%2C+M">Mohammad Motamed</a>, 
<a href="/search/cs?searchtype=author&query=Tempone%2C+R">Raul Tempone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03668" title="Abstract">arXiv:2310.03668</a> (replaced) [<a href="/pdf/2310.03668" title="Download PDF">pdf</a>, <a href="/format/2310.03668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sainz%2C+O">Oscar Sainz</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Ferrero%2C+I">Iker Garc&#xed;a-Ferrero</a>, 
<a href="/search/cs?searchtype=author&query=Agerri%2C+R">Rodrigo Agerri</a>, 
<a href="/search/cs?searchtype=author&query=de+Lacalle%2C+O+L">Oier Lopez de Lacalle</a>, 
<a href="/search/cs?searchtype=author&query=Rigau%2C+G">German Rigau</a>, 
<a href="/search/cs?searchtype=author&query=Agirre%2C+E">Eneko Agirre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The Twelfth International Conference on Learning Representations - ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04687" title="Abstract">arXiv:2310.04687</a> (replaced) [<a href="/pdf/2310.04687" title="Download PDF">pdf</a>, <a href="/format/2310.04687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Attacks on Latent Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Boyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chumeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04799" title="Abstract">arXiv:2310.04799</a> (replaced) [<a href="/pdf/2310.04799" title="Download PDF">pdf</a>, <a href="/format/2310.04799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chat Vector: A Simple Approach to Equip LLMs with Instruction Following  and Model Alignment in New Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shih-Cheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pin-Zu Li</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+Y">Yu-Chi Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kuang-Ming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y+T">Yu Tung Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+S">Shih-Kai Hsiao</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+R+T">Richard Tzong-Han Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10023" title="Abstract">arXiv:2310.10023</a> (replaced) [<a href="/pdf/2310.10023" title="Download PDF">pdf</a>, <a href="/format/2310.10023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-BBS: Global Localization for 3D Point Cloud Scan Matching Using  Branch-and-Bound Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aoki%2C+K">Koki Aoki</a>, 
<a href="/search/cs?searchtype=author&query=Koide%2C+K">Kenji Koide</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+S">Shuji Oishi</a>, 
<a href="/search/cs?searchtype=author&query=Yokozuka%2C+M">Masashi Yokozuka</a>, 
<a href="/search/cs?searchtype=author&query=Banno%2C+A">Atsuhiko Banno</a>, 
<a href="/search/cs?searchtype=author&query=Meguro%2C+J">Junichi Meguro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Robotics and Automation (ICRA2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12357" title="Abstract">arXiv:2310.12357</a> (replaced) [<a href="/pdf/2310.12357" title="Download PDF">pdf</a>, <a href="/format/2310.12357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Code Analysis: Do LLMs Really Do Their Job?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chongzhou Fang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+N">Ning Miao</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+S">Shaurya Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Ruijie Fang</a>, 
<a href="/search/cs?searchtype=author&query=Asmita">Asmita</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+R">Ryan Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Nazari%2C+N">Najmeh Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Homayoun%2C+H">Houman Homayoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Usenix Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13225" title="Abstract">arXiv:2310.13225</a> (replaced) [<a href="/pdf/2310.13225" title="Download PDF">pdf</a>, <a href="/format/2310.13225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Neural Network Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sehanobish%2C+A">Arijit Sehanobish</a>, 
<a href="/search/cs?searchtype=author&query=Choromanski%2C+K">Krzysztof Choromanski</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunfan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Avinava Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Likhosherstov%2C+V">Valerii Likhosherstov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14328" title="Abstract">arXiv:2310.14328</a> (replaced) [<a href="/pdf/2310.14328" title="Download PDF">pdf</a>, <a href="/format/2310.14328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Key Leasing for PKE and FHE with a Classical Lessor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chardouvelis%2C+O">Orestis Chardouvelis</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vipul Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aayush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor revisions on parameters in the construction. Revised proof Theorem 10.6 proof. Added Seciton 5.2.1 to help with proof
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14814" title="Abstract">arXiv:2310.14814</a> (replaced) [<a href="/pdf/2310.14814" title="Download PDF">pdf</a>, <a href="/format/2310.14814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Ensemble Diversity for Robust Self-Training in the Presence  of Sample Selection Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Odonnat%2C+A">Ambroise Odonnat</a>, 
<a href="/search/cs?searchtype=author&query=Feofanov%2C+V">Vasilii Feofanov</a>, 
<a href="/search/cs?searchtype=author&query=Redko%2C+I">Ievgen Redko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024, Valencia, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14985" title="Abstract">arXiv:2310.14985</a> (replaced) [<a href="/pdf/2310.14985" title="Download PDF">pdf</a>, <a href="/format/2310.14985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Based Agent Society Investigation: Collaboration and Confrontation  in Avalon Gameplay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yihuai Lan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiqiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Deheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E">Ee-Peng Lim</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19515" title="Abstract">arXiv:2310.19515</a> (replaced) [<a href="/pdf/2310.19515" title="Download PDF">pdf</a>, <a href="/format/2310.19515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based nowcasting of radar composites from satellite images  for severe weather
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=K%C3%BC%C3%A7%C3%BCk%2C+%C3%87">&#xc7;a&#x11f;lar K&#xfc;&#xe7;&#xfc;k</a>, 
<a href="/search/physics?searchtype=author&query=Giannakos%2C+A">Apostolos Giannakos</a>, 
<a href="/search/physics?searchtype=author&query=Schneider%2C+S">Stefan Schneider</a>, 
<a href="/search/physics?searchtype=author&query=Jann%2C+A">Alexander Jann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, and further supplementary figures. Accepted to Artificial Intelligence for Earth Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20172" title="Abstract">arXiv:2310.20172</a> (replaced) [<a href="/pdf/2310.20172" title="Download PDF">pdf</a>, <a href="/format/2310.20172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Binary Systems Waveform Generation with Generative Pre-trained  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/gr-qc?searchtype=author&query=Shi%2C+R">Ruijun Shi</a>, 
<a href="/search/gr-qc?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/gr-qc?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/gr-qc?searchtype=author&query=Cao%2C+Z">Zhoujian Cao</a>, 
<a href="/search/gr-qc?searchtype=author&query=Ren%2C+Z">Zhixiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Relativity and Quantum Cosmology (gr-qc)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20707" title="Abstract">arXiv:2310.20707</a> (replaced) [<a href="/pdf/2310.20707" title="Download PDF">pdf</a>, <a href="/format/2310.20707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What&#x27;s In My Big Data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elazar%2C+Y">Yanai Elazar</a>, 
<a href="/search/cs?searchtype=author&query=Bhagia%2C+A">Akshita Bhagia</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+I">Ian Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=Suhr%2C+A">Alane Suhr</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+P">Pete Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+D">Dirk Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sameer Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hanna Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jesse Dodge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024 spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00369" title="Abstract">arXiv:2311.00369</a> (replaced) [<a href="/pdf/2311.00369" title="Download PDF">pdf</a>, <a href="/format/2311.00369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct System Identification of Dynamical Networks with Partial  Measurements: a Maximum Likelihood Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=da+Mata%2C+J+V+G">Jo&#xe3;o Victor Galv&#xe3;o da Mata</a>, 
<a href="/search/eess?searchtype=author&query=Hansson%2C+A">Anders Hansson</a>, 
<a href="/search/eess?searchtype=author&query=Andersen%2C+M+S">Martin S. Andersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03260" title="Abstract">arXiv:2311.03260</a> (replaced) [<a href="/pdf/2311.03260" title="Download PDF">pdf</a>, <a href="/format/2311.03260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Coupled Oscillators to Graph Neural Networks: Reducing  Over-smoothing via a Kuramoto Model-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+H">Hirotada Honda</a>, 
<a href="/search/cs?searchtype=author&query=Sano%2C+T">Takashi Sano</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Shugo Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+M">Tan M. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06874" title="Abstract">arXiv:2311.06874</a> (replaced) [<a href="/pdf/2311.06874" title="Download PDF">pdf</a>, <a href="/format/2311.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Charging Coordination of Electric Trucks with Limited  Charging Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuchao Li</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A5rtensson%2C+J">Jonas M&#xe5;rtensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper for ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07277" title="Abstract">arXiv:2311.07277</a> (replaced) [<a href="/pdf/2311.07277" title="Download PDF">pdf</a>, <a href="/format/2311.07277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaCCD: Adaptive Semantic Contrasts Discovery Based Cross Lingual  Adaptation for Code Clone Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yangkai Du</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07565" title="Abstract">arXiv:2311.07565</a> (replaced) [<a href="/pdf/2311.07565" title="Download PDF">pdf</a>, <a href="/format/2311.07565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration via linearly perturbed loss minimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janz%2C+D">David Janz</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ayoub%2C+A">Alex Ayoub</a>, 
<a href="/search/cs?searchtype=author&query=Szepesv%C3%A1ri%2C+C">Csaba Szepesv&#xe1;ri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08376" title="Abstract">arXiv:2311.08376</a> (replaced) [<a href="/pdf/2311.08376" title="Download PDF">pdf</a>, <a href="/ps/2311.08376" title="Download PostScript">ps</a>, <a href="/format/2311.08376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble sampling for linear bandits: small ensembles suffice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Janz%2C+D">David Janz</a>, 
<a href="/search/stat?searchtype=author&query=Litvak%2C+A+E">Alexander E. Litvak</a>, 
<a href="/search/stat?searchtype=author&query=Szepesv%C3%A1ri%2C+C">Csaba Szepesv&#xe1;ri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09393" title="Abstract">arXiv:2311.09393</a> (replaced) [<a href="/pdf/2311.09393" title="Download PDF">pdf</a>, <a href="/format/2311.09393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic  Oblivious Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qianchuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Delaware%2C+B">Benjamin Delaware</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11016" title="Abstract">arXiv:2311.11016</a> (replaced) [<a href="/pdf/2311.11016" title="Download PDF">pdf</a>, <a href="/format/2311.11016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SNI-SLAM: Semantic Neural Implicit SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Siting Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+H">Hermann Blum</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Liang Song</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12472" title="Abstract">arXiv:2311.12472</a> (replaced) [<a href="/pdf/2311.12472" title="Download PDF">pdf</a>, <a href="/format/2311.12472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiahao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yue He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14339" title="Abstract">arXiv:2311.14339</a> (replaced) [<a href="/pdf/2311.14339" title="Download PDF">pdf</a>, <a href="/format/2311.14339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Concept-based Interpretability of Skin Lesion Diagnosis using  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patr%C3%ADcio%2C+C">Cristiano Patr&#xed;cio</a>, 
<a href="/search/cs?searchtype=author&query=Teixeira%2C+L+F">Lu&#xed;s F. Teixeira</a>, 
<a href="/search/cs?searchtype=author&query=Neves%2C+J+C">Jo&#xe3;o C. Neves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14479" title="Abstract">arXiv:2311.14479</a> (replaced) [<a href="/pdf/2311.14479" title="Download PDF">pdf</a>, <a href="/format/2311.14479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlled Text Generation via Language Model Arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dekoninck%2C+J">Jasper Dekoninck</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marc Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Beurer-Kellner%2C+L">Luca Beurer-Kellner</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14920" title="Abstract">arXiv:2311.14920</a> (replaced) [<a href="/pdf/2311.14920" title="Download PDF">pdf</a>, <a href="/format/2311.14920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DECap: Towards Generalized Explicit Caption Editing via Diffusion  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15707" title="Abstract">arXiv:2311.15707</a> (replaced) [<a href="/pdf/2311.15707" title="Download PDF">pdf</a>, <a href="/format/2311.15707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Dekun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR2024. Github Page: <a href="https://github.com/JiehongLin/SAM-6D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17695" title="Abstract">arXiv:2311.17695</a> (replaced) [<a href="/pdf/2311.17695" title="Download PDF">pdf</a>, <a href="/format/2311.17695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Text-to-Image Diffusion via Fair Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lijie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17841" title="Abstract">arXiv:2311.17841</a> (replaced) [<a href="/pdf/2311.17841" title="Download PDF">pdf</a>, <a href="/ps/2311.17841" title="Download PostScript">ps</a>, <a href="/format/2311.17841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast list-decoding of univariate multiplicity and folded Reed-Solomon  codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+R">Rohan Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Harsha%2C+P">Prahladh Harsha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Mrinal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+A">Ashutosh Shankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02483" title="Abstract">arXiv:2312.02483</a> (replaced) [<a href="/pdf/2312.02483" title="Download PDF">pdf</a>, <a href="/format/2312.02483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EtC: Temporal Boundary Expand then Clarify for Weakly Supervised Video  Grounding with Multimodal Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guozhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xinpeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">De Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02725" title="Abstract">arXiv:2312.02725</a> (replaced) [<a href="/pdf/2312.02725" title="Download PDF">pdf</a>, <a href="/format/2312.02725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R3D-SWIN:Use Shifted Window Attention for Single-View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meihua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=li%2C+z">zehuan li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Shanshan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mengxi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> being consider to patter recognition letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02731" title="Abstract">arXiv:2312.02731</a> (replaced) [<a href="/pdf/2312.02731" title="Download PDF">pdf</a>, <a href="/format/2312.02731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-LGP: Dynamic Logic-Geometric Program for Reactive Task and Motion  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Teng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Razmjoo%2C+A">Amirreza Razmjoo</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05409" title="Abstract">arXiv:2312.05409</a> (replaced) [<a href="/pdf/2312.05409" title="Download PDF">pdf</a>, <a href="/format/2312.05409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Training of Foundation Models for Wearable Biosignals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbaspourazad%2C+S">Salar Abbaspourazad</a>, 
<a href="/search/cs?searchtype=author&query=Elachqar%2C+O">Oussama Elachqar</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+A+C">Andrew C. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Emrani%2C+S">Saba Emrani</a>, 
<a href="/search/cs?searchtype=author&query=Nallasamy%2C+U">Udhyakumar Nallasamy</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+I">Ian Shapiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready version for ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07932" title="Abstract">arXiv:2312.07932</a> (replaced) [<a href="/pdf/2312.07932" title="Download PDF">pdf</a>, <a href="/format/2312.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Image Classification Framework Based on Variational Quantum  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yixiong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10187" title="Abstract">arXiv:2312.10187</a> (replaced) [<a href="/pdf/2312.10187" title="Download PDF">pdf</a>, <a href="/format/2312.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSRNet: Simple Framework for Real-time ECG Anomaly Detection with  Multimodal Time and Spectrogram Restoration Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/eess?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/eess?searchtype=author&query=Phan%2C+T">Thinh Phan</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/eess?searchtype=author&query=Patel%2C+B">Brijesh Patel</a>, 
<a href="/search/eess?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/eess?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12869" title="Abstract">arXiv:2312.12869</a> (replaced) [<a href="/pdf/2312.12869" title="Download PDF">pdf</a>, <a href="/format/2312.12869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Projected Bellman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vincent%2C+T">Th&#xe9;o Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Metelli%2C+A+M">Alberto Maria Metelli</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+B">Boris Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Restelli%2C+M">Marcello Restelli</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the National Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14197" title="Abstract">arXiv:2312.14197</a> (replaced) [<a href="/pdf/2312.14197" title="Download PDF">pdf</a>, <a href="/format/2312.14197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking and Defending Against Indirect Prompt Injection Attacks on  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yueqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kiciman%2C+E">Emre Kiciman</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangzhong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangzhao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17285" title="Abstract">arXiv:2312.17285</a> (replaced) [<a href="/pdf/2312.17285" title="Download PDF">pdf</a>, <a href="/format/2312.17285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Distributed Representations of Concepts in Deep Neural  Networks without Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wonjoon Chang</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Dahee Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaesik Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AAAI2024. First two authors contributed equally. The code is available at <a href="https://github.com/daheekwon/RDR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01673" title="Abstract">arXiv:2401.01673</a> (replaced) [<a href="/pdf/2401.01673" title="Download PDF">pdf</a>, <a href="/format/2401.01673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coded Beam Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiumo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yongli Yan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Linglong Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In this paper, we introduce channel coding theory into hierarchical beam training and propose a beam training scheme called coded beam training. By leveraging the error-correcting capability of channel codes, the proposed coded beam training method can enable reliable beam training performance for remote users with low SNR, while keeping training overhead low
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02880" title="Abstract">arXiv:2401.02880</a> (replaced) [<a href="/pdf/2401.02880" title="Download PDF">pdf</a>, <a href="/format/2401.02880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lotto: Secure Participant Selection against Adversarial Servers in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhifeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shiqi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruichuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted to USENIX Security '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03093" title="Abstract">arXiv:2401.03093</a> (replaced) [<a href="/pdf/2401.03093" title="Download PDF">pdf</a>, <a href="/ps/2401.03093" title="Download PostScript">ps</a>, <a href="/format/2401.03093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicitly explainable AI solution to the AI black box problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalmykov%2C+V+L">V. L. Kalmykov</a>, 
<a href="/search/cs?searchtype=author&query=Kalmykov%2C+L+V">L.V. Kalmykov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 1 figure, 70 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Populations and Evolution (q-bio.PE)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03407" title="Abstract">arXiv:2401.03407</a> (replaced) [<a href="/pdf/2401.03407" title="Download PDF">pdf</a>, <a href="/format/2401.03407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilateral Reference for High-Resolution Dichotomous Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Peng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dehong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Laaksonen%2C+J">Jorma Laaksonen</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add the link to codes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04560" title="Abstract">arXiv:2401.04560</a> (replaced) [<a href="/pdf/2401.04560" title="Download PDF">pdf</a>, <a href="/format/2401.04560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-shifted remote photoplethysmography for estimating heart rate and  blood pressure from facial video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+G">Gyutae Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+J">Sang Jun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04575" title="Abstract">arXiv:2401.04575</a> (replaced) [<a href="/pdf/2401.04575" title="Download PDF">pdf</a>, <a href="/format/2401.04575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual  Concept Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yatong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+U">Utsav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+A">Apaar Shanker</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Parajuli%2C+S">Samyak Parajuli</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+E">Erhan Bas</a>, 
<a href="/search/cs?searchtype=author&query=Filipovic%2C+I">Isidora Filipovic</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+A+N">Amelia N. Chu</a>, 
<a href="/search/cs?searchtype=author&query=Fomitcheva%2C+E+D">Eugenia D Fomitcheva</a>, 
<a href="/search/cs?searchtype=author&query=Branson%2C+E">Elliot Branson</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Aerin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06401" title="Abstract">arXiv:2401.06401</a> (replaced) [<a href="/e-print/2401.06401" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DevEval: Evaluating Code Generation in Practical Software Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunfei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huanyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanshen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiazheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yihong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengfei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are re-checking this benchmark and repeating related experiments. New versions of DevEval will be released later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07342" title="Abstract">arXiv:2401.07342</a> (replaced) [<a href="/pdf/2401.07342" title="Download PDF">pdf</a>, <a href="/format/2401.07342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Said What? An Automated Approach to Analyzing Speech in Preschool  Classrooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+A">Anchen Sun</a>, 
<a href="/search/eess?searchtype=author&query=Londono%2C+J+J">Juan J Londono</a>, 
<a href="/search/eess?searchtype=author&query=Elbaum%2C+B">Batya Elbaum</a>, 
<a href="/search/eess?searchtype=author&query=Estrada%2C+L">Luis Estrada</a>, 
<a href="/search/eess?searchtype=author&query=Lazo%2C+R+J">Roberto Jose Lazo</a>, 
<a href="/search/eess?searchtype=author&query=Vitale%2C+L">Laura Vitale</a>, 
<a href="/search/eess?searchtype=author&query=Villasanti%2C+H+G">Hugo Gonzalez Villasanti</a>, 
<a href="/search/eess?searchtype=author&query=Fusaroli%2C+R">Riccardo Fusaroli</a>, 
<a href="/search/eess?searchtype=author&query=Perry%2C+L+K">Lynn K Perry</a>, 
<a href="/search/eess?searchtype=author&query=Messinger%2C+D+S">Daniel S Messinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 3 tables, The paper has been accepted to 2024 IEEE International Conference on Development and Learning (ICDL) as a full oral presentation and will appear in the ICDL proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09027" title="Abstract">arXiv:2401.09027</a> (replaced) [<a href="/pdf/2401.09027" title="Download PDF">pdf</a>, <a href="/ps/2401.09027" title="Download PostScript">ps</a>, <a href="/format/2401.09027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Su%2C+Z">Zheng-Yao Su</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tsai%2C+M">Ming-Chung Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09340" title="Abstract">arXiv:2401.09340</a> (replaced) [<a href="/pdf/2401.09340" title="Download PDF">pdf</a>, <a href="/format/2401.09340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Baoxiong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huangyue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xuesong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10557" title="Abstract">arXiv:2401.10557</a> (replaced) [<a href="/pdf/2401.10557" title="Download PDF">pdf</a>, <a href="/format/2401.10557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newton&#x27;s method and its hybrid with machine learning for Navier-Stokes  Darcy Models discretized by mixed element methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+J">Jianguo Huang</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+H">Hui Peng</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+H">Haohao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10712" title="Abstract">arXiv:2401.10712</a> (replaced) [<a href="/pdf/2401.10712" title="Download PDF">pdf</a>, <a href="/format/2401.10712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q&amp;A Prompts: Discovering Rich Visual Clues through Mining  Question-Answer Prompts for VQA requiring Diverse World Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Weifeng Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11389" title="Abstract">arXiv:2401.11389</a> (replaced) [<a href="/pdf/2401.11389" title="Download PDF">pdf</a>, <a href="/format/2401.11389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedLM: Exploring Language Models for Medical Question Answering Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yagnik%2C+N">Niraj Yagnik</a>, 
<a href="/search/cs?searchtype=author&query=Jhaveri%2C+J">Jay Jhaveri</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vivek Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Pila%2C+G">Gabriel Pila</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.13267" title="Abstract">arXiv:2401.13267</a> (replaced) [<a href="/pdf/2401.13267" title="Download PDF">pdf</a>, <a href="/format/2401.13267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-modal Dynamic Traceback Learning for Medical Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shuchang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M">Mingyuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dagan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinman Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.16553" title="Abstract">arXiv:2401.16553</a> (replaced) [<a href="/pdf/2401.16553" title="Download PDF">pdf</a>, <a href="/format/2401.16553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelectLLM: Can LLMs Select Important Instructions to Annotate?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parkar%2C+R+S">Ritik Sachin Parkar</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+I">Jong Inn Park</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongyeop Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First Authors: Ritik Sachin Parkar and Jaehyung Kim | Second Author: Jong Inn Park | PI: Dongyeop Kang
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.17919" title="Abstract">arXiv:2401.17919</a> (replaced) [<a href="/pdf/2401.17919" title="Download PDF">pdf</a>, <a href="/format/2401.17919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOCOST: State-Space Models for Long Document Abstractive Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bronnec%2C+F+L">Florian Le Bronnec</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+S">Song Duong</a>, 
<a href="/search/cs?searchtype=author&query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guigue%2C+V">Vincent Guigue</a>, 
<a href="/search/cs?searchtype=author&query=Lumbreras%2C+A">Alberto Lumbreras</a>, 
<a href="/search/cs?searchtype=author&query=Soulier%2C+L">Laure Soulier</a>, 
<a href="/search/cs?searchtype=author&query=Gallinari%2C+P">Patrick Gallinari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 7 tables, EACL 2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.02547" title="Abstract">arXiv:2402.02547</a> (replaced) [<a href="/pdf/2402.02547" title="Download PDF">pdf</a>, <a href="/ps/2402.02547" title="Download PostScript">ps</a>, <a href="/format/2402.02547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration of cognitive tasks into artificial general intelligence test  for large models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Youzhi Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+P">Penghui Du</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+W">Wenxin Che</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Y">Yatao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kai Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiyan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Quanying Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03077" title="Abstract">arXiv:2402.03077</a> (replaced) [<a href="/pdf/2402.03077" title="Download PDF">pdf</a>, <a href="/ps/2402.03077" title="Download PostScript">ps</a>, <a href="/format/2402.03077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov Persuasion Processes: Learning to Persuade from Scratch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bacchiocchi%2C+F">Francesco Bacchiocchi</a>, 
<a href="/search/cs?searchtype=author&query=Stradi%2C+F+E">Francesco Emanuele Stradi</a>, 
<a href="/search/cs?searchtype=author&query=Castiglioni%2C+M">Matteo Castiglioni</a>, 
<a href="/search/cs?searchtype=author&query=Marchesi%2C+A">Alberto Marchesi</a>, 
<a href="/search/cs?searchtype=author&query=Gatti%2C+N">Nicola Gatti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03223" title="Abstract">arXiv:2402.03223</a> (replaced) [<a href="/pdf/2402.03223" title="Download PDF">pdf</a>, <a href="/format/2402.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barei%C3%9F%2C+P">Patrick Barei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Klinger%2C+R">Roman Klinger</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+J">Jeremy Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to the PromptEng workshop at The Web Conf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03299" title="Abstract">arXiv:2402.03299</a> (replaced) [<a href="/pdf/2402.03299" title="Download PDF">pdf</a>, <a href="/format/2402.03299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GUARD: Role-playing to Generate Natural-language Jailbreakings to Test  Guideline Adherence of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haibo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Andy Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 papges
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03302" title="Abstract">arXiv:2402.03302</a> (replaced) [<a href="/pdf/2402.03302" title="Download PDF">pdf</a>, <a href="/format/2402.03302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiarun Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Hong-Yu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xi%2C+Y">Yan Xi</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+L">Lequan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+Y">Yong Liang</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+G">Guangming Shi</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+H">Hairong Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models of Swin-UMamba are publicly available at: <a href="https://github.com/JiarunLiu/Swin-UMamba">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.03697" title="Abstract">arXiv:2402.03697</a> (replaced) [<a href="/pdf/2402.03697" title="Download PDF">pdf</a>, <a href="/format/2402.03697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHMC-Net: A Mask-guided Feature Fusion Network for Sperm Head Morphology  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapkota%2C+N">Nishchal Sapkota</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yejia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peixian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingjing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+X">Xiaomin Zha</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiru Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunxia Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Danny Z Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04154" title="Abstract">arXiv:2402.04154</a> (replaced) [<a href="/pdf/2402.04154" title="Download PDF">pdf</a>, <a href="/format/2402.04154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Read to Play (R2-Play): Decision Transformer with Multimodal Game  Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yonggang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiawei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liuyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Shawn Yue</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+W">Stephen W. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.04405" title="Abstract">arXiv:2402.04405</a> (replaced) [<a href="/pdf/2402.04405" title="Download PDF">pdf</a>, <a href="/ps/2402.04405" title="Download PostScript">ps</a>, <a href="/format/2402.04405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable domain knowledge enhanced machine learning framework on  axial capacity prediction of circular CFST columns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhigang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+G">Gen Kondo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal Research Article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.06326" title="Abstract">arXiv:2402.06326</a> (replaced) [<a href="/pdf/2402.06326" title="Download PDF">pdf</a>, <a href="/format/2402.06326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Learning on Temporal Interaction Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yulin Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.07153" title="Abstract">arXiv:2402.07153</a> (replaced) [<a href="/pdf/2402.07153" title="Download PDF">pdf</a>, <a href="/format/2402.07153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Estimation for Physics-informed Neural Networks Approximating  Semilinear Wave Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lorenz%2C+B">Beatrice Lorenz</a>, 
<a href="/search/math?searchtype=author&query=Bacho%2C+A">Aras Bacho</a>, 
<a href="/search/math?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.08144" title="Abstract">arXiv:2402.08144</a> (replaced) [<a href="/pdf/2402.08144" title="Download PDF">pdf</a>, <a href="/format/2402.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average-Case Analysis of Iterative Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavner%2C+J">Joshua Kavner</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lirong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.09752" title="Abstract">arXiv:2402.09752</a> (replaced) [<a href="/pdf/2402.09752" title="Download PDF">pdf</a>, <a href="/ps/2402.09752" title="Download PostScript">ps</a>, <a href="/format/2402.09752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector spectrometer with Hertz-level resolution and super-recognition  capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Qing%2C+T">Ting Qing</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+S">Shupeng Li</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+H">Huashan Yang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+L">Lihan Wang</a>, 
<a href="/search/physics?searchtype=author&query=Fang%2C+Y">Yijie Fang</a>, 
<a href="/search/physics?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>, 
<a href="/search/physics?searchtype=author&query=Cao%2C+M">Meihui Cao</a>, 
<a href="/search/physics?searchtype=author&query=Lu%2C+J">Jianming Lu</a>, 
<a href="/search/physics?searchtype=author&query=He%2C+J">Jijun He</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+J">Junqiu Liu</a>, 
<a href="/search/physics?searchtype=author&query=Lyu%2C+Y">Yueguang Lyu</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+S">Shilong Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Systems and Control (eess.SY); Applied Physics (physics.app-ph); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10251" title="Abstract">arXiv:2402.10251</a> (replaced) [<a href="/pdf/2402.10251" title="Download PDF">pdf</a>, <a href="/format/2402.10251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brant-2: Foundation Model for Brain Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yuan%2C+Z">Zhizhang Yuan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+D">Daoze Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+J">Junru Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Gu%2C+G">Gefei Gu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.10329" title="Abstract">arXiv:2402.10329</a> (replaced) [<a href="/pdf/2402.10329" title="Download PDF">pdf</a>, <a href="/format/2402.10329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Manipulation Interface: In-The-Wild Robot Teaching Without  In-The-Wild Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenjia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chuer Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cousineau%2C+E">Eric Cousineau</a>, 
<a href="/search/cs?searchtype=author&query=Burchfiel%2C+B">Benjamin Burchfiel</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Siyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tedrake%2C+R">Russ Tedrake</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://umi-gripper.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13874" title="Abstract">arXiv:2402.13874</a> (replaced) [<a href="/pdf/2402.13874" title="Download PDF">pdf</a>, <a href="/format/2402.13874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $Se^2$: Sequential Example Selection for In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yuefeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.13959" title="Abstract">arXiv:2402.13959</a> (replaced) [<a href="/pdf/2402.13959" title="Download PDF">pdf</a>, <a href="/format/2402.13959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retention Induced Biases in a Recommendation System with Heterogeneous  Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shichao Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14300" title="Abstract">arXiv:2402.14300</a> (replaced) [<a href="/pdf/2402.14300" title="Download PDF">pdf</a>, <a href="/format/2402.14300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Framework Uniting Visual In-context Learning with Masked Image  Modeling to Improve Ultrasound Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Felfeliyan%2C+B">Banafshe Felfeliyan</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shrimanti Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Knight%2C+J">Jessica Knight</a>, 
<a href="/search/cs?searchtype=author&query=Alves-Pereira%2C+F">Fatima Alves-Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Keen%2C+C">Christopher Keen</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCpper%2C+J">Jessica K&#xfc;pper</a>, 
<a href="/search/cs?searchtype=author&query=Hareendranathan%2C+A+R">Abhilash Rakkunedeth Hareendranathan</a>, 
<a href="/search/cs?searchtype=author&query=Jaremko%2C+J+L">Jacob L. Jaremko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.14494" title="Abstract">arXiv:2402.14494</a> (replaced) [<a href="/pdf/2402.14494" title="Download PDF">pdf</a>, <a href="/format/2402.14494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-BERT: A Unified Perturbation-Robust Framework with Noise Alignment  Pre-training for Noisy Slot Filling Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yueyan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+T">Tingfeng Hui</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoshuai Song</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Daichi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15293" title="Abstract">arXiv:2402.15293</a> (replaced) [<a href="/pdf/2402.15293" title="Download PDF">pdf</a>, <a href="/format/2402.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: What don&#x27;t we know? Understanding Security Vulnerabilities in  SNARKs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaliasos%2C+S">Stefanos Chaliasos</a>, 
<a href="/search/cs?searchtype=author&query=Ernstberger%2C+J">Jens Ernstberger</a>, 
<a href="/search/cs?searchtype=author&query=Theodore%2C+D">David Theodore</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+D">David Wong</a>, 
<a href="/search/cs?searchtype=author&query=Jahanara%2C+M">Mohammad Jahanara</a>, 
<a href="/search/cs?searchtype=author&query=Livshits%2C+B">Benjamin Livshits</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.15653" title="Abstract">arXiv:2402.15653</a> (replaced) [<a href="/pdf/2402.15653" title="Download PDF">pdf</a>, <a href="/format/2402.15653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Frequency Black-Box Backdoor Attack via Evolutionary Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yanqi Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dazhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaitai Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16001" title="Abstract">arXiv:2402.16001</a> (replaced) [<a href="/pdf/2402.16001" title="Download PDF">pdf</a>, <a href="/ps/2402.16001" title="Download PostScript">ps</a>, <a href="/format/2402.16001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Resolution Land Cover Classification Using Outdated Products and  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Huan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yubin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haiyan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Cheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jie%2C+Y">Yongshi Jie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yiyang Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16029" title="Abstract">arXiv:2402.16029</a> (replaced) [<a href="/pdf/2402.16029" title="Download PDF">pdf</a>, <a href="/format/2402.16029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphWiz: An Instruction-Following Language Model for Graph Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jianheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27pages, 15 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16073" title="Abstract">arXiv:2402.16073</a> (replaced) [<a href="/pdf/2402.16073" title="Download PDF">pdf</a>, <a href="/format/2402.16073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pfeed: Generating near real-time personalized feeds using precomputed  embedding similarities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gebre%2C+B">Binyam Gebre</a>, 
<a href="/search/cs?searchtype=author&query=Ranta%2C+K">Karoliina Ranta</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Elzen%2C+S">Stef van den Elzen</a>, 
<a href="/search/cs?searchtype=author&query=Kuiper%2C+E">Ernst Kuiper</a>, 
<a href="/search/cs?searchtype=author&query=Baars%2C+T">Thijs Baars</a>, 
<a href="/search/cs?searchtype=author&query=Heskes%2C+T">Tom Heskes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16712" title="Abstract">arXiv:2402.16712</a> (replaced) [<a href="/pdf/2402.16712" title="Download PDF">pdf</a>, <a href="/format/2402.16712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> l1-norm regularized l1-norm best-fit lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ling%2C+X">Xiao Ling</a>, 
<a href="/search/stat?searchtype=author&query=Brooks%2C+P">Paul Brooks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16796" title="Abstract">arXiv:2402.16796</a> (replaced) [<a href="/pdf/2402.16796" title="Download PDF">pdf</a>, <a href="/format/2402.16796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive Whole-Body Control for Humanoid Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xuxin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yandong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruihan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Ge Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://expressive-humanoid.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.16899" title="Abstract">arXiv:2402.16899</a> (replaced) [<a href="/pdf/2402.16899" title="Download PDF">pdf</a>, <a href="/format/2402.16899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A priori Estimates for Deep Residual Network in Continuous-time  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shuyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Fei Wen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17277" title="Abstract">arXiv:2402.17277</a> (replaced) [<a href="/pdf/2402.17277" title="Download PDF">pdf</a>, <a href="/format/2402.17277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RISAR: RIS-assisted Human Activity Recognition with Commercial Wi-Fi  Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Junshuo Liu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yunlong Huang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+R">Rujing Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Mi%2C+T">Tiebin Mi</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+X">Xin Shi</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+R+C">Robert C. Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17766" title="Abstract">arXiv:2402.17766</a> (replaced) [<a href="/pdf/2402.17766" title="Download PDF">pdf</a>, <a href="/format/2402.17766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShapeLLM: Universal 3D Object Understanding for Embodied Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zekun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Runpei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaochen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Haoran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chunrui Han</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaisheng Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://qizekun.github.io/shapellm/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.17933" title="Abstract">arXiv:2402.17933</a> (replaced) [<a href="/pdf/2402.17933" title="Download PDF">pdf</a>, <a href="/format/2402.17933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICAT: An Indoor Connected and Autonomous Testbed for Vehicle Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhaofeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">William He</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Boyang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ren Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Foorginejad%2C+E">Erfan Foorginejad</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weisong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18061" title="Abstract">arXiv:2402.18061</a> (replaced) [<a href="/pdf/2402.18061" title="Download PDF">pdf</a>, <a href="/format/2402.18061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the use of Silver Standard Data for Zero-shot Classification Tasks in  Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziqian Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by coling2024. <a href="/abs/2211.13883">arXiv:2211.13883</a> is our first edition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18162" title="Abstract">arXiv:2402.18162</a> (replaced) [<a href="/pdf/2402.18162" title="Download PDF">pdf</a>, <a href="/format/2402.18162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Detection using Neural Activation Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18383" title="Abstract">arXiv:2402.18383</a> (replaced) [<a href="/pdf/2402.18383" title="Download PDF">pdf</a>, <a href="/ps/2402.18383" title="Download PostScript">ps</a>, <a href="/format/2402.18383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Quantification of Percent Emphysema on CT via Domain Attention:  the Multi-Ethnic Study of Atherosclerosis (MESA) Lung Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+E+D">Elsa D. Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+E+A">Eric A. Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+K+E">Karol E. Watson</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+B+M">Benjamin M. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+R+G">R. Graham Barr</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+A+F">Andrew F. Laine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures. Accepted to IEEE International Symposium on Biomedical Imaging 2024 (ISBI 2024). Camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18394" title="Abstract">arXiv:2402.18394</a> (replaced) [<a href="/pdf/2402.18394" title="Download PDF">pdf</a>, <a href="/format/2402.18394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-IMU State Estimation for Relative Localization of Two Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wenqian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruonan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K+J">Kejian J. Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18571" title="Abstract">arXiv:2402.18571</a> (replaced) [<a href="/pdf/2402.18571" title="Download PDF">pdf</a>, <a href="/format/2402.18571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic Control of LLMs for Diverse User Preferences: Directional  Preference Alignment with Multi-Objective Rewards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+S">Shizhe Diao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shuang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and model are released at <a href="https://github.com/Haoxiang-Wang/directional-preference-alignment">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.18759" title="Abstract">arXiv:2402.18759</a> (replaced) [<a href="/pdf/2402.18759" title="Download PDF">pdf</a>, <a href="/format/2402.18759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Language-Guided State Abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+A">Andi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sucholutsky%2C+I">Ilia Sucholutsky</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B+Z">Belinda Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Sumers%2C+T+R">Theodore R. Sumers</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+J+A">Julie A. Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19270" title="Abstract">arXiv:2402.19270</a> (replaced) [<a href="/pdf/2402.19270" title="Download PDF">pdf</a>, <a href="/format/2402.19270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Intra-view and Cross-view Geometric Knowledge for Stereo  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+R">Rui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weide Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zaiwang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xulei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jun Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19290" title="Abstract">arXiv:2402.19290</a> (replaced) [<a href="/pdf/2402.19290" title="Download PDF">pdf</a>, <a href="/ps/2402.19290" title="Download PostScript">ps</a>, <a href="/format/2402.19290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation and Deconvolution of Second Order Cyclostationary Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makienko%2C+I">Igor Makienko</a>, 
<a href="/search/cs?searchtype=author&query=Grebshtein%2C+M">Michael Grebshtein</a>, 
<a href="/search/cs?searchtype=author&query=Gildish%2C+E">Eli Gildish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19322" title="Abstract">arXiv:2402.19322</a> (replaced) [<a href="/pdf/2402.19322" title="Download PDF">pdf</a>, <a href="/format/2402.19322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of Neural Networks&#x27; Global Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabaha%2C+A">Anan Kabaha</a>, 
<a href="/search/cs?searchtype=author&query=Drachsler-Cohen%2C+D">Dana Drachsler-Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2402.19379" title="Abstract">arXiv:2402.19379</a> (replaced) [<a href="/pdf/2402.19379" title="Download PDF">pdf</a>, <a href="/format/2402.19379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Rival  Human Crowd Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schoenegger%2C+P">Philipp Schoenegger</a>, 
<a href="/search/cs?searchtype=author&query=Tuminauskaite%2C+I">Indre Tuminauskaite</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+P+S">Peter S. Park</a>, 
<a href="/search/cs?searchtype=author&query=Tetlock%2C+P+E">Philip E. Tetlock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages; 13 visualizations (nine figures, four tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.00331" title="Abstract">arXiv:2403.00331</a> (replaced) [<a href="/pdf/2403.00331" title="Download PDF">pdf</a>, <a href="/format/2403.00331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WindGP: Efficient Graph Partitioning on Heterogenous Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Li Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Binfan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shengcheng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinhua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rongqian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 15 figures, 18 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01317" title="Abstract">arXiv:2403.01317</a> (replaced) [<a href="/pdf/2403.01317" title="Download PDF">pdf</a>, <a href="/format/2403.01317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More: Hop-Wise Graph Attention for Scalable and Generalizable  Learning on Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chenhui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zichao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunxi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sarar%2C+G">Gokce Sarar</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+R">Ryan Carey</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rajeev Jain</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiru Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at Design Automation Conference (DAC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01636" title="Abstract">arXiv:2403.01636</a> (replaced) [<a href="/pdf/2403.01636" title="Download PDF">pdf</a>, <a href="/format/2403.01636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Efficient Myopic Exploration Through Multitask Reinforcement  Learning with Diverse Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+Z">Ziping Xu</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+Z">Zifan Xu</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+R">Runxuan Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/stat?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01766" title="Abstract">arXiv:2403.01766</a> (replaced) [<a href="/pdf/2403.01766" title="Download PDF">pdf</a>, <a href="/format/2403.01766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Visual Perception of a Social Robot for Controlled and  In-the-wild Human-robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wangjie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Leimin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+T">Duy Tho Le</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+H">Hamid Rezatofighi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to HRI 2024 (LBR track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.01818" title="Abstract">arXiv:2403.01818</a> (replaced) [<a href="/pdf/2403.01818" title="Download PDF">pdf</a>, <a href="/format/2403.01818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AllSpark: Reborn Labeled Features from Unlabeled in Transformer for  Semi-Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2024; correct typos; this is not the camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02118" title="Abstract">arXiv:2403.02118</a> (replaced) [<a href="/pdf/2403.02118" title="Download PDF">pdf</a>, <a href="/format/2403.02118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Implicit Prompt For Text-To-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yue Yang</a>, 
<a href="/search/cs?searchtype=author&query=lin%2C+Y">Yuqi lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+H">Hailong Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02131" title="Abstract">arXiv:2403.02131</a> (replaced) [<a href="/pdf/2403.02131" title="Download PDF">pdf</a>, <a href="/format/2403.02131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Dynamic Algorithm Selection: A  Proof-of-Principle Study on Differential Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongshu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yining Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zeyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yue-Jiao Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Systems, Man, and Cybernetics: Systems at Thu, Feb 29, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02331" title="Abstract">arXiv:2403.02331</a> (replaced) [<a href="/pdf/2403.02331" title="Download PDF">pdf</a>, <a href="/ps/2403.02331" title="Download PostScript">ps</a>, <a href="/format/2403.02331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Neuromic Computing: Neurons as Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bull%2C+L">Larry Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02332" title="Abstract">arXiv:2403.02332</a> (replaced) [<a href="/pdf/2403.02332" title="Download PDF">pdf</a>, <a href="/format/2403.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniCtrl: Improving the Spatiotemporal Consistency of Text-to-Video  Diffusion Models via Training-Free Unified Attention Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuweiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tian Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sihan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github: <a href="https://github.com/XuweiyiChen/UniCtrl">this https URL</a> Website: <a href="https://unified-attention-control.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02371" title="Abstract">arXiv:2403.02371</a> (replaced) [<a href="/pdf/2403.02371" title="Download PDF">pdf</a>, <a href="/format/2403.02371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroVoz: a Castillian Spanish corpus of parkinsonian speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mendes-Laureano%2C+J">Jana&#xed;na Mendes-Laureano</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%B3mez-Garc%C3%ADa%2C+J+A">Jorge A. G&#xf3;mez-Garc&#xed;a</a>, 
<a href="/search/eess?searchtype=author&query=Guerrero-L%C3%B3pez%2C+A">Alejandro Guerrero-L&#xf3;pez</a>, 
<a href="/search/eess?searchtype=author&query=Luque-Buzo%2C+E">Elisa Luque-Buzo</a>, 
<a href="/search/eess?searchtype=author&query=Arias-Londo%C3%B1o%2C+J+D">Juli&#xe1;n D. Arias-Londo&#xf1;o</a>, 
<a href="/search/eess?searchtype=author&query=Grandas-P%C3%A9rez%2C+F+J">Francisco J. Grandas-P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Godino-Llorente%2C+J+I">Juan I. Godino-Llorente</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02472" title="Abstract">arXiv:2403.02472</a> (replaced) [<a href="/pdf/2403.02472" title="Download PDF">pdf</a>, <a href="/format/2403.02472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OffLanDat: A Community Based Implicit Offensive Language Dataset  Generated by Large Language Model Through Prompt Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amit Das</a>, 
<a href="/search/cs?searchtype=author&query=Rahgouy%2C+M">Mostafa Rahgouy</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dongji Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+T">Tathagata Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Raychawdhary%2C+N">Nilanjana Raychawdhary</a>, 
<a href="/search/cs?searchtype=author&query=Sandage%2C+M">Mary Sandage</a>, 
<a href="/search/cs?searchtype=author&query=Pope%2C+L">Lauramarie Pope</a>, 
<a href="/search/cs?searchtype=author&query=Dozier%2C+G">Gerry Dozier</a>, 
<a href="/search/cs?searchtype=author&query=Seals%2C+C">Cheryl Seals</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02525" title="Abstract">arXiv:2403.02525</a> (replaced) [<a href="/pdf/2403.02525" title="Download PDF">pdf</a>, <a href="/format/2403.02525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of Intent-Based Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chitra%2C+T">Tarun Chitra</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+K">Kshitij Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+M">Mallesh Pai</a>, 
<a href="/search/cs?searchtype=author&query=Diamandis%2C+T">Theo Diamandis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02630" title="Abstract">arXiv:2403.02630</a> (replaced) [<a href="/pdf/2403.02630" title="Download PDF">pdf</a>, <a href="/format/2403.02630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedHCDR: Federated Cross-Domain Recommendation with Hypergraph Signal  Decoupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yunqing Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02640" title="Abstract">arXiv:2403.02640</a> (replaced) [<a href="/pdf/2403.02640" title="Download PDF">pdf</a>, <a href="/format/2403.02640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoloVIC: Large-scale Dataset and Benchmark for Multi-Sensor Holographic  Intersection and Vehicle-Infrastructure Cooperative
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Cong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Lei Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chengkai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zelong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xueqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+Y">Yuheng Kan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024 accepted, (Not Camera-ready Version), Benchmark Website(Coming Soon): <a href="https://holovic.net">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02781" title="Abstract">arXiv:2403.02781</a> (replaced) [<a href="/pdf/2403.02781" title="Download PDF">pdf</a>, <a href="/format/2403.02781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptKD: Unsupervised Prompt Distillation for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xinyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2024. Project Page: <a href="https://zhengli97.github.io/PromptKD.">this https URL</a> Code: <a href="https://github.com/zhengli97/PromptKD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02910" title="Abstract">arXiv:2403.02910</a> (replaced) [<a href="/pdf/2403.02910" title="Download PDF">pdf</a>, <a href="/format/2403.02910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImgTrojan: Jailbreaking Vision-Language Models with ONE Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xijia Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shuai Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingpeng Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02951" title="Abstract">arXiv:2403.02951</a> (replaced) [<a href="/pdf/2403.02951" title="Download PDF">pdf</a>, <a href="/format/2403.02951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking the Text-to-SQL Capability of Large Language Models: A  Comprehensive Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuxiao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+G">Guoqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoru Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+H">Chi Harold Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26pages, 6figures, 14tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.02971" title="Abstract">arXiv:2403.02971</a> (replaced) [<a href="/pdf/2403.02971" title="Download PDF">pdf</a>, <a href="/ps/2403.02971" title="Download PostScript">ps</a>, <a href="/format/2403.02971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space Complexity of Euclidean Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaoyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuxiang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lingxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zengfeng Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SoCG2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03097" title="Abstract">arXiv:2403.03097</a> (replaced) [<a href="/pdf/2403.03097" title="Download PDF">pdf</a>, <a href="/format/2403.03097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tappy: Predicting Tap Accuracy of User-Interface Elements by  Reverse-Engineering Webpage Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Usuba%2C+H">Hiroki Usuba</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+J">Junichi Sato</a>, 
<a href="/search/cs?searchtype=author&query=Sasaya%2C+N">Naomi Sasaya</a>, 
<a href="/search/cs?searchtype=author&query=Yamanaka%2C+S">Shota Yamanaka</a>, 
<a href="/search/cs?searchtype=author&query=Yamashita%2C+F">Fumiya Yamashita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03105" title="Abstract">arXiv:2403.03105</a> (replaced) [<a href="/pdf/2403.03105" title="Download PDF">pdf</a>, <a href="/format/2403.03105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biomechanical Comparison of Human Walking Locomotion on Solid Ground and  Sand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chunchu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xunjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingang Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures, submitted to Journal of Biomechanics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03190" title="Abstract">arXiv:2403.03190</a> (replaced) [<a href="/pdf/2403.03190" title="Download PDF">pdf</a>, <a href="/format/2403.03190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triple-CFN: Restructuring Conceptual Spaces for Enhancing Abstract  Reasoning process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruizhuo Song</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Beiming Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2403.03213" title="Abstract">arXiv:2403.03213</a> (replaced) [<a href="/pdf/2403.03213" title="Download PDF">pdf</a>, <a href="/format/2403.03213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the computation of lattice sums without translational invariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buchheit%2C+A+A">Andreas A. Buchheit</a>, 
<a href="/search/math?searchtype=author&query=Ke%C3%9Fler%2C+T">Torsten Ke&#xdf;ler</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Strongly Correlated Electrons (cond-mat.str-el); High Energy Physics - Lattice (hep-lat)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item316">Cross-lists</a></li>
<li><a href="#item376">Replacements</a></li>
</ul>
<small>[ total of 589 entries:  <b>1-589</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2403">2403</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
