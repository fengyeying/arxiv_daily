<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 10 Oct 23  to  Wed 11 Oct 23, announced Thu, 12 Oct 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item393">Cross-lists</a></li>
<li><a href="#item444">Replacements</a></li>
</ul>
<small>[ total of 670 entries:  <b>1-670</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 12 Oct 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06840" title="Abstract">arXiv:2310.06840</a> [<a href="/pdf/2310.06840" title="Download PDF">pdf</a>, <a href="/format/2310.06840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperdimensional Computing as a Rescue for Efficient Privacy-Preserving  Machine Learning-as-a-Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaewoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+C">Chenghao Quan</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+H">Hyungon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongeun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICCAD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning models are often provisioned as a cloud-based service where
the clients send their data to the service provider to obtain the result. This
setting is commonplace due to the high value of the models, but it requires the
clients to forfeit the privacy that the query data may contain. Homomorphic
encryption (HE) is a promising technique to address this adversity. With HE,
the service provider can take encrypted data as a query and run the model
without decrypting it. The result remains encrypted, and only the client can
decrypt it. All these benefits come at the cost of computational cost because
HE turns simple floating-point arithmetic into the computation between long
(degree over 1024) polynomials. Previous work has proposed to tailor deep
neural networks for efficient computation over encrypted data, but already high
computational cost is again amplified by HE, hindering performance improvement.
In this paper we show hyperdimensional computing can be a rescue for
privacy-preserving machine learning over encrypted data. We find that the
advantage of hyperdimensional computing in performance is amplified when
working with HE. This observation led us to design HE-HDC, a machine-learning
inference system that uses hyperdimensional computing with HE. We carefully
structure the machine learning service so that the server will perform only the
HE-friendly computation. Moreover, we adapt the computation and HE parameters
to expedite computation while preserving accuracy and security. Our
experimental result based on real measurements shows that HE-HDC outperforms
existing systems by 26~3000 times with comparable classification accuracy.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06841" title="Abstract">arXiv:2310.06841</a> [<a href="/pdf/2310.06841" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Malware Classification using Deep Neural Networks: Performance  Evaluation and Applications in Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%2C+A+M">Akhil M R</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A+K+V">Adithya Krishna V Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Swamy%2C+H">Harivardhan Swamy</a>, 
<a href="/search/cs?searchtype=author&query=A%2C+P">Pavan A</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+A">Ashray Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Sathyanarayana%2C+A+B">Anirudh B Sathyanarayana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With the increasing extent of malware attacks in the present day along with
the difficulty in detecting modern malware, it is necessary to evaluate the
effectiveness and performance of Deep Neural Networks (DNNs) for malware
classification. Multiple DNN architectures can be designed and trained to
detect and classify malware binaries. Results demonstrate the potential of DNNs
in accurately classifying malware with high accuracy rates observed across
different malware types. Additionally, the feasibility of deploying these DNN
models on edge devices to enable real-time classification, particularly in
resource-constrained scenarios proves to be integral to large IoT systems. By
optimizing model architectures and leveraging edge computing capabilities, the
proposed methodologies achieve efficient performance even with limited
resources. This study contributes to advancing malware detection techniques and
emphasizes the significance of integrating cybersecurity measures for the early
detection of malware and further preventing the adverse effects caused by such
attacks. Optimal considerations regarding the distribution of security tasks to
edge devices are addressed to ensure that the integrity and availability of
large scale IoT systems are not compromised due to malware attacks, advocating
for a more resilient and secure digital ecosystem.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06842" title="Abstract">arXiv:2310.06842</a> [<a href="/pdf/2310.06842" title="Download PDF">pdf</a>, <a href="/format/2310.06842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational models of object motion detectors accelerated using FPGA  technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machado%2C+P">Pedro Machado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This PhD research introduces three key contributions in the domain of object
motion detection:
<br />Multi-Hierarchical Spiking Neural Network (MHSNN): A specialized four-layer
Spiking Neural Network (SNN) architecture inspired by vertebrate retinas.
Trained on custom lab-generated images, it exhibited 6.75% detection error for
horizontal and vertical movements. While non-scalable, MHSNN laid the
foundation for further advancements. Hybrid Sensitive Motion Detector (HSMD):
Enhancing Dynamic Background Subtraction (DBS) using a tailored three-layer
SNN, stabilizing foreground data to enhance object motion detection. Evaluated
on standard datasets, HSMD outperformed OpenCV-based methods, excelling in four
categories across eight metrics. It maintained real-time processing
(13.82-13.92 fps) on a high-performance computer but showed room for hardware
optimisation. Neuromorphic Hybrid Sensitive Motion Detector (NeuroHSMD):
Building upon HSMD, this adaptation implemented the SNN component on dedicated
hardware (FPGA). OpenCL simplified FPGA design and enabled portability.
NeuroHSMD demonstrated an 82% speedup over HSMD, achieving 28.06-28.71 fps on
CDnet2012 and CDnet2014 datasets.
<br />These contributions collectively represent significant advancements in object
motion detection, from a biologically inspired neural network design to an
optimized hardware implementation that outperforms existing methods in accuracy
and processing speed.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06845" title="Abstract">arXiv:2310.06845</a> [<a href="/pdf/2310.06845" title="Download PDF">pdf</a>, <a href="/format/2310.06845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobustEdge: Low Power Adversarial Detection for Cloud-Edge Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Abhishek Moitra</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Abhiroop Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+P">Priyadarshini Panda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In practical cloud-edge scenarios, where a resource constrained edge performs
data acquisition and a cloud system (having sufficient resources) performs
inference tasks with a deep neural network (DNN), adversarial robustness is
critical for reliability and ubiquitous deployment. Adversarial detection is a
prime adversarial defence technique used in prior literature. However, in prior
detection works, the detector is attached to the classifier model and both
detector and classifier work in tandem to perform adversarial detection that
requires a high computational overhead which is not available at the low-power
edge. Therefore, prior works can only perform adversarial detection at the
cloud and not at the edge. This means that in case of adversarial attacks, the
unfavourable adversarial samples must be communicated to the cloud which leads
to energy wastage at the edge device. Therefore, a low-power edge-friendly
adversarial detection method is required to improve the energy efficiency of
the edge and robustness of the cloud-based classifier. To this end, RobustEdge
proposes Quantization-enabled Energy Separation (QES) training with "early
detection and exit" to perform edge-based low cost adversarial detection. The
QES-trained detector implemented at the edge blocks adversarial data
transmission to the classifier model, thereby improving adversarial robustness
and energy-efficiency of the Cloud-Edge system.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06846" title="Abstract">arXiv:2310.06846</a> [<a href="/pdf/2310.06846" title="Download PDF">pdf</a>, <a href="/format/2310.06846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Language Models as a Source of Knowledge for Cognitive Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirk%2C+J+R">James R. Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Wray%2C+R+E">Robert E. Wray</a>, 
<a href="/search/cs?searchtype=author&query=Laird%2C+J+E">John E. Laird</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 2 tables. AAAI FSS on Integrating Cognitive Architecture and Generative Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) provide capabilities far beyond sentence
completion, including question answering, summarization, and natural-language
inference. While many of these capabilities have potential application to
cognitive systems, our research is exploiting language models as a source of
task knowledge for cognitive agents, that is, agents realized via a cognitive
architecture. We identify challenges and opportunities for using language
models as an external knowledge source for cognitive systems and possible ways
to improve the effectiveness of knowledge extraction by integrating extraction
with cognitive architecture capabilities, highlighting with examples from our
recent work in this area.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06847" title="Abstract">arXiv:2310.06847</a> [<a href="/pdf/2310.06847" title="Download PDF">pdf</a>, <a href="/format/2310.06847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Various EfficientNet Based U-Net++ Architecture  for Automatic Building Extraction from High Resolution Satellite Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ovi%2C+T+B">Tareque Bashar Ovi</a>, 
<a href="/search/cs?searchtype=author&query=Bashree%2C+N">Nomaiya Bashree</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+P">Protik Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Mosharrof%2C+S">Shakil Mosharrof</a>, 
<a href="/search/cs?searchtype=author&query=Parthima%2C+M+A">Masuma Anjum Parthima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages,Keywords: Deep learning,satellite image,transfer learning,segmentation,deep supervision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Building extraction is an essential component of study in the science of
remote sensing, and applications for building extraction heavily rely on
semantic segmentation of high-resolution remote sensing imagery. Semantic
information extraction gap constraints in the present deep learning based
approaches, however can result in inadequate segmentation outcomes. To address
this issue and extract buildings with high accuracy, various efficientNet
backbone based U-Net++ has been proposed in this study. The designed network,
based on U-Net, can improve the sensitivity of the model by deep supervision,
voluminous redesigned skip-connections and hence reducing the influence of
irrelevant feature areas in the background. Various effecientNet backbone based
encoders have been employed when training the network to enhance the capacity
of the model to extract more relevant feature. According on the experimental
findings, the suggested model significantly outperforms previous cutting-edge
approaches. Among the 5 efficientNet variation Unet++ based on efficientb4
achieved the best result by scoring mean accuracy of 92.23%, mean iou of
88.32%, and mean precision of 93.2% on publicly available Massachusetts
building dataset and thus showing the promises of the model for automatic
building extraction from high resolution satellite images.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06848" title="Abstract">arXiv:2310.06848</a> [<a href="/pdf/2310.06848" title="Download PDF">pdf</a>, <a href="/format/2310.06848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepTriNet: A Tri-Level Attention Based DeepLabv3+ Architecture for  Semantic Segmentation of Satellite Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ovi%2C+T+B">Tareque Bashar Ovi</a>, 
<a href="/search/cs?searchtype=author&query=Mosharrof%2C+S">Shakil Mosharrof</a>, 
<a href="/search/cs?searchtype=author&query=Bashree%2C+N">Nomaiya Bashree</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Shofiqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+N">Muhammad Nazrul Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Attention mechanism, Deep learning, Satellite image, DeepLabv3+, Segmentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The segmentation of satellite images is crucial in remote sensing
applications. Existing methods face challenges in recognizing small-scale
objects in satellite images for semantic segmentation primarily due to ignoring
the low-level characteristics of the underlying network and due to containing
distinct amounts of information by different feature maps. Thus, in this
research, a tri-level attention-based DeepLabv3+ architecture (DeepTriNet) is
proposed for the semantic segmentation of satellite images. The proposed hybrid
method combines squeeze-and-excitation networks (SENets) and tri-level
attention units (TAUs) with the vanilla DeepLabv3+ architecture, where the TAUs
are used to bridge the semantic feature gap among encoders output and the
SENets used to put more weight on relevant features. The proposed DeepTriNet
finds which features are the more relevant and more generalized way by its
self-supervision rather we annotate them. The study showed that the proposed
DeepTriNet performs better than many conventional techniques with an accuracy
of 98% and 77%, IoU 80% and 58%, precision 88% and 68%, and recall of 79% and
55% on the 4-class Land-Cover.ai dataset and the 15-class GID-2 dataset
respectively. The proposed method will greatly contribute to natural resource
management and change detection in rural and urban regions through efficient
and semantic satellite image segmentation
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06850" title="Abstract">arXiv:2310.06850</a> [<a href="/pdf/2310.06850" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of variations of citation-based parameters for selected Indian  science journals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+B">Bidyarthi Dutta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The ratio of the total number of citations to the total number of cited
papers was predicted as a constant by Garfield. But, later he observed the
changing nature of this constant over time. Scientometricians thus preferred to
call it Garfield Ratio rather than Garfield Constant. The Garfield Ratio is a
very well-known citation-based parameter, which actually indicates the average
citation per cited article. However, Garfield still pointed out that behind
this ratio some deeper regularity may be found. In this paper, an analysis of
this indicator, the Garfield Ratio is attempted for twelve distinguished Indian
science journals over twelve years time span ranging from 2009 to 2020.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06851" title="Abstract">arXiv:2310.06851</a> [<a href="/pdf/2310.06851" title="Download PDF">pdf</a>, <a href="/format/2310.06851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BodyFormer: Semantics-guided 3D Body Gesture Synthesis with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+K">Kunkun Pang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+D">Dafei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yingruo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Habekost%2C+J">Julian Habekost</a>, 
<a href="/search/cs?searchtype=author&query=Shiratori%2C+T">Takaaki Shiratori</a>, 
<a href="/search/cs?searchtype=author&query=Yamagishi%2C+J">Junichi Yamagishi</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Automatic gesture synthesis from speech is a topic that has attracted
researchers for applications in remote communication, video games and
Metaverse. Learning the mapping between speech and 3D full-body gestures is
difficult due to the stochastic nature of the problem and the lack of a rich
cross-modal dataset that is needed for training. In this paper, we propose a
novel transformer-based framework for automatic 3D body gesture synthesis from
speech. To learn the stochastic nature of the body gesture during speech, we
propose a variational transformer to effectively model a probabilistic
distribution over gestures, which can produce diverse gestures during
inference. Furthermore, we introduce a mode positional embedding layer to
capture the different motion speeds in different speaking modes. To cope with
the scarcity of data, we design an intra-modal pre-training scheme that can
learn the complex mapping between the speech and the 3D gesture from a limited
amount of data. Our system is trained with either the Trinity speech-gesture
dataset or the Talking With Hands 16.2M dataset. The results show that our
system can produce more realistic, appropriate, and diverse body gestures
compared to existing state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06854" title="Abstract">arXiv:2310.06854</a> [<a href="/pdf/2310.06854" title="Download PDF">pdf</a>, <a href="/format/2310.06854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Noisy Labels for Human Fall Events Classification: Joint  Cooperative Training with Trinity Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Leiyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Naqvi%2C+S+M">Syed Mohsen Naqvi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">With the increasing ageing population, fall events classification has drawn
much research attention. In the development of deep learning, the quality of
data labels is crucial. Most of the datasets are labelled automatically or
semi-automatically, and the samples may be mislabeled, which constrains the
performance of Deep Neural Networks (DNNs). Recent research on noisy label
learning confirms that neural networks first focus on the clean and simple
instances and then follow the noisy and hard instances in the training stage.
To address the learning with noisy label problem and protect the human
subjects' privacy, we propose a simple but effective approach named Joint
Cooperative training with Trinity Networks (JoCoT). To mitigate the privacy
issue, human skeleton data are used. The robustness and performance of the
noisy label learning framework is improved by using the two teacher modules and
one student module in the proposed JoCoT. To mitigate the incorrect selections,
the predictions from the teacher modules are applied with the consensus-based
method to guide the student module training. The performance evaluation on the
widely used UP-Fall dataset and comparison with the state-of-the-art, confirms
the effectiveness of the proposed JoCoT in high noise rates. Precisely, JoCoT
outperforms the state-of-the-art by 5.17% and 3.35% with the averaged pairflip
and symmetric noises, respectively.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06855" title="Abstract">arXiv:2310.06855</a> [<a href="/pdf/2310.06855" title="Download PDF">pdf</a>, <a href="/format/2310.06855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Algorithm-Based Dynamic Backdoor Attack on Federated  Learning-Based Network Traffic Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazzal%2C+M">Mahmoud Nazzal</a>, 
<a href="/search/cs?searchtype=author&query=Aljaafari%2C+N">Nura Aljaafari</a>, 
<a href="/search/cs?searchtype=author&query=Sawalmeh%2C+A">Ahmed Sawalmeh</a>, 
<a href="/search/cs?searchtype=author&query=Khreishah%2C+A">Abdallah Khreishah</a>, 
<a href="/search/cs?searchtype=author&query=Anan%2C+M">Muhammad Anan</a>, 
<a href="/search/cs?searchtype=author&query=Algosaibi%2C+A">Abdulelah Algosaibi</a>, 
<a href="/search/cs?searchtype=author&query=Alnaeem%2C+M">Mohammed Alnaeem</a>, 
<a href="/search/cs?searchtype=author&query=Aldalbahi%2C+A">Adel Aldalbahi</a>, 
<a href="/search/cs?searchtype=author&query=Alhumam%2C+A">Abdulaziz Alhumam</a>, 
<a href="/search/cs?searchtype=author&query=Vizcarra%2C+C+P">Conrado P. Vizcarra</a>, 
<a href="/search/cs?searchtype=author&query=Alhamed%2C+S">Shadan Alhamed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning enables multiple clients to collaboratively contribute to
the learning of a global model orchestrated by a central server. This learning
scheme promotes clients' data privacy and requires reduced communication
overheads. In an application like network traffic classification, this helps
hide the network vulnerabilities and weakness points. However, federated
learning is susceptible to backdoor attacks, in which adversaries inject
manipulated model updates into the global model. These updates inject a salient
functionality in the global model that can be launched with specific input
patterns. Nonetheless, the vulnerability of network traffic classification
models based on federated learning to these attacks remains unexplored. In this
paper, we propose GABAttack, a novel genetic algorithm-based backdoor attack
against federated learning for network traffic classification. GABAttack
utilizes a genetic algorithm to optimize the values and locations of backdoor
trigger patterns, ensuring a better fit with the input and the model. This
input-tailored dynamic attack is promising for improved attack evasiveness
while being effective. Extensive experiments conducted over real-world network
datasets validate the success of the proposed GABAttack in various situations
while maintaining almost invisible activity. This research serves as an
alarming call for network security experts and practitioners to develop robust
defense measures against such attacks.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06856" title="Abstract">arXiv:2310.06856</a> [<a href="/pdf/2310.06856" title="Download PDF">pdf</a>, <a href="/format/2310.06856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brave new world: Artificial Intelligence in teaching and learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groza%2C+A">Adrian Groza</a>, 
<a href="/search/cs?searchtype=author&query=Marginean%2C+A">Anca Marginean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We exemplify how Large Language Models are used in both teaching and
learning. We also discuss the AI incidents that have already occurred in the
education domain, and we argue for the urgent need to introduce AI policies in
universities and for the ongoing strategies to regulate AI. Regarding policy
for AI, our view is that each institution should have a policy for AI in
teaching and learning. This is important from at least twofolds: (i) to raise
awareness on the numerous educational tools that can both positively and
negatively affect education; (ii) to minimise the risk of AI incidents in
education.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06857" title="Abstract">arXiv:2310.06857</a> [<a href="/pdf/2310.06857" title="Download PDF">pdf</a>, <a href="/format/2310.06857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Real-Time Rate Control for Live Streaming on  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mortaheb%2C+M">Matin Mortaheb</a>, 
<a href="/search/cs?searchtype=author&query=Khojastepour%2C+M+A+A">Mohammad A. Amir Khojastepour</a>, 
<a href="/search/cs?searchtype=author&query=Chakradhar%2C+S+T">Srimat T. Chakradhar</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">Providing wireless users with high-quality video content has become
increasingly important. However, ensuring consistent video quality poses
challenges due to variable encoded bitrate caused by dynamic video content and
fluctuating channel bitrate caused by wireless fading effects. Suboptimal
selection of encoder parameters can lead to video quality loss due to
underutilized bandwidth or the introduction of video artifacts due to packet
loss. To address this, a real-time deep learning based H.264 controller is
proposed. This controller leverages instantaneous channel quality data driven
from the physical layer, along with the video chunk, to dynamically estimate
the optimal encoder parameters with a negligible delay in real-time. The
objective is to maintain an encoded video bitrate slightly below the available
channel bitrate. Experimental results, conducted on both QCIF dataset and a
diverse selection of random videos from public datasets, validate the
effectiveness of the approach. Remarkably, improvements of 10-20 dB in PSNR
with repect to the state-of-the-art adaptive bitrate video streaming is
achieved, with an average packet drop rate as low as 0.002.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06858" title="Abstract">arXiv:2310.06858</a> [<a href="/pdf/2310.06858" title="Download PDF">pdf</a>, <a href="/ps/2310.06858" title="Download PostScript">ps</a>, <a href="/format/2310.06858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of JiuTian Intelligent Network Simulation Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaomiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Zhuowen Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhaobin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuting Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhe Lv</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yanping Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduced the JiuTian Intelligent Network Simulation Platform,
which can provide wireless communication simulation data services for the Open
Innovation Platform. The platform contains a series of scalable simulator
functionalities, offering open services that enable users to use reinforcement
learning algorithms for model training and inference based on simulation
environments and data. Additionally, it allows users to address optimization
tasks in different scenarios by uploading and updating parameter
configurations. The platform and its open services were primarily introduced
from the perspectives of background, overall architecture, simulator, business
scenarios, and future directions.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06860" title="Abstract">arXiv:2310.06860</a> [<a href="/pdf/2310.06860" title="Download PDF">pdf</a>, <a href="/format/2310.06860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptote-based scientific animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gevorkyan%2C+M+N">Migran N. Gevorkyan</a>, 
<a href="/search/cs?searchtype=author&query=Korolkova%2C+A+V">Anna V. Korolkova</a>, 
<a href="/search/cs?searchtype=author&query=Kulyabov%2C+D+S">Dmitry S. Kulyabov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in English; in Russian
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">This article discusses a universal way to create animation using Asymptote
the language for vector graphics. The Asymptote language itself has a built-in
library for creating animations, but its practical use is complicated by an
extremely brief description in the official documentation and unstable
execution of existing examples. The purpose of this article is to eliminate
this gap. The method we describe is based on creating a PDF file with frames
using Asymptote, with further converting it into a set of PNG images and
merging them into a video using FFmpeg. All stages are described in detail,
which allows the reader to use the described method without being familiar with
the used utilities.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06872" title="Abstract">arXiv:2310.06872</a> [<a href="/pdf/2310.06872" title="Download PDF">pdf</a>, <a href="/format/2310.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On sparse regression, Lp-regularization, and automated model discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCulloch%2C+J+A">Jeremy A. McCulloch</a>, 
<a href="/search/cs?searchtype=author&query=Pierre%2C+S+R+S">Skyler R. St. Pierre</a>, 
<a href="/search/cs?searchtype=author&query=Linka%2C+K">Kevin Linka</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+E">Ellen Kuhl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 15 figures, 2 tables, 62 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Sparse regression and feature extraction are the cornerstones of knowledge
discovery from massive data. Their goal is to discover interpretable and
predictive models that provide simple relationships among scientific variables.
While the statistical tools for model discovery are well established in the
context of linear regression, their generalization to nonlinear regression in
material modeling is highly problem-specific and insufficiently understood.
Here we explore the potential of neural networks for automatic model discovery
and induce sparsity by a hybrid approach that combines two strategies:
regularization and physical constraints. We integrate the concept of Lp
regularization for subset selection with constitutive neural networks that
leverage our domain knowledge in kinematics and thermodynamics. We train our
networks with both, synthetic and real data, and perform several thousand
discovery runs to infer common guidelines and trends: L2 regularization or
ridge regression is unsuitable for model discovery; L1 regularization or lasso
promotes sparsity, but induces strong bias; only L0 regularization allows us to
transparently fine-tune the trade-off between interpretability and
predictability, simplicity and accuracy, and bias and variance. With these
insights, we demonstrate that Lp regularized constitutive neural networks can
simultaneously discover both, interpretable models and physically meaningful
parameters. We anticipate that our findings will generalize to alternative
discovery techniques such as sparse and symbolic regression, and to other
domains such as biology, chemistry, or medicine. Our ability to automatically
discover material models from data could have tremendous applications in
generative material design and open new opportunities to manipulate matter,
alter properties of existing materials, and discover new materials with
user-defined properties.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06874" title="Abstract">arXiv:2310.06874</a> [<a href="/pdf/2310.06874" title="Download PDF">pdf</a>, <a href="/format/2310.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Reality via Cooperative NOMA in Hybrid Cloud/Mobile-Edge  Computing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reifert%2C+R">Robert-Jeron Reifert</a>, 
<a href="/search/cs?searchtype=author&query=Dahrouj%2C+H">Hayssam Dahrouj</a>, 
<a href="/search/cs?searchtype=author&query=Sezgin%2C+A">Aydin Sezgin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 15 figures, 3 tables. Submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Extended reality (XR) applications often perform resource-intensive tasks,
which are computed remotely, a process that prioritizes the latency criticality
aspect. To this end, this paper shows that through leveraging the power of the
central cloud (CC), the close proximity of edge computers (ECs), and the
flexibility of uncrewed aerial vehicles (UAVs), a UAV-aided hybrid
cloud/mobile-edge computing architecture promises to handle the intricate
requirements of future XR applications. In this context, this paper
distinguishes between two types of XR devices, namely, strong and weak devices.
The paper then introduces a cooperative non-orthogonal multiple access
(Co-NOMA) scheme, pairing strong and weak devices, so as to aid the XR devices
quality-of-user experience by intelligently selecting either the direct or the
relay links toward the weak XR devices. A sum logarithmic-rate maximization
problem is, thus, formulated so as to jointly determine the computation and
communication resources, and link-selection strategy as a means to strike a
trade-off between the system throughput and fairness. Subject to realistic
network constraints, e.g., power consumption and delay, the optimization
problem is then solved iteratively via discrete relaxations, successive-convex
approximation, and fractional programming, an approach which can be implemented
in a distributed fashion across the network. Simulation results validate the
proposed algorithms performance in terms of log-rate maximization,
delay-sensitivity, scalability, and runtime performance. The practical
distributed Co-NOMA implementation is particularly shown to offer appreciable
benefits over traditional multiple access and NOMA methods, highlighting its
applicability in decentralized XR systems.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06879" title="Abstract">arXiv:2310.06879</a> [<a href="/pdf/2310.06879" title="Download PDF">pdf</a>, <a href="/format/2310.06879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Solution for the CVPR2023 NICE Image Captioning Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiangyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weili Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we present our solution to the New frontiers for Zero-shot
Image Captioning Challenge. Different from the traditional image captioning
datasets, this challenge includes a larger new variety of visual concepts from
many domains (such as COVID-19) as well as various image types (photographs,
illustrations, graphics). For the data level, we collect external training data
from Laion-5B, a large-scale CLIP-filtered image-text dataset. For the model
level, we use OFA, a large-scale visual-language pre-training model based on
handcrafted templates, to perform the image captioning task. In addition, we
introduce contrastive learning to align image-text pairs to learn new visual
concepts in the pre-training stage. Then, we propose a similarity-bucket
strategy and incorporate this strategy into the template to force the model to
generate higher quality and more matching captions. Finally, by
retrieval-augmented strategy, we construct a content-rich template, containing
the most relevant top-k captions from other image-text pairs, to guide the
model in generating semantic-rich captions. Our method ranks first on the
leaderboard, achieving 105.17 and 325.72 Cider-Score in the validation and test
phase, respectively.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06903" title="Abstract">arXiv:2310.06903</a> [<a href="/pdf/2310.06903" title="Download PDF">pdf</a>, <a href="/format/2310.06903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning in a Safety-Embedded MDP with Trajectory  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Safe Reinforcement Learning (RL) plays an important role in applying RL
algorithms to safety-critical real-world applications, addressing the trade-off
between maximizing rewards and adhering to safety constraints. This work
introduces a novel approach that combines RL with trajectory optimization to
manage this trade-off effectively. Our approach embeds safety constraints
within the action space of a modified Markov Decision Process (MDP). The RL
agent produces a sequence of actions that are transformed into safe
trajectories by a trajectory optimizer, thereby effectively ensuring safety and
increasing training stability. This novel approach excels in its performance on
challenging Safety Gym tasks, achieving significantly higher rewards and
near-zero safety violations during inference. The method's real-world
applicability is demonstrated through a safe and effective deployment in a real
robot task of box-pushing around obstacles.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06904" title="Abstract">arXiv:2310.06904</a> [<a href="/pdf/2310.06904" title="Download PDF">pdf</a>, <a href="/ps/2310.06904" title="Download PostScript">ps</a>, <a href="/format/2310.06904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating stereotypical biases in text to image generative systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esposito%2C+P">Piero Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Atighehchian%2C+P">Parmida Atighehchian</a>, 
<a href="/search/cs?searchtype=author&query=Germanidis%2C+A">Anastasis Germanidis</a>, 
<a href="/search/cs?searchtype=author&query=Ghadiyaram%2C+D">Deepti Ghadiyaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">State-of-the-art generative text-to-image models are known to exhibit social
biases and over-represent certain groups like people of perceived lighter skin
tones and men in their outcomes. In this work, we propose a method to mitigate
such biases and ensure that the outcomes are fair across different groups of
people. We do this by finetuning text-to-image models on synthetic data that
varies in perceived skin tones and genders constructed from diverse text
prompts. These text prompts are constructed from multiplicative combinations of
ethnicities, genders, professions, age groups, and so on, resulting in diverse
synthetic data. Our diversity finetuned (DFT) model improves the group fairness
metric by 150% for perceived skin tone and 97.7% for perceived gender. Compared
to baselines, DFT models generate more people with perceived darker skin tone
and more women. To foster open research, we will release all text prompts and
code to generate training images.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06906" title="Abstract">arXiv:2310.06906</a> [<a href="/pdf/2310.06906" title="Download PDF">pdf</a>, <a href="/format/2310.06906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distillation Improves Visual Place Recognition for Low-Quality Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+A">Anbang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+J">John-Ross Rizzo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The shift to online computing for real-time visual localization often
requires streaming query images/videos to a server for visual place recognition
(VPR), where fast video transmission may result in reduced resolution or
increased quantization. This compromises the quality of global image
descriptors, leading to decreased VPR performance. To improve the low recall
rate for low-quality query images, we present a simple yet effective method
that uses high-quality queries only during training to distill better feature
representations for deep-learning-based VPR, such as NetVLAD. Specifically, we
use mean squared error (MSE) loss between the global descriptors of queries
with different qualities, and inter-channel correlation knowledge distillation
(ICKD) loss over their corresponding intermediate features. We validate our
approach using the both Pittsburgh 250k dataset and our own indoor dataset with
varying quantization levels. By fine-tuning NetVLAD parameters with our
distillation-augmented losses, we achieve notable VPR recall-rate improvements
over low-quality queries, as demonstrated in our extensive experimental
results. We believe this work not only pushes forward the VPR research but also
provides valuable insights for applications needing dependable place
recognition under resource-limited conditions.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06907" title="Abstract">arXiv:2310.06907</a> [<a href="/pdf/2310.06907" title="Download PDF">pdf</a>, <a href="/format/2310.06907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Object-Centric Learning for Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aydemir%2C+G">G&#xf6;rkay Aydemir</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCney%2C+F">Fatma G&#xfc;ney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised multi-object segmentation has shown impressive results on images
by utilizing powerful semantics learned from self-supervised pretraining. An
additional modality such as depth or motion is often used to facilitate the
segmentation in video sequences. However, the performance improvements observed
in synthetic sequences, which rely on the robustness of an additional cue, do
not translate to more challenging real-world scenarios. In this paper, we
propose the first fully unsupervised method for segmenting multiple objects in
real-world sequences. Our object-centric learning framework spatially binds
objects to slots on each frame and then relates these slots across frames. From
these temporally-aware slots, the training objective is to reconstruct the
middle frame in a high-level semantic feature space. We propose a masking
strategy by dropping a significant portion of tokens in the feature space for
efficiency and regularization. Additionally, we address over-clustering by
merging slots based on similarity. Our method can successfully segment multiple
instances of complex and high-variety classes in YouTube videos.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06911" title="Abstract">arXiv:2310.06911</a> [<a href="/pdf/2310.06911" title="Download PDF">pdf</a>, <a href="/format/2310.06911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum annealing-sequential quadratic programming assisted finite  element simulation for non-linear and history-dependent mechanical problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Dung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Remacle%2C+F">Francoise Remacle</a>, 
<a href="/search/cs?searchtype=author&query=Noels%2C+L">Ludovic Noels</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We propose a framework to solve non-linear and history-dependent mechanical
problems based on a hybrid classical computer-quantum annealer approach.
Quantum Computers are anticipated to solve particular operations exponentially
faster. The available possible operations are however not as versatile as with
a classical computer. However, quantum annealers (QAs) is well suited to
evaluate the minimum state of a Hamiltonian quadratic potential. Therefore, we
reformulate the elasto-plastic finite element problem as a double minimisation
process framed at the structural scale using the variational updates
formulation. In order to comply with the expected quadratic nature of the
Hamiltonian, the resulting non-linear minimisation problems are iteratively
solved with the suggested Quantum Annealing-assisted Sequential Quadratic
Programming (QA-SQP): a sequence of minimising quadratic problems is performed
by approximating the objective function by a quadratic Taylor's series. Each
quadratic minimisation problem of continuous variables is then transformed into
a binary quadratic problem. This binary quadratic minimisation problem can be
solved on quantum annealing hardware such as the D-Wave system. The
applicability of the proposed framework is demonstrated with one and
two-dimensional elasto-plastic numerical benchmarks. The current work provides
a pathway of performing general non-linear finite element simulations assisted
by quantum computing.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06912" title="Abstract">arXiv:2310.06912</a> [<a href="/pdf/2310.06912" title="Download PDF">pdf</a>, <a href="/format/2310.06912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Deep Learning Fuzzers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harzevili%2C+N+S">Nima Shiri Harzevili</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+V">Hung Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In this work, we set out to conduct the first ground-truth empirical
evaluation of state-of-the-art DL fuzzers. Specifically, we first manually
created an extensive DL bug benchmark dataset, which includes 627 real-world DL
bugs from TensorFlow and PyTorch libraries reported by users between 2020 and
2022. Then we run three state-of-the-art DL fuzzers, i.e., FreeFuzz, DeepRel,
and DocTer, on the benchmark by following their instructions. We find that
these fuzzers are unable to detect many real bugs collected in our benchmark
dataset. Specifically, most (235) of the 257 applicable bugs cannot be detected
by any fuzzer.
<br />Our systematic analysis further identifies four major, broad, and common
factors that affect these fuzzers' ability to detect real bugs. These findings
present opportunities to improve the performance of the fuzzers in future work.
As a proof of concept, we propose a lightweight corner case generator as an
extension to the three DL fuzzers, which simply covers several boundary values
as well as DL-specific data types. It helps FreeFuzz, DeepRel, and DocTer
detect 12, 12, and 14 more bugs, respectively, that were overlooked by the
original fuzzers. Overall, this work complements prior studies on DL fuzzers
with an extensive performance evaluation and provides a benchmark for future DL
library fuzzing studies. Also, our proposed corner case generator proves that
the fuzzers can be extended to detect more bugs by extending their internal
fuzzing logic based on the insights provided in root cause analysis.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06913" title="Abstract">arXiv:2310.06913</a> [<a href="/pdf/2310.06913" title="Download PDF">pdf</a>, <a href="/format/2310.06913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Transformer-based Neural Text Representation  Techniques on Bug Triaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dipongkor%2C+A+K">Atish Kumar Dipongkor</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+K">Kevin Moran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, to appear in the Proceedings of 38th IEEE/ACM International Conference on Automated Software Engineering (ASE'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Often, the first step in managing bug reports is related to triaging a bug to
the appropriate developer who is best suited to understand, localize, and fix
the target bug. Additionally, assigning a given bug to a particular part of a
software project can help to expedite the fixing process. However, despite the
importance of these activities, they are quite challenging, where days can be
spent on the manual triaging process. Past studies have attempted to leverage
the limited textual data of bug reports to train text classification models
that automate this process -- to varying degrees of success. However, the
textual representations and machine learning models used in prior work are
limited by their expressiveness, often failing to capture nuanced textual
patterns that might otherwise aid in the triaging process. Recently, large,
transformer-based, pre-trained neural text representation techniques such as
BERT have achieved greater performance in several natural language processing
tasks. However, the potential for using these techniques to improve upon prior
approaches for automated bug triaging is not well studied or understood.
<br />Therefore, in this paper we offer one of the first investigations that
fine-tunes transformer-based language models for the task of bug triaging on
four open source datasets, spanning a collective 53 years of development
history with over 400 developers and over 150 software project components. Our
study includes both a quantitative and qualitative analysis of effectiveness.
Our findings illustrate that DeBERTa is the most effective technique across the
triaging tasks of developer and component assignment, and the measured
performance delta is statistically significant compared to other techniques.
However, through our qualitative analysis, we also observe that each technique
possesses unique abilities best suited to certain types of bug reports.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06916" title="Abstract">arXiv:2310.06916</a> [<a href="/pdf/2310.06916" title="Download PDF">pdf</a>, <a href="/format/2310.06916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Transfer Learning with 4th Gen Intel Xeon Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arunachalam%2C+L">Lakshmi Arunachalam</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+F">Fahim Mohammad</a>, 
<a href="/search/cs?searchtype=author&query=Sanghavi%2C+V+H">Vrushabh H. Sanghavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we explore how transfer learning, coupled with Intel Xeon,
specifically 4th Gen Intel Xeon scalable processor, defies the conventional
belief that training is primarily GPU-dependent. We present a case study where
we achieved near state-of-the-art accuracy for image classification on a
publicly available Image Classification TensorFlow dataset using Intel Advanced
Matrix Extensions(AMX) and distributed training with Horovod.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06918" title="Abstract">arXiv:2310.06918</a> [<a href="/pdf/2310.06918" title="Download PDF">pdf</a>, <a href="/format/2310.06918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Contrastive Learning of Sentence Embeddings with Focal-InfoNCE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+P">Pengyue Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp 2023 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent success of SimCSE has greatly advanced state-of-the-art sentence
representations. However, the original formulation of SimCSE does not fully
exploit the potential of hard negative samples in contrastive learning. This
study introduces an unsupervised contrastive learning framework that combines
SimCSE with hard negative mining, aiming to enhance the quality of sentence
embeddings. The proposed focal-InfoNCE function introduces self-paced
modulation terms in the contrastive objective, downweighting the loss
associated with easy negatives and encouraging the model focusing on hard
negatives. Experimentation on various STS benchmarks shows that our method
improves sentence embeddings in terms of Spearman's correlation and
representation alignment and uniformity.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06923" title="Abstract">arXiv:2310.06923</a> [<a href="/pdf/2310.06923" title="Download PDF">pdf</a>, <a href="/format/2310.06923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PICProp: Physics-Informed Confidence Propagation for Uncertainty  Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qianli Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W+H">Wai Hoh Tang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Psaros%2C+A">Apostolos Psaros</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. Code is available at <a href="https://github.com/ShenQianli/PICProp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Standard approaches for uncertainty quantification in deep learning and
physics-informed learning have persistent limitations. Indicatively, strong
assumptions regarding the data likelihood are required, the performance highly
depends on the selection of priors, and the posterior can be sampled only
approximately, which leads to poor approximations because of the associated
computational cost. This paper introduces and studies confidence interval (CI)
estimation for deterministic partial differential equations as a novel problem.
That is, to propagate confidence, in the form of CIs, from data locations to
the entire domain with probabilistic guarantees. We propose a method, termed
Physics-Informed Confidence Propagation (PICProp), based on bi-level
optimization to compute a valid CI without making heavy assumptions. We provide
a theorem regarding the validity of our method, and computational experiments,
where the focus is on physics-informed learning.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06927" title="Abstract">arXiv:2310.06927</a> [<a href="/pdf/2310.06927" title="Download PDF">pdf</a>, <a href="/format/2310.06927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Finetuning for Inference Acceleration of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurtic%2C+E">Eldar Kurtic</a>, 
<a href="/search/cs?searchtype=author&query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Goin%2C+M">Michael Goin</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the problem of accurate sparse finetuning of large language
models (LLMs), that is, finetuning pretrained LLMs on specialized tasks, while
inducing sparsity in their weights. On the accuracy side, we observe that
standard loss-based finetuning may fail to recover accuracy, especially at high
sparsities. To address this, we perform a detailed study of distillation-type
losses, determining an L2-based distillation approach we term SquareHead which
enables accurate recovery even at higher sparsities, across all model types. On
the practical efficiency side, we show that sparse LLMs can be executed with
speedups by taking advantage of sparsity, for both CPU and GPU runtimes. While
the standard approach is to leverage sparsity for computational reduction, we
observe that in the case of memory-bound LLMs sparsity can also be leveraged
for reducing memory bandwidth. We exhibit end-to-end results showing speedups
due to sparsity, while recovering accuracy, on T5 (language translation),
Whisper (speech translation), and open GPT-type (MPT for text generation). For
MPT text generation, we show for the first time that sparse finetuning can
reach 75% sparsity without accuracy drops, provide notable end-to-end speedups
for both CPU and GPU inference, and highlight that sparsity is also compatible
with quantization approaches. Models and software for reproducing our results
are provided in Section 6.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06930" title="Abstract">arXiv:2310.06930</a> [<a href="/pdf/2310.06930" title="Download PDF">pdf</a>, <a href="/format/2310.06930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prosody Analysis of Audiobooks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pethe%2C+C">Charuta Pethe</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yunting Yin</a>, 
<a href="/search/cs?searchtype=author&query=Skiena%2C+S">Steven Skiena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent advances in text-to-speech have made it possible to generate
natural-sounding audio from text. However, audiobook narrations involve
dramatic vocalizations and intonations by the reader, with greater reliance on
emotions, dialogues, and descriptions in the narrative. Using our dataset of 93
aligned book-audiobook pairs, we present improved models for prosody prediction
properties (pitch, volume, and rate of speech) from narrative text using
language modeling. Our predicted prosody attributes correlate much better with
human audiobook readings than results from a state-of-the-art commercial TTS
system: our predicted pitch shows a higher correlation with human reading for
22 out of the 24 books, while our predicted volume attribute proves more
similar to human reading for 23 out of the 24 books. Finally, we present a
human evaluation study to quantify the extent that people prefer
prosody-enhanced audiobook readings over commercial text-to-speech systems.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06931" title="Abstract">arXiv:2310.06931</a> [<a href="/pdf/2310.06931" title="Download PDF">pdf</a>, <a href="/format/2310.06931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAILing CAVs: Speed-Adaptive Infrastructure-Linked Connected and  Automated Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nice%2C+M">Matthew Nice</a>, 
<a href="/search/cs?searchtype=author&query=Bunting%2C+M">Matthew Bunting</a>, 
<a href="/search/cs?searchtype=author&query=Gunter%2C+G">George Gunter</a>, 
<a href="/search/cs?searchtype=author&query=Barbour%2C+W">William Barbour</a>, 
<a href="/search/cs?searchtype=author&query=Sprinkle%2C+J">Jonathan Sprinkle</a>, 
<a href="/search/cs?searchtype=author&query=Work%2C+D">Dan Work</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work demonstrates a new capability in roadway control: Speed-adaptive,
infrastructure-linked connected and automated vehicles. We develop and deploy a
lightly modified vehicle that is able to dynamically adjust the vehicle speed
in response to posted variable speed limit messages generated by the
infrastructure using LTE connectivity. This work describes the open source
hardware and software platform that enables integration between
infrastructure-based variable posted speed limits, and existing vehicle
platforms for automated control. The vehicle is deployed in heavy morning
traffic on I-24 in Nashville, TN. The control vehicle follows the posted
variable speed limits, resulting in as much as a 25% reduction in speed
variability compared to a human-piloted vehicle in the same traffic stream.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06933" title="Abstract">arXiv:2310.06933</a> [<a href="/pdf/2310.06933" title="Download PDF">pdf</a>, <a href="/format/2310.06933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eclares: Energy-Aware Clarity-Driven Ergodic Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naveed%2C+K+B">Kaleb Ben Naveed</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+D">Devansh Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Vermillion%2C+C">Christopher Vermillion</a>, 
<a href="/search/cs?searchtype=author&query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to International Conference of Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Planning informative trajectories while considering the spatial distribution
of the information over the environment, as well as constraints such as the
robot's limited battery capacity, makes the long-time horizon persistent
coverage problem complex. Ergodic search methods consider the spatial
distribution of environmental information while optimizing robot trajectories;
however, current methods lack the ability to construct the target information
spatial distribution for environments that vary stochastically across space and
time. Moreover, current coverage methods dealing with battery capacity
constraints either assume simple robot and battery models, or are
computationally expensive. To address these problems, we propose a framework
called Eclares, in which our contribution is two-fold. 1) First, we propose a
method to construct the target information spatial distribution for ergodic
trajectory optimization using clarity, an information measure bounded between
[0,1]. The clarity dynamics allows us to capture information decay due to lack
of measurements and to quantify the maximum attainable information in
stochastic spatiotemporal environments. 2) Second, instead of directly tracking
the ergodic trajectory, we introduce the energy-aware (eware) filter, which
iteratively validates the ergodic trajectory to ensure that the robot has
enough energy to return to the charging station when needed. The proposed eware
filter is applicable to nonlinear robot models and is computationally
lightweight. We demonstrate the working of the framework through a simulation
case study.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06936" title="Abstract">arXiv:2310.06936</a> [<a href="/pdf/2310.06936" title="Download PDF">pdf</a>, <a href="/format/2310.06936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs Killed the Script Kiddie: How Agents Supported by Large Language  Models Change the Landscape of Network Threat Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskal%2C+S">Stephen Moskal</a>, 
<a href="/search/cs?searchtype=author&query=Laney%2C+S">Sam Laney</a>, 
<a href="/search/cs?searchtype=author&query=Hemberg%2C+E">Erik Hemberg</a>, 
<a href="/search/cs?searchtype=author&query=O%27Reilly%2C+U">Una-May O&#x27;Reilly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we explore the potential of Large Language Models (LLMs) to
reason about threats, generate information about tools, and automate cyber
campaigns. We begin with a manual exploration of LLMs in supporting specific
threat-related actions and decisions. We proceed by automating the decision
process in a cyber campaign. We present prompt engineering approaches for a
plan-act-report loop for one action of a threat campaign and and a prompt
chaining design that directs the sequential decision process of a multi-action
campaign. We assess the extent of LLM's cyber-specific knowledge w.r.t the
short campaign we demonstrate and provide insights into prompt design for
eliciting actionable responses. We discuss the potential impact of LLMs on the
threat landscape and the ethical considerations of using LLMs for accelerating
threat actor capabilities. We report a promising, yet concerning, application
of generative AI to cyber threats. However, the LLM's capabilities to deal with
more complex networks, sophisticated vulnerabilities, and the sensitivity of
prompts are open questions. This research should spur deliberations over the
inevitable advancements in LLM-supported cyber adversarial landscape.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06939" title="Abstract">arXiv:2310.06939</a> [<a href="/pdf/2310.06939" title="Download PDF">pdf</a>, <a href="/format/2310.06939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Font Formats in Building Efficient Web Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dornauer%2C+B">Benedikt Dornauer</a>, 
<a href="/search/cs?searchtype=author&query=Vigl%2C+W">Wolfgang Vigl</a>, 
<a href="/search/cs?searchtype=author&query=Felderer%2C+M">Michael Felderer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint: Product-Focused Software Process Improvement 24th International Conference, PROFES 2023, Dornbirn, Austria, December 10-13, 2023, Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The success of a web application is closely linked to its performance, which
positively impacts user satisfaction and contributes to energy-saving efforts.
Among the various optimization techniques, one specific subject focuses on
improving the utilization of web fonts. This study investigates the impact of
different font formats on client-side resource consumption, such as CPU,
memory, load time, and energy. In a controlled experiment, we evaluate
performance metrics using the four font formats: OTF, TTF, WOFF, and WOFF2. The
results of the study show that there are significant differences between all
pair-wise format comparisons regarding all performance metrics. Overall, WOFF2
performs best, except in terms of memory allocation. Through the study and
examination of literature, this research contributes (1) an overview of
methodologies to enhance web performance through font utilization, (2) a
specific exploration of the four prevalent font formats in an experimental
setup, and (3) practical recommendations for scientific professionals and
practitioners.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06940" title="Abstract">arXiv:2310.06940</a> [<a href="/pdf/2310.06940" title="Download PDF">pdf</a>, <a href="/format/2310.06940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Document-Level Supervision for Multi-Aspect Sentiment Analysis Without  Fine-grained Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+K">Kasturi Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Gangadharaiah%2C+R">Rashmi Gangadharaiah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aspect-based sentiment analysis (ABSA) is a widely studied topic, most often
trained through supervision from human annotations of opinionated texts. These
fine-grained annotations include identifying aspects towards which a user
expresses their sentiment, and their associated polarities (aspect-based
sentiments). Such fine-grained annotations can be expensive and often
infeasible to obtain in real-world settings. There is, however, an abundance of
scenarios where user-generated text contains an overall sentiment, such as a
rating of 1-5 in user reviews or user-generated feedback, which may be
leveraged for this task. In this paper, we propose a VAE-based topic modeling
approach that performs ABSA using document-level supervision and without
requiring fine-grained labels for either aspects or sentiments. Our approach
allows for the detection of multiple aspects in a document, thereby allowing
for the possibility of reasoning about how sentiment expressed through multiple
aspects comes together to form an observable overall document-level sentiment.
We demonstrate results on two benchmark datasets from two different domains,
significantly outperforming a state-of-the-art baseline.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06947" title="Abstract">arXiv:2310.06947</a> [<a href="/pdf/2310.06947" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open SYCL on heterogeneous GPU systems: A case of study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carratal%C3%A1-S%C3%A1ez%2C+R">Roc&#xed;o Carratal&#xe1;-S&#xe1;ez</a>, 
<a href="/search/cs?searchtype=author&query=and%C3%BAjar%2C+F+J">Francisco J. and&#xfa;jar</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+Y">Yuri Torres</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Escribano%2C+A">Arturo Gonzalez-Escribano</a>, 
<a href="/search/cs?searchtype=author&query=Llanos%2C+D+R">Diego R. Llanos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Computational platforms for high-performance scientific applications are
becoming more heterogenous, including hardware accelerators such as multiple
GPUs. Applications in a wide variety of scientific fields require an efficient
and careful management of the computational resources of this type of hardware
to obtain the best possible performance. However, there are currently different
GPU vendors, architectures and families that can be found in heterogeneous
clusters or machines. Programming with the vendor provided languages or
frameworks, and optimizing for specific devices, may become cumbersome and
compromise portability to other systems. To overcome this problem, several
proposals for high-level heterogeneous programming have appeared, trying to
reduce the development effort and increase functional and performance
portability, specifically when using GPU hardware accelerators.
<br />This paper evaluates the SYCL programming model, using the Open SYCL
compiler, from two different perspectives: The performance it offers when
dealing with single or multiple GPU devices from the same or different vendors,
and the development effort required to implement the code. We use as case of
study the Finite Time Lyapunov Exponent calculation over two real-world
scenarios and compare the performance and the development effort of its Open
SYCL-based version against the equivalent versions that use CUDA or HIP.
<br />Based on the experimental results, we observe that the use of SYCL does not
lead to a remarkable overhead in terms of the GPU kernels execution time. In
general terms, the Open SYCL development effort for the host code is lower than
that observed with CUDA or HIP. Moreover, the SYCL version can take advantage
of both CUDA and AMD GPU devices simultaneously much easier than directly using
the vendor-specific programming solutions.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06948" title="Abstract">arXiv:2310.06948</a> [<a href="/pdf/2310.06948" title="Download PDF">pdf</a>, <a href="/format/2310.06948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Variational Autoencoder Framework for Robust, Physics-Informed  Cyberattack Recognition in Industrial Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aftabi%2C+N">Navid Aftabi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+P">Paritosh Ramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2009.12360">arXiv:2009.12360</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Cybersecurity of Industrial Cyber-Physical Systems is drawing significant
concerns as data communication increasingly leverages wireless networks. A lot
of data-driven methods were develope for detecting cyberattacks, but few are
focused on distinguishing them from equipment faults. In this paper, we develop
a data-driven framework that can be used to detect, diagnose, and localize a
type of cyberattack called covert attacks on networked industrial control
systems. The framework has a hybrid design that combines a variational
autoencoder (VAE), a recurrent neural network (RNN), and a Deep Neural Network
(DNN). This data-driven framework considers the temporal behavior of a generic
physical system that extracts features from the time series of the sensor
measurements that can be used for detecting covert attacks, distinguishing them
from equipment faults, as well as localize the attack/fault. We evaluate the
performance of the proposed method through a realistic simulation study on a
networked power transmission system as a typical example of ICS. We compare the
performance of the proposed method with the traditional model-based method to
show its applicability and efficacy.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06950" title="Abstract">arXiv:2310.06950</a> [<a href="/pdf/2310.06950" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Horizon: A Comprehensive Survey of Rowhammer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naseredini%2C+A">Amir Naseredini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Rowhammer poses a significant security challenge for modern computers,
specifically affecting Dynamic Random Access Memory(DRAM). Given society's
growing reliance on computer systems, ensuring the reliability of hardware is
of utmost importance. This paper provides a comprehensive survey of Rowhammer,
examining the literature from various angles. We categorise studies on
Rowhammer into attacks, defences, and intriguing work, exploring each category
in detail. Furthermore, we classify papers within each category into distinct
yet overlapping classes and present an overview of the papers in each class.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06951" title="Abstract">arXiv:2310.06951</a> [<a href="/pdf/2310.06951" title="Download PDF">pdf</a>, <a href="/format/2310.06951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monsters in the Dark: Sanitizing Hidden Threats with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinette%2C+P+K">Preston K. Robinette</a>, 
<a href="/search/cs?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+T+T">Taylor T. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Steganography is the art of hiding information in plain sight. This form of
covert communication can be used by bad actors to propagate malware, exfiltrate
victim data, and communicate with other bad actors. Current image steganography
defenses rely upon steganalysis, or the detection of hidden messages. These
methods, however, are non-blind as they require information about known
steganography techniques and are easily bypassed. Recent work has instead
focused on a defense mechanism known as sanitization, which eliminates hidden
information from images. In this work, we introduce a novel blind deep learning
steganography sanitization method that utilizes a diffusion model framework to
sanitize universal and dependent steganography (DM-SUDS), which both sanitizes
and preserves image quality. We evaluate this approach against state-of-the-art
deep learning sanitization frameworks and provide further detailed analysis
through an ablation study. DM-SUDS outperforms previous sanitization methods
and improves image preservation MSE by 71.32%, PSNR by 22.43% and SSIM by
17.30%. This is the first blind deep learning image sanitization framework to
meet these image quality results.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06952" title="Abstract">arXiv:2310.06952</a> [<a href="/pdf/2310.06952" title="Download PDF">pdf</a>, <a href="/ps/2310.06952" title="Download PostScript">ps</a>, <a href="/format/2310.06952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Golub-Kahan bidiagonalization for nonsymmetric saddle point  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dumitrasc%2C+A">Andrei Dumitrasc</a>, 
<a href="/search/math?searchtype=author&query=Kruse%2C+C">Carola Kruse</a>, 
<a href="/search/math?searchtype=author&query=Ruede%2C+U">Ulrich Ruede</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The generalized Golub-Kahan bidiagonalization has been used to solve
saddle-point systems where the leading block is symmetric and positive
definite. We extend this iterative method for the case where the symmetry
condition no longer holds. We do so by relying on the known connection the
algorithm has with the Conjugate Gradient method and following the line of
reasoning that adapts the latter into the Full Orthogonalization Method. We
propose appropriate stopping criteria based on the residual and an estimate of
the energy norm for the error associated with the primal variable. Numerical
comparison with GMRES highlights the advantages of our proposed strategy
regarding its low memory requirements and the associated implications.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06956" title="Abstract">arXiv:2310.06956</a> [<a href="/pdf/2310.06956" title="Download PDF">pdf</a>, <a href="/format/2310.06956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial optimization leads to over-optimistic security-constrained  dispatch, but sampling can help
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dawson%2C+C">Charles Dawson</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NAPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">To ensure safe, reliable operation of the electrical grid, we must be able to
predict and mitigate likely failures. This need motivates the classic
security-constrained AC optimal power flow (SCOPF) problem. SCOPF is commonly
solved using adversarial optimization, where the dispatcher and an adversary
take turns optimizing a robust dispatch and adversarial attack, respectively.
We show that adversarial optimization is liable to severely overestimate the
robustness of the optimized dispatch (when the adversary encounters a local
minimum), leading the operator to falsely believe that their dispatch is
secure.
<br />To prevent this overconfidence, we develop a novel adversarial sampling
approach that prioritizes diversity in the predicted attacks. We find that our
method not only substantially improves the robustness of the optimized dispatch
but also avoids overconfidence, accurately characterizing the likelihood of
voltage collapse under a given threat model. We demonstrate a proof-of-concept
on small-scale transmission systems with 14 and 57 nodes.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06958" title="Abstract">arXiv:2310.06958</a> [<a href="/pdf/2310.06958" title="Download PDF">pdf</a>, <a href="/format/2310.06958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing the robustness of modern no-reference image- and video-quality  metrics to adversarial attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antsiferova%2C+A">Anastasia Antsiferova</a>, 
<a href="/search/cs?searchtype=author&query=Abud%2C+K">Khaled Abud</a>, 
<a href="/search/cs?searchtype=author&query=Gushchin%2C+A">Aleksandr Gushchin</a>, 
<a href="/search/cs?searchtype=author&query=Lavrushkin%2C+S">Sergey Lavrushkin</a>, 
<a href="/search/cs?searchtype=author&query=Shumitskaya%2C+E">Ekaterina Shumitskaya</a>, 
<a href="/search/cs?searchtype=author&query=Velikanov%2C+M">Maksim Velikanov</a>, 
<a href="/search/cs?searchtype=author&query=Vatolin%2C+D">Dmitriy Vatolin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Nowadays neural-network-based image- and video-quality metrics show better
performance compared to traditional methods. However, they also became more
vulnerable to adversarial attacks that increase metrics' scores without
improving visual quality. The existing benchmarks of quality metrics compare
their performance in terms of correlation with subjective quality and
calculation time. However, the adversarial robustness of image-quality metrics
is also an area worth researching. In this paper, we analyse modern metrics'
robustness to different adversarial attacks. We adopted adversarial attacks
from computer vision tasks and compared attacks' efficiency against 15
no-reference image/video-quality metrics. Some metrics showed high resistance
to adversarial attacks which makes their usage in benchmarks safer than
vulnerable metrics. The benchmark accepts new metrics submissions for
researchers who want to make their metrics more robust to attacks or to find
such metrics for their needs. Try our benchmark using pip install
robustness-benchmark.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06959" title="Abstract">arXiv:2310.06959</a> [<a href="/pdf/2310.06959" title="Download PDF">pdf</a>, <a href="/ps/2310.06959" title="Download PostScript">ps</a>, <a href="/format/2310.06959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Proof Repair in Cubical Agda
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Viola%2C+C">Cosmo Viola</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Max Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ringer%2C+T">Talia Ringer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for associated code, see <a href="https://github.com/InnovativeInventor/proof-repair-cubical">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Recent work introduced an algorithm and tool in Coq to automatically repair
broken proofs in response to changes that correspond to type equivalences. We
report on case studies for manual proof repair across type equivalences using
an adaptation of this algorithm in Cubical Agda. Crucially, these case studies
capture proof repair use cases that were challenging to impossible in prior
work in Coq due to type theoretic limitations, highlighting three benefits to
working in Cubical Agda: (1) quotient types enrich the space of repairs we can
express as type equivalences, (2) dependent path equality makes it possible to
internally state and prove correctness of repaired proofs relative to the
original proofs, and (3) functional extensionality and transport make it simple
to move between slow and fast computations after repair. They also highlight
two challenges of working in Cubical Agda, namely those introduced by: (1) lack
of tools for automation, and (2) proof relevance, especially as it interacts
with definitional equality. We detail these benefits and challenges in hopes to
set the stage for later work in proof repair bridging the benefits of both
languages.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06964" title="Abstract">arXiv:2310.06964</a> [<a href="/pdf/2310.06964" title="Download PDF">pdf</a>, <a href="/format/2310.06964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Cooperative Navigation in Crowds: A Game-Theoretic  Learning-Based Model Predictive Control Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Viet-Anh Le</a>, 
<a href="/search/cs?searchtype=author&query=Tadiparthi%2C+V">Vaishnav Tadiparthi</a>, 
<a href="/search/cs?searchtype=author&query=Chalaki%2C+B">Behdad Chalaki</a>, 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+H+N">Hossein Nourkhiz Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=D%27sa%2C+J">Jovin D&#x27;sa</a>, 
<a href="/search/cs?searchtype=author&query=Moradi-Pari%2C+E">Ehsan Moradi-Pari</a>, 
<a href="/search/cs?searchtype=author&query=Malikopoulos%2C+A+A">Andreas A. Malikopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this paper, we develop a control framework for the coordination of
multiple robots as they navigate through crowded environments. Our framework
comprises of a local model predictive control (MPC) for each robot and a social
long short-term memory model that forecasts pedestrians' trajectories. We
formulate the local MPC formulation for each individual robot that includes
both individual and shared objectives, in which the latter encourages the
emergence of coordination among robots. Next, we consider the multi-robot
navigation and human-robot interaction, respectively, as a potential game and a
two-player game, then employ an iterative best response approach to solve the
resulting optimization problems in a centralized and distributed fashion.
Finally, we demonstrate the effectiveness of coordination among robots in
simulated crowd navigation.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06966" title="Abstract">arXiv:2310.06966</a> [<a href="/pdf/2310.06966" title="Download PDF">pdf</a>, <a href="/format/2310.06966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interpretability of Part-Prototype Based Classifiers: A Human  Centric Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davoodi%2C+O">Omid Davoodi</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadizadehsamakosh%2C+S">Shayan Mohammadizadehsamakosh</a>, 
<a href="/search/cs?searchtype=author&query=Komeili%2C+M">Majid Komeili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Intended for submission to Nature Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Part-prototype networks have recently become methods of interest as an
interpretable alternative to many of the current black-box image classifiers.
However, the interpretability of these methods from the perspective of human
users has not been sufficiently explored. In this work, we have devised a
framework for evaluating the interpretability of part-prototype-based models
from a human perspective. The proposed framework consists of three actionable
metrics and experiments. To demonstrate the usefulness of our framework, we
performed an extensive set of experiments using Amazon Mechanical Turk. They
not only show the capability of our framework in assessing the interpretability
of various part-prototype-based models, but they also are, to the best of our
knowledge, the most comprehensive work on evaluating such methods in a unified
framework.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06968" title="Abstract">arXiv:2310.06968</a> [<a href="/pdf/2310.06968" title="Download PDF">pdf</a>, <a href="/format/2310.06968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ObjectComposer: Consistent Generation of Multiple Objects Without  Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helbling%2C+A">Alec Helbling</a>, 
<a href="/search/cs?searchtype=author&query=Montoya%2C+E">Evan Montoya</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+D+H">Duen Horng Chau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent text-to-image generative models can generate high-fidelity images from
text prompts. However, these models struggle to consistently generate the same
objects in different contexts with the same appearance. Consistent object
generation is important to many downstream tasks like generating comic book
illustrations with consistent characters and setting. Numerous approaches
attempt to solve this problem by extending the vocabulary of diffusion models
through fine-tuning. However, even lightweight fine-tuning approaches can be
prohibitively expensive to run at scale and in real-time. We introduce a method
called ObjectComposer for generating compositions of multiple objects that
resemble user-specified images. Our approach is training-free, leveraging the
abilities of preexisting models. We build upon the recent BLIP-Diffusion model,
which can generate images of single objects specified by reference images.
ObjectComposer enables the consistent generation of compositions containing
multiple specific objects simultaneously, all without modifying the weights of
the underlying models.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06970" title="Abstract">arXiv:2310.06970</a> [<a href="/pdf/2310.06970" title="Download PDF">pdf</a>, <a href="/format/2310.06970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flood and Echo: Algorithmic Alignment of GNNs with Distributed Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathys%2C+J">Jo&#xeb;l Mathys</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6tschl%2C+F">Florian Gr&#xf6;tschl</a>, 
<a href="/search/cs?searchtype=author&query=Nadimpalli%2C+K+V">Kalyan Varma Nadimpalli</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks are a natural fit for learning algorithms. They can
directly represent tasks through an abstract but versatile graph structure and
handle inputs of different sizes. This opens up the possibility for scaling and
extrapolation to larger graphs, one of the most important advantages of an
algorithm. However, this raises two core questions i) How can we enable nodes
to gather the required information in a given graph ($\textit{information
exchange}$), even if is far away and ii) How can we design an execution
framework which enables this information exchange for extrapolation to larger
graph sizes ($\textit{algorithmic alignment for extrapolation}$). We propose a
new execution framework that is inspired by the design principles of
distributed algorithms: Flood and Echo Net. It propagates messages through the
entire graph in a wave like activation pattern, which naturally generalizes to
larger instances. Through its sparse but parallel activations it is provably
more efficient in terms of message complexity. We study the proposed model and
provide both empirical evidence and theoretical insights in terms of its
expressiveness, efficiency, information exchange and ability to extrapolate.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06974" title="Abstract">arXiv:2310.06974</a> [<a href="/pdf/2310.06974" title="Download PDF">pdf</a>, <a href="/format/2310.06974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Path Planning in Large Unknown Environments with Switchable  System Models for Automated Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schumann%2C+O">Oliver Schumann</a>, 
<a href="/search/cs?searchtype=author&query=Buchholz%2C+M">Michael Buchholz</a>, 
<a href="/search/cs?searchtype=author&query=Dietmayer%2C+K">Klaus Dietmayer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Large environments are challenging for path planning algorithms as the size
of the configuration space increases. Furthermore, if the environment is mainly
unexplored, large amounts of the path are planned through unknown areas. Hence,
a complete replanning of the entire path occurs whenever the path collides with
newly discovered obstacles. We propose a novel method that stops the path
planning algorithm after a certain distance. It is used to navigate the
algorithm in large environments and is not prone to problems of existing
navigation approaches. Furthermore, we developed a method to detect significant
environment changes to allow a more efficient replanning. At last, we extend
the path planner to be used in the U-Shift concept vehicle. It can switch to
another system model and rotate around the center of its rear axis. The results
show that the proposed methods generate nearly identical paths compared to the
standard Hybrid A* while drastically reducing the execution time. Furthermore,
we show that the extended path planning algorithm enables the efficient use of
the maneuvering capabilities of the concept vehicle to plan concise paths in
narrow environments.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06975" title="Abstract">arXiv:2310.06975</a> [<a href="/pdf/2310.06975" title="Download PDF">pdf</a>, <a href="/ps/2310.06975" title="Download PostScript">ps</a>, <a href="/format/2310.06975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Intelligent Surfaces-Enabled Intra-Cell Pilot Reuse in  Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filho%2C+J+C+M">Jose Carlos Marinello Filho</a>, 
<a href="/search/cs?searchtype=author&query=Abrao%2C+T">Taufik Abrao</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Mezghani%2C+A">Amine Mezghani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, full paper, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Applications (stat.AP)

</div>
<p class="mathjax">Channel state information (CSI) estimation is a critical issue in the design
of modern massive multiple-input multiple-output (mMIMO) networks. With the
increasing number of users, assigning orthogonal pilots to everyone incurs a
large overhead that strongly penalizes the system's spectral efficiency (SE).
It becomes thus necessary to reuse pilots, giving rise to pilot contamination,
a vital performance bottleneck of mMIMO networks. Reusing pilots among the
users of the same cell is a desirable operation condition from the perspective
of reducing training overheads; however, the intra-cell pilot contamination
might worsen due to the users' proximity. Reconfigurable intelligent surfaces
(RISs), capable of smartly controlling the wireless channel, can be leveraged
for intra-cell pilot reuse. In this paper, our main contribution is a RIS-aided
approach for intra-cell pilot reuse and the corresponding channel estimation
method. Relying upon the knowledge of only statistical CSI, we optimize the RIS
phase shifts based on a manifold optimization framework and the RIS positioning
based on a deterministic approach. The extensive numerical results highlight
the remarkable performance improvements the proposed scheme achieves (for both
uplink and downlink transmissions) compared to other alternatives.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06977" title="Abstract">arXiv:2310.06977</a> [<a href="/pdf/2310.06977" title="Download PDF">pdf</a>, <a href="/format/2310.06977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why bother with geometry? On the relevance of linear decompositions of  Transformer embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mickus%2C+T">Timothee Mickus</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A1zquez%2C+R">Ra&#xfa;l V&#xe1;zquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BlackBoxNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A recent body of work has demonstrated that Transformer embeddings can be
linearly decomposed into well-defined sums of factors, that can in turn be
related to specific network inputs or components. There is however still a
dearth of work studying whether these mathematical reformulations are
empirically meaningful. In the present work, we study representations from
machine-translation decoders using two of such embedding decomposition methods.
Our results indicate that, while decomposition-derived indicators effectively
correlate with model performance, variation across different runs suggests a
more nuanced take on this question. The high variability of our measurements
indicate that geometry reflects model-specific characteristics more than it
does sentence-specific computations, and that similar training conditions do
not guarantee similar vector spaces.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06982" title="Abstract">arXiv:2310.06982</a> [<a href="/pdf/2310.06982" title="Download PDF">pdf</a>, <a href="/format/2310.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Distillation Can Be Like Vodka: Distilling More Times For Better  Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dataset distillation aims to minimize the time and memory needed for training
deep networks on large datasets, by creating a small set of synthetic images
that has a similar generalization performance to that of the full dataset.
However, current dataset distillation techniques fall short, showing a notable
performance gap when compared to training on the original data. In this work,
we are the first to argue that using just one synthetic subset for distillation
will not yield optimal generalization performance. This is because the training
dynamics of deep networks drastically change during the training. Hence,
multiple synthetic subsets are required to capture the training dynamics at
different phases of training. To address this issue, we propose Progressive
Dataset Distillation (PDD). PDD synthesizes multiple small sets of synthetic
images, each conditioned on the previous sets, and trains the model on the
cumulative union of these subsets without requiring additional training time.
Our extensive experiments show that PDD can effectively improve the performance
of existing dataset distillation methods by up to 4.3%. In addition, our method
for the first time enable generating considerably larger synthetic datasets.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06983" title="Abstract">arXiv:2310.06983</a> [<a href="/pdf/2310.06983" title="Download PDF">pdf</a>, <a href="/format/2310.06983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Violation of Expectation via Metacognitive Prompting Reduces Theory of  Mind Prediction Error in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leer%2C+C">Courtland Leer</a>, 
<a href="/search/cs?searchtype=author&query=Trost%2C+V">Vincent Trost</a>, 
<a href="/search/cs?searchtype=author&query=Voruganti%2C+V">Vineeth Voruganti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent research shows that Large Language Models (LLMs) exhibit a compelling
level of proficiency in Theory of Mind (ToM) tasks. This ability to impute
unobservable mental states to others is vital to human social cognition and may
prove equally important in principal-agent relations between individual humans
and Artificial Intelligences (AIs). In this paper, we explore how a mechanism
studied in developmental psychology known as Violation of Expectation (VoE) can
be implemented to reduce errors in LLM prediction about users by leveraging
emergent ToM affordances. And we introduce a \textit{metacognitive prompting}
framework to apply VoE in the context of an AI tutor. By storing and retrieving
facts derived in cases where LLM expectation about the user was violated, we
find that LLMs are able to learn about users in ways that echo theories of
human learning. Finally, we discuss latent hazards and augmentative
opportunities associated with modeling user psychology and propose ways to
mitigate risk along with possible directions for future inquiry.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06984" title="Abstract">arXiv:2310.06984</a> [<a href="/pdf/2310.06984" title="Download PDF">pdf</a>, <a href="/format/2310.06984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Neural Radiance Fields for Uncertainty-Aware Visual  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weirong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">As a promising fashion for visual localization, scene coordinate regression
(SCR) has seen tremendous progress in the past decade. Most recent methods
usually adopt neural networks to learn the mapping from image pixels to 3D
scene coordinates, which requires a vast amount of annotated training data. We
propose to leverage Neural Radiance Fields (NeRF) to generate training samples
for SCR. Despite NeRF's efficiency in rendering, many of the rendered data are
polluted by artifacts or only contain minimal information gain, which can
hinder the regression accuracy or bring unnecessary computational costs with
redundant data. These challenges are addressed in three folds in this paper:
(1) A NeRF is designed to separately predict uncertainties for the rendered
color and depth images, which reveal data reliability at the pixel level. (2)
SCR is formulated as deep evidential learning with epistemic uncertainty, which
is used to evaluate information gain and scene coordinate quality. (3) Based on
the three arts of uncertainties, a novel view selection policy is formed that
significantly improves data efficiency. Experiments on public datasets
demonstrate that our method could select the samples that bring the most
information gain and promote the performance with the highest efficiency.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06986" title="Abstract">arXiv:2310.06986</a> [<a href="/pdf/2310.06986" title="Download PDF">pdf</a>, <a href="/format/2310.06986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order biorthogonal functions in H(Curl)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haubold%2C+T">Tim Haubold</a>, 
<a href="/search/math?searchtype=author&query=Beuchler%2C+S">Sven Beuchler</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6berl%2C+J">Joachim Sch&#xf6;berl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">From the literature, it is known that the choice of basis functions in hp-FEM
heavily influences the computational cost in order to obtain an approximate
solution. Depending on the choice of the reference element, suitable tensor
product like basis functions of Jacobi polynomials with different weights lead
to optimal properties due to condition number and sparsity. This paper presents
biorthogonal basis functions to the primal basis functions mentioned above. The
authors investigate hypercubes and simplices as reference elements, as well as
the cases of $H^1$ and H(Curl). The functions can be expressed sums of tensor
products of Jacobi polynomials with maximal two summands.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06987" title="Abstract">arXiv:2310.06987</a> [<a href="/pdf/2310.06987" title="Download PDF">pdf</a>, <a href="/format/2310.06987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangsibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Samyak Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Mengzhou Xia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The rapid progress in open-source large language models (LLMs) is
significantly advancing AI development. Extensive efforts have been made before
model release to align their behavior with human values, with the primary goal
of ensuring their helpfulness and harmlessness. However, even carefully aligned
models can be manipulated maliciously, leading to unintended behaviors, known
as "jailbreaks". These jailbreaks are typically triggered by specific text
inputs, often referred to as adversarial prompts. In this work, we propose the
generation exploitation attack, an extremely simple approach that disrupts
model alignment by only manipulating variations of decoding methods. By
exploiting different generation strategies, including varying decoding
hyper-parameters and sampling methods, we increase the misalignment rate from
0% to more than 95% across 11 language models including LLaMA2, Vicuna, Falcon,
and MPT families, outperforming state-of-the-art attacks with $30\times$ lower
computational cost. Finally, we propose an effective alignment method that
explores diverse generation strategies, which can reasonably reduce the
misalignment rate under our attack. Altogether, our study underscores a major
failure in current safety evaluation and alignment procedures for open-source
LLMs, strongly advocating for more comprehensive red teaming and better
alignment before releasing such models. Our code is available at
https://github.com/Princeton-SysML/Jailbreak_LLM.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06989" title="Abstract">arXiv:2310.06989</a> [<a href="/pdf/2310.06989" title="Download PDF">pdf</a>, <a href="/format/2310.06989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TDPP: Two-Dimensional Permutation-Based Protection of Memristive Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+M">Minhui Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhenhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg-Toledo%2C+T">Tzofnat Greenberg-Toledo</a>, 
<a href="/search/cs?searchtype=author&query=Leitersdorf%2C+O">Orian Leitersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junlong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>, 
<a href="/search/cs?searchtype=author&query=Kvatinsky%2C+S">Shahar Kvatinsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The execution of deep neural network (DNN) algorithms suffers from
significant bottlenecks due to the separation of the processing and memory
units in traditional computer systems. Emerging memristive computing systems
introduce an in situ approach that overcomes this bottleneck. The
non-volatility of memristive devices, however, may expose the DNN weights
stored in memristive crossbars to potential theft attacks. Therefore, this
paper proposes a two-dimensional permutation-based protection (TDPP) method
that thwarts such attacks. We first introduce the underlying concept that
motivates the TDPP method: permuting both the rows and columns of the DNN
weight matrices. This contrasts with previous methods, which focused solely on
permuting a single dimension of the weight matrices, either the rows or
columns. While it's possible for an adversary to access the matrix values, the
original arrangement of rows and columns in the matrices remains concealed. As
a result, the extracted DNN model from the accessed matrix values would fail to
operate correctly. We consider two different memristive computing systems
(designed for layer-by-layer and layer-parallel processing, respectively) and
demonstrate the design of the TDPP method that could be embedded into the two
systems. Finally, we present a security analysis. Our experiments demonstrate
that TDPP can achieve comparable effectiveness to prior approaches, with a high
level of security when appropriately parameterized. In addition, TDPP is more
scalable than previous methods and results in reduced area and power overheads.
The area and power are reduced by, respectively, 1218$\times$ and 2815$\times$
for the layer-by-layer system and by 178$\times$ and 203$\times$ for the
layer-parallel system compared to prior works.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06992" title="Abstract">arXiv:2310.06992</a> [<a href="/pdf/2310.06992" title="Download PDF">pdf</a>, <a href="/format/2310.06992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Open-Vocabulary Tracking with Large Pre-Trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wen-Hsuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Harley%2C+A+W">Adam W. Harley</a>, 
<a href="/search/cs?searchtype=author&query=Tokmakov%2C+P">Pavel Tokmakov</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A">Achal Dave</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page available at <a href="https://wenhsuanchu.github.io/ovtracktor/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object tracking is central to robot perception and scene understanding.
Tracking-by-detection has long been a dominant paradigm for object tracking of
specific object categories. Recently, large-scale pre-trained models have shown
promising advances in detecting and segmenting objects and parts in 2D static
images in the wild. This begs the question: can we re-purpose these large-scale
pre-trained static image models for open-vocabulary video tracking? In this
paper, we re-purpose an open-vocabulary detector, segmenter, and dense optical
flow estimator, into a model that tracks and segments objects of any category
in 2D videos. Our method predicts object and part tracks with associated
language descriptions in monocular videos, rebuilding the pipeline of Tractor
with modern large pre-trained models for static image detection and
segmentation: we detect open-vocabulary object instances and propagate their
boxes from frame to frame using a flow-based motion model, refine the
propagated boxes with the box regression module of the visual detector, and
prompt an open-world segmenter with the refined box to segment the objects. We
decide the termination of an object track based on the objectness score of the
propagated boxes, as well as forward-backward optical flow consistency. We
re-identify objects across occlusions using deep feature matching. We show that
our model achieves strong performance on multiple established video object
segmentation and tracking benchmarks, and can produce reasonable tracks in
manipulation data. In particular, our model outperforms previous
state-of-the-art in UVO and BURST, benchmarks for open-world object tracking
and segmentation, despite never being explicitly trained for tracking. We hope
that our approach can serve as a simple and extensible framework for future
research.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06993" title="Abstract">arXiv:2310.06993</a> [<a href="/pdf/2310.06993" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultima: Robust and Tail-Optimal AllReduce for Distributed Deep Learning  in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warraich%2C+E">Ertza Warraich</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+O">Omer Shabtai</a>, 
<a href="/search/cs?searchtype=author&query=Manaa%2C+K">Khalid Manaa</a>, 
<a href="/search/cs?searchtype=author&query=Vargaftik%2C+S">Shay Vargaftik</a>, 
<a href="/search/cs?searchtype=author&query=Piasetzky%2C+Y">Yonatan Piasetzky</a>, 
<a href="/search/cs?searchtype=author&query=Kadosh%2C+M">Matty Kadosh</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+L">Lalith Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Shahbaz%2C+M">Muhammad Shahbaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We present Ultima, a new collective-communication system for the cloud with
bounded, predictable completion times for deep-learning jobs in the presence of
varying computation (stragglers) and communication (congestion and gradient
drops) variabilities. Ultima exploits the inherent resiliency and the
stochastic nature of distributed deep-learning (DDL) training to work with
approximated gradients, and provides an efficient balance between (tail)
performance and the resulting accuracy of the trained models.
<br />Exploiting this domain-specific characteristic of DDL, Ultima introduces (1)
mechanisms (e.g., Transpose AllReduce, unreliable connection-oriented
transport, and adaptive timeout) to improve the DDL jobs' tail execution time,
and (2) strategies (e.g., Hadamard Transform) to mitigate the impact of
gradient drops on model accuracy. Our evaluation shows that Ultima achieves 60%
faster time-to-accuracy (TTA), on average, when operating in shared
environments (e.g., public cloud), and is on par with existing algorithms
(e.g., Ring-AllReduce) in dedicated environments (like HPC).
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06998" title="Abstract">arXiv:2310.06998</a> [<a href="/pdf/2310.06998" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Machine Learning Enabled Phishing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+K+A">Krystal A. Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Developments in artificial intelligence (AI) are likely to affect social
engineering and change cyber defense operations. The broad and sweeping nature
of AI impact means that many aspects of social engineering could be automated,
potentially giving adversaries an advantage. In this review, we assess the ways
phishing and spear-phishing might be affected by machine learning techniques.
By performing a systematic review of demonstrated ML-enabled phishing
campaigns, we take a broad survey the space for current developments. We
develop a detailed approach for evaluation by creating a risk framework for
analyzing and contextualizing these developments. The object of this review is
to answer the research questions: (1) Are there high-risk ML-enabled phishing
use cases? (2) Is there a meaningful difference between traditional targeted
phishing campaigns and ML-enabled phishing campaigns? Practitioners may use
this review to inform standards, future research directions, and cyber defense
strategies.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07000" title="Abstract">arXiv:2310.07000</a> [<a href="/pdf/2310.07000" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CarDS-Plus ECG Platform: Development and Feasibility Evaluation of a  Multiplatform Artificial Intelligence Toolkit for Portable and Wearable  Device Electrocardiograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shankar%2C+S+V">Sumukh Vasisht Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Oikonomou%2C+E+K">Evangelos K Oikonomou</a>, 
<a href="/search/cs?searchtype=author&query=Khera%2C+R">Rohan Khera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the rapidly evolving landscape of modern healthcare, the integration of
wearable &amp; portable technology provides a unique opportunity for personalized
health monitoring in the community. Devices like the Apple Watch, FitBit, and
AliveCor KardiaMobile have revolutionized the acquisition and processing of
intricate health data streams. Amidst the variety of data collected by these
gadgets, single-lead electrocardiogram (ECG) recordings have emerged as a
crucial source of information for monitoring cardiovascular health. There has
been significant advances in artificial intelligence capable of interpreting
these 1-lead ECGs, facilitating clinical diagnosis as well as the detection of
rare cardiac disorders. This design study describes the development of an
innovative multiplatform system aimed at the rapid deployment of AI-based ECG
solutions for clinical investigation &amp; care delivery. The study examines design
considerations, aligning them with specific applications, develops data flows
to maximize efficiency for research &amp; clinical use. This process encompasses
the reception of single-lead ECGs from diverse wearable devices, channeling
this data into a centralized data lake &amp; facilitating real-time inference
through AI models for ECG interpretation. An evaluation of the platform
demonstrates a mean duration from acquisition to reporting of results of 33.0
to 35.7 seconds, after a standard 30 second acquisition. There were no
substantial differences in acquisition to reporting across two commercially
available devices (Apple Watch and KardiaMobile). These results demonstrate the
succcessful translation of design principles into a fully integrated &amp;
efficient strategy for leveraging 1-lead ECGs across platforms &amp; interpretation
by AI-ECG algorithms. Such a platform is critical to translating AI discoveries
for wearable and portable ECG devices to clinical impact through rapid
deployment.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07005" title="Abstract">arXiv:2310.07005</a> [<a href="/pdf/2310.07005" title="Download PDF">pdf</a>, <a href="/format/2310.07005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound-skwatter (Did You Mean: Sound-squatter?) AI-powered Generator for  Phishing Prevention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valentim%2C+R">Rodolfo Valentim</a>, 
<a href="/search/cs?searchtype=author&query=Drago%2C+I">Idilio Drago</a>, 
<a href="/search/cs?searchtype=author&query=Mellia%2C+M">Marco Mellia</a>, 
<a href="/search/cs?searchtype=author&query=Cerutti%2C+F">Federico Cerutti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sound-squatting is a phishing attack that tricks users into malicious
resources by exploiting similarities in the pronunciation of words. Proactive
defense against sound-squatting candidates is complex, and existing solutions
rely on manually curated lists of homophones. We here introduce Sound-skwatter,
a multi-language AI-based system that generates sound-squatting candidates for
proactive defense. Sound-skwatter relies on an innovative multi-modal
combination of Transformers Networks and acoustic models to learn sound
similarities. We show that Sound-skwatter can automatically list known
homophones and thousands of high-quality candidates. In addition, it covers
cross-language sound-squatting, i.e., when the reader and the listener speak
different languages, supporting any combination of languages. We apply
Sound-skwatter to network-centric phishing via squatted domain names. We find ~
10% of the generated domains exist in the wild, the vast majority unknown to
protection solutions. Next, we show attacks on the PyPI package manager, where
~ 17% of the popular packages have at least one existing candidate. We believe
Sound-skwatter is a crucial asset to mitigate the sound-squatting phenomenon
proactively on the Internet. To increase its impact, we publish an online demo
and release our models and code as open source.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07008" title="Abstract">arXiv:2310.07008</a> [<a href="/pdf/2310.07008" title="Download PDF">pdf</a>, <a href="/format/2310.07008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Answer Candidate Type Selection: Text-to-Text Language Model for Closed  Book Question Answering Meets Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salnikov%2C+M">Mikhail Salnikov</a>, 
<a href="/search/cs?searchtype=author&query=Lysyuk%2C+M">Maria Lysyuk</a>, 
<a href="/search/cs?searchtype=author&query=Braslavski%2C+P">Pavel Braslavski</a>, 
<a href="/search/cs?searchtype=author&query=Razzhigaev%2C+A">Anton Razzhigaev</a>, 
<a href="/search/cs?searchtype=author&query=Malykh%2C+V">Valentin Malykh</a>, 
<a href="/search/cs?searchtype=author&query=Panchenko%2C+A">Alexander Panchenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pre-trained Text-to-Text Language Models (LMs), such as T5 or BART yield
promising results in the Knowledge Graph Question Answering (KGQA) task.
However, the capacity of the models is limited and the quality decreases for
questions with less popular entities. In this paper, we present a novel
approach which works on top of the pre-trained Text-to-Text QA system to
address this issue. Our simple yet effective method performs filtering and
re-ranking of generated candidates based on their types derived from Wikidata
"instance_of" property.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07009" title="Abstract">arXiv:2310.07009</a> [<a href="/pdf/2310.07009" title="Download PDF">pdf</a>, <a href="/format/2310.07009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Galerkin methods for elliptic interface problems on curved  polygonal partitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+D">Dan Li</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Chunmei Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shangyou Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 tables and 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a new weak Galerkin (WG) method for elliptic interface
problems on general curved polygonal partitions. The method's key innovation
lies in its ability to transform the complex interface jump condition into a
more manageable Dirichlet boundary condition, simplifying the theoretical
analysis significantly. The numerical scheme is designed by using locally
constructed weak gradient on the curved polygonal partitions. We establish
error estimates of optimal order for the numerical approximation in both
discrete $H^1$ and $L^2$ norms. Additionally, we present various numerical
results that serve to illustrate the robust numerical performance of the
proposed WG interface method.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07010" title="Abstract">arXiv:2310.07010</a> [<a href="/pdf/2310.07010" title="Download PDF">pdf</a>, <a href="/ps/2310.07010" title="Download PostScript">ps</a>, <a href="/format/2310.07010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Lexicographically Least Binary Rich Word Achieving the Repetition  Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Currie%2C+J">James Currie</a>, 
<a href="/search/cs?searchtype=author&query=Rampersad%2C+N">Narad Rampersad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">We find the lexicographically least infinite binary rich word having critical
exponent $2+\sqrt{2}/2$
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07014" title="Abstract">arXiv:2310.07014</a> [<a href="/pdf/2310.07014" title="Download PDF">pdf</a>, <a href="/format/2310.07014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LeakyOhm: Secret Bits Extraction using Impedance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monfared%2C+S+K">Saleh Khalaj Monfared</a>, 
<a href="/search/cs?searchtype=author&query=Mosavirik%2C+T">Tahoura Mosavirik</a>, 
<a href="/search/cs?searchtype=author&query=Tajik%2C+S">Shahin Tajik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The threat of physical side-channel attacks and their countermeasures is a
widely researched field. Most physical side-channel attacks rely on the
unavoidable influence of computation or storage on voltage or current
fluctuations. Such data-dependent influence can be exploited by, for instance,
power or electromagnetic analysis. In this work, we introduce a novel
non-invasive physical side-channel attack, which exploits the data-dependent
changes in the impedance of the chip. Our attack relies on the fact that the
temporarily stored contents in registers alter the physical characteristics of
the circuit, which results in changes in the die's impedance. To sense such
impedance variations, we deploy a well-known RF/microwave method called
scattering parameter analysis, in which we inject sine wave signals with high
frequencies into the system's power distribution network (PDN) and measure the
echo of the signals. We demonstrate that according to the content bits and
physical location of a register, the reflected signal is modulated differently
at various frequency points enabling the simultaneous and independent probing
of individual registers. Such side-channel leakage violates the $t$-probing
security model assumption used in masking, which is a prominent side-channel
countermeasure. To validate our claims, we mount non-profiled and profiled
impedance analysis attacks on hardware implementations of unprotected and
high-order masked AES. We show that in the case of profiled attack, only a
single trace is required to recover the secret key. Finally, we discuss how a
specific class of hiding countermeasures might be effective against impedance
leakage.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07015" title="Abstract">arXiv:2310.07015</a> [<a href="/pdf/2310.07015" title="Download PDF">pdf</a>, <a href="/format/2310.07015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Relational Inference with Fast Modular Meta-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alet%2C+F">Ferran Alet</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+E">Erica Weng</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+T+L">Tom&#xe1;s Lozano P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper in NeurIPs 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">\textit{Graph neural networks} (GNNs) are effective models for many dynamical
systems consisting of entities and relations. Although most GNN applications
assume a single type of entity and relation, many situations involve multiple
types of interactions. \textit{Relational inference} is the problem of
inferring these interactions and learning the dynamics from observational data.
We frame relational inference as a \textit{modular meta-learning} problem,
where neural modules are trained to be composed in different ways to solve many
tasks. This meta-learning framework allows us to implicitly encode time
invariance and infer relations in context of one another rather than
independently, which increases inference capacity. Framing inference as the
inner-loop optimization of meta-learning leads to a model-based approach that
is more data-efficient and capable of estimating the state of entities that we
do not observe directly, but whose existence can be inferred from their effect
on observed entities. To address the large search space of graph neural network
compositions, we meta-learn a \textit{proposal function} that speeds up the
inner-loop simulated annealing search within the modular meta-learning
algorithm, providing two orders of magnitude increase in the size of problems
that can be addressed.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07018" title="Abstract">arXiv:2310.07018</a> [<a href="/pdf/2310.07018" title="Download PDF">pdf</a>, <a href="/format/2310.07018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NEWTON: Are Large Language Models Capable of Physical Reasoning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+R">Yi Ru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jiafei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+D">Dieter Fox</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+S">Siddhartha Srinivasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings; 8 pages, 3 figures, 7 tables; Project page: <a href="https://newtonreasoning.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Large Language Models (LLMs), through their contextualized representations,
have been empirically proven to encapsulate syntactic, semantic, word sense,
and common-sense knowledge. However, there has been limited exploration of
their physical reasoning abilities, specifically concerning the crucial
attributes for comprehending everyday objects. To address this gap, we
introduce NEWTON, a repository and benchmark for evaluating the physics
reasoning skills of LLMs. Further, to enable domain-specific adaptation of this
benchmark, we present a pipeline to enable researchers to generate a variant of
this benchmark that has been customized to the objects and attributes relevant
for their application. The NEWTON repository comprises a collection of 2800
object-attribute pairs, providing the foundation for generating infinite-scale
assessment templates. The NEWTON benchmark consists of 160K QA questions,
curated using the NEWTON repository to investigate the physical reasoning
capabilities of several mainstream language models across foundational,
explicit, and implicit reasoning tasks. Through extensive empirical analysis,
our results highlight the capabilities of LLMs for physical reasoning. We find
that LLMs like GPT-4 demonstrate strong reasoning capabilities in
scenario-based tasks but exhibit less consistency in object-attribute reasoning
compared to humans (50% vs. 84%). Furthermore, the NEWTON platform demonstrates
its potential for evaluating and enhancing language models, paving the way for
their integration into physically grounded settings, such as robotic
manipulation. Project site: https://newtonreasoning.github.io
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07019" title="Abstract">arXiv:2310.07019</a> [<a href="/pdf/2310.07019" title="Download PDF">pdf</a>, <a href="/format/2310.07019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Case Law Grounding: Aligning Judgments of Humans and AI on  Socially-Constructed Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+Z">Quan Ze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Systems for making determinations on socially-constructed and complex
concepts at scale are increasingly being deployed. To make such fuzzy concepts
tractable for training and evaluating AI, aligning model outputs, or
human-in-the-loop workflows, the prevailing strategy involves developing
`constitutions' in the form of rules, policies, or principles. However,
high-level rules often fail to capture situational nuances or have differing
interpretations, resulting in inconsistent decisions. In this work, we
introduce case law grounding (CLG), a hybrid workflow inspired by case law in
the legal realm where past judgments on specific cases inform new decisions.
Evaluating on two task domains, we find that CLG can improve alignment of
decisions (+9.6% and +10.9% accuracy) and consistency ($\Delta\bar{\kappa}$ of
+0.263 and +0.433) of human decision-makers, while also providing auditable
rationales. We also find similarly substantial alignment improvements for an
LLM decision-maker (+25% and +23% accuracy).
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07021" title="Abstract">arXiv:2310.07021</a> [<a href="/pdf/2310.07021" title="Download PDF">pdf</a>, <a href="/format/2310.07021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-Trained Masked Image Model for Mobile Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V+D">Vishnu Dutt Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anukriti Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">2D top-down maps are commonly used for the navigation and exploration of
mobile robots through unknown areas. Typically, the robot builds the navigation
maps incrementally from local observations using onboard sensors. Recent works
have shown that predicting the structural patterns in the environment through
learning-based approaches can greatly enhance task efficiency. While many such
works build task-specific networks using limited datasets, we show that the
existing foundational vision networks can accomplish the same without any
fine-tuning. Specifically, we use Masked Autoencoders, pre-trained on street
images, to present novel applications for field-of-view expansion, single-agent
topological exploration, and multi-agent exploration for indoor mapping, across
different input modalities. Our work motivates the use of foundational vision
models for generalized structure prediction-driven applications, especially in
the dearth of training data. For more qualitative results see
https://raaslab.org/projects/MIM4Robots.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07022" title="Abstract">arXiv:2310.07022</a> [<a href="/pdf/2310.07022" title="Download PDF">pdf</a>, <a href="/ps/2310.07022" title="Download PostScript">ps</a>, <a href="/format/2310.07022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barrier States Theory for Safety-Critical Multi-Objective Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Almubarak%2C+H">Hassan Almubarak</a>, 
<a href="/search/eess?searchtype=author&query=Sadegh%2C+N">Nader Sadegh</a>, 
<a href="/search/eess?searchtype=author&query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Multi-objective safety-critical control entails a diligent design to avoid
possibly conflicting scenarios and ensure safety. This paper studies the
concept of barrier states (BaS) for safe multi-objective controls in which the
safety condition is manifested as a dynamical sub-system to be controlled along
other states of the system. This allows us to introduce the idea of safety
embedded systems. The proposition is that the control problem is now
transformed to designing a control law for the new, unconstrained, system in
which the barrier state is driven to stay bounded while achieving other
performance objectives. In the stabilization case, for example, we show that
designing a stabilizing controller for the safety embedded system implies
guaranteed safe stabilization for the original safety-critical system.
Consequently, a conflict between performance objectives and safety constraints
is substantially avoided. This allows us to embrace various legacy control
methods from the literature to acquire safe control laws. Moreover, we discuss
how the proposed technique can be espoused for enforcing input constraints.
Additionally, dealing with the constraint through a state allows us to extend
various existing control approaches to the safety case. We consider the case of
bounded input disturbance and adopt the notion of input-to-state stability
(ISS) for barrier states to obtain the notion of input-to-state safety (ISSf)
to analyze safe robustness of systems. Subsequently, we derive the notion of
input-to-state safe stability (IS$^3$) and discuss the synthesis of robust
safely stabilizing feedback controls through designing robust stabilizing
controllers for the safety embedded systems. The proposed techniques and
concepts are used in various examples including the design of
proportional-integral-derivative-barrier (PIDB) control for adaptive cruise
control.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07023" title="Abstract">arXiv:2310.07023</a> [<a href="/pdf/2310.07023" title="Download PDF">pdf</a>, <a href="/format/2310.07023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Macro Mining from Interaction Traces at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Forrest Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Macros are building block tasks of our everyday smartphone activity (e.g.,
"login", or "booking a flight"). Effectively extracting macros is important for
understanding mobile interaction and enabling task automation. These macros are
however difficult to extract at scale as they can be comprised of multiple
steps yet hidden within programmatic components of the app. In this paper, we
introduce a novel approach based on Large Language Models (LLMs) to
automatically extract semantically meaningful macros from both random and
user-curated mobile interaction traces. The macros produced by our approach are
automatically tagged with natural language descriptions and are fully
executable. To examine the quality of extraction, we conduct multiple studies,
including user evaluation, comparative analysis against human-curated tasks,
and automatic execution of these macros. These experiments and analyses show
the effectiveness of our approach and the usefulness of extracted macros in
various downstream applications.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07027" title="Abstract">arXiv:2310.07027</a> [<a href="/pdf/2310.07027" title="Download PDF">pdf</a>, <a href="/format/2310.07027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Synthetic Data for Medical Vision-Language Pre-training:  Bypassing the Need for Real Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anand Shah</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical Vision-Language Pre-training (VLP) learns representations jointly
from medical images and paired radiology reports. It typically requires
large-scale paired image-text datasets to achieve effective pre-training for
both the image encoder and text encoder. The advent of text-guided generative
models raises a compelling question: Can VLP be implemented solely with
synthetic images generated from genuine radiology reports, thereby mitigating
the need for extensively pairing and curating image-text datasets? In this
work, we scrutinize this very question by examining the feasibility and
effectiveness of employing synthetic images for medical VLP. We replace real
medical images with their synthetic equivalents, generated from authentic
medical reports. Utilizing three state-of-the-art VLP algorithms, we
exclusively train on these synthetic samples. Our empirical evaluation across
three subsequent tasks, namely image classification, semantic segmentation and
object detection, reveals that the performance achieved through synthetic data
is on par with or even exceeds that obtained with real images. As a pioneering
contribution to this domain, we introduce a large-scale synthetic medical image
dataset, paired with anonymized real radiology reports. This alleviates the
need of sharing medical images, which are not easy to curate and share in
practice. The code and the dataset will be made publicly available upon paper
acceptance.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07028" title="Abstract">arXiv:2310.07028</a> [<a href="/pdf/2310.07028" title="Download PDF">pdf</a>, <a href="/format/2310.07028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial Forgery-based Deepfake Detection using Fine-Grained Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadimpalli%2C+A+V">Aakash Varma Nadimpalli</a>, 
<a href="/search/cs?searchtype=author&query=Rattani%2C+A">Ajita Rattani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Facial forgery by deepfakes has caused major security risks and raised severe
societal concerns. As a countermeasure, a number of deepfake detection methods
have been proposed. Most of them model deepfake detection as a binary
classification problem using a backbone convolutional neural network (CNN)
architecture pretrained for the task. These CNN-based methods have demonstrated
very high efficacy in deepfake detection with the Area under the Curve (AUC) as
high as $0.99$. However, the performance of these methods degrades
significantly when evaluated across datasets and deepfake manipulation
techniques. This draws our attention towards learning more subtle, local, and
discriminative features for deepfake detection. In this paper, we formulate
deepfake detection as a fine-grained classification problem and propose a new
fine-grained solution to it. Specifically, our method is based on learning
subtle and generalizable features by effectively suppressing background noise
and learning discriminative features at various scales for deepfake detection.
Through extensive experimental validation, we demonstrate the superiority of
our method over the published research in cross-dataset and cross-manipulation
generalization of deepfake detectors for the majority of the experimental
scenarios.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07031" title="Abstract">arXiv:2310.07031</a> [<a href="/pdf/2310.07031" title="Download PDF">pdf</a>, <a href="/format/2310.07031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate Adaptation Aware Positioning for Flying Gateways using  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pantale%C3%A3o%2C+G">Gabriella Pantale&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Queir%C3%B3s%2C+R">R&#xfa;ben Queir&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Fontes%2C+H">H&#xe9;lder Fontes</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+R">Rui Campos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">With the growing connectivity demands, Unmanned Aerial Vehicles (UAVs) have
emerged as a prominent component in the deployment of Next Generation On-demand
Wireless Networks. However, current UAV positioning solutions typically neglect
the impact of Rate Adaptation (RA) algorithms or simplify its effect by
considering ideal and non-implementable RA algorithms. This work proposes the
Rate Adaptation aware RL-based Flying Gateway Positioning (RARL) algorithm, a
positioning method for Flying Gateways that applies Deep Q-Learning, accounting
for the dynamic data rate imposed by the underlying RA algorithm. The RARL
algorithm aims to maximize the throughput of the flying wireless links serving
one or more Flying Access Points, which in turn serve ground terminals. The
performance evaluation of the RARL algorithm demonstrates that it is capable of
taking into account the effect of the underlying RA algorithm and achieve the
maximum throughput in all analysed static and mobile scenarios.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07032" title="Abstract">arXiv:2310.07032</a> [<a href="/pdf/2310.07032" title="Download PDF">pdf</a>, <a href="/format/2310.07032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Harmonium: An Interpretable Deep Structure for Nonlinear Dynamic  System Identification with Application to Audio Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helwani%2C+K">Karim Helwani</a>, 
<a href="/search/cs?searchtype=author&query=Soltanmohammadi%2C+E">Erfan Soltanmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Goodwin%2C+M+M">Michael M. Goodwin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Systems and Control (eess.SY)

</div>
<p class="mathjax">Improving the interpretability of deep neural networks has recently gained
increased attention, especially when the power of deep learning is leveraged to
solve problems in physics. Interpretability helps us understand a model's
ability to generalize and reveal its limitations. In this paper, we introduce a
causal interpretable deep structure for modeling dynamic systems. Our proposed
model makes use of the harmonic analysis by modeling the system in a
time-frequency domain while maintaining high temporal and spectral resolution.
Moreover, the model is built in an order recursive manner which allows for
fast, robust, and exact second order optimization without the need for an
explicit Hessian calculation. To circumvent the resulting high dimensionality
of the building blocks of our system, a neural network is designed to identify
the frequency interdependencies. The proposed model is illustrated and
validated on nonlinear system identification problems as required for audio
signal processing tasks. Crowd-sourced experimentation contrasting the
performance of the proposed approach to other state-of-the-art solutions on an
acoustic echo cancellation scenario confirms the effectiveness of our method
for real-life applications.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07033" title="Abstract">arXiv:2310.07033</a> [<a href="/pdf/2310.07033" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Pathology at Health System Scale -- Self-Supervised  Foundation Models from Three Billion Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campanella%2C+G">Gabriele Campanella</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+R">Ricky Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Fluder%2C+E">Eugene Fluder</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jennifer Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Stock%2C+A">Aryeh Stock</a>, 
<a href="/search/cs?searchtype=author&query=Veremis%2C+B">Brandon Veremis</a>, 
<a href="/search/cs?searchtype=author&query=Polydorides%2C+A+D">Alexandros D. Polydorides</a>, 
<a href="/search/cs?searchtype=author&query=Hedvat%2C+C">Cyrus Hedvat</a>, 
<a href="/search/cs?searchtype=author&query=Schoenfeld%2C+A">Adam Schoenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Vanderbilt%2C+C">Chad Vanderbilt</a>, 
<a href="/search/cs?searchtype=author&query=Kovatch%2C+P">Patricia Kovatch</a>, 
<a href="/search/cs?searchtype=author&query=Cordon-Cardo%2C+C">Carlos Cordon-Cardo</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+T+J">Thomas J. Fuchs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent breakthroughs in self-supervised learning have enabled the use of
large unlabeled datasets to train visual foundation models that can generalize
to a variety of downstream tasks. While this training paradigm is well suited
for the medical domain where annotations are scarce, large-scale pre-training
in the medical domain, and in particular pathology, has not been extensively
studied. Previous work in self-supervised learning in pathology has leveraged
smaller datasets for both pre-training and evaluating downstream performance.
The aim of this project is to train the largest academic foundation model and
benchmark the most prominent self-supervised learning algorithms by
pre-training and evaluating downstream performance on large clinical pathology
datasets. We collected the largest pathology dataset to date, consisting of
over 3 billion images from over 423 thousand microscopy slides. We compared
pre-training of visual transformer models using the masked autoencoder (MAE)
and DINO algorithms. We evaluated performance on six clinically relevant tasks
from three anatomic sites and two institutions: breast cancer detection,
inflammatory bowel disease detection, breast cancer estrogen receptor
prediction, lung adenocarcinoma EGFR mutation prediction, and lung cancer
immunotherapy response prediction. Our results demonstrate that pre-training on
pathology data is beneficial for downstream performance compared to
pre-training on natural images. Additionally, the DINO algorithm achieved
better generalization performance across all tasks tested. The presented
results signify a phase change in computational pathology research, paving the
way into a new era of more performant models based on large-scale, parallel
pre-training at the billion-image scale.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07047" title="Abstract">arXiv:2310.07047</a> [<a href="/pdf/2310.07047" title="Download PDF">pdf</a>, <a href="/format/2310.07047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A predict-and-optimize approach to profit-driven churn prevention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Vargas%2C+N">Nuria G&#xf3;mez-Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+S">Sebasti&#xe1;n Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Vairetti%2C+C">Carla Vairetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, submitted to OMEGA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel predict-and-optimize method for
profit-driven churn prevention. We frame the task of targeting customers for a
retention campaign as a regret minimization problem. The main objective is to
leverage individual customer lifetime values (CLVs) to ensure that only the
most valuable customers are targeted. In contrast, many profit-driven
strategies focus on churn probabilities while considering average CLVs. This
often results in significant information loss due to data aggregation. Our
proposed model aligns with the guidelines of Predict-and-Optimize (PnO)
frameworks and can be efficiently solved using stochastic gradient descent
methods. Results from 12 churn prediction datasets underscore the effectiveness
of our approach, which achieves the best average performance compared to other
well-established strategies in terms of average profit.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07048" title="Abstract">arXiv:2310.07048</a> [<a href="/pdf/2310.07048" title="Download PDF">pdf</a>, <a href="/format/2310.07048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMFS: Federated Multimodal Fusion Learning with Selective Modality  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dong-Jun Han</a>, 
<a href="/search/cs?searchtype=author&query=Chellapandi%2C+V+P">Vishnu Pandi Chellapandi</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BBak%2C+S+H">Stanislaw H. &#x17b;ak</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Federated learning (FL) is a distributed machine learning (ML) paradigm that
enables clients to collaborate without accessing, infringing upon, or leaking
original user data by sharing only model parameters. In the Internet of Things
(IoT), edge devices are increasingly leveraging multimodal data compositions
and fusion paradigms to enhance model performance. However, in FL applications,
two main challenges remain open: (i) addressing the issues caused by
heterogeneous clients lacking specific modalities and (ii) devising an optimal
modality upload strategy to minimize communication overhead while maximizing
learning performance. In this paper, we propose Federated Multimodal Fusion
learning with Selective modality communication (FedMFS), a new multimodal
fusion FL methodology that can tackle the above mentioned challenges. The key
idea is to utilize Shapley values to quantify each modality's contribution and
modality model size to gauge communication overhead, so that each client can
selectively upload the modality models to the server for aggregation. This
enables FedMFS to flexibly balance performance against communication costs,
depending on resource constraints and applications. Experiments on real-world
multimodal datasets demonstrate the effectiveness of FedMFS, achieving
comparable accuracy while reducing communication overhead by one twentieth
compared to baselines.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07056" title="Abstract">arXiv:2310.07056</a> [<a href="/pdf/2310.07056" title="Download PDF">pdf</a>, <a href="/format/2310.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextPSG: Panoptic Scene Graph Generation from Textual Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chengyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Panoptic Scene Graph has recently been proposed for comprehensive scene
understanding. However, previous works adopt a fully-supervised learning
manner, requiring large amounts of pixel-wise densely-annotated data, which is
always tedious and expensive to obtain. To address this limitation, we study a
new problem of Panoptic Scene Graph Generation from Purely Textual Descriptions
(Caption-to-PSG). The key idea is to leverage the large collection of free
image-caption data on the Web alone to generate panoptic scene graphs. The
problem is very challenging for three constraints: 1) no location priors; 2) no
explicit links between visual regions and textual entities; and 3) no
pre-defined concept sets. To tackle this problem, we propose a new framework
TextPSG consisting of four modules, i.e., a region grouper, an entity grounder,
a segment merger, and a label generator, with several novel techniques. The
region grouper first groups image pixels into different segments and the entity
grounder then aligns visual segments with language entities based on the
textual description of the segment being referred to. The grounding results can
thus serve as pseudo labels enabling the segment merger to learn the segment
similarity as well as guiding the label generator to learn object semantics and
relation predicates, resulting in a fine-grained structured scene
understanding. Our framework is effective, significantly outperforming the
baselines and achieving strong out-of-distribution robustness. We perform
comprehensive ablation studies to corroborate the effectiveness of our design
choices and provide an in-depth analysis to highlight future directions. Our
code, data, and results are available on our project page:
https://vis-www.cs.umass.edu/TextPSG.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07057" title="Abstract">arXiv:2310.07057</a> [<a href="/pdf/2310.07057" title="Download PDF">pdf</a>, <a href="/format/2310.07057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Community-Driven Descriptions for Making Livestreams  Accessible
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Killough%2C+D">Daniel Killough</a>, 
<a href="/search/cs?searchtype=author&query=Pavel%2C+A">Amy Pavel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages; to appear in The 25th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">People watch livestreams to connect with others and learn about their
hobbies. Livestreams feature multiple visual streams including the main video,
webcams, on-screen overlays, and chat, all of which are inaccessible to
livestream viewers with visual impairments. While prior work explores creating
audio descriptions for recorded videos, live videos present new challenges:
authoring descriptions in real-time, describing domain-specific content, and
prioritizing which complex visual information to describe. We explore inviting
livestream community members who are domain experts to provide live
descriptions. We first conducted a study with 18 sighted livestream community
members authoring descriptions for livestreams using three different
description methods: live descriptions using text, live descriptions using
speech, and asynchronous descriptions using text. We then conducted a study
with 9 livestream community members with visual impairments, who shared their
current strategies and challenges for watching livestreams and provided
feedback on the community-written descriptions. We conclude with implications
for improving the accessibility of livestreams.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07059" title="Abstract">arXiv:2310.07059</a> [<a href="/pdf/2310.07059" title="Download PDF">pdf</a>, <a href="/format/2310.07059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DKEC: Domain Knowledge Enhanced Multi-Label Classification for  Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+X">Xueren Ge</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+R+D">Ronald Dean Williams</a>, 
<a href="/search/cs?searchtype=author&query=Stankovic%2C+J+A">John A. Stankovic</a>, 
<a href="/search/cs?searchtype=author&query=Alemzadeh%2C+H">Homa Alemzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-label text classification (MLTC) tasks in the medical domain often face
long-tail label distribution, where rare classes have fewer training samples
than frequent classes. Although previous works have explored different model
architectures and hierarchical label structures to find important features,
most of them neglect to incorporate the domain knowledge from medical
guidelines. In this paper, we present DKEC, Domain Knowledge Enhanced
Classifier for medical diagnosis prediction with two innovations: (1) a
label-wise attention mechanism that incorporates a heterogeneous graph and
domain ontologies to capture the semantic relationships between medical
entities, (2) a simple yet effective group-wise training method based on
similarity of labels to increase samples of rare classes. We evaluate DKEC on
two real-world medical datasets: the RAA dataset, a collection of 4,417 patient
care reports from emergency medical services (EMS) incidents, and a subset of
53,898 reports from the MIMIC-III dataset. Experimental results show that our
method outperforms the state-of-the-art, particularly for the few-shot (tail)
classes. More importantly, we study the applicability of DKEC to different
language models and show that DKEC can help the smaller language models achieve
comparable performance to large language models.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07061" title="Abstract">arXiv:2310.07061</a> [<a href="/pdf/2310.07061" title="Download PDF">pdf</a>, <a href="/format/2310.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QualiGPT: GPT as an easy-to-use tool for qualitative coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jingyi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">ChanMin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures, 1 table, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Qualitative research delves deeply into individual complex perspectives on
technology and various phenomena. However, a meticulous analysis of qualitative
data often requires a significant amount of time, especially during the crucial
coding stage. Although there is software specifically designed for qualitative
evaluation, many of these platforms fall short in terms of automatic coding,
intuitive usability, and cost-effectiveness. With the rise of Large Language
Models (LLMs) such as GPT-3 and its successors, we are at the forefront of a
transformative era for enhancing qualitative analysis. In this paper, we
introduce QualiGPT, a specialized tool designed after considering challenges
associated with ChatGPT and qualitative analysis. It harnesses the capabilities
of the Generative Pretrained Transformer (GPT) and its API for thematic
analysis of qualitative data. By comparing traditional manual coding with
QualiGPT's analysis on both simulated and actual datasets, we verify that
QualiGPT not only refines the qualitative analysis process but also elevates
its transparency, credibility, and accessibility. Notably, compared to existing
analytical platforms, QualiGPT stands out with its intuitive design,
significantly reducing the learning curve and operational barriers for users.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07062" title="Abstract">arXiv:2310.07062</a> [<a href="/pdf/2310.07062" title="Download PDF">pdf</a>, <a href="/format/2310.07062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic Model Fusion for End-to-end Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhihong Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shiyi Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Leo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+T">Tim Ng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pusateri%2C+E">Ernest Pusateri</a>, 
<a href="/search/cs?searchtype=author&query=Hannemann%2C+M">Mirko Hannemann</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yaqiao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Siu%2C+M">Man-Hung Siu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent advances in deep learning and automatic speech recognition (ASR) have
enabled the end-to-end (E2E) ASR system and boosted the accuracy to a new
level. The E2E systems implicitly model all conventional ASR components, such
as the acoustic model (AM) and the language model (LM), in a single network
trained on audio-text pairs. Despite this simpler system architecture, fusing a
separate LM, trained exclusively on text corpora, into the E2E system has
proven to be beneficial. However, the application of LM fusion presents certain
drawbacks, such as its inability to address the domain mismatch issue inherent
to the internal AM. Drawing inspiration from the concept of LM fusion, we
propose the integration of an external AM into the E2E system to better address
the domain mismatch. By implementing this novel approach, we have achieved a
significant reduction in the word error rate, with an impressive drop of up to
14.3% across varied test sets. We also discovered that this AM fusion approach
is particularly beneficial in enhancing named entity recognition.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07064" title="Abstract">arXiv:2310.07064</a> [<a href="/pdf/2310.07064" title="Download PDF">pdf</a>, <a href="/format/2310.07064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models can Learn Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhaocheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Schuurmans%2C+D">Dale Schuurmans</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hanjun Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">When prompted with a few examples and intermediate steps, large language
models (LLMs) have demonstrated impressive performance in various reasoning
tasks. However, prompting methods that rely on implicit knowledge in an LLM
often hallucinate incorrect answers when the implicit knowledge is wrong or
inconsistent with the task. To tackle this problem, we present
Hypotheses-to-Theories (HtT), a framework that learns a rule library for
reasoning with LLMs. HtT contains two stages, an induction stage and a
deduction stage. In the induction stage, an LLM is first asked to generate and
verify rules over a set of training examples. Rules that appear and lead to
correct answers sufficiently often are collected to form a rule library. In the
deduction stage, the LLM is then prompted to employ the learned rule library to
perform reasoning to answer test questions. Experiments on both numerical
reasoning and relational reasoning problems show that HtT improves existing
prompting methods, with an absolute gain of 11-27% in accuracy. The learned
rules are also transferable to different models and to different forms of the
same problem.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07069" title="Abstract">arXiv:2310.07069</a> [<a href="/pdf/2310.07069" title="Download PDF">pdf</a>, <a href="/format/2310.07069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Distribution System Load Flow Through Linearization of  Non-Holomorphic Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Habiballah%2C+I">Ibrahim Habiballah</a>, 
<a href="/search/eess?searchtype=author&query=Sulaimon%2C+W">Wasiu Sulaimon</a>, 
<a href="/search/eess?searchtype=author&query=Al-Ismail%2C+F">Fahad Al-Ismail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This letter presents a novel non-iterative power flow solution for radial
distribution systems. In the pursuit of a linear power flow solution that
seamlessly integrates into other power system operations, an approximate
solution via complex linearization of non-holomorphic functions, making no
assumptions about the network's parameters was developed. This approach can be
readily adapted to different load models, and its accuracy is comparable to
other established conventional radial load flow analysis tools.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07070" title="Abstract">arXiv:2310.07070</a> [<a href="/pdf/2310.07070" title="Download PDF">pdf</a>, <a href="/format/2310.07070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D2M2N: Decentralized Differentiable Memory-Enabled Mapping and  Navigation for Multiple Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishat-E-Rabban%2C+M">Md Ishat-E-Rabban</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recently, a number of learning-based models have been proposed for
multi-robot navigation. However, these models lack memory and only rely on the
current observations of the robot to plan their actions. They are unable to
leverage past observations to plan better paths, especially in complex
environments. In this work, we propose a fully differentiable and decentralized
memory-enabled architecture for multi-robot navigation and mapping called
D2M2N. D2M2N maintains a compact representation of the environment to remember
past observations and uses Value Iteration Network for complex navigation. We
conduct extensive experiments to show that D2M2N significantly outperforms the
state-of-the-art model in complex mapping and navigation task.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07074" title="Abstract">arXiv:2310.07074</a> [<a href="/pdf/2310.07074" title="Download PDF">pdf</a>, <a href="/format/2310.07074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EtrusChain: File Storage with DNA and Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1r%C4%B1m%2C+O">Onur Y&#x131;ld&#x131;r&#x131;m</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This article proposes a blockchain-based file storage system that utilizes
DNA encryption for enhanced security. The system utilizes blockchain technology
to provide decentralized and tamper-proof file storage, while DNA encryption is
employed to further strengthen data protection. The proposed system employs a
unique approach to encryption by utilizing DNA sequences as keys, which
enhances data security and privacy. Additionally, the use of blockchain
technology ensures that all file storage and access operations are transparent,
immutable, and distributed among a network of nodes, making it resistant to
tampering and unauthorized access. The proposed system represents a significant
advancement in file storage security and provides a foundation for future
research and development in the field of blockchain-based data storage
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07075" title="Abstract">arXiv:2310.07075</a> [<a href="/pdf/2310.07075" title="Download PDF">pdf</a>, <a href="/format/2310.07075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntax Error-Free and Generalizable Tool Use for LLMs via Finite-State  Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kexun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongqiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">William Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown promising capabilities in using
external tools to solve complex problems. However, existing approaches either
involve fine-tuning on tool demonstrations, which do not generalize to new
tools without additional training, or providing tool documentation in context,
limiting the number of tools. Both approaches often generate syntactically
invalid tool calls. In this paper, we propose ToolDec, a finite-state
machine-guided decoding algorithm for tool-augmented LLMs. ToolDec eliminates
tool-related errors for any tool-augmented LLMs by ensuring valid tool names
and type-conforming arguments. Furthermore, ToolDec enables LLM to effectively
select tools using only the information contained in their names, with no need
for fine-tuning or in-context documentation. We evaluated multiple prior
methods and their ToolDec-enhanced versions on a variety of tasks involving
tools like math functions, knowledge graph relations, and complex real-world
RESTful APIs. Our experiments show that ToolDec reduces syntactic errors to
zero, consequently achieving significantly better performance and as much as a
2x speedup. We also show that ToolDec achieves superior generalization
performance on unseen tools, performing up to 8x better than the baselines.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07076" title="Abstract">arXiv:2310.07076</a> [<a href="/pdf/2310.07076" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformation Monitoring of Tunnel using Phase-based Motion Magnification  and Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kecheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kogi%2C+H">Hiroshi Kogi</a>, 
<a href="/search/cs?searchtype=author&query=Soga%2C+K">Kenichi Soga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4th International Symposium on Machine Learning &amp; Big Data in Geoscience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">During construction, continuous monitoring of underground tunnels can
mitigate potential hazards and facilitate an in-depth understanding of the
ground-tunnel interaction behavior. Traditional vision-based monitoring can
directly capture an extensive range of motion but cannot separate the tunnel's
vibration and deformation mode. Phase-based motion magnification is one of the
techniques to magnify the motion in target frequency bands and identify system
dynamics. Optical flow is a popular method of calculating the motion of image
intensities in computer vision and has a much lower computational cost than
Digital Image Correlation. This study combines PMM and OF to quantify the
underground tunnel scene's magnified deformation mode pixel displacements. As
motion magnification artifacts may lead to inaccurate quantification, the 2D
Wiener filter is used to smooth the high-frequency content. With GPU
acceleration, a dense OF algorithm computing each pixel's displacement is
adopted to derive the whole scene motion. A validation experiment is conducted
between the amplification motion and the actual motion of prisms preinstalled
in the tunnel.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07078" title="Abstract">arXiv:2310.07078</a> [<a href="/pdf/2310.07078" title="Download PDF">pdf</a>, <a href="/format/2310.07078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditing and Robustifying COVID-19 Misinformation Datasets via  Anticontent Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+H">Clay H. Yoo</a>, 
<a href="/search/cs?searchtype=author&query=KhudaBukhsh%2C+A+R">Ashiqur R. KhudaBukhsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at AAAI 2023 (Robust and Safe AI track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper makes two key contributions. First, it argues that highly
specialized rare content classifiers trained on small data typically have
limited exposure to the richness and topical diversity of the negative class
(dubbed anticontent) as observed in the wild. As a result, these classifiers'
strong performance observed on the test set may not translate into real-world
settings. In the context of COVID-19 misinformation detection, we conduct an
in-the-wild audit of multiple datasets and demonstrate that models trained with
several prominently cited recent datasets are vulnerable to anticontent when
evaluated in the wild. Second, we present a novel active learning pipeline that
requires zero manual annotation and iteratively augments the training data with
challenging anticontent, robustifying these classifiers.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07079" title="Abstract">arXiv:2310.07079</a> [<a href="/pdf/2310.07079" title="Download PDF">pdf</a>, <a href="/format/2310.07079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Decentralized Learning with Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yifan Hua</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) is a well-known paradigm of distributed machine
learning on mobile and IoT devices, which preserves data privacy and optimizes
communication efficiency. To avoid the single point of failure problem in FL,
decentralized federated learning (DFL) has been proposed to use peer-to-peer
communication for model aggregation, which has been considered an attractive
solution for machine learning tasks on distributed personal devices. However,
this process is vulnerable to attackers who share false models and data. If
there exists a group of malicious clients, they might harm the performance of
the model by carrying out a poisoning attack. In addition, in DFL, clients
often lack the incentives to contribute their computing powers to do model
training. In this paper, we proposed Blockchain-based Decentralized Federated
Learning (BDFL), which leverages a blockchain for decentralized model
verification and auditing. BDFL includes an auditor committee for model
verification, an incentive mechanism to encourage the participation of clients,
a reputation model to evaluate the trustworthiness of clients, and a protocol
suite for dynamic network updates. Evaluation results show that, with the
reputation mechanism, BDFL achieves fast model convergence and high accuracy on
real datasets even if there exist 30\% malicious clients in the system.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07081" title="Abstract">arXiv:2310.07081</a> [<a href="/pdf/2310.07081" title="Download PDF">pdf</a>, <a href="/format/2310.07081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crossing the Threshold: Idiomatic Machine Translation through Retrieval  Augmentation and Loss Weighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+E">Emmy Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+A">Aditi Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Idioms are common in everyday language, but often pose a challenge to
translators because their meanings do not follow from the meanings of their
parts. Despite significant advances, machine translation systems still struggle
to translate idiomatic expressions. We provide a simple characterization of
idiomatic translation and related issues. This allows us to conduct a synthetic
experiment revealing a tipping point at which transformer-based machine
translation models correctly default to idiomatic translations. To expand
multilingual resources, we compile a dataset of ~4k natural sentences
containing idiomatic expressions in French, Finnish, and Japanese. To improve
translation of natural idioms, we introduce two straightforward yet effective
techniques: the strategic upweighting of training loss on potentially idiomatic
sentences, and using retrieval-augmented models. This not only improves the
accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in
absolute accuracy, but also holds potential benefits for non-idiomatic
sentences.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07084" title="Abstract">arXiv:2310.07084</a> [<a href="/pdf/2310.07084" title="Download PDF">pdf</a>, <a href="/format/2310.07084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Adversarial Robustness of Density Estimation Using the  Probability Flow ODE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arvinte%2C+M">Marius Arvinte</a>, 
<a href="/search/cs?searchtype=author&query=Cornelius%2C+C">Cory Cornelius</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J">Jason Martin</a>, 
<a href="/search/cs?searchtype=author&query=Himayat%2C+N">Nageen Himayat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Beyond their impressive sampling capabilities, score-based diffusion models
offer a powerful analysis tool in the form of unbiased density estimation of a
query sample under the training data distribution. In this work, we investigate
the robustness of density estimation using the probability flow (PF) neural
ordinary differential equation (ODE) model against gradient-based likelihood
maximization attacks and the relation to sample complexity, where the
compressed size of a sample is used as a measure of its complexity. We
introduce and evaluate six gradient-based log-likelihood maximization attacks,
including a novel reverse integration attack. Our experimental evaluations on
CIFAR-10 show that density estimation using the PF ODE is robust against
high-complexity, high-likelihood attacks, and that in some cases adversarial
samples are semantically meaningful, as expected from a robust estimator.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07086" title="Abstract">arXiv:2310.07086</a> [<a href="/pdf/2310.07086" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Twitter Data for Sentiment Analysis of Transit User Feedback:  An NLP Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Adway Das</a>, 
<a href="/search/cs?searchtype=author&query=Prajapati%2C+A+K">Abhishek Kumar Prajapati</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Srinath%2C+M">Mukund Srinath</a>, 
<a href="/search/cs?searchtype=author&query=Ranjbari%2C+A">Andisheh Ranjbari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Word Count: 5515 words + 3 table (250 words per table) = 6265 words
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Traditional methods of collecting user feedback through transit surveys are
often time-consuming, resource intensive, and costly. In this paper, we propose
a novel NLP-based framework that harnesses the vast, abundant, and inexpensive
data available on social media platforms like Twitter to understand users'
perceptions of various service issues. Twitter, being a microblogging platform,
hosts a wealth of real-time user-generated content that often includes valuable
feedback and opinions on various products, services, and experiences. The
proposed framework streamlines the process of gathering and analyzing user
feedback without the need for costly and time-consuming user feedback surveys
using two techniques. First, it utilizes few-shot learning for tweet
classification within predefined categories, allowing effective identification
of the issues described in tweets. It then employs a lexicon-based sentiment
analysis model to assess the intensity and polarity of the tweet sentiments,
distinguishing between positive, negative, and neutral tweets. The
effectiveness of the framework was validated on a subset of manually labeled
Twitter data and was applied to the NYC subway system as a case study. The
framework accurately classifies tweets into predefined categories related to
safety, reliability, and maintenance of the subway system and effectively
measured sentiment intensities within each category. The general findings were
corroborated through a comparison with an agency-run customer survey conducted
in the same year. The findings highlight the effectiveness of the proposed
framework in gauging user feedback through inexpensive social media data to
understand the pain points of the transit system and plan for targeted
improvements.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07088" title="Abstract">arXiv:2310.07088</a> [<a href="/pdf/2310.07088" title="Download PDF">pdf</a>, <a href="/format/2310.07088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity of Thought Improves Reasoning Abilities of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naik%2C+R">Ranjita Naik</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+V">Varun Chandrasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Yuksekgonul%2C+M">Mert Yuksekgonul</a>, 
<a href="/search/cs?searchtype=author&query=Palangi%2C+H">Hamid Palangi</a>, 
<a href="/search/cs?searchtype=author&query=Nushi%2C+B">Besmira Nushi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) are documented to struggle in settings that
require complex reasoning. Nevertheless, instructing the model to break down
the problem into smaller reasoning steps (Wei et al., 2022), or ensembling
various generations through modifying decoding steps (Wang et al., 2023) boosts
performance. Current methods assume that the input prompt is fixed and expect
the decoding strategies to introduce the diversity needed for ensembling. In
this work, we relax this assumption and discuss how one can create and leverage
variations of the input prompt as a means to diversity of thought to improve
model performance. We propose a method that automatically improves prompt
diversity by soliciting feedback from the LLM to ideate approaches that fit for
the problem. We then ensemble the diverse prompts in our method DIV-SE (DIVerse
reasoning path Self-Ensemble) across multiple inference calls. We also propose
a cost-effective alternative where diverse prompts are used within a single
inference call; we call this IDIV-SE (In-call DIVerse reasoning path
Self-Ensemble). Under a fixed generation budget, DIV-SE and IDIV-SE outperform
the previously discussed baselines using both GPT-3.5 and GPT-4 on several
reasoning benchmarks, without modifying the decoding process. Additionally,
DIV-SE advances state-of-the-art performance on recent planning benchmarks
(Valmeekam et al., 2023), exceeding the highest previously reported accuracy by
at least 29.6 percentage points on the most challenging 4/5 Blocksworld task.
Our results shed light on how to enforce prompt diversity toward LLM reasoning
and thereby improve the pareto frontier of the accuracy-cost trade-off.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07091" title="Abstract">arXiv:2310.07091</a> [<a href="/pdf/2310.07091" title="Download PDF">pdf</a>, <a href="/format/2310.07091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jaeger: A Concatenation-Based Multi-Transformer VQA Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+J">Jieting Long</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zewei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Penghao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yidong Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the technical research paper of CIKM 2023 DocIU challenges. The authors received the CIKM 2023 DocIU Winner Award, sponsored by Google, Microsoft, and the Centre for data-driven geoscience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Document-based Visual Question Answering poses a challenging task between
linguistic sense disambiguation and fine-grained multimodal retrieval. Although
there has been encouraging progress in document-based question answering due to
the utilization of large language and open-world prior models\cite{1}, several
challenges persist, including prolonged response times, extended inference
durations, and imprecision in matching. In order to overcome these challenges,
we propose Jaegar, a concatenation-based multi-transformer VQA model. To derive
question features, we leverage the exceptional capabilities of RoBERTa
large\cite{2} and GPT2-xl\cite{3} as feature extractors. Subsequently, we
subject the outputs from both models to a concatenation process. This operation
allows the model to consider information from diverse sources concurrently,
strengthening its representational capability. By leveraging pre-trained models
for feature extraction, our approach has the potential to amplify the
performance of these models through concatenation. After concatenation, we
apply dimensionality reduction to the output features, reducing the model's
computational effectiveness and inference time. Empirical results demonstrate
that our proposed model achieves competitive performance on Task C of the
PDF-VQA Dataset. If the user adds any new data, they should make sure to style
it as per the instructions provided in previous sections.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07093" title="Abstract">arXiv:2310.07093</a> [<a href="/pdf/2310.07093" title="Download PDF">pdf</a>, <a href="/format/2310.07093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Argumentative Stance Prediction: An Exploratory Study on Multimodality  and Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Arushi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhibha Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bilalpur%2C+M">Maneesh Bilalpur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To advance argumentative stance prediction as a multimodal problem, the First
Shared Task in Multimodal Argument Mining hosted stance prediction in crucial
social topics of gun control and abortion. Our exploratory study attempts to
evaluate the necessity of images for stance prediction in tweets and compare
out-of-the-box text-based large-language models (LLM) in few-shot settings
against fine-tuned unimodal and multimodal models. Our work suggests an
ensemble of fine-tuned text-based language models (0.817 F1-score) outperforms
both the multimodal (0.677 F1-score) and text-based few-shot prediction using a
recent state-of-the-art LLM (0.550 F1-score). In addition to the differences in
performance, our findings suggest that the multimodal models tend to perform
better when image content is summarized as natural language over their native
pixel structure and, using in-context examples improves few-shot performance of
LLMs.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07096" title="Abstract">arXiv:2310.07096</a> [<a href="/pdf/2310.07096" title="Download PDF">pdf</a>, <a href="/format/2310.07096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Universal Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shawn Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Universal Transformer (UT) is a variant of the Transformer that shares
parameters across its layers. Empirical evidence shows that UTs have better
compositional generalization than Vanilla Transformers (VTs) in formal language
tasks. The parameter-sharing also affords it better parameter efficiency than
VTs. Despite its many advantages, scaling UT parameters is much more compute
and memory intensive than scaling up a VT. This paper proposes the Sparse
Universal Transformer (SUT), which leverages Sparse Mixture of Experts (SMoE)
and a new stick-breaking-based dynamic halting mechanism to reduce UT's
computation complexity while retaining its parameter efficiency and
generalization ability. Experiments show that SUT achieves the same performance
as strong baseline models while only using half computation and parameters on
WMT'14 and strong generalization results on formal language tasks (Logical
inference and CFQ). The new halting mechanism also enables around 50\%
reduction in computation during inference with very little performance decrease
on formal language tasks.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07099" title="Abstract">arXiv:2310.07099</a> [<a href="/pdf/2310.07099" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClausewitzGPT Framework: A New Frontier in Theoretical Large Language  Model Enhanced Information Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kereopa-Yorke%2C+B">Benjamin Kereopa-Yorke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In a digital epoch where cyberspace is the emerging nexus of geopolitical
contention, the melding of information operations and Large Language Models
(LLMs) heralds a paradigm shift, replete with immense opportunities and
intricate challenges. As tools like the Mistral 7B LLM (Mistral, 2023)
democratise access to LLM capabilities (Jin et al., 2023), a vast spectrum of
actors, from sovereign nations to rogue entities (Howard et al., 2023), find
themselves equipped with potent narrative-shaping instruments (Goldstein et
al., 2023). This paper puts forth a framework for navigating this brave new
world in the "ClausewitzGPT" equation. This novel formulation not only seeks to
quantify the risks inherent in machine-speed LLM-augmented operations but also
underscores the vital role of autonomous AI agents (Wang, Xie, et al., 2023).
These agents, embodying ethical considerations (Hendrycks et al., 2021), emerge
as indispensable components (Wang, Ma, et al., 2023), ensuring that as we race
forward, we do not lose sight of moral compasses and societal imperatives.
<br />Mathematically underpinned and inspired by the timeless tenets of
Clausewitz's military strategy (Clausewitz, 1832), this thesis delves into the
intricate dynamics of AI-augmented information operations. With references to
recent findings and research (Department of State, 2023), it highlights the
staggering year-on-year growth of AI information campaigns (Evgeny Pashentsev,
2023), stressing the urgency of our current juncture. The synthesis of
Enlightenment thinking, and Clausewitz's principles provides a foundational
lens, emphasising the imperative of clear strategic vision, ethical
considerations, and holistic understanding in the face of rapid technological
advancement.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07100" title="Abstract">arXiv:2310.07100</a> [<a href="/pdf/2310.07100" title="Download PDF">pdf</a>, <a href="/format/2310.07100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphCloak: Safeguarding Task-specific Knowledge within Graph-structured  Data from Unauthorized Exploitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenrui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As Graph Neural Networks (GNNs) become increasingly prevalent in a variety of
fields, from social network analysis to protein-protein interaction studies,
growing concerns have emerged regarding the unauthorized utilization of
personal data. Recent studies have shown that imperceptible poisoning attacks
are an effective method of protecting image data from such misuse. However, the
efficacy of this approach in the graph domain remains unexplored. To bridge
this gap, this paper introduces GraphCloak to safeguard against the
unauthorized usage of graph data. Compared with prior work, GraphCloak offers
unique significant innovations: (1) graph-oriented, the perturbations are
applied to both topological structures and descriptive features of the graph;
(2) effective and stealthy, our cloaking method can bypass various inspections
while causing a significant performance drop in GNNs trained on the cloaked
graphs; and (3) stable across settings, our methods consistently perform
effectively under a range of practical settings with limited knowledge. To
address the intractable bi-level optimization problem, we propose two
error-minimizing-based poisoning methods that target perturbations on the
structural and feature space, along with a subgraph injection poisoning method.
Our comprehensive evaluation of these methods underscores their effectiveness,
stealthiness, and stability. We also delve into potential countermeasures and
provide analytical justification for their effectiveness, paving the way for
intriguing future research.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07101" title="Abstract">arXiv:2310.07101</a> [<a href="/pdf/2310.07101" title="Download PDF">pdf</a>, <a href="/format/2310.07101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Arrays: How Many RF Chains Are Required to Prevent Beam Squint?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+H">Heedong Do</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namyoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Angel Lozano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With increasing frequencies, bandwidths, and array apertures, the phenomenon
of beam squint arises as a serious impairment to beamforming. Fully digital
arrays with true time delay per antenna element are a potential solution, but
they require downconversion at each element. This paper shows that hybrid
arrays can perform essentially as well as digital arrays once the number of
radio-frequency chains exceeds a certain threshold that is far below the number
of elements. The result is robust, holding also for suboptimum but highly
appealing beamspace architectures.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07103" title="Abstract">arXiv:2310.07103</a> [<a href="/pdf/2310.07103" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralization of Energy Systems with Blockchain: Bridging Top-down  and Bottom-up Management of the Electricity Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mishra%2C+S">Sakshi Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Khatami%2C+R">Roohallah Khatami</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y+C">Yu Christine Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 Figure. arXiv admin note: text overlap with <a href="/abs/2112.09756">arXiv:2112.09756</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">For more than a century, the grid has operated in a centralized top-down
fashion. However, as distributed energy resources (DERs) penetration grows, the
grid edge is increasingly infused with intelligent computing and communication
capabilities. Thus, the bottom-up approach to grid operations inclined toward
decentralizing energy systems will likely gain momentum alongside the existing
centralized paradigm. Decentralization refers to transferring control and
decision-making from a centralized entity (individual, organization, or group
thereof) to a distributed network. It is not a new concept - in energy systems
context or otherwise. In the energy systems context, however, the complexity of
this multifaceted concept increases manifolds due to two major reasons - i) the
nature of the commodity being traded (the electricity) and ii) the enormity of
the traditional electricity sector's structure that builds, operates, and
maintains this capital-intensive network. In this work, we aim to highlight the
need for and outline a credible path toward restructuring the current
operational architecture of the electricity grid in view of the ongoing
decentralization trends with an emphasis on peer-to-peer energy trading. We
further introduce blockchain technology in the context of decentralized energy
systems problems. We also suggest that blockchain is an effective technology
for facilitating the synergistic operations of top-down and bottom-up
approaches to grid management.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07106" title="Abstract">arXiv:2310.07106</a> [<a href="/pdf/2310.07106" title="Download PDF">pdf</a>, <a href="/format/2310.07106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Temporal Structure of Language Processing in the Human Brain  Corresponds to The Layered Hierarchy of Deep Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+A">Ariel Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Ham%2C+E">Eric Ham</a>, 
<a href="/search/cs?searchtype=author&query=Schain%2C+M">Mariano Schain</a>, 
<a href="/search/cs?searchtype=author&query=Nastase%2C+S">Samuel Nastase</a>, 
<a href="/search/cs?searchtype=author&query=Zada%2C+Z">Zaid Zada</a>, 
<a href="/search/cs?searchtype=author&query=Dabush%2C+A">Avigail Dabush</a>, 
<a href="/search/cs?searchtype=author&query=Aubrey%2C+B">Bobbi Aubrey</a>, 
<a href="/search/cs?searchtype=author&query=Gazula%2C+H">Harshvardhan Gazula</a>, 
<a href="/search/cs?searchtype=author&query=Feder%2C+A">Amir Feder</a>, 
<a href="/search/cs?searchtype=author&query=Doyle%2C+W+K">Werner K Doyle</a>, 
<a href="/search/cs?searchtype=author&query=Devore%2C+S">Sasha Devore</a>, 
<a href="/search/cs?searchtype=author&query=Dugan%2C+P">Patricia Dugan</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+D">Daniel Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>, 
<a href="/search/cs?searchtype=author&query=Brenner%2C+M">Michael Brenner</a>, 
<a href="/search/cs?searchtype=author&query=Hassidim%2C+A">Avinatan Hassidim</a>, 
<a href="/search/cs?searchtype=author&query=Devinsky%2C+O">Orrin Devinsky</a>, 
<a href="/search/cs?searchtype=author&query=Flinker%2C+A">Adeen Flinker</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+O">Omer Levy</a>, 
<a href="/search/cs?searchtype=author&query=Hasson%2C+U">Uri Hasson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Deep Language Models (DLMs) provide a novel computational paradigm for
understanding the mechanisms of natural language processing in the human brain.
Unlike traditional psycholinguistic models, DLMs use layered sequences of
continuous numerical vectors to represent words and context, allowing a
plethora of emerging applications such as human-like text generation. In this
paper we show evidence that the layered hierarchy of DLMs may be used to model
the temporal dynamics of language comprehension in the brain by demonstrating a
strong correlation between DLM layer depth and the time at which layers are
most predictive of the human brain. Our ability to temporally resolve
individual layers benefits from our use of electrocorticography (ECoG) data,
which has a much higher temporal resolution than noninvasive methods like fMRI.
Using ECoG, we record neural activity from participants listening to a
30-minute narrative while also feeding the same narrative to a high-performing
DLM (GPT2-XL). We then extract contextual embeddings from the different layers
of the DLM and use linear encoding models to predict neural activity. We first
focus on the Inferior Frontal Gyrus (IFG, or Broca's area) and then extend our
model to track the increasing temporal receptive window along the linguistic
processing hierarchy from auditory to syntactic and semantic areas. Our results
reveal a connection between human language processing and DLMs, with the DLM's
layer-by-layer accumulation of contextual information mirroring the timing of
neural activity in high-order language areas.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07108" title="Abstract">arXiv:2310.07108</a> [<a href="/pdf/2310.07108" title="Download PDF">pdf</a>, <a href="/format/2310.07108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient saddle search method for ordered phase transitions  involving translational invariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cui%2C+G">Gang Cui</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+T">Tiejun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The bottleneck of studying phase transitions is the barrier-crossing process
composed of escaping from the basin of the local minimum and finding the saddle
point. Breaking the bottleneck requires designing efficient algorithms relevant
to the properties of concrete phase transition. In this work, we propose an
efficient nullspace-preserving saddle search (NPSS) method for a class of phase
transitions involving translational invariance. These critical states in these
phase transitions are usually degenerate. The NPSS overcomes the difficulty of
degeneration by ensuring the ascent direction orthogonal to the kernel space of
the initial minimum, then efficiently escapes from the basin and finds the
saddle point. We apply the NPSS method to the phase transitions between
crystals, and between crystal and quasicrystal, based on the Landau-Brazvoskii
and Lifshitz-Petrich free energy functionals. Numerical results show a good
performance of the proposed method. Finally, we investigate an important
property of the inflection point, where symmetry-breaking begins to occur and
nullspace is no longer maintained.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07109" title="Abstract">arXiv:2310.07109</a> [<a href="/pdf/2310.07109" title="Download PDF">pdf</a>, <a href="/format/2310.07109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparseCoder: Advancing Source Code Analysis with Sparse Attention and  Learned Token Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xueqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jakubowski%2C+M">Mariusz Jakubowski</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+K">Kelly Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haojie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Menzies%2C+T">Tim Menzies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">As software projects rapidly evolve, software artifacts become more complex
and defects behind get harder to identify. The emerging Transformer-based
approaches, though achieving remarkable performance, struggle with long code
sequences due to their self-attention mechanism, which scales quadratically
with the sequence length. This paper introduces SparseCoder, an innovative
approach incorporating sparse attention and learned token pruning (LTP) method
(adapted from natural language processing) to address this limitation.
Extensive experiments carried out on a large-scale dataset for vulnerability
detection demonstrate the effectiveness and efficiency of SparseCoder, scaling
from quadratically to linearly on long code sequence analysis in comparison to
CodeBERT and RoBERTa. We further achieve 50% FLOPs reduction with a negligible
performance drop of less than 1% comparing to Transformer leveraging sparse
attention. Moverover, SparseCoder goes beyond making "black-box" decisions by
elucidating the rationale behind those decisions. Code segments that contribute
to the final decision can be highlighted with importance scores, offering an
interpretable, transparent analysis tool for the software engineering
landscape.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07112" title="Abstract">arXiv:2310.07112</a> [<a href="/pdf/2310.07112" title="Download PDF">pdf</a>, <a href="/format/2310.07112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new mixed finite element method for arbitrary element pair for a  quasi-static nonlinear permeability thermo-poroelasticity model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ge%2C+Z">Zhihao Ge</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+W">Wenshuai Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 15 figures. arXiv admin note: text overlap with <a href="/abs/2310.05084">arXiv:2310.05084</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we develop a multiphysics finite element method for solving
the quasi-static thermo-poroelasticity model with nonlinear permeability. The
model involves multiple physical processes such as deformation, pressure,
diffusion and heat transfer. To reveal the multi-physical processes of
deformation, diffusion and heat transfer, we reformulate the original model
into a fluid coupled problem that is general Stokes equation coupled with two
reaction-diffusion equations. Then, we prove the existence and uniqueness of
weak solution for the original problem by the $B$-operator technique and by
sequence approximation for the reformulated problem. As for the reformulated
problem we propose a fully discrete finite element method which can use
arbitrary finite element pairs to solve the displacement $\bu$ pressure $\tau $
and variable $\varpi,\varsigma$, and the backward Euler method for time
discretization. Finally, we give the stability analysis of the above proposed
method, also we prove that the fully discrete multiphysics finite element
method has an optimal convergence order. Numerical experiments show that the
proposed method can achieve good results under different finite element pairs
and are consistent with the theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07116" title="Abstract">arXiv:2310.07116</a> [<a href="/pdf/2310.07116" title="Download PDF">pdf</a>, <a href="/format/2310.07116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Digital Twin Approach for Adaptive Compliance in Cyber-Physical  Systems: Case of Smart Warehouse Logistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bahsoon%2C+R">Rami Bahsoon</a>, 
<a href="/search/eess?searchtype=author&query=Tziritas%2C+N">Nikos Tziritas</a>, 
<a href="/search/eess?searchtype=author&query=Theodoropoulos%2C+G">Georgios Theodoropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures, submitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Engineering regulatory compliance in complex Cyber-Physical Systems (CPS),
such as smart warehouse logistics, is challenging due to the open and dynamic
nature of these systems, scales, and unpredictable modes of human-robot
interactions that can be best learnt at runtime. Traditional offline approaches
for engineering compliance often involve modelling at a higher, more abstract
level (e.g. using languages like SysML). These abstract models only support
analysis in offline-designed and simplified scenarios. However, open and
complex systems may be unpredictable, and their behaviours are difficult to be
fully captured by abstract models. These systems may also involve other
business goals, possibly conflicting with regulatory compliance. To overcome
these challenges, fine-grained simulation models are promising to complement
abstract models and support accurate runtime predictions and performance
evaluation with trade-off analysis. The novel contribution of this work is a
Digital Twin-oriented architecture for adaptive compliance leveraging abstract
goal modelling, fine-grained agent-based modelling and runtime simulation for
managing compliance trade-offs. A case study from smart warehouse logistics is
used to demonstrate the approach considering safety and productivity
trade-offs.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07118" title="Abstract">arXiv:2310.07118</a> [<a href="/pdf/2310.07118" title="Download PDF">pdf</a>, <a href="/ps/2310.07118" title="Download PostScript">ps</a>, <a href="/format/2310.07118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unclonable Non-Interactive Zero-Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jawale%2C+R">Ruta Jawale</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+D">Dakshita Khurana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">A non-interactive ZK (NIZK) proof enables verification of NP statements
without revealing secrets about them. However, an adversary that obtains a NIZK
proof may be able to clone this proof and distribute arbitrarily many copies of
it to various entities: this is inevitable for any proof that takes the form of
a classical string. In this paper, we ask whether it is possible to rely on
quantum information in order to build NIZK proof systems that are impossible to
clone.
<br />We define and construct unclonable non-interactive zero-knowledge proofs (of
knowledge) for NP. Besides satisfying the zero-knowledge and proof of knowledge
properties, these proofs additionally satisfy unclonability. Very roughly, this
ensures that no adversary can split an honestly generated proof of membership
of an instance $x$ in an NP language $\mathcal{L}$ and distribute copies to
multiple entities that all obtain accepting proofs of membership of $x$ in
$\mathcal{L}$. Our result has applications to unclonable signatures of
knowledge, which we define and construct in this work; these non-interactively
prevent replay attacks.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07121" title="Abstract">arXiv:2310.07121</a> [<a href="/pdf/2310.07121" title="Download PDF">pdf</a>, <a href="/format/2310.07121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Vector-Domain Video Steganalysis Exploiting Skipped Macroblocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+K">Ke Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingnan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoyuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Video steganography has the potential to be used to convey illegal
information, and video steganalysis is a vital tool to detect the presence of
this illicit act. Currently, all the motion vector (MV)-based video
steganalysis algorithms extract feature sets directly on the MVs, but ignoring
the steganograhic operation may perturb the statistics distribution of other
video encoding elements, such as the skipped macroblocks (no direct MVs). This
paper proposes a novel 11-dimensional feature set to detect MV-based video
steganography based on the above observation. The proposed feature is extracted
based on the skipped macroblocks by recompression calibration. Specifically,
the feature consists of two components. The first is the probability
distribution of motion vector prediction (MVP) difference, and the second is
the probability distribution of partition state transfer. Extensive experiments
on different conditions demonstrate that the proposed feature set achieves good
detection accuracy, especially in lower embedding capacity. In addition, the
loss of detection performance caused by recompression calibration using
mismatched quantization parameters (QP) is within the acceptable range, so the
proposed method can be used in practical scenarios.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07122" title="Abstract">arXiv:2310.07122</a> [<a href="/pdf/2310.07122" title="Download PDF">pdf</a>, <a href="/ps/2310.07122" title="Download PostScript">ps</a>, <a href="/format/2310.07122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum Sharing Towards Delay Deterministic Wireless Network: Delay  Performance Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+G">Gaofeng Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zeyang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">To accommodate Machine-type Communication (MTC) service, the wireless network
needs to support low-delay and low-jitter data transmission, realizing delay
deterministic wireless network. This paper analyzes the delay and jitter of the
wireless network with and without spectrum sharing. When sharing the spectrum
of the licensed network, the spectrum band of wireless network can be expanded,
such that the delay and jitter of data transmission are reduced. The challenge
of this research is to model the relation between the delay/jitter and the
parameters such as node distribution, transmit power, and bandwidth, etc. To
this end, this paper applies stochastic geometry and queueing theory to analyze
the outage probability of the licensed network and the delay performance of the
wireless network with and without spectrum sharing. By establishing the M/G/1
queueing model for the queueing of the Base Station (BS) in the wireless
network, the downlink delay and jitter are derived. Monte Carlo simulation
results show that the spectrum sharing reduces the delay and jitter without
causing serious interference to the licensed network, which can lay a
foundation for the application of spectrum sharing in delay deterministic
wireless network supporting MTC service.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07123" title="Abstract">arXiv:2310.07123</a> [<a href="/pdf/2310.07123" title="Download PDF">pdf</a>, <a href="/format/2310.07123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Off-Policy Evaluation for Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qitong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Juncheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tarokh%2C+V">Vahid Tarokh</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+M">Min Chi</a>, 
<a href="/search/cs?searchtype=author&query=Pajic%2C+M">Miroslav Pajic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Off-policy evaluation (OPE) is important for closing the gap between offline
training and evaluation of reinforcement learning (RL), by estimating
performance and/or rank of target (evaluation) policies using offline
trajectories only. It can improve the safety and efficiency of data collection
and policy testing procedures in situations where online deployments are
expensive, such as healthcare. However, existing OPE methods fall short in
estimating human feedback (HF) signals, as HF may be conditioned over multiple
underlying factors and is only sparsely available; as opposed to the
agent-defined environmental rewards (used in policy optimization), which are
usually determined over parametric functions or distributions. Consequently,
the nature of HF signals makes extrapolating accurate OPE estimations to be
challenging. To resolve this, we introduce an OPE for HF (OPEHF) framework that
revives existing OPE methods in order to accurately evaluate the HF signals.
Specifically, we develop an immediate human reward (IHR) reconstruction
approach, regularized by environmental knowledge distilled in a latent space
that captures the underlying dynamics of state transitions as well as issuing
HF signals. Our approach has been tested over two real-world experiments,
adaptive in-vivo neurostimulation and intelligent tutoring, as well as in a
simulation environment (visual Q&amp;A). Results show that our approach
significantly improves the performance toward estimating HF signals accurately,
compared to directly applying (variants of) existing OPE methods.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07127" title="Abstract">arXiv:2310.07127</a> [<a href="/pdf/2310.07127" title="Download PDF">pdf</a>, <a href="/format/2310.07127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jingyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rahul Jain</a>, 
<a href="/search/cs?searchtype=author&query=Doh%2C+H">Hyungjun Doh</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+R">Ryo Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Ramani%2C+K">Karthik Ramani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Generative AI (GenAI) has shown remarkable capabilities in generating diverse
and realistic content across different formats like images, videos, and text.
In Generative AI, human involvement is essential, thus HCI literature has
investigated how to effectively create collaborations between humans and GenAI
systems. However, the current literature lacks a comprehensive framework to
better understand Human-GenAI Interactions, as the holistic aspects of
human-centered GenAI systems are rarely analyzed systematically. In this paper,
we present a survey of 154 papers, providing a novel taxonomy and analysis of
Human-GenAI Interactions from both human and Gen-AI perspectives. The dimension
of design space includes 1) Purposes of Using Generative AI, 2) Feedback from
Models to Users , 3) Control from Users to Models, 4) Levels of Engagement, 5)
Application Domains, and 6) Evaluation Strategies. Our work is also timely at
the current development stage of GenAI, where the Human-GenAI interaction
design is of paramount importance. We also highlight challenges and
opportunities to guide the design of Gen-AI systems and interactions towards
the future design of human-centered Generative AI applications.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07128" title="Abstract">arXiv:2310.07128</a> [<a href="/pdf/2310.07128" title="Download PDF">pdf</a>, <a href="/format/2310.07128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrashTranslator: Automatically Reproducing Mobile Application Crashes  Directly from Stack Trace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuchao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yawen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuanzhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICSE 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Crash reports are vital for software maintenance since they allow the
developers to be informed of the problems encountered in the mobile
application. Before fixing, developers need to reproduce the crash, which is an
extremely time-consuming and tedious task. Existing studies conducted the
automatic crash reproduction with the natural language described reproducing
steps. Yet we find a non-neglectable portion of crash reports only contain the
stack trace when the crash occurs. Such stack-trace-only crashes merely reveal
the last GUI page when the crash occurs, and lack step-by-step guidance.
Developers tend to spend more effort in understanding the problem and
reproducing the crash, and existing techniques cannot work on this, thus
calling for a greater need for automatic support. This paper proposes an
approach named CrashTranslator to automatically reproduce mobile application
crashes directly from the stack trace. It accomplishes this by leveraging a
pre-trained Large Language Model to predict the exploration steps for
triggering the crash, and designing a reinforcement learning based technique to
mitigate the inaccurate prediction and guide the search holistically. We
evaluate CrashTranslator on 75 crash reports involving 58 popular Android apps,
and it successfully reproduces 61.3% of the crashes, outperforming the
state-of-the-art baselines by 109% to 206%. Besides, the average reproducing
time is 68.7 seconds, outperforming the baselines by 302% to 1611%. We also
evaluate the usefulness of CrashTranslator with promising results.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07129" title="Abstract">arXiv:2310.07129</a> [<a href="/pdf/2310.07129" title="Download PDF">pdf</a>, <a href="/format/2310.07129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The impact when neural min-sum variants meet ordered statistics decoding  of LDPC codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiao Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The decoding performance of conventional belief propagation decoders is
seriously confined by the existence of message dependence in the code structure
for short or moderate LDPC codes. In spite of the similarity of the external
performance, we found the corresponding decoding failures of varied decoders,
symbolized by the cross-entropy metric, will leave differed room for
improvement for the postprocessing of ordered statistical decoding. Bearing in
mind the postprocessor of higher order ensures better performance and incurs
more expensive complexity, we propose a dynamic assignment of searching scope
with respect to each decoding pattern for the order statistical decoding.
Furthermore, the segmentation of decoding patterns, determined on the fly by
the number of swaps in reducing the code check matrix into its systematic form
via Gaussian elimination operation. will also benefit reducing complexity.
Compared with the existing methods, our adapted strategy is justified by saving
most memory consumption and inefficient searching of code-word candidates in
extensive simulation especially for longer codes, at the cost of marginal
performance loss.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07130" title="Abstract">arXiv:2310.07130</a> [<a href="/pdf/2310.07130" title="Download PDF">pdf</a>, <a href="/format/2310.07130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Cloud Collaborative Stream Computing for Real-Time Structural  Health Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Cheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Wei Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Structural Health Monitoring (SHM) is crucial for the safety and maintenance
of various infrastructures. Due to the large amount of data generated by
numerous sensors and the high real-time requirements of many applications, SHM
poses significant challenges. Although the cloud-centric stream computing
paradigm opens new opportunities for real-time data processing, it consumes too
much network bandwidth. In this paper, we propose ECStream, an Edge Cloud
collaborative fine-grained stream operator scheduling framework for SHM. We
collectively consider atomic and composite operators together with their
iterative computability to model and formalize the problem of minimizing
bandwidth usage and end-to-end operator processing latency. Preliminary
evaluation results show that ECStream can effectively balance bandwidth usage
and end-to-end operator computation latency, reducing bandwidth usage by 73.01%
and latency by 34.08% on average compared to the cloud-centric approach.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07132" title="Abstract">arXiv:2310.07132</a> [<a href="/pdf/2310.07132" title="Download PDF">pdf</a>, <a href="/format/2310.07132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Assessment and Statistical Significance in the Age of Foundation  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nitsure%2C+A">Apoorva Nitsure</a>, 
<a href="/search/cs?searchtype=author&query=Mroueh%2C+Y">Youssef Mroueh</a>, 
<a href="/search/cs?searchtype=author&query=Rigotti%2C+M">Mattia Rigotti</a>, 
<a href="/search/cs?searchtype=author&query=Greenewald%2C+K">Kristjan Greenewald</a>, 
<a href="/search/cs?searchtype=author&query=Belgodere%2C+B">Brian Belgodere</a>, 
<a href="/search/cs?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>, 
<a href="/search/cs?searchtype=author&query=Navratil%2C+J">Jiri Navratil</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+I">Igor Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+J">Jerret Ross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Risk Management (q-fin.RM); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a distributional framework for assessing socio-technical risks of
foundation models with quantified statistical significance. Our approach hinges
on a new statistical relative testing based on first and second order
stochastic dominance of real random variables. We show that the second order
statistics in this test are linked to mean-risk models commonly used in
econometrics and mathematical finance to balance risk and utility when choosing
between alternatives. Using this framework, we formally develop a risk-aware
approach for foundation model selection given guardrails quantified by
specified metrics. Inspired by portfolio optimization and selection theory in
mathematical finance, we define a \emph{metrics portfolio} for each model as a
means to aggregate a collection of metrics, and perform model selection based
on the stochastic dominance of these portfolios. The statistical significance
of our tests is backed theoretically by an asymptotic analysis via central
limit theorems instantiated in practice via a bootstrap variance estimate. We
use our framework to compare various large language models regarding risks
related to drifting from instructions and outputting toxic content.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07135" title="Abstract">arXiv:2310.07135</a> [<a href="/pdf/2310.07135" title="Download PDF">pdf</a>, <a href="/format/2310.07135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Styles across Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havaldar%2C+S">Shreya Havaldar</a>, 
<a href="/search/cs?searchtype=author&query=Pressimone%2C+M">Matthew Pressimone</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Ungar%2C+L">Lyle Ungar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Understanding how styles differ across languages is advantageous for training
both humans and computers to generate culturally appropriate text. We introduce
an explanation framework to extract stylistic differences from multilingual LMs
and compare styles across languages. Our framework (1) generates comprehensive
style lexica in any language and (2) consolidates feature importances from LMs
into comparable lexical categories. We apply this framework to compare
politeness, creating the first holistic multilingual politeness dataset and
exploring how politeness varies across four languages. Our approach enables an
effective evaluation of how distinct linguistic categories contribute to
stylistic variations and provides interpretable insights into how people
communicate differently around the world.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07137" title="Abstract">arXiv:2310.07137</a> [<a href="/pdf/2310.07137" title="Download PDF">pdf</a>, <a href="/format/2310.07137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AE-smnsMLC: Multi-Label Classification with Semantic Matching and  Negative Label Sampling for Product Attribute Value Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongfen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei-Te Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Big Data, pages 1816-1821
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Product attribute value extraction plays an important role for many
real-world applications in e-Commerce such as product search and
recommendation. Previous methods treat it as a sequence labeling task that
needs more annotation for position of values in the product text. This limits
their application to real-world scenario in which only attribute values are
weakly-annotated for each product without their position. Moreover, these
methods only use product text (i.e., product title and description) and do not
consider the semantic connection between the multiple attribute values of a
given product and its text, which can help attribute value extraction. In this
paper, we reformulate this task as a multi-label classification task that can
be applied for real-world scenario in which only annotation of attribute values
is available to train models (i.e., annotation of positional information of
attribute values is not available). We propose a classification model with
semantic matching and negative label sampling for attribute value extraction.
Semantic matching aims to capture semantic interactions between attribute
values of a given product and its text. Negative label sampling aims to enhance
the model's ability of distinguishing similar values belonging to the same
attribute. Experimental results on three subsets of a large real-world
e-Commerce dataset demonstrate the effectiveness and superiority of our
proposed model.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07138" title="Abstract">arXiv:2310.07138</a> [<a href="/pdf/2310.07138" title="Download PDF">pdf</a>, <a href="/format/2310.07138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Task Routing for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Byeongjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sangmin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Go%2C+H">Hyojun Go</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin-Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models generate highly realistic images through learning a
multi-step denoising process, naturally embodying the principles of multi-task
learning (MTL). Despite the inherent connection between diffusion models and
MTL, there remains an unexplored area in designing neural architectures that
explicitly incorporate MTL into the framework of diffusion models. In this
paper, we present Denoising Task Routing (DTR), a simple add-on strategy for
existing diffusion model architectures to establish distinct information
pathways for individual tasks within a single architecture by selectively
activating subsets of channels in the model. What makes DTR particularly
compelling is its seamless integration of prior knowledge of denoising tasks
into the framework: (1) Task Affinity: DTR activates similar channels for tasks
at adjacent timesteps and shifts activated channels as sliding windows through
timesteps, capitalizing on the inherent strong affinity between tasks at
adjacent timesteps. (2) Task Weights: During the early stages (higher
timesteps) of the denoising process, DTR assigns a greater number of
task-specific channels, leveraging the insight that diffusion models prioritize
reconstructing global structure and perceptually rich contents in earlier
stages, and focus on simple noise removal in later stages. Our experiments
demonstrate that DTR consistently enhances the performance of diffusion models
across various evaluation protocols, all without introducing additional
parameters. Furthermore, DTR contributes to accelerating convergence during
training. Finally, we show the complementarity between our architectural
approach and existing MTL optimization techniques, providing a more complete
view of MTL within the context of diffusion training.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07141" title="Abstract">arXiv:2310.07141</a> [<a href="/pdf/2310.07141" title="Download PDF">pdf</a>, <a href="/ps/2310.07141" title="Download PostScript">ps</a>, <a href="/format/2310.07141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time and Frequency Offset Estimation and Intercarrier Interference  Cancellation for AFDM Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuankun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Anjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Miaowen Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+F">Fei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinming Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Affine frequency division multiplexing (AFDM) is an emerging multicarrier
waveform that offers a potential solution for achieving reliable communication
for time-varying channels. This paper proposes two maximum likelihood (ML)
estimators of symbol time offset and carrier frequency offset for AFDM systems.
The joint ML estimator evaluates the arrival time and frequency offset by
comparing the correlations of samples. Moreover, we propose the stepwise ML
estimator to reduce the complexity. The proposed estimators exploit the
redundant information contained within the chirp-periodic prefix inherent in
AFDM symbols, thus dispensing with any additional pilots. To further mitigate
the intercarrier interference resulting from the residual frequency offset, we
design a mirror-mappingbased scheme for AFDM systems. Numerical results verify
the effectiveness of the proposed time and frequency offset estimation criteria
and the mirror-mapping-based modulation for AFDM systems.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07142" title="Abstract">arXiv:2310.07142</a> [<a href="/pdf/2310.07142" title="Download PDF">pdf</a>, <a href="/ps/2310.07142" title="Download PostScript">ps</a>, <a href="/format/2310.07142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validating Synthetic Usage Data in Living Lab Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breuer%2C+T">Timo Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Fuhr%2C+N">Norbert Fuhr</a>, 
<a href="/search/cs?searchtype=author&query=Schaer%2C+P">Philipp Schaer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages + appendix and references, accepted JDIQ journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Data and Information Quality 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Evaluating retrieval performance without editorial relevance judgments is
challenging, but instead, user interactions can be used as relevance signals.
Living labs offer a way for small-scale platforms to validate information
retrieval systems with real users. If enough user interaction data are
available, click models can be parameterized from historical sessions to
evaluate systems before exposing users to experimental rankings. However,
interaction data are sparse in living labs, and little is studied about how
click models can be validated for reliable user simulations when click data are
available in moderate amounts.
<br />This work introduces an evaluation approach for validating synthetic usage
data generated by click models in data-sparse human-in-the-loop environments
like living labs. We ground our methodology on the click model's estimates
about a system ranking compared to a reference ranking for which the relative
performance is known. Our experiments compare different click models and their
reliability and robustness as more session log data becomes available. In our
setup, simple click models can reliably determine the relative system
performance with already 20 logged sessions for 50 queries. In contrast, more
complex click models require more session data for reliable estimates, but they
are a better choice in simulated interleaving experiments when enough session
data are available. While it is easier for click models to distinguish between
more diverse systems, it is harder to reproduce the system ranking based on the
same retrieval algorithm with different interpolation weights. Our setup is
entirely open, and we share the code to reproduce the experiments.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07143" title="Abstract">arXiv:2310.07143</a> [<a href="/pdf/2310.07143" title="Download PDF">pdf</a>, <a href="/format/2310.07143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Learning from Purified Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Minjing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Imitation learning has emerged as a promising approach for addressing
sequential decision-making problems, with the assumption that expert
demonstrations are optimal. However, in real-world scenarios, expert
demonstrations are often imperfect, leading to challenges in effectively
applying imitation learning. While existing research has focused on optimizing
with imperfect demonstrations, the training typically requires a certain
proportion of optimal demonstrations to guarantee performance. To tackle these
problems, we propose to purify the potential perturbations in imperfect
demonstrations and subsequently conduct imitation learning from purified
demonstrations. Motivated by the success of diffusion models, we introduce a
two-step purification via the diffusion process. In the first step, we apply a
forward diffusion process to effectively smooth out the potential perturbations
in imperfect demonstrations by introducing additional noise. Subsequently, a
reverse generative process is utilized to recover the optimal expert
demonstrations from the diffused ones. We provide theoretical evidence
supporting our approach, demonstrating that total variance distance between the
purified and optimal demonstration distributions can be upper-bounded. The
evaluation results on MuJoCo demonstrate the effectiveness of our method from
different aspects.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07146" title="Abstract">arXiv:2310.07146</a> [<a href="/pdf/2310.07146" title="Download PDF">pdf</a>, <a href="/format/2310.07146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Psychotherapy with Large Language Models: Cognitive  Distortion Detection through Diagnosis of Thought Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Mental illness remains one of the most critical public health issues of our
time, due to the severe scarcity and accessibility limit of professionals.
Psychotherapy requires high-level expertise to conduct deep, complex reasoning
and analysis on the cognition modeling of the patients. In the era of Large
Language Models, we believe it is the right time to develop AI assistance for
computational psychotherapy. We study the task of cognitive distortion
detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs
diagnosis on the patient's speech via three stages: subjectivity assessment to
separate the facts and the thoughts; contrastive reasoning to elicit the
reasoning processes supporting and contradicting the thoughts; and schema
analysis to summarize the cognition schemas. The generated diagnosis rationales
through the three stages are essential for assisting the professionals.
Experiments demonstrate that DoT obtains significant improvements over ChatGPT
for cognitive distortion detection, while generating high-quality rationales
approved by human experts.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07147" title="Abstract">arXiv:2310.07147</a> [<a href="/pdf/2310.07147" title="Download PDF">pdf</a>, <a href="/format/2310.07147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qingyi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have showcased remarkable impacts across a wide
spectrum of natural language processing tasks. Fine-tuning these pre-trained
models on downstream datasets provides further significant performance gains,
but this process has been challenging due to its extraordinary resource
requirements. To this end, existing efforts focus on parameter-efficient
fine-tuning, which, unfortunately, fail to capitalize on the powerful potential
of full-parameter fine-tuning. In this work, we propose QFT, a novel Quantized
Full-parameter Tuning framework for LLMs that enables memory-efficient
fine-tuning without harming performance. Our framework incorporates two novel
ideas: (i) we adopt the efficient Lion optimizer, which only keeps track of the
momentum and has consistent update magnitudes for each parameter, an inherent
advantage for robust quantization; and (ii) we quantize all model states and
store them as integer values, and present a gradient flow and parameter update
scheme for the quantized weights. As a result, QFT reduces the model state
memory to 21% of the standard solution while achieving comparable performance,
e.g., tuning a LLaMA-7B model requires only &lt;30GB of memory, satisfied by a
single A6000 GPU.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07148" title="Abstract">arXiv:2310.07148</a> [<a href="/pdf/2310.07148" title="Download PDF">pdf</a>, <a href="/format/2310.07148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ObliuSky: Oblivious User-Defined Skyline Query Processing in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yifeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Songlei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Z">Zhongyun Hua</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yansong Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review by a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The proliferation of cloud computing has greatly spurred the popularity of
outsourced database storage and management, in which the cloud holding
outsourced databases can process database queries on demand. Among others,
skyline queries play an important role in the database field due to its
prominent usefulness in multi-criteria decision support systems. To accommodate
the tailored needs of users, user-defined skyline query has recently emerged as
an intriguing advanced type of skyline query, which allows users to define
custom preferences in their skyline queries (including the target attributes,
preferred dominance relations, and range constraints on the target attributes).
However, user-defined skyline query services, if deployed in the cloud, may
raise critical privacy concerns as the outsourced databases and skyline queries
may contain proprietary/privacy-sensitive information, and the cloud might even
suffer from data breaches. In light of the above, this paper presents ObliuSky,
a new system framework enabling oblivious user-defined skyline query processing
in the cloud. ObliuSky departs from the state-of-the-art prior work by not only
providing confidentiality protection for the content of the outsourced
database, the user-defined skyline query, and the query results, but also
making the cloud oblivious to the data patterns (e.g., user-defined dominance
relations among database points and search access patterns) which may
indirectly cause data leakages. We formally analyze the security guarantees and
conduct extensive performance evaluations. The results show that while
achieving much stronger security guarantees than the state-of-the-art prior
work, ObliuSky is superior in database and query encryption efficiency, with
practically affordable query latency.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07149" title="Abstract">arXiv:2310.07149</a> [<a href="/pdf/2310.07149" title="Download PDF">pdf</a>, <a href="/format/2310.07149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Unsupervised Domain Adaptation by Retaining Confident Entropy via  Edge Concatenation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hye-Seong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dong-Gyu Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The generalization capability of unsupervised domain adaptation can mitigate
the need for extensive pixel-level annotations to train semantic segmentation
networks by training models on synthetic data as a source with
computer-generated annotations. Entropy-based adversarial networks are proposed
to improve source domain prediction; however, they disregard significant
external information, such as edges, which have the potential to identify and
distinguish various objects within an image accurately. To address this issue,
we introduce a novel approach to domain adaptation, leveraging the synergy of
internal and external information within entropy-based adversarial networks. In
this approach, we enrich the discriminator network with edge-predicted
probability values within this innovative framework to enhance the clarity of
class boundaries. Furthermore, we devised a probability-sharing network that
integrates diverse information for more effective segmentation. Incorporating
object edges addresses a pivotal aspect of unsupervised domain adaptation that
has frequently been neglected in the past -- the precise delineation of object
boundaries. Conventional unsupervised domain adaptation methods usually center
around aligning feature distributions and may not explicitly model object
boundaries. Our approach effectively bridges this gap by offering clear
guidance on object boundaries, thereby elevating the quality of domain
adaptation. Our approach undergoes rigorous evaluation on the established
unsupervised domain adaptation benchmarks, specifically in adapting SYNTHIA
$\rightarrow$ Cityscapes and SYNTHIA $\rightarrow$ Mapillary. Experimental
results show that the proposed model attains better performance than
state-of-the-art methods. The superior performance across different
unsupervised domain adaptation scenarios highlights the versatility and
robustness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07150" title="Abstract">arXiv:2310.07150</a> [<a href="/pdf/2310.07150" title="Download PDF">pdf</a>, <a href="/format/2310.07150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determining Winners in Elections with Absent Votes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qishen Han</a>, 
<a href="/search/cs?searchtype=author&query=Marian%2C+A">Am&#xe9;lie Marian</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lirong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">An important question in elections is the determine whether a candidate can
be a winner when some votes are absent. We study this determining winner with
the absent votes (WAV) problem when the votes are top-truncated. We show that
the WAV problem is NP-complete for the single transferable vote, Maximin, and
Copeland, and propose a special case of positional scoring rule such that the
problem can be computed in polynomial time. Our results in top-truncated
rankings differ from the results in full rankings as their hardness results
still hold when the number of candidates or the number of missing votes are
bounded, while we show that the problem can be solved in polynomial time in
either case.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07152" title="Abstract">arXiv:2310.07152</a> [<a href="/pdf/2310.07152" title="Download PDF">pdf</a>, <a href="/format/2310.07152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN  Partition for On-Device ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yifeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuanyuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Ding Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangqun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by S&amp;P'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">On-device ML introduces new security challenges: DNN models become white-box
accessible to device users. Based on white-box information, adversaries can
conduct effective model stealing (MS) and membership inference attack (MIA).
Using Trusted Execution Environments (TEEs) to shield on-device DNN models aims
to downgrade (easy) white-box attacks to (harder) black-box attacks. However,
one major shortcoming is the sharply increased latency (up to 50X). To
accelerate TEE-shield DNN computation with GPUs, researchers proposed several
model partition techniques. These solutions, referred to as TEE-Shielded DNN
Partition (TSDP), partition a DNN model into two parts, offloading the
privacy-insensitive part to the GPU while shielding the privacy-sensitive part
within the TEE. This paper benchmarks existing TSDP solutions using both MS and
MIA across a variety of DNN models, datasets, and metrics. We show important
findings that existing TSDP solutions are vulnerable to privacy-stealing
attacks and are not as safe as commonly believed. We also unveil the inherent
difficulty in deciding optimal DNN partition configurations (i.e., the highest
security with minimal utility cost) for present TSDP solutions. The experiments
show that such ``sweet spot'' configurations vary across datasets and models.
Based on lessons harvested from the experiments, we present TEESlice, a novel
TSDP method that defends against MS and MIA during DNN inference. TEESlice
follows a partition-before-training strategy, which allows for accurate
separation between privacy-related weights from public weights. TEESlice
delivers the same security protection as shielding the entire DNN model inside
TEE (the ``upper-bound'' security guarantees) with over 10X less overhead (in
both experimental and real-world environments) than prior TSDP solutions and no
accuracy loss.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07154" title="Abstract">arXiv:2310.07154</a> [<a href="/pdf/2310.07154" title="Download PDF">pdf</a>, <a href="/format/2310.07154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Because Some Sighted People, They Don&#x27;t Know What the Heck You&#x27;re  Talking About:&quot; A Study of Blind TikTokers&#x27; Infrastructuring Work to Build  Independence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CSCW'24, 29 pages, 2 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">There has been extensive research on the experiences of individuals with
visual impairments on text- and image-based social media platforms, such as
Facebook and Twitter. However, little is known about the experiences of
visually impaired users on short-video platforms like TikTok. To bridge this
gap, we conducted an interview study with 30 BlindTokers (the nickname of blind
TikTokers). Our study aimed to explore the various activities of BlindTokers on
TikTok, including everyday entertainment, professional development, and
community engagement. The widespread usage of TikTok among participants
demonstrated that they considered TikTok and its associated experiences as the
infrastructure for their activities. Additionally, participants reported
experiencing breakdowns in this infrastructure due to accessibility issues.
They had to carry out infrastructuring work to resolve the breakdowns. Blind
users' various practices on TikTok also foregrounded their perceptions of
independence. We then discussed blind users' nuanced understanding of the
TikTok-mediated independence; we also critically examined BlindTokers'
infrastructuring work for such independence.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07155" title="Abstract">arXiv:2310.07155</a> [<a href="/pdf/2310.07155" title="Download PDF">pdf</a>, <a href="/format/2310.07155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;A Tale of Two Movements&quot;: Identifying and Comparing Perspectives in  #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly  Supervised Graph-based Structured Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Shamik Roy</a>, 
<a href="/search/cs?searchtype=author&query=Goldwasser%2C+D">Dan Goldwasser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version to Findings of EMNLP 2023 (camera ready coming soon)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media has become a major driver of social change, by facilitating the
formation of online social movements. Automatically understanding the
perspectives driving the movement and the voices opposing it, is a challenging
task as annotated data is difficult to obtain. We propose a weakly supervised
graph-based approach that explicitly models perspectives in
#BackLivesMatter-related tweets. Our proposed approach utilizes a
social-linguistic representation of the data. We convert the text to a graph by
breaking it into structured elements and connect it with the social network of
authors, then structured prediction is done over the elements for identifying
perspectives. Our approach uses a small seed set of labeled examples. We
experiment with large language models for generating artificial training
examples, compare them to manual annotation, and find that it achieves
comparable performance. We perform quantitative and qualitative analyses using
a human-annotated test set. Our model outperforms multitask baselines by a
large margin, successfully characterizing the perspectives supporting and
opposing #BLM.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07156" title="Abstract">arXiv:2310.07156</a> [<a href="/pdf/2310.07156" title="Download PDF">pdf</a>, <a href="/format/2310.07156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Travelling Thief Problems using Coordination Based Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Namazi%2C+M">Majid Namazi</a>, 
<a href="/search/cs?searchtype=author&query=Newton%2C+M+A+H">M.A. Hakim Newton</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+C">Conrad Sanderson</a>, 
<a href="/search/cs?searchtype=author&query=Sattar%2C+A">Abdul Sattar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> expanded and revised version of <a href="/abs/1911.03124">arXiv:1911.03124</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">A travelling thief problem (TTP) is a proxy to real-life problems such as
postal collection. TTP comprises an entanglement of a travelling salesman
problem (TSP) and a knapsack problem (KP) since items of KP are scattered over
cities of TSP, and a thief has to visit cities to collect items. In TTP, city
selection and item selection decisions need close coordination since the
thief's travelling speed depends on the knapsack's weight and the order of
visiting cities affects the order of item collection. Existing TTP solvers deal
with city selection and item selection separately, keeping decisions for one
type unchanged while dealing with the other type. This separation essentially
means very poor coordination between two types of decision. In this paper, we
first show that a simple local search based coordination approach does not work
in TTP. Then, to address the aforementioned problems, we propose a human
designed coordination heuristic that makes changes to collection plans during
exploration of cyclic tours. We further propose another human designed
coordination heuristic that explicitly exploits the cyclic tours in item
selections during collection plan exploration. Lastly, we propose a machine
learning based coordination heuristic that captures characteristics of the two
human designed coordination heuristics. Our proposed coordination based
approaches help our TTP solver significantly outperform existing
state-of-the-art TTP solvers on a set of benchmark problems. Our solver is
named Cooperation Coordination (CoCo) and its source code is available from
https://github.com/majid75/CoCo
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07157" title="Abstract">arXiv:2310.07157</a> [<a href="/pdf/2310.07157" title="Download PDF">pdf</a>, <a href="/ps/2310.07157" title="Download PostScript">ps</a>, <a href="/format/2310.07157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operating-Envelopes-Aware Decentralized Welfare Maximization for Energy  Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alahmed%2C+A+S">Ahmed S. Alahmed</a>, 
<a href="/search/eess?searchtype=author&query=Cavraro%2C+G">Guido Cavraro</a>, 
<a href="/search/eess?searchtype=author&query=Bernstein%2C+A">Andrey Bernstein</a>, 
<a href="/search/eess?searchtype=author&query=Tong%2C+L">Lang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures, 1 table. Presented at the 59th Annual Allerton Conference on Communication, Control, and Computing, Monticello, IL, Sep., 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Theoretical Economics (econ.TH); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose an operating-envelope-aware, prosumer-centric, and efficient
energy community that aggregates individual and shared community distributed
energy resources and transacts with a regulated distribution system operator
(DSO) under a generalized net energy metering tariff design. To ensure safe
network operation, the DSO imposes dynamic export and import limits, known as
dynamic operating envelopes, on end-users' revenue meters. Given the operating
envelopes, we propose an incentive-aligned community pricing mechanism under
which the decentralized optimization of community members' benefit implies the
optimization of overall community welfare. The proposed pricing mechanism
satisfies the cost-causation principle and ensures the stability of the energy
community in a coalition game setting. Numerical examples provide insights into
the characteristics of the proposed pricing mechanism and quantitative measures
of its performance.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07159" title="Abstract">arXiv:2310.07159</a> [<a href="/pdf/2310.07159" title="Download PDF">pdf</a>, <a href="/format/2310.07159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> My Brother Helps Me: Node Injection Based Adversarial Attack on Social  Bot Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanjun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xinran Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yanwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Social platforms such as Twitter are under siege from a multitude of
fraudulent users. In response, social bot detection tasks have been developed
to identify such fake users. Due to the structure of social networks, the
majority of methods are based on the graph neural network(GNN), which is
susceptible to attacks. In this study, we propose a node injection-based
adversarial attack method designed to deceive bot detection models. Notably,
neither the target bot nor the newly injected bot can be detected when a new
bot is added around the target bot. This attack operates in a black-box
fashion, implying that any information related to the victim model remains
unknown. To our knowledge, this is the first study exploring the resilience of
bot detection through graph node injection. Furthermore, we develop an
attribute recovery module to revert the injected node embedding from the graph
embedding space back to the original feature space, enabling the adversary to
manipulate node perturbation effectively. We conduct adversarial attacks on
four commonly used GNN structures for bot detection on two widely used
datasets: Cresci-2015 and TwiBot-22. The attack success rate is over 73\% and
the rate of newly injected nodes being detected as bots is below 13\% on these
two datasets.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07160" title="Abstract">arXiv:2310.07160</a> [<a href="/pdf/2310.07160" title="Download PDF">pdf</a>, <a href="/format/2310.07160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLark: A Multimodal Foundation Model for Music
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Josh Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+S">Simon Durand</a>, 
<a href="/search/cs?searchtype=author&query=Stoller%2C+D">Daniel Stoller</a>, 
<a href="/search/cs?searchtype=author&query=Bittner%2C+R+M">Rachel M. Bittner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Music has a unique and complex structure which is challenging for both expert
humans and existing AI systems to understand, and presents unique challenges
relative to other forms of audio. We present LLark, an instruction-tuned
multimodal model for music understanding. We detail our process for dataset
creation, which involves augmenting the annotations of diverse open-source
music datasets and converting them to a unified instruction-tuning format. We
propose a multimodal architecture for LLark, integrating a pretrained
generative model for music with a pretrained language model. In evaluations on
three types of tasks (music understanding, captioning, and reasoning), we show
that our model matches or outperforms existing baselines in zero-shot
generalization for music understanding, and that humans show a high degree of
agreement with the model's responses in captioning and reasoning tasks. LLark
is trained entirely from open-source music data and models, and we make our
training code available along with the release of this paper. Additional
results and audio examples are at https://bit.ly/llark, and our source code is
available at https://github.com/spotify-research/llark .
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07161" title="Abstract">arXiv:2310.07161</a> [<a href="/pdf/2310.07161" title="Download PDF">pdf</a>, <a href="/ps/2310.07161" title="Download PostScript">ps</a>, <a href="/format/2310.07161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konan%2C+J">Joseph Konan</a>, 
<a href="/search/cs?searchtype=author&query=Bhargave%2C+O">Ojas Bhargave</a>, 
<a href="/search/cs?searchtype=author&query=Agnihotri%2C+S">Shikhar Agnihotri</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuo Han</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yunyang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Within the ambit of VoIP (Voice over Internet Protocol) telecommunications,
the complexities introduced by acoustic transformations merit rigorous
analysis. This research, rooted in the exploration of proprietary sender-side
denoising effects, meticulously evaluates platforms such as Google Meets and
Zoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset,
ensuring a structured examination tailored to various denoising settings and
receiver interfaces. A methodological novelty is introduced via the Oaxaca
decomposition, traditionally an econometric tool, repurposed herein to analyze
acoustic-phonetic perturbations within VoIP systems. To further ground the
implications of these transformations, psychoacoustic metrics, specifically
PESQ and STOI, were harnessed to furnish a comprehensive understanding of
speech alterations. Cumulatively, the insights garnered underscore the
intricate landscape of VoIP-influenced acoustic dynamics. In addition to the
primary findings, a multitude of metrics are reported, extending the research
purview. Moreover, out-of-domain benchmarking for both time and time-frequency
domain speech enhancement models is included, thereby enhancing the depth and
applicability of this inquiry.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07165" title="Abstract">arXiv:2310.07165</a> [<a href="/pdf/2310.07165" title="Download PDF">pdf</a>, <a href="/format/2310.07165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Microgrid Trading Framework Based on PoC Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lianghaojie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Youquan Xian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jianyong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianxian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the field of energy Internet, blockchain-based distributed energy trading
mode is a promising way to replace the traditional centralized trading mode.
However, the current power blockchain platform based on public chain has
problems such as low consensus efficiency and waste of computing resources. The
energy trading platform based on the consortium chain has problems such as
inability to attract users to join and collusion between alliances. We propose
a microgrid trading framework based on proof of contribution (PoC). According
to the contribution value, we randomly select nodes based on weights through
verifiable random functions (VRF) in each round of consensus to form the next
round of consensus committee. The proposed electricity trading framework not
only improves the consensus efficiency of the blockchain, but also is suitable
as an incentive mechanism to attract users to participate in the power
blockchain. Experiments show that our framework is effective and the
contribution value we designed is reasonable. Through our framework, we can
motivate users to participate and make energy transactions more fair.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07166" title="Abstract">arXiv:2310.07166</a> [<a href="/pdf/2310.07166" title="Download PDF">pdf</a>, <a href="/format/2310.07166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anchor-based Multi-view Subspace Clustering with Hierarchical Feature  Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou%2C+Q">Qiyuan Ou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+E">En Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-view clustering has attracted growing attention owing to its
capabilities of aggregating information from various sources and its promising
horizons in public affairs. Up till now, many advanced approaches have been
proposed in recent literature. However, there are several ongoing difficulties
to be tackled. One common dilemma occurs while attempting to align the features
of different views. We dig out as well as deploy the dependency amongst views
through hierarchical feature descent, which leads to a common latent space(
STAGE 1). This latent space, for the first time of its kind, is regarded as a
'resemblance space', as it reveals certain correlations and dependencies of
different views. To be exact, the one-hot encoding of a category can also be
referred to as a resemblance space in its terminal phase. Moreover, due to the
intrinsic fact that most of the existing multi-view clustering algorithms stem
from k-means clustering and spectral clustering, this results in cubic time
complexity w.r.t. the number of the objects. However, we propose Anchor-based
Multi-view Subspace Clustering with Hierarchical Feature Descent(MVSC-HFD) to
further reduce the computing complexity to linear time cost through a unified
sampling strategy in resemblance space( STAGE 2), followed by subspace
clustering to learn the representation collectively( STAGE 3). Extensive
experimental results on public benchmark datasets demonstrate that our proposed
model consistently outperforms the state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07170" title="Abstract">arXiv:2310.07170</a> [<a href="/pdf/2310.07170" title="Download PDF">pdf</a>, <a href="/format/2310.07170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHALM: Building a Knowledge Graph from Scratch by Prompting Humans and a  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ide%2C+T">Tatsuya Ide</a>, 
<a href="/search/cs?searchtype=author&query=Murata%2C+E">Eiki Murata</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+D">Daisuke Kawahara</a>, 
<a href="/search/cs?searchtype=author&query=Yamazaki%2C+T">Takato Yamazaki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Shinzato%2C+K">Kenta Shinzato</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+T">Toshinori Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite the remarkable progress in natural language understanding with
pretrained Transformers, neural language models often do not handle commonsense
knowledge well. Toward commonsense-aware models, there have been attempts to
obtain knowledge, ranging from automatic acquisition to crowdsourcing. However,
it is difficult to obtain a high-quality knowledge base at a low cost,
especially from scratch. In this paper, we propose PHALM, a method of building
a knowledge graph from scratch, by prompting both crowdworkers and a large
language model (LLM). We used this method to build a Japanese event knowledge
graph and trained Japanese commonsense generation models. Experimental results
revealed the acceptability of the built graph and inferences generated by the
trained models. We also report the difference in prompting humans and an LLM.
Our code, data, and models are available at
github.com/nlp-waseda/comet-atomic-ja.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07171" title="Abstract">arXiv:2310.07171</a> [<a href="/pdf/2310.07171" title="Download PDF">pdf</a>, <a href="/format/2310.07171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Generalization via Information-Theoretic Distribution  Diversification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheshun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Federated Learning (FL) has surged in prominence due to its capability of
collaborative model training without direct data sharing. However, the vast
disparity in local data distributions among clients, often termed the
non-Independent Identically Distributed (non-IID) challenge, poses a
significant hurdle to FL's generalization efficacy. The scenario becomes even
more complex when not all clients participate in the training process, a common
occurrence due to unstable network connections or limited computational
capacities. This can greatly complicate the assessment of the trained models'
generalization abilities. While a plethora of recent studies has centered on
the generalization gap pertaining to unseen data from participating clients
with diverse distributions, the divergence between the training distributions
of participating clients and the testing distributions of non-participating
ones has been largely overlooked. In response, our paper unveils an
information-theoretic generalization framework for FL. Specifically, it
quantifies generalization errors by evaluating the information entropy of local
distributions and discerning discrepancies across these distributions. Inspired
by our deduced generalization bounds, we introduce a weighted aggregation
approach and a duo of client selection strategies. These innovations aim to
bolster FL's generalization prowess by encompassing a more varied set of client
data distributions. Our extensive empirical evaluations reaffirm the potency of
our proposed methods, aligning seamlessly with our theoretical construct.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07174" title="Abstract">arXiv:2310.07174</a> [<a href="/pdf/2310.07174" title="Download PDF">pdf</a>, <a href="/format/2310.07174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Neural Sorting Networks with Error-Free Differentiable Swap  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jungtaek Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jeongbeen Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsu Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, 21 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Sorting is a fundamental operation of all computer systems, having been a
long-standing significant research topic. Beyond the problem formulation of
traditional sorting algorithms, we consider sorting problems for more abstract
yet expressive inputs, e.g., multi-digit images and image fragments, through a
neural sorting network. To learn a mapping from a high-dimensional input to an
ordinal variable, the differentiability of sorting networks needs to be
guaranteed. In this paper we define a softening error by a differentiable swap
function, and develop an error-free swap function that holds non-decreasing and
differentiability conditions. Furthermore, a permutation-equivariant
Transformer network with multi-head attention is adopted to capture dependency
between given inputs and also leverage its model capacity with self-attention.
Experiments on diverse sorting benchmarks show that our methods perform better
than or comparable to baseline methods.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07176" title="Abstract">arXiv:2310.07176</a> [<a href="/pdf/2310.07176" title="Download PDF">pdf</a>, <a href="/format/2310.07176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving mitosis detection on histopathology images using large  vision-language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Ruiwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+J">James Hall</a>, 
<a href="/search/cs?searchtype=author&query=Tenenholtz%2C+N">Neil Tenenholtz</a>, 
<a href="/search/cs?searchtype=author&query=Severson%2C+K">Kristen Severson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ISBI 2024. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In certain types of cancerous tissue, mitotic count has been shown to be
associated with tumor proliferation, poor prognosis, and therapeutic
resistance. Due to the high inter-rater variability of mitotic counting by
pathologists, convolutional neural networks (CNNs) have been employed to reduce
the subjectivity of mitosis detection in hematoxylin and eosin (H&amp;E)-stained
whole slide images. However, most existing models have performance that lags
behind expert panel review and only incorporate visual information. In this
work, we demonstrate that pre-trained large-scale vision-language models that
leverage both visual features and natural language improve mitosis detection
accuracy. We formulate the mitosis detection task as an image captioning task
and a visual question answering (VQA) task by including metadata such as tumor
and scanner types as context. The effectiveness of our pipeline is demonstrated
via comparison with various baseline models using 9,501 mitotic figures and
11,051 hard negatives (non-mitotic figures that are difficult to characterize)
from the publicly available Mitosis Domain Generalization Challenge (MIDOG22)
dataset.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07177" title="Abstract">arXiv:2310.07177</a> [<a href="/pdf/2310.07177" title="Download PDF">pdf</a>, <a href="/format/2310.07177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Speculative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lanxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Bailis%2C+P">Peter Bailis</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+A">Alvin Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Speculative decoding is a pivotal technique to accelerate the inference of
large language models (LLMs) by employing a smaller draft model to predict the
target model's outputs. However, its efficacy can be limited due to the low
predictive accuracy of the draft model, particularly when faced with diverse
text inputs and a significant capability gap between the draft and target
models. We introduce online speculative decoding (OSD) to address this
challenge. The main idea is to continually update (multiple) draft model(s) on
observed user query data using the abundant excess computational power in an
LLM serving cluster. Given that LLM inference is memory-bounded, the surplus
computational power in a typical LLM serving cluster can be repurposed for
online retraining of draft models, thereby making the training cost-neutral.
Since the query distribution of an LLM service is relatively simple, retraining
on query distribution enables the draft model to more accurately predict the
target model's outputs, particularly on data originating from query
distributions. As the draft model evolves online, it aligns with the query
distribution in real time, mitigating distribution shifts. We develop a
prototype of online speculative decoding based on online knowledge distillation
and evaluate it using both synthetic and real query data on several popular
LLMs. The results show a substantial increase in the token acceptance rate by
0.1 to 0.65, which translates into 1.22x to 3.06x latency reduction.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07179" title="Abstract">arXiv:2310.07179</a> [<a href="/pdf/2310.07179" title="Download PDF">pdf</a>, <a href="/format/2310.07179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tongtong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanxiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Novel view synthesis of satellite images holds a wide range of practical
applications. While recent advances in the Neural Radiance Field have
predominantly targeted pin-hole cameras, and models for satellite cameras often
demand sufficient input views. This paper presents rpcPRF, a Multiplane Images
(MPI) based Planar neural Radiance Field for Rational Polynomial Camera (RPC).
Unlike coordinate-based neural radiance fields in need of sufficient views of
one scene, our model is applicable to single or few inputs and performs well on
images from unseen scenes. To enable generalization across scenes, we propose
to use reprojection supervision to induce the predicted MPI to learn the
correct geometry between the 3D coordinates and the images. Moreover, we remove
the stringent requirement of dense depth supervision from deep
multiview-stereo-based methods by introducing rendering techniques of radiance
fields. rpcPRF combines the superiority of implicit representations and the
advantages of the RPC model, to capture the continuous altitude space while
learning the 3D structure. Given an RGB image and its corresponding RPC, the
end-to-end model learns to synthesize the novel view with a new RPC and
reconstruct the altitude of the scene. When multiple views are provided as
inputs, rpcPRF exerts extra supervision provided by the extra views. On the TLC
dataset from ZY-3, and the SatMVS3D dataset with urban scenes from WV-3, rpcPRF
outperforms state-of-the-art nerf-based methods by a significant margin in
terms of image fidelity, reconstruction accuracy, and efficiency, for both
single-view and multiview task.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07180" title="Abstract">arXiv:2310.07180</a> [<a href="/pdf/2310.07180" title="Download PDF">pdf</a>, <a href="/format/2310.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication enabled Multiple Base Stations  Cooperative Sensing Towards 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kaifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruizhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE NetWork 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Driven by the intelligent applications of sixth-generation (6G) mobile
communication systems such as smart city and autonomous driving, which connect
the physical and cyber space, the integrated sensing and communication (ISAC)
brings a revolutionary change to the base stations (BSs) of 6G by integrating
radar sensing and communication in the same hardware and wireless resource.
However, with the requirements of long-range and accurate sensing in the
applications of smart city and autonomous driving, the ISAC enabled single BS
still has a limitation in the sensing range and accuracy. With the networked
infrastructures of mobile communication systems, multi-BS cooperative sensing
is a natural choice satisfying the requirement of long-range and accurate
sensing. In this article, the framework of multi-BS cooperative sensing is
proposed, breaking through the limitation of single-BS sensing. The enabling
technologies, including unified ISAC performance metrics, ISAC signal design
and optimization, interference management, cooperative sensing algorithms, are
introduced in details. The performance evaluation results are provided to
verify the effectiveness of multi-BS cooperative sensing schemes. With ISAC
enabled multi-BS cooperative sensing (ISAC-MCS), the intelligent
infrastructures connecting physical and cyber space can be established,
ushering the era of 6G promoting the intelligence of everything.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07182" title="Abstract">arXiv:2310.07182</a> [<a href="/pdf/2310.07182" title="Download PDF">pdf</a>, <a href="/format/2310.07182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generate Coherent Rays Directly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zaonan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Weilai Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xu Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yulong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Songnan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Q">Qilong Kou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bo Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">The path tracing method generates incoherent rays by randomly sampling
directions. This randomness makes it unsuitable for modern processor
architectures that rely on coherence to achieve optimal performance. Many
efforts have been made to address this issue by reordering rays based on their
origin, end, or direction to enhance coherence. However, a drawback of
reordering methods is the need to encode and sort rays before tracing,
introducing additional overhead. We propose a technique to generate coherent
rays directly by reusing the direction. Additionally, we introduce an
interleaved reuse domain partition method to mitigate the impact of sampling
correlation resulting from direction reuse. We demonstrate the effectiveness of
our approach across various scenes, establishing its superiority over
reordering methods.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07183" title="Abstract">arXiv:2310.07183</a> [<a href="/pdf/2310.07183" title="Download PDF">pdf</a>, <a href="/format/2310.07183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-OCTA: Prompting Segment-Anything for OCTA Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+H">Haojian Ning</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiying Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.11758">arXiv:2309.11758</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the analysis of optical coherence tomography angiography (OCTA) images,
the operation of segmenting specific targets is necessary. Existing methods
typically train on supervised datasets with limited samples (approximately a
few hundred), which can lead to overfitting. To address this, the low-rank
adaptation technique is adopted for foundation model fine-tuning and proposed
corresponding prompt point generation strategies to process various
segmentation tasks on OCTA datasets. This method is named SAM-OCTA and has been
experimented on the publicly available OCTA-500 and ROSE datasets. This method
achieves or approaches state-of-the-art segmentation performance metrics. The
effect and applicability of prompt points are discussed in detail for the
retinal vessel, foveal avascular zone, capillary, artery, and vein segmentation
tasks. Furthermore, SAM-OCTA accomplishes local vessel segmentation and
effective artery-vein segmentation, which was not well-solved in previous
works. The code is available at https://github.com/ShellRedia/SAM-OCTA.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07184" title="Abstract">arXiv:2310.07184</a> [<a href="/pdf/2310.07184" title="Download PDF">pdf</a>, <a href="/format/2310.07184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroInspect: Interpretable Neuron-based Debugging Framework through  Class-conditional Visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yeong-Joon Ju</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Ji-Hoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Summitted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite deep learning (DL) has achieved remarkable progress in various
domains, the DL models are still prone to making mistakes. This issue
necessitates effective debugging tools for DL practitioners to interpret the
decision-making process within the networks. However, existing debugging
methods often demand extra data or adjustments to the decision process,
limiting their applicability. To tackle this problem, we present NeuroInspect,
an interpretable neuron-based debugging framework with three key stages:
counterfactual explanations, feature visualizations, and false correlation
mitigation. Our debugging framework first pinpoints neurons responsible for
mistakes in the network and then visualizes features embedded in the neurons to
be human-interpretable. To provide these explanations, we introduce
CLIP-Illusion, a novel feature visualization method that generates images
representing features conditioned on classes to examine the connection between
neurons and the decision layer. We alleviate convoluted explanations of the
conventional visualization approach by employing class information, thereby
isolating mixed properties. This process offers more human-interpretable
explanations for model errors without altering the trained network or requiring
additional data. Furthermore, our framework mitigates false correlations
learned from a dataset under a stochastic perspective, modifying decisions for
the neurons considered as the main causes. We validate the effectiveness of our
framework by addressing false correlations and improving inferences for classes
with the worst performance in real-world settings. Moreover, we demonstrate
that NeuroInspect helps debug the mistakes of DL models through evaluation for
human understanding. The code is openly available at
https://github.com/yeongjoonJu/NeuroInspect.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07186" title="Abstract">arXiv:2310.07186</a> [<a href="/pdf/2310.07186" title="Download PDF">pdf</a>, <a href="/format/2310.07186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiview Transformer: Rethinking Spatial Information in Hyperspectral  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongshan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yicong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identifying the land cover category for each pixel in a hyperspectral image
(HSI) relies on spectral and spatial information. An HSI cuboid with a specific
patch size is utilized to extract spatial-spectral feature representation for
the central pixel. In this article, we investigate that scene-specific but not
essential correlations may be recorded in an HSI cuboid. This additional
information improves the model performance on existing HSI datasets and makes
it hard to properly evaluate the ability of a model. We refer to this problem
as the spatial overfitting issue and utilize strict experimental settings to
avoid it. We further propose a multiview transformer for HSI classification,
which consists of multiview principal component analysis (MPCA), spectral
encoder-decoder (SED), and spatial-pooling tokenization transformer (SPTT).
MPCA performs dimension reduction on an HSI via constructing spectral multiview
observations and applying PCA on each view data to extract low-dimensional view
representation. The combination of view representations, named multiview
representation, is the dimension reduction output of the MPCA. To aggregate the
multiview information, a fully-convolutional SED with a U-shape in spectral
dimension is introduced to extract a multiview feature map. SPTT transforms the
multiview features into tokens using the spatial-pooling tokenization strategy
and learns robust and discriminative spatial-spectral features for land cover
identification. Classification is conducted with a linear classifier.
Experiments on three HSI datasets with rigid settings demonstrate the
superiority of the proposed multiview transformer over the state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07188" title="Abstract">arXiv:2310.07188</a> [<a href="/pdf/2310.07188" title="Download PDF">pdf</a>, <a href="/format/2310.07188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Gating in Mixture-of-Experts based Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiamin Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qiang Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yitao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yimin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models, such as OpenAI's ChatGPT, have demonstrated
exceptional language understanding capabilities in various NLP tasks. Sparsely
activated mixture-of-experts (MoE) has emerged as a promising solution for
scaling models while maintaining a constant number of computational operations.
Existing MoE model adopts a fixed gating network where each token is computed
by the same number of experts. However, this approach contradicts our intuition
that the tokens in each sequence vary in terms of their linguistic complexity
and, consequently, require different computational costs. Little is discussed
in prior research on the trade-off between computation per token and model
performance. This paper introduces adaptive gating in MoE, a flexible training
strategy that allows tokens to be processed by a variable number of experts
based on expert probability distribution. The proposed framework preserves
sparsity while improving training efficiency. Additionally, curriculum learning
is leveraged to further reduce training time. Extensive experiments on diverse
NLP tasks show that adaptive gating reduces at most 22.5% training time while
maintaining inference quality. Moreover, we conduct a comprehensive analysis of
the routing decisions and present our insights when adaptive gating is used.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07189" title="Abstract">arXiv:2310.07189</a> [<a href="/pdf/2310.07189" title="Download PDF">pdf</a>, <a href="/format/2310.07189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpikePoint: An Efficient Point-based Spiking Neural Network for Event  Cameras Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yulong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haotian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaopeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bojun Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras are bio-inspired sensors that respond to local changes in light
intensity and feature low latency, high energy efficiency, and high dynamic
range. Meanwhile, Spiking Neural Networks (SNNs) have gained significant
attention due to their remarkable efficiency and fault tolerance. By
synergistically harnessing the energy efficiency inherent in event cameras and
the spike-based processing capabilities of SNNs, their integration could enable
ultra-low-power application scenarios, such as action recognition tasks.
However, existing approaches often entail converting asynchronous events into
conventional frames, leading to additional data mapping efforts and a loss of
sparsity, contradicting the design concept of SNNs and event cameras. To
address this challenge, we propose SpikePoint, a novel end-to-end point-based
SNN architecture. SpikePoint excels at processing sparse event cloud data,
effectively extracting both global and local features through a singular-stage
structure. Leveraging the surrogate training method, SpikePoint achieves high
accuracy with few parameters and maintains low power consumption, specifically
employing the identity mapping feature extractor on diverse datasets.
SpikePoint achieves state-of-the-art (SOTA) performance on four event-based
action recognition datasets using only 16 timesteps, surpassing other SNN
methods. Moreover, it also achieves SOTA performance across all methods on
three datasets, utilizing approximately 0.3\% of the parameters and 0.5\% of
power consumption employed by artificial neural networks (ANNs). These results
emphasize the significance of Point Cloud and pave the way for many
ultra-low-power event-based data processing applications.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07191" title="Abstract">arXiv:2310.07191</a> [<a href="/pdf/2310.07191" title="Download PDF">pdf</a>, <a href="/format/2310.07191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $p&#x3ba;$-Curves: Interpolatory curves with curvature approximating a  parabola
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Juan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tuan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhonggui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+J">Yongjie Jessica Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper introduces a novel class of fair and interpolatory curves called
$p\kappa$-curves. These curves are comprised of smoothly stitched B\'ezier
curve segments, where the curvature distribution of each segment is made to
closely resemble a parabola, resulting in an aesthetically pleasing shape.
Moreover, each segment passes through an interpolated point at a parameter
where the parabola has an extremum, encouraging the alignment of interpolated
points with curvature extrema. To achieve these properties, we tailor an energy
function that guides the optimization process to obtain the desired curve
characteristics. Additionally, we develop an efficient algorithm and an
initialization method, enabling interactive modeling of the $p\kappa$-curves
without the need for global optimization. We provide various examples and
comparisons with existing state-of-the-art methods to demonstrate the curve
modeling capabilities and visually pleasing appearance of $p\kappa$-curves.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07194" title="Abstract">arXiv:2310.07194</a> [<a href="/pdf/2310.07194" title="Download PDF">pdf</a>, <a href="/format/2310.07194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Learning for LDPC Codes to Improve the Error-Floor Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwak%2C+H">Hee-Youl Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+D">Dae-Young Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongjune Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Hyo Kim</a>, 
<a href="/search/cs?searchtype=author&query=No%2C+J">Jong-Seon No</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Low-density parity-check (LDPC) codes have been successfully commercialized
in communication systems due to their strong error correction ability and
simple decoding process. However, the error-floor phenomenon of LDPC codes, in
which the error rate stops decreasing rapidly at a certain level, poses
challenges in achieving extremely low error rates and the application of LDPC
codes in scenarios demanding ultra high reliability. In this work, we propose
training methods to optimize neural min-sum (NMS) decoders that are robust to
the error-floor. Firstly, by leveraging the boosting learning technique of
ensemble networks, we divide the decoding network into two networks and train
the post network to be specialized for uncorrected codewords that failed in the
first network. Secondly, to address the vanishing gradient issue in training,
we introduce a block-wise training schedule that locally trains a block of
weights while retraining the preceding block. Lastly, we show that assigning
different weights to unsatisfied check nodes effectively lowers the error-floor
with a minimal number of weights. By applying these training methods to
standard LDPC codes, we achieve the best error-floor performance compared to
other decoding methods. The proposed NMS decoder, optimized solely through
novel training methods without additional modules, can be implemented into
current LDPC decoders without incurring extra hardware costs. The source code
is available at https://github.com/ghy1228/LDPC_Error_Floor.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07200" title="Abstract">arXiv:2310.07200</a> [<a href="/pdf/2310.07200" title="Download PDF">pdf</a>, <a href="/format/2310.07200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input-Output Relation and Low-Complexity Receiver Design for CP-OTFS  Systems with Doppler Squint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuehan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jian Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted by the 2023 IEEE Global Communication Conference workshops (GC WKshps)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In orthogonal time frequency space (OTFS) systems, the impact of
frequency-dependent Doppler which is referred to as the Doppler squint effect
(DSE) is accumulated through longer duration, whose negligence has prevented
OTFS systems from exploiting the performance superiority. In this paper,
practical OFDM system using cyclic prefix time guard interval (CP-OFDM)-based
OTFS systems with DSE are adopted. Cyclic prefix (CP) length is analyzed while
the input-output relation considering DSE is derived. By deploying two prefix
OFDM symbols, the channel estimation can be easily divided into three parts as
delay detection, Doppler extraction and gain estimation. The linear
equalization scheme is adopted taking the block diagonal property of the
channel matrix into account, which completes the low-complexity receiver
design. Simulation results confirm the significance of DSE and the considerable
performance of the proposed low-complexity receiver scheme considering DSE.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07202" title="Abstract">arXiv:2310.07202</a> [<a href="/pdf/2310.07202" title="Download PDF">pdf</a>, <a href="/format/2310.07202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Algorithmic Framework for Dynamic Compressive Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We propose a unified dynamic tracking algorithmic framework (PLAY-CS) to
reconstruct signal sequences with their intrinsic structured dynamic sparsity.
By capitalizing on specific statistical assumptions concerning the dynamic
filter of the signal sequences, the proposed framework exhibits versatility by
encompassing various existing dynamic compressive sensing (DCS) algorithms.
This is achieved through the incorporation of a newly proposed
Partial-Laplacian filtering sparsity model, tailored to capture a more
sophisticated dynamic sparsity. In practical scenarios such as dynamic channel
tracking in wireless communications, the framework demonstrates enhanced
performance compared to existing DCS algorithms.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07204" title="Abstract">arXiv:2310.07204</a> [<a href="/pdf/2310.07204" title="Download PDF">pdf</a>, <a href="/format/2310.07204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State of the Art on Diffusion Models for Visual Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Po%2C+R">Ryan Po</a>, 
<a href="/search/cs?searchtype=author&query=Yifan%2C+W">Wang Yifan</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+J+T">Jonathan T. Barron</a>, 
<a href="/search/cs?searchtype=author&query=Bermano%2C+A+H">Amit H. Bermano</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+E+R">Eric Ryan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Dekel%2C+T">Tali Dekel</a>, 
<a href="/search/cs?searchtype=author&query=Holynski%2C+A">Aleksander Holynski</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mildenhall%2C+B">Ben Mildenhall</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Ommer%2C+B">Bj&#xf6;rn Ommer</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The field of visual computing is rapidly advancing due to the emergence of
generative artificial intelligence (AI), which unlocks unprecedented
capabilities for the generation, editing, and reconstruction of images, videos,
and 3D scenes. In these domains, diffusion models are the generative AI
architecture of choice. Within the last year alone, the literature on
diffusion-based tools and applications has seen exponential growth and relevant
papers are published across the computer graphics, computer vision, and AI
communities with new works appearing daily on arXiv. This rapid growth of the
field makes it difficult to keep up with all recent developments. The goal of
this state-of-the-art report (STAR) is to introduce the basic mathematical
concepts of diffusion models, implementation details and design choices of the
popular Stable Diffusion model, as well as overview important aspects of these
generative AI tools, including personalization, conditioning, inversion, among
others. Moreover, we give a comprehensive overview of the rapidly growing
literature on diffusion-based generation and editing, categorized by the type
of generated medium, including 2D images, videos, 3D objects, locomotion, and
4D scenes. Finally, we discuss available datasets, metrics, open challenges,
and social implications. This STAR provides an intuitive starting point to
explore this exciting topic for researchers, artists, and practitioners alike.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07206" title="Abstract">arXiv:2310.07206</a> [<a href="/pdf/2310.07206" title="Download PDF">pdf</a>, <a href="/format/2310.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSimHO: Stable Pose Estimation for Hand-Object Interaction via  Physics Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the task of 3D pose estimation for a hand interacting
with an object from a single image observation. When modeling hand-object
interaction, previous works mainly exploit proximity cues, while overlooking
the dynamical nature that the hand must stably grasp the object to counteract
gravity and thus preventing the object from slipping or falling. These works
fail to leverage dynamical constraints in the estimation and consequently often
produce unstable results. Meanwhile, refining unstable configurations with
physics-based reasoning remains challenging, both by the complexity of contact
dynamics and by the lack of effective and efficient physics inference in the
data-driven learning framework. To address both issues, we present DeepSimHO: a
novel deep-learning pipeline that combines forward physics simulation and
backward gradient approximation with a neural network. Specifically, for an
initial hand-object pose estimated by a base network, we forward it to a
physics simulator to evaluate its stability. However, due to non-smooth contact
geometry and penetration, existing differentiable simulators can not provide
reliable state gradient. To remedy this, we further introduce a deep network to
learn the stability evaluation process from the simulator, while smoothly
approximating its gradient and thus enabling effective back-propagation.
Extensive experiments show that our method noticeably improves the stability of
the estimation and achieves superior efficiency over test-time optimization.
The code is available at https://github.com/rongakowang/DeepSimHO.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07207" title="Abstract">arXiv:2310.07207</a> [<a href="/pdf/2310.07207" title="Download PDF">pdf</a>, <a href="/format/2310.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Safe Reinforcement Learning under Adversarial Disturbances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chuxiong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jia Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Safety is a primary concern when applying reinforcement learning to
real-world control tasks, especially in the presence of external disturbances.
However, existing safe reinforcement learning algorithms rarely account for
external disturbances, limiting their applicability and robustness in practice.
To address this challenge, this paper proposes a robust safe reinforcement
learning framework that tackles worst-case disturbances. First, this paper
presents a policy iteration scheme to solve for the robust invariant set, i.e.,
a subset of the safe set, where persistent safety is only possible for states
within. The key idea is to establish a two-player zero-sum game by leveraging
the safety value function in Hamilton-Jacobi reachability analysis, in which
the protagonist (i.e., control inputs) aims to maintain safety and the
adversary (i.e., external disturbances) tries to break down safety. This paper
proves that the proposed policy iteration algorithm converges monotonically to
the maximal robust invariant set. Second, this paper integrates the proposed
policy iteration scheme into a constrained reinforcement learning algorithm
that simultaneously synthesizes the robust invariant set and uses it for
constrained policy optimization. This algorithm tackles both optimality and
safety, i.e., learning a policy that attains high rewards while maintaining
safety under worst-case disturbances. Experiments on classic control tasks show
that the proposed method achieves zero constraint violation with learned
worst-case adversarial disturbances, while other baseline algorithms violate
the safety constraints substantially. Our proposed method also attains
comparable performance as the baselines even in the absence of the adversary.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07208" title="Abstract">arXiv:2310.07208</a> [<a href="/pdf/2310.07208" title="Download PDF">pdf</a>, <a href="/ps/2310.07208" title="Download PostScript">ps</a>, <a href="/format/2310.07208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault-tolerant $k$-Supplier with Outliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+D">Deeparnab Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Cote%2C+L">Luc Cote</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Ankita Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract edited to meet arXiv requirements. 17+3 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present approximation algorithms for the Fault-tolerant $k$-Supplier with
Outliers ($\mathsf{F}k\mathsf{SO}$) problem. This is a common generalization of
two known problems -- $k$-Supplier with Outliers, and Fault-tolerant
$k$-Supplier -- each of which generalize the well-known $k$-Supplier problem.
In the $k$-Supplier problem the goal is to serve $n$ clients $C$, by opening
$k$ facilities from a set of possible facilities $F$; the objective function is
the farthest that any client must travel to access an open facility. In
$\mathsf{F}k\mathsf{SO}$, each client $v$ has a fault-tolerance $\ell_v$, and
now desires $\ell_v$ facilities to serve it; so each client $v$'s contribution
to the objective function is now its distance to the $\ell_v^{\text{th}}$
closest open facility. Furthermore, we are allowed to choose $m$ clients that
we will serve, and only those clients contribute to the objective function,
while the remaining $n-m$ are considered outliers.
<br />Our main result is a $\min\{4t-1,2^t+1\}$-approximation for the
$\mathsf{F}k\mathsf{SO}$ problem, where $t$ is the number of distinct values of
$\ell_v$ that appear in the instance. At $t=1$, i.e. in the case where the
$\ell_v$'s are uniformly some $\ell$, this yields a $3$-approximation,
improving upon the $11$-approximation given for the uniform case by Inamdar and
Varadarajan [2020], who also introduced the problem. Our result for the uniform
case matches tight $3$-approximations that exist for $k$-Supplier, $k$-Supplier
with Outliers, and Fault-tolerant $k$-Supplier. Our key technical contribution
is an application of the round-or-cut schema to $\mathsf{F}k\mathsf{SO}$.
Guided by an LP relaxation, we reduce to a simpler optimization problem, which
we can solve to obtain distance bounds for the "round" step, and valid
inequalities for the "cut" step.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07209" title="Abstract">arXiv:2310.07209</a> [<a href="/pdf/2310.07209" title="Download PDF">pdf</a>, <a href="/format/2310.07209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Explainable Skin Lesion Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khurshid%2C+M">Mahapara Khurshid</a>, 
<a href="/search/cs?searchtype=author&query=Vatsa%2C+M">Mayank Vatsa</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Richa Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Skin cancer is one of the deadliest diseases and has a high mortality rate if
left untreated. The diagnosis generally starts with visual screening and is
followed by a biopsy or histopathological examination. Early detection can aid
in lowering mortality rates. Visual screening can be limited by the experience
of the doctor. Due to the long tail distribution of dermatological datasets and
significant intra-variability between classes, automatic classification
utilizing computer-aided methods becomes challenging. In this work, we propose
a multitask few-shot-based approach for skin lesions that generalizes well with
few labelled data to address the small sample space challenge. The proposed
approach comprises a fusion of a segmentation network that acts as an attention
module and classification network. The output of the segmentation network helps
to focus on the most discriminatory features while making a decision by the
classification network. To further enhance the classification performance, we
have combined segmentation and classification loss in a weighted manner. We
have also included the visualization results that explain the decisions made by
the algorithm. Three dermatological datasets are used to evaluate the proposed
method thoroughly. We also conducted cross-database experiments to ensure that
the proposed approach is generalizable across similar datasets. Experimental
results demonstrate the efficacy of the proposed work.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07211" title="Abstract">arXiv:2310.07211</a> [<a href="/pdf/2310.07211" title="Download PDF">pdf</a>, <a href="/format/2310.07211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap between Newton-Raphson Method and Regularized Policy  Iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chuxiong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+G">Guojian Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Regularization is one of the most important techniques in reinforcement
learning algorithms. The well-known soft actor-critic algorithm is a special
case of regularized policy iteration where the regularizer is chosen as Shannon
entropy. Despite some empirical success of regularized policy iteration, its
theoretical underpinnings remain unclear. This paper proves that regularized
policy iteration is strictly equivalent to the standard Newton-Raphson method
in the condition of smoothing out Bellman equation with strongly convex
functions. This equivalence lays the foundation of a unified analysis for both
global and local convergence behaviors of regularized policy iteration. We
prove that regularized policy iteration has global linear convergence with the
rate being $\gamma$ (discount factor). Furthermore, this algorithm converges
quadratically once it enters a local region around the optimal value. We also
show that a modified version of regularized policy iteration, i.e., with
finite-step policy evaluation, is equivalent to inexact Newton method where the
Newton iteration formula is solved with truncated iterations. We prove that the
associated algorithm achieves an asymptotic linear convergence rate of
$\gamma^M$ in which $M$ denotes the number of steps carried out in policy
evaluation. Our results take a solid step towards a better understanding of the
convergence properties of regularized policy iteration algorithms.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07212" title="Abstract">arXiv:2310.07212</a> [<a href="/pdf/2310.07212" title="Download PDF">pdf</a>, <a href="/format/2310.07212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Learning-Enabled Automatic Vessel Draft Reading for  Intelligent Maritime Surveillance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Jingxiang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R+W">Ryan Wen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S+S">Sendren Sheng-Dong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fenghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yisheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,11 figures, submitted to IEEE T-ITS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The accurate and efficient vessel draft reading (VDR) is an important
component of intelligent maritime surveillance, which could be exploited to
assist in judging whether the vessel is normally loaded or overloaded. The
computer vision technique with an excellent price-to-performance ratio has
become a popular medium to estimate vessel draft depth. However, the
traditional estimation methods easily suffer from several limitations, such as
sensitivity to low-quality images, high computational cost, etc. In this work,
we propose a multi-task learning-enabled computational method (termed MTL-VDR)
for generating highly reliable VDR. In particular, our MTL-VDR mainly consists
of four components, i.e., draft mark detection, draft scale recognition,
vessel/water segmentation, and final draft depth estimation. We first construct
a benchmark dataset related to draft mark detection and employ a powerful and
efficient convolutional neural network to accurately perform the detection
task. The multi-task learning method is then proposed for simultaneous draft
scale recognition and vessel/water segmentation. To obtain more robust VDR
under complex conditions (e.g., damaged and stained scales, etc.), the accurate
draft scales are generated by an automatic correction method, which is
presented based on the spatial distribution rules of draft scales. Finally, an
adaptive computational method is exploited to yield an accurate and robust
draft depth. Extensive experiments have been implemented on the realistic
dataset to compare our MTL-VDR with state-of-the-art methods. The results have
demonstrated its superior performance in terms of accuracy, robustness, and
efficiency. The computational speed exceeds 40 FPS, which satisfies the
requirements of real-time maritime surveillance to guarantee vessel traffic
safety.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07216" title="Abstract">arXiv:2310.07216</a> [<a href="/pdf/2310.07216" title="Download PDF">pdf</a>, <a href="/format/2310.07216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Modeling on Manifolds Through Mixture of Riemannian Diffusion  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jo%2C+J">Jaehyeong Jo</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Learning the distribution of data on Riemannian manifolds is crucial for
modeling data from non-Euclidean space, which is required by many applications
from diverse scientific fields. Yet, existing generative models on manifolds
suffer from expensive divergence computation or rely on approximations of heat
kernel. These limitations restrict their applicability to simple geometries and
hinder scalability to high dimensions. In this work, we introduce the
Riemannian Diffusion Mixture, a principled framework for building a generative
process on manifolds as a mixture of endpoint-conditioned diffusion processes
instead of relying on the denoising approach of previous diffusion models, for
which the generative process is characterized by its drift guiding toward the
most probable endpoint with respect to the geometry of the manifold. We further
propose a simple yet efficient training objective for learning the mixture
process, that is readily applicable to general manifolds. Our method
outperforms previous generative models on various manifolds while scaling to
high dimensions and requires a dramatically reduced number of in-training
simulation steps for general manifolds.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07217" title="Abstract">arXiv:2310.07217</a> [<a href="/pdf/2310.07217" title="Download PDF">pdf</a>, <a href="/format/2310.07217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Neural Architecture Search with Multiple Hardware Constraints  for Deep Learning Model Deployment on Tiny IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burrello%2C+A">Alessio Burrello</a>, 
<a href="/search/cs?searchtype=author&query=Risso%2C+M">Matteo Risso</a>, 
<a href="/search/cs?searchtype=author&query=Motetti%2C+B+A">Beatrice Alessandra Motetti</a>, 
<a href="/search/cs?searchtype=author&query=Macii%2C+E">Enrico Macii</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Pagliari%2C+D+J">Daniele Jahier Pagliari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the IEEE Transactions on Emerging Topics in Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The rapid proliferation of computing domains relying on Internet of Things
(IoT) devices has created a pressing need for efficient and accurate
deep-learning (DL) models that can run on low-power devices. However,
traditional DL models tend to be too complex and computationally intensive for
typical IoT end-nodes. To address this challenge, Neural Architecture Search
(NAS) has emerged as a popular design automation technique for co-optimizing
the accuracy and complexity of deep neural networks. Nevertheless, existing NAS
techniques require many iterations to produce a network that adheres to
specific hardware constraints, such as the maximum memory available on the
hardware or the maximum latency allowed by the target application. In this
work, we propose a novel approach to incorporate multiple constraints into
so-called Differentiable NAS optimization methods, which allows the generation,
in a single shot, of a model that respects user-defined constraints on both
memory and latency in a time comparable to a single standard training. The
proposed approach is evaluated on five IoT-relevant benchmarks, including the
MLPerf Tiny suite and Tiny ImageNet, demonstrating that, with a single search,
it is possible to reduce memory and latency by 87.4% and 54.2%, respectively
(as defined by our targets), while ensuring non-inferior accuracy on
state-of-the-art hand-tuned deep neural networks for TinyML.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07218" title="Abstract">arXiv:2310.07218</a> [<a href="/pdf/2310.07218" title="Download PDF">pdf</a>, <a href="/format/2310.07218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Agent Interaction in Multi-agent Reinforcement Learning for  Cost-efficient Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Ran Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenran Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinning Li</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generalization poses a significant challenge in Multi-agent Reinforcement
Learning (MARL). The extent to which an agent is influenced by unseen
co-players depends on the agent's policy and the specific scenario. A
quantitative examination of this relationship sheds light on effectively
training agents for diverse scenarios. In this study, we present the Level of
Influence (LoI), a metric quantifying the interaction intensity among agents
within a given scenario and environment. We observe that, generally, a more
diverse set of co-play agents during training enhances the generalization
performance of the ego agent; however, this improvement varies across distinct
scenarios and environments. LoI proves effective in predicting these
improvement disparities within specific scenarios. Furthermore, we introduce a
LoI-guided resource allocation method tailored to train a set of policies for
diverse scenarios under a constrained budget. Our results demonstrate that
strategic resource allocation based on LoI can achieve higher performance than
uniform allocation under the same computation budget.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07219" title="Abstract">arXiv:2310.07219</a> [<a href="/pdf/2310.07219" title="Download PDF">pdf</a>, <a href="/format/2310.07219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Membership Inference Attacks Against Language Classification  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shachor%2C+S">Shlomit Shachor</a>, 
<a href="/search/cs?searchtype=author&query=Razinkov%2C+N">Natalia Razinkov</a>, 
<a href="/search/cs?searchtype=author&query=Goldsteen%2C+A">Abigail Goldsteen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Artificial intelligence systems are prevalent in everyday life, with use
cases in retail, manufacturing, health, and many other fields. With the rise in
AI adoption, associated risks have been identified, including privacy risks to
the people whose data was used to train models. Assessing the privacy risks of
machine learning models is crucial to enabling knowledgeable decisions on
whether to use, deploy, or share a model. A common approach to privacy risk
assessment is to run one or more known attacks against the model and measure
their success rate. We present a novel framework for running membership
inference attacks against classification models. Our framework takes advantage
of the ensemble method, generating many specialized attack models for different
subsets of the data. We show that this approach achieves higher accuracy than
either a single attack model or an attack model per class label, both on
classical and language classification tasks.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07220" title="Abstract">arXiv:2310.07220</a> [<a href="/pdf/2310.07220" title="Download PDF">pdf</a>, <a href="/format/2310.07220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COPlanner: Plan to Roll Out Conservatively but to Explore Optimistically  for Model-Based RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ruijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanchao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruonan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wongkamjan%2C+W">Wichayaporn Wongkamjan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Dyna-style model-based reinforcement learning contains two phases: model
rollouts to generate sample for policy learning and real environment
exploration using current policy for dynamics model learning. However, due to
the complex real-world environment, it is inevitable to learn an imperfect
dynamics model with model prediction error, which can further mislead policy
learning and result in sub-optimal solutions. In this paper, we propose
$\texttt{COPlanner}$, a planning-driven framework for model-based methods to
address the inaccurately learned dynamics model problem with conservative model
rollouts and optimistic environment exploration. $\texttt{COPlanner}$ leverages
an uncertainty-aware policy-guided model predictive control (UP-MPC) component
to plan for multi-step uncertainty estimation. This estimated uncertainty then
serves as a penalty during model rollouts and as a bonus during real
environment exploration respectively, to choose actions. Consequently,
$\texttt{COPlanner}$ can avoid model uncertain regions through conservative
model rollouts, thereby alleviating the influence of model error.
Simultaneously, it explores high-reward model uncertain regions to reduce model
error actively through optimistic real environment exploration.
$\texttt{COPlanner}$ is a plug-and-play framework that can be applied to any
dyna-style model-based methods. Experimental results on a series of
proprioceptive and visual continuous control tasks demonstrate that both sample
efficiency and asymptotic performance of strong model-based methods are
significantly improved combined with $\texttt{COPlanner}$.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07221" title="Abstract">arXiv:2310.07221</a> [<a href="/pdf/2310.07221" title="Download PDF">pdf</a>, <a href="/format/2310.07221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Learnable Physics for Real-Time Exercise Form Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+A">Abhishek Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+G">Gautam Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+N">Nisheeth Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM RecSys '23, 12 pages , 7 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Seventeenth ACM Conference on Recommender Systems (RecSys 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Good posture and form are essential for safe and productive exercising. Even
in gym settings, trainers may not be readily available for feedback.
Rehabilitation therapies and fitness workouts can thus benefit from recommender
systems that provide real-time evaluation. In this paper, we present an
algorithmic pipeline that can diagnose problems in exercise techniques and
offer corrective recommendations, with high sensitivity and specificity in
real-time. We use MediaPipe for pose recognition, count repetitions using
peak-prominence detection, and use a learnable physics simulator to track
motion evolution for each exercise. A test video is diagnosed based on
deviations from the prototypical learned motion using statistical learning. The
system is evaluated on six full and upper body exercises. These real-time
recommendations, counseled via low-cost equipment like smartphones, will allow
exercisers to rectify potential mistakes making self-practice feasible while
reducing the risk of workout injuries.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07222" title="Abstract">arXiv:2310.07222</a> [<a href="/pdf/2310.07222" title="Download PDF">pdf</a>, <a href="/format/2310.07222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uni-paint: A Unified Framework for Multimodal Image Inpainting with  Pretrained Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaodong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACMMM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, text-to-image denoising diffusion probabilistic models (DDPMs) have
demonstrated impressive image generation capabilities and have also been
successfully applied to image inpainting. However, in practice, users often
require more control over the inpainting process beyond textual guidance,
especially when they want to composite objects with customized appearance,
color, shape, and layout. Unfortunately, existing diffusion-based inpainting
methods are limited to single-modal guidance and require task-specific
training, hindering their cross-modal scalability. To address these
limitations, we propose Uni-paint, a unified framework for multimodal
inpainting that offers various modes of guidance, including unconditional,
text-driven, stroke-driven, exemplar-driven inpainting, as well as a
combination of these modes. Furthermore, our Uni-paint is based on pretrained
Stable Diffusion and does not require task-specific training on specific
datasets, enabling few-shot generalizability to customized images. We have
conducted extensive qualitative and quantitative evaluations that show our
approach achieves comparable results to existing single-modal methods while
offering multimodal inpainting capabilities not available in other methods.
Code will be available at https://github.com/ysy31415/unipaint.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07223" title="Abstract">arXiv:2310.07223</a> [<a href="/pdf/2310.07223" title="Download PDF">pdf</a>, <a href="/format/2310.07223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for blind spectral unmixing of LULC classes with MODIS  multispectral time series and ancillary data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Ortega%2C+J">Jos&#xe9; Rodr&#xed;guez-Ortega</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Khaldi%2C+R">Rohaifa Khaldi</a> (2), 
<a href="/search/cs?searchtype=author&query=Alcaraz-Segura%2C+D">Domingo Alcaraz-Segura</a> (3), 
<a href="/search/cs?searchtype=author&query=Tabik%2C+S">Siham Tabik</a> (1) ((1) Department of Computer Science and Artificial Intelligence, DaSCI, University of Granada, Granada, Spain, (2) LifeWatch-ERIC ICT Core, Seville, Spain, (3) Department of Botany, Faculty of Science, University of Granada, Granada, Spain)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC)
types. Spectral unmixing is a technique to extract information from mixed
pixels into their constituent LULC types and corresponding abundance fractions.
Traditionally, solving this task has relied on either classical methods that
require prior knowledge of endmembers or machine learning methods that avoid
explicit endmembers calculation, also known as blind spectral unmixing (BSU).
Most BSU studies based on Deep Learning (DL) focus on one time-step
hyperspectral data, yet its acquisition remains quite costly compared with
multispectral data. To our knowledge, here we provide the first study on BSU of
LULC classes using multispectral time series data with DL models. We further
boost the performance of a Long-Short Term Memory (LSTM)-based model by
incorporating geographic plus topographic (geo-topographic) and climatic
ancillary information. Our experiments show that combining spectral-temporal
input data together with geo-topographic and climatic information substantially
improves the abundance estimation of LULC classes in mixed pixels. To carry out
this study, we built a new labeled dataset of the region of Andalusia (Spain)
with monthly multispectral time series of pixels for the year 2013 from MODIS
at 460m resolution, for two hierarchical levels of LULC classes, named
Andalusia MultiSpectral MultiTemporal Unmixing (Andalusia-MSMTU). This dataset
provides, at the pixel level, a multispectral time series plus ancillary
information annotated with the abundance of each LULC class inside each pixel.
The dataset and code are available to the public.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07225" title="Abstract">arXiv:2310.07225</a> [<a href="/pdf/2310.07225" title="Download PDF">pdf</a>, <a href="/ps/2310.07225" title="Download PostScript">ps</a>, <a href="/format/2310.07225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Landscape of Large Language Models In Medical Question  Answering: Observations and Open Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korgul%2C+K">Karolina Korgul</a>, 
<a href="/search/cs?searchtype=author&query=Bean%2C+A+M">Andrew M. Bean</a>, 
<a href="/search/cs?searchtype=author&query=Krones%2C+F">Felix Krones</a>, 
<a href="/search/cs?searchtype=author&query=McCraith%2C+R">Robert McCraith</a>, 
<a href="/search/cs?searchtype=author&query=Mahdi%2C+A">Adam Mahdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have shown promise in medical question answering
by achieving passing scores in standardised exams and have been suggested as
tools for supporting healthcare workers. Deploying LLMs into such a high-risk
context requires a clear understanding of the limitations of these models. With
the rapid development and release of new LLMs, it is especially valuable to
identify patterns which exist across models and may, therefore, continue to
appear in newer versions. In this paper, we evaluate a wide range of popular
LLMs on their knowledge of medical questions in order to better understand
their properties as a group. From this comparison, we provide preliminary
observations and raise open questions for further research.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07229" title="Abstract">arXiv:2310.07229</a> [<a href="/pdf/2310.07229" title="Download PDF">pdf</a>, <a href="/format/2310.07229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Pocket Pretraining via Protein Fragment-Surroundings  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bowen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yinjun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yuanle Mo</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuyan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weiying Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Pocket representations play a vital role in various biomedical applications,
such as druggability estimation, ligand affinity prediction, and de novo drug
design. While existing geometric features and pretrained representations have
demonstrated promising results, they usually treat pockets independent of
ligands, neglecting the fundamental interactions between them. However, the
limited pocket-ligand complex structures available in the PDB database (less
than 100 thousand non-redundant pairs) hampers large-scale pretraining
endeavors for interaction modeling. To address this constraint, we propose a
novel pocket pretraining approach that leverages knowledge from high-resolution
atomic protein structures, assisted by highly effective pretrained small
molecule representations. By segmenting protein structures into drug-like
fragments and their corresponding pockets, we obtain a reasonable simulation of
ligand-receptor interactions, resulting in the generation of over 5 million
complexes. Subsequently, the pocket encoder is trained in a contrastive manner
to align with the representation of pseudo-ligand furnished by some pretrained
small molecule encoders. Our method, named ProFSA, achieves state-of-the-art
performance across various tasks, including pocket druggability prediction,
pocket matching, and ligand binding affinity prediction. Notably, ProFSA
surpasses other pretraining methods by a substantial margin. Moreover, our work
opens up a new avenue for mitigating the scarcity of protein-ligand complex
data through the utilization of high-quality and diverse protein structure
databases.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07234" title="Abstract">arXiv:2310.07234</a> [<a href="/pdf/2310.07234" title="Download PDF">pdf</a>, <a href="/format/2310.07234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Decomposition of Prompt-Based Continual Learning:  Rethinking Obscured Sub-optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jingyi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 20 figures, 11 tables, accepted by NeurIPS as a Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Prompt-based continual learning is an emerging direction in leveraging
pre-trained knowledge for downstream continual learning, and has almost reached
the performance pinnacle under supervised pre-training. However, our empirical
research reveals that the current strategies fall short of their full potential
under the more realistic self-supervised pre-training, which is essential for
handling vast quantities of unlabeled data in practice. This is largely due to
the difficulty of task-specific knowledge being incorporated into instructed
representations via prompt parameters and predicted by uninstructed
representations at test time. To overcome the exposed sub-optimality, we
conduct a theoretical analysis of the continual learning objective in the
context of pre-training, and decompose it into hierarchical components:
within-task prediction, task-identity inference, and task-adaptive prediction.
Following these empirical and theoretical insights, we propose Hierarchical
Decomposition (HiDe-)Prompt, an innovative approach that explicitly optimizes
the hierarchical components with an ensemble of task-specific prompts and
statistics of both uninstructed and instructed representations, further with
the coordination of a contrastive regularization strategy. Our extensive
experiments demonstrate the superior performance of HiDe-Prompt and its
robustness to pre-training paradigms in continual learning (e.g., up to 15.01%
and 9.61% lead on Split CIFAR-100 and Split ImageNet-R, respectively). Our code
is available at \url{https://github.com/thu-ml/HiDe-Prompt}.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07235" title="Abstract">arXiv:2310.07235</a> [<a href="/pdf/2310.07235" title="Download PDF">pdf</a>, <a href="/format/2310.07235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are GATs Out of Balance?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+N">Nimrah Mustafa</a>, 
<a href="/search/cs?searchtype=author&query=Bojchevski%2C+A">Aleksandar Bojchevski</a>, 
<a href="/search/cs?searchtype=author&query=Burkholz%2C+R">Rebekka Burkholz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. To be published in Advances in Neural Information Processing Systems (NeurIPS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While the expressive power and computational capabilities of graph neural
networks (GNNs) have been theoretically studied, their optimization and
learning dynamics, in general, remain largely unexplored. Our study undertakes
the Graph Attention Network (GAT), a popular GNN architecture in which a node's
neighborhood aggregation is weighted by parameterized attention coefficients.
We derive a conservation law of GAT gradient flow dynamics, which explains why
a high portion of parameters in GATs with standard initialization struggle to
change during training. This effect is amplified in deeper GATs, which perform
significantly worse than their shallow counterparts. To alleviate this problem,
we devise an initialization scheme that balances the GAT network. Our approach
i) allows more effective propagation of gradients and in turn enables
trainability of deeper networks, and ii) attains a considerable speedup in
training and convergence time in comparison to the standard initialization. Our
main theorem serves as a stepping stone to studying the learning dynamics of
positive homogeneous models with attention mechanisms.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07236" title="Abstract">arXiv:2310.07236</a> [<a href="/pdf/2310.07236" title="Download PDF">pdf</a>, <a href="/format/2310.07236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaMesh: Personalized Facial Expressions and Head Poses for  Speech-Driven 3D Facial Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+W">Weihong Bao</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shun Lei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Boshi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Shiyin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haozhi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://adamesh.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Speech-driven 3D facial animation aims at generating facial movements that
are synchronized with the driving speech, which has been widely explored
recently. Existing works mostly neglect the person-specific talking style in
generation, including facial expression and head pose styles. Several works
intend to capture the personalities by fine-tuning modules. However, limited
training data leads to the lack of vividness. In this work, we propose AdaMesh,
a novel adaptive speech-driven facial animation approach, which learns the
personalized talking style from a reference video of about 10 seconds and
generates vivid facial expressions and head poses. Specifically, we propose
mixture-of-low-rank adaptation (MoLoRA) to fine-tune the expression adapter,
which efficiently captures the facial expression style. For the personalized
pose style, we propose a pose adapter by building a discrete pose prior and
retrieving the appropriate style embedding with a semantic-aware pose style
matrix without fine-tuning. Extensive experimental results show that our
approach outperforms state-of-the-art methods, preserves the talking style in
the reference video, and generates vivid facial animation. The supplementary
video and code will be available at https://adamesh.github.io.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07237" title="Abstract">arXiv:2310.07237</a> [<a href="/pdf/2310.07237" title="Download PDF">pdf</a>, <a href="/format/2310.07237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAGE-ICP: Semantic Information-Assisted ICP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6+1 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robust and accurate pose estimation in unknown environments is an essential
part of robotic applications. We focus on LiDAR-based point-to-point ICP
combined with effective semantic information. This paper proposes a novel
semantic information-assisted ICP method named SAGE-ICP, which leverages
semantics in odometry. The semantic information for the whole scan is timely
and efficiently extracted by a 3D convolution network, and these point-wise
labels are deeply involved in every part of the registration, including
semantic voxel downsampling, data association, adaptive local map, and dynamic
vehicle removal. Unlike previous semantic-aided approaches, the proposed method
can improve localization accuracy in large-scale scenes even if the semantic
information has certain errors. Experimental evaluations on KITTI and KITTI-360
show that our method outperforms the baseline methods, and improves accuracy
while maintaining real-time performance, i.e., runs faster than the sensor
frame rate.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07239" title="Abstract">arXiv:2310.07239</a> [<a href="/pdf/2310.07239" title="Download PDF">pdf</a>, <a href="/ps/2310.07239" title="Download PostScript">ps</a>, <a href="/format/2310.07239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multidimensional Hopfield Networks for clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stomfai%2C+G">Gergely Stomfai</a>, 
<a href="/search/cs?searchtype=author&query=Sienkiewicz%2C+%C5%81">&#x141;ukasz Sienkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Rychalska%2C+B">Barbara Rychalska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">We present the Multidimensional Hopfield Network (DHN), a natural
generalisation of the Hopfield Network. In our theoretical investigations we
focus on DHNs with a certain activation function and provide energy functions
for them. We conclude that these DHNs are convergent in finite time, and are
equivalent to greedy methods that aim to find graph clusterings of locally
minimal cuts. We also show that the general framework of DHNs encapsulates
several previously known algorithms used for generating graph embeddings and
clusterings. Namely, the Cleora graph embedding algorithm, the Louvain method,
and the Newmans method can be cast as DHNs with appropriate activation function
and update rule. Motivated by these findings we provide a generalisation of
Newmans method to the multidimensional case.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07240" title="Abstract">arXiv:2310.07240</a> [<a href="/pdf/2310.07240" title="Download PDF">pdf</a>, <a href="/format/2310.07240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CacheGen: Fast Context Loading for Language Model Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kuntai Du</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiayi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Maire%2C+M">Michael Maire</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+H">Henry Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Holtzman%2C+A">Ari Holtzman</a>, 
<a href="/search/cs?searchtype=author&query=Ananthanarayanan%2C+G">Ganesh Ananthanarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junchen Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As large language models (LLMs) take on more complex tasks, their inputs
incorporate longer contexts to respond to questions that require domain
knowledge or user-specific conversational histories. Yet, using long contexts
poses a challenge for responsive LLM systems, as nothing can be generated until
all the contexts are fetched to and processed by the LLM. Existing systems
optimize only the computation delay in context processing (e.g., by caching
intermediate key-value features of the text context) but often cause longer
network delays in context fetching (e.g., key-value features consume orders of
magnitude larger bandwidth than the text context).
<br />This paper presents CacheGen to minimize the delays in fetching and
processing contexts for LLMs. CacheGen reduces the bandwidth needed for
transmitting long contexts' key-value (KV) features through a novel encoder
that compresses KV features into more compact bitstream representations. The
encoder combines adaptive quantization with a tailored arithmetic coder, taking
advantage of the KV features' distributional properties, such as locality
across tokens. Furthermore, CacheGen minimizes the total delay in fetching and
processing a context by using a controller that determines when to load the
context as compressed KV features or raw text and picks the appropriate
compression level if loaded as KV features. We test CacheGen on three models of
various sizes and three datasets of different context lengths. Compared to
recent methods that handle long contexts, CacheGen reduces bandwidth usage by
3.7-4.3x and the total delay in fetching and processing contexts by 2.7-3x
while maintaining similar LLM performance on various tasks as loading the text
contexts.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07242" title="Abstract">arXiv:2310.07242</a> [<a href="/pdf/2310.07242" title="Download PDF">pdf</a>, <a href="/format/2310.07242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textiverse: A Scalable Visual Analytics System for Exploring Geotagged  and Timestamped Text Corpora
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berger%2C+C">Caroline Berger</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+H">Hanjun Xian</a>, 
<a href="/search/cs?searchtype=author&query=Madhavan%2C+K">Krishna Madhavan</a>, 
<a href="/search/cs?searchtype=author&query=Elmqvist%2C+N">Niklas Elmqvist</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We propose Textiverse, a big data approach for mining geotagged timestamped
textual data on a map, such as for Twitter feeds, crime reports, or restaurant
reviews. We use a scalable data management pipeline that extracts keyphrases
from online databases in parallel. We speed up this time-consuming step so that
it outpaces the content creation rate of popular social media. The result is
presented in a web-based interface that integrates with Google Maps to
visualize textual content of massive scale. The visual design is based on
aggregating spatial regions into discrete sites and rendering each such site as
a circular tag cloud. To demonstrate the intended use of our technique, we
first show how it can be used to characterize the U.S.\ National Science
Foundation funding status based on all 489,151 awards. We then apply the same
technique on visually representing a more spatially scattered and
linguistically informal dataset: 1.2 million Twitter posts about the Android
mobile operating system.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07243" title="Abstract">arXiv:2310.07243</a> [<a href="/pdf/2310.07243" title="Download PDF">pdf</a>, <a href="/format/2310.07243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-aware Joint Caching and Forwarding in Networks with Heterogeneous  Cache Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+F+V">Faruk Volkan Mutlu</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+E">Edmund Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Caching is crucial for enabling high-throughput networks for data intensive
applications. Traditional caching technology relies on DRAM, as it can transfer
data at a high rate. However, DRAM capacity is subject to contention by most
system components and thus is very limited, implying that DRAM-only caches
cannot scale to meet growing demand. Fortunately, persistent memory and flash
storage technologies are rapidly evolving and can be utilized alongside DRAM to
increase cache capacities. To do so without compromising network performance
requires caching techniques adapted to the characteristics of these
technologies. In this paper, we model the cache as a collection of storage
blocks with different rate parameters and utilization costs. We introduce an
optimization technique based on the drift-plus-penalty method and apply it in a
framework which enables joint caching and forwarding. We show that it achieves
an optimal trade-off between throughput and cache utilization costs in a
virtual control plane. We then develop a corresponding practical policy in the
data plane. Finally, through simulations in several settings, we demonstrate
the superior performance of our proposed approach with respect to total user
delay and cache utilization costs.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07244" title="Abstract">arXiv:2310.07244</a> [<a href="/pdf/2310.07244" title="Download PDF">pdf</a>, <a href="/format/2310.07244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Sampling via Appproximate Symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Sampling from multimodal distributions is a challenging task in scientific
computing. When a distribution has an exact symmetry between the modes, direct
jumps among them can accelerate the samplings significantly. However, the
distributions from most applications do not have exact symmetries. This paper
considers the distributions with approximate symmetries. We first construct an
exactly symmetric reference distribution from the target one by averaging over
the group orbit associated with the approximate symmetry. Next, we can apply
the multilevel Monte Carlo methods by constructing a continuation path between
the reference and target distributions. We discuss how to implement these steps
with annealed importance sampling and tempered transitions. Compared with
traditional multilevel methods, the proposed approach can be more effective
since the reference and target distributions are much closer. Numerical results
of the Ising models are presented to illustrate the efficiency of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07245" title="Abstract">arXiv:2310.07245</a> [<a href="/pdf/2310.07245" title="Download PDF">pdf</a>, <a href="/format/2310.07245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crowd Counting in Harsh Weather using Image Denoising with Pix2Pix GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Muhammad Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Menouar%2C+H">Hamid Menouar</a>, 
<a href="/search/cs?searchtype=author&query=Hamila%2C+R">Ridha Hamila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted for presentation in IEEE 38th International Conference on Image and Vision Computing New Zealand (IVCNZ 2023). The final manuscript can be accessed at ieeexplore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Visual crowd counting estimates the density of the crowd using deep learning
models such as convolution neural networks (CNNs). The performance of the model
heavily relies on the quality of the training data that constitutes crowd
images. In harsh weather such as fog, dust, and low light conditions, the
inference performance may severely degrade on the noisy and blur images. In
this paper, we propose the use of Pix2Pix generative adversarial network (GAN)
to first denoise the crowd images prior to passing them to the counting model.
A Pix2Pix network is trained using synthetic noisy images generated from
original crowd images and then the pretrained generator is then used in the
inference engine to estimate the crowd density in unseen, noisy crowd images.
The performance is tested on JHU-Crowd dataset to validate the significance of
the proposed method particularly when high reliability and accuracy are
required.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07246" title="Abstract">arXiv:2310.07246</a> [<a href="/pdf/2310.07246" title="Download PDF">pdf</a>, <a href="/format/2310.07246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vec-Tok Speech: speech vectorization and tokenization for neural speech  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yuanjun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wendi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongbin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Heng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Language models (LMs) have recently flourished in natural language processing
and computer vision, generating high-fidelity texts or images in various tasks.
In contrast, the current speech generative models are still struggling
regarding speech quality and task generalization. This paper presents Vec-Tok
Speech, an extensible framework that resembles multiple speech generation
tasks, generating expressive and high-fidelity speech. Specifically, we propose
a novel speech codec based on speech vectors and semantic tokens. Speech
vectors contain acoustic details contributing to high-fidelity speech
reconstruction, while semantic tokens focus on the linguistic content of
speech, facilitating language modeling. Based on the proposed speech codec,
Vec-Tok Speech leverages an LM to undertake the core of speech generation.
Moreover, Byte-Pair Encoding (BPE) is introduced to reduce the token length and
bit rate for lower exposure bias and longer context coverage, improving the
performance of LMs. Vec-Tok Speech can be used for intra- and cross-lingual
zero-shot voice conversion (VC), zero-shot speaking style transfer
text-to-speech (TTS), speech-to-speech translation (S2ST), speech denoising,
and speaker de-identification and anonymization. Experiments show that Vec-Tok
Speech, built on 50k hours of speech, performs better than other SOTA models.
Code will be available at https://github.com/BakerBunker/VecTok .
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07247" title="Abstract">arXiv:2310.07247</a> [<a href="/pdf/2310.07247" title="Download PDF">pdf</a>, <a href="/format/2310.07247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing the Placement of Roadside LiDARs for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wentao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+H">Hao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runsheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Multi-agent cooperative perception is an increasingly popular topic in the
field of autonomous driving, where roadside LiDARs play an essential role.
However, how to optimize the placement of roadside LiDARs is a crucial but
often overlooked problem. This paper proposes an approach to optimize the
placement of roadside LiDARs by selecting optimized positions within the scene
for better perception performance. To efficiently obtain the best combination
of locations, a greedy algorithm based on perceptual gain is proposed, which
selects the location that can maximize the perceptual gain sequentially. We
define perceptual gain as the increased perceptual capability when a new LiDAR
is placed. To obtain the perception capability, we propose a perception
predictor that learns to evaluate LiDAR placement using only a single point
cloud frame. A dataset named Roadside-Opt is created using the CARLA simulator
to facilitate research on the roadside LiDAR placement problem.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07248" title="Abstract">arXiv:2310.07248</a> [<a href="/pdf/2310.07248" title="Download PDF">pdf</a>, <a href="/format/2310.07248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IBoxCLA: Towards Robust Box-supervised Segmentation of Polyp via  Improved Box-dice and Contrastive Latent-anchors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hongkuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Li He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Man He</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenxuan Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Ting Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yitong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Box-supervised polyp segmentation attracts increasing attention for its
cost-effective potential. Existing solutions often rely on learning-free
methods or pretrained models to laboriously generate pseudo masks, triggering
Dice constraint subsequently. In this paper, we found that a model guided by
the simplest box-filled masks can accurately predict polyp locations/sizes, but
suffers from shape collapsing. In response, we propose two innovative learning
fashions, Improved Box-dice (IBox) and Contrastive Latent-Anchors (CLA), and
combine them to train a robust box-supervised model IBoxCLA. The core idea
behind IBoxCLA is to decouple the learning of location/size and shape, allowing
for focused constraints on each of them. Specifically, IBox transforms the
segmentation map into a proxy map using shape decoupling and confusion-region
swapping sequentially. Within the proxy map, shapes are disentangled, while
locations/sizes are encoded as box-like responses. By constraining the proxy
map instead of the raw prediction, the box-filled mask can well supervise
IBoxCLA without misleading its shape learning. Furthermore, CLA contributes to
shape learning by generating two types of latent anchors, which are learned and
updated using momentum and segmented polyps to steadily represent polyp and
background features. The latent anchors facilitate IBoxCLA to capture
discriminative features within and outside boxes in a contrastive manner,
yielding clearer boundaries. We benchmark IBoxCLA on five public polyp
datasets. The experimental results demonstrate the competitive performance of
IBoxCLA compared to recent fully-supervised polyp segmentation methods, and its
superiority over other box-supervised state-of-the-arts with a relative
increase of overall mDice and mIoU by at least 6.5% and 7.5%, respectively.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07251" title="Abstract">arXiv:2310.07251</a> [<a href="/pdf/2310.07251" title="Download PDF">pdf</a>, <a href="/format/2310.07251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethical Reasoning over Moral Alignment: A Case and Framework for  In-Context Ethical Policies in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Abhinav Rao</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Aditi Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Tanmay%2C+K">Kumar Tanmay</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+U">Utkarsh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+M">Monojit Choudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this position paper, we argue that instead of morally aligning LLMs to
specific set of ethical principles, we should infuse generic ethical reasoning
capabilities into them so that they can handle value pluralism at a global
scale. When provided with an ethical policy, an LLM should be capable of making
decisions that are ethically consistent to the policy. We develop a framework
that integrates moral dilemmas with moral principles pertaining to different
foramlisms of normative ethics, and at different levels of abstractions.
Initial experiments with GPT-x models shows that while GPT-4 is a nearly
perfect ethical reasoner, the models still have bias towards the moral values
of Western and English speaking societies.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07252" title="Abstract">arXiv:2310.07252</a> [<a href="/pdf/2310.07252" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of Pre-trained CNNs and GRU-Based Attention for  Image Caption Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+R">Rashid Khan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bingding Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+H">Haseeb Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+A">Asim Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhongfu Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15pages, 10 figures, 5 tables. 2023 the 5th International Conference on Robotics and Computer Vision (ICRCV 2023). arXiv admin note: substantial text overlap with <a href="/abs/2203.01594">arXiv:2203.01594</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Image captioning is a challenging task involving generating a textual
description for an image using computer vision and natural language processing
techniques. This paper proposes a deep neural framework for image caption
generation using a GRU-based attention mechanism. Our approach employs multiple
pre-trained convolutional neural networks as the encoder to extract features
from the image and a GRU-based language model as the decoder to generate
descriptive sentences. To improve performance, we integrate the Bahdanau
attention model with the GRU decoder to enable learning to focus on specific
image parts. We evaluate our approach using the MSCOCO and Flickr30k datasets
and show that it achieves competitive scores compared to state-of-the-art
methods. Our proposed framework can bridge the gap between computer vision and
natural language and can be extended to specific domains.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07253" title="Abstract">arXiv:2310.07253</a> [<a href="/pdf/2310.07253" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADMEOOD: Out-of-Distribution Benchmark for Drug Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuoying Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xinlong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lida Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Songquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Rongbo Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Obtaining accurate and valid information for drug molecules is a crucial and
challenging task. However, chemical knowledge and information have been
accumulated over the past 100 years from various regions, laboratories, and
experimental purposes. Little has been explored in terms of the
out-of-distribution (OOD) problem with noise and inconsistency, which may lead
to weak robustness and unsatisfied performance. This study proposes a novel
benchmark ADMEOOD, a systematic OOD dataset curator and benchmark specifically
designed for drug property prediction. ADMEOOD obtained 27 ADME (Absorption,
Distribution, Metabolism, Excretion) drug properties from Chembl and relevant
literature. Additionally, it includes two kinds of OOD data shifts: Noise Shift
and Concept Conflict Drift (CCD). Noise Shift responds to the noise level by
categorizing the environment into different confidence levels. On the other
hand, CCD describes the data which has inconsistent label among the original
data. Finally, it tested on a variety of domain generalization models, and the
experimental results demonstrate the effectiveness of the proposed partition
method in ADMEOOD: ADMEOOD demonstrates a significant difference performance
between in-distribution and out-of-distribution data. Moreover, ERM (Empirical
Risk Minimization) and other models exhibit distinct trends in performance
across different domains and measurement types.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07255" title="Abstract">arXiv:2310.07255</a> [<a href="/pdf/2310.07255" title="Download PDF">pdf</a>, <a href="/format/2310.07255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADASR: An Adversarial Auto-Augmentation Framework for Hyperspectral and  Multispectral Data Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jinghui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Lihuang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Ruitao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Geoscience and Remote Sensing Letters. Code is released at <a href="https://github.com/fangfang11-plog/ADASR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep learning-based hyperspectral image (HSI) super-resolution, which aims to
generate high spatial resolution HSI (HR-HSI) by fusing hyperspectral image
(HSI) and multispectral image (MSI) with deep neural networks (DNNs), has
attracted lots of attention. However, neural networks require large amounts of
training data, hindering their application in real-world scenarios. In this
letter, we propose a novel adversarial automatic data augmentation framework
ADASR that automatically optimizes and augments HSI-MSI sample pairs to enrich
data diversity for HSI-MSI fusion. Our framework is sample-aware and optimizes
an augmentor network and two downsampling networks jointly by adversarial
learning so that we can learn more robust downsampling networks for training
the upsampling network. Extensive experiments on two public classical
hyperspectral datasets demonstrate the effectiveness of our ADASR compared to
the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07256" title="Abstract">arXiv:2310.07256</a> [<a href="/pdf/2310.07256" title="Download PDF">pdf</a>, <a href="/ps/2310.07256" title="Download PostScript">ps</a>, <a href="/format/2310.07256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Learning for Stochastic Games: Beyond Zero Sum and  Identical Interest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayin%2C+M+O">Muhammed O. Sayin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a decentralized learning algorithm for stochastic games,
also known as Markov games (MGs). The algorithm is radically uncoupled,
model-free, rational, and convergent by reaching near equilibrium in two-agent
zero-sum and identical-interest MGs, and certain multi-agent general-sum MGs
for both discounted and time-averaged cases. The paper introduces
additive-reward product (ARP) games as a new class of Markov games to address
convergence beyond zero-sum and identical-interest cases. In ARP games, state
is a composition of local states, each local state determines the rewards in an
additive way and they get controlled by a single agent. The algorithm can
converge almost surely to near equilibrium in general-sum ARP games, provided
that the strategic-form games induced by the immediate rewards are
strategically equivalent to either two-agent zero-sum or potential games. The
approximation errors in the results decay with the episode length and the
convergence results can be generalized to the cases with more than two agents
if the strategic-form games induced by the rewards are polymatrix games.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07259" title="Abstract">arXiv:2310.07259</a> [<a href="/pdf/2310.07259" title="Download PDF">pdf</a>, <a href="/format/2310.07259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Hidden Connections: Iterative Tracking and Reasoning for  Video-grounded Dialog
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+D">Da Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Weili Guan</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In contrast to conventional visual question answering, video-grounded dialog
necessitates a profound understanding of both dialog history and video content
for accurate response generation. Despite commendable strides made by existing
methodologies, they often grapple with the challenges of incrementally
understanding intricate dialog histories and assimilating video information. In
response to this gap, we present an iterative tracking and reasoning strategy
that amalgamates a textual encoder, a visual encoder, and a generator. At its
core, our textual encoder is fortified with a path tracking and aggregation
mechanism, adept at gleaning nuances from dialog history that are pivotal to
deciphering the posed questions. Concurrently, our visual encoder harnesses an
iterative reasoning network, meticulously crafted to distill and emphasize
critical visual markers from videos, enhancing the depth of visual
comprehension. Culminating this enriched information, we employ the pre-trained
GPT-2 model as our response generator, stitching together coherent and
contextually apt answers. Our empirical assessments, conducted on two renowned
datasets, testify to the prowess and adaptability of our proposed design.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07261" title="Abstract">arXiv:2310.07261</a> [<a href="/pdf/2310.07261" title="Download PDF">pdf</a>, <a href="/ps/2310.07261" title="Download PostScript">ps</a>, <a href="/format/2310.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep ReLU networks and high-order finite element methods II: Chebyshev  emulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Opschoor%2C+J+A+A">Joost A. A. Opschoor</a>, 
<a href="/search/math?searchtype=author&query=Schwab%2C+C">Christoph Schwab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Expression rates and stability in Sobolev norms of deep ReLU neural networks
(NNs) in terms of the number of parameters defining the NN for continuous,
piecewise polynomial functions, on arbitrary, finite partitions $\mathcal{T}$
of a bounded interval $(a,b)$ are addressed. Novel constructions of ReLU NN
surrogates encoding the approximated functions in terms of Chebyshev polynomial
expansion coefficients are developed. Chebyshev coefficients can be computed
easily from the values of the function in the Clenshaw--Curtis points using the
inverse fast Fourier transform. Bounds on expression rates and stability that
are superior to those of constructions based on ReLU NN emulations of monomials
considered in [Opschoor, Petersen, Schwab, 2020] are obtained. All emulation
bounds are explicit in terms of the (arbitrary) partition of the interval, the
target emulation accuracy and the polynomial degree in each element of the
partition. ReLU NN emulation error estimates are provided for various classes
of functions and norms, commonly encountered in numerical analysis. In
particular, we show exponential ReLU emulation rate bounds for analytic
functions with point singularities and develop an interface between Chebfun
approximations and constructive ReLU NN emulations.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07262" title="Abstract">arXiv:2310.07262</a> [<a href="/pdf/2310.07262" title="Download PDF">pdf</a>, <a href="/format/2310.07262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Brain Networks with Prescribed Functional Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Casti%2C+U">Umberto Casti</a>, 
<a href="/search/eess?searchtype=author&query=Baggio%2C+G">Giacomo Baggio</a>, 
<a href="/search/eess?searchtype=author&query=Benozzo%2C+D">Danilo Benozzo</a>, 
<a href="/search/eess?searchtype=author&query=Zampieri%2C+S">Sandro Zampieri</a>, 
<a href="/search/eess?searchtype=author&query=Bertoldo%2C+A">Alessandra Bertoldo</a>, 
<a href="/search/eess?searchtype=author&query=Chiuso%2C+A">Alessandro Chiuso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, to appear in the proceedings of IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">In this paper, we consider stable stochastic linear systems modeling
whole-brain resting-state dynamics. We parametrize the state matrix of the
system (effective connectivity) in terms of its steady-state covariance matrix
(functional connectivity) and a skew-symmetric matrix $S$. We examine how the
matrix $S$ influences some relevant dynamic properties of the system.
Specifically, we show that a large $S$ enhances the degree of stability and
excitability of the system, and makes the latter more responsive to
high-frequency inputs.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07263" title="Abstract">arXiv:2310.07263</a> [<a href="/pdf/2310.07263" title="Download PDF">pdf</a>, <a href="/format/2310.07263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoPAL: Corrective Planning of Robot Actions with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joublin%2C+F">Frank Joublin</a>, 
<a href="/search/cs?searchtype=author&query=Ceravola%2C+A">Antonello Ceravola</a>, 
<a href="/search/cs?searchtype=author&query=Smirnov%2C+P">Pavel Smirnov</a>, 
<a href="/search/cs?searchtype=author&query=Ocker%2C+F">Felix Ocker</a>, 
<a href="/search/cs?searchtype=author&query=Deigmoeller%2C+J">Joerg Deigmoeller</a>, 
<a href="/search/cs?searchtype=author&query=Belardinelli%2C+A">Anna Belardinelli</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hasler%2C+S">Stephan Hasler</a>, 
<a href="/search/cs?searchtype=author&query=Tanneberg%2C+D">Daniel Tanneberg</a>, 
<a href="/search/cs?searchtype=author&query=Gienger%2C+M">Michael Gienger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the pursuit of fully autonomous robotic systems capable of taking over
tasks traditionally performed by humans, the complexity of open-world
environments poses a considerable challenge. Addressing this imperative, this
study contributes to the field of Large Language Models (LLMs) applied to task
and motion planning for robots. We propose a system architecture that
orchestrates a seamless interplay between multiple cognitive levels,
encompassing reasoning, planning, and motion generation. At its core lies a
novel replanning strategy that handles physically grounded, logical, and
semantic errors in the generated plans. We demonstrate the efficacy of the
proposed feedback architecture, particularly its impact on executability,
correctness, and time complexity via empirical evaluation in the context of a
simulation and two intricate real-world scenarios: blocks world, barman and
pizza preparation.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07264" title="Abstract">arXiv:2310.07264</a> [<a href="/pdf/2310.07264" title="Download PDF">pdf</a>, <a href="/format/2310.07264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Dysarthria based on the Levels of Severity. A  Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Ali%2C+A">Afnan Al-Ali</a>, 
<a href="/search/cs?searchtype=author&query=Al-Maadeed%2C+S">Somaya Al-Maadeed</a>, 
<a href="/search/cs?searchtype=author&query=Saleh%2C+M">Moutaz Saleh</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+R+C">Rani Chinnappa Naidu</a>, 
<a href="/search/cs?searchtype=author&query=Alex%2C+Z+C">Zachariah C Alex</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+P">Prakash Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Khoodeeram%2C+R">Rajeev Khoodeeram</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+R+K">Rajesh Kumar M</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> no comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Dysarthria is a neurological speech disorder that can significantly impact
affected individuals' communication abilities and overall quality of life. The
accurate and objective classification of dysarthria and the determination of
its severity are crucial for effective therapeutic intervention. While
traditional assessments by speech-language pathologists (SLPs) are common, they
are often subjective, time-consuming, and can vary between practitioners.
Emerging machine learning-based models have shown the potential to provide a
more objective dysarthria assessment, enhancing diagnostic accuracy and
reliability. This systematic review aims to comprehensively analyze current
methodologies for classifying dysarthria based on severity levels.
Specifically, this review will focus on determining the most effective set and
type of features that can be used for automatic patient classification and
evaluating the best AI techniques for this purpose. We will systematically
review the literature on the automatic classification of dysarthria severity
levels. Sources of information will include electronic databases and grey
literature. Selection criteria will be established based on relevance to the
research questions. Data extraction will include methodologies used, the type
of features extracted for classification, and AI techniques employed. The
findings of this systematic review will contribute to the current understanding
of dysarthria classification, inform future research, and support the
development of improved diagnostic tools. The implications of these findings
could be significant in advancing patient care and improving therapeutic
outcomes for individuals affected by dysarthria.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07265" title="Abstract">arXiv:2310.07265</a> [<a href="/pdf/2310.07265" title="Download PDF">pdf</a>, <a href="/format/2310.07265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Efficient Vision Transformers from CNNs for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yunhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we tackle a new problem: how to transfer knowledge from the
pre-trained cumbersome yet well-performed CNN-based model to learn a compact
Vision Transformer (ViT)-based model while maintaining its learning capacity?
Due to the completely different characteristics of ViT and CNN and the
long-existing capacity gap between teacher and student models in Knowledge
Distillation (KD), directly transferring the cross-model knowledge is
non-trivial. To this end, we subtly leverage the visual and
linguistic-compatible feature character of ViT (i.e., student), and its
capacity gap with the CNN (i.e., teacher) and propose a novel CNN-to-ViT KD
framework, dubbed C2VKD. Importantly, as the teacher's features are
heterogeneous to those of the student, we first propose a novel
visual-linguistic feature distillation (VLFD) module that explores efficient KD
among the aligned visual and linguistic-compatible representations. Moreover,
due to the large capacity gap between the teacher and student and the
inevitable prediction errors of the teacher, we then propose a pixel-wise
decoupled distillation (PDD) module to supervise the student under the
combination of labels and teacher's predictions from the decoupled target and
non-target classes. Experiments on three semantic segmentation benchmark
datasets consistently show that the increment of mIoU of our method is over
200% of the SoTA KD methods
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07268" title="Abstract">arXiv:2310.07268</a> [<a href="/pdf/2310.07268" title="Download PDF">pdf</a>, <a href="/format/2310.07268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaftFed: A Lightweight Federated Learning Framework for Vehicular Crowd  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Helei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Vehicular crowd intelligence (VCI) is an emerging research field. Facilitated
by state-of-the-art vehicular ad-hoc networks and artificial intelligence,
various VCI applications come to place, e.g., collaborative sensing,
positioning, and mapping. The collaborative property of VCI applications
generally requires data to be shared among participants, thus forming
network-wide intelligence. How to fulfill this process without compromising
data privacy remains a challenging issue. Although federated learning (FL) is a
promising tool to solve the problem, adapting conventional FL frameworks to VCI
is nontrivial. First, the centralized model aggregation is unreliable in VCI
because of the existence of stragglers with unfavorable channel conditions.
Second, existing FL schemes are vulnerable to Non-IID data, which is
intensified by the data heterogeneity in VCI. This paper proposes a novel
federated learning framework called RaftFed to facilitate privacy-preserving
VCI. The experimental results show that RaftFed performs better than baselines
regarding communication overhead, model accuracy, and model convergence.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07269" title="Abstract">arXiv:2310.07269</a> [<a href="/pdf/2310.07269" title="Download PDF">pdf</a>, <a href="/format/2310.07269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Does Sharpness-Aware Minimization Generalize Better Than SGD?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Y">Yiwen Kou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 4 figures, 2 tables. In NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">The challenge of overfitting, in which the model memorizes the training data
and fails to generalize to test data, has become increasingly significant in
the training of large neural networks. To tackle this challenge,
Sharpness-Aware Minimization (SAM) has emerged as a promising training method,
which can improve the generalization of neural networks even in the presence of
label noise. However, a deep understanding of how SAM works, especially in the
setting of nonlinear neural networks and classification tasks, remains largely
missing. This paper fills this gap by demonstrating why SAM generalizes better
than Stochastic Gradient Descent (SGD) for a certain data model and two-layer
convolutional ReLU networks. The loss landscape of our studied problem is
nonsmooth, thus current explanations for the success of SAM based on the
Hessian information are insufficient. Our result explains the benefits of SAM,
particularly its ability to prevent noise learning in the early stages, thereby
facilitating more effective learning of features. Experiments on both synthetic
and real data corroborate our theory.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07276" title="Abstract">arXiv:2310.07276</a> [<a href="/pdf/2310.07276" title="Download PDF">pdf</a>, <a href="/format/2310.07276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioT5: Enriching Cross-modal Integration in Biology with Chemical  Knowledge and Natural Language Associations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+Q">Qizhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kehan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kaiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yingce Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Empirical Methods in Natural Language Processing (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Recent advancements in biological research leverage the integration of
molecules, proteins, and natural language to enhance drug discovery. However,
current models exhibit several limitations, such as the generation of invalid
molecular SMILES, underutilization of contextual information, and equal
treatment of structured and unstructured knowledge. To address these issues, we
propose $\mathbf{BioT5}$, a comprehensive pre-training framework that enriches
cross-modal integration in biology with chemical knowledge and natural language
associations. $\mathbf{BioT5}$ utilizes SELFIES for $100%$ robust molecular
representations and extracts knowledge from the surrounding context of
bio-entities in unstructured biological literature. Furthermore,
$\mathbf{BioT5}$ distinguishes between structured and unstructured knowledge,
leading to more effective utilization of information. After fine-tuning, BioT5
shows superior performance across a wide range of tasks, demonstrating its
strong capability of capturing underlying relations and properties of
bio-entities. Our code is available at
$\href{https://github.com/QizhiPei/BioT5}{Github}$.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07279" title="Abstract">arXiv:2310.07279</a> [<a href="/pdf/2310.07279" title="Download PDF">pdf</a>, <a href="/format/2310.07279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing expressivity transfer in textless speech-to-speech translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duret%2C+J">Jarod Duret</a> (LIA), 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+B">Benjamin O&#x27;Brien</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Est%C3%A8ve%2C+Y">Yannick Est&#xe8;ve</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Parcollet%2C+T">Titouan Parcollet</a> (CAM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ASRU, Dec 2023, Taipei, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Textless speech-to-speech translation systems are rapidly advancing, thanks
to the integration of self-supervised learning techniques. However, existing
state-of-the-art systems fall short when it comes to capturing and transferring
expressivity accurately across different languages. Expressivity plays a vital
role in conveying emotions, nuances, and cultural subtleties, thereby enhancing
communication across diverse languages. To address this issue this study
presents a novel method that operates at the discrete speech unit level and
leverages multilingual emotion embeddings to capture language-agnostic
information. Specifically, we demonstrate how these embeddings can be used to
effectively predict the pitch and duration of speech units in the target
language. Through objective and subjective experiments conducted on a
French-to-English translation task, our findings highlight the superior
expressivity transfer achieved by our approach compared to current
state-of-the-art systems.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07281" title="Abstract">arXiv:2310.07281</a> [<a href="/pdf/2310.07281" title="Download PDF">pdf</a>, <a href="/format/2310.07281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Completely Locale-independent Session-based Recommender System by  Leveraging Trained Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tokutake%2C+Y">Yu Tokutake</a>, 
<a href="/search/cs?searchtype=author&query=Yamasaki%2C+C">Chihiro Yamasaki</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yongzhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+A">Ayuka Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+K">Kei Harada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In this paper, we propose a solution that won the 10th prize in the KDD Cup
2023 Challenge Task 2 (Next Product Recommendation for Underrepresented
Languages/Locales). Our approach involves two steps: (i) Identify candidate
item sets based on co-visitation, and (ii) Re-ranking the items using LightGBM
with locale-independent features, including session-based features and product
similarity. The experiment demonstrated that the locale-independent model
performed consistently well across different test locales, and performed even
better when incorporating data from other locales into the training.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07282" title="Abstract">arXiv:2310.07282</a> [<a href="/pdf/2310.07282" title="Download PDF">pdf</a>, <a href="/format/2310.07282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis on Large Language Models in Healthcare: A Case Study of  BioBERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharaf%2C+S">Shyni Sharaf</a>, 
<a href="/search/cs?searchtype=author&query=Anoop%2C+V+S">V. S. Anoop</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper conducts a comprehensive investigation into applying large
language models, particularly on BioBERT, in healthcare. It begins with
thoroughly examining previous natural language processing (NLP) approaches in
healthcare, shedding light on the limitations and challenges these methods
face. Following that, this research explores the path that led to the
incorporation of BioBERT into healthcare applications, highlighting its
suitability for addressing the specific requirements of tasks related to
biomedical text mining. The analysis outlines a systematic methodology for
fine-tuning BioBERT to meet the unique needs of the healthcare domain. This
approach includes various components, including the gathering of data from a
wide range of healthcare sources, data annotation for tasks like identifying
medical entities and categorizing them, and the application of specialized
preprocessing techniques tailored to handle the complexities found in
biomedical texts. Additionally, the paper covers aspects related to model
evaluation, with a focus on healthcare benchmarks and functions like processing
of natural language in biomedical, question-answering, clinical document
classification, and medical entity recognition. It explores techniques to
improve the model's interpretability and validates its performance compared to
existing healthcare-focused language models. The paper thoroughly examines
ethical considerations, particularly patient privacy and data security. It
highlights the benefits of incorporating BioBERT into healthcare contexts,
including enhanced clinical decision support and more efficient information
retrieval. Nevertheless, it acknowledges the impediments and complexities of
this integration, encompassing concerns regarding data privacy, transparency,
resource-intensive requirements, and the necessity for model customization to
align with diverse healthcare domains.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07287" title="Abstract">arXiv:2310.07287</a> [<a href="/pdf/2310.07287" title="Download PDF">pdf</a>, <a href="/format/2310.07287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Interior Design Recommendation via Coarse-to-fine Multimodal  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weiyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yafei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaodong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM International Conference on Multimedia'23. 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Personalized interior decoration design often incurs high labor costs. Recent
efforts in developing intelligent interior design systems have focused on
generating textual requirement-based decoration designs while neglecting the
problem of how to mine homeowner's hidden preferences and choose the proper
initial design. To fill this gap, we propose an Interactive Interior Design
Recommendation System (IIDRS) based on reinforcement learning (RL). IIDRS aims
to find an ideal plan by interacting with the user, who provides feedback on
the gap between the recommended plan and their ideal one. To improve
decision-making efficiency and effectiveness in large decoration spaces, we
propose a Decoration Recommendation Coarse-to-Fine Policy Network (DecorRCFN).
Additionally, to enhance generalization in online scenarios, we propose an
object-aware feedback generation method that augments model training with
diversified and dynamic textual feedback. Extensive experiments on a real-world
dataset demonstrate our method outperforms traditional methods by a large
margin in terms of recommendation accuracy. Further user studies demonstrate
that our method reaches higher real-world user satisfaction than baseline
methods.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07289" title="Abstract">arXiv:2310.07289</a> [<a href="/pdf/2310.07289" title="Download PDF">pdf</a>, <a href="/format/2310.07289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Factuality: A Comprehensive Evaluation of Large Language Models  as Knowledge Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Y">Yatao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zeyu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) outperform information retrieval techniques for
downstream knowledge-intensive tasks when being prompted to generate world
knowledge. However, community concerns abound regarding the factuality and
potential implications of using this uncensored knowledge. In light of this, we
introduce CONNER, a COmpreheNsive kNowledge Evaluation fRamework, designed to
systematically and automatically evaluate generated knowledge from six
important perspectives -- Factuality, Relevance, Coherence, Informativeness,
Helpfulness and Validity. We conduct an extensive empirical analysis of the
generated knowledge from three different types of LLMs on two widely studied
knowledge-intensive tasks, i.e., open-domain question answering and
knowledge-grounded dialogue. Surprisingly, our study reveals that the
factuality of generated knowledge, even if lower, does not significantly hinder
downstream tasks. Instead, the relevance and coherence of the outputs are more
important than small factual mistakes. Further, we show how to use CONNER to
improve knowledge-intensive tasks by designing two strategies: Prompt
Engineering and Knowledge Selection. Our evaluation code and LLM-generated
knowledge with human annotations will be released to facilitate future
research.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07290" title="Abstract">arXiv:2310.07290</a> [<a href="/pdf/2310.07290" title="Download PDF">pdf</a>, <a href="/format/2310.07290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Android App Categorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alecci%2C+M">Marco Alecci</a>, 
<a href="/search/cs?searchtype=author&query=Samhi%2C+J">Jordan Samhi</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T+F">Tegawend&#xe9; F. Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Numerous tools rely on automatic categorization of Android apps as part of
their methodology. However, incorrect categorization can lead to inaccurate
outcomes, such as a malware detector wrongly flagging a benign app as
malicious. One such example is the SlideIT Free Keyboard app, which has over
500000 downloads on Google Play. Despite being a "Keyboard" app, it is often
wrongly categorized alongside "Language" apps due to the app's description
focusing heavily on language support, resulting in incorrect analysis outcomes,
including mislabeling it as a potential malware when it is actually a benign
app. Hence, there is a need to improve the categorization of Android apps to
benefit all the tools relying on it. In this paper, we present a comprehensive
evaluation of existing Android app categorization approaches using our new
ground-truth dataset. Our evaluation demonstrates the notable superiority of
approaches that utilize app descriptions over those solely relying on data
extracted from the APK file, while also leaving space for potential improvement
in the former category. Thus, we propose two innovative approaches that
effectively outperform the performance of existing methods in both
description-based and APK-based methodologies. Finally, by employing our novel
description-based approach, we have successfully demonstrated that adopting a
higher-performing categorization method can significantly benefit tools reliant
on app categorization, leading to an improvement in their overall performance.
This highlights the significance of developing advanced and efficient app
categorization methodologies for improved results in software engineering
tasks.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07292" title="Abstract">arXiv:2310.07292</a> [<a href="/pdf/2310.07292" title="Download PDF">pdf</a>, <a href="/ps/2310.07292" title="Download PostScript">ps</a>, <a href="/format/2310.07292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication Neighbor Discovery for MANET with  Gossip Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chenfei Li</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+Y">Yanpeng Cui</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+Z">Zeyang Meng</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 16 figures, in IEEE Sensors Journal, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Mobile Ad hoc Network (MANET), supporting Machine-Type Communication(MTC),
has a strong demand for rapid networking. Neighbor Discovery (ND) is a key
initial step in configuring MANETs and faces a serious challenge in decreasing
convergence time. Integrated Sensing and Communication (ISAC), as one of the
potential key technologies in the 6th Generation (6G) mobile networks, can
obtain the sensing data as the priori information to accelerate ND convergence.
In order to further reduce the convergence time of ND, this paper introduces
the ISAC-enabled gossip mechanism into the ND algorithm. The prior information
acquired by ISAC reduces the information redundancy brought by the gossip
mechanism and thus decreases the probability of collision, which further
improves convergence speed. The average number of discovered nodes within a
given period is derived, which is applied as the critical metric to evaluate
the performance of ND algorithms. The simulation results confirm the
correctness of the theoretical derivation and show that the interplay between
the prior mechanisms and the gossip mechanism significantly reduces the
convergence time. In addition, to solve the problem of imperfect sensing
information, reinforcement learning is applied. Under the constraints of the
convergence condition, the non-Reply and non-Stop Algorithm based on Gossip and
Q-learning (GQ-nRnS) proposed in this paper not only ensures the completeness
of ND, but also maintains a high convergence speed of ND. Compared with the
Q-learning-based ND algorithm (Q-ND), the average convergence time of the
GQ-nRnS algorithm is reduced by about 66.4%.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07297" title="Abstract">arXiv:2310.07297</a> [<a href="/pdf/2310.07297" title="Download PDF">pdf</a>, <a href="/format/2310.07297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score Regularized Policy Optimization through Diffusion Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent developments in offline reinforcement learning have uncovered the
immense potential of diffusion modeling, which excels at representing
heterogeneous behavior policies. However, sampling from diffusion policies is
considerably slow because it necessitates tens to hundreds of iterative
inference steps for one action. To address this issue, we propose to extract an
efficient deterministic inference policy from critic models and pretrained
diffusion behavior models, leveraging the latter to directly regularize the
policy gradient with the behavior distribution's score function during
optimization. Our method enjoys powerful generative capabilities of diffusion
modeling while completely circumventing the computationally intensive and
time-consuming diffusion sampling scheme, both during training and evaluation.
Extensive results on D4RL tasks show that our method boosts action sampling
speed by more than 25 times compared with various leading diffusion-based
methods in locomotion tasks, while still maintaining state-of-the-art
performance.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07298" title="Abstract">arXiv:2310.07298</a> [<a href="/pdf/2310.07298" title="Download PDF">pdf</a>, <a href="/format/2310.07298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Memorization: Violating Privacy Via Inference with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Staab%2C+R">Robin Staab</a>, 
<a href="/search/cs?searchtype=author&query=Vero%2C+M">Mark Vero</a>, 
<a href="/search/cs?searchtype=author&query=Balunovi%C4%87%2C+M">Mislav Balunovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Vechev%2C+M">Martin Vechev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Current privacy research on large language models (LLMs) primarily focuses on
the issue of extracting memorized training data. At the same time, models'
inference capabilities have increased drastically. This raises the key question
of whether current LLMs could violate individuals' privacy by inferring
personal attributes from text given at inference time. In this work, we present
the first comprehensive study on the capabilities of pretrained LLMs to infer
personal attributes from text. We construct a dataset consisting of real Reddit
profiles, and show that current LLMs can infer a wide range of personal
attributes (e.g., location, income, sex), achieving up to $85\%$ top-1 and
$95.8\%$ top-3 accuracy at a fraction of the cost ($100\times$) and time
($240\times$) required by humans. As people increasingly interact with
LLM-powered chatbots across all aspects of life, we also explore the emerging
threat of privacy-invasive chatbots trying to extract personal information
through seemingly benign questions. Finally, we show that common mitigations,
i.e., text anonymization and model alignment, are currently ineffective at
protecting user privacy against LLM inference. Our findings highlight that
current LLMs can infer personal data at a previously unattainable scale. In the
absence of working defenses, we advocate for a broader discussion around LLM
privacy implications beyond memorization, striving for a wider privacy
protection.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07299" title="Abstract">arXiv:2310.07299</a> [<a href="/pdf/2310.07299" title="Download PDF">pdf</a>, <a href="/format/2310.07299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobustGEC: Robust Grammatical Error Correction Against Subtle Context  Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+E">Enbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (main conference, long paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Grammatical Error Correction (GEC) systems play a vital role in assisting
people with their daily writing tasks. However, users may sometimes come across
a GEC system that initially performs well but fails to correct errors when the
inputs are slightly modified. To ensure an ideal user experience, a reliable
GEC system should have the ability to provide consistent and accurate
suggestions when encountering irrelevant context perturbations, which we refer
to as context robustness. In this paper, we introduce RobustGEC, a benchmark
designed to evaluate the context robustness of GEC systems. RobustGEC comprises
5,000 GEC cases, each with one original error-correct sentence pair and five
variants carefully devised by human annotators. Utilizing RobustGEC, we reveal
that state-of-the-art GEC systems still lack sufficient robustness against
context perturbations. In addition, we propose a simple yet effective method
for remitting this issue.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07300" title="Abstract">arXiv:2310.07300</a> [<a href="/pdf/2310.07300" title="Download PDF">pdf</a>, <a href="/format/2310.07300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> uxSense: Supporting User Experience Analysis with Visualization and  Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batch%2C+A">Andrea Batch</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yipeng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Elmqvist%2C+N">Niklas Elmqvist</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 14 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Visualization and Computer Graphics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Analyzing user behavior from usability evaluation can be a challenging and
time-consuming task, especially as the number of participants and the scale and
complexity of the evaluation grows. We propose uxSense, a visual analytics
system using machine learning methods to extract user behavior from audio and
video recordings as parallel time-stamped data streams. Our implementation
draws on pattern recognition, computer vision, natural language processing, and
machine learning to extract user sentiment, actions, posture, spoken words, and
other features from such recordings. These streams are visualized as parallel
timelines in a web-based front-end, enabling the researcher to search, filter,
and annotate data across time and space. We present the results of a user study
involving professional UX researchers evaluating user data using uxSense. In
fact, we used uxSense itself to evaluate their sessions.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07301" title="Abstract">arXiv:2310.07301</a> [<a href="/pdf/2310.07301" title="Download PDF">pdf</a>, <a href="/format/2310.07301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parrot: Enhancing Multi-Turn Chat Models by Learning to Ask Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuchong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jinwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruihua Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fuzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Impressive progress has been made on chat models based on Large Language
Models (LLMs) recently; however, there is a noticeable lag in multi-turn
conversations between open-source chat models (e.g., Alpaca and Vicuna) and the
leading chat models (e.g., ChatGPT and GPT-4). Through a series of analyses, we
attribute the lag to the lack of enough high-quality multi-turn
instruction-tuning data. The available instruction-tuning data for the
community are either single-turn conversations or multi-turn ones with certain
issues, such as non-human-like instructions, less detailed responses, or rare
topic shifts. In this paper, we address these challenges by introducing Parrot,
a highly scalable solution designed to automatically generate high-quality
instruction-tuning data, which are then used to enhance the effectiveness of
chat models in multi-turn conversations. Specifically, we start by training the
Parrot-Ask model, which is designed to emulate real users in generating
instructions. We then utilize Parrot-Ask to engage in multi-turn conversations
with ChatGPT across a diverse range of topics, resulting in a collection of 40K
high-quality multi-turn dialogues (Parrot-40K). These data are subsequently
employed to train a chat model that we have named Parrot-Chat. We demonstrate
that the dialogues gathered from Parrot-Ask markedly outperform existing
multi-turn instruction-following datasets in critical metrics, including topic
diversity, number of turns, and resemblance to human conversation. With only
40K training examples, Parrot-Chat achieves strong performance against other
13B open-source models across a range of instruction-following benchmarks, and
particularly excels in evaluations of multi-turn capabilities. We make all
codes, datasets, and two versions of the Parrot-Ask model based on LLaMA2-13B
and KuaiYii-13B available at https://github.com/kwai/KwaiYii/Parrot.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07306" title="Abstract">arXiv:2310.07306</a> [<a href="/pdf/2310.07306" title="Download PDF">pdf</a>, <a href="/format/2310.07306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SNOiC: Soft Labeling and Noisy Mixup based Open Intent Classification  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanwar%2C+A">Aditi Kanwar</a> (1), 
<a href="/search/cs?searchtype=author&query=Seetha%2C+A">Aditi Seetha</a> (1), 
<a href="/search/cs?searchtype=author&query=Chouhan%2C+S+S">Satyendra Singh Chouhan</a> (1), 
<a href="/search/cs?searchtype=author&query=Niyogi%2C+R">Rajdeep Niyogi</a> (2) ((1) MNIT Jaipur, 302017, INDIA, (2) IIT Roorkee, 247667, INDIA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper presents a Soft Labeling and Noisy Mixup-based open intent
classification model (SNOiC). Most of the previous works have used
threshold-based methods to identify open intents, which are prone to
overfitting and may produce biased predictions. Additionally, the need for more
available data for an open intent class presents another limitation for these
existing models. SNOiC combines Soft Labeling and Noisy Mixup strategies to
reduce the biasing and generate pseudo-data for open intent class. The
experimental results on four benchmark datasets show that the SNOiC model
achieves a minimum and maximum performance of 68.72\% and 94.71\%,
respectively, in identifying open intents. Moreover, compared to
state-of-the-art models, the SNOiC model improves the performance of
identifying open intents by 0.93\% (minimum) and 12.76\% (maximum). The model's
efficacy is further established by analyzing various parameters used in the
proposed model. An ablation study is also conducted, which involves creating
three model variants to validate the effectiveness of the SNOiC model.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07310" title="Abstract">arXiv:2310.07310</a> [<a href="/pdf/2310.07310" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Aramaic: Towards a Synthetic Data Paradigm Enabling Machine  Learning in Epigraphy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aioanei%2C+A+C">Andrei C. Aioanei</a>, 
<a href="/search/cs?searchtype=author&query=Hunziker-Rodewald%2C+R">Regine Hunziker-Rodewald</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+K">Konstantin Klein</a>, 
<a href="/search/cs?searchtype=author&query=Michels%2C+D+L">Dominik L. Michels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 19 images
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Epigraphy increasingly turns to modern artificial intelligence (AI)
technologies such as machine learning (ML) for extracting insights from ancient
inscriptions. However, scarce labeled data for training ML algorithms severely
limits current techniques, especially for ancient scripts like Old Aramaic. Our
research pioneers an innovative methodology for generating synthetic training
data tailored to Old Aramaic letters. Our pipeline synthesizes photo-realistic
Aramaic letter datasets, incorporating textural features, lighting, damage, and
augmentations to mimic real-world inscription diversity. Despite minimal real
examples, we engineer a dataset of 250,000 training and 25,000 validation
images covering the 22 letter classes in the Aramaic alphabet. This
comprehensive corpus provides a robust volume of data for training a residual
neural network (ResNet) to classify highly degraded Aramaic letters. The ResNet
model demonstrates high accuracy in classifying real images from the 8th
century BCE Hadad statue inscription. Additional experiments validate
performance on varying materials and styles, proving effective generalization.
Our results validate the model's capabilities in handling diverse real-world
scenarios, proving the viability of our synthetic data approach and avoiding
the dependence on scarce training data that has constrained epigraphic
analysis. Our innovative framework elevates interpretation accuracy on damaged
inscriptions, thus enhancing knowledge extraction from these historical
resources.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07312" title="Abstract">arXiv:2310.07312</a> [<a href="/pdf/2310.07312" title="Download PDF">pdf</a>, <a href="/ps/2310.07312" title="Download PostScript">ps</a>, <a href="/format/2310.07312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WiGenAI: The Symphony of Wireless and Generative AI via Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Letafati%2C+M">Mehdi Letafati</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Samad Ali</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Innovative foundation models, such as GPT-3 and stable diffusion models, have
made a paradigm shift in the realm of artificial intelligence (AI) towards
generative AI-based systems. In unison, from data communication and networking
perspective, AI and machine learning (AI/ML) algorithms are envisioned to be
pervasively incorporated into the future generations of wireless communications
systems, highlighting the need for novel AI-native solutions for the emergent
communication scenarios. In this article, we outline the applications of
generative AI in wireless communication systems to lay the foundations for
research in this field. Diffusion-based generative models, as the new
state-of-the-art paradigm of generative models, are introduced, and their
applications in wireless communication systems are discussed. Two case studies
are also presented to showcase how diffusion models can be exploited for the
development of resilient AI-native communication systems. Specifically, we
propose denoising diffusion probabilistic models (DDPM) for a wireless
communication scheme with non-ideal transceivers, where 30% improvement is
achieved in terms of bit error rate. As the second application, DDPMs are
employed at the transmitter to shape the constellation symbols, highlighting a
robust out-of-distribution performance. Finally, future directions and open
issues for the development of generative AI-based wireless systems are
discussed to promote future research endeavors towards wireless generative AI
(WiGenAI).
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07313" title="Abstract">arXiv:2310.07313</a> [<a href="/pdf/2310.07313" title="Download PDF">pdf</a>, <a href="/format/2310.07313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecule-Edit Templates for Efficient and Accurate Retrosynthesis  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sacha%2C+M">Miko&#x142;aj Sacha</a>, 
<a href="/search/cs?searchtype=author&query=Sadowski%2C+M">Micha&#x142; Sadowski</a>, 
<a href="/search/cs?searchtype=author&query=Kozakowski%2C+P">Piotr Kozakowski</a>, 
<a href="/search/cs?searchtype=author&query=van+Workum%2C+R">Ruard van Workum</a>, 
<a href="/search/cs?searchtype=author&query=Jastrz%C4%99bski%2C+S">Stanis&#x142;aw Jastrz&#x119;bski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Retrosynthesis involves determining a sequence of reactions to synthesize
complex molecules from simpler precursors. As this poses a challenge in organic
chemistry, machine learning has offered solutions, particularly for predicting
possible reaction substrates for a given target molecule. These solutions
mainly fall into template-based and template-free categories. The former is
efficient but relies on a vast set of predefined reaction patterns, while the
latter, though more flexible, can be computationally intensive and less
interpretable. To address these issues, we introduce METRO (Molecule-Edit
Templates for RetrOsynthesis), a machine-learning model that predicts reactions
using minimal templates - simplified reaction patterns capturing only essential
molecular changes - reducing computational overhead and achieving
state-of-the-art results on standard benchmarks.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07314" title="Abstract">arXiv:2310.07314</a> [<a href="/pdf/2310.07314" title="Download PDF">pdf</a>, <a href="/format/2310.07314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive and Gamified Learning Paths with Polyglot and .NET Interactive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martorella%2C+T">Tommaso Martorella</a>, 
<a href="/search/cs?searchtype=author&query=Bucchiarone%2C+A">Antonio Bucchiarone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 17 figures. arXiv admin note: text overlap with <a href="/abs/2210.15256">arXiv:2210.15256</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The digital age is changing the role of educators and pushing for a paradigm
shift in the education system as a whole. Growing demand for general and
specialized education inside and outside classrooms is at the heart of this
rising trend. In modern, heterogeneous learning environments, the
one-size-fits-all approach is proven to be fundamentally flawed.
Individualization through adaptivity is, therefore, crucial to nurture
individual potential and address accessibility needs and neurodiversity. By
formalizing a learning framework that takes into account all these different
aspects, we aim to define and implement an open, content-agnostic, and
extensible platform to design and consume adaptive and gamified learning
experiences.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07320" title="Abstract">arXiv:2310.07320</a> [<a href="/pdf/2310.07320" title="Download PDF">pdf</a>, <a href="/format/2310.07320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine-Resilient Decentralized Multi-Armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingxuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Koppel%2C+A">Alec Koppel</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">Alvaro Velasquez</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In decentralized cooperative multi-armed bandits (MAB), each agent observes a
distinct stream of rewards, and seeks to exchange information with others to
select a sequence of arms so as to minimize its regret. Agents in the
cooperative setting can outperform a single agent running a MAB method such as
Upper-Confidence Bound (UCB) independently. In this work, we study how to
recover such salient behavior when an unknown fraction of the agents can be
Byzantine, that is, communicate arbitrarily wrong information in the form of
reward mean-estimates or confidence sets. This framework can be used to model
attackers in computer networks, instigators of offensive content into
recommender systems, or manipulators of financial markets. Our key contribution
is the development of a fully decentralized resilient upper confidence bound
(UCB) algorithm that fuses an information mixing step among agents with a
truncation of inconsistent and extreme values. This truncation step enables us
to establish that the performance of each normal agent is no worse than the
classic single-agent UCB1 algorithm in terms of regret, and more importantly,
the cumulative regret of all normal agents is strictly better than the
non-cooperative case, provided that each agent has at least 3f+1 neighbors
where f is the maximum possible Byzantine agents in each agent's neighborhood.
Extensions to time-varying neighbor graphs, and minimax lower bounds are
further established on the achievable regret. Experiments corroborate the
merits of this framework in practice.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07321" title="Abstract">arXiv:2310.07321</a> [<a href="/pdf/2310.07321" title="Download PDF">pdf</a>, <a href="/format/2310.07321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of Cross-Domain Data on German Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dada%2C+A">Amin Dada</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+E">Kaleb E Smith</a>, 
<a href="/search/cs?searchtype=author&query=Idrissi-Yaghir%2C+A">Ahmad Idrissi-Yaghir</a>, 
<a href="/search/cs?searchtype=author&query=Seibold%2C+C+M">Constantin Marc Seibold</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Heiliger%2C+L">Lars Heiliger</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+C+M">Christoph M. Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yonghui Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure, accepted at Findings of the Association for Computational Linguistics: EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditionally, large language models have been either trained on general web
crawls or domain-specific data. However, recent successes of generative large
language models, have shed light on the benefits of cross-domain datasets. To
examine the significance of prioritizing data diversity over quality, we
present a German dataset comprising texts from five domains, along with another
dataset aimed at containing high-quality data. Through training a series of
models ranging between 122M and 750M parameters on both datasets, we conduct a
comprehensive benchmark on multiple downstream tasks. Our findings demonstrate
that the models trained on the cross-domain dataset outperform those trained on
quality data alone, leading to improvements up to $4.45\%$ over the previous
state-of-the-art. The models are available at
https://huggingface.co/ikim-uk-essen
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07322" title="Abstract">arXiv:2310.07322</a> [<a href="/pdf/2310.07322" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A webcam-based machine learning approach for three-dimensional range of  motion evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+M">Xiaoye Michael Wang</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+D+T">Derek T. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Background. Joint range of motion (ROM) is an important quantitative measure
for physical therapy. Commonly relying on a goniometer, accurate and reliable
ROM measurement requires extensive training and practice. This, in turn,
imposes a significant barrier for those who have limited in-person access to
healthcare.
<br />Objective. The current study presents and evaluates an alternative machine
learning-based ROM evaluation method that could be remotely accessed via a
webcam.
<br />Methods. To evaluate its reliability, the ROM measurements for a diverse set
of joints (neck, spine, and upper and lower extremities) derived using this
method were compared to those obtained from a marker-based optical motion
capture system.
<br />Results. Data collected from 25 healthy adults demonstrated that the webcam
solution exhibited high test-retest reliability, with substantial to almost
perfect intraclass correlation coefficients for most joints. Compared with the
marker-based system, the webcam-based system demonstrated substantial to almost
perfect inter-rater reliability for some joints, and lower inter-rater
reliability for other joints (e.g., shoulder flexion and elbow flexion), which
could be attributed to the reduced sensitivity to joint locations at the apex
of the movement.
<br />Conclusions. The proposed webcam-based method exhibited high test-retest and
inter-rater reliability, making it a versatile alternative for existing ROM
evaluation methods in clinical practice and the tele-implementation of physical
therapy and rehabilitation.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07323" title="Abstract">arXiv:2310.07323</a> [<a href="/pdf/2310.07323" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multichannel consecutive data cross-extraction with 1DCNN-attention for  diagnosis of power transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guogang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qianqian Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Power transformer plays a critical role in grid infrastructure, and its
diagnosis is paramount for maintaining stable operation. However, the current
methods for transformer diagnosis focus on discrete dissolved gas analysis,
neglecting deep feature extraction of multichannel consecutive data. The
unutilized sequential data contains the significant temporal information
reflecting the transformer condition. In light of this, the structure of
multichannel consecutive data cross-extraction (MCDC) is proposed in this
article in order to comprehensively exploit the intrinsic characteristic and
evaluate the states of transformer. Moreover, for the better accommodation in
scenario of transformer diagnosis, one dimensional convolution neural network
attention (1DCNN-attention) mechanism is introduced and offers a more efficient
solution given the simplified spatial complexity. Finally, the effectiveness of
MCDC and the superior generalization ability, compared with other algorithms,
are validated in experiments conducted on a dataset collected from real
operation cases of power transformer. Additionally, the better stability of
1DCNN-attention has also been certified.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07324" title="Abstract">arXiv:2310.07324</a> [<a href="/pdf/2310.07324" title="Download PDF">pdf</a>, <a href="/format/2310.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Attention for Interpretable Motion Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radouane%2C+K">Karim Radouane</a>, 
<a href="/search/cs?searchtype=author&query=Tchechmedjiev%2C+A">Andon Tchechmedjiev</a>, 
<a href="/search/cs?searchtype=author&query=Ranwez%2C+S">Sylvie Ranwez</a>, 
<a href="/search/cs?searchtype=author&query=Lagarde%2C+J">Julien Lagarde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While much effort has been invested in generating human motion from text,
relatively few studies have been dedicated to the reverse direction, that is,
generating text from motion. Much of the research focuses on maximizing
generation quality without any regard for the interpretability of the
architectures, particularly regarding the influence of particular body parts in
the generation and the temporal synchronization of words with specific
movements and actions. This study explores the combination of movement encoders
with spatio-temporal attention models and proposes strategies to guide the
attention during training to highlight perceptually pertinent areas of the
skeleton in time. We show that adding guided attention with adaptive gate leads
to interpretable captioning while improving performance compared to higher
parameter-count non-interpretable SOTA systems. On the KIT MLD dataset, we
obtain a BLEU@4 of 24.4% (SOTA+6%), a ROUGE-L of 58.30% (SOTA +14.1%), a CIDEr
of 112.10 (SOTA +32.6) and a Bertscore of 41.20% (SOTA +18.20%). On HumanML3D,
we obtain a BLEU@4 of 25.00 (SOTA +2.7%), a ROUGE-L score of 55.4% (SOTA
+6.1%), a CIDEr of 61.6 (SOTA -10.9%), a Bertscore of 40.3% (SOTA +2.5%). Our
code implementation and reproduction details will be soon available at
https://github.com/rd20karim/M2T-Interpretable/tree/main.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07325" title="Abstract">arXiv:2310.07325</a> [<a href="/pdf/2310.07325" title="Download PDF">pdf</a>, <a href="/format/2310.07325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adversarial Example for Direct Logit Attribution: Memory Management  in gelu-4l
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dao%2C+J">James Dao</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Y">Yeu-Tong Lao</a>, 
<a href="/search/cs?searchtype=author&query=Rager%2C+C">Can Rager</a>, 
<a href="/search/cs?searchtype=author&query=Janiak%2C+J">Jett Janiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We provide concrete evidence for memory management in a 4-layer transformer.
Specifically, we identify clean-up behavior, in which model components
consistently remove the output of preceeding components during a forward pass.
Our findings suggest that the interpretability technique Direct Logit
Attribution provides misleading results. We show explicit examples where this
technique is inaccurate, as it does not account for clean-up behavior.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07327" title="Abstract">arXiv:2310.07327</a> [<a href="/pdf/2310.07327" title="Download PDF">pdf</a>, <a href="/format/2310.07327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Polymorphism Meets Code Encryption: Confidentiality and  Side-Channel Protection of Software Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morel%2C+L">Lionel Morel</a> (LFIM), 
<a href="/search/cs?searchtype=author&query=Courouss%C3%A9%2C+D">Damien Courouss&#xe9;</a> (UGA [2016-2019], LIST (CEA), LFIM), 
<a href="/search/cs?searchtype=author&query=Hiscock%2C+T">Thomas Hiscock</a> (DSYS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Digital Threats: Research and Practice, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In this paper, we consider that, in practice, attack scenarios involving
side-channel analysis combine two successive phases:an analysis phase,
targeting the extraction of information about the target and the identification
of possible vulnerabilities;and an exploitation phase, applying attack
techniques on candidate vulnerabilities. We advocate that protections need to
coverthese two phases in order to be effective against real-life attacks. We
present PolEn, a toolchain and a processor architecturethat combine
countermeasures in order to provide an effective mitigation of side-channel
attacks: as a countermeasure againstthe analysis phase, our approach considers
the use of code encryption; as a countermeasure against the exploitation
phase,our approach considers the use of code polymorphism, because it relies on
runtime code generation, and its combinationwith code encryption is
particularly challenging. Code encryption is supported by a processor extension
such that machineinstructions are only decrypted inside the CPU, which
effectively prevents reverse engineering or any extraction of usefulinformation
from memory dumps. Code polymorphism is implemented by software means. It
regularly changes the observablebehaviour of the program, making it
unpredictable for an attacker, hence reducing the possibility to exploit
side-channelleakages. We present a prototype implementation, based on the
RISC-V Spike simulator and a modified LLVM toolchain. Inour experimental
evaluation, we illustrate that PolEn effectively reduces side-channel leakages.
For the protected functionsevaluated, static memory use increases by a factor
of 5 to 22, corresponding to the joint application of code encryption andcode
polymorphism. The overhead, in terms of execution time, ranges between a factor
of 1.8 and 4.6.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07328" title="Abstract">arXiv:2310.07328</a> [<a href="/pdf/2310.07328" title="Download PDF">pdf</a>, <a href="/format/2310.07328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Instruction-tuning Large Language Models in  Chinese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+Q">Qingyi Si</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The success of ChatGPT validates the potential of large language models
(LLMs) in artificial general intelligence (AGI). Subsequently, the release of
LLMs has sparked the open-source community's interest in instruction-tuning,
which is deemed to accelerate ChatGPT's replication process. However, research
on instruction-tuning LLMs in Chinese, the world's most spoken language, is
still in its early stages. Therefore, this paper makes an in-depth empirical
study of instruction-tuning LLMs in Chinese, which can serve as a cookbook that
provides valuable findings for effectively customizing LLMs that can better
respond to Chinese instructions. Specifically, we systematically explore the
impact of LLM bases, parameter-efficient methods, instruction data types, which
are the three most important elements for instruction-tuning. Besides, we also
conduct experiment to study the impact of other factors, e.g., chain-of-thought
data and human-value alignment. We hope that this empirical study can make a
modest contribution to the open Chinese version of ChatGPT. This paper will
release a powerful Chinese LLMs that is comparable to ChatGLM. The code and
data are available at https://github.com/PhoebusSi/Alpaca-CoT.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07331" title="Abstract">arXiv:2310.07331</a> [<a href="/pdf/2310.07331" title="Download PDF">pdf</a>, <a href="/ps/2310.07331" title="Download PostScript">ps</a>, <a href="/format/2310.07331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically stable Particle-in-Cell methods for the magnetized  Vlasov--Poisson equations in orthogonal curvilinear coordinates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gu%2C+A">Anjiao Gu</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+Y">Yajuan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In high-temperature plasma physics, a strong magnetic field is usually used
to confine charged particles. Therefore, for studying the classical
mathematical models of the physical problems it needs to consider the effect of
external magnetic fields. One of the important model equations in plasma is the
Vlasov-Poisson equation with an external magnetic field. This equation usually
has multi-scale characteristics and rich physical properties, thus it is very
important and meaningful to construct numerical methods that can maintain the
physical properties inherited by the original systems over long time. This
paper extends the corresponding theory in Cartesian coordinates to general
orthogonal curvilinear coordinates, and proves that a Poisson-bracket structure
can still be obtained after applying the corresponding finite element
discretization. However, the Hamiltonian systems in the new coordinate systems
generally cannot be decomposed into sub-systems that can be solved accurately,
so it is impossible to use the splitting methods to construct the corresponding
geometric integrators. Therefore, this paper proposes a semi-implicit method
for strong magnetic fields and analyzes the asymptotic stability of this
method.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07333" title="Abstract">arXiv:2310.07333</a> [<a href="/pdf/2310.07333" title="Download PDF">pdf</a>, <a href="/format/2310.07333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing approximate roots of monotone functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+C">Chester Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> If you have any idea how to extend the result to three or more dimensions, please contact me
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Given a function $f: [a,b] \to \mathbb{R}$, if $f(a)&lt;0$ and $f(b)&gt;0$ and $f$
is continuous, the Intermediate Value Theorem implies that $f$ has a root in
$[a,b]$. Moreover, given a value-oracle for $f$, an approximate root of $f$ can
be computed using the bisection method, and the number of required evaluations
is polynomial in the number of accuracy digits. The goal of this paper is to
identify conditions under which this polynomiality result extends to a
multi-dimensional function that satisfies the conditions of Miranda's theorem
-- the natural multi-dimensional extension of the Intermediate Value Theorem.
In general, finding an approximate root of $f$ might require an exponential
number of evaluations even for a two-dimensional function. We show that, if $f$
is two-dimensional, and at least one component of $f$ is monotone, an
approximate root of $f$ can be found using a polynomial number of evalutaions.
This result has applications for computing an approximately envy-free
cake-cutting among three groups.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07335" title="Abstract">arXiv:2310.07335</a> [<a href="/pdf/2310.07335" title="Download PDF">pdf</a>, <a href="/format/2310.07335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Social Motion Latent Space and Human Awareness for Effective  Robot Navigation in Crowded Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ansari%2C+J+A">Junaid Ahmed Ansari</a>, 
<a href="/search/cs?searchtype=author&query=Tourani%2C+S">Satyajit Tourani</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+G">Gourav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+B">Brojeshwar Bhowmick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work proposes a novel approach to social robot navigation by learning to
generate robot controls from a social motion latent space. By leveraging this
social motion latent space, the proposed method achieves significant
improvements in social navigation metrics such as success rate, navigation
time, and trajectory length while producing smoother (less jerk and angular
deviations) and more anticipatory trajectories. The superiority of the proposed
method is demonstrated through comparison with baseline models in various
scenarios. Additionally, the concept of humans' awareness towards the robot is
introduced into the social robot navigation framework, showing that
incorporating human awareness leads to shorter and smoother trajectories owing
to humans' ability to positively interact with the robot.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07338" title="Abstract">arXiv:2310.07338</a> [<a href="/pdf/2310.07338" title="Download PDF">pdf</a>, <a href="/format/2310.07338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Foundation Models for Learning on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xumeng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning on tabular data underpins numerous real-world applications. Despite
considerable efforts in developing effective learning models for tabular data,
current transferable tabular models remain in their infancy, limited by either
the lack of support for direct instruction following in new tasks or the
neglect of acquiring foundational knowledge and capabilities from diverse
tabular datasets. In this paper, we propose Tabular Foundation Models (TabFMs)
to overcome these limitations. TabFMs harness the potential of generative
tabular learning, employing a pre-trained large language model (LLM) as the
base model and fine-tuning it using purpose-designed objectives on an extensive
range of tabular datasets. This approach endows TabFMs with a profound
understanding and universal capabilities essential for learning on tabular
data. Our evaluations underscore TabFM's effectiveness: not only does it
significantly excel in instruction-following tasks like zero-shot and
in-context inference, but it also showcases performance that approaches, and in
instances, even transcends, the renowned yet mysterious closed-source LLMs like
GPT-4. Furthermore, when fine-tuning with scarce data, our model achieves
remarkable efficiency and maintains competitive performance with abundant
training data. Finally, while our results are promising, we also delve into
TabFM's limitations and potential opportunities, aiming to stimulate and
expedite future research on developing more potent TabFMs.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07343" title="Abstract">arXiv:2310.07343</a> [<a href="/pdf/2310.07343" title="Download PDF">pdf</a>, <a href="/format/2310.07343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Do Large Language Models Capture the Ever-changing World Knowledge?  A Review of Recent Advances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Namazi-Rad%2C+M">Mohammad-Reza Namazi-Rad</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 main conference, paper link at <a href="https://github.com/hyintell/awesome-refreshing-llms">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Although large language models (LLMs) are impressive in solving various
tasks, they can quickly be outdated after deployment. Maintaining their
up-to-date status is a pressing concern in the current era. This paper provides
a comprehensive review of recent advances in aligning LLMs with the
ever-changing world knowledge without re-training from scratch. We categorize
research works systemically and provide in-depth comparisons and discussion. We
also discuss existing challenges and highlight future directions to facilitate
research in this field. We release the paper list at
https://github.com/hyintell/awesome-refreshing-llms
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07345" title="Abstract">arXiv:2310.07345</a> [<a href="/pdf/2310.07345" title="Download PDF">pdf</a>, <a href="/ps/2310.07345" title="Download PostScript">ps</a>, <a href="/format/2310.07345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Effect of Language Models in Sequence Discriminative  Training for Neural Transducers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%BCter%2C+R">Ralf Schl&#xfc;ter</a>, 
<a href="/search/cs?searchtype=author&query=Ney%2C+H">Hermann Ney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this work, we investigate the effect of language models (LMs) with
different context lengths and label units (phoneme vs. word) used in sequence
discriminative training for phoneme-based neural transducers. Both lattice-free
and N-best-list approaches are examined. For lattice-free methods with
phoneme-level LMs, we propose a method to approximate the context history to
employ LMs with full-context dependency. This approximation can be extended to
arbitrary context length and enables the usage of word-level LMs in
lattice-free methods. Moreover, a systematic comparison is conducted across
lattice-free and N-best-list-based methods. Experimental results on Librispeech
show that using the word-level LM in training outperforms the phoneme-level LM.
Besides, we find that the context size of the LM used for probability
computation has a limited effect on performance. Moreover, our results reveal
the pivotal importance of the hypothesis space quality in sequence
discriminative training.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07346" title="Abstract">arXiv:2310.07346</a> [<a href="/pdf/2310.07346" title="Download PDF">pdf</a>, <a href="/format/2310.07346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preliminary Results of a Scientometric Analysis of the German  Information Retrieval Community 2020-2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaer%2C+P">Philipp Schaer</a>, 
<a href="/search/cs?searchtype=author&query=Myshkina%2C+S">Svetlana Myshkina</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+J">J&#xfc;ri Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Data available at <a href="https://github.com/irgroup/LWDA2023-IR-community">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> M. Leyer, Wichmann, J. (Eds.): Proceedings of the LWDA 2023
  Workshops: BIA, DB, IR, KDML and WM. Marburg, Germany, 09.-11. October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">The German Information Retrieval community is located in two different
sub-fields: Information and computer science. There are no current studies that
investigate these communities on a scientometric level. Available studies only
focus on the information scientific part of the community. We generated a data
set of 401 recent IR-related publications extracted from six core IR
conferences from a mainly computer scientific background. We analyze this data
set at the institutional and researcher level. The data set is publicly
released, and we also demonstrate a mapping use case.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07347" title="Abstract">arXiv:2310.07347</a> [<a href="/pdf/2310.07347" title="Download PDF">pdf</a>, <a href="/format/2310.07347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast-ELECTRA for Efficient Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chengyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaodong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">ELECTRA pre-trains language models by detecting tokens in a sequence that
have been replaced by an auxiliary model. Although ELECTRA offers a significant
boost in efficiency, its potential is constrained by the training cost brought
by the auxiliary model. Notably, this model, which is jointly trained with the
main model, only serves to assist the training of the main model and is
discarded post-training. This results in a substantial amount of training cost
being expended in vain. To mitigate this issue, we propose Fast-ELECTRA, which
leverages an existing language model as the auxiliary model. To construct a
learning curriculum for the main model, we smooth its output distribution via
temperature scaling following a descending schedule. Our approach rivals the
performance of state-of-the-art ELECTRA-style pre-training methods, while
significantly eliminating the computation and memory cost brought by the joint
training of the auxiliary model. Our method also reduces the sensitivity to
hyper-parameters and enhances the pre-training stability.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07348" title="Abstract">arXiv:2310.07348</a> [<a href="/pdf/2310.07348" title="Download PDF">pdf</a>, <a href="/format/2310.07348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Association Rule Learning from Time Series Data and Knowledge  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karabulut%2C+E">Erkan Karabulut</a>, 
<a href="/search/cs?searchtype=author&query=Degeler%2C+V">Victoria Degeler</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+P">Paul Groth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted to SemIIM23: 2nd International Workshop on Semantic Industrial Information Modelling, 7th November 2023, Athens, Greece, co-located with 22nd International Semantic Web Conference (ISWC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Digital Twins (DT) are a promising concept in cyber-physical systems research
due to their advanced features including monitoring and automated reasoning.
Semantic technologies such as Knowledge Graphs (KG) are recently being utilized
in DTs especially for information modelling. Building on this move, this paper
proposes a pipeline for semantic association rule learning in DTs using KGs and
time series data. In addition to this initial pipeline, we also propose new
semantic association rule criterion. The approach is evaluated on an industrial
water network scenario. Initial evaluation shows that the proposed approach is
able to learn a high number of association rules with semantic information
which are more generalizable. The paper aims to set a foundation for further
work on using semantic association rule learning especially in the context of
industrial applications.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07350" title="Abstract">arXiv:2310.07350</a> [<a href="/pdf/2310.07350" title="Download PDF">pdf</a>, <a href="/format/2310.07350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choosing optimal parameters for a distributed multi-constrained QoS  routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Komech%2C+S">Sergey Komech</a>, 
<a href="/search/cs?searchtype=author&query=Kupavskii%2C+A">Andrey Kupavskii</a>, 
<a href="/search/cs?searchtype=author&query=Vezolainen%2C+A">Alexei Vezolainen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We consider several basic questions on distributed routing in directed graphs
with multiple additive costs, or metrics, and multiple constraints. Distributed
routing in this sense is used in several protocols, such as IS-IS and OSPF. A
practical approach to the multi-constraint routing problem is to, first,
combine the metrics into a single `composite' metric, and then apply one-to-all
shortest path algorithms, e.g. Dijkstra, in order to find shortest path trees.
We show that, in general, even if a feasible path exists and is known for every
source and destination pair, it is impossible to guarantee a distributed
routing under several constraints. We also study the question of choosing the
optimal `composite' metric. We show that under certain mathematical assumptions
we can efficiently find a convex combination of several metrics that maximizes
the number of discovered feasible paths. Sometimes it can be done analytically,
and is in general possible using what we call a 'smart iterative approach'. We
illustrate these findings by extensive experiments on several typical network
topologies.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07351" title="Abstract">arXiv:2310.07351</a> [<a href="/pdf/2310.07351" title="Download PDF">pdf</a>, <a href="/format/2310.07351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atom-Motif Contrastive Transformer for Molecular Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wentao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+G">Gang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, Graph Transformer (GT) models have been widely used in the task of
Molecular Property Prediction (MPP) due to their high reliability in
characterizing the latent relationship among graph nodes (i.e., the atoms in a
molecule). However, most existing GT-based methods usually explore the basic
interactions between pairwise atoms, and thus they fail to consider the
important interactions among critical motifs (e.g., functional groups consisted
of several atoms) of molecules. As motifs in a molecule are significant
patterns that are of great importance for determining molecular properties
(e.g., toxicity and solubility), overlooking motif interactions inevitably
hinders the effectiveness of MPP. To address this issue, we propose a novel
Atom-Motif Contrastive Transformer (AMCT), which not only explores the
atom-level interactions but also considers the motif-level interactions. Since
the representations of atoms and motifs for a given molecule are actually two
different views of the same instance, they are naturally aligned to generate
the self-supervisory signals for model training. Meanwhile, the same motif can
exist in different molecules, and hence we also employ the contrastive loss to
maximize the representation agreement of identical motifs across different
molecules. Finally, in order to clearly identify the motifs that are critical
in deciding the properties of each molecule, we further construct a
property-aware attention mechanism into our learning framework. Our proposed
AMCT is extensively evaluated on seven popular benchmark datasets, and both
quantitative and qualitative results firmly demonstrate its effectiveness when
compared with the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07352" title="Abstract">arXiv:2310.07352</a> [<a href="/pdf/2310.07352" title="Download PDF">pdf</a>, <a href="/format/2310.07352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Distributionally Robust Planning for Renewable-Powered Fast  Charging Stations Under Decision-Dependent EV Diffusion Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yujia Li</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+F">Feng Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+C">Chenxi Hu</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+Y">Yunhe Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">When deploying fast charging stations (FCSs) to support long-distance trips
of electric vehicles (EVs), there exist indirect network effects: while the
gradual diffusion of EVs directly influences the timing and capacities of FCS
allocation, the decisions for FCS allocations, in turn, impact the drivers'
willingness to adopt EVs. This interplay, if neglected, can result in uncovered
EVs and security issues on the grid side and even hinder the effective
diffusion of EVs. In this paper, we explicitly incorporate this interdependence
by quantifying EV adoption rates as decision-dependent uncertainties (DDUs)
using decision-dependent ambiguity sets (DDASs). Then, a two-stage
decision-dependent distributionally robust FCS planning (D$^3$R-FCSP) model is
developed for adaptively deploying FCSs with on-site sources and expanding the
coupled distribution network. A multi-period capacitated arc cover-path cover
(MCACPC) model is incorporated to capture the EVs' recharging patterns to
ensure the feasibility of FCS locations and capacities. To resolve the
nonlinearity and nonconvexity, the D$^3$R-FCSP model is equivalently
reformulated into a single-level mixed-integer linear programming by exploiting
its strong duality and applying the McCormick envelope. Finally, case studies
highlight the superior out-of-sample performances of our model in terms of
security and cost-efficiency. Furthermore, the byproduct of accelerated EV
adoption through an implicit positive feedback loop is highlighted.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07354" title="Abstract">arXiv:2310.07354</a> [<a href="/pdf/2310.07354" title="Download PDF">pdf</a>, <a href="/format/2310.07354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Give and Take: Federated Transfer Learning for Industrial IoT Network  Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajesh%2C+L+T">Lochana Telugu Rajesh</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+T">Tapadhir Das</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+R+M">Raj Mani Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Shamik Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The rapid growth in Internet of Things (IoT) technology has become an
integral part of today's industries forming the Industrial IoT (IIoT)
initiative, where industries are leveraging IoT to improve communication and
connectivity via emerging solutions like data analytics and cloud computing.
Unfortunately, the rapid use of IoT has made it an attractive target for
cybercriminals. Therefore, protecting these systems is of utmost importance. In
this paper, we propose a federated transfer learning (FTL) approach to perform
IIoT network intrusion detection. As part of the research, we also propose a
combinational neural network as the centerpiece for performing FTL. The
proposed technique splits IoT data between the client and server devices to
generate corresponding models, and the weights of the client models are
combined to update the server model. Results showcase high performance for the
FTL setup between iterations on both the IIoT clients and the server.
Additionally, the proposed FTL setup achieves better overall performance than
contemporary machine learning algorithms at performing network intrusion
detection.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07355" title="Abstract">arXiv:2310.07355</a> [<a href="/pdf/2310.07355" title="Download PDF">pdf</a>, <a href="/format/2310.07355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMITATE: Clinical Prior Guided Hierarchical Vision-Language Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sibo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anand Shah</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of medical Vision-Language Pre-training (VLP), significant
efforts have been devoted to deriving text and image features from both
clinical reports and associated medical images. However, most existing methods
may have overlooked the opportunity in leveraging the inherent hierarchical
structure of clinical reports, which are generally split into `findings' for
descriptive content and `impressions' for conclusive observation. Instead of
utilizing this rich, structured format, current medical VLP approaches often
simplify the report into either a unified entity or fragmented tokens. In this
work, we propose a novel clinical prior guided VLP framework named IMITATE to
learn the structure information from medical reports with hierarchical
vision-language alignment. The framework derives multi-level visual features
from the chest X-ray (CXR) images and separately aligns these features with the
descriptive and the conclusive text encoded in the hierarchical medical report.
Furthermore, a new clinical-informed contrastive loss is introduced for
cross-modal learning, which accounts for clinical prior knowledge in
formulating sample correlations in contrastive learning. The proposed model,
IMITATE, outperforms baseline VLP methods across six different datasets,
spanning five medical imaging downstream tasks. Comprehensive experimental
results highlight the advantages of integrating the hierarchical structure of
medical reports for vision-language alignment.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07361" title="Abstract">arXiv:2310.07361</a> [<a href="/pdf/2310.07361" title="Download PDF">pdf</a>, <a href="/format/2310.07361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization Guided by Gradient Signal to Noise Ratio of  Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michalkiewicz%2C+M">Mateusz Michalkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Faraki%2C+M">Masoud Faraki</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>, 
<a href="/search/cs?searchtype=author&query=Baktashmotlagh%2C+M">Mahsa Baktashmotlagh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper was accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Overfitting to the source domain is a common issue in gradient-based training
of deep neural networks. To compensate for the over-parameterized models,
numerous regularization techniques have been introduced such as those based on
dropout. While these methods achieve significant improvements on classical
benchmarks such as ImageNet, their performance diminishes with the introduction
of domain shift in the test set i.e. when the unseen data comes from a
significantly different distribution. In this paper, we move away from the
classical approach of Bernoulli sampled dropout mask construction and propose
to base the selection on gradient-signal-to-noise ratio (GSNR) of network's
parameters. Specifically, at each training step, parameters with high GSNR will
be discarded. Furthermore, we alleviate the burden of manually searching for
the optimal dropout ratio by leveraging a meta-learning approach. We evaluate
our method on standard domain generalization benchmarks and achieve competitive
results on classification and face anti-spoofing problems.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07365" title="Abstract">arXiv:2310.07365</a> [<a href="/pdf/2310.07365" title="Download PDF">pdf</a>, <a href="/ps/2310.07365" title="Download PostScript">ps</a>, <a href="/format/2310.07365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphControl: Adding Conditional Control to Universal Graph Pre-trained  Models for Graph Domain Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haizhou Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenshuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph-structured data is ubiquitous in the world which models complex
relationships between objects, enabling various Web applications. Daily
influxes of unlabeled graph data on the Web offer immense potential for these
applications. Graph self-supervised algorithms have achieved significant
success in acquiring generic knowledge from abundant unlabeled graph data.
These pre-trained models can be applied to various downstream Web applications,
saving training time and improving downstream (target) performance. However,
different graphs, even across seemingly similar domains, can differ
significantly in terms of attribute semantics, posing difficulties, if not
infeasibility, for transferring the pre-trained models to downstream tasks.
Concretely speaking, for example, the additional task-specific node information
in downstream tasks (specificity) is usually deliberately omitted so that the
pre-trained representation (transferability) can be leveraged. The trade-off as
such is termed as "transferability-specificity dilemma" in this work. To
address this challenge, we introduce an innovative deployment module coined as
GraphControl, motivated by ControlNet, to realize better graph domain transfer
learning. Specifically, by leveraging universal structural pre-trained models
and GraphControl, we align the input space across various graphs and
incorporate unique characteristics of target data as conditional inputs. These
conditions will be progressively integrated into the model during fine-tuning
or prompt tuning through ControlNet, facilitating personalized deployment.
Extensive experiments show that our method significantly enhances the
adaptability of pre-trained models on target attributed datasets, achieving
1.4-3x performance gain. Furthermore, it outperforms training-from-scratch
methods on target data with a comparable margin and exhibits faster
convergence.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07367" title="Abstract">arXiv:2310.07367</a> [<a href="/pdf/2310.07367" title="Download PDF">pdf</a>, <a href="/ps/2310.07367" title="Download PostScript">ps</a>, <a href="/format/2310.07367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Analysis of Sparse Linear Regression in Local Differential  Privacy Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Meng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinhui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we revisit the problem of sparse linear regression in the
local differential privacy (LDP) model. Existing research in the
non-interactive and sequentially local models has focused on obtaining the
lower bounds for the case where the underlying parameter is $1$-sparse, and
extending such bounds to the more general $k$-sparse case has proven to be
challenging. Moreover, it is unclear whether efficient non-interactive LDP
(NLDP) algorithms exist. To address these issues, we first consider the problem
in the $\epsilon$ non-interactive LDP model and provide a lower bound of
$\Omega(\frac{\sqrt{dk\log d}}{\sqrt{n}\epsilon})$ on the $\ell_2$-norm
estimation error for sub-Gaussian data, where $n$ is the sample size and $d$ is
the dimension of the space. We propose an innovative NLDP algorithm, the very
first of its kind for the problem. As a remarkable outcome, this algorithm also
yields a novel and highly efficient estimator as a valuable by-product. Our
algorithm achieves an upper bound of
$\tilde{O}({\frac{d\sqrt{k}}{\sqrt{n}\epsilon}})$ for the estimation error when
the data is sub-Gaussian, which can be further improved by a factor of
$O(\sqrt{d})$ if the server has additional public but unlabeled data. For the
sequentially interactive LDP model, we show a similar lower bound of
$\Omega({\frac{\sqrt{dk}}{\sqrt{n}\epsilon}})$. As for the upper bound, we
rectify a previous method and show that it is possible to achieve a bound of
$\tilde{O}(\frac{k\sqrt{d}}{\sqrt{n}\epsilon})$. Our findings reveal
fundamental differences between the non-private case, central DP model, and
local DP model in the sparse linear regression problem.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07370" title="Abstract">arXiv:2310.07370</a> [<a href="/pdf/2310.07370" title="Download PDF">pdf</a>, <a href="/format/2310.07370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal Random Features: Explicit Forms and Sharp Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demni%2C+N">Nizar Demni</a>, 
<a href="/search/cs?searchtype=author&query=Kadri%2C+H">Hachem Kadri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Random features have been introduced to scale up kernel methods via
randomization techniques. In particular, random Fourier features and orthogonal
random features were used to approximate the popular Gaussian kernel. The
former is performed by a random Gaussian matrix and leads exactly to the
Gaussian kernel after averaging. In this work, we analyze the bias and the
variance of the kernel approximation based on orthogonal random features which
makes use of Haar orthogonal matrices. We provide explicit expressions for
these quantities using normalized Bessel functions and derive sharp exponential
bounds supporting the view that orthogonal random features are more informative
than random Fourier features.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07375" title="Abstract">arXiv:2310.07375</a> [<a href="/pdf/2310.07375" title="Download PDF">pdf</a>, <a href="/ps/2310.07375" title="Download PostScript">ps</a>, <a href="/format/2310.07375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New analytical solution for time fractional Burgers-Huxley equation  describing the interaction between reaction mechanisms and diffusion  transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Das%2C+G">Gayatri Das</a>, 
<a href="/search/math?searchtype=author&query=Ray%2C+S+S">S. Saha Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">This manuscript studies the numerical solution of the time-fractional
Burgers-Huxley equation in a reproducing kernel Hilbert space. The analytical
solution of the equation is obtained in terms of a convergent series with
easily computable components. It is observed that the approximate solution
uniformly converges to the exact solution for the aforementioned equation.
Also, the convergence of the proposed method is investigated. Numerical
examples are given to demonstrate the validity and applicability of the
presented method. The numerical results indicate that the proposed method is
powerful and effective with a small computational overhead.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07376" title="Abstract">arXiv:2310.07376</a> [<a href="/pdf/2310.07376" title="Download PDF">pdf</a>, <a href="/format/2310.07376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud Denoising and Outlier Detection with Local Geometric  Structure by Dynamic Graph CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+K">Kosuke Nakayama</a>, 
<a href="/search/cs?searchtype=author&query=Fukuta%2C+H">Hiroto Fukuta</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+H">Hiroshi Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 12th Global Conference on Consumer Electronics (GCCE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The digitalization of society is rapidly developing toward the realization of
the digital twin and metaverse. In particular, point clouds are attracting
attention as a media format for 3D space. Point cloud data is contaminated with
noise and outliers due to measurement errors. Therefore, denoising and outlier
detection are necessary for point cloud processing. Among them, PointCleanNet
is an effective method for point cloud denoising and outlier detection.
However, it does not consider the local geometric structure of the patch. We
solve this problem by applying two types of graph convolutional layer designed
based on the Dynamic Graph CNN. Experimental results show that the proposed
methods outperform the conventional method in AUPR, which indicates outlier
detection accuracy, and Chamfer Distance, which indicates denoising accuracy.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07378" title="Abstract">arXiv:2310.07378</a> [<a href="/pdf/2310.07378" title="Download PDF">pdf</a>, <a href="/format/2310.07378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLaGA: A Reinforcement Learning Augmented Genetic Algorithm For  Searching Real and Diverse Marker-Based Landing Violations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Linfeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Morton%2C+K">Kye Morton</a>, 
<a href="/search/cs?searchtype=author&query=Kallinen%2C+V">Valtteri Kallinen</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+A">Alice James</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Avishkar Seth</a>, 
<a href="/search/cs?searchtype=author&query=Kuantama%2C+E">Endrowednes Kuantama</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+S">Subhas Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Richard Han</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xi Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automated landing for Unmanned Aerial Vehicles (UAVs), like multirotor
drones, requires intricate software encompassing control algorithms, obstacle
avoidance, and machine vision, especially when landing markers assist. Failed
landings can lead to significant costs from damaged drones or payloads and the
time spent seeking alternative landing solutions. Therefore, it's important to
fully test auto-landing systems through simulations before deploying them in
the real-world to ensure safety. This paper proposes \tool, a reinforcement
learning (RL) augmented search-based testing framework, which constructs
diverse and real marker-based landing cases that involve safety violations.
Specifically, \tool \ introduces a genetic algorithm (GA) to conservatively
search for diverse static environment configurations offline and RL to
aggressively manipulate dynamic objects' trajectories online to find potential
vulnerabilities in the target deployment environment. Quantitative results
reveal that our method generates up to 22.19\% more violation cases and nearly
doubles the diversity of generated violation cases compared to baseline
methods. Qualitatively, our method can discover those corner cases which would
be missed by state-of-the-art algorithms. We demonstrate that select types of
these corner cases can be confirmed via real-world testing with drones in the
field.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07379" title="Abstract">arXiv:2310.07379</a> [<a href="/pdf/2310.07379" title="Download PDF">pdf</a>, <a href="/format/2310.07379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Unsupervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byung-Kwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code available: <a href="https://github.com/ByungKwanLee/Causal-Unsupervised-Segmentation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Unsupervised semantic segmentation aims to achieve high-quality semantic
grouping without human-labeled annotations. With the advent of self-supervised
pre-training, various frameworks utilize the pre-trained features to train
prediction heads for unsupervised dense prediction. However, a significant
challenge in this unsupervised setup is determining the appropriate level of
clustering required for segmenting concepts. To address it, we propose a novel
framework, CAusal Unsupervised Semantic sEgmentation (CAUSE), which leverages
insights from causal inference. Specifically, we bridge intervention-oriented
approach (i.e., frontdoor adjustment) to define suitable two-step tasks for
unsupervised prediction. The first step involves constructing a concept
clusterbook as a mediator, which represents possible concept prototypes at
different levels of granularity in a discretized form. Then, the mediator
establishes an explicit link to the subsequent concept-wise self-supervised
learning for pixel-level grouping. Through extensive experiments and analyses
on various datasets, we corroborate the effectiveness of CAUSE and achieve
state-of-the-art performance in unsupervised semantic segmentation.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07380" title="Abstract">arXiv:2310.07380</a> [<a href="/pdf/2310.07380" title="Download PDF">pdf</a>, <a href="/format/2310.07380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Histopathological Image Classification and Vulnerability Analysis using  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyas%2C+S">Sankalp Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Patra%2C+A+N">Amar Nath Patra</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+R+M">Raj Mani Shukla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Healthcare is one of the foremost applications of machine learning (ML).
Traditionally, ML models are trained by central servers, which aggregate data
from various distributed devices to forecast the results for newly generated
data. This is a major concern as models can access sensitive user information,
which raises privacy concerns. A federated learning (FL) approach can help
address this issue: A global model sends its copy to all clients who train
these copies, and the clients send the updates (weights) back to it. Over time,
the global model improves and becomes more accurate. Data privacy is protected
during training, as it is conducted locally on the clients' devices.
<br />However, the global model is susceptible to data poisoning. We develop a
privacy-preserving FL technique for a skin cancer dataset and show that the
model is prone to data poisoning attacks. Ten clients train the model, but one
of them intentionally introduces flipped labels as an attack. This reduces the
accuracy of the global model. As the percentage of label flipping increases,
there is a noticeable decrease in accuracy. We use a stochastic gradient
descent optimization algorithm to find the most optimal accuracy for the model.
Although FL can protect user privacy for healthcare diagnostics, it is also
vulnerable to data poisoning, which must be addressed.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07381" title="Abstract">arXiv:2310.07381</a> [<a href="/pdf/2310.07381" title="Download PDF">pdf</a>, <a href="/format/2310.07381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremal Mechanisms for Pointwise Maximal Leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grosse%2C+L">Leonhard Grosse</a>, 
<a href="/search/cs?searchtype=author&query=Saeidian%2C+S">Sara Saeidian</a>, 
<a href="/search/cs?searchtype=author&query=Oechtering%2C+T">Tobias Oechtering</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Data publishing under privacy constraints can be achieved with mechanisms
that add randomness to data points when released to an untrusted party, thereby
decreasing the data's utility. In this paper, we analyze this privacy-utility
tradeoff for the pointwise maximal leakage privacy measure and a general class
of convex utility functions. Pointwise maximal leakage (PML) was recently
proposed as an operationally meaningful privacy measure based on two equivalent
threat models: An adversary guessing a randomized function and an adversary
aiming to maximize a general gain function. We study the behavior of the
randomized response mechanism designed for local differential privacy under
different prior distributions of the private data. Motivated by the findings of
this analysis, we derive several closed-form solutions for the optimal
privacy-utility tradeoff in the presented PML context using tools from convex
analysis. Finally, we present a linear program that can compute optimal
mechanisms for PML in a general setting.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07387" title="Abstract">arXiv:2310.07387</a> [<a href="/pdf/2310.07387" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linguistic laws in biology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Semple%2C+S">Stuart Semple</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer-i-Cancho%2C+R">Ramon Ferrer-i-Cancho</a>, 
<a href="/search/cs?searchtype=author&query=Gustison%2C+M+L">Morgan L. Gustison</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Trends in Ecology and Evolution 37(1), 53-66 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Linguistic laws, the common statistical patterns of human language, have been
investigated by quantitative linguists for nearly a century. Recently,
biologists from a range of disciplines have started to explore the prevalence
of these laws beyond language, finding patterns consistent with linguistic laws
across multiple levels of biological organisation, from molecular (genomes,
genes, and proteins) to organismal (animal behaviour) to ecological
(populations and ecosystems). We propose a new conceptual framework for the
study of linguistic laws in biology, comprising and integrating distinct levels
of analysis, from description to prediction to theory building. Adopting this
framework will provide critical new insights into the fundamental rules of
organisation underpinning natural systems, unifying linguistic laws and core
theory in biology.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07389" title="Abstract">arXiv:2310.07389</a> [<a href="/pdf/2310.07389" title="Download PDF">pdf</a>, <a href="/format/2310.07389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Reward Function for User-Preferred Appliance Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C4%8Covi%C4%87%2C+N">Nikolina &#x10c;ovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cremer%2C+J">Jochen Cremer</a>, 
<a href="/search/cs?searchtype=author&query=Pand%C5%BEi%C4%87%2C+H">Hrvoje Pand&#x17e;i&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to PSCC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Accelerated development of demand response service provision by the
residential sector is crucial for reducing carbon-emissions in the power
sector. Along with the infrastructure advancement, encouraging the end users to
participate is crucial. End users highly value their privacy and control, and
want to be included in the service design and decision-making process when
creating the daily appliance operation schedules. Furthermore, unless they are
financially or environmentally motivated, they are generally not prepared to
sacrifice their comfort to help balance the power system. In this paper, we
present an inverse-reinforcement-learning-based model that helps create the end
users' daily appliance schedules without asking them to explicitly state their
needs and wishes. By using their past consumption data, the end consumers will
implicitly participate in the creation of those decisions and will thus be
motivated to continue participating in the provision of demand response
services.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07390" title="Abstract">arXiv:2310.07390</a> [<a href="/pdf/2310.07390" title="Download PDF">pdf</a>, <a href="/format/2310.07390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LESS-Map: Lightweight and Evolving Semantic Map in Parking Lots for  Long-term Self-Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xinyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yeqiang Qian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Precise and long-term stable localization is essential in parking lots for
tasks like autonomous driving or autonomous valet parking, \textit{etc}.
Existing methods rely on a fixed and memory-inefficient map, which lacks robust
data association approaches. And it is not suitable for precise localization or
long-term map maintenance. In this paper, we propose a novel mapping,
localization, and map update system based on ground semantic features,
utilizing low-cost cameras. We present a precise and lightweight
parameterization method to establish improved data association and achieve
accurate localization at centimeter-level. Furthermore, we propose a novel map
update approach by implementing high-quality data association for parameterized
semantic features, allowing continuous map update and refinement during
re-localization, while maintaining centimeter-level accuracy. We validate the
performance of the proposed method in real-world experiments and compare it
against state-of-the-art algorithms. The proposed method achieves an average
accuracy improvement of 5cm during the registration process. The generated maps
consume only a compact size of 450 KB/km and remain adaptable to evolving
environments through continuous update.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07392" title="Abstract">arXiv:2310.07392</a> [<a href="/pdf/2310.07392" title="Download PDF">pdf</a>, <a href="/format/2310.07392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Kernel and Image Quality Estimators for Optimizing Robotic  Ultrasound Controller using Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raina%2C+D">Deepak Raina</a>, 
<a href="/search/cs?searchtype=author&query=Chandrashekhara%2C+S">SH Chandrashekhara</a>, 
<a href="/search/cs?searchtype=author&query=Voyles%2C+R">Richard Voyles</a>, 
<a href="/search/cs?searchtype=author&query=Wachs%2C+J">Juan Wachs</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S+K">Subir Kumar Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE International Symposium on Medical Robotics (ISMR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ultrasound is a commonly used medical imaging modality that requires expert
sonographers to manually maneuver the ultrasound probe based on the acquired
image. Autonomous Robotic Ultrasound (A-RUS) is an appealing alternative to
this manual procedure in order to reduce sonographers' workload. The key
challenge to A-RUS is optimizing the ultrasound image quality for the region of
interest across different patients. This requires knowledge of anatomy,
recognition of error sources and precise probe position, orientation and
pressure. Sample efficiency is important while optimizing these parameters
associated with the robotized probe controller. Bayesian Optimization (BO), a
sample-efficient optimization framework, has recently been applied to optimize
the 2D motion of the probe. Nevertheless, further improvements are needed to
improve the sample efficiency for high-dimensional control of the probe. We aim
to overcome this problem by using a neural network to learn a low-dimensional
kernel in BO, termed as Deep Kernel (DK). The neural network of DK is trained
using probe and image data acquired during the procedure. The two image quality
estimators are proposed that use a deep convolution neural network and provide
real-time feedback to the BO. We validated our framework using these two
feedback functions on three urinary bladder phantoms. We obtained over 50%
increase in sample efficiency for 6D control of the robotized probe.
Furthermore, our results indicate that this performance enhancement in BO is
independent of the specific training dataset, demonstrating inter-patient
adaptability.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07393" title="Abstract">arXiv:2310.07393</a> [<a href="/pdf/2310.07393" title="Download PDF">pdf</a>, <a href="/format/2310.07393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RANS: Highly-Parallelised Simulator for Reinforcement Learning based  Autonomous Navigating Spacecrafts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Hariry%2C+M">Matteo El-Hariry</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+A">Antoine Richard</a>, 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M">Miguel Olivares-Mendez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Nowadays, realistic simulation environments are essential to validate and
build reliable robotic solutions. This is particularly true when using
Reinforcement Learning (RL) based control policies. To this end, both robotics
and RL developers need tools and workflows to create physically accurate
simulations and synthetic datasets. Gazebo, MuJoCo, Webots, Pybullets or Isaac
Sym are some of the many tools available to simulate robotic systems.
Developing learning-based methods for space navigation is, due to the highly
complex nature of the problem, an intensive data-driven process that requires
highly parallelized simulations. When it comes to the control of spacecrafts,
there is no easy to use simulation library designed for RL. We address this gap
by harnessing the capabilities of NVIDIA Isaac Gym, where both physics
simulation and the policy training reside on GPU. Building on this tool, we
provide an open-source library enabling users to simulate thousands of parallel
spacecrafts, that learn a set of maneuvering tasks, such as position, attitude,
and velocity control. These tasks enable to validate complex space scenarios,
such as trajectory optimization for landing, docking, rendezvous and more.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07394" title="Abstract">arXiv:2310.07394</a> [<a href="/pdf/2310.07394" title="Download PDF">pdf</a>, <a href="/ps/2310.07394" title="Download PostScript">ps</a>, <a href="/format/2310.07394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP for Lightweight Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+K">Ke Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wankou Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The large-scale pretrained model CLIP, trained on 400 million image-text
pairs, offers a promising paradigm for tackling vision tasks, albeit at the
image level. Later works, such as DenseCLIP and LSeg, extend this paradigm to
dense prediction, including semantic segmentation, and have achieved excellent
results. However, the above methods either rely on CLIP-pretrained visual
backbones or use none-pretrained but heavy backbones such as Swin, while
falling ineffective when applied to lightweight backbones. The reason for this
is that the lightweitht networks, feature extraction ability of which are
relatively limited, meet difficulty embedding the image feature aligned with
text embeddings perfectly. In this work, we present a new feature fusion module
which tackles this problem and enables language-guided paradigm to be applied
to lightweight networks. Specifically, the module is a parallel design of CNN
and transformer with a two-way bridge in between, where CNN extracts spatial
information and visual context of the feature map from the image encoder, and
the transformer propagates text embeddings from the text encoder forward. The
core of the module is the bidirectional fusion of visual and text feature
across the bridge which prompts their proximity and alignment in embedding
space. The module is model-agnostic, which can not only make language-guided
lightweight semantic segmentation practical, but also fully exploit the
pretrained knowledge of language priors and achieve better performance than
previous SOTA work, such as DenseCLIP, whatever the vision backbone is.
Extensive experiments have been conducted to demonstrate the superiority of our
method.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07397" title="Abstract">arXiv:2310.07397</a> [<a href="/pdf/2310.07397" title="Download PDF">pdf</a>, <a href="/format/2310.07397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-oriented Proactive Dialogue Systems with Personalization: Problem  Formulation and Dataset Curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dongding Lin</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+C+T">Chak Tou Leong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP-2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Target-oriented dialogue systems, designed to proactively steer conversations
toward predefined targets or accomplish specific system-side goals, are an
exciting area in conversational AI. In this work, by formulating a &lt;dialogue
act, topic&gt; pair as the conversation target, we explore a novel problem of
personalized target-oriented dialogue by considering personalization during the
target accomplishment process. However, there remains an emergent need for
high-quality datasets, and building one from scratch requires tremendous human
effort. To address this, we propose an automatic dataset curation framework
using a role-playing approach. Based on this framework, we construct a
large-scale personalized target-oriented dialogue dataset, TopDial, which
comprises about 18K multi-turn dialogues. The experimental results show that
this dataset is of high quality and could contribute to exploring personalized
target-oriented dialogue.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07399" title="Abstract">arXiv:2310.07399</a> [<a href="/pdf/2310.07399" title="Download PDF">pdf</a>, <a href="/format/2310.07399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Runge-Kutta-Nystr&#xf6;m
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bou-Rabee%2C+N">Nawaf Bou-Rabee</a>, 
<a href="/search/math?searchtype=author&query=Kleppe%2C+T+S">Tore Selland Kleppe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR); Computation (stat.CO); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present 5/2- and 7/2-order $L^2$-accurate randomized Runge-Kutta-Nystr\"om
methods to approximate the Hamiltonian flow underlying various non-reversible
Markov chain Monte Carlo chains including unadjusted Hamiltonian Monte Carlo
and unadjusted kinetic Langevin chains. Quantitative 5/2-order $L^2$-accuracy
upper bounds are provided under gradient and Hessian Lipschitz assumptions on
the potential energy function. The superior complexity of the corresponding
Markov chains is numerically demonstrated for a selection of `well-behaved',
high-dimensional target distributions.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07402" title="Abstract">arXiv:2310.07402</a> [<a href="/pdf/2310.07402" title="Download PDF">pdf</a>, <a href="/format/2310.07402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenguo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xumeng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Wei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Congrui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Stephen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhirong Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent research on time-series self-supervised models shows great promise in
learning semantic representations. However, it has been limited to small-scale
datasets, e.g., thousands of temporal sequences. In this work, we make key
technical contributions that are tailored to the numerical properties of
time-series data and allow the model to scale to large datasets, e.g., millions
of temporal sequences. We adopt the Transformer architecture by first
partitioning the input into non-overlapping windows. Each window is then
characterized by its normalized shape and two scalar values denoting the mean
and standard deviation within each window. To embed scalar values that may
possess arbitrary numerical scales to high-dimensional vectors, we propose a
numerically multi-scaled embedding module enumerating all possible scales for
the scalar values. The model undergoes pretraining using the proposed
numerically multi-scaled embedding with a simple contrastive objective on a
large-scale dataset containing over a million sequences. We study its transfer
performance on a number of univariate and multivariate classification
benchmarks. Our method exhibits remarkable improvement against previous
representation learning approaches and establishes the new state of the art,
even compared with domain-specific non-learning-based methods.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07403" title="Abstract">arXiv:2310.07403</a> [<a href="/pdf/2310.07403" title="Download PDF">pdf</a>, <a href="/format/2310.07403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DASpeech: Directed Acyclic Transformer for Fast and High-quality  Speech-to-Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qingkai Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Audio samples are available at <a href="https://ictnlp.github.io/daspeech-demo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Direct speech-to-speech translation (S2ST) translates speech from one
language into another using a single model. However, due to the presence of
linguistic and acoustic diversity, the target speech follows a complex
multimodal distribution, posing challenges to achieving both high-quality
translations and fast decoding speeds for S2ST models. In this paper, we
propose DASpeech, a non-autoregressive direct S2ST model which realizes both
fast and high-quality S2ST. To better capture the complex distribution of the
target speech, DASpeech adopts the two-pass architecture to decompose the
generation process into two steps, where a linguistic decoder first generates
the target text, and an acoustic decoder then generates the target speech based
on the hidden states of the linguistic decoder. Specifically, we use the
decoder of DA-Transformer as the linguistic decoder, and use FastSpeech 2 as
the acoustic decoder. DA-Transformer models translations with a directed
acyclic graph (DAG). To consider all potential paths in the DAG during
training, we calculate the expected hidden states for each target token via
dynamic programming, and feed them into the acoustic decoder to predict the
target mel-spectrogram. During inference, we select the most probable path and
take hidden states on that path as input to the acoustic decoder. Experiments
on the CVSS Fr-En benchmark demonstrate that DASpeech can achieve comparable or
even better performance than the state-of-the-art S2ST model Translatotron 2,
while preserving up to 18.53x speedup compared to the autoregressive baseline.
Compared with the previous non-autoregressive S2ST model, DASpeech does not
rely on knowledge distillation and iterative decoding, achieving significant
improvements in both translation quality and decoding speed. Furthermore,
DASpeech shows the ability to preserve the speaker's voice of the source speech
during translation.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07405" title="Abstract">arXiv:2310.07405</a> [<a href="/pdf/2310.07405" title="Download PDF">pdf</a>, <a href="/ps/2310.07405" title="Download PostScript">ps</a>, <a href="/format/2310.07405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRS Assisted Federated Learning A Broadband Over-the-Air Aggregation  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Z">Zhibo Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lihui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider a broadband over-the-air computation empowered model aggregation
approach for wireless federated learning (FL) systems and propose to leverage
an intelligent reflecting surface (IRS) to combat wireless fading and noise. We
first investigate the conventional node-selection based framework, where a few
edge nodes are dropped in model aggregation to control the aggregation error.
We analyze the performance of this node-selection based framework and derive an
upper bound on its performance loss, which is shown to be related to the
selected edge nodes. Then, we seek to minimize the mean-squared error (MSE)
between the desired global gradient parameters and the actually received ones
by optimizing the selected edge nodes, their transmit equalization
coefficients, the IRS phase shifts, and the receive factors of the cloud
server. By resorting to the matrix lifting technique and difference-of-convex
programming, we successfully transform the formulated optimization problem into
a convex one and solve it using off-the-shelf solvers. To improve learning
performance, we further propose a weight-selection based FL framework. In such
a framework, we assign each edge node a proper weight coefficient in model
aggregation instead of discarding any of them to reduce the aggregation error,
i.e., amplitude alignment of the received local gradient parameters from
different edge nodes is not required. We also analyze the performance of this
weight-selection based framework and derive an upper bound on its performance
loss, followed by minimizing the MSE via optimizing the weight coefficients of
the edge nodes, their transmit equalization coefficients, the IRS phase shifts,
and the receive factors of the cloud server. Furthermore, we use the MNIST
dataset for simulations to evaluate the performance of both node-selection and
weight-selection based FL frameworks.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07408" title="Abstract">arXiv:2310.07408</a> [<a href="/pdf/2310.07408" title="Download PDF">pdf</a>, <a href="/format/2310.07408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Control of Reactive Brain Computer Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tufvesson%2C+P">Pex Tufvesson</a>, 
<a href="/search/eess?searchtype=author&query=Heskebeck%2C+F">Frida Heskebeck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The authors contributed equally and share first authorship
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This article discusses practical and theoretical aspects of real-time brain
computer interface control methods based on Bayesian statistics. We investigate
and improve the performance of automatic control and feedback algorithms of a
reactive brain computer interface based on a visual oddball paradigm for faster
statistical convergence. We introduce transfer learning using Gaussian mixture
models, enabling a ready-to-use setup.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07414" title="Abstract">arXiv:2310.07414</a> [<a href="/pdf/2310.07414" title="Download PDF">pdf</a>, <a href="/format/2310.07414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metamorphic Runtime Monitoring of Autonomous Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayerdi%2C+J">Jon Ayerdi</a>, 
<a href="/search/cs?searchtype=author&query=Iriarte%2C+A">Asier Iriarte</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+P">Pablo Valle</a>, 
<a href="/search/cs?searchtype=author&query=Roman%2C+I">Ibai Roman</a>, 
<a href="/search/cs?searchtype=author&query=Illarramendi%2C+M">Miren Illarramendi</a>, 
<a href="/search/cs?searchtype=author&query=Arrieta%2C+A">Aitor Arrieta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Autonomous Driving Systems (ADSs) are complex Cyber-Physical Systems (CPSs)
that must ensure safety even in uncertain conditions. Modern ADSs often employ
Deep Neural Networks (DNNs), which may not produce correct results in every
possible driving scenario. Thus, an approach to estimate the confidence of an
ADS at runtime is necessary to prevent potentially dangerous situations. In
this paper we propose MarMot, an online monitoring approach for ADSs based on
Metamorphic Relations (MRs), which are properties of a system that hold among
multiple inputs and the corresponding outputs. Using domain-specific MRs,
MarMot estimates the uncertainty of the ADS at runtime, allowing the
identification of anomalous situations that are likely to cause a faulty
behavior of the ADS, such as driving off the road.
<br />We perform an empirical assessment of MarMot with five different MRs, using a
small-scale ADS, two different circuits for training, and two additional
circuits for evaluation. Our evaluation encompasses the identification of both
external anomalies, e.g., fog, as well as internal anomalies, e.g., faulty DNNs
due to mislabeled training data. Our results show that MarMot can identify 35\%
to 65\% of the external anomalies and 77\% to 100\% of the internal anomalies,
outperforming both SelfOracle and Ensemble-based ADS monitoring approaches.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07416" title="Abstract">arXiv:2310.07416</a> [<a href="/pdf/2310.07416" title="Download PDF">pdf</a>, <a href="/format/2310.07416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Voronoi-based Convolutional Neural Network Framework for Pushing  Person Detection in Crowd Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alia%2C+A">Ahmed Alia</a>, 
<a href="/search/cs?searchtype=author&query=Maree%2C+M">Mohammed Maree</a>, 
<a href="/search/cs?searchtype=author&query=Chraibi%2C+M">Mohcine Chraibi</a>, 
<a href="/search/cs?searchtype=author&query=Seyfried%2C+A">Armin Seyfried</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Analyzing the microscopic dynamics of pushing behavior within crowds can
offer valuable insights into crowd patterns and interactions. By identifying
instances of pushing in crowd videos, a deeper understanding of when, where,
and why such behavior occurs can be achieved. This knowledge is crucial to
creating more effective crowd management strategies, optimizing crowd flow, and
enhancing overall crowd experiences. However, manually identifying pushing
behavior at the microscopic level is challenging, and the existing automatic
approaches cannot detect such microscopic behavior. Thus, this article
introduces a novel automatic framework for identifying pushing in videos of
crowds on a microscopic level. The framework comprises two main components: i)
Feature extraction and ii) Video labeling. In the feature extraction component,
a new Voronoi-based method is developed for determining the local regions
associated with each person in the input video. Subsequently, these regions are
fed into EfficientNetV1B0 Convolutional Neural Network to extract the deep
features of each person over time. In the second component, a combination of a
fully connected layer with a Sigmoid activation function is employed to analyze
these deep features and annotate the individuals involved in pushing within the
video. The framework is trained and evaluated on a new dataset created using
six real-world experiments, including their corresponding ground truths. The
experimental findings indicate that the suggested framework outperforms seven
baseline methods that are employed for comparative analysis purposes.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07417" title="Abstract">arXiv:2310.07417</a> [<a href="/pdf/2310.07417" title="Download PDF">pdf</a>, <a href="/ps/2310.07417" title="Download PostScript">ps</a>, <a href="/format/2310.07417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What can knowledge graph alignment gain with Neuro-Symbolic learning  approaches?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotovio%2C+P+G">Pedro Giesteira Cotovio</a>, 
<a href="/search/cs?searchtype=author&query=Jimenez-Ruiz%2C+E">Ernesto Jimenez-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Pesquita%2C+C">Catia Pesquita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Knowledge Graphs (KG) are the backbone of many data-intensive applications
since they can represent data coupled with its meaning and context. Aligning
KGs across different domains and providers is necessary to afford a fuller and
integrated representation. A severe limitation of current KG alignment (KGA)
algorithms is that they fail to articulate logical thinking and reasoning with
lexical, structural, and semantic data learning. Deep learning models are
increasingly popular for KGA inspired by their good performance in other tasks,
but they suffer from limitations in explainability, reasoning, and data
efficiency. Hybrid neurosymbolic learning models hold the promise of
integrating logical and data perspectives to produce high-quality alignments
that are explainable and support validation through human-centric approaches.
This paper examines the current state of the art in KGA and explores the
potential for neurosymbolic integration, highlighting promising research
directions for combining these fields.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07418" title="Abstract">arXiv:2310.07418</a> [<a href="/pdf/2310.07418" title="Download PDF">pdf</a>, <a href="/format/2310.07418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Plasticity in Visual Reinforcement Learning: Data, Modules  and Training Stages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guozheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Plasticity, the ability of a neural network to evolve with new data, is
crucial for high-performance and sample-efficient visual reinforcement learning
(VRL). Although methods like resetting and regularization can potentially
mitigate plasticity loss, the influences of various components within the VRL
framework on the agent's plasticity are still poorly understood. In this work,
we conduct a systematic empirical exploration focusing on three primary
underexplored facets and derive the following insightful conclusions: (1) data
augmentation is essential in maintaining plasticity; (2) the critic's
plasticity loss serves as the principal bottleneck impeding efficient training;
and (3) without timely intervention to recover critic's plasticity in the early
stages, its loss becomes catastrophic. These insights suggest a novel strategy
to address the high replay ratio (RR) dilemma, where exacerbated plasticity
loss hinders the potential improvements of sample efficiency brought by
increased reuse frequency. Rather than setting a static RR for the entire
training process, we propose Adaptive RR, which dynamically adjusts the RR
based on the critic's plasticity level. Extensive evaluations indicate that
Adaptive RR not only avoids catastrophic plasticity loss in the early stages
but also benefits from more frequent reuse in later phases, resulting in
superior sample efficiency.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07419" title="Abstract">arXiv:2310.07419</a> [<a href="/pdf/2310.07419" title="Download PDF">pdf</a>, <a href="/format/2310.07419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Concept T2I-Zero: Tweaking Only The Text Embeddings and Nothing  Else
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tunanyan%2C+H">Hazarapet Tunanyan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Navasardyan%2C+S">Shant Navasardyan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in text-to-image diffusion models have enabled the
photorealistic generation of images from text prompts. Despite the great
progress, existing models still struggle to generate compositional
multi-concept images naturally, limiting their ability to visualize human
imagination. While several recent works have attempted to address this issue,
they either introduce additional training or adopt guidance at inference time.
In this work, we consider a more ambitious goal: natural multi-concept
generation using a pre-trained diffusion model, and with almost no extra cost.
To achieve this goal, we identify the limitations in the text embeddings used
for the pre-trained text-to-image diffusion models. Specifically, we observe
concept dominance and non-localized contribution that severely degrade
multi-concept generation performance. We further design a minimal low-cost
solution that overcomes the above issues by tweaking (not re-training) the text
embeddings for more realistic multi-concept text-to-image generation. Our
Correction by Similarities method tweaks the embedding of concepts by
collecting semantic features from most similar tokens to localize the
contribution. To avoid mixing features of concepts, we also apply Cross-Token
Non-Maximum Suppression, which excludes the overlap of contributions from
different concepts. Experiments show that our approach outperforms previous
methods in text-to-image, image manipulation, and personalization tasks,
despite not introducing additional training or inference costs to the diffusion
steps.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07422" title="Abstract">arXiv:2310.07422</a> [<a href="/pdf/2310.07422" title="Download PDF">pdf</a>, <a href="/ps/2310.07422" title="Download PostScript">ps</a>, <a href="/format/2310.07422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Composition Theorem of a Universal Relation and Most  Functions via Effective Restriction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages,Abstract shorten due to limitation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Recently, Ivan Mihajlin and Alexander Smal proved a composition theorem of a
universal relation and some function via so called xor composition, that is
there exists some function $f:\{0,1\}^n \rightarrow \{0,1\}$ such that
$\textsf{CC}(\text{U}_n \diamond \text{KW}_f) \geq 1.5n-o(n)$ where
$\textsf{CC}$ denotes the communication complexity of the problem. In this
paper, we significantly improve their result and present an asymptotically
tight and much more general composition theorem of a universal relation and
most functions, that is for most functions $f:\{0,1\}^n \rightarrow \{0,1\}$ we
have $\textsf{CC}(\text{U}_m \diamond \text{KW}_f) \geq m+ n -O(\sqrt{m})$ when
$m=\omega(\log^2 n),n =\omega(\sqrt{m})$. This is done by a direct proof of
composition theorem of a universal relation and a multiplexor in the partially
half-duplex model avoiding the xor composition. And the proof works even when
the multiplexor only contains a few functions. One crucial ingredient in our
proof involves a combinatorial problem of constructing a tree of many leaves
and every leaf contains a non-overlapping set of functions. For each leaf,
there is a set of inputs such that every function in the leaf takes the same
value, that is all functions are restricted. We show how to choose a set of
good inputs to effectively restrict these functions to force that the number of
functions in each leaf is as small as possible while maintaining the total
number of functions in all leaves. This results in a large number of leaves.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07423" title="Abstract">arXiv:2310.07423</a> [<a href="/pdf/2310.07423" title="Download PDF">pdf</a>, <a href="/format/2310.07423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting the adapters for code-switching in multilingual ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Atharva Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Ajinkya Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Couceiro%2C+M">Miguel Couceiro</a>, 
<a href="/search/cs?searchtype=author&query=Aldarmaki%2C+H">Hanan Aldarmaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, large pre-trained multilingual speech models have shown potential
in scaling Automatic Speech Recognition (ASR) to many low-resource languages.
Some of these models employ language adapters in their formulation, which helps
to improve monolingual performance and avoids some of the drawbacks of
multi-lingual modeling on resource-rich languages. However, this formulation
restricts the usability of these models on code-switched speech, where two
languages are mixed together in the same utterance. In this work, we propose
ways to effectively fine-tune such models on code-switched speech, by
assimilating information from both language adapters at each language
adaptation point in the network. We also model code-switching as a sequence of
latent binary sequences that can be used to guide the flow of information from
each language adapter at the frame level. The proposed approaches are evaluated
on three code-switched datasets encompassing Arabic, Mandarin, and Hindi
languages paired with English, showing consistent improvements in
code-switching performance with at least 10\% absolute reduction in CER across
all test sets.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07424" title="Abstract">arXiv:2310.07424</a> [<a href="/pdf/2310.07424" title="Download PDF">pdf</a>, <a href="/format/2310.07424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical Die-to-Die 3D Placement with Bistratal Wirelength Model and  GPU Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+P">Peiyu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dawei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yibo Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In this paper, we present a new analytical 3D placement framework with a
bistratal wirelength model for F2F-bonded 3D ICs with heterogeneous technology
nodes based on the electrostatic-based density model. The proposed framework,
enabled GPU-acceleration, is capable of efficiently determining node
partitioning and locations simultaneously, leveraging the dedicated 3D
wirelength model and density model. The experimental results on ICCAD 2022
contest benchmarks demonstrate that our proposed 3D placement framework can
achieve up to 6.1% wirelength improvement and 4.1% on average compared to the
first-place winner with much fewer vertical interconnections and up to 9.8x
runtime speedup. Notably, the proposed framework also outperforms the
state-of-the-art 3D analytical placer by up to 3.3% wirelength improvement and
2.1% on average with up to 8.8x acceleration on large cases using GPUs.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07427" title="Abstract">arXiv:2310.07427</a> [<a href="/pdf/2310.07427" title="Download PDF">pdf</a>, <a href="/format/2310.07427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Enhanced Forecasting: Leveraging Quantum Gramian Angular Field  and CNNs for Stock Return Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengmeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hai Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Finance (q-fin.CP)

</div>
<p class="mathjax">We propose a time series forecasting method named Quantum Gramian Angular
Field (QGAF). This approach merges the advantages of quantum computing
technology with deep learning, aiming to enhance the precision of time series
classification and forecasting. We successfully transformed stock return time
series data into two-dimensional images suitable for Convolutional Neural
Network (CNN) training by designing specific quantum circuits. Distinct from
the classical Gramian Angular Field (GAF) approach, QGAF's uniqueness lies in
eliminating the need for data normalization and inverse cosine calculations,
simplifying the transformation process from time series data to two-dimensional
images. To validate the effectiveness of this method, we conducted experiments
on datasets from three major stock markets: the China A-share market, the Hong
Kong stock market, and the US stock market. Experimental results revealed that
compared to the classical GAF method, the QGAF approach significantly improved
time series prediction accuracy, reducing prediction errors by an average of
25\% for Mean Absolute Error (MAE) and 48\% for Mean Squared Error (MSE). This
research confirms the potential and promising prospects of integrating quantum
computing with deep learning techniques in financial time series forecasting.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07430" title="Abstract">arXiv:2310.07430</a> [<a href="/pdf/2310.07430" title="Download PDF">pdf</a>, <a href="/format/2310.07430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-backtracking Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonghyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+N">Narae Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gahee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+D">Dongyeop Woo</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungsoo Ahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The celebrated message-passing updates for graph neural networks allow the
representation of large-scale graphs with local and computationally tractable
updates. However, the local updates suffer from backtracking, i.e., a message
flows through the same edge twice and revisits the previously visited node.
Since the number of message flows increases exponentially with the number of
updates, the redundancy in local updates prevents the graph neural network from
accurately recognizing a particular message flow for downstream tasks. In this
work, we propose to resolve such a redundancy via the non-backtracking graph
neural network (NBA-GNN) that updates a message without incorporating the
message from the previously visited node. We further investigate how NBA-GNN
alleviates the over-squashing of GNNs, and establish a connection between
NBA-GNN and the impressive performance of non-backtracking updates for
stochastic block model recovery. We empirically verify the effectiveness of our
NBA-GNN on long-range graph benchmark and transductive node classification
problems.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07431" title="Abstract">arXiv:2310.07431</a> [<a href="/pdf/2310.07431" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Adaptive Compensation of External Disturbances for Multi-Channel  Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bui%2C+V+H">V.H. Bui</a>, 
<a href="/search/eess?searchtype=author&query=Margun%2C+A+A">A.A. Margun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a new algorithm for compensating external disturbances
for class of multi-channel linear systems. The solution to this problem is
based on the use of the internal model principle and the extended error
adaptation algorithm. It is assumed that the disturbance is the output of an
autonomous linear generator with unknown parameters. At the first stage, a
full-order observer with unknown input signals (Unknown Input Observer - UIO)
is synthesized to solve the problem of estimating the state vector of this
plant. Then a new observer of external disturbance is formed on the basis of
state vector estimations. At the last stage, based on the new observer's
estimations, a system with an extended state vector is formed for which a
regulator providing compensation of disturbance is constructed. The performance
of the obtained results is confirmed using computer simulation in MATLAB
Simulink.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07433" title="Abstract">arXiv:2310.07433</a> [<a href="/pdf/2310.07433" title="Download PDF">pdf</a>, <a href="/format/2310.07433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Learning from Observation with Automatic Discount Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weijun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yingdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhao-Heng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chongjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans often acquire new skills through observation and imitation. For
robotic agents, learning from the plethora of unlabeled video demonstration
data available on the Internet necessitates imitating the expert without access
to its action, presenting a challenge known as Imitation Learning from
Observations (ILfO). A common approach to tackle ILfO problems is to convert
them into inverse reinforcement learning problems, utilizing a proxy reward
computed from the agent's and the expert's observations. Nonetheless, we
identify that tasks characterized by a progress dependency property pose
significant challenges for such approaches; in these tasks, the agent needs to
initially learn the expert's preceding behaviors before mastering the
subsequent ones. Our investigation reveals that the main cause is that the
reward signals assigned to later steps hinder the learning of initial
behaviors. To address this challenge, we present a novel ILfO framework that
enables the agent to master earlier behaviors before advancing to later ones.
We introduce an Automatic Discount Scheduling (ADS) mechanism that adaptively
alters the discount factor in reinforcement learning during the training phase,
prioritizing earlier rewards initially and gradually engaging later rewards
only when the earlier behaviors have been mastered. Our experiments, conducted
on nine Meta-World tasks, demonstrate that our method significantly outperforms
state-of-the-art methods across all tasks, including those that are unsolvable
by them.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07434" title="Abstract">arXiv:2310.07434</a> [<a href="/pdf/2310.07434" title="Download PDF">pdf</a>, <a href="/format/2310.07434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HealthWalk: Promoting Health and Mobility through Sensor-Based Rollator  Walker Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kramer%2C+I">Ivanna Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Weirauch%2C+K">Kevin Weirauch</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+S">Sabine Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Mints%2C+M+O">Mark Oliver Mints</a>, 
<a href="/search/cs?searchtype=author&query=Neubert%2C+P">Peer Neubert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Rollator walkers allow people with physical limitations to increase their
mobility and give them the confidence and independence to participate in
society for longer. However, rollator walker users often have poor posture,
leading to further health problems and, in the worst case, falls. Integrating
sensors into rollator walker designs can help to address this problem and
results in a platform that allows several other interesting use cases. This
paper briefly overviews existing systems and the current research directions
and challenges in this field. We also present our early HealthWalk rollator
walker prototype for data collection with older people, rheumatism, multiple
sclerosis and Parkinson patients, and individuals with visual impairments.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07435" title="Abstract">arXiv:2310.07435</a> [<a href="/pdf/2310.07435" title="Download PDF">pdf</a>, <a href="/format/2310.07435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Mixture Model for Extreme Events Forecasting in Time Series  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jincheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time Series Forecasting (TSF) is a widely researched topic with broad
applications in weather forecasting, traffic control, and stock price
prediction. Extreme values in time series often significantly impact human and
natural systems, but predicting them is challenging due to their rare
occurrence. Statistical methods based on Extreme Value Theory (EVT) provide a
systematic approach to modeling the distribution of extremes, particularly the
Generalized Pareto (GP) distribution for modeling the distribution of
exceedances beyond a threshold. To overcome the subpar performance of deep
learning in dealing with heavy-tailed data, we propose a novel framework to
enhance the focus on extreme events. Specifically, we propose a Deep Extreme
Mixture Model with Autoencoder (DEMMA) for time series prediction. The model
comprises two main modules: 1) a generalized mixture distribution based on the
Hurdle model and a reparameterized GP distribution form independent of the
extreme threshold, 2) an Autoencoder-based LSTM feature extractor and a
quantile prediction module with a temporal attention mechanism. We demonstrate
the effectiveness of our approach on multiple real-world rainfall datasets.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07438" title="Abstract">arXiv:2310.07438</a> [<a href="/pdf/2310.07438" title="Download PDF">pdf</a>, <a href="/format/2310.07438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DESTINE: Dynamic Goal Queries with Temporal Transductive Alignment for  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karim%2C+R">Rezaul Karim</a>, 
<a href="/search/cs?searchtype=author&query=Shabestary%2C+S+M+A">Soheil Mohamad Alizadeh Shabestary</a>, 
<a href="/search/cs?searchtype=author&query=Rasouli%2C+A">Amir Rasouli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 tables 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Predicting temporally consistent road users' trajectories in a multi-agent
setting is a challenging task due to unknown characteristics of agents and
their varying intentions. Besides using semantic map information and modeling
interactions, it is important to build an effective mechanism capable of
reasoning about behaviors at different levels of granularity. To this end, we
propose Dynamic goal quErieS with temporal Transductive alIgNmEnt (DESTINE)
method. Unlike past arts, our approach 1) dynamically predicts agents' goals
irrespective of particular road structures, such as lanes, allowing the method
to produce a more accurate estimation of destinations; 2) achieves map
compliant predictions by generating future trajectories in a coarse-to-fine
fashion, where the coarser predictions at a lower frame rate serve as
intermediate goals; and 3) uses an attention module designed to temporally
align predicted trajectories via masked attention. Using the common Argoverse
benchmark dataset, we show that our method achieves state-of-the-art
performance on various metrics, and further investigate the contributions of
proposed modules via comprehensive ablation studies.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07440" title="Abstract">arXiv:2310.07440</a> [<a href="/pdf/2310.07440" title="Download PDF">pdf</a>, <a href="/format/2310.07440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-based Weighted Transformer Network for Image Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shamsolmoali%2C+P">Pourya Shamsolmoali</a>, 
<a href="/search/cs?searchtype=author&query=Zareapoor%2C+M">Masoumeh Zareapoor</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huiyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yue Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The challenge of image generation has been effectively modeled as a problem
of structure priors or transformation. However, existing models have
unsatisfactory performance in understanding the global input image structures
because of particular inherent features (for example, local inductive prior).
Recent studies have shown that self-attention is an efficient modeling
technique for image completion problems. In this paper, we propose a new
architecture that relies on Distance-based Weighted Transformer (DWT) to better
understand the relationships between an image's components. In our model, we
leverage the strengths of both Convolutional Neural Networks (CNNs) and DWT
blocks to enhance the image completion process. Specifically, CNNs are used to
augment the local texture information of coarse priors and DWT blocks are used
to recover certain coarse textures and coherent visual structures. Unlike
current approaches that generally use CNNs to create feature maps, we use the
DWT to encode global dependencies and compute distance-based weighted feature
maps, which substantially minimizes the problem of visual ambiguities.
Meanwhile, to better produce repeated textures, we introduce Residual Fast
Fourier Convolution (Res-FFC) blocks to combine the encoder's skip features
with the coarse features provided by our generator. Furthermore, a simple yet
effective technique is proposed to normalize the non-zero values of
convolutions, and fine-tune the network layers for regularization of the
gradient norms to provide an efficient training stabiliser. Extensive
quantitative and qualitative experiments on three challenging datasets
demonstrate the superiority of our proposed model compared to existing
approaches.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07446" title="Abstract">arXiv:2310.07446</a> [<a href="/pdf/2310.07446" title="Download PDF">pdf</a>, <a href="/format/2310.07446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProbTS: A Unified Toolkit to Probe Deep Time-series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xumeng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time-series forecasting serves as a linchpin in a myriad of applications,
spanning various domains. With the growth of deep learning, this arena has
bifurcated into two salient branches: one focuses on crafting specific neural
architectures tailored for time series, and the other harnesses advanced deep
generative models for probabilistic forecasting. While both branches have made
significant progress, their differences across data scenarios, methodological
focuses, and decoding schemes pose profound, yet unexplored, research
questions. To bridge this knowledge chasm, we introduce ProbTS, a pioneering
toolkit developed to synergize and compare these two distinct branches. Endowed
with a unified data module, a modularized model module, and a comprehensive
evaluator module, ProbTS allows us to revisit and benchmark leading methods
from both branches. The scrutiny with ProbTS highlights their distinct
characteristics, relative strengths and weaknesses, and areas that need further
exploration. Our analyses point to new avenues for research, aiming for more
effective time-series forecasting.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07448" title="Abstract">arXiv:2310.07448</a> [<a href="/pdf/2310.07448" title="Download PDF">pdf</a>, <a href="/format/2310.07448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Location in Combinatorial Interaction Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dougherty%2C+R+E">Ryan E. Dougherty</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+D+N">Dylan N. Green</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G+M">Grace M. Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Factors within a large-scale software system that simultaneously interact and
strongly impact the system's response under a configuration are often difficult
to identify. Although screening such a system for the existence of such
interactions is important, determining their location is more useful for system
engineers. Combinatorial interaction testing (CIT) concerns creation of test
suites that nonadaptively either detect or locate the desired interactions,
each of at most a specified size or show that no such set exists. Under the
assumption that there are at most a given number of such interactions causing
such a response, locating arrays (LAs) guarantee unique location for every such
set of interactions and an algorithm to deal with outliers and nondeterministic
behavior from real systems, we additionally require the LAs to have a
"separation" between these collections. State-of-the-art approaches generate
LAs that can locate at most one interaction of size at most three, due to the
massive number of interaction combinations for larger parameters if no
constraints are given. This paper presents LocAG, a two-stage algorithm that
generates (unconstrained) LAs using a simple, but powerful partitioning
strategy of these combinations. In particular, we are able to generate LAs with
more factors, with any desired separation, and greater interaction size than
existing approaches.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07449" title="Abstract">arXiv:2310.07449</a> [<a href="/pdf/2310.07449" title="Download PDF">pdf</a>, <a href="/format/2310.07449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoRF: Pose Residual Field for Accurate Neural Surface Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jia-Wang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Wenjing Bian</a>, 
<a href="/search/cs?searchtype=author&query=Prisacariu%2C+V+A">Victor Adrian Prisacariu</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural surface reconstruction is sensitive to the camera pose noise, even if
state-of-the-art pose estimators like COLMAP or ARKit are used. More
importantly, existing Pose-NeRF joint optimisation methods have struggled to
improve pose accuracy in challenging real-world scenarios. To overcome the
challenges, we introduce the pose residual field (\textbf{PoRF}), a novel
implicit representation that uses an MLP for regressing pose updates. This is
more robust than the conventional pose parameter optimisation due to parameter
sharing that leverages global information over the entire sequence.
Furthermore, we propose an epipolar geometry loss to enhance the supervision
that leverages the correspondences exported from COLMAP results without the
extra computational overhead. Our method yields promising results. On the DTU
dataset, we reduce the rotation error by 78\% for COLMAP poses, leading to the
decreased reconstruction Chamfer distance from 3.48mm to 0.85mm. On the
MobileBrick dataset that contains casually captured unbounded 360-degree
videos, our method refines ARKit poses and improves the reconstruction F1 score
from 69.18 to 75.67, outperforming that with the dataset provided ground-truth
pose (75.14). These achievements demonstrate the efficacy of our approach in
refining camera poses and improving the accuracy of neural surface
reconstruction in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07458" title="Abstract">arXiv:2310.07458</a> [<a href="/pdf/2310.07458" title="Download PDF">pdf</a>, <a href="/format/2310.07458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealityDrop: A Multimodal Mixed Reality Framework to Manipulate Virtual  Content between Cross-system Displays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDade%2C+J">Jeremy McDade</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+A">Allison Jing</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+A">Andrew Cunningham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this poster, we present RealityDrop, a novel multimodal framework that
uses Mixed Reality (MR) technology to manipulate, display, and transfer virtual
content across different display systems. Employing MR as the centre of
control, RealityDrop affords concise information dissemination among diverse
collaborators, through varied representations that best fit each display
system's unique features using `superhuman' gaze and gesture interactions.
Three multimodal interaction techniques, a customised content interpreter, and
two cross-system interfaces are incorporated for fluent content manipulation
and presentation.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07461" title="Abstract">arXiv:2310.07461</a> [<a href="/pdf/2310.07461" title="Download PDF">pdf</a>, <a href="/format/2310.07461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient machine-learning surrogates for large-scale geological carbon  and energy storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadeethum%2C+T">Teeratorn Kadeethum</a>, 
<a href="/search/cs?searchtype=author&query=Verzi%2C+S+J">Stephen J. Verzi</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hongkyu Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Geological carbon and energy storage are pivotal for achieving net-zero
carbon emissions and addressing climate change. However, they face
uncertainties due to geological factors and operational limitations, resulting
in possibilities of induced seismic events or groundwater contamination. To
overcome these challenges, we propose a specialized machine-learning (ML) model
to manage extensive reservoir models efficiently.
<br />While ML approaches hold promise for geological carbon storage, the
substantial computational resources required for large-scale analysis are the
obstacle. We've developed a method to reduce the training cost for deep neural
operator models, using domain decomposition and a topology embedder to link
spatio-temporal points. This approach allows accurate predictions within the
model's domain, even for untrained data, enhancing ML efficiency for
large-scale geological storage applications.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07465" title="Abstract">arXiv:2310.07465</a> [<a href="/pdf/2310.07465" title="Download PDF">pdf</a>, <a href="/format/2310.07465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic study on liar&#x27;s vertex-edge domination problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+D">Debojyoti Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Subhabrata Paul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">A vertex set $L\subseteq V$ is liar's vertex-edge dominating set of a graph
$G=(V,E)$ if for every $e_i\in E$, $|N_G[e_i]\cap L|\geq 2$ and for every pair
of distinct edges $e_i$ and $e_j$, $|(N_G[e_i]\cup N_G[e_j])\cap L|\geq 3$. In
this paper, we introduce the notion of liar's vertex-edge domination which
arise naturally from some application in communication network. Given a graph
$G$, the \textsc{Minimum Liar's Vertex-Edge Domination Problem}
(\textsc{MinLVEDP}) asks to find a minimum liar's vertex-edge dominating set of
$G$ of minimum cardinality. We have studied this problem from algorithmic point
of view. We show that \textsc{MinLVEDP} can be solved in linear time for trees,
whereas the decision version of this problem is NP-complete for general graphs.
We further study approximation algorithms for this problem. We propose an
$O(\ln \Delta(G))$-approximation algorithm for \textsc{MinLVEDP} in general
graphs, where $\Delta(G)$ is the maximum degree of the input graph.
<br />On the negative side, we show that the \textsc{MinLVEDP} cannot be
approximated within $\frac{1}{2}(\frac{1}{8}-\epsilon)\ln|V|$ for any $\epsilon
&gt;0$, unless $NP\subseteq DTIME(|V|^{O(\log(\log|V|)})$.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07467" title="Abstract">arXiv:2310.07467</a> [<a href="/pdf/2310.07467" title="Download PDF">pdf</a>, <a href="/format/2310.07467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI/ML-based Load Prediction in IEEE 802.11 Enterprise Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilhelmi%2C+F">Francesc Wilhelmi</a>, 
<a href="/search/cs?searchtype=author&query=Salami%2C+D">Dariush Salami</a>, 
<a href="/search/cs?searchtype=author&query=Fontanesi%2C+G">Gianluca Fontanesi</a>, 
<a href="/search/cs?searchtype=author&query=Galati-Giordano%2C+L">Lorenzo Galati-Giordano</a>, 
<a href="/search/cs?searchtype=author&query=Kasslin%2C+M">Mika Kasslin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Enterprise Wi-Fi networks can greatly benefit from Artificial Intelligence
and Machine Learning (AI/ML) thanks to their well-developed management and
operation capabilities. At the same time, AI/ML-based traffic/load prediction
is one of the most appealing data-driven solutions to improve the Wi-Fi
experience, either through the enablement of autonomous operation or by
boosting troubleshooting with forecasted network utilization. In this paper, we
study the suitability and feasibility of adopting AI/ML-based load prediction
in practical enterprise Wi-Fi networks. While leveraging AI/ML solutions can
potentially contribute to optimizing Wi-Fi networks in terms of energy
efficiency, performance, and reliability, their effective adoption is
constrained to aspects like data availability and quality, computational
capabilities, and energy consumption. Our results show that
hardware-constrained AI/ML models can potentially predict network load with
less than 20% average error and 3% 85th-percentile error, which constitutes a
suitable input for proactively driving Wi-Fi network optimization.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07471" title="Abstract">arXiv:2310.07471</a> [<a href="/pdf/2310.07471" title="Download PDF">pdf</a>, <a href="/format/2310.07471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Implications of Decentralization in Blockchained Federated Learning:  Evaluating the Impact of Model Staleness and Inconsistencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilhelmi%2C+F">Francesc Wilhelmi</a>, 
<a href="/search/cs?searchtype=author&query=Afraz%2C+N">Nima Afraz</a>, 
<a href="/search/cs?searchtype=author&query=Guerra%2C+E">Elia Guerra</a>, 
<a href="/search/cs?searchtype=author&query=Dini%2C+P">Paolo Dini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Blockchain promises to enhance distributed machine learning (ML) approaches
such as federated learning (FL) by providing further decentralization,
security, immutability, and trust, which are key properties for enabling
collaborative intelligence in next-generation applications. Nonetheless, the
intrinsic decentralized operation of peer-to-peer (P2P) blockchain nodes leads
to an uncharted setting for FL, whereby the concepts of FL round and global
model become meaningless, as devices' synchronization is lost without the
figure of a central orchestrating server. In this paper, we study the practical
implications of outsourcing the orchestration of FL to a democratic network
such as in a blockchain. In particular, we focus on the effects that model
staleness and inconsistencies, endorsed by blockchains' modus operandi, have on
the training procedure held by FL devices asynchronously. Using simulation, we
evaluate the blockchained FL operation on the well-known CIFAR-10 dataset and
focus on the accuracy and timeliness of the solutions. Our results show the
high impact of model inconsistencies on the accuracy of the models (up to a
~35% decrease in prediction accuracy), which underscores the importance of
properly designing blockchain systems based on the characteristics of the
underlying FL application.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07472" title="Abstract">arXiv:2310.07472</a> [<a href="/pdf/2310.07472" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ontology of Co-Creative AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M">Mark Riedl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to NeurIPS Workshop on ML for Creativity and Design 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The term co-creativity has been used to describe a wide variety of human-AI
assemblages in which human and AI are both involved in a creative endeavor. In
order to assist with disambiguating research efforts, we present an ontology of
co-creative systems, focusing on how responsibilities are divided between human
and AI system and the information exchanged between them. We extend Lubart's
original ontology of creativity support tools with three new categories
emphasizing artificial intelligence: computer-as-subcontractor,
computer-as-critic, and computer-as-teammate, some of which have
sub-categorizations.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07473" title="Abstract">arXiv:2310.07473</a> [<a href="/pdf/2310.07473" title="Download PDF">pdf</a>, <a href="/format/2310.07473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FGPrompt: Fine-grained Goal Prompting for Image-goal Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jugang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+H">Thomas H. Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingkui Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Learning to navigate to an image-specified goal is an important but
challenging task for autonomous systems. The agent is required to reason the
goal location from where a picture is shot. Existing methods try to solve this
problem by learning a navigation policy, which captures semantic features of
the goal image and observation image independently and lastly fuses them for
predicting a sequence of navigation actions. However, these methods suffer from
two major limitations. 1) They may miss detailed information in the goal image,
and thus fail to reason the goal location. 2) More critically, it is hard to
focus on the goal-relevant regions in the observation image, because they
attempt to understand observation without goal conditioning. In this paper, we
aim to overcome these limitations by designing a Fine-grained Goal Prompting
(FGPrompt) method for image-goal navigation. In particular, we leverage
fine-grained and high-resolution feature maps in the goal image as prompts to
perform conditioned embedding, which preserves detailed information in the goal
image and guides the observation encoder to pay attention to goal-relevant
regions. Compared with existing methods on the image-goal navigation benchmark,
our method brings significant performance improvement on 3 benchmark datasets
(i.e., Gibson, MP3D, and HM3D). Especially on Gibson, we surpass the
state-of-the-art success rate by 8% with only 1/50 model size. Project page:
https://xinyusun.github.io/fgprompt-pages
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07475" title="Abstract">arXiv:2310.07475</a> [<a href="/pdf/2310.07475" title="Download PDF">pdf</a>, <a href="/ps/2310.07475" title="Download PostScript">ps</a>, <a href="/format/2310.07475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spike-time encoding of gas concentrations using neuromorphic analog  sensory front-end
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+S">Shavika Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Dennler%2C+N">Nik Dennler</a>, 
<a href="/search/cs?searchtype=author&query=Schmuker%2C+M">Michael Schmuker</a>, 
<a href="/search/cs?searchtype=author&query=van+Schaik%2C+A">Andr&#xe9; van Schaik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Gas concentration detection is important for applications such as gas leakage
monitoring. Metal Oxide (MOx) sensors show high sensitivities for specific
gases, which makes them particularly useful for such monitoring applications.
However, how to efficiently sample and further process the sensor responses
remains an open question. Here we propose a simple analog circuit design
inspired by the spiking output of the mammalian olfactory bulb and by
event-based vision sensors. Our circuit encodes the gas concentration in the
time difference between the pulses of two separate pathways. We show that in
the setting of controlled airflow-embedded gas injections, the time difference
between the two generated pulses varies inversely with gas concentration, which
is in agreement with the spike timing difference between tufted cells and
mitral cells of the mammalian olfactory bulb. Encoding concentration
information in analog spike timings may pave the way for rapid and efficient
gas detection, and ultimately lead to data- and power-efficient monitoring
devices to be deployed in uncontrolled and turbulent environments.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07477" title="Abstract">arXiv:2310.07477</a> [<a href="/pdf/2310.07477" title="Download PDF">pdf</a>, <a href="/format/2310.07477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized  Adaptive Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Ting Long</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Liang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Q">Qichen Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+D">Dingyin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Computerized Adaptive Testing(CAT) refers to an online system that adaptively
selects the best-suited question for students with various abilities based on
their historical response records. Most CAT methods only focus on the quality
objective of predicting the student ability accurately, but neglect concept
diversity or question exposure control, which are important considerations in
ensuring the performance and validity of CAT. Besides, the students' response
records contain valuable relational information between questions and knowledge
concepts. The previous methods ignore this relational information, resulting in
the selection of sub-optimal test questions. To address these challenges, we
propose a Graph-Enhanced Multi-Objective method for CAT (GMOCAT). Firstly,
three objectives, namely quality, diversity and novelty, are introduced into
the Scalarized Multi-Objective Reinforcement Learning framework of CAT, which
respectively correspond to improving the prediction accuracy, increasing the
concept diversity and reducing the question exposure. We use an Actor-Critic
Recommender to select questions and optimize three objectives simultaneously by
the scalarization function. Secondly, we utilize the graph neural network to
learn relation-aware embeddings of questions and concepts. These embeddings are
able to aggregate neighborhood information in the relation graphs between
questions and concepts. We conduct experiments on three real-world educational
datasets, and show that GMOCAT not only outperforms the state-of-the-art
methods in the ability prediction, but also achieve superior performance in
improving the concept diversity and alleviating the question exposure. Our code
is available at https://github.com/justarter/GMOCAT.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07478" title="Abstract">arXiv:2310.07478</a> [<a href="/pdf/2310.07478" title="Download PDF">pdf</a>, <a href="/format/2310.07478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Graph Learning for Generative Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+M">Minji Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+J+Y">Jing Yu Koh</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multimodal learning combines multiple data modalities, broadening the types
and complexity of data our models can utilize: for example, from plain text to
image-caption pairs. Most multimodal learning algorithms focus on modeling
simple one-to-one pairs of data from two modalities, such as image-caption
pairs, or audio-text pairs. However, in most real-world settings, entities of
different modalities interact with each other in more complex and multifaceted
ways, going beyond one-to-one mappings. We propose to represent these complex
relationships as graphs, allowing us to capture data with any number of
modalities, and with complex relationships between modalities that can flexibly
vary from one sample to another. Toward this goal, we propose Multimodal Graph
Learning (MMGL), a general and systematic framework for capturing information
from multiple multimodal neighbors with relational structures among them. In
particular, we focus on MMGL for generative tasks, building upon pretrained
Language Models (LMs), aiming to augment their text generation with multimodal
neighbor contexts. We study three research questions raised by MMGL: (1) how
can we infuse multiple neighbor information into the pretrained LMs, while
avoiding scalability issues? (2) how can we infuse the graph structure
information among multimodal neighbors into the LMs? and (3) how can we
finetune the pretrained LMs to learn from the neighbor context in a
parameter-efficient manner? We conduct extensive experiments to answer these
three questions on MMGL and analyze the empirical results to pave the way for
future MMGL research.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07480" title="Abstract">arXiv:2310.07480</a> [<a href="/pdf/2310.07480" title="Download PDF">pdf</a>, <a href="/format/2310.07480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3bc;$TAS: Design and implementation of Time Aware Shaper on SmartNICs to  achieve bounded latency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+J">Joydeep Pal</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+D">Deepak Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Gnani%2C+N+K">Nithish Krishnabharathi Gnani</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+C">Chandramani Singh</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+T+V">T. V. Prabhakar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Time-Aware Shaper (TAS) is a time-triggered scheduling mechanism that ensures
bounded latency for time-critical Scheduled Traffic (ST) flows. The Linux
kernel implementation (a.k.a TAPRIO) has limited capabilities due to varying
CPU workloads and thus does not offer tight latency bound for the ST flows.
Also, currently only higher cycle times are possible. Other software
implementations are limited to simulation studies without physical
implementation. In this paper, we present $\mu$TAS, a MicroC-based hardware
implementation of TAS onto a programmable SmartNIC. $\mu$TAS takes advantage of
the parallel-processing architecture of the SmartNIC to configure the
scheduling behaviour of its queues at runtime. To demonstrate the effectiveness
of $\mu$TAS, we built a Time-Sensitive Networking (TSN) testbed from scratch.
This consists of multiple end-hosts capable of generating ST and Best Effort
(BE) flows and TSN switches equipped with SmartNICs running $\mu$TAS. Time
synchronization is maintained between the switches and hosts. Our experiments
demonstrate that the ST flows experience a bounded latency of the order of tens
of microseconds.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07485" title="Abstract">arXiv:2310.07485</a> [<a href="/pdf/2310.07485" title="Download PDF">pdf</a>, <a href="/format/2310.07485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear embeddings for conserving Hamiltonians and other quantities  with Neural Galerkin schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schwerdtner%2C+P">Paul Schwerdtner</a>, 
<a href="/search/math?searchtype=author&query=Schulze%2C+P">Philipp Schulze</a>, 
<a href="/search/math?searchtype=author&query=Berman%2C+J">Jules Berman</a>, 
<a href="/search/math?searchtype=author&query=Peherstorfer%2C+B">Benjamin Peherstorfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This work focuses on the conservation of quantities such as Hamiltonians,
mass, and momentum when solution fields of partial differential equations are
approximated with nonlinear parametrizations such as deep networks. The
proposed approach builds on Neural Galerkin schemes that are based on the
Dirac--Frenkel variational principle to train nonlinear parametrizations
sequentially in time. We first show that only adding constraints that aim to
conserve quantities in continuous time can be insufficient because the
nonlinear dependence on the parameters implies that even quantities that are
linear in the solution fields become nonlinear in the parameters and thus are
challenging to discretize in time. Instead, we propose Neural Galerkin schemes
that compute at each time step an explicit embedding onto the manifold of
nonlinearly parametrized solution fields to guarantee conservation of
quantities. The embeddings can be combined with standard explicit and implicit
time integration schemes. Numerical experiments demonstrate that the proposed
approach conserves quantities up to machine precision.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07487" title="Abstract">arXiv:2310.07487</a> [<a href="/pdf/2310.07487" title="Download PDF">pdf</a>, <a href="/format/2310.07487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognate Transformer for Automated Phonological Reconstruction and  Cognate Reflex Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akavarapu%2C+V+S+D+S+M">V.S.D.S. Mahesh Akavarapu</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Arnab Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to appear at the conference of EMNLP-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Phonological reconstruction is one of the central problems in historical
linguistics where a proto-word of an ancestral language is determined from the
observed cognate words of daughter languages. Computational approaches to
historical linguistics attempt to automate the task by learning models on
available linguistic data. Several ideas and techniques drawn from
computational biology have been successfully applied in the area of
computational historical linguistics. Following these lines, we adapt MSA
Transformer, a protein language model, to the problem of automated phonological
reconstruction. MSA Transformer trains on multiple sequence alignments as input
and is, thus, apt for application on aligned cognate words. We, hence, name our
model as Cognate Transformer. We also apply the model on another associated
task, namely, cognate reflex prediction, where a reflex word in a daughter
language is predicted based on cognate words from other daughter languages. We
show that our model outperforms the existing models on both tasks, especially
when it is pre-trained on masked word prediction task.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07488" title="Abstract">arXiv:2310.07488</a> [<a href="/pdf/2310.07488" title="Download PDF">pdf</a>, <a href="/format/2310.07488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KwaiYiiMath: Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jiayi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaoyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengzong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengnan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xucheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yiqiao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Chao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chengru Song</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Junchen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fuzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have demonstrated
remarkable abilities in handling a variety of natural language processing (NLP)
downstream tasks, even on mathematical tasks requiring multi-step reasoning. In
this report, we introduce the KwaiYiiMath which enhances the mathematical
reasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT)
and Reinforced Learning from Human Feedback (RLHF), including on both English
and Chinese mathematical tasks. Meanwhile, we also constructed a small-scale
Chinese primary school mathematics test set (named KMath), consisting of 188
examples to evaluate the correctness of the problem-solving process generated
by the models. Empirical studies demonstrate that KwaiYiiMath can achieve
state-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with
the similar size models, respectively.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07489" title="Abstract">arXiv:2310.07489</a> [<a href="/pdf/2310.07489" title="Download PDF">pdf</a>, <a href="/format/2310.07489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Semi-Discrete Optimal Transport Problems: star shapedeness and  Newton&#x27;s method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dieci%2C+L">Luca Dieci</a>, 
<a href="/search/math?searchtype=author&query=Omarov%2C+D">Daniyar Omarov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 32 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this work, we propose a novel implementation of Newton's method for
solving semi-discrete optimal transport (OT) problems for cost functions which
are a positive combination of $p$-norms, $1&lt;p&lt;\infty$. It is well understood
that the solution of a semi-discrete OT problem is equivalent to finding a
partition of a bounded region in Laguerre cells, and we prove that the Laguerre
cells are star-shaped with respect to the target points. By exploiting the
geometry of the Laguerre cells, we obtain an efficient and reliable
implementation of Newton's method to find the sought network structure. We
provide implementation details and extensive results in support of our
technique in 2-d problems, as well as comparison with other approaches used in
the literature.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07491" title="Abstract">arXiv:2310.07491</a> [<a href="/pdf/2310.07491" title="Download PDF">pdf</a>, <a href="/format/2310.07491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based Clustering of Individuals&#x27; Ecological Momentary Assessment  Time-series Data for Improving Forecasting Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ntekouli%2C+M">Mandani Ntekouli</a>, 
<a href="/search/cs?searchtype=author&query=Spanakis%2C+G">Gerasimos Spanakis</a>, 
<a href="/search/cs?searchtype=author&query=Waldorp%2C+L">Lourens Waldorp</a>, 
<a href="/search/cs?searchtype=author&query=Roefs%2C+A">Anne Roefs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures, BNAIC/BeNeLearn 2023 (Joint International Scientific Conferences on AI and Machine Learning)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Through Ecological Momentary Assessment (EMA) studies, a number of
time-series data is collected across multiple individuals, continuously
monitoring various items of emotional behavior. Such complex data is commonly
analyzed in an individual level, using personalized models. However, it is
believed that additional information of similar individuals is likely to
enhance these models leading to better individuals' description. Thus,
clustering is investigated with an aim to group together the most similar
individuals, and subsequently use this information in group-based models in
order to improve individuals' predictive performance. More specifically, two
model-based clustering approaches are examined, where the first is using
model-extracted parameters of personalized models, whereas the second is
optimized on the model-based forecasting performance. Both methods are then
analyzed using intrinsic clustering evaluation measures (e.g. Silhouette
coefficients) as well as the performance of a downstream forecasting scheme,
where each forecasting group-model is devoted to describe all individuals
belonging to one cluster. Among these, clustering based on performance shows
the best results, in terms of all examined evaluation measures. As another
level of evaluation, those group-models' performance is compared to three
baseline scenarios, the personalized, the all-in-one group and the random
group-based concept. According to this comparison, the superiority of
clustering-based methods is again confirmed, indicating that the utilization of
group-based information could be effectively enhance the overall performance of
all individuals' data.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07492" title="Abstract">arXiv:2310.07492</a> [<a href="/pdf/2310.07492" title="Download PDF">pdf</a>, <a href="/format/2310.07492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Black-box Attack to Deep Neural Networks with Conditional  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Renyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kangjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing black-box attacks have demonstrated promising potential in creating
adversarial examples (AE) to deceive deep learning models. Most of these
attacks need to handle a vast optimization space and require a large number of
queries, hence exhibiting limited practical impacts in real-world scenarios. In
this paper, we propose a novel black-box attack strategy, Conditional Diffusion
Model Attack (CDMA), to improve the query efficiency of generating AEs under
query-limited situations. The key insight of CDMA is to formulate the task of
AE synthesis as a distribution transformation problem, i.e., benign examples
and their corresponding AEs can be regarded as coming from two distinctive
distributions and can transform from each other with a particular converter.
Unlike the conventional \textit{query-and-optimization} approach, we generate
eligible AEs with direct conditional transform using the aforementioned data
converter, which can significantly reduce the number of queries needed. CDMA
adopts the conditional Denoising Diffusion Probabilistic Model as the
converter, which can learn the transformation from clean samples to AEs, and
ensure the smooth development of perturbed noise resistant to various defense
strategies. We demonstrate the effectiveness and efficiency of CDMA by
comparing it with nine state-of-the-art black-box attacks across three
benchmark datasets. On average, CDMA can reduce the query count to a handful of
times; in most cases, the query count is only ONE. We also show that CDMA can
obtain $&gt;99\%$ attack success rate for untarget attacks over all datasets and
targeted attack over CIFAR-10 with the noise budget of $\epsilon=16$.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07493" title="Abstract">arXiv:2310.07493</a> [<a href="/pdf/2310.07493" title="Download PDF">pdf</a>, <a href="/format/2310.07493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity for Contingency: Learning Diverse Behaviors for Efficient  Adaptation and Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rietz%2C+F">Finn Rietz</a>, 
<a href="/search/cs?searchtype=author&query=Stork%2C+J+A">Johannes Andreas Stork</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the third RL-Conform workshop at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Discovering all useful solutions for a given task is crucial for transferable
RL agents, to account for changes in the task or transition dynamics. This is
not considered by classical RL algorithms that are only concerned with finding
the optimal policy, given the current task and dynamics. We propose a simple
method for discovering all possible solutions of a given task, to obtain an
agent that performs well in the transfer setting and adapts quickly to changes
in the task or transition dynamics. Our method iteratively learns a set of
policies, while each subsequent policy is constrained to yield a solution that
is unlikely under all previous policies. Unlike prior methods, our approach
does not require learning additional models for novelty detection and avoids
balancing task and novelty reward signals, by directly incorporating the
constraint into the action selection and optimization steps.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07497" title="Abstract">arXiv:2310.07497</a> [<a href="/pdf/2310.07497" title="Download PDF">pdf</a>, <a href="/format/2310.07497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-Driven Federated Learning for Energy-Efficient and Real-Time IoT  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luu%2C+M+N">Minh Ngoc Luu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh-Duong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bedeer%2C+E">Ebrahim Bedeer</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+D">Van Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the domain of Federated Learning (FL) systems, recent cutting-edge methods
heavily rely on ideal conditions convergence analysis. Specifically, these
approaches assume that the training datasets on IoT devices possess similar
attributes to the global data distribution. However, this approach fails to
capture the full spectrum of data characteristics in real-time sensing FL
systems. In order to overcome this limitation, we suggest a new approach system
specifically designed for IoT networks with real-time sensing capabilities. Our
approach takes into account the generalization gap due to the user's data
sampling process. By effectively controlling this sampling process, we can
mitigate the overfitting issue and improve overall accuracy. In particular, We
first formulate an optimization problem that harnesses the sampling process to
concurrently reduce overfitting while maximizing accuracy. In pursuit of this
objective, our surrogate optimization problem is adept at handling energy
efficiency while optimizing the accuracy with high generalization. To solve the
optimization problem with high complexity, we introduce an online reinforcement
learning algorithm, named Sample-driven Control for Federated Learning (SCFL)
built on the Soft Actor-Critic (A2C) framework. This enables the agent to
dynamically adapt and find the global optima even in changing environments. By
leveraging the capabilities of SCFL, our system offers a promising solution for
resource allocation in FL systems with real-time sensing capabilities.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07506" title="Abstract">arXiv:2310.07506</a> [<a href="/pdf/2310.07506" title="Download PDF">pdf</a>, <a href="/format/2310.07506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Hierarchical Feature Sharing for Efficient Dataset  Condensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haizhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiachen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shutong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhuoqing Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Atul Prakash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Given a real-world dataset, data condensation (DC) aims to synthesize a
significantly smaller dataset that captures the knowledge of this dataset for
model training with high performance. Recent works propose to enhance DC with
data parameterization, which condenses data into parameterized data containers
rather than pixel space. The intuition behind data parameterization is to
encode shared features of images to avoid additional storage costs. In this
paper, we recognize that images share common features in a hierarchical way due
to the inherent hierarchical structure of the classification system, which is
overlooked by current data parameterization methods. To better align DC with
this hierarchical nature and encourage more efficient information sharing
inside data containers, we propose a novel data parameterization architecture,
Hierarchical Memory Network (HMN). HMN stores condensed data in a three-tier
structure, representing the dataset-level, class-level, and instance-level
features. Another helpful property of the hierarchical architecture is that HMN
naturally ensures good independence among images despite achieving information
sharing. This enables instance-level pruning for HMN to reduce redundant
information, thereby further minimizing redundancy and enhancing performance.
We evaluate HMN on four public datasets (SVHN, CIFAR10, CIFAR100, and
Tiny-ImageNet) and compare HMN with eight DC baselines. The evaluation results
show that our proposed method outperforms all baselines, even when trained with
a batch-based loss consuming less GPU memory.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07510" title="Abstract">arXiv:2310.07510</a> [<a href="/pdf/2310.07510" title="Download PDF">pdf</a>, <a href="/format/2310.07510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heuristic Vision Pre-Training with Self-Supervised and Supervised  Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhiming Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To mimic human vision with the way of recognizing the diverse and open world,
foundation vision models are much critical. While recent techniques of
self-supervised learning show the promising potentiality of this mission, we
argue that signals from labelled data are also important for common-sense
recognition, and properly chosen pre-text tasks can facilitate the efficiency
of vision representation learning. To this end, we propose a novel pre-training
framework by adopting both self-supervised and supervised visual pre-text tasks
in a multi-task manner. Specifically, given an image, we take a heuristic way
by considering its intrinsic style properties, inside objects with their
locations and correlations, and how it looks like in 3D space for basic visual
understanding. However, large-scale object bounding boxes and correlations are
usually hard to achieve. Alternatively, we develop a hybrid method by
leveraging both multi-label classification and self-supervised learning. On the
one hand, under the multi-label supervision, the pre-trained model can explore
the detailed information of an image, e.g., image types, objects, and part of
semantic relations. On the other hand, self-supervised learning tasks, with
respect to Masked Image Modeling (MIM) and contrastive learning, can help the
model learn pixel details and patch correlations. Results show that our
pre-trained models can deliver results on par with or better than
state-of-the-art (SOTA) results on multiple visual tasks. For example, with a
vanilla Swin-B backbone, we achieve 85.3\% top-1 accuracy on ImageNet-1K
classification, 47.9 box AP on COCO object detection for Mask R-CNN, and 50.6
mIoU on ADE-20K semantic segmentation when using Upernet. The performance shows
the ability of our vision foundation model to serve general purpose vision
tasks.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07511" title="Abstract">arXiv:2310.07511</a> [<a href="/pdf/2310.07511" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Remote Sensing Anomaly Detector Across Modalities and Scenes  via Deviation Relationship Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingtao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangpei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yanfei Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Remote sensing anomaly detector can find the objects deviating from the
background as potential targets. Given the diversity in earth anomaly types, a
unified anomaly detector across modalities and scenes should be cost-effective
and flexible to new earth observation sources and anomaly types. However, the
current anomaly detectors are limited to a single modality and single scene,
since they aim to learn the varying background distribution. Motivated by the
universal anomaly deviation pattern, in that anomalies exhibit deviations from
their local context, we exploit this characteristic to build a unified anomaly
detector. Firstly, we reformulate the anomaly detection task as an undirected
bilayer graph based on the deviation relationship, where the anomaly score is
modeled as the conditional probability, given the pattern of the background and
normal objects. The learning objective is then expressed as a conditional
probability ranking problem. Furthermore, we design an instantiation of the
reformulation in the data, architecture, and optimization aspects. Simulated
spectral and spatial anomalies drive the instantiated architecture. The model
is optimized directly for the conditional probability ranking. The proposed
model was validated in five modalities including the hyperspectral, visible
light, synthetic aperture radar (SAR), infrared and low light to show its
unified detection ability.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07516" title="Abstract">arXiv:2310.07516</a> [<a href="/pdf/2310.07516" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Estimates Across Layers of Computing: From Devices to Large-Scale  Applications in Machine Learning for Natural Language Processing, Scientific  Computing, and Cryptocurrency Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shankar%2C+S">Sadasivan Shankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Estimates of energy usage in layers of computing from devices to algorithms
have been determined and analyzed. Building on the previous analysis [3],
energy needed from single devices and systems including three large-scale
computing applications such as Artificial Intelligence (AI)/Machine Learning
for Natural Language Processing, Scientific Simulations, and Cryptocurrency
Mining have been estimated. In contrast to the bit-level switching, in which
transistors achieved energy efficiency due to geometrical scaling, higher
energy is expended both at the at the instructions and simulations levels of an
application. Additionally, the analysis based on AI/ML Accelerators indicate
that changes in architectures using an older semiconductor technology node have
comparable energy efficiency with a different architecture using a newer
technology. Further comparisons of the energy in computing systems with the
thermodynamic and biological limits, indicate that there is a 27-36 orders of
magnitude higher energy requirements for total simulation of an application.
These energy estimates underscore the need for serious considerations of energy
efficiency in computing by including energy as a design parameter, enabling
growing needs of compute-intensive applications in a digital world.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07517" title="Abstract">arXiv:2310.07517</a> [<a href="/pdf/2310.07517" title="Download PDF">pdf</a>, <a href="/format/2310.07517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CM-PIE: Cross-modal perception for interactive-enhanced audio-visual  video parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruohao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peipei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 15 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Audio-visual video parsing is the task of categorizing a video at the segment
level with weak labels, and predicting them as audible or visible events.
Recent methods for this task leverage the attention mechanism to capture the
semantic correlations among the whole video across the audio-visual modalities.
However, these approaches have overlooked the importance of individual segments
within a video and the relationship among them, and tend to rely on a single
modality when learning features. In this paper, we propose a novel
interactive-enhanced cross-modal perception method~(CM-PIE), which can learn
fine-grained features by applying a segment-based attention module.
Furthermore, a cross-modal aggregation block is introduced to jointly optimize
the semantic representation of audio and visual signals by enhancing
inter-modal interactions. The experimental results show that our model offers
improved parsing performance on the Look, Listen, and Parse dataset compared to
other methods.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07518" title="Abstract">arXiv:2310.07518</a> [<a href="/pdf/2310.07518" title="Download PDF">pdf</a>, <a href="/format/2310.07518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mutti%2C+M">Mirco Mutti</a>, 
<a href="/search/cs?searchtype=author&query=De+Santi%2C+R">Riccardo De Santi</a>, 
<a href="/search/cs?searchtype=author&query=Restelli%2C+M">Marcello Restelli</a>, 
<a href="/search/cs?searchtype=author&query=Marx%2C+A">Alexander Marx</a>, 
<a href="/search/cs?searchtype=author&query=Ramponi%2C+G">Giorgia Ramponi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Posterior sampling allows the exploitation of prior knowledge of the
environment's transition dynamics to improve the sample efficiency of
reinforcement learning. The prior is typically specified as a class of
parametric distributions, a task that can be cumbersome in practice, often
resulting in the choice of uninformative priors. In this work, we propose a
novel posterior sampling approach in which the prior is given as a (partial)
causal graph over the environment's variables. The latter is often more natural
to design, such as listing known causal dependencies between biometric features
in a medical treatment study. Specifically, we propose a hierarchical Bayesian
procedure, called C-PSRL, simultaneously learning the full causal graph at the
higher level and the parameters of the resulting factored dynamics at the lower
level. For this procedure, we provide an analysis of its Bayesian regret, which
explicitly connects the regret rate with the degree of prior knowledge. Our
numerical evaluation conducted in illustrative domains confirms that C-PSRL
strongly improves the efficiency of posterior sampling with an uninformative
prior while performing close to posterior sampling with the full causal graph.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07521" title="Abstract">arXiv:2310.07521</a> [<a href="/pdf/2310.07521" title="Download PDF">pdf</a>, <a href="/format/2310.07521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Factuality in Large Language Models: Knowledge, Retrieval and  Domain-Specificity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cunxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yuanhao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiayang%2C+C">Cheng Jiayang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wenyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zehan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages; 300+ references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This survey addresses the crucial issue of factuality in Large Language
Models (LLMs). As LLMs find applications across diverse domains, the
reliability and accuracy of their outputs become vital. We define the
Factuality Issue as the probability of LLMs to produce content inconsistent
with established facts. We first delve into the implications of these
inaccuracies, highlighting the potential consequences and challenges posed by
factual errors in LLM outputs. Subsequently, we analyze the mechanisms through
which LLMs store and process facts, seeking the primary causes of factual
errors. Our discussion then transitions to methodologies for evaluating LLM
factuality, emphasizing key metrics, benchmarks, and studies. We further
explore strategies for enhancing LLM factuality, including approaches tailored
for specific domains. We focus two primary LLM configurations standalone LLMs
and Retrieval-Augmented LLMs that utilizes external data, we detail their
unique challenges and potential enhancements. Our survey offers a structured
guide for researchers aiming to fortify the factual reliability of LLMs.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07522" title="Abstract">arXiv:2310.07522</a> [<a href="/pdf/2310.07522" title="Download PDF">pdf</a>, <a href="/format/2310.07522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S4C: Self-Supervised Semantic Scene Completion with Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayler%2C+A">Adrian Hayler</a>, 
<a href="/search/cs?searchtype=author&query=Wimbauer%2C+F">Felix Wimbauer</a>, 
<a href="/search/cs?searchtype=author&query=Muhle%2C+D">Dominik Muhle</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D semantic scene understanding is a fundamental challenge in computer
vision. It enables mobile agents to autonomously plan and navigate arbitrary
environments. SSC formalizes this challenge as jointly estimating dense
geometry and semantic information from sparse observations of a scene. Current
methods for SSC are generally trained on 3D ground truth based on aggregated
LiDAR scans. This process relies on special sensors and annotation by hand
which are costly and do not scale well. To overcome this issue, our work
presents the first self-supervised approach to SSC called S4C that does not
rely on 3D ground truth data. Our proposed method can reconstruct a scene from
a single image and only relies on videos and pseudo segmentation ground truth
generated from off-the-shelf image segmentation network during training. Unlike
existing methods, which use discrete voxel grids, we represent scenes as
implicit semantic fields. This formulation allows querying any point within the
camera frustum for occupancy and semantic class. Our architecture is trained
through rendering-based self-supervised losses. Nonetheless, our method
achieves performance close to fully supervised state-of-the-art methods.
Additionally, our method demonstrates strong generalization capabilities and
can synthesize accurate segmentation maps for far away viewpoints.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07524" title="Abstract">arXiv:2310.07524</a> [<a href="/pdf/2310.07524" title="Download PDF">pdf</a>, <a href="/ps/2310.07524" title="Download PostScript">ps</a>, <a href="/format/2310.07524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Lower Bounds for the Minimum Distance of Cyclic Codes and  Applications to Locally Repairable Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+W">Weijun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fang-Wei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Cyclic codes are an important class of linear codes. Bounding the minimum
distance of cyclic codes is a long-standing research topic in coding theory,
and several well-known and basic results have been developed on this topic.
Recently, locally repairable codes (LRCs) have attracted much attention due to
their repair efficiency in large-scale distributed storage systems. In this
paper, by employing the singleton procedure technique, we first provide a
sufficient condition for bounding the minimum distance of cyclic codes with
typical defining sets. Secondly, by considering a specific case, we establish a
connection between bounds for the minimum distance of cyclic codes and
solutions to a system of inequalities. This connection leads to the derivation
of new bounds, including some with general patterns. In particular, we provide
three new bounds with general patterns, one of which serves as a generalization
of the Betti-Sala bound. Finally, we present a generalized lower bound for a
special case and construct several families of $(2, \delta)$-LRCs with
unbounded length and minimum distance $2\delta$. It turns out that these LRCs
are distance-optimal, and their parameters are new. To the best of our
knowledge, this work represents the first construction of distance-optimal $(r,
\delta)$-LRCs with unbounded length and minimum distance exceeding
$r+\delta-1$.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07525" title="Abstract">arXiv:2310.07525</a> [<a href="/pdf/2310.07525" title="Download PDF">pdf</a>, <a href="/format/2310.07525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViT-A*: Legged Robot Path Planning using Vision Transformer A*
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shirui Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hadjivelichkov%2C+D">Denis Hadjivelichkov</a>, 
<a href="/search/cs?searchtype=author&query=Modugno%2C+V">Valerio Modugno</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+D">Dimitrios Kanoulas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, conference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE-RAS International Conference on Humanoids Robots (Humanoids)
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Legged robots, particularly quadrupeds, offer promising navigation
capabilities, especially in scenarios requiring traversal over diverse terrains
and obstacle avoidance. This paper addresses the challenge of enabling legged
robots to navigate complex environments effectively through the integration of
data-driven path-planning methods. We propose an approach that utilizes
differentiable planners, allowing the learning of end-to-end global plans via a
neural network for commanding quadruped robots. The approach leverages 2D maps
and obstacle specifications as inputs to generate a global path. To enhance the
functionality of the developed neural network-based path planner, we use Vision
Transformers (ViT) for map pre-processing, to enable the effective handling of
larger maps. Experimental evaluations on two real robotic quadrupeds (Boston
Dynamics Spot and Unitree Go1) demonstrate the effectiveness and versatility of
the proposed approach in generating reliable path plans.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07526" title="Abstract">arXiv:2310.07526</a> [<a href="/pdf/2310.07526" title="Download PDF">pdf</a>, <a href="/format/2310.07526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction-aware Traffic Prediction and Scenario-based Model Predictive  Control for Autonomous Vehicles on Highways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaorong Zhang</a> (1), 
<a href="/search/eess?searchtype=author&query=Zeinali%2C+S">Sahar Zeinali</a> (1), 
<a href="/search/eess?searchtype=author&query=Schildbach%2C+G">Georg Schildbach</a> (1) ((1) Institute for electrical engineering in Medicine, University of luebeck, Luebeck, Germany)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the problem of traffic prediction and control of
autonomous vehicles on highways. A modified Interacting Multiple Model Kalman
filter algorithm is applied to predict the motion behavior of the traffic
participants by considering their interactions. A scenario generation component
is used to produce plausible scenarios of the vehicles based on the predicted
information. A novel integrated decision-making and control system is proposed
by applying a Scenario-based Model Predictive Control approach. The designed
controller considers safety, driving comfort, and traffic rules. The recursive
feasibility of the controller is guaranteed under the inclusion of the `worst
case' as an additional scenario to obtain safe inputs. Finally, the proposed
scheme is evaluated using the HighD dataset. Simulation results indicate that
the vehicle performs safe maneuvers in different traffic situations under the
designed control framework.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07534" title="Abstract">arXiv:2310.07534</a> [<a href="/pdf/2310.07534" title="Download PDF">pdf</a>, <a href="/format/2310.07534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centered Evaluation of XAI Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dawoud%2C+K">Karam Dawoud</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>, 
<a href="/search/cs?searchtype=author&query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>, 
<a href="/search/cs?searchtype=author&query=Bosse%2C+S">Sebastian Bosse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the ever-evolving field of Artificial Intelligence, a critical challenge
has been to decipher the decision-making processes within the so-called "black
boxes" in deep learning. Over recent years, a plethora of methods have emerged,
dedicated to explaining decisions across diverse tasks. Particularly in tasks
like image classification, these methods typically identify and emphasize the
pivotal pixels that most influence a classifier's prediction. Interestingly,
this approach mirrors human behavior: when asked to explain our rationale for
classifying an image, we often point to the most salient features or aspects.
Capitalizing on this parallel, our research embarked on a user-centric study.
We sought to objectively measure the interpretability of three leading
explanation methods: (1) Prototypical Part Network, (2) Occlusion, and (3)
Layer-wise Relevance Propagation. Intriguingly, our results highlight that
while the regions spotlighted by these methods can vary widely, they all offer
humans a nearly equivalent depth of understanding. This enables users to
discern and categorize images efficiently, reinforcing the value of these
methods in enhancing AI transparency.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07535" title="Abstract">arXiv:2310.07535</a> [<a href="/pdf/2310.07535" title="Download PDF">pdf</a>, <a href="/format/2310.07535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Fairness-Accuracy tradeoff with few Test Samples under  Covariate Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havaldar%2C+S">Shreyas Havaldar</a>, 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+J">Jatin Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+K">Karthikeyan Shanmugam</a>, 
<a href="/search/cs?searchtype=author&query=Nandy%2C+J">Jay Nandy</a>, 
<a href="/search/cs?searchtype=author&query=Raghuveer%2C+A">Aravindan Raghuveer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Covariate shift in the test data can significantly downgrade both the
accuracy and the fairness performance of the model. Ensuring fairness across
different sensitive groups in such settings is of paramount importance due to
societal implications like criminal justice. We operate under the unsupervised
regime where only a small set of unlabeled test samples along with a labeled
training set is available. Towards this problem, we make three contributions.
First is a novel composite weighted entropy based objective for prediction
accuracy which is optimized along with a representation matching loss for
fairness. We experimentally verify that optimizing with our loss formulation
outperforms a number of state-of-the-art baselines in the pareto sense with
respect to the fairness-accuracy tradeoff on several standard datasets. Our
second contribution is a new setting we term Asymmetric Covariate Shift that,
to the best of our knowledge, has not been studied before. Asymmetric covariate
shift occurs when distribution of covariates of one group shifts significantly
compared to the other groups and this happens when a dominant group is
over-represented. While this setting is extremely challenging for current
baselines, We show that our proposed method significantly outperforms them. Our
third contribution is theoretical, where we show that our weighted entropy term
along with prediction loss on the training set approximates test loss under
covariate shift. Empirically and through formal sample complexity bounds, we
show that this approximation to the unseen test loss does not depend on
importance sampling variance which affects many other baselines.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07541" title="Abstract">arXiv:2310.07541</a> [<a href="/pdf/2310.07541" title="Download PDF">pdf</a>, <a href="/format/2310.07541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building hierarchies of semiclassical Jacobi polynomials for spectral  methods in annuli
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Papadopoulos%2C+I+P+A">Ioannis P. A. Papadopoulos</a>, 
<a href="/search/math?searchtype=author&query=Gutleb%2C+T+S">Timon S. Gutleb</a>, 
<a href="/search/math?searchtype=author&query=Slevinsky%2C+R+M">Richard M. Slevinsky</a>, 
<a href="/search/math?searchtype=author&query=Olver%2C+S">Sheehan Olver</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We discuss computing with hierarchies of families of (potentially weighted)
semiclassical Jacobi polynomials which arise in the construction of
multivariate orthogonal polynomials. In particular, we outline how to build
connection and differentiation matrices with optimal complexity and compute
analysis and synthesis operations in quasi-optimal complexity. We investigate a
particular application of these results to constructing orthogonal polynomials
in annuli, called the generalised Zernike annular polynomials, which lead to
sparse discretisations of partial differential equations. We compare against a
scaled-and-shifted Chebyshev--Fourier series showing that in general the
annular polynomials converge faster when approximating smooth functions and
have better conditioning. We also construct a sparse spectral element method by
combining disk and annulus cells, which is highly effective for solving PDEs
with radially discontinuous variable coefficients and data.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07545" title="Abstract">arXiv:2310.07545</a> [<a href="/pdf/2310.07545" title="Download PDF">pdf</a>, <a href="/format/2310.07545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Agent-Based Social Networks for Disinformation: Research  Opportunities and Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pastor-Galindo%2C+J">Javier Pastor-Galindo</a>, 
<a href="/search/cs?searchtype=author&query=Nespoli%2C+P">Pantaleone Nespoli</a>, 
<a href="/search/cs?searchtype=author&query=Ruip%C3%A9rez-Valiente%2C+J+A">Jos&#xe9; A. Ruip&#xe9;rez-Valiente</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This article presents the affordances that Generative Artificial Intelligence
can have in disinformation context, one of the major threats to our digitalized
society. We present a research framework to generate customized agent-based
social networks for disinformation simulations that would enable understanding
and evaluation of the phenomena whilst discussing open challenges.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07548" title="Abstract">arXiv:2310.07548</a> [<a href="/pdf/2310.07548" title="Download PDF">pdf</a>, <a href="/format/2310.07548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Localization and Revision Network for Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Suling Duan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chenwei Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenan He</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot learning enables the model to recognize unseen categories with the
aid of auxiliary semantic information such as attributes. Current works
proposed to detect attributes from local image regions and align extracted
features with class-level semantics. In this paper, we find that the choice
between local and global features is not a zero-sum game, global features can
also contribute to the understanding of attributes. In addition, aligning
attribute features with class-level semantics ignores potential intra-class
attribute variation. To mitigate these disadvantages, we present Attribute
Localization and Revision Network in this paper. First, we design Attribute
Localization Module (ALM) to capture both local and global features from image
regions, a novel module called Scale Control Unit is incorporated to fuse
global and local representations. Second, we propose Attribute Revision Module
(ARM), which generates image-level semantics by revising the ground-truth value
of each attribute, compensating for performance degradation caused by ignoring
intra-class variation. Finally, the output of ALM will be aligned with revised
semantics produced by ARM to achieve the training process. Comprehensive
experimental results on three widely used benchmarks demonstrate the
effectiveness of our model in the zero-shot prediction task.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07551" title="Abstract">arXiv:2310.07551</a> [<a href="/pdf/2310.07551" title="Download PDF">pdf</a>, <a href="/ps/2310.07551" title="Download PostScript">ps</a>, <a href="/format/2310.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Third order tensor-oriented directional splitting for exponential  integrators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cassini%2C+F">Fabio Cassini</a>, 
<a href="/search/math?searchtype=author&query=Caliari%2C+M">Marco Caliari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Suitable discretizations through tensor product formulas of popular
multidimensional operators (diffusion--advection, for instance) lead to
matrices with $d$-dimensional Kronecker sum structure. For evolutionary PDEs
containing such operators and integrated in time with exponential integrators,
it is of paramount importance to efficiently approximate actions of
$\varphi$-functions of this kind of matrices. In this work, we show how to
produce directional split approximations of third order with respect to the
time step size. They conveniently employ tensor-matrix products (realized with
highly performance level 3 BLAS) and that allow for the effective usage in
practice of exponential integrators up to order three. The approach has been
successfully tested against state-of-the-art techniques on two well-known
physical models, namely FitzHugh--Nagumo and Schnakenberg.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07552" title="Abstract">arXiv:2310.07552</a> [<a href="/pdf/2310.07552" title="Download PDF">pdf</a>, <a href="/format/2310.07552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoHPE: Prototype-guided High-frequency Patch Enhancement for  Visible-Infrared Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zichang Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visible-infrared person re-identification is challenging due to the large
modality gap. To bridge the gap, most studies heavily rely on the correlation
of visible-infrared holistic person images, which may perform poorly under
severe distribution shifts. In contrast, we find that some cross-modal
correlated high-frequency components contain discriminative visual patterns and
are less affected by variations such as wavelength, pose, and background
clutter than holistic images. Therefore, we are motivated to bridge the
modality gap based on such high-frequency components, and propose
\textbf{Proto}type-guided \textbf{H}igh-frequency \textbf{P}atch
\textbf{E}nhancement (ProtoHPE) with two core designs. \textbf{First}, to
enhance the representation ability of cross-modal correlated high-frequency
components, we split patches with such components by Wavelet Transform and
exponential moving average Vision Transformer (ViT), then empower ViT to take
the split patches as auxiliary input. \textbf{Second}, to obtain semantically
compact and discriminative high-frequency representations of the same identity,
we propose Multimodal Prototypical Contrast. To be specific, it hierarchically
captures the comprehensive semantics of different modal instances, facilitating
the aggregation of high-frequency representations belonging to the same
identity. With it, ViT can capture key high-frequency components during
inference without relying on ProtoHPE, thus bringing no extra complexity.
Extensive experiments validate the effectiveness of ProtoHPE.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07554" title="Abstract">arXiv:2310.07554</a> [<a href="/pdf/2310.07554" title="Download PDF">pdf</a>, <a href="/format/2310.07554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieve Anything To Augment Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jian-Yun Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Large language models (LLMs) face significant challenges stemming from the
inherent limitations in knowledge, memory, alignment, and action. These
challenges cannot be addressed by LLMs alone, but should rely on assistance
from the external world, such as knowledge base, memory store, demonstration
examples, and tools. Retrieval augmentation stands as a vital mechanism for
bridging the gap between LLMs and the external assistance. However,
conventional methods encounter two pressing issues. On one hand, the
general-purpose retrievers are not properly optimized for the retrieval
augmentation of LLMs. On the other hand, the task-specific retrievers lack the
required versatility, hindering their performance across the diverse retrieval
augmentation scenarios.
<br />In this work, we present a novel approach, the LLM Embedder, which
comprehensively support the diverse needs of LLMs' retrieval augmentation with
one unified embedding model. Training such an unified model is non-trivial, as
various retrieval tasks aim to capture distinct semantic relationships, often
subject to mutual interference. To address this challenge, we systematically
optimize our training methodology. This includes reward formulation based on
LLMs' feedback, the stabilization of knowledge distillation, multi-task
fine-tuning with explicit instructions, and the use of homogeneous in-batch
negative sampling. These optimization strategies contribute to the outstanding
empirical performance of the LLM-Embedder. Notably, it yields remarkable
enhancements in retrieval augmentation for LLMs, surpassing both
general-purpose and task-specific retrievers in various evaluation scenarios.
This project is made publicly available at
https://github.com/FlagOpen/FlagEmbedding.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07555" title="Abstract">arXiv:2310.07555</a> [<a href="/pdf/2310.07555" title="Download PDF">pdf</a>, <a href="/format/2310.07555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does resistance to Style-Transfer equal Shape Bias? Evaluating Shape  Bias by Distorted Shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Ziqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T+S">Tai Sing Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models are known to exhibit a strong texture bias, while human
tends to rely heavily on global shape for object recognition. The current
benchmark for evaluating a model's shape bias is a set of style-transferred
images with the assumption that resistance to the attack of style transfer is
related to the development of shape sensitivity in the model. In this work, we
show that networks trained with style-transfer images indeed learn to ignore
style, but its shape bias arises primarily from local shapes. We provide a
Distorted Shape Testbench (DiST) as an alternative measurement of global shape
sensitivity. Our test includes 2400 original images from ImageNet-1K, each of
which is accompanied by two images with the global shapes of the original image
distorted while preserving its texture via the texture synthesis program. We
found that (1) models that performed well on the previous shape bias evaluation
do not fare well in the proposed DiST; (2) the widely adopted ViT models do not
show significant advantages over Convolutional Neural Networks (CNNs) on this
benchmark despite that ViTs rank higher on the previous shape bias tests. (3)
training with DiST images bridges the significant gap between human and
existing SOTA models' performance while preserving the models' accuracy on
standard image classification tasks; training with DiST images and
style-transferred images are complementary, and can be combined to train
network together to enhance both the global and local shape sensitivity of the
network. Our code will be host at: https://github.com/leelabcnbc/DiST
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07557" title="Abstract">arXiv:2310.07557</a> [<a href="/pdf/2310.07557" title="Download PDF">pdf</a>, <a href="/format/2310.07557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality of Service-Constrained Online Routing in High Throughput  Satellites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A9langer%2C+O">Olivier B&#xe9;langer</a>, 
<a href="/search/cs?searchtype=author&query=Yahia%2C+O+B">Olfa Ben Yahia</a>, 
<a href="/search/cs?searchtype=author&query=Martel%2C+S">St&#xe9;phane Martel</a>, 
<a href="/search/cs?searchtype=author&query=Lesage-Landry%2C+A">Antoine Lesage-Landry</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+G+K">Gunes Karabulut Kurt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Aerospace Conference. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">High Throughput Satellites (HTSs) outpace traditional satellites due to their
multi-beam transmission. The rise of low Earth orbit mega constellations
amplifies HTS data rate demands to terabits/second with acceptable latency.
This surge in data rate necessitates multiple modems, often exceeding single
device capabilities. Consequently, satellites employ several processors,
forming a complex packet-switch network. This can lead to potential internal
congestion and challenges in adhering to strict quality of service (QoS)
constraints. While significant research exists on constellation-level routing,
a literature gap remains on the internal routing within a singular HTS. The
intricacy of this internal network architecture presents a significant
challenge to achieve high data rates.
<br />This paper introduces an online optimal flow allocation and scheduling method
for HTSs. The problem is treated as a multi-commodity flow instance with
different priority data streams. An initial full time horizon model is proposed
as a benchmark. We apply a model predictive control (MPC) approach to enable
adaptive routing based on current information and the forecast within the
prediction time horizon while allowing for deviation of the latter.
Importantly, MPC is inherently suited to handle uncertainty in incoming flows.
Our approach minimizes packet loss by optimally and adaptively managing the
priority queue schedulers and flow exchanges between satellite processing
modules. Central to our method is a routing model focusing on optimal priority
scheduling to enhance data rates and maintain QoS. The model's stages are
critically evaluated, and results are compared to traditional methods via
numerical simulations. Through simulations, our method demonstrates performance
nearly on par with the hindsight optimum, showcasing its efficiency and
adaptability in addressing satellite communication challenges.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07560" title="Abstract">arXiv:2310.07560</a> [<a href="/pdf/2310.07560" title="Download PDF">pdf</a>, <a href="/format/2310.07560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROMO: Retrieval-enhanced Offline Model-based Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingcheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hulei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hongqiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zheng Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data-driven black-box model-based optimization (MBO) problems arise in a
great number of practical application scenarios, where the goal is to find a
design over the whole space maximizing a black-box target function based on a
static offline dataset. In this work, we consider a more general but
challenging MBO setting, named constrained MBO (CoMBO), where only part of the
design space can be optimized while the rest is constrained by the environment.
A new challenge arising from CoMBO is that most observed designs that satisfy
the constraints are mediocre in evaluation. Therefore, we focus on optimizing
these mediocre designs in the offline dataset while maintaining the given
constraints rather than further boosting the best observed design in the
traditional MBO setting. We propose retrieval-enhanced offline model-based
optimization (ROMO), a new derivable forward approach that retrieves the
offline dataset and aggregates relevant samples to provide a trusted
prediction, and use it for gradient-based optimization. ROMO is simple to
implement and outperforms state-of-the-art approaches in the CoMBO setting.
Empirically, we conduct experiments on a synthetic Hartmann (3D) function
dataset, an industrial CIO dataset, and a suite of modified tasks in the
Design-Bench benchmark. Results show that ROMO performs well in a wide range of
constrained optimization tasks.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07563" title="Abstract">arXiv:2310.07563</a> [<a href="/pdf/2310.07563" title="Download PDF">pdf</a>, <a href="/format/2310.07563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Tableau and Google Map API for Understanding the Impact of  Walkability on Dublin City
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Applications (stat.AP)

</div>
<p class="mathjax">In this article, we explore two effective means to communicate the concept of
walkability - 1) visualization, and 2) descriptive statistics. We introduce the
concept of walkability as measuring the quality of an urban space based on the
distance needed to walk from that space to a range of different social,
environmental, and economic amenities. We use Dublin city as a worked example
and explore quantification and visualization of walkability of various areas of
the city. We utilize the Google Map API and Tableau to visualize the less
walkable areas across Dublin city and using WLS regression, we assess the
effects of unwalkability on house prices in Dublin, thus quantifying the
importance of walkable areas from an economic perspective.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07572" title="Abstract">arXiv:2310.07572</a> [<a href="/pdf/2310.07572" title="Download PDF">pdf</a>, <a href="/format/2310.07572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Label Types on Training SWIN Models with Overhead Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ford%2C+R">Ryan Ford</a>, 
<a href="/search/cs?searchtype=author&query=Hutchison%2C+K">Kenneth Hutchison</a>, 
<a href="/search/cs?searchtype=author&query=Felts%2C+N">Nicholas Felts</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Benjamin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lew%2C+J">Jesse Lew</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+K">Kyle Jackson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding the impact of data set design on model training and performance
can help alleviate the costs associated with generating remote sensing and
overhead labeled data. This work examined the impact of training shifted window
transformers using bounding boxes and segmentation labels, where the latter are
more expensive to produce. We examined classification tasks by comparing models
trained with both target and backgrounds against models trained with only
target pixels, extracted by segmentation labels. For object detection models,
we compared performance using either label type when training. We found that
the models trained on only target pixels do not show performance improvement
for classification tasks, appearing to conflate background pixels in the
evaluation set with target pixels. For object detection, we found that models
trained with either label type showed equivalent performance across testing. We
found that bounding boxes appeared to be sufficient for tasks that did not
require more complex labels, such as object segmentation. Continuing work to
determine consistency of this result across data types and model architectures
could potentially result in substantial savings in generating remote sensing
data sets for deep learning.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07573" title="Abstract">arXiv:2310.07573</a> [<a href="/pdf/2310.07573" title="Download PDF">pdf</a>, <a href="/format/2310.07573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relational Prior Knowledge Graphs for Detection and Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%9Clger%2C+O">Osman &#xdc;lger</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Galama%2C+Y">Ysbrand Galama</a>, 
<a href="/search/cs?searchtype=author&query=Karaoglu%2C+S">Sezer Karaoglu</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV2023 SG2RL Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans have a remarkable ability to perceive and reason about the world
around them by understanding the relationships between objects. In this paper,
we investigate the effectiveness of using such relationships for object
detection and instance segmentation. To this end, we propose a Relational
Prior-based Feature Enhancement Model (RP-FEM), a graph transformer that
enhances object proposal features using relational priors. The proposed
architecture operates on top of scene graphs obtained from initial proposals
and aims to concurrently learn relational context modeling for object detection
and instance segmentation. Experimental evaluations on COCO show that the
utilization of scene graphs, augmented with relational priors, offer benefits
for object detection and instance segmentation. RP-FEM demonstrates its
capacity to suppress improbable class predictions within the image while also
preventing the model from generating duplicate predictions, leading to
improvements over the baseline model on which it is built.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07576" title="Abstract">arXiv:2310.07576</a> [<a href="/pdf/2310.07576" title="Download PDF">pdf</a>, <a href="/format/2310.07576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Trendy Twitter Hashtags in the 2022 French Election
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandviwalla%2C+A">Aamir Mandviwalla</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lake Yin</a>, 
<a href="/search/cs?searchtype=author&query=Szymanski%2C+B+K">Boleslaw K. Szymanski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, to be published in Complex Networks 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Regressions trained to predict the future activity of social media users need
rich features for accurate predictions. Many advanced models exist to generate
such features; however, the time complexities of their computations are often
prohibitive when they run on enormous data-sets. Some studies have shown that
simple semantic network features can be rich enough to use for regressions
without requiring complex computations. We propose a method for using semantic
networks as user-level features for machine learning tasks. We conducted an
experiment using a semantic network of 1037 Twitter hashtags from a corpus of
3.7 million tweets related to the 2022 French presidential election. A
bipartite graph is formed where hashtags are nodes and weighted edges connect
the hashtags reflecting the number of Twitter users that interacted with both
hashtags. The graph is then transformed into a maximum-spanning tree with the
most popular hashtag as its root node to construct a hierarchy amongst the
hashtags. We then provide a vector feature for each user based on this tree. To
validate the usefulness of our semantic feature we performed a regression
experiment to predict the response rate of each user with six emotions like
anger, enjoyment, or disgust. Our semantic feature performs well with the
regression with most emotions having $R^2$ above 0.5. These results suggest
that our semantic feature could be considered for use in further experiments
predicting social media response on big data-sets.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07579" title="Abstract">arXiv:2310.07579</a> [<a href="/pdf/2310.07579" title="Download PDF">pdf</a>, <a href="/format/2310.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Unlearning: Language Models as Few Shot Unlearners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pawelczyk%2C+M">Martin Pawelczyk</a>, 
<a href="/search/cs?searchtype=author&query=Neel%2C+S">Seth Neel</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine unlearning, the study of efficiently removing the impact of specific
training points on the trained model, has garnered increased attention of late,
driven by the need to comply with privacy regulations like the \emph{Right to
be Forgotten}. Although unlearning is particularly relevant for LLMs in light
of the copyright issues they raise, achieving precise unlearning is
computationally infeasible for very large models. To this end, recent work has
proposed several algorithms which approximate the removal of training data
without retraining the model. These algorithms crucially rely on access to the
model parameters in order to update them, an assumption that may not hold in
practice due to computational constraints or when the LLM is accessed via API.
In this work, we propose a new class of unlearning methods for LLMs we call
``In-Context Unlearning'', providing inputs in context and without having to
update model parameters. To unlearn a particular training instance, we provide
the instance alongside a flipped label and additional correctly labelled
instances which are prepended as inputs to the LLM at inference time. Our
experimental results demonstrate that these contexts effectively remove
specific information from the training set while maintaining performance levels
that are competitive with (or in some cases exceed) state-of-the-art unlearning
methods that require access to the LLM parameters.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07581" title="Abstract">arXiv:2310.07581</a> [<a href="/pdf/2310.07581" title="Download PDF">pdf</a>, <a href="/format/2310.07581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qlarify: Bridging Scholarly Abstracts and Papers with Recursively  Expandable Summaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fok%2C+R">Raymond Fok</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+C">Joseph Chee Chang</a>, 
<a href="/search/cs?searchtype=author&query=August%2C+T">Tal August</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Weld%2C+D+S">Daniel S. Weld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, 4 tables. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">As scientific literature has grown exponentially, researchers often rely on
paper triaging strategies such as browsing abstracts before deciding to delve
into a paper's full text. However, when an abstract is insufficient,
researchers are required to navigate an informational chasm between 150-word
abstracts and 10,000-word papers. To bridge that gap, we introduce the idea of
recursively expandable summaries and present Qlarify, an interactive system
that allows users to recursively expand an abstract by progressively
incorporating additional information from a paper's full text. Starting from an
abstract, users can brush over summary text to specify targeted information
needs or select AI-suggested entities in the text. Responses are then generated
on-demand by an LLM and appear in the form of a fluid, threaded expansion of
the existing text. Each generated summary can be efficiently verified through
attribution to a relevant source-passage in the paper. Through an interview
study (n=9) and a field deployment (n=275) at a research conference, we use
Qlarify as a technology probe to elaborate upon the expandable summaries design
space, highlight how scholars benefit from Qlarify's expandable abstracts, and
identify future opportunities to support low-effort and just-in-time
exploration of scientific documents $\unicode{x2013}$ and other information
spaces $\unicode{x2013}$ through LLM-powered interactions.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07582" title="Abstract">arXiv:2310.07582</a> [<a href="/pdf/2310.07582" title="Download PDF">pdf</a>, <a href="/format/2310.07582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Latent World Models in Simple Transformers: A Case Study on  Othello-GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazineh%2C+D+S">Dean S. Hazineh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+J">Jeffery Chiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Foundation models exhibit significant capabilities in decision-making and
logical deductions. Nonetheless, a continuing discourse persists regarding
their genuine understanding of the world as opposed to mere stochastic mimicry.
This paper meticulously examines a simple transformer trained for Othello,
extending prior research to enhance comprehension of the emergent world model
of Othello-GPT. The investigation reveals that Othello-GPT encapsulates a
linear representation of opposing pieces, a factor that causally steers its
decision-making process. This paper further elucidates the interplay between
the linear world representation and causal decision-making, and their
dependence on layer depth and model complexity. We have made the code public.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07584" title="Abstract">arXiv:2310.07584</a> [<a href="/pdf/2310.07584" title="Download PDF">pdf</a>, <a href="/format/2310.07584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centrality of the Fingerprint Core Location
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruzicka%2C+L">Laurenz Ruzicka</a>, 
<a href="/search/cs?searchtype=author&query=Strobl%2C+B">Bernhard Strobl</a>, 
<a href="/search/cs?searchtype=author&query=Kohn%2C+B">Bernhard Kohn</a>, 
<a href="/search/cs?searchtype=author&query=Heitzinger%2C+C">Clemens Heitzinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fingerprints have long been recognized as a unique and reliable means of
personal identification. Central to the analysis and enhancement of
fingerprints is the concept of the fingerprint core. Although the location of
the core is used in many applications, to the best of our knowledge, this study
is the first to investigate the empirical distribution of the core over a
large, combined dataset of rolled, as well as plain fingerprint recordings. We
identify and investigate the extent of incomplete rolling during the rolled
fingerprint acquisition and investigate the centrality of the core. After
correcting for the incomplete rolling, we find that the core deviates from the
fingerprint center by 5.7% $\pm$ 5.2% to 7.6% $\pm$ 6.9%, depending on the
finger. Additionally, we find that the assumption of normal distribution of the
core position of plain fingerprint recordings cannot be rejected, but for
rolled ones it can. Therefore, we use a multi-step process to find the
distribution of the rolled fingerprint recordings. The process consists of an
Anderson-Darling normality test, the Bayesian Information Criterion to reduce
the number of possible candidate distributions and finally a Generalized Monte
Carlo goodness-of-fit procedure to find the best fitting distribution. We find
the non-central Fischer distribution best describes the cores' horizontal
positions. Finally, we investigate the correlation between mean core position
offset and the NFIQ 2 score and find that the NFIQ 2 prefers rolled fingerprint
recordings where the core sits slightly below the fingerprint center.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07585" title="Abstract">arXiv:2310.07585</a> [<a href="/pdf/2310.07585" title="Download PDF">pdf</a>, <a href="/format/2310.07585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Discrepancy Aware Framework for Robust Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuxuan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dingkang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinwei He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Industrial Informatics. Code is available at: <a href="https://github.com/caiyuxuan1120/DAF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Defect detection is a critical research area in artificial intelligence.
Recently, synthetic data-based self-supervised learning has shown great
potential on this task. Although many sophisticated synthesizing strategies
exist, little research has been done to investigate the robustness of models
when faced with different strategies. In this paper, we focus on this issue and
find that existing methods are highly sensitive to them. To alleviate this
issue, we present a Discrepancy Aware Framework (DAF), which demonstrates
robust performance consistently with simple and cheap strategies across
different anomaly detection benchmarks. We hypothesize that the high
sensitivity to synthetic data of existing self-supervised methods arises from
their heavy reliance on the visual appearance of synthetic data during
decoding. In contrast, our method leverages an appearance-agnostic cue to guide
the decoder in identifying defects, thereby alleviating its reliance on
synthetic appearance. To this end, inspired by existing knowledge distillation
methods, we employ a teacher-student network, which is trained based on
synthesized outliers, to compute the discrepancy map as the cue. Extensive
experiments on two challenging datasets prove the robustness of our method.
Under the simple synthesis strategies, it outperforms existing methods by a
large margin. Furthermore, it also achieves the state-of-the-art localization
performance. Code is available at: https://github.com/caiyuxuan1120/DAF.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07587" title="Abstract">arXiv:2310.07587</a> [<a href="/pdf/2310.07587" title="Download PDF">pdf</a>, <a href="/format/2310.07587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient  Balancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zikai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songshang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+H">Howard Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data privacy and long-tailed distribution are the norms rather than the
exception in many real-world tasks. This paper investigates a federated
long-tailed learning (Fed-LT) task in which each client holds a locally
heterogeneous dataset; if the datasets can be globally aggregated, they jointly
exhibit a long-tailed distribution. Under such a setting, existing federated
optimization and/or centralized long-tailed learning methods hardly apply due
to challenges in (a) characterizing the global long-tailed distribution under
privacy constraints and (b) adjusting the local learning strategy to cope with
the head-tail imbalance. In response, we propose a method termed
$\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB)
module that re-weights clients' gradients in a closed-loop manner, based on the
feedback of global long-tailed distribution evaluated by a Direct Prior
Analyzer (DPA) module. Using $\texttt{Fed-GraB}$, clients can effectively
alleviate the distribution drift caused by data heterogeneity during the model
training process and obtain a global model with better performance on the
minority classes while maintaining the performance of the majority classes.
Extensive experiments demonstrate that $\texttt{Fed-GraB}$ achieves
state-of-the-art performance on representative datasets such as CIFAR-10-LT,
CIFAR-100-LT, ImageNet-LT, and iNaturalist.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07588" title="Abstract">arXiv:2310.07588</a> [<a href="/pdf/2310.07588" title="Download PDF">pdf</a>, <a href="/format/2310.07588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Use of Label Dependency in Multi-Label Text Classification  Through the Lens of Causality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Caoyun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenqing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jidong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yitian Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Applied Intelligence 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-Label Text Classification (MLTC) aims to assign the most relevant
labels to each given text. Existing methods demonstrate that label dependency
can help to improve the model's performance. However, the introduction of label
dependency may cause the model to suffer from unwanted prediction bias. In this
study, we attribute the bias to the model's misuse of label dependency, i.e.,
the model tends to utilize the correlation shortcut in label dependency rather
than fusing text information and label dependency for prediction. Motivated by
causal inference, we propose a CounterFactual Text Classifier (CFTC) to
eliminate the correlation bias, and make causality-based predictions.
Specifically, our CFTC first adopts the predict-then-modify backbone to extract
precise label information embedded in label dependency, then blocks the
correlation shortcut through the counterfactual de-bias technique with the help
of the human causal graph. Experimental results on three datasets demonstrate
that our CFTC significantly outperforms the baselines and effectively
eliminates the correlation bias in datasets.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07589" title="Abstract">arXiv:2310.07589</a> [<a href="/pdf/2310.07589" title="Download PDF">pdf</a>, <a href="/format/2310.07589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pozzobon%2C+L">Luiza Pozzobon</a>, 
<a href="/search/cs?searchtype=author&query=Ermis%2C+B">Beyza Ermis</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+P">Patrick Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Considerable effort has been dedicated to mitigating toxicity, but existing
methods often require drastic modifications to model parameters or the use of
computationally intensive auxiliary models. Furthermore, previous approaches
have often neglected the crucial factor of language's evolving nature over
time. In this work, we present a comprehensive perspective on toxicity
mitigation that takes into account its changing nature. We introduce
Goodtriever, a flexible methodology that matches the current state-of-the-art
toxicity mitigation while achieving 43% relative latency reduction during
inference and being more computationally efficient. By incorporating a
retrieval-based approach at decoding time, Goodtriever enables
toxicity-controlled text generation. Our research advocates for an increased
focus on adaptable mitigation techniques, which better reflect the data drift
models face when deployed in the wild. Code and data are available at
https://github.com/for-ai/goodtriever.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07591" title="Abstract">arXiv:2310.07591</a> [<a href="/pdf/2310.07591" title="Download PDF">pdf</a>, <a href="/format/2310.07591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PeP: a Point enhanced Painting method for unified point cloud tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zichao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Hang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xufeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xin Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junbo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point encoder is of vital importance for point cloud recognition. As the very
beginning step of whole model pipeline, adding features from diverse sources
and providing stronger feature encoding mechanism would provide better input
for downstream modules. In our work, we proposed a novel PeP module to tackle
above issue. PeP contains two main parts, a refined point painting method and a
LM-based point encoder. Experiments results on the nuScenes and KITTI datasets
validate the superior performance of our PeP. The advantages leads to strong
performance on both semantic segmentation and object detection, in both lidar
and multi-modal settings. Notably, our PeP module is model agnostic and
plug-and-play. Our code will be publicly available soon.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07592" title="Abstract">arXiv:2310.07592</a> [<a href="/pdf/2310.07592" title="Download PDF">pdf</a>, <a href="/format/2310.07592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers for Green Semantic Communication: Less Energy, More  Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Shubhabrata Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Beard%2C+C">Cory Beard</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Sejun Song</a> (School of Science and Engineering, University of Missouri-Kansas City, Kansas City, MO, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Semantic communication aims to transmit meaningful and effective information
rather than focusing on individual symbols or bits, resulting in benefits like
reduced latency, bandwidth usage, and higher throughput compared to traditional
communication. However, semantic communication poses significant challenges due
to the need for universal metrics for benchmarking the joint effects of
semantic information loss and practical energy consumption. This research
presents a novel multi-objective loss function named "Energy-Optimized Semantic
Loss" (EOSL), addressing the challenge of balancing semantic information loss
and energy consumption. Through comprehensive experiments on transformer
models, including CPU and GPU energy usage, it is demonstrated that EOSL-based
encoder model selection can save up to 90\% of energy while achieving a 44\%
improvement in semantic similarity performance during inference in this
experiment. This work paves the way for energy-efficient neural network
selection and the development of greener semantic communication architectures.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07595" title="Abstract">arXiv:2310.07595</a> [<a href="/pdf/2310.07595" title="Download PDF">pdf</a>, <a href="/ps/2310.07595" title="Download PostScript">ps</a>, <a href="/format/2310.07595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Subset Sum Ratio faster than Subset Sum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+K">Karl Bringmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SODA'24, 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Subset Sum Ratio is the following optimization problem: Given a set of $n$
positive numbers $I$, find disjoint subsets $X,Y \subseteq I$ minimizing the
ratio $\max\{\Sigma(X)/\Sigma(Y),\Sigma(Y)/\Sigma(X)\}$, where $\Sigma(Z)$
denotes the sum of all elements of $Z$. Subset Sum Ratio is an optimization
variant of the Equal Subset Sum problem. It was introduced by Woeginger and Yu
in '92 and is known to admit an FPTAS [Bazgan, Santha, Tuza '98]. The best
approximation schemes before this work had running time $O(n^4/\varepsilon)$
[Melissinos, Pagourtzis '18], $\tilde O(n^{2.3}/\varepsilon^{2.6})$ and $\tilde
O(n^2/\varepsilon^3)$ [Alonistiotis et al. '22].
<br />In this work, we present an improved approximation scheme for Subset Sum
Ratio running in time $O(n / \varepsilon^{0.9386})$. Here we assume that the
items are given in sorted order, otherwise we need an additional running time
of $O(n \log n)$ for sorting. Our improved running time simultaneously improves
the dependence on $n$ to linear and the dependence on $1/\varepsilon$ to
sublinear.
<br />For comparison, the related Subset Sum problem admits an approximation scheme
running in time $O(n/\varepsilon)$ [Gens, Levner '79]. If one would achieve an
approximation scheme with running time $\tilde O(n / \varepsilon^{0.99})$ for
Subset Sum, then one would falsify the Strong Exponential Time Hypothesis
[Abboud, Bringmann, Hermelin, Shabtay '19] as well as the Min-Plus-Convolution
Hypothesis [Bringmann, Nakos '21]. We thus establish that Subset Sum Ratio
admits faster approximation schemes than Subset Sum. This comes as a surprise,
since at any point in time before this work the best known approximation scheme
for Subset Sum Ratio had a worse running time than the best known approximation
scheme for Subset Sum.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07596" title="Abstract">arXiv:2310.07596</a> [<a href="/pdf/2310.07596" title="Download PDF">pdf</a>, <a href="/format/2310.07596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prospective Side Information for Latent MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+J">Jeongyeol Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Efroni%2C+Y">Yonathan Efroni</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>, 
<a href="/search/cs?searchtype=author&query=Caramanis%2C+C">Constantine Caramanis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In many interactive decision-making settings, there is latent and unobserved
information that remains fixed. Consider, for example, a dialogue system, where
complete information about a user, such as the user's preferences, is not
given. In such an environment, the latent information remains fixed throughout
each episode, since the identity of the user does not change during an
interaction. This type of environment can be modeled as a Latent Markov
Decision Process (LMDP), a special instance of Partially Observed Markov
Decision Processes (POMDPs). Previous work established exponential lower bounds
in the number of latent contexts for the LMDP class. This puts forward a
question: under which natural assumptions a near-optimal policy of an LMDP can
be efficiently learned? In this work, we study the class of LMDPs with {\em
prospective side information}, when an agent receives additional, weakly
revealing, information on the latent context at the beginning of each episode.
We show that, surprisingly, this problem is not captured by contemporary
settings and algorithms designed for partially observed environments. We then
establish that any sample efficient algorithm must suffer at least
$\Omega(K^{2/3})$-regret, as opposed to standard $\Omega(\sqrt{K})$ lower
bounds, and design an algorithm with a matching upper bound.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07598" title="Abstract">arXiv:2310.07598</a> [<a href="/pdf/2310.07598" title="Download PDF">pdf</a>, <a href="/format/2310.07598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Imbalanced Data, Representation Learning and SEP Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moukpe%2C+J">Josias Moukpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Survey Paper, 4 figures, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep Learning methods have significantly advanced various data-driven tasks
such as regression, classification, and forecasting. However, much of this
progress has been predicated on the strong but often unrealistic assumption
that training datasets are balanced with respect to the targets they contain.
This misalignment with real-world conditions, where data is frequently
imbalanced, hampers the effectiveness of such models in practical applications.
Methods that reconsider that assumption and tackle real-world imbalances have
begun to emerge and explore avenues to address this challenge. One such
promising avenue is representation learning, which enables models to capture
complex data characteristics and generalize better to minority classes. By
focusing on a richer representation of the feature space, these techniques hold
the potential to mitigate the impact of data imbalance. In this survey, we
present deep learning works that step away from the balanced-data assumption,
employing strategies like representation learning to better approximate
real-world imbalances. We also highlight a critical application in SEP
forecasting where addressing data imbalance is paramount for success.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07602" title="Abstract">arXiv:2310.07602</a> [<a href="/pdf/2310.07602" title="Download PDF">pdf</a>, <a href="/format/2310.07602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Radar: A Multi-modal Dataset with Dual 4D Radar for Autononous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziying Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Radar has stronger adaptability in adverse scenarios for autonomous driving
environmental perception compared to widely adopted cameras and LiDARs.
Compared with commonly used 3D radars, latest 4D radars have precise vertical
resolution and higher point cloud density, making it a highly promising sensor
for autonomous driving in complex environmental perception. However, due to the
much higher noise than LiDAR, manufacturers choose different filtering
strategies, resulting in an inverse ratio between noise level and point cloud
density. There is still a lack of comparative analysis on which method is
beneficial for deep learning-based perception algorithms in autonomous driving.
One of the main reasons is that current datasets only adopt one type of 4D
radar, making it difficult to compare different 4D radars in the same scene.
Therefore, in this paper, we introduce a novel large-scale multi-modal dataset
featuring, for the first time, two types of 4D radars captured simultaneously.
This dataset enables further research into effective 4D radar perception
algorithms.Our dataset consists of 151 consecutive series, most of which last
20 seconds and contain 10,007 meticulously synchronized and annotated frames.
Moreover, our dataset captures a variety of challenging driving scenarios,
including many road conditions, weather conditions, nighttime and daytime with
different lighting intensities and periods. Our dataset annotates consecutive
frames, which can be applied to 3D object detection and tracking, and also
supports the study of multi-modal tasks. We experimentally validate our
dataset, providing valuable results for studying different types of 4D radars.
This dataset is released on https://github.com/adept-thu/Dual-Radar.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07607" title="Abstract">arXiv:2310.07607</a> [<a href="/pdf/2310.07607" title="Download PDF">pdf</a>, <a href="/format/2310.07607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explicit Local Space-Time Adaptive Framework for Monodomain Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ogiermann%2C+D">Dennis Ogiermann</a>, 
<a href="/search/math?searchtype=author&query=Balzani%2C+D">Daniel Balzani</a>, 
<a href="/search/math?searchtype=author&query=Perotti%2C+L+E">Luigi E. Perotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">We present a new explicit local space-time adaptive framework to decrease the
time required for monodomain simulations for cardiac electrophysiology. Based
on the localized structure of the steep activation wavefront in solutions to
monodomain problems, the proposed framework adopts small time steps and a
tree-based adaptive mesh refinement scheme only in the regions necessary to
resolve these localized structures. The time step and mesh adaptation selection
process is fully controlled by a combination of local error indicators. The
main contributions of this work consist in the introduction of a primal
symmetric interior penalty formulation of the monodomain model and an efficient
algorithmic strategy to manage local time stepping for its temporal
discretization. In a first serial implementation of this framework, we report
decreases in wall-clock time between 2 and 20 times with respect to an
optimized implementation of a commonly used numerical scheme, showing that this
framework is a promising candidate to accelerate monodomain simulations of
cardiac electrophysiology.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07608" title="Abstract">arXiv:2310.07608</a> [<a href="/pdf/2310.07608" title="Download PDF">pdf</a>, <a href="/format/2310.07608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leader-Follower Formation Control of Perturbed Nonholonomic Agents along  Parametric Curves with Directed Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+H">Hui Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+G">Jose Guadalupe Romero</a>, 
<a href="/search/cs?searchtype=author&query=Navarro-Alarcon%2C+D">David Navarro-Alarcon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we propose a novel formation controller for nonholonomic
agents to form general parametric curves. First, we derive a unified parametric
representation for both open and closed curves. Then, a leader-follower
formation controller is designed to form the parametric curves. We consider
directed communications and constant input disturbances rejection in the
controller design. Rigorous Lyapunov-based stability analysis proves the
asymptotic stability of the proposed controller. Detailed numerical simulations
and experimental studies are conducted to verify the performance of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07609" title="Abstract">arXiv:2310.07609</a> [<a href="/pdf/2310.07609" title="Download PDF">pdf</a>, <a href="/format/2310.07609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QACHECK: A Demonstration System for Question-Guided Multi-Hop  Fact-Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xinyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+M">Min-Yen Kan</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 System Demonstrations Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Fact-checking real-world claims often requires complex, multi-step reasoning
due to the absence of direct evidence to support or refute them. However,
existing fact-checking systems often lack transparency in their
decision-making, making it challenging for users to comprehend their reasoning
process. To address this, we propose the Question-guided Multi-hop
Fact-Checking (QACHECK) system, which guides the model's reasoning process by
asking a series of questions critical for verifying a claim. QACHECK has five
key modules: a claim verifier, a question generator, a question-answering
module, a QA validator, and a reasoner. Users can input a claim into QACHECK,
which then predicts its veracity and provides a comprehensive report detailing
its reasoning process, guided by a sequence of (question, answer) pairs.
QACHECK also provides the source of evidence supporting each question,
fostering a transparent, explainable, and user-friendly fact-checking process.
A recorded video of QACHECK is at https://www.youtube.com/watch?v=ju8kxSldM64
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07611" title="Abstract">arXiv:2310.07611</a> [<a href="/pdf/2310.07611" title="Download PDF">pdf</a>, <a href="/format/2310.07611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in  Self-Refined Open-Source Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shashidhar%2C+S">Sumuk Shashidhar</a>, 
<a href="/search/cs?searchtype=author&query=Chinta%2C+A">Abhinav Chinta</a>, 
<a href="/search/cs?searchtype=author&query=Sahai%2C+V">Vaibhav Sahai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenhailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Initial Preprint. Accepted to Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF)

</div>
<p class="mathjax">The dominance of proprietary LLMs has led to restricted access and raised
information privacy concerns. High-performing open-source alternatives are
crucial for information-sensitive and high-volume applications but often lag
behind in performance. To address this gap, we propose (1) A untargeted variant
of iterative self-critique and self-refinement devoid of external influence.
(2) A novel ranking metric - Performance, Refinement, and Inference Cost Score
(PeRFICS) - to find the optimal model for a given task considering refined
performance and cost. Our experiments show that SoTA open source models of
varying sizes from 7B - 65B, on average, improve 8.2% from their baseline
performance. Strikingly, even models with extremely small memory footprints,
such as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39%
improvement in high-creativity, open ended tasks on the Vicuna benchmark.
Vicuna-13B takes it a step further and outperforms ChatGPT post-refinement.
This work has profound implications for resource-constrained and
information-sensitive environments seeking to leverage LLMs without incurring
prohibitive costs, compromising on performance and privacy. The domain-agnostic
self-refinement process coupled with our novel ranking metric facilitates
informed decision-making in model selection, thereby reducing costs and
democratizing access to high-performing language models, as evidenced by case
studies.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07612" title="Abstract">arXiv:2310.07612</a> [<a href="/pdf/2310.07612" title="Download PDF">pdf</a>, <a href="/format/2310.07612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHYDI: Initializing Parameterized Hypercomplex Neural Networks as  Identity Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mancanelli%2C+M">Matteo Mancanelli</a>, 
<a href="/search/cs?searchtype=author&query=Grassucci%2C+E">Eleonora Grassucci</a>, 
<a href="/search/cs?searchtype=author&query=Uncini%2C+A">Aurelio Uncini</a>, 
<a href="/search/cs?searchtype=author&query=Comminiello%2C+D">Danilo Comminiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE MLSP 2023 (Honorable Mention TOP 5% Outstanding Papers)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Neural models based on hypercomplex algebra systems are growing and
prolificating for a plethora of applications, ranging from computer vision to
natural language processing. Hand in hand with their adoption, parameterized
hypercomplex neural networks (PHNNs) are growing in size and no techniques have
been adopted so far to control their convergence at a large scale. In this
paper, we study PHNNs convergence and propose parameterized hypercomplex
identity initialization (PHYDI), a method to improve their convergence at
different scales, leading to more robust performance when the number of layers
scales up, while also reaching the same performance with fewer iterations. We
show the effectiveness of this approach in different benchmarks and with common
PHNNs with ResNets- and Transformer-based architecture. The code is available
at https://github.com/ispamm/PHYDI.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07613" title="Abstract">arXiv:2310.07613</a> [<a href="/pdf/2310.07613" title="Download PDF">pdf</a>, <a href="/format/2310.07613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning-based Knowledge Graph Reasoning for Explainable  Fact-checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikopensius%2C+G">Gustav Nikopensius</a>, 
<a href="/search/cs?searchtype=author&query=Mayank%2C+M">Mohit Mayank</a>, 
<a href="/search/cs?searchtype=author&query=Phukan%2C+O+C">Orchid Chetia Phukan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rajesh Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASONAM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Fact-checking is a crucial task as it ensures the prevention of
misinformation. However, manual fact-checking cannot keep up with the rate at
which false information is generated and disseminated online. Automated
fact-checking by machines is significantly quicker than by humans. But for
better trust and transparency of these automated systems, explainability in the
fact-checking process is necessary. Fact-checking often entails contrasting a
factual assertion with a body of knowledge for such explanations. An effective
way of representing knowledge is the Knowledge Graph (KG). There have been
sufficient works proposed related to fact-checking with the usage of KG but not
much focus is given to the application of reinforcement learning (RL) in such
cases. To mitigate this gap, we propose an RL-based KG reasoning approach for
explainable fact-checking. Extensive experiments on FB15K-277 and NELL-995
datasets reveal that reasoning over a KG is an effective way of producing
human-readable explanations in the form of paths and classifications for fact
claims. The RL reasoning agent computes a path that either proves or disproves
a factual claim, but does not provide a verdict itself. A verdict is reached by
a voting mechanism that utilizes paths produced by the agent. These paths can
be presented to human readers so that they themselves can decide whether or not
the provided evidence is convincing or not. This work will encourage works in
this direction for incorporating RL for explainable fact-checking as it
increases trustworthiness by providing a human-in-the-loop approach.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07621" title="Abstract">arXiv:2310.07621</a> [<a href="/pdf/2310.07621" title="Download PDF">pdf</a>, <a href="/format/2310.07621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AG-CVG: Coverage Planning with a Mobile Recharging UGV and an  Energy-Constrained UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karapetyan%2C+N">Nare Karapetyan</a>, 
<a href="/search/cs?searchtype=author&query=Asghar%2C+A+B">Ahmad Bilal Asghar</a>, 
<a href="/search/cs?searchtype=author&query=Bhaskar%2C+A">Amisha Bhaskar</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangyao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we present an approach for coverage path planning for a team
of an energy-constrained Unmanned Aerial Vehicle (UAV) and an Unmanned Ground
Vehicle (UGV). Both the UAV and the UGV have predefined areas that they have to
cover. The goal is to perform complete coverage by both robots while minimizing
the coverage time. The UGV can also serve as a mobile recharging station. The
UAV and UGV need to occasionally rendezvous for recharging. We propose a
heuristic method to address this NP-Hard planning problem. Our approach
involves initially determining coverage paths without factoring in energy
constraints. Subsequently, we cluster segments of these paths and employ graph
matching to assign UAV clusters to UGV clusters for efficient recharging
management. We perform numerical analysis on real-world coverage applications
and show that compared with a greedy approach our method reduces rendezvous
overhead on average by 11.33\%. We demonstrate proof-of-concept with a team of
a VOXL m500 drone and a Clearpath Jackal ground vehicle, providing a complete
system from the offline algorithm to the field execution.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07623" title="Abstract">arXiv:2310.07623</a> [<a href="/pdf/2310.07623" title="Download PDF">pdf</a>, <a href="/format/2310.07623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Quaternion Rotational and Translational Equivariance in 3D Rigid  Motion Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vieira%2C+G">Guilherme Vieira</a>, 
<a href="/search/cs?searchtype=author&query=Grassucci%2C+E">Eleonora Grassucci</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+M+E">Marcos Eduardo Valle</a>, 
<a href="/search/cs?searchtype=author&query=Comminiello%2C+D">Danilo Comminiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE MLSP 2023 (Honorable Mention Top 10% Outstanding Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Objects' rigid motions in 3D space are described by rotations and
translations of a highly-correlated set of points, each with associated $x,y,z$
coordinates that real-valued networks consider as separate entities, losing
information. Previous works exploit quaternion algebra and their ability to
model rotations in 3D space. However, these algebras do not properly encode
translations, leading to sub-optimal performance in 3D learning tasks. To
overcome these limitations, we employ a dual quaternion representation of rigid
motions in the 3D space that jointly describes rotations and translations of
point sets, processing each of the points as a single entity. Our approach is
translation and rotation equivariant, so it does not suffer from shifts in the
data and better learns object trajectories, as we validate in the experimental
evaluations. Models endowed with this formulation outperform previous
approaches in a human pose forecasting application, attesting to the
effectiveness of the proposed dual quaternion formulation for rigid motions in
3D space.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07625" title="Abstract">arXiv:2310.07625</a> [<a href="/pdf/2310.07625" title="Download PDF">pdf</a>, <a href="/format/2310.07625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity as a Crosscutting Concept Across an Undergrad Computer  Science Curriculum: An Experience Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+A">Azqa Nadeem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages; Accepted at SIGCSE TS '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Although many Computer Science (CS) programs offer cybersecurity courses,
they are typically optional and placed at the periphery of the program. We
advocate to integrate cybersecurity as a crosscutting concept in CS curricula,
which is also consistent with latest cybersecurity curricular guidelines, e.g.,
CSEC2017. We describe our experience of implementing this crosscutting
intervention across three undergraduate core CS courses at a leading technical
university in Europe between 2018 and 2023, collectively educating over 2200
students. The security education was incorporated within CS courses using a
partnership between the responsible course instructor and a security expert,
i.e., the security expert (after consultation with course instructors)
developed and taught lectures covering multiple CSEC2017 knowledge areas. This
created a complex dynamic between three stakeholders: the course instructor,
the security expert, and the students. We reflect on our intervention from the
perspective of the three stakeholders -- we conducted a post-course survey to
collect student perceptions, and semi-supervised interviews with responsible
course instructors and the security expert to gauge their experience. We found
that while the students were extremely enthusiastic about the security content
and retained its impact several years later, the misaligned incentives for the
instructors and the security expert made it difficult to sustain this
intervention without organizational support. By identifying limitations in our
intervention, we suggest ideas for sustaining it.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07626" title="Abstract">arXiv:2310.07626</a> [<a href="/pdf/2310.07626" title="Download PDF">pdf</a>, <a href="/format/2310.07626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning of Sea Surface Height Interpolation from  Multi-variate Simulated Satellite Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Archambault%2C+T">Theo Archambault</a>, 
<a href="/search/cs?searchtype=author&query=Filoche%2C+A">Arthur Filoche</a>, 
<a href="/search/cs?searchtype=author&query=Charantonis%2C+A">Anastase Charantonis</a>, 
<a href="/search/cs?searchtype=author&query=Bereziat%2C+D">Dominique Bereziat</a>, 
<a href="/search/cs?searchtype=author&query=Thiria%2C+S">Sylvie Thiria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to JAMES. 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Satellite-based remote sensing missions have revolutionized our understanding
of the Ocean state and dynamics. Among them, spaceborne altimetry provides
valuable measurements of Sea Surface Height (SSH), which is used to estimate
surface geostrophic currents. However, due to the sensor technology employed,
important gaps occur in SSH observations. Complete SSH maps are produced by the
altimetry community using linear Optimal Interpolations (OI) such as the
widely-used Data Unification and Altimeter Combination System (DUACS). However,
OI is known for producing overly smooth fields and thus misses some
mesostructures and eddies. On the other hand, Sea Surface Temperature (SST)
products have much higher data coverage and SST is physically linked to
geostrophic currents through advection. We design a realistic twin experiment
to emulate the satellite observations of SSH and SST to evaluate interpolation
methods. We introduce a deep learning network able to use SST information, and
a trainable in two settings: one where we have no access to ground truth during
training and one where it is accessible. Our investigation involves a
comparative analysis of the aforementioned network when trained using either
supervised or unsupervised loss functions. We assess the quality of SSH
reconstructions and further evaluate the network's performance in terms of eddy
detection and physical properties. We find that it is possible, even in an
unsupervised setting to use SST to improve reconstruction performance compared
to SST-agnostic interpolations. We compare our reconstructions to DUACS's and
report a decrease of 41\% in terms of root mean squared error.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07629" title="Abstract">arXiv:2310.07629</a> [<a href="/pdf/2310.07629" title="Download PDF">pdf</a>, <a href="/format/2310.07629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Past, Present and Better Future of Feedback Learning in Large  Language Models for Subjective Human Preferences and Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Bean%2C+A+M">Andrew M. Bean</a>, 
<a href="/search/cs?searchtype=author&query=Vidgen%2C+B">Bertie Vidgen</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6ttger%2C+P">Paul R&#xf6;ttger</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+S+A">Scott A. Hale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP, Main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Human feedback is increasingly used to steer the behaviours of Large Language
Models (LLMs). However, it is unclear how to collect and incorporate feedback
in a way that is efficient, effective and unbiased, especially for highly
subjective human preferences and values. In this paper, we survey existing
approaches for learning from human feedback, drawing on 95 papers primarily
from the ACL and arXiv repositories.First, we summarise the past, pre-LLM
trends for integrating human feedback into language models. Second, we give an
overview of present techniques and practices, as well as the motivations for
using feedback; conceptual frameworks for defining values and preferences; and
how feedback is collected and from whom. Finally, we encourage a better future
of feedback learning in LLMs by raising five unresolved conceptual and
practical challenges.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07630" title="Abstract">arXiv:2310.07630</a> [<a href="/pdf/2310.07630" title="Download PDF">pdf</a>, <a href="/format/2310.07630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Euler Characteristic Transforms for Shape Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roell%2C+E">Ernst Roell</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+B">Bastian Rieck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The Euler Characteristic Transform (ECT) has proven to be a powerful
representation, combining geometrical and topological characteristics of shapes
and graphs. However, the ECT was hitherto unable to learn task-specific
representations. We overcome this issue and develop a novel computational layer
that enables learning the ECT in an end-to-end fashion. Our method DECT is fast
and computationally efficient, while exhibiting performance on a par with more
complex models in both graph and point cloud classification tasks. Moreover, we
show that this seemingly unexpressive statistic still provides the same
topological expressivity as more complex topological deep learning layers
provide.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07631" title="Abstract">arXiv:2310.07631</a> [<a href="/pdf/2310.07631" title="Download PDF">pdf</a>, <a href="/format/2310.07631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Transformer Network for Flood Forecasting with Heterogeneous  Covariates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jimeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Stebliankin%2C+V">Vitalii Stebliankin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+G">Giri Narasimhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Floods can be very destructive causing heavy damage to life, property, and
livelihoods. Global climate change and the consequent sea-level rise have
increased the occurrence of extreme weather events, resulting in elevated and
frequent flood risk. Therefore, accurate and timely flood forecasting in
coastal river systems is critical to facilitate good flood management. However,
the computational tools currently used are either slow or inaccurate. In this
paper, we propose a Flood prediction tool using Graph Transformer Network
(FloodGTN) for river systems. More specifically, FloodGTN learns the
spatio-temporal dependencies of water levels at different monitoring stations
using Graph Neural Networks (GNNs) and an LSTM. It is currently implemented to
consider external covariates such as rainfall, tide, and the settings of
hydraulic structures (e.g., outflows of dams, gates, pumps, etc.) along the
river. We use a Transformer to learn the attention given to external covariates
in computing water levels. We apply the FloodGTN tool to data from the South
Florida Water Management District, which manages a coastal area prone to
frequent storms and hurricanes. Experimental results show that FloodGTN
outperforms the physics-based model (HEC-RAS) by achieving higher accuracy with
70% improvement while speeding up run times by at least 500x.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07632" title="Abstract">arXiv:2310.07632</a> [<a href="/pdf/2310.07632" title="Download PDF">pdf</a>, <a href="/format/2310.07632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Backdoors in Visual Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhengyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fine-tuning large pre-trained computer vision models is infeasible for
resource-limited users. Visual prompt learning (VPL) has thus emerged to
provide an efficient and flexible alternative to model fine-tuning through
Visual Prompt as a Service (VPPTaaS). Specifically, the VPPTaaS provider
optimizes a visual prompt given downstream data, and downstream users can use
this prompt together with the large pre-trained model for prediction. However,
this new learning paradigm may also pose security risks when the VPPTaaS
provider instead provides a malicious visual prompt. In this paper, we take the
first step to explore such risks through the lens of backdoor attacks.
Specifically, we propose BadVisualPrompt, a simple yet effective backdoor
attack against VPL. For example, poisoning $5\%$ CIFAR10 training data leads to
above $99\%$ attack success rates with only negligible model accuracy drop by
$1.5\%$. In particular, we identify and then address a new technical challenge
related to interactions between the backdoor trigger and visual prompt, which
does not exist in conventional, model-level backdoors. Moreover, we provide
in-depth analyses of seven backdoor defenses from model, prompt, and input
levels. Overall, all these defenses are either ineffective or impractical to
mitigate our BadVisualPrompt, implying the critical vulnerability of VPL.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07637" title="Abstract">arXiv:2310.07637</a> [<a href="/pdf/2310.07637" title="Download PDF">pdf</a>, <a href="/format/2310.07637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+C">Changhua Pei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Longlong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bohan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yongqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Gaogang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xidaoo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+X">Xiaohui Nie</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+D">Dan Pei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Large language models (LLMs) have exhibited remarkable capabilities in
NLP-related tasks such as translation, summarizing, and generation. The
application of LLMs in specific areas, notably AIOps (Artificial Intelligence
for IT Operations), holds great potential due to their advanced abilities in
information summarizing, report analyzing, and ability of API calling.
Nevertheless, the performance of current LLMs in AIOps tasks is yet to be
determined. Furthermore, a comprehensive benchmark is required to steer the
optimization of LLMs tailored for AIOps. Compared with existing benchmarks that
focus on evaluating specific fields like network configuration, in this paper,
we present \textbf{OpsEval}, a comprehensive task-oriented AIOps benchmark
designed for LLMs. For the first time, OpsEval assesses LLMs' proficiency in
three crucial scenarios (Wired Network Operation, 5G Communication Operation,
and Database Operation) at various ability levels (knowledge recall, analytical
thinking, and practical application). The benchmark includes 7,200 questions in
both multiple-choice and question-answer (QA) formats, available in English and
Chinese. With quantitative and qualitative results, we show how various LLM
tricks can affect the performance of AIOps, including zero-shot,
chain-of-thought, and few-shot in-context learning. We find that GPT4-score is
more consistent with experts than widely used Bleu and Rouge, which can be used
to replace automatic metrics for large-scale qualitative evaluations.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07638" title="Abstract">arXiv:2310.07638</a> [<a href="/pdf/2310.07638" title="Download PDF">pdf</a>, <a href="/format/2310.07638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Enhanced Detector For Building Detection From Remote Sensing  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhe Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of building detection from remote sensing images has made
significant progress, but faces challenges in achieving high-accuracy detection
due to the diversity in building appearances and the complexity of vast scenes.
To address these challenges, we propose a novel approach called
Context-Enhanced Detector (CEDet). Our approach utilizes a three-stage cascade
structure to enhance the extraction of contextual information and improve
building detection accuracy. Specifically, we introduce two modules: the
Semantic Guided Contextual Mining (SGCM) module, which aggregates multi-scale
contexts and incorporates an attention mechanism to capture long-range
interactions, and the Instance Context Mining Module (ICMM), which captures
instance-level relationship context by constructing a spatial relationship
graph and aggregating instance features. Additionally, we introduce a semantic
segmentation loss based on pseudo-masks to guide contextual information
extraction. Our method achieves state-of-the-art performance on three building
detection benchmarks, including CNBuilding-9P, CNBuilding-23P, and SpaceNet.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07641" title="Abstract">arXiv:2310.07641</a> [<a href="/pdf/2310.07641" title="Download PDF">pdf</a>, <a href="/format/2310.07641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models at Evaluating Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhiyuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiatong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tianyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+T">Tanya Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As research in large language models (LLMs) continues to accelerate,
LLM-based evaluation has emerged as a scalable and cost-effective alternative
to human evaluations for comparing the ever increasing list of models. This
paper investigates the efficacy of these "LLM evaluators", particularly in
using them to assess instruction following, a metric that gauges how closely
generated text adheres to the given instruction. We introduce a challenging
meta-evaluation benchmark, LLMBar, designed to test the ability of an LLM
evaluator in discerning instruction-following outputs. The authors manually
curated 419 pairs of outputs, one adhering to instructions while the other
diverging, yet may possess deceptive qualities that mislead an LLM evaluator,
e.g., a more engaging tone. Contrary to existing meta-evaluation, we discover
that different evaluators (i.e., combinations of LLMs and prompts) exhibit
distinct performance on LLMBar and even the highest-scoring ones have
substantial room for improvement. We also present a novel suite of prompting
strategies that further close the gap between LLM and human evaluators. With
LLMBar, we hope to offer more insight into LLM evaluators and foster future
research in developing better instruction-following models.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07644" title="Abstract">arXiv:2310.07644</a> [<a href="/pdf/2310.07644" title="Download PDF">pdf</a>, <a href="/format/2310.07644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the BERT-like Pretraining for DNA Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chaoqi Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Weiqiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Lifeng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuchen Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianle Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hongliang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinzhu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the success of large-scale pretraining in NLP, there is an increasing
trend of applying it to the domain of life sciences. In particular, pretraining
methods based on DNA sequences have garnered growing attention due to their
potential to capture generic information about genes. However, existing
pretraining methods for DNA sequences largely rely on direct adoptions of BERT
pretraining from NLP, lacking a comprehensive understanding and a specifically
tailored approach. To address this research gap, we first conducted a series of
exploratory experiments and gained several insightful observations: 1) In the
fine-tuning phase of downstream tasks, when using K-mer overlapping
tokenization instead of K-mer non-overlapping tokenization, both overlapping
and non-overlapping pretraining weights show consistent performance
improvement.2) During the pre-training process, using K-mer overlapping
tokenization quickly produces clear K-mer embeddings and reduces the loss to a
very low level, while using K-mer non-overlapping tokenization results in less
distinct embeddings and continuously decreases the loss. 3) Using overlapping
tokenization causes the self-attention in the intermediate layers of
pre-trained models to tend to overly focus on certain tokens, reflecting that
these layers are not adequately optimized. In summary, overlapping tokenization
can benefit the fine-tuning of downstream tasks but leads to inadequate
pretraining with fast convergence. To unleash the pretraining potential, we
introduce a novel approach called RandomMask, which gradually increases the
task difficulty of BERT-like pretraining by continuously expanding its mask
boundary, forcing the model to learn more knowledge. RandomMask is simple but
effective, achieving top-tier performance across 26 datasets of 28 datasets
spanning 7 downstream tasks.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07646" title="Abstract">arXiv:2310.07646</a> [<a href="/pdf/2310.07646" title="Download PDF">pdf</a>, <a href="/format/2310.07646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEO Satellite Networking Relaunched: Survey and Current Research  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westphal%2C+C">Cedric Westphal</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lin Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Richard Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures, to be published in ITU Journal on Future and Evolving Technologies (ITU J-FET)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This document surveys recent and current developments in LEO satellite
networking. It presents a brief overview of satellite networking in order to
contextualize the issue. It then focuses on current research work in emerging
domains, such as Machine Learning, SDN, low latency networking, green
networking, Information-Centric Networks, etc. For each, it presents recent
works and a direction of the research community within that emerging domain.
<br />The paper also describes the current state of standardization efforts in 3GPP
and in IETF for LEO satellite networking. In particular, we present in some
detail the direction these standards body are pointing towards for LEO
networking with inter-satellites links. Finally, some future challenges and
interesting research directions are described and motivated. This is an
overview of the current state of the LEO satellite research in both academic
and industrial standardization environments which we believe will be helpful to
understand the current state of the art.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07648" title="Abstract">arXiv:2310.07648</a> [<a href="/pdf/2310.07648" title="Download PDF">pdf</a>, <a href="/format/2310.07648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypercomplex Multimodal Emotion Recognition from EEG and Peripheral  Physiological Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopez%2C+E">Eleonora Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Chiarantano%2C+E">Eleonora Chiarantano</a>, 
<a href="/search/cs?searchtype=author&query=Grassucci%2C+E">Eleonora Grassucci</a>, 
<a href="/search/cs?searchtype=author&query=Comminiello%2C+D">Danilo Comminiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at IEEE ICASSP workshops 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Multimodal emotion recognition from physiological signals is receiving an
increasing amount of attention due to the impossibility to control them at will
unlike behavioral reactions, thus providing more reliable information. Existing
deep learning-based methods still rely on extracted handcrafted features, not
taking full advantage of the learning ability of neural networks, and often
adopt a single-modality approach, while human emotions are inherently expressed
in a multimodal way. In this paper, we propose a hypercomplex multimodal
network equipped with a novel fusion module comprising parameterized
hypercomplex multiplications. Indeed, by operating in a hypercomplex domain the
operations follow algebraic rules which allow to model latent relations among
learned feature dimensions for a more effective fusion step. We perform
classification of valence and arousal from electroencephalogram (EEG) and
peripheral physiological signals, employing the publicly available database
MAHNOB-HCI surpassing a multimodal state-of-the-art network. The code of our
work is freely available at https://github.com/ispamm/MHyEEG.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07649" title="Abstract">arXiv:2310.07649</a> [<a href="/pdf/2310.07649" title="Download PDF">pdf</a>, <a href="/format/2310.07649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Layout Design and Control of Robust Cooperative Grasped-Load  Aerial Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosio%2C+C">Carlo Bosio</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jerry Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting-Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+M+W">Mark W. Mueller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a novel approach to cooperative aerial transportation through a
team of drones, using optimal control theory and a hierarchical control
strategy. We assume the drones are connected to the payload through rigid
attachments, essentially transforming the whole system into a larger flying
object with "thrust modules" at the attachment locations of the drones. We
investigate the optimal arrangement of the thrust modules around the payload,
so that the resulting system is robust to disturbances. We choose the
$\mathcal{H}_2$ norm as a measure of robustness, and propose an iterative
optimization routine to compute the optimal layout of the vehicles around the
object. We experimentally validate our approach using four drones and comparing
the disturbance rejection performances achieved by two different layouts (the
optimal one and a sub-optimal one), and observe that the results match our
predictions.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07651" title="Abstract">arXiv:2310.07651</a> [<a href="/pdf/2310.07651" title="Download PDF">pdf</a>, <a href="/format/2310.07651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polytopal discontinuous Galerkin discretization of brain multiphysics  flow dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fumagalli%2C+I">Ivan Fumagalli</a>, 
<a href="/search/math?searchtype=author&query=Corti%2C+M">Mattia Corti</a>, 
<a href="/search/math?searchtype=author&query=Parolini%2C+N">Nicola Parolini</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">A comprehensive mathematical model of the multiphysics flow of blood and
Cerebrospinal Fluid (CSF) in the brain can be expressed as the coupling of a
poromechanics system and Stokes' equations: the first describes fluids
filtration through the cerebral tissue and the tissue's elastic response, while
the latter models the flow of the CSF in the brain ventricles. This model
describes the functioning of the brain's waste clearance mechanism, which has
been recently discovered to play an essential role in the progress of
neurodegenerative diseases. To model the interactions between different scales
in the porous medium, we propose a physically consistent coupling between
Multi-compartment Poroelasticity (MPE) equations and Stokes' equations. In this
work, we introduce a numerical scheme for the discretization of such coupled
MPE-Stokes system, employing a high-order discontinuous Galerkin method on
polytopal grids to efficiently account for the geometric complexity of the
domain. We analyze the stability and convergence of the space semidiscretized
formulation, we prove a-priori error estimates, and we present a temporal
discretization based on a combination of Newmark's $\beta$-method for the
elastic wave equation and the $\theta$-method for the other equations of the
model. Numerical simulations carried out on test cases with manufactured
solutions validate the theoretical error estimates. We also present numerical
results on a two-dimensional slice of a patient-specific brain geometry
reconstructed from diagnostic images, to test in practice the advantages of the
proposed approach.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07652" title="Abstract">arXiv:2310.07652</a> [<a href="/pdf/2310.07652" title="Download PDF">pdf</a>, <a href="/format/2310.07652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4Vis: Explainable Visualization Recommendation using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E">Ee-Peng Lim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Industry Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Data visualization is a powerful tool for exploring and communicating
insights in various domains. To automate visualization choice for datasets, a
task known as visualization recommendation has been proposed. Various
machine-learning-based approaches have been developed for this purpose, but
they often require a large corpus of dataset-visualization pairs for training
and lack natural explanations for their results. To address this research gap,
we propose LLM4Vis, a novel ChatGPT-based prompting approach to perform
visualization recommendation and return human-like explanations using very few
demonstration examples. Our approach involves feature description,
demonstration example selection, explanation generation, demonstration example
construction, and inference steps. To obtain demonstration examples with
high-quality explanations, we propose a new explanation generation
bootstrapping to iteratively refine generated explanations by considering the
previous generation and template-based hint. Evaluations on the VizML dataset
show that LLM4Vis outperforms or performs similarly to supervised learning
models like Random Forest, Decision Tree, and MLP in both few-shot and
zero-shot settings. The qualitative evaluation also shows the effectiveness of
explanations generated by LLM4Vis. We make our code publicly available at
\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07653" title="Abstract">arXiv:2310.07653</a> [<a href="/pdf/2310.07653" title="Download PDF">pdf</a>, <a href="/format/2310.07653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini-DALLE3: Interactive Text to Image by Prompting Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeqiang%2C+L">Lai Zeqiang</a>, 
<a href="/search/cs?searchtype=author&query=Xizhou%2C+Z">Zhu Xizhou</a>, 
<a href="/search/cs?searchtype=author&query=Jifeng%2C+D">Dai Jifeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wenhai%2C+W">Wang Wenhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Project page at <a href="https://minidalle3.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The revolution of artificial intelligence content generation has been rapidly
accelerated with the booming text-to-image (T2I) diffusion models. Within just
two years of development, it was unprecedentedly of high-quality, diversity,
and creativity that the state-of-the-art models could generate. However, a
prevalent limitation persists in the effective communication with these popular
T2I models, such as Stable Diffusion, using natural language descriptions. This
typically makes an engaging image hard to obtain without expertise in prompt
engineering with complex word compositions, magic tags, and annotations.
Inspired by the recently released DALLE3 - a T2I model directly built-in
ChatGPT that talks human language, we revisit the existing T2I systems
endeavoring to align human intent and introduce a new task - interactive text
to image (iT2I), where people can interact with LLM for interleaved
high-quality image generation/edit/refinement and question answering with
stronger images and text correspondences using natural language. In addressing
the iT2I problem, we present a simple approach that augments LLMs for iT2I with
prompting techniques and off-the-shelf T2I models. We evaluate our approach for
iT2I in a variety of common-used scenarios under different LLMs, e.g., ChatGPT,
LLAMA, Baichuan, and InternLM. We demonstrate that our approach could be a
convenient and low-cost way to introduce the iT2I ability for any existing LLMs
and any text-to-image models without any training while bringing little
degradation on LLMs' inherent capabilities in, e.g., question answering and
code generation. We hope this work could draw broader attention and provide
inspiration for boosting user experience in human-machine interactions
alongside the image quality of the next-generation T2I systems.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07654" title="Abstract">arXiv:2310.07654</a> [<a href="/pdf/2310.07654" title="Download PDF">pdf</a>, <a href="/format/2310.07654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Neural Syntax Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+C+J">Cheng-I Jeff Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Freda Shi</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Puyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gimpel%2C+K">Kevin Gimpel</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yung-Sung Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Bhati%2C+S">Saurabhchand Bhati</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+D">David Cox</a>, 
<a href="/search/cs?searchtype=author&query=Harwath%2C+D">David Harwath</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Livescu%2C+K">Karen Livescu</a>, 
<a href="/search/cs?searchtype=author&query=Glass%2C+J">James Glass</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We study phrase structure induction from visually-grounded speech. The core
idea is to first segment the speech waveform into sequences of word segments,
and subsequently induce phrase structure using the inferred segment-level
continuous representations. We present the Audio-Visual Neural Syntax Learner
(AV-NSL) that learns phrase structure by listening to audio and looking at
images, without ever being exposed to text. By training on paired images and
spoken captions, AV-NSL exhibits the capability to infer meaningful phrase
structures that are comparable to those derived by naturally-supervised text
parsers, for both English and German. Our findings extend prior work in
unsupervised language acquisition from speech and grounded grammar induction,
and present one approach to bridge the gap between the two topics.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07656" title="Abstract">arXiv:2310.07656</a> [<a href="/pdf/2310.07656" title="Download PDF">pdf</a>, <a href="/ps/2310.07656" title="Download PostScript">ps</a>, <a href="/format/2310.07656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Throughput and Makespan of Queuing Systems by Information  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Griesbach%2C+S+M">Svenja M. Griesbach</a>, 
<a href="/search/cs?searchtype=author&query=Klimm%2C+M">Max Klimm</a>, 
<a href="/search/cs?searchtype=author&query=Warode%2C+P">Philipp Warode</a>, 
<a href="/search/cs?searchtype=author&query=Ziemke%2C+T">Theresa Ziemke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study the optimal provision of information for two natural performance
measures of queuing systems: throughput and makespan. A set of parallel links
is equipped with deterministic capacities and stochastic travel times where the
latter depend on a realized scenario. A continuum of flow particles arrives at
the system at a constant rate. A system operator knows the realization of the
scenario and may (partially) reveal this information via a public signaling
scheme to the flow particles. Upon arrival, the flow particles observe the
signal issued by the system operator, form an updated belief about the realized
scenario, and decide on a link to use. Inflow into a link exceeding the link's
capacity builds up in a queue that increases the travel time on the link.
Dynamic inflow rates are in a Bayesian dynamic equilibrium when the expected
travel time along all links with positive inflow is equal at every point in
time. We provide an additive polynomial time approximation scheme (PTAS) that
approximates the optimal throughput by an arbitrary additive constant
$\epsilon&gt;0$. The algorithm solves a Langrangian dual of the signaling problem
with the Ellipsoid method whose separation oracle is implemented by a cell
decomposition technique. We also provide a multiplicative fully polynomial time
approximation scheme (FPTAS) that does not rely on strong duality and, thus,
allows to compute also the optimal signals. It uses a different cell
decomposition technique together with a piece-wise convex under-estimator of
the optimal value function. Finally, we consider the makespan of a Bayesian
dynamic equilibrium which is defined as the last point in time when a total
given value of flow leaves the system. Using a variational inequality argument,
we show that full information revelation is a public signaling scheme that
minimizes the makespan.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07659" title="Abstract">arXiv:2310.07659</a> [<a href="/pdf/2310.07659" title="Download PDF">pdf</a>, <a href="/format/2310.07659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for  Knowledge-Grounded Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lang%2C+Q">Qin Lang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Hongru%2C+L">Liang Hongru</a>, 
<a href="/search/cs?searchtype=author&query=jun%2C+W">Wang jun</a>, 
<a href="/search/cs?searchtype=author&query=Zhenglu%2C+Y">Yang Zhenglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Accurate knowledge selection is critical in knowledge-grounded dialogue
systems. Towards a closer look at it, we offer a novel perspective to organize
existing literature, i.e., knowledge selection coupled with, after, and before
generation. We focus on the third under-explored category of study, which can
not only select knowledge accurately in advance, but has the advantage to
reduce the learning, adjustment, and interpretation burden of subsequent
response generation models, especially LLMs. We propose GATE, a
generator-agnostic knowledge selection method, to prepare knowledge for
subsequent response generation models by selecting context-related knowledge
among different knowledge structures and variable knowledge requirements.
Experimental results demonstrate the superiority of GATE, and indicate that
knowledge selection before generation is a lightweight yet effective way to
facilitate LLMs (e.g., ChatGPT) to generate more informative responses.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07662" title="Abstract">arXiv:2310.07662</a> [<a href="/pdf/2310.07662" title="Download PDF">pdf</a>, <a href="/ps/2310.07662" title="Download PostScript">ps</a>, <a href="/format/2310.07662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical stability of the symplectic $LL^T$ factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bujok%2C+M">Maksymilian Bujok</a>, 
<a href="/search/math?searchtype=author&query=Rozlo%C5%BEn%C3%ADk%2C+M">Miroslav Rozlo&#x17e;n&#xed;k</a>, 
<a href="/search/math?searchtype=author&query=Smoktunowicz%2C+A">Agata Smoktunowicz</a>, 
<a href="/search/math?searchtype=author&query=Smoktunowicz%2C+A">Alicja Smoktunowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we give the detailed error analysis of two algorithms (denoted
as $W_1$ and $W_2$) for computing the symplectic factorization of a symmetric
positive definite and symplectic matrix $A \in \mathbb R^{2n \times 2n}$ in the
form $A=LL^T$, where $L \in \mathbb R^{2n \times 2n}$ is a symplectic block
lower triangular matrix. Algorithm $W_1$ is an implementation of the $HH^T$
factorization from [Dopico et al., 2009]. Algorithm $W_2$, proposed in [Bujok
et al., 2023], uses both Cholesky and Reverse Cholesky decompositions of
symmetric positive definite matrix blocks that appear during the factorization.
<br />We prove that Algorithm $W_2$ is numerically stable for a broader class of
symmetric positive definite matrices $A \in \mathbb R^{2n \times 2n}$,
producing the computed factors $\tilde L$ in floating-point arithmetic with
machine precision $u$, such that $||A-\tilde L {\tilde L}^T||_2= {\cal O}(u
||A||_2)$. However, Algorithm $W_1$ is unstable in general for symmetric
positive definite and symplectic matrix $A$. This was confirmed by numerical
experiments in [Bujok et al., 2023]. In this paper we give corresponding bounds
also for Algorithm $W_1$ that are weaker, since we show that the factorization
error depends on the size of the inverse of the principal submatrix $A_{11}$.
The tests performed in MATLAB illustrate that our error bounds for considered
algorithms are reasonably sharp.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07664" title="Abstract">arXiv:2310.07664</a> [<a href="/pdf/2310.07664" title="Download PDF">pdf</a>, <a href="/format/2310.07664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Vision Transformers Based on Heterogeneous Attention  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Deli Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+T">Teng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baopu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Haocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingtuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+E">Errui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, Vision Transformers (ViTs) have attracted a lot of attention in the
field of computer vision. Generally, the powerful representative capacity of
ViTs mainly benefits from the self-attention mechanism, which has a high
computation complexity. To accelerate ViTs, we propose an integrated
compression pipeline based on observed heterogeneous attention patterns across
layers. On one hand, different images share more similar attention patterns in
early layers than later layers, indicating that the dynamic query-by-key
self-attention matrix may be replaced with a static self-attention matrix in
early layers. Then, we propose a dynamic-guided static self-attention (DGSSA)
method where the matrix inherits self-attention information from the replaced
dynamic self-attention to effectively improve the feature representation
ability of ViTs. On the other hand, the attention maps have more low-rank
patterns, which reflect token redundancy, in later layers than early layers. In
a view of linear dimension reduction, we further propose a method of global
aggregation pyramid (GLAD) to reduce the number of tokens in later layers of
ViTs, such as Deit. Experimentally, the integrated compression pipeline of
DGSSA and GLAD can accelerate up to 121% run-time throughput compared with
DeiT, which surpasses all SOTA approaches.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07665" title="Abstract">arXiv:2310.07665</a> [<a href="/pdf/2310.07665" title="Download PDF">pdf</a>, <a href="/format/2310.07665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Backtracking Counterfactuals for Causally Compliant Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kladny%2C+K">Klaus-Rudolf Kladny</a>, 
<a href="/search/cs?searchtype=author&query=von+K%C3%BCgelgen%2C+J">Julius von K&#xfc;gelgen</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Muehlebach%2C+M">Michael Muehlebach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Counterfactuals can offer valuable insights by answering what would have been
observed under altered circumstances, conditional on a factual observation.
Whereas the classical interventional interpretation of counterfactuals has been
studied extensively, backtracking constitutes a less studied alternative the
backtracking principle has emerged as an alternative philosophy where all
causal laws are kept intact. In the present work, we introduce a practical
method for computing backtracking counterfactuals in structural causal models
that consist of deep generative components. To this end, we impose conditions
on the structural assignments that enable the generation of counterfactuals by
solving a tractable constrained optimization problem in the structured latent
space of a causal model. Our formulation also facilitates a comparison with
methods in the field of counterfactual explanations. Compared to these, our
method represents a versatile, modular and causally compliant alternative. We
demonstrate these properties experimentally on a modified version of MNIST and
CelebA.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07667" title="Abstract">arXiv:2310.07667</a> [<a href="/pdf/2310.07667" title="Download PDF">pdf</a>, <a href="/format/2310.07667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Minima, Recoverability Thresholds, and Higher-Order Structure in  GNNS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+D">Drake Brown</a>, 
<a href="/search/cs?searchtype=author&query=Garrity%2C+T">Trevor Garrity</a>, 
<a href="/search/cs?searchtype=author&query=Parker%2C+K">Kaden Parker</a>, 
<a href="/search/cs?searchtype=author&query=Oliphant%2C+J">Jason Oliphant</a>, 
<a href="/search/cs?searchtype=author&query=Carson%2C+S">Stone Carson</a>, 
<a href="/search/cs?searchtype=author&query=Hanson%2C+C">Cole Hanson</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+Z">Zachary Boyd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We analyze the performance of graph neural network (GNN) architectures from
the perspective of random graph theory. Our approach promises to complement
existing lenses on GNN analysis, such as combinatorial expressive power and
worst-case adversarial analysis, by connecting the performance of GNNs to
typical-case properties of the training data. First, we theoretically
characterize the nodewise accuracy of one- and two-layer GCNs relative to the
contextual stochastic block model (cSBM) and related models. We additionally
prove that GCNs cannot beat linear models under certain circumstances. Second,
we numerically map the recoverability thresholds, in terms of accuracy, of four
diverse GNN architectures (GCN, GAT, SAGE, and Graph Transformer) under a
variety of assumptions about the data. Sample results of this second analysis
include: heavy-tailed degree distributions enhance GNN performance, GNNs can
work well on strongly heterophilous graphs, and SAGE and Graph Transformer can
perform well on arbitrarily noisy edge data, but no architecture handled
sufficiently noisy feature data well. Finally, we show how both specific
higher-order structures in synthetic data and the mix of empirical structures
in real data have dramatic effects (usually negative) on GNN performance.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07668" title="Abstract">arXiv:2310.07668</a> [<a href="/pdf/2310.07668" title="Download PDF">pdf</a>, <a href="/format/2310.07668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRaMuFeN: Graph-based Multi-modal Fake News Detection in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kananian%2C+M">Makan Kananian</a>, 
<a href="/search/cs?searchtype=author&query=Badiei%2C+F">Fatima Badiei</a>, 
<a href="/search/cs?searchtype=author&query=Ghahramani%2C+S+A+G">S. AmirAli Gh. Ghahramani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The proliferation of social media platforms such as Twitter, Instagram, and
Weibo has significantly enhanced the dissemination of false information. This
phenomenon grants both individuals and governmental entities the ability to
shape public opinions, highlighting the need for deploying effective detection
methods. In this paper, we propose GraMuFeN, a model designed to detect fake
content by analyzing both the textual and image content of news. GraMuFeN
comprises two primary components: a text encoder and an image encoder. For
textual analysis, GraMuFeN treats each text as a graph and employs a Graph
Convolutional Neural Network (GCN) as the text encoder. Additionally, the
pre-trained ResNet-152, as a Convolutional Neural Network (CNN), has been
utilized as the image encoder. By integrating the outputs from these two
encoders and implementing a contrastive similarity loss function, GraMuFeN
achieves remarkable results. Extensive evaluations conducted on two publicly
available benchmark datasets for social media news indicate a 10 % increase in
micro F1-Score, signifying improvement over existing state-of-the-art models.
These findings underscore the effectiveness of combining GCN and CNN models for
detecting fake news in multi-modal data, all while minimizing the additional
computational burden imposed by model parameters.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07669" title="Abstract">arXiv:2310.07669</a> [<a href="/pdf/2310.07669" title="Download PDF">pdf</a>, <a href="/format/2310.07669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HaarNet: Large-scale Linear-Morphological Hybrid Network for RGB-D  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groenendijk%2C+R">Rick Groenendijk</a>, 
<a href="/search/cs?searchtype=author&query=Dorst%2C+L">Leo Dorst</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Signals from different modalities each have their own combination algebra
which affects their sampling processing. RGB is mostly linear; depth is a
geometric signal following the operations of mathematical morphology. If a
network obtaining RGB-D input has both kinds of operators available in its
layers, it should be able to give effective output with fewer parameters. In
this paper, morphological elements in conjunction with more familiar linear
modules are used to construct a mixed linear-morphological network called
HaarNet. This is the first large-scale linear-morphological hybrid, evaluated
on a set of sizeable real-world datasets. In the network, morphological Haar
sampling is applied to both feature channels in several layers, which splits
extreme values and high-frequency information such that both can be processed
to improve both modalities. Moreover, morphologically parameterised ReLU is
used, and morphologically-sound up-sampling is applied to obtain a
full-resolution output. Experiments show that HaarNet is competitive with a
state-of-the-art CNN, implying that morphological networks are a promising
research direction for geometry-based learning tasks.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07671" title="Abstract">arXiv:2310.07671</a> [<a href="/pdf/2310.07671" title="Download PDF">pdf</a>, <a href="/format/2310.07671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovery of Novel Reticular Materials for Carbon Dioxide Capture using  GFlowNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cipcigan%2C+F">Flaviu Cipcigan</a>, 
<a href="/search/cs?searchtype=author&query=Booth%2C+J">Jonathan Booth</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+R+N+B">Rodrigo Neumann Barros Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Santo%2C+C+R+d">Carine Ribeiro dos Santo</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+M">Mathias Steiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Artificial intelligence holds promise to improve materials discovery.
GFlowNets are an emerging deep learning algorithm with many applications in
AI-assisted discovery. By using GFlowNets, we generate porous reticular
materials, such as metal organic frameworks and covalent organic frameworks,
for applications in carbon dioxide capture. We introduce a new Python package
(matgfn) to train and sample GFlowNets. We use matgfn to generate the matgfn-rm
dataset of novel and diverse reticular materials with gravimetric surface area
above 5000 m$^2$/g. We calculate single- and two-component gas adsorption
isotherms for the top-100 candidates in matgfn-rm. These candidates are novel
compared to the state-of-art ARC-MOF dataset and rank in the 90th percentile in
terms of working capacity compared to the CoRE2019 dataset. We discover 15
materials outperforming all materials in CoRE2019.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07675" title="Abstract">arXiv:2310.07675</a> [<a href="/pdf/2310.07675" title="Download PDF">pdf</a>, <a href="/ps/2310.07675" title="Download PostScript">ps</a>, <a href="/format/2310.07675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-twisting based sliding mode control of hydraulic actuator without  velocity state
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Estrada%2C+M">Manuel Estrada</a>, 
<a href="/search/eess?searchtype=author&query=Ruderman%2C+M">Michael Ruderman</a>, 
<a href="/search/eess?searchtype=author&query=Fridman%2C+L">Leonid Fridman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper provides a novel surface design and experimental evaluation of a
super-twisting algorithm (STA) based control for hydraulic cylinder actuators.
The proposed integral sliding surface allows to track a sufficiently smooth
reference without using the velocity state which is hardly accessible in the
noisy hydraulic systems. A design methodology based on LMI's is given, and the
STA gains are designed to be adjusted by only one free parameter. The
feasibility and effectiveness of the proposed control method are shown on a
standard hydraulic test bench with one linear degree of freedom and passive
load, where a typical motion profile is tracked with a bounded average error
below 1 % from the total drive effective output.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07676" title="Abstract">arXiv:2310.07676</a> [<a href="/pdf/2310.07676" title="Download PDF">pdf</a>, <a href="/format/2310.07676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composite Backdoor Attacks Against Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhengyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated superior performance compared
to previous methods on various tasks, and often serve as the foundation models
for many researches and services. However, the untrustworthy third-party LLMs
may covertly introduce vulnerabilities for downstream tasks. In this paper, we
explore the vulnerability of LLMs through the lens of backdoor attacks.
Different from existing backdoor attacks against LLMs, ours scatters multiple
trigger keys in different prompt components. Such a Composite Backdoor Attack
(CBA) is shown to be stealthier than implanting the same multiple trigger keys
in only a single component. CBA ensures that the backdoor is activated only
when all trigger keys appear. Our experiments demonstrate that CBA is effective
in both natural language processing (NLP) and multimodal tasks. For instance,
with $3\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset,
our attack achieves a $100\%$ Attack Success Rate (ASR) with a False Triggered
Rate (FTR) below $2.06\%$ and negligible model accuracy degradation. The unique
characteristics of our CBA can be tailored for various practical scenarios,
e.g., targeting specific user groups. Our work highlights the necessity of
increased security research on the trustworthiness of foundation LLMs.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07678" title="Abstract">arXiv:2310.07678</a> [<a href="/pdf/2310.07678" title="Download PDF">pdf</a>, <a href="/format/2310.07678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Livieris%2C+I+E">Ioannis E. Livieris</a>, 
<a href="/search/cs?searchtype=author&query=Pintelas%2C+E">Emmanuel Pintelas</a>, 
<a href="/search/cs?searchtype=author&query=Kiriakidou%2C+N">Niki Kiriakidou</a>, 
<a href="/search/cs?searchtype=author&query=Pintelas%2C+P">Panagiotis Pintelas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript has been submitted for publication in "Journal of Imaging"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the proliferation of image-based applications in various domains, the
need for accurate and interpretable image similarity measures has become
increasingly critical. Existing image similarity models often lack
transparency, making it challenging to understand the reasons why two images
are considered similar. In this paper, we propose the concept of explainable
image similarity, where the goal is the development of an approach, which is
capable of providing similarity scores along with visual factual and
counterfactual explanations. Along this line, we present a new framework, which
integrates Siamese Networks and Grad-CAM for providing explainable image
similarity and discuss the potential benefits and challenges of adopting this
approach. In addition, we provide a comprehensive discussion about factual and
counterfactual explanations provided by the proposed framework for assisting
decision making. The proposed approach has the potential to enhance the
interpretability, trustworthiness and user acceptance of image-based systems in
real-world image similarity applications. The implementation code can be found
in https://github.com/ioannislivieris/Grad_CAM_Siamese.git.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07682" title="Abstract">arXiv:2310.07682</a> [<a href="/pdf/2310.07682" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of MET Overexpression in Non-Small Cell Lung Adenocarcinomas  from Hematoxylin and Eosin Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ingale%2C+K">Kshitij Ingale</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+H">Sun Hae Hong</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+J+S+K">Josh S.K. Bell</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+A">Abbas Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Welch%2C+A">Amy Welch</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+L">Lingdao Sha</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+I">Irvin Ho</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+K">Kunal Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=BenTaieb%2C+A">Aicha BenTaieb</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R+P">Rohan P Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Stumpe%2C+M+C">Martin C Stumpe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">MET protein overexpression is a targetable event in non-small cell lung
cancer (NSCLC) and is the subject of active drug development. Challenges in
identifying patients for these therapies include lack of access to validated
testing, such as standardized immunohistochemistry (IHC) assessment, and
consumption of valuable tissue for a single gene/protein assay. Development of
pre-screening algorithms using routinely available digitized hematoxylin and
eosin (H&amp;E)-stained slides to predict MET overexpression could promote testing
for those who will benefit most. While assessment of MET expression using IHC
is currently not routinely performed in NSCLC, next-generation sequencing is
common and in some cases includes RNA expression panel testing. In this work,
we leveraged a large database of matched H&amp;E slides and RNA expression data to
train a weakly supervised model to predict MET RNA overexpression directly from
H&amp;E images. This model was evaluated on an independent holdout test set of 300
over-expressed and 289 normal patients, demonstrating an ROC-AUC of 0.70 (95th
percentile interval: 0.66 - 0.74) with stable performance characteristics
across different patient clinical variables and robust to synthetic noise on
the test set. These results suggest that H&amp;E-based predictive models could be
useful to prioritize patients for confirmatory testing of MET protein or MET
gene expression status.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07683" title="Abstract">arXiv:2310.07683</a> [<a href="/pdf/2310.07683" title="Download PDF">pdf</a>, <a href="/format/2310.07683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Data Generation Via Iterative Data-Property Mutual Mappings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bo Pan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Muran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep generative models have been widely used for their ability to generate
realistic data samples in various areas, such as images, molecules, text, and
speech. One major goal of data generation is controllability, namely to
generate new data with desired properties. Despite growing interest in the area
of controllable generation, significant challenges still remain, including 1)
disentangling desired properties with unrelated latent variables, 2)
out-of-distribution property control, and 3) objective optimization for
out-of-distribution property control. To address these challenges, in this
paper, we propose a general framework to enhance VAE-based data generators with
property controllability and ensure disentanglement. Our proposed objective can
be optimized on both data seen and unseen in the training set. We propose a
training procedure to train the objective in a semi-supervised manner by
iteratively conducting mutual mappings between the data and properties. The
proposed framework is implemented on four VAE-based controllable generators to
evaluate its performance on property error, disentanglement, generation
quality, and training time. The results indicate that our proposed framework
enables more precise control over the properties of generated samples in a
short training time, ensuring the disentanglement and keeping the validity of
the generated samples.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07684" title="Abstract">arXiv:2310.07684</a> [<a href="/pdf/2310.07684" title="Download PDF">pdf</a>, <a href="/format/2310.07684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph Neural Networks through the Lens of Message Passing: A Common  Perspective to Homophily and Architecture Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Telyatnikov%2C+L">Lev Telyatnikov</a>, 
<a href="/search/cs?searchtype=author&query=Bucarelli%2C+M+S">Maria Sofia Bucarelli</a>, 
<a href="/search/cs?searchtype=author&query=Bernardez%2C+G">Guillermo Bernardez</a>, 
<a href="/search/cs?searchtype=author&query=Zaghen%2C+O">Olga Zaghen</a>, 
<a href="/search/cs?searchtype=author&query=Scardapane%2C+S">Simone Scardapane</a>, 
<a href="/search/cs?searchtype=author&query=Lio%2C+P">Pietro Lio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Most of the current hypergraph learning methodologies and benchmarking
datasets in the hypergraph realm are obtained by lifting procedures from their
graph analogs, simultaneously leading to overshadowing hypergraph network
foundations. This paper attempts to confront some pending questions in that
regard: Can the concept of homophily play a crucial role in Hypergraph Neural
Networks (HGNNs), similar to its significance in graph-based research? Is there
room for improving current hypergraph architectures and methodologies? (e.g. by
carefully addressing the specific characteristics of higher-order networks) Do
existing datasets provide a meaningful benchmark for HGNNs? Diving into the
details, this paper proposes a novel conceptualization of homophily in
higher-order networks based on a message passing scheme; this approach
harmonizes the analytical frameworks of datasets and architectures, offering a
unified perspective for exploring and interpreting complex, higher-order
network structures and dynamics. Further, we propose MultiSet, a novel message
passing framework that redefines HGNNs by allowing hyperedge-dependent node
representations, as well as introduce a novel architecture MultiSetMixer that
leverages a new hyperedge sampling strategy. Finally, we provide an extensive
set of experiments that contextualize our proposals and lead to valuable
insights in hypergraph representation learning.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07686" title="Abstract">arXiv:2310.07686</a> [<a href="/pdf/2310.07686" title="Download PDF">pdf</a>, <a href="/ps/2310.07686" title="Download PostScript">ps</a>, <a href="/format/2310.07686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New optimal trade-off point for coded caching systems with limited cache  size
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yinbin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tuninetti%2C+D">Daniela Tuninetti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper presents a new achievable scheme for coded caching systems with
$\mathsf{N}$ files, $\mathsf{K}=\mathsf{N}$ users, and cache size
$\mathsf{M}=1/(\mathsf{N}-1)$. The scheme employs linear coding during the
cache placement phase, and a three-stage transmissions designed to eliminate
interference in the delivery phase. The achievable load meets a known converse
bound, which impose no constraint on the cache placement, and is thus optimal.
This new result, together with known inner and outer bounds, shows optimality
of linear coding placement for $\mathsf{M} \leq 1/(\mathsf{N}-1)$ when
$\mathsf{K}=\mathsf{N}\geq 3$. Interestingly and surprisingly, the proposed
scheme is relatively simple but requires operations on a finite field of size
at least 3.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07689" title="Abstract">arXiv:2310.07689</a> [<a href="/pdf/2310.07689" title="Download PDF">pdf</a>, <a href="/format/2310.07689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid System Stability Analysis of Multi-Lane Mixed-Autonomy Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+R">Roy Dong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Autonomous vehicles (AVs) hold vast potential to enhance transportation
systems by reducing congestion, improving safety, and lowering emissions. AV
controls lead to emergent traffic phenomena; one such intriguing phenomenon is
traffic breaks (rolling roadblocks), where a single AV efficiently stabilizes
multiple lanes through frequent lane switching, similar to the highway
patrolling officers weaving across multiple lanes during difficult traffic
conditions. While previous theoretical studies focus on single-lane
mixed-autonomy systems, this work proposes a stability analysis framework for
multi-lane systems under AV controls. Casting this problem into the hybrid
system paradigm, the proposed analysis integrates continuous vehicle dynamics
and discrete jumps from AV lane-switches. Through examining the influence of
the lane-switch frequency on the system's stability, the analysis offers a
principled explanation to the traffic break phenomena, and further discovers
opportunities for less-intrusive traffic smoothing by employing less frequent
lane-switching. The analysis further facilitates the design of traffic-aware AV
lane-switch strategies to enhance system stability. Numerical analysis reveals
a strong alignment between the theory and simulation, validating the
effectiveness of the proposed stability framework in analyzing multi-lane
mixed-autonomy traffic systems.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07697" title="Abstract">arXiv:2310.07697</a> [<a href="/pdf/2310.07697" title="Download PDF">pdf</a>, <a href="/format/2310.07697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConditionVideo: Training-Free Condition-Guided Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chaochao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent works have successfully extended large-scale text-to-image models to
the video domain, producing promising results but at a high computational cost
and requiring a large amount of video data. In this work, we introduce
ConditionVideo, a training-free approach to text-to-video generation based on
the provided condition, video, and input text, by leveraging the power of
off-the-shelf text-to-image generation methods (e.g., Stable Diffusion).
ConditionVideo generates realistic dynamic videos from random noise or given
scene videos. Our method explicitly disentangles the motion representation into
condition-guided and scenery motion components. To this end, the ConditionVideo
model is designed with a UNet branch and a control branch. To improve temporal
coherence, we introduce sparse bi-directional spatial-temporal attention
(sBiST-Attn). The 3D control network extends the conventional 2D controlnet
model, aiming to strengthen conditional generation accuracy by additionally
leveraging the bi-directional frames in the temporal domain. Our method
exhibits superior performance in terms of frame consistency, clip score, and
conditional accuracy, outperforming other compared methods.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07698" title="Abstract">arXiv:2310.07698</a> [<a href="/pdf/2310.07698" title="Download PDF">pdf</a>, <a href="/format/2310.07698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SurroCBM: Concept Bottleneck Surrogate Models for Generative Post-hoc  Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bo Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenke Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainable AI seeks to bring light to the decision-making processes of
black-box models. Traditional saliency-based methods, while highlighting
influential data segments, often lack semantic understanding. Recent
advancements, such as Concept Activation Vectors (CAVs) and Concept Bottleneck
Models (CBMs), offer concept-based explanations but necessitate human-defined
concepts. However, human-annotated concepts are expensive to attain. This paper
introduces the Concept Bottleneck Surrogate Models (SurroCBM), a novel
framework that aims to explain the black-box models with automatically
discovered concepts. SurroCBM identifies shared and unique concepts across
various black-box models and employs an explainable surrogate model for
post-hoc explanations. An effective training strategy using self-generated data
is proposed to enhance explanation quality continuously. Through extensive
experiments, we demonstrate the efficacy of SurroCBM in concept discovery and
explanation, underscoring its potential in advancing the field of explainable
AI.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07699" title="Abstract">arXiv:2310.07699</a> [<a href="/pdf/2310.07699" title="Download PDF">pdf</a>, <a href="/format/2310.07699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Scarcity to Efficiency: Improving CLIP Training via Visual-enriched  Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhengfeng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wentao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haoping Bai</a>, 
<a href="/search/cs?searchtype=author&query=Timofeev%2C+A">Aleksei Timofeev</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xianzhi Du</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+J">Jiulong Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chuah%2C+C">Chen-Nee Chuah</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yinfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CV/ML
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Web-crawled datasets are pivotal to the success of pre-training
vision-language models, exemplified by CLIP. However, web-crawled AltTexts can
be noisy and potentially irrelevant to images, thereby undermining the crucial
image-text alignment. Existing methods for rewriting captions using large
language models (LLMs) have shown promise on small, curated datasets like CC3M
and CC12M. Nevertheless, their efficacy on massive web-captured captions is
constrained by the inherent noise and randomness in such data. In this study,
we address this limitation by focusing on two key aspects: data quality and
data variety. Unlike recent LLM rewriting techniques, we emphasize exploiting
visual concepts and their integration into the captions to improve data
quality. For data variety, we propose a novel mixed training scheme that
optimally leverages AltTexts alongside newly generated Visual-enriched Captions
(VeC). We use CLIP as one example and adapt the method for CLIP training on
large-scale web-crawled datasets, named VeCLIP. We conduct a comprehensive
evaluation of VeCLIP across small, medium, and large scales of raw data. Our
results show significant advantages in image-text alignment and overall model
performance, underscoring the effectiveness of VeCLIP in improving CLIP
training. For example, VeCLIP achieves a remarkable over 20% improvement in
COCO and Flickr30k retrieval tasks under the 12M setting. For data efficiency,
we also achieve a notable over 3% improvement while using only 14% of the data
employed in the vanilla CLIP and 11% in ALIGN.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07700" title="Abstract">arXiv:2310.07700</a> [<a href="/pdf/2310.07700" title="Download PDF">pdf</a>, <a href="/format/2310.07700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-enhanced Memory Model for Emotional Support Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mengzhao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liqiang Jing</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dawei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Renyu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The prevalence of mental disorders has become a significant issue, leading to
the increased focus on Emotional Support Conversation as an effective
supplement for mental health support. Existing methods have achieved compelling
results, however, they still face three challenges: 1) variability of emotions,
2) practicality of the response, and 3) intricate strategy modeling. To address
these challenges, we propose a novel knowledge-enhanced Memory mODEl for
emotional suppoRt coNversation (MODERN). Specifically, we first devise a
knowledge-enriched dialogue context encoding to perceive the dynamic emotion
change of different periods of the conversation for coherent user state
modeling and select context-related concepts from ConceptNet for practical
response generation. Thereafter, we implement a novel memory-enhanced strategy
modeling module to model the semantic patterns behind the strategy categories.
Extensive experiments on a widely used large-scale dataset verify the
superiority of our model over cutting-edge baselines.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07702" title="Abstract">arXiv:2310.07702</a> [<a href="/pdf/2310.07702" title="Download PDF">pdf</a>, <a href="/format/2310.07702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingqing He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaoshu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Menghan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yingqinghe.github.io/scalecrafter/">this https URL</a> Github: <a href="https://github.com/YingqingHe/ScaleCrafter">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we investigate the capability of generating images from
pre-trained diffusion models at much higher resolutions than the training image
sizes. In addition, the generated images should have arbitrary image aspect
ratios. When generating images directly at a higher resolution, 1024 x 1024,
with the pre-trained Stable Diffusion using training images of resolution 512 x
512, we observe persistent problems of object repetition and unreasonable
object structures. Existing works for higher-resolution generation, such as
attention-based and joint-diffusion approaches, cannot well address these
issues. As a new perspective, we examine the structural components of the U-Net
in diffusion models and identify the crucial cause as the limited perception
field of convolutional kernels. Based on this key observation, we propose a
simple yet effective re-dilation that can dynamically adjust the convolutional
perception field during inference. We further propose the dispersed convolution
and noise-damped classifier-free guidance, which can enable
ultra-high-resolution image generation (e.g., 4096 x 4096). Notably, our
approach does not require any training or optimization. Extensive experiments
demonstrate that our approach can address the repetition issue well and achieve
state-of-the-art performance on higher-resolution image synthesis, especially
in texture details. Our work also suggests that a pre-trained diffusion model
trained on low-resolution images can be directly used for high-resolution
visual generation without further tuning, which may provide insights for future
research on ultra-high-resolution image and video synthesis.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07704" title="Abstract">arXiv:2310.07704</a> [<a href="/pdf/2310.07704" title="Download PDF">pdf</a>, <a href="/format/2310.07704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ferret: Refer and Ground Anything Anywhere at Any Granularity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+H">Haoxuan You</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xianzhi Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liangliang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yinfei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures. Code/Project Website: <a href="https://github.com/apple/ml-ferret">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of
understanding spatial referring of any shape or granularity within an image and
accurately grounding open-vocabulary descriptions. To unify referring and
grounding in the LLM paradigm, Ferret employs a novel and powerful hybrid
region representation that integrates discrete coordinates and continuous
features jointly to represent a region in the image. To extract the continuous
features of versatile regions, we propose a spatial-aware visual sampler, adept
at handling varying sparsity across different shapes. Consequently, Ferret can
accept diverse region inputs, such as points, bounding boxes, and free-form
shapes. To bolster the desired capability of Ferret, we curate GRIT, a
comprehensive refer-and-ground instruction tuning dataset including 1.1M
samples that contain rich hierarchical spatial knowledge, with 95K hard
negative data to promote model robustness. The resulting model not only
achieves superior performance in classical referring and grounding tasks, but
also greatly outperforms existing MLLMs in region-based and
localization-demanded multimodal chatting. Our evaluations also reveal a
significantly improved capability of describing image details and a remarkable
alleviation in object hallucination. Code and data will be available at
https://github.com/apple/ml-ferret
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07706" title="Abstract">arXiv:2310.07706</a> [<a href="/pdf/2310.07706" title="Download PDF">pdf</a>, <a href="/format/2310.07706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel State Value Network for Combined Prediction and Planning in  Interactive Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosbach%2C+S">Sascha Rosbach</a>, 
<a href="/search/cs?searchtype=author&query=Leupold%2C+S+M">Stefan M. Leupold</a>, 
<a href="/search/cs?searchtype=author&query=Gro%C3%9Fjohann%2C+S">Simon Gro&#xdf;johann</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+S">Stefan Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automated vehicles operating in urban environments have to reliably interact
with other traffic participants. Planning algorithms often utilize separate
prediction modules forecasting probabilistic, multi-modal, and interactive
behaviors of objects. Designing prediction and planning as two separate modules
introduces significant challenges, particularly due to the interdependence of
these modules. This work proposes a deep learning methodology to combine
prediction and planning. A conditional GAN with the U-Net architecture is
trained to predict two high-resolution image sequences. The sequences represent
explicit motion predictions, mainly used to train context understanding, and
pixel state values suitable for planning encoding kinematic reachability,
object dynamics, safety, and driving comfort. The model can be trained offline
on target images rendered by a sampling-based model-predictive planner,
leveraging real-world driving data. Our results demonstrate intuitive behavior
in complex situations, such as lane changes amidst conflicting objectives.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07707" title="Abstract">arXiv:2310.07707</a> [<a href="/pdf/2310.07707" title="Download PDF">pdf</a>, <a href="/format/2310.07707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatFormer: Nested Transformer for Elastic Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devvrit">Devvrit</a>, 
<a href="/search/cs?searchtype=author&query=Kudugunta%2C+S">Sneha Kudugunta</a>, 
<a href="/search/cs?searchtype=author&query=Kusupati%2C+A">Aditya Kusupati</a>, 
<a href="/search/cs?searchtype=author&query=Dettmers%2C+T">Tim Dettmers</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dhillon%2C+I">Inderjit Dhillon</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=Kakade%2C+S">Sham Kakade</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Prateek Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 12 figures, first three authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Transformer models are deployed in a wide range of settings, from
multi-accelerator clusters to standalone mobile phones. The diverse inference
constraints in these scenarios necessitate practitioners to train foundation
models such as PaLM 2, Llama, &amp; ViTs as a series of models of varying sizes.
Due to significant training costs, only a select few model sizes are trained
and supported, limiting more fine-grained control over relevant tradeoffs,
including latency, cost, and accuracy. This work introduces MatFormer, a nested
Transformer architecture designed to offer elasticity in a variety of
deployment constraints. Each Feed Forward Network (FFN) block of a MatFormer
model is jointly optimized with a few nested smaller FFN blocks. This training
procedure allows for the Mix'n'Match of model granularities across layers --
i.e., a trained universal MatFormer model enables extraction of hundreds of
accurate smaller models, which were never explicitly optimized. We empirically
demonstrate MatFormer's effectiveness across different model classes (decoders
&amp; encoders), modalities (language &amp; vision), and scales (up to 2.6B
parameters). We find that a 2.6B decoder-only MatFormer language model (MatLM)
allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting
comparable validation loss and one-shot downstream evaluations to their
independently trained counterparts. Furthermore, we observe that smaller
encoders extracted from a universal MatFormer-based ViT (MatViT) encoder
preserve the metric-space structure for adaptive large-scale retrieval.
Finally, we showcase that speculative decoding with the accurate and consistent
submodels extracted from MatFormer can further reduce inference latency.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07710" title="Abstract">arXiv:2310.07710</a> [<a href="/pdf/2310.07710" title="Download PDF">pdf</a>, <a href="/format/2310.07710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiPmark: A Stealthy, Efficient and Resilient Watermark for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengmian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Watermarking techniques offer a promising way to secure data via embedding
covert information into the data. A paramount challenge in the domain lies in
preserving the distribution of original data during watermarking. Our research
extends and refines existing watermarking framework, placing emphasis on the
importance of a distribution-preserving (DiP) watermark. Contrary to the
current strategies, our proposed DiPmark preserves the original token
distribution during watermarking (stealthy), is detectable without access to
the language model API or weights (efficient), and is robust to moderate
changes of tokens (resilient). This is achieved by incorporating a novel
reweight strategy, combined with a hash function that assigns unique
\textit{i.i.d.} ciphers based on the context. The empirical benchmarks of our
approach underscore its stealthiness, efficiency, and resilience, making it a
robust solution for watermarking tasks that demand impeccable quality
preservation.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07712" title="Abstract">arXiv:2310.07712</a> [<a href="/pdf/2310.07712" title="Download PDF">pdf</a>, <a href="/format/2310.07712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Found in the Middle: Permutation Self-Consistency Improves Listwise  Ranking in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Raphael Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xueguang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ture%2C+F">Ferhan Ture</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally; 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) exhibit positional bias in how they use context,
which especially complicates listwise ranking. To address this, we propose
permutation self-consistency, a form of self-consistency over ranking list
outputs of black-box LLMs. Our key idea is to marginalize out different list
orders in the prompt to produce an order-independent ranking with less
positional bias. First, given some input prompt, we repeatedly shuffle the list
in the prompt and pass it through the LLM while holding the instructions the
same. Next, we aggregate the resulting sample of rankings by computing the
central ranking closest in distance to all of them, marginalizing out prompt
order biases in the process. Theoretically, we prove the robustness of our
method, showing convergence to the true ranking in the presence of random
perturbations. Empirically, on five list-ranking datasets in sorting and
passage reranking, our approach improves scores from conventional inference by
up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous
state of the art in passage reranking. Our code is at
https://github.com/castorini/perm-sc.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07713" title="Abstract">arXiv:2310.07713</a> [<a href="/pdf/2310.07713" title="Download PDF">pdf</a>, <a href="/format/2310.07713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=McAfee%2C+L">Lawrence McAfee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pretraining auto-regressive large language models (LLMs) with retrieval
demonstrates better perplexity and factual accuracy by leveraging external
databases. However, the size of existing pretrained retrieval-augmented LLM is
still limited (e.g., Retro has 7.5B parameters), which limits the effectiveness
of instruction tuning and zero-shot generalization. In this work, we introduce
Retro 48B, the largest LLM pretrained with retrieval before instruction tuning.
Specifically, we continue to pretrain the 43B GPT model on additional 100
billion tokens using the Retro augmentation method by retrieving from 1.2
trillion tokens. The obtained foundation model, Retro 48B, largely outperforms
the original 43B GPT in terms of perplexity. After instruction tuning on Retro,
InstructRetro demonstrates significant improvement over the instruction tuned
GPT on zero-shot question answering (QA) tasks. Specifically, the average
improvement of InstructRetro is 7% over its GPT counterpart across 8 short-form
QA tasks, and 10% over GPT across 4 challenging long-form QA tasks.
Surprisingly, we find that one can ablate the encoder from InstructRetro
architecture and directly use its decoder backbone, while achieving comparable
results. We hypothesize that pretraining with retrieval makes its decoder good
at incorporating context for QA. Our results highlights the promising direction
to obtain a better GPT decoder for QA through continued pretraining with
retrieval before instruction tuning.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07715" title="Abstract">arXiv:2310.07715</a> [<a href="/pdf/2310.07715" title="Download PDF">pdf</a>, <a href="/format/2310.07715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Build Our Future, We Must Know Our Past: Contextualizing Paradigm  Shifts in Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gururaja%2C+S">Sireesh Gururaja</a>, 
<a href="/search/cs?searchtype=author&query=Bertsch%2C+A">Amanda Bertsch</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+C">Clara Na</a>, 
<a href="/search/cs?searchtype=author&query=Widder%2C+D+G">David Gray Widder</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">NLP is in a period of disruptive change that is impacting our methodologies,
funding sources, and public perception. In this work, we seek to understand how
to shape our future by better understanding our past. We study factors that
shape NLP as a field, including culture, incentives, and infrastructure by
conducting long-form interviews with 26 NLP researchers of varying seniority,
research area, institution, and social identity. Our interviewees identify
cyclical patterns in the field, as well as new shifts without historical
parallel, including changes in benchmark culture and software infrastructure.
We complement this discussion with quantitative analysis of citation,
authorship, and language use in the ACL Anthology over time. We conclude by
discussing shared visions, concerns, and hopes for the future of NLP. We hope
that this study of our field's past and present can prompt informed discussion
of our community's implicit norms and more deliberate action to consciously
shape the future.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07716" title="Abstract">arXiv:2310.07716</a> [<a href="/pdf/2310.07716" title="Download PDF">pdf</a>, <a href="/format/2310.07716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weize Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lihan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023. Codes are available at <a href="https://github.com/EricLee0224/PAD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Object anomaly detection is an important problem in the field of machine
vision and has seen remarkable progress recently. However, two significant
challenges hinder its research and application. First, existing datasets lack
comprehensive visual information from various pose angles. They usually have an
unrealistic assumption that the anomaly-free training dataset is pose-aligned,
and the testing samples have the same pose as the training data. However, in
practice, anomaly may exist in any regions on a object, the training and query
samples may have different poses, calling for the study on pose-agnostic
anomaly detection. Second, the absence of a consensus on experimental protocols
for pose-agnostic anomaly detection leads to unfair comparisons of different
methods, hindering the research on pose-agnostic anomaly detection. To address
these issues, we develop Multi-pose Anomaly Detection (MAD) dataset and
Pose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step to
address the pose-agnostic anomaly detection problem. Specifically, we build MAD
using 20 complex-shaped LEGO toys including 4K views with various poses, and
high-quality and diverse 3D anomalies in both simulated and real environments.
Additionally, we propose a novel method OmniposeAD, trained using MAD,
specifically designed for pose-agnostic anomaly detection. Through
comprehensive evaluations, we demonstrate the relevance of our dataset and
method. Furthermore, we provide an open-source benchmark library, including
dataset and baseline methods that cover 8 anomaly detection paradigms, to
facilitate future research and application in this domain. Code, data, and
models are publicly available at https://github.com/EricLee0224/PAD.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 12 Oct 23</h3>
<dl>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10436" title="Abstract">arXiv:2303.10436</a> (cross-list from eess.IV) [<a href="/pdf/2303.10436" title="Download PDF">pdf</a>, <a href="/format/2303.10436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FD-Net: An Unsupervised Deep Forward-Distortion Model for Susceptibility  Artifact Correction in EPI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alkilani%2C+A+Z">Abdallah Zaid Alkilani</a>, 
<a href="/search/eess?searchtype=author&query=%C3%87ukur%2C+T">Tolga &#xc7;ukur</a>, 
<a href="/search/eess?searchtype=author&query=Saritas%2C+E+U">Emine Ulku Saritas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Magn Reson Med. 2023; 1-17
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent learning-based correction approaches in EPI estimate a displacement
field, unwarp the reversed-PE image pair with the estimated field, and average
the unwarped pair to yield a corrected image. Unsupervised learning in these
unwarping-based methods is commonly attained via a similarity constraint
between the unwarped images in reversed-PE directions, neglecting consistency
to the acquired EPI images. This work introduces an unsupervised deep-learning
method for fast and effective correction of susceptibility artifacts in
reversed phase-encode (PE) image pairs acquired with EPI. FD-Net predicts both
the susceptibility-induced displacement field and the underlying
anatomically-correct image. Unlike previous methods, FD-Net enforces the
forward-distortions of the correct image in both PE directions to be consistent
with the acquired reversed-PE image pair. FD-Net further leverages a
multiresolution architecture to maintain high local and global performance.
FD-Net performs competitively with a gold-standard reference method (TOPUP) in
image quality, while enabling a leap in computational efficiency. Furthermore,
FD-Net outperforms recent unwarping-based methods for unsupervised correction
in terms of both image and field quality. The unsupervised FD-Net method
introduces a deep forward-distortion approach to enable fast, high-fidelity
correction of susceptibility artifacts in EPI by maintaining consistency to
measured data. Therefore, it holds great promise for improving the anatomical
accuracy of EPI imaging.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05273" title="Abstract">arXiv:2310.05273</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2310.05273" title="Download PDF">pdf</a>, <a href="/format/2310.05273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning force laws in many-body systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yu%2C+W">Wentao Yu</a>, 
<a href="/search/physics?searchtype=author&query=Abdelaleem%2C+E">Eslam Abdelaleem</a>, 
<a href="/search/physics?searchtype=author&query=Nemenman%2C+I">Ilya Nemenman</a>, 
<a href="/search/physics?searchtype=author&query=Burton%2C+J+C">Justin C. Burton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 Figures, 2 Supplemental Figures, 6 Supplemental Videos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Scientific laws describing natural systems may be more complex than our
intuition can handle, and thus how we discover laws must change. Machine
learning (ML) models can analyze large quantities of data, but their structure
should match the underlying physical constraints to provide useful insight.
Here we demonstrate a ML approach that incorporates such physical intuition to
infer force laws in dusty plasma experiments. Trained on 3D particle
trajectories, the model accounts for inherent symmetries and non-identical
particles, accurately learns the effective non-reciprocal forces between
particles, and extracts each particle's mass and charge. The model's accuracy
(R^2 &gt; 0.99) points to new physics in dusty plasma beyond the resolution of
current theories and demonstrates how ML-powered approaches can guide new
routes of scientific discovery in many-body systems.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06844" title="Abstract">arXiv:2310.06844</a> (cross-list from q-fin.TR) [<a href="/pdf/2310.06844" title="Download PDF">pdf</a>, <a href="/format/2310.06844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Unfair Advantages: Investigating Opportunistic Trading in the  NFT Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Bose%2C+P">Priyanka Bose</a>, 
<a href="/search/q-fin?searchtype=author&query=Das%2C+D">Dipanjan Das</a>, 
<a href="/search/q-fin?searchtype=author&query=Gritti%2C+F">Fabio Gritti</a>, 
<a href="/search/q-fin?searchtype=author&query=Ruaro%2C+N">Nicola Ruaro</a>, 
<a href="/search/q-fin?searchtype=author&query=Kruegel%2C+C">Christopher Kruegel</a>, 
<a href="/search/q-fin?searchtype=author&query=Vigna%2C+G">Giovanni Vigna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">As cryptocurrency evolved, new financial instruments, such as lending and
borrowing protocols, currency exchanges, fungible and non-fungible tokens
(NFT), staking and mining protocols have emerged. A financial ecosystem built
on top of a blockchain is supposed to be fair and transparent for each
participating actor. Yet, there are sophisticated actors who turn their domain
knowledge and market inefficiencies to their strategic advantage; thus
extracting value from trades not accessible to others. This situation is
further exacerbated by the fact that blockchain-based markets and decentralized
finance (DeFi) instruments are mostly unregulated. Though a large body of work
has already studied the unfairness of different aspects of DeFi and
cryptocurrency trading, the economic intricacies of non-fungible token (NFT)
trades necessitate further analysis and academic scrutiny.
<br />The trading volume of NFTs has skyrocketed in recent years. A single NFT
trade worth over a million US dollars, or marketplaces making billions in
revenue is not uncommon nowadays. While previous research indicated the
presence of wrongdoings in the NFT market, to our knowledge, we are the first
to study predatory trading practices, what we call opportunistic trading, in
depth. Opportunistic traders are sophisticated actors who employ automated,
high-frequency NFT trading strategies, which, oftentimes, are malicious,
deceptive, or, at the very least, unfair. Such attackers weaponize their
advanced technical knowledge and superior understanding of DeFi protocols to
disrupt trades of unsuspecting users, and collect profits from economic
situations that are inaccessible to ordinary users, in a "supposedly" fair
market. In this paper, we explore three such broad classes of opportunistic
strategies aiming to realize three distinct trading objectives, viz., acquire,
instant profit generation, and loss minimization.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06852" title="Abstract">arXiv:2310.06852</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2310.06852" title="Download PDF">pdf</a>, <a href="/format/2310.06852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCrysTet: A Deep Learning Approach Using Tetrahedral Mesh for  Predicting Properties of Crystalline Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Tsuruta%2C+H">Hirofumi Tsuruta</a>, 
<a href="/search/cond-mat?searchtype=author&query=Katsura%2C+Y">Yukari Katsura</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kumagai%2C+M">Masaya Kumagai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) is becoming increasingly popular for predicting
material properties to accelerate materials discovery. Because material
properties are strongly affected by its crystal structure, a key issue is
converting the crystal structure into the features for input to the ML model.
Currently, the most common method is to convert the crystal structure into a
graph and predicting its properties using a graph neural network (GNN). Some
GNN models, such as crystal graph convolutional neural network (CGCNN) and
atomistic line graph neural network (ALIGNN), have achieved highly accurate
predictions of material properties. Despite these successes, using a graph to
represent a crystal structure has the notable limitation of losing the crystal
structure's three-dimensional (3D) information. In this work, we propose
DeepCrysTet, a novel deep learning approach for predicting material properties,
which uses crystal structures represented as a 3D tetrahedral mesh generated by
Delaunay tetrahedralization. DeepCrysTet provides a useful framework that
includes a 3D mesh generation method, mesh-based feature design, and neural
network design. The experimental results using the Materials Project dataset
show that DeepCrysTet significantly outperforms existing GNN models in
classifying crystal structures and achieves state-of-the-art performance in
predicting elastic properties.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06873" title="Abstract">arXiv:2310.06873</a> (cross-list from eess.IV) [<a href="/pdf/2310.06873" title="Download PDF">pdf</a>, <a href="/format/2310.06873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of uncertainty quantification in medical image analysis:  probabilistic and non-probabilistic methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Ling Huang</a>, 
<a href="/search/eess?searchtype=author&query=Ruan%2C+S">Su Ruan</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+Y">Yucheng Xing</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+M">Mengling Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.03736">arXiv:2210.03736</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The comprehensive integration of machine learning healthcare models within
clinical practice remains suboptimal, notwithstanding the proliferation of
high-performing solutions reported in the literature. A predominant factor
hindering widespread adoption pertains to an insufficiency of evidence
affirming the reliability of the aforementioned models. Recently, uncertainty
quantification methods have been proposed as a potential solution to quantify
the reliability of machine learning models and thus increase the
interpretability and acceptability of the result. In this review, we offer a
comprehensive overview of prevailing methods proposed to quantify uncertainty
inherent in machine learning models developed for various medical image tasks.
Contrary to earlier reviews that exclusively focused on probabilistic methods,
this review also explores non-probabilistic approaches, thereby furnishing a
more holistic survey of research pertaining to uncertainty quantification for
machine learning models. Analysis of medical images with the summary and
discussion on medical applications and the corresponding uncertainty evaluation
protocols are presented, which focus on the specific challenges of uncertainty
in medical image analysis. We also highlight some potential future research
work at the end. Generally, this review aims to allow researchers from both
clinical and technical backgrounds to gain a quick and yet in-depth
understanding of the research in uncertainty quantification for medical image
analysis machine learning models.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06881" title="Abstract">arXiv:2310.06881</a> (cross-list from q-bio.QM) [<a href="/pdf/2310.06881" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAFA-evaluator: A Python Tool for Benchmarking Ontological  Classification Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Piovesan%2C+D">Damiano Piovesan</a>, 
<a href="/search/q-bio?searchtype=author&query=Zago%2C+D">Davide Zago</a>, 
<a href="/search/q-bio?searchtype=author&query=Joshi%2C+P">Parnal Joshi</a>, 
<a href="/search/q-bio?searchtype=author&query=De+Paolis+Kaluza%2C+M+C">M. Clara De Paolis Kaluza</a>, 
<a href="/search/q-bio?searchtype=author&query=Monzon%2C+A+M">Alexander Miguel Monzon</a>, 
<a href="/search/q-bio?searchtype=author&query=Reade%2C+W">Walter Reade</a>, 
<a href="/search/q-bio?searchtype=author&query=Friedberg%2C+I">Iddo Friedberg</a>, 
<a href="/search/q-bio?searchtype=author&query=Radivojac%2C+P">Predrag Radivojac</a>, 
<a href="/search/q-bio?searchtype=author&query=Tosatto%2C+S+C+E">Silvio C. E. Tosatto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Performance (cs.PF)

</div>
<p class="mathjax">We present CAFA-evaluator, a powerful Python program designed to evaluate the
performance of prediction methods on targets with hierarchical concept
dependencies. It generalizes multi-label evaluation to modern ontologies where
the prediction targets are drawn from a directed acyclic graph and achieves
high efficiency by leveraging matrix computation and topological sorting. The
program requirements include a small number of standard Python libraries,
making CAFA-evaluator easy to maintain. The code replicates the Critical
Assessment of protein Function Annotation (CAFA) benchmarking, which evaluates
predictions of the consistent subgraphs in Gene Ontology. Owing to its
reliability and accuracy, the organizers have selected CAFA-evaluator as the
official CAFA evaluation software.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06921" title="Abstract">arXiv:2310.06921</a> (cross-list from math.OC) [<a href="/pdf/2310.06921" title="Download PDF">pdf</a>, <a href="/format/2310.06921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Zonotope-Based Backward Reachability Analysis for Neural Feedback  Systems With Nonlinear System Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+H">Hang Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xiangru Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The increasing prevalence of neural networks in safety-critical control
systems underscores the imperative need for rigorous methods to ensure the
reliability and safety of these systems. This work introduces a novel approach
employing hybrid zonotopes to compute the over-approximation of backward
reachable sets for neural feedback systems with nonlinear system models and
general activation functions. Closed-form expressions as hybrid zonotopes are
provided for the over-approximated backward reachable sets, and a refinement
procedure is proposed to alleviate the potential conservatism of the
approximation. Two numerical examples are provided to illustrate the
effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06929" title="Abstract">arXiv:2310.06929</a> (cross-list from astro-ph.CO) [<a href="/pdf/2310.06929" title="Download PDF">pdf</a>, <a href="/format/2310.06929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Super-resolution of Cosmological Simulations with Denoising  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Schanz%2C+A">Andreas Schanz</a>, 
<a href="/search/astro-ph?searchtype=author&query=List%2C+F">Florian List</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hahn%2C+O">Oliver Hahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, to be submitted to OJA, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, deep learning models have been successfully employed for
augmenting low-resolution cosmological simulations with small-scale
information, a task known as "super-resolution". So far, these cosmological
super-resolution models have relied on generative adversarial networks (GANs),
which can achieve highly realistic results, but suffer from various
shortcomings (e.g. low sample diversity). We introduce denoising diffusion
models as a powerful generative model for super-resolving cosmic large-scale
structure predictions (as a first proof-of-concept in two dimensions). To
obtain accurate results down to small scales, we develop a new "filter-boosted"
training approach that redistributes the importance of different scales in the
pixel-wise training objective. We demonstrate that our model not only produces
convincing super-resolution images and power spectra consistent at the percent
level, but is also able to reproduce the diversity of small-scale features
consistent with a given low-resolution simulation. This enables uncertainty
quantification for the generated small-scale features, which is critical for
the usefulness of such super-resolution models as a viable surrogate model for
cosmic structure formation.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06935" title="Abstract">arXiv:2310.06935</a> (cross-list from quant-ph) [<a href="/pdf/2310.06935" title="Download PDF">pdf</a>, <a href="/format/2310.06935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Shadow Gradient Descent for Quantum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Heidari%2C+M">Mohsen Heidari</a>, 
<a href="/search/quant-ph?searchtype=author&query=Naved%2C+M+A">Mobasshir A Naved</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xie%2C+W">Wenbo Xie</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grama%2C+A+J">Arjun Jacob Grama</a>, 
<a href="/search/quant-ph?searchtype=author&query=Szpankowski%2C+W">Wojciech Szpankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a new procedure called quantum shadow gradient descent
(QSGD) that addresses these key challenges. Our method has the benefits of a
one-shot approach, in not requiring any sample duplication while having a
convergence rate comparable to the ideal update rule using exact gradient
computation. We propose a new technique for generating quantum shadow samples
(QSS), which generates quantum shadows as opposed to classical shadows used in
existing works. With classical shadows, the computations are typically
performed on classical computers and, hence, are prohibitive since the
dimension grows exponentially. Our approach resolves this issue by measurements
of quantum shadows. As the second main contribution, we study more general
non-product ansatz of the form $\exp\{i\sum_j \theta_j A_j\}$ that model
variational Hamiltonians. We prove that the gradient can be written in terms of
the gradient of single-parameter ansatzes that can be easily measured. Our
proof is based on the Suzuki-Trotter approximation; however, our expressions
are exact, unlike prior efforts that approximate non-product operators. As a
result, existing gradient measurement techniques can be applied to more general
VQAs followed by correction terms without any approximation penalty. We provide
theoretical proofs, convergence analysis and verify our results through
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06945" title="Abstract">arXiv:2310.06945</a> (cross-list from eess.IV) [<a href="/pdf/2310.06945" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Evaluation of Practical Video Analytics Systems for Face  Detection and Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+P">Praneet Singh</a>, 
<a href="/search/eess?searchtype=author&query=Delp%2C+E+J">Edward J. Delp</a>, 
<a href="/search/eess?searchtype=author&query=Reibman%2C+A+R">Amy R. Reibman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Autonomous Vehicles and Machines 2023 Conference, IS&amp;T Electronic Imaging (EI) Symposium
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Electronic Imaging, 2023, pp 111-1 - 111-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Practical video analytics systems that are deployed in bandwidth constrained
environments like autonomous vehicles perform computer vision tasks such as
face detection and recognition. In an end-to-end face analytics system, inputs
are first compressed using popular video codecs like HEVC and then passed onto
modules that perform face detection, alignment, and recognition sequentially.
Typically, the modules of these systems are evaluated independently using
task-specific imbalanced datasets that can misconstrue performance estimates.
In this paper, we perform a thorough end-to-end evaluation of a face analytics
system using a driving-specific dataset, which enables meaningful
interpretations. We demonstrate how independent task evaluations, dataset
imbalances, and inconsistent annotations can lead to incorrect system
performance estimates. We propose strategies to create balanced evaluation
subsets of our dataset and to make its annotations consistent across multiple
analytics tasks and scenarios. We then evaluate the end-to-end system
performance sequentially to account for task interdependencies. Our experiments
show that our approach provides consistent, accurate, and interpretable
estimates of the system's performance which is critical for real-world
applications.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06949" title="Abstract">arXiv:2310.06949</a> (cross-list from eess.IV) [<a href="/pdf/2310.06949" title="Download PDF">pdf</a>, <a href="/format/2310.06949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Prior Regularized Iterative Reconstruction for Low-dose CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xia%2C+W">Wenjun Xia</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yongyi Shi</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+C">Chuang Niu</a>, 
<a href="/search/eess?searchtype=author&query=Cong%2C+W">Wenxiang Cong</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Ge Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Computed tomography (CT) involves a patient's exposure to ionizing radiation.
To reduce the radiation dose, we can either lower the X-ray photon count or
down-sample projection views. However, either of the ways often compromises
image quality. To address this challenge, here we introduce an iterative
reconstruction algorithm regularized by a diffusion prior. Drawing on the
exceptional imaging prowess of the denoising diffusion probabilistic model
(DDPM), we merge it with a reconstruction procedure that prioritizes data
fidelity. This fusion capitalizes on the merits of both techniques, delivering
exceptional reconstruction results in an unsupervised framework. To further
enhance the efficiency of the reconstruction process, we incorporate the
Nesterov momentum acceleration technique. This enhancement facilitates superior
diffusion sampling in fewer steps. As demonstrated in our experiments, our
method offers a potential pathway to high-definition CT image reconstruction
with minimized radiation.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06969" title="Abstract">arXiv:2310.06969</a> (cross-list from stat.ME) [<a href="/pdf/2310.06969" title="Download PDF">pdf</a>, <a href="/format/2310.06969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positivity-free Policy Learning with Observational Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhao%2C+P">Pan Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Chambaz%2C+A">Antoine Chambaz</a>, 
<a href="/search/stat?searchtype=author&query=Josse%2C+J">Julie Josse</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+S">Shu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Policy learning utilizing observational data is pivotal across various
domains, with the objective of learning the optimal treatment assignment policy
while adhering to specific constraints such as fairness, budget, and
simplicity. This study introduces a novel positivity-free (stochastic) policy
learning framework designed to address the challenges posed by the
impracticality of the positivity assumption in real-world scenarios. This
framework leverages incremental propensity score policies to adjust propensity
score values instead of assigning fixed values to treatments. We characterize
these incremental propensity score policies and establish identification
conditions, employing semiparametric efficiency theory to propose efficient
estimators capable of achieving rapid convergence rates, even when integrated
with advanced machine learning algorithms. This paper provides a thorough
exploration of the theoretical guarantees associated with policy learning and
validates the proposed framework's finite-sample performance through
comprehensive numerical experiments, ensuring the identification of causal
effects from observational data is both robust and reliable.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06973" title="Abstract">arXiv:2310.06973</a> (cross-list from quant-ph) [<a href="/pdf/2310.06973" title="Download PDF">pdf</a>, <a href="/format/2310.06973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Quantum Machine Learning with Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Rofougaran%2C+R">Rod Rofougaran</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tseng%2C+H">Huan-Hsin Tseng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+S+Y">Samuel Yen-Chi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The preservation of privacy is a critical concern in the implementation of
artificial intelligence on sensitive training data. There are several
techniques to preserve data privacy but quantum computations are inherently
more secure due to the no-cloning theorem, resulting in a most desirable
computational platform on top of the potential quantum advantages. There have
been prior works in protecting data privacy by Quantum Federated Learning (QFL)
and Quantum Differential Privacy (QDP) studied independently. However, to the
best of our knowledge, no prior work has addressed both QFL and QDP together
yet. Here, we propose to combine these privacy-preserving methods and implement
them on the quantum platform, so that we can achieve comprehensive protection
against data leakage (QFL) and model inversion attacks (QDP). This
implementation promises more efficient and secure artificial intelligence. In
this paper, we present a successful implementation of these
privacy-preservation methods by performing the binary classification of the
Cats vs Dogs dataset. Using our quantum-classical machine learning model, we
obtained a test accuracy of over 0.98, while maintaining epsilon values less
than 1.3. We show that federated differentially private training is a viable
privacy preservation method for quantum machine learning on Noisy
Intermediate-Scale Quantum (NISQ) devices.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07029" title="Abstract">arXiv:2310.07029</a> (cross-list from q-bio.NC) [<a href="/pdf/2310.07029" title="Download PDF">pdf</a>, <a href="/format/2310.07029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Age Revisited: Investigating the State vs. Trait Hypotheses of  EEG-derived Brain-Age Dynamics with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gemein%2C+L+A">Lukas AW Gemein</a>, 
<a href="/search/q-bio?searchtype=author&query=Schirrmeister%2C+R+T">Robin T Schirrmeister</a>, 
<a href="/search/q-bio?searchtype=author&query=Boedecker%2C+J">Joschka Boedecker</a>, 
<a href="/search/q-bio?searchtype=author&query=Ball%2C+T">Tonio Ball</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">The brain's biological age has been considered as a promising candidate for a
neurologically significant biomarker. However, recent results based on
longitudinal magnetic resonance imaging data have raised questions on its
interpretation. A central question is whether an increased biological age of
the brain is indicative of brain pathology and if changes in brain age
correlate with diagnosed pathology (state hypothesis). Alternatively, could the
discrepancy in brain age be a stable characteristic unique to each individual
(trait hypothesis)? To address this question, we present a comprehensive study
on brain aging based on clinical EEG, which is complementary to previous
MRI-based investigations. We apply a state-of-the-art Temporal Convolutional
Network (TCN) to the task of age regression. We train on recordings of the
Temple University Hospital EEG Corpus (TUEG) explicitly labeled as
non-pathological and evaluate on recordings of subjects with non-pathological
as well as pathological recordings, both with examinations at a single point in
time and repeated examinations over time. Therefore, we created four novel
subsets of TUEG that include subjects with multiple recordings: I) all labeled
non-pathological; II) all labeled pathological; III) at least one recording
labeled non-pathological followed by at least one recording labeled
pathological; IV) similar to III) but with opposing transition (first
pathological then non-pathological). The results show that our TCN reaches
state-of-the-art performance in age decoding with a mean absolute error of 6.6
years. Our extensive analyses demonstrate that the model significantly
underestimates the age of non-pathological and pathological subjects (-1 and -5
years, paired t-test, p &lt;= 0.18 and p &lt;= 0.0066). Furthermore, the brain age
gap biomarker is not indicative of pathological EEG.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07045" title="Abstract">arXiv:2310.07045</a> (cross-list from math.CO) [<a href="/pdf/2310.07045" title="Download PDF">pdf</a>, <a href="/ps/2310.07045" title="Download PostScript">ps</a>, <a href="/format/2310.07045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural convergence and algebraic roots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hartman%2C+D">David Hartman</a>, 
<a href="/search/math?searchtype=author&query=Hons%2C+T">Tom&#xe1;&#x161; Hons</a>, 
<a href="/search/math?searchtype=author&query=Ne%C5%A1et%C5%99il%2C+J">Jaroslav Ne&#x161;et&#x159;il</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Structural convergence is a framework for convergence of graphs by
Ne\v{s}et\v{r}il and Ossona de Mendez that unifies the dense (left) graph
convergence and Benjamini-Schramm convergence. They posed a problem asking
whether for a given sequence of graphs $(G_n)$ converging to a limit $L$ and a
vertex $r$ of $L$ it is possible to find a sequence of vertices $(r_n)$ such
that $L$ rooted at $r$ is the limit of the graphs $G_n$ rooted at $r_n$. A
counterexample was found by Christofides and Kr\'{a}l', but they showed that
the statement holds for almost all vertices $r$ of $L$. We offer another
perspective to the original problem by considering the size of definable sets
to which the root $r$ belongs. We prove that if $r$ is an algebraic vertex
(i.e. belongs to a finite definable set), the sequence of roots $(r_n)$ always
exists.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07060" title="Abstract">arXiv:2310.07060</a> (cross-list from eess.IV) [<a href="/pdf/2310.07060" title="Download PDF">pdf</a>, <a href="/format/2310.07060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BeSt-LeS: Benchmarking Stroke Lesion Segmentation using Deep Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deb%2C+P">Prantik Deb</a>, 
<a href="/search/eess?searchtype=author&query=Baru%2C+L+B">Lalith Bharadwaj Baru</a>, 
<a href="/search/eess?searchtype=author&query=Dadi%2C+K">Kamalaker Dadi</a>, 
<a href="/search/eess?searchtype=author&query=S%2C+B+R">Bapi Raju S</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to MICCAI BrainLes 2023 (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Brain stroke has become a significant burden on global health and thus we
need remedies and prevention strategies to overcome this challenge. For this,
the immediate identification of stroke and risk stratification is the primary
task for clinicians. To aid expert clinicians, automated segmentation models
are crucial. In this work, we consider the publicly available dataset ATLAS
$v2.0$ to benchmark various end-to-end supervised U-Net style models.
Specifically, we have benchmarked models on both 2D and 3D brain images and
evaluated them using standard metrics. We have achieved the highest Dice score
of 0.583 on the 2D transformer-based model and 0.504 on the 3D residual U-Net
respectively. We have conducted the Wilcoxon test for 3D models to correlate
the relationship between predicted and actual stroke volume. For
reproducibility, the code and model weights are made publicly available:
https://github.com/prantik-pdeb/BeSt-LeS.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07068" title="Abstract">arXiv:2310.07068</a> (cross-list from math.OC) [<a href="/pdf/2310.07068" title="Download PDF">pdf</a>, <a href="/format/2310.07068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking the human out of decomposition-based optimization via artificial  intelligence: Part I. Learning when to decompose
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mitrai%2C+I">Ilias Mitrai</a>, 
<a href="/search/math?searchtype=author&query=Daoutidis%2C+P">Prodromos Daoutidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we propose a graph classification approach for automatically
determining whether to use a monolithic or a decomposition-based solution
method. In this approach, an optimization problem is represented as a graph
that captures the structural and functional coupling among the variables and
constraints of the problem via an appropriate set of features. Given this
representation, a graph classifier is built to determine the best solution
method for a given problem. The proposed approach is used to develop a
classifier that determines whether a convex Mixed Integer Nonlinear Programming
problem should be solved using branch and bound or the outer approximation
algorithm. Finally, it is shown how the learned classifier can be incorporated
into existing mixed integer optimization solvers.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07082" title="Abstract">arXiv:2310.07082</a> (cross-list from math.OC) [<a href="/pdf/2310.07082" title="Download PDF">pdf</a>, <a href="/format/2310.07082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking the human out of decomposition-based optimization via artificial  intelligence: Part II. Learning to initialize
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mitrai%2C+I">Ilias Mitrai</a>, 
<a href="/search/math?searchtype=author&query=Daoutidis%2C+P">Prodromos Daoutidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The repeated solution of large-scale optimization problems arises frequently
in process systems engineering tasks. Decomposition-based solution methods have
been widely used to reduce the corresponding computational time, yet their
implementation has multiple steps that are difficult to configure. We propose a
machine learning approach to learn the optimal initialization of such
algorithms which minimizes the computational time. Active and supervised
learning is used to learn a surrogate model that predicts the computational
performance for a given initialization. We apply this approach to the
initialization of Generalized Benders Decomposition for the solution of mixed
integer model predictive control problems. The surrogate models are used to
find the optimal number of initial cuts that should be added in the master
problem. The results show that the proposed approach can lead to a significant
reduction in solution time, and active learning can reduce the data required
for learning.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07089" title="Abstract">arXiv:2310.07089</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2310.07089" title="Download PDF">pdf</a>, <a href="/format/2310.07089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Methods for Background Potential Estimation in 2DEGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=da+Cunha%2C+C">Carlo da Cunha</a>, 
<a href="/search/cond-mat?searchtype=author&query=Aoki%2C+N">Nobuyuki Aoki</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ferry%2C+D">David Ferry</a>, 
<a href="/search/cond-mat?searchtype=author&query=Vora%2C+K">Kevin Vora</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of quantum-effect devices and materials, two-dimensional
electron gases (2DEGs) stand as fundamental structures that promise
transformative technologies. However, the presence of impurities and defects in
2DEGs poses substantial challenges, impacting carrier mobility, conductivity,
and quantum coherence time. To address this, we harness the power of scanning
gate microscopy (SGM) and employ three distinct machine learning techniques to
estimate the background potential of 2DEGs from SGM data: image-to-image
translation using generative adversarial neural networks, cellular neural
network, and evolutionary search. Our findings, despite data constraints,
highlight the effectiveness of an evolutionary search algorithm in this
context, offering a novel approach for defect analysis. This work not only
advances our understanding of 2DEGs but also underscores the potential of
machine learning in probing quantum materials, with implications for quantum
computing and nanoelectronics.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07131" title="Abstract">arXiv:2310.07131</a> (cross-list from eess.IV) [<a href="/pdf/2310.07131" title="Download PDF">pdf</a>, <a href="/format/2310.07131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Echocardiography video synthesis from end diastolic semantic map via  diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Van%2C+P+N">Phi Nguyen Van</a>, 
<a href="/search/eess?searchtype=author&query=Minh%2C+D+T">Duc Tran Minh</a>, 
<a href="/search/eess?searchtype=author&query=Huy%2C+H+P">Hieu Pham Huy</a>, 
<a href="/search/eess?searchtype=author&query=Quoc%2C+L+T">Long Tran Quoc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Denoising Diffusion Probabilistic Models (DDPMs) have demonstrated
significant achievements in various image and video generation tasks, including
the domain of medical imaging. However, generating echocardiography videos
based on semantic anatomical information remains an unexplored area of
research. This is mostly due to the constraints imposed by the currently
available datasets, which lack sufficient scale and comprehensive frame-wise
annotations for every cardiac cycle. This paper aims to tackle the
aforementioned challenges by expanding upon existing video diffusion models for
the purpose of cardiac video synthesis. More specifically, our focus lies in
generating video using semantic maps of the initial frame during the cardiac
cycle, commonly referred to as end diastole. To further improve the synthesis
process, we integrate spatial adaptive normalization into multiscale feature
maps. This enables the inclusion of semantic guidance during synthesis,
resulting in enhanced realism and coherence of the resultant video sequences.
Experiments are conducted on the CAMUS dataset, which is a highly used dataset
in the field of echocardiography. Our model exhibits better performance
compared to the standard diffusion technique in terms of multiple metrics,
including FID, FVD, and SSMI.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07173" title="Abstract">arXiv:2310.07173</a> (cross-list from quant-ph) [<a href="/pdf/2310.07173" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing quantum algorithms with Qinterpreter: bridging the gap  between theory and practice across leading quantum computing platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sep%C3%BAlveda%2C+W+C">Wilmer Contreras Sep&#xfa;lveda</a>, 
<a href="/search/quant-ph?searchtype=author&query=Torres-Palencia%2C+%C3%81+D">&#xc1;ngel David Torres-Palencia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mondrag%C3%B3n%2C+J+J+S">Jos&#xe9; Javier S&#xe1;nchez Mondrag&#xf3;n</a>, 
<a href="/search/quant-ph?searchtype=author&query=Villegas-Mart%C3%ADnez%2C+B+M">Braulio Misael Villegas-Mart&#xed;nez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Escobedo-Alatorre%2C+J+J">J. Jes&#xfa;s Escobedo-Alatorre</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gesing%2C+S">Sandra Gesing</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lozano-Cris%C3%B3stomo%2C+N">N&#xe9;stor Lozano-Cris&#xf3;stomo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Garc%C3%ADa-Melgarejo%2C+J+C">Julio C&#xe9;sar Garc&#xed;a-Melgarejo</a>, 
<a href="/search/quant-ph?searchtype=author&query=P%C3%A9rez%2C+J+C+S">Juan Carlos S&#xe1;nchez P&#xe9;rez</a>, 
<a href="/search/quant-ph?searchtype=author&query=P%C3%A9rez%2C+E+N+P">Eddie Nelson Palacios- P&#xe9;rez</a>, 
<a href="/search/quant-ph?searchtype=author&query=PalilleroSandoval%2C+O">Omar PalilleroSandoval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computing is a rapidly emerging and promising field that has the
potential to revolutionize numerous research domains, including drug design,
network technologies and sustainable energy. Due to the inherent complexity and
divergence from classical computing, several major quantum computing libraries
have been developed to implement quantum algorithms, namely IBM Qiskit, Amazon
Braket, Cirq, PyQuil, and PennyLane. These libraries allow for quantum
simulations on classical computers and facilitate program execution on
corresponding quantum hardware, e.g., Qiskit programs on IBM quantum computers.
While all platforms have some differences, the main concepts are the same.
QInterpreter is a tool embedded in the Quantum Science Gateway QubitHub using
Jupyter Notebooks that translates seamlessly programs from one library to the
other and visualizes the results. It combines the five well-known quantum
libraries: into a unified framework. Designed as an educational tool for
beginners, Qinterpreter enables the development and execution of quantum
circuits across various platforms in a straightforward way. The work highlights
the versatility and accessibility of Qinterpreter in quantum programming and
underscores our ultimate goal of pervading Quantum Computing through younger,
less specialized, and diverse cultural and national communities.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07187" title="Abstract">arXiv:2310.07187</a> (cross-list from stat.ML) [<a href="/pdf/2310.07187" title="Download PDF">pdf</a>, <a href="/format/2310.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Cox partially linear regression: building predictive models for  cancer patients&#x27; survival
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rong%2C+Y">Yaohua Rong</a>, 
<a href="/search/stat?searchtype=author&query=Zhao%2C+S+D">Sihai Dave Zhao</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+X">Xia Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Wide heterogeneity exists in cancer patients' survival, ranging from a few
months to several decades. To accurately predict clinical outcomes, it is vital
to build an accurate predictive model that relates patients' molecular profiles
with patients' survival. With complex relationships between survival and
high-dimensional molecular predictors, it is challenging to conduct
non-parametric modeling and irrelevant predictors removing simultaneously. In
this paper, we build a kernel Cox proportional hazards semi-parametric model
and propose a novel regularized garrotized kernel machine (RegGKM) method to
fit the model. We use the kernel machine method to describe the complex
relationship between survival and predictors, while automatically removing
irrelevant parametric and non-parametric predictors through a LASSO penalty. An
efficient high-dimensional algorithm is developed for the proposed method.
Comparison with other competing methods in simulation shows that the proposed
method always has better predictive accuracy. We apply this method to analyze a
multiple myeloma dataset and predict patients' death burden based on their gene
expressions. Our results can help classify patients into groups with different
death risks, facilitating treatment for better clinical outcomes.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07190" title="Abstract">arXiv:2310.07190</a> (cross-list from stat.ML) [<a href="/pdf/2310.07190" title="Download PDF">pdf</a>, <a href="/ps/2310.07190" title="Download PostScript">ps</a>, <a href="/format/2310.07190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural networks: deep, shallow, or in between?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Petrova%2C+G">Guergana Petrova</a>, 
<a href="/search/stat?searchtype=author&query=Wojtaszczyk%2C+P">Przemyslaw Wojtaszczyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We give estimates from below for the error of approximation of a compact
subset from a Banach space by the outputs of feed-forward neural networks with
width W, depth l and Lipschitz activation functions. We show that, modulo
logarithmic factors, rates better that entropy numbers' rates are possibly
attainable only for neural networks for which the depth l goes to infinity, and
that there is no gain if we fix the depth and let the width W go to infinity.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07197" title="Abstract">arXiv:2310.07197</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2310.07197" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatChat: A Large Language Model and Application Service Platform for  Materials Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+Z">Ziyi Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xie%2C+F">Fankai Xie</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wan%2C+M">Meng Wan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yuan%2C+Y">Yang Yuan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+M">Miao Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Z">Zongguo Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Meng%2C+S">Sheng Meng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Y">Yangang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prediction of chemical synthesis pathways plays a pivotal role in
materials science research. Challenges, such as the complexity of synthesis
pathways and the lack of comprehensive datasets, currently hinder our ability
to predict these chemical processes accurately. However, recent advancements in
generative artificial intelligence (GAI), including automated text generation
and question-answering systems, coupled with fine-tuning techniques, have
facilitated the deployment of large-scale AI models tailored to specific
domains. In this study, we harness the power of the LLaMA2-7B model and enhance
it through a learning process that incorporates 13,878 pieces of structured
material knowledge data. This specialized AI model, named MatChat, focuses on
predicting inorganic material synthesis pathways. MatChat exhibits remarkable
proficiency in generating and reasoning with knowledge in materials science.
Although MatChat requires further refinement to meet the diverse material
design needs, this research undeniably highlights its impressive reasoning
capabilities and innovative potential in the field of materials science.
MatChat is now accessible online and open for use, with both the model and its
application framework available as open source. This study establishes a robust
foundation for collaborative innovation in the integration of generative AI in
materials science.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07224" title="Abstract">arXiv:2310.07224</a> (cross-list from math.OC) [<a href="/pdf/2310.07224" title="Download PDF">pdf</a>, <a href="/format/2310.07224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $O(n)$ Algorithms for Projection onto the Top-$k$-sum Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Roth%2C+J">Jake Roth</a>, 
<a href="/search/math?searchtype=author&query=Cui%2C+Y">Ying Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The top-$k$-sum operator computes the sum of the largest $k$ components of a
given vector. The Euclidean projection onto the top-$k$-sum constraint serves
as a crucial subroutine in iterative methods to solve composite superquantile
optimization problems. In this paper, we introduce a solver that implements two
finite-termination algorithms to compute this projection. Both algorithms have
complexity $O(n)$ when applied to a sorted $n$-dimensional input vector, where
the absorbed constant is independent of $k$. This stands in contrast to the
existing grid-search-inspired method that has $O(k(n-k))$ complexity. The
improvement is significant when $k$ is linearly dependent on $n$, which
frequently encountered in practical superquantile optimization applications. In
instances where the input vector is unsorted, an additional cost is incurred to
(partially) sort the vector. To reduce this cost, we further derive a rigorous
procedure that leverages approximate sorting to compute the projection, which
is particularly useful when solving a sequence of similar projection problems.
Numerical results show that our methods solve problems of scale $n=10^7$ and
$k=10^4$ within $0.05$ seconds, whereas the existing grid-search-based method
and the Gurobi QP solver can take minutes to hours.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07241" title="Abstract">arXiv:2310.07241</a> (cross-list from stat.ML) [<a href="/pdf/2310.07241" title="Download PDF">pdf</a>, <a href="/format/2310.07241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surrogate modeling for stochastic crack growth processes in structural  health monitoring applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Silionis%2C+N+E">Nicholas E. Silionis</a>, 
<a href="/search/stat?searchtype=author&query=Anyfantis%2C+K+N">Konstantinos N. Anyfantis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures. Preprint submitted to Elsevier journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fatigue crack growth is one of the most common types of deterioration in
metal structures with significant implications on their reliability. Recent
advances in Structural Health Monitoring (SHM) have motivated the use of
structural response data to predict future crack growth under uncertainty, in
order to enable a transition towards predictive maintenance. Accurately
representing different sources of uncertainty in stochastic crack growth (SCG)
processes is a non-trivial task. The present work builds on previous research
on physics-based SCG modeling under both material and load-related uncertainty.
The aim here is to construct computationally efficient, probabilistic surrogate
models for SCG processes that successfully encode these different sources of
uncertainty. An approach inspired by latent variable modeling is employed that
utilizes Gaussian Process (GP) regression models to enable the surrogates to be
used to generate prior distributions for different Bayesian SHM tasks as the
application of interest. Implementation is carried out in a numerical setting
and model performance is assessed for two fundamental crack SHM problems;
namely crack length monitoring (damage quantification) and crack growth
monitoring (damage prognosis).
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07250" title="Abstract">arXiv:2310.07250</a> (cross-list from q-bio.QM) [<a href="/pdf/2310.07250" title="Download PDF">pdf</a>, <a href="/format/2310.07250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Missing MRI Sequences from Available Modalities using  Generative Adversarial Networks in BraTS Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hamamci%2C+I+E">Ibrahim Ethem Hamamci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Glioblastoma is a highly aggressive and lethal form of brain cancer. Magnetic
resonance imaging (MRI) plays a significant role in the diagnosis, treatment
planning, and follow-up of glioblastoma patients due to its non-invasive and
radiation-free nature. The International Brain Tumor Segmentation (BraTS)
challenge has contributed to generating numerous AI algorithms to accurately
and efficiently segment glioblastoma sub-compartments using four structural
(T1, T1Gd, T2, T2-FLAIR) MRI scans. However, these four MRI sequences may not
always be available. To address this issue, Generative Adversarial Networks
(GANs) can be used to synthesize the missing MRI sequences. In this paper, we
implement and utilize an open-source GAN approach that takes any three MRI
sequences as input to generate the missing fourth structural sequence. Our
proposed approach is contributed to the community-driven generally nuanced deep
learning framework (GaNDLF) and demonstrates promising results in synthesizing
high-quality and realistic MRI sequences, enabling clinicians to improve their
diagnostic capabilities and support the application of AI methods to brain
tumor MRI quantification.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07284" title="Abstract">arXiv:2310.07284</a> (cross-list from eess.AS) [<a href="/pdf/2310.07284" title="Download PDF">pdf</a>, <a href="/format/2310.07284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typing to Listen at the Cocktail Party: Text-Guided Target Speaker  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hao%2C+X">Xiang Hao</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jibin Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+C">Chenglin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+K+C">Kay Chen Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Humans possess an extraordinary ability to selectively focus on the sound
source of interest amidst complex acoustic environments, commonly referred to
as cocktail party scenarios. In an attempt to replicate this remarkable
auditory attention capability in machines, target speaker extraction (TSE)
models have been developed. These models leverage the pre-registered cues of
the target speaker to extract the sound source of interest. However, the
effectiveness of these models is hindered in real-world scenarios due to the
potential variation or even absence of pre-registered cues. To address this
limitation, this study investigates the integration of natural language to
enhance the flexibility and controllability of existing TSE models.
Specifically, we propose a model named LLM-TSE, wherein a large language model
(LLM) to extract useful semantic cues from the user's typed text input, which
can complement the pre-registered cues or work independently to control the TSE
process. Our experimental results demonstrate competitive performance when only
text-based cues are presented, and a new state-of-the-art is set when combined
with pre-registered acoustic cues. To the best of our knowledge, this is the
first work that has successfully incorporated text-based cues to guide target
speaker extraction, which can be a cornerstone for cocktail party problem
research.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07359" title="Abstract">arXiv:2310.07359</a> (cross-list from eess.IV) [<a href="/pdf/2310.07359" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosing Bipolar Disorder from 3-D Structural Magnetic Resonance  Images Using a Hybrid GAN-CNN Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saghayan%2C+M+H">Masood Hamed Saghayan</a>, 
<a href="/search/eess?searchtype=author&query=Zolfagharnasab%2C+M+H">Mohammad Hossein Zolfagharnasab</a>, 
<a href="/search/eess?searchtype=author&query=Khadem%2C+A">Ali Khadem</a>, 
<a href="/search/eess?searchtype=author&query=Matinfar%2C+F">Farzam Matinfar</a>, 
<a href="/search/eess?searchtype=author&query=Rashidi%2C+H">Hassan Rashidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Bipolar Disorder (BD) is a psychiatric condition diagnosed by repetitive
cycles of hypomania and depression. Since diagnosing BD relies on subjective
behavioral assessments over a long period, a solid diagnosis based on objective
criteria is not straightforward. The current study responded to the described
obstacle by proposing a hybrid GAN-CNN model to diagnose BD from 3-D structural
MRI Images (sMRI). The novelty of this study stems from diagnosing BD from sMRI
samples rather than conventional datasets such as functional MRI (fMRI),
electroencephalography (EEG), and behavioral symptoms while removing the data
insufficiency usually encountered when dealing with sMRI samples. The impact of
various augmentation ratios is also tested using 5-fold cross-validation. Based
on the results, this study obtains an accuracy rate of 75.8%, a sensitivity of
60.3%, and a specificity of 82.5%, which are 3-5% higher than prior work while
utilizing less than 6% sample counts. Next, it is demonstrated that a 2- D
layer-based GAN generator can effectively reproduce complex 3D brain samples, a
more straightforward technique than manual image processing. Lastly, the
optimum augmentation threshold for the current study using 172 sMRI samples is
50%, showing the applicability of the described method for larger sMRI
datasets. In conclusion, it is established that data augmentation using GAN
improves the accuracy of the CNN classifier using sMRI samples, thus developing
more reliable decision support systems to assist practitioners in identifying
BD patients more reliably and in a shorter period
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07362" title="Abstract">arXiv:2310.07362</a> (cross-list from quant-ph) [<a href="/pdf/2310.07362" title="Download PDF">pdf</a>, <a href="/ps/2310.07362" title="Download PostScript">ps</a>, <a href="/format/2310.07362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fully Quantum Algorithm for Hydrodynamic Lattice Gas Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fonio%2C+N">Niccolo Fonio</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sagaut%2C+P">Pierre Sagaut</a>, 
<a href="/search/quant-ph?searchtype=author&query=Di+Molfetta%2C+G">Giuseppe Di Molfetta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Cellular Automata and Lattice Gases (nlin.CG); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Lattice Gas Cellular Automata (LGCA) are a computational model widely known
and applied for the simulation of many physical phenomena. Their implementation
requires an amount of resources and operations which scale linearly versus the
system size and number of time steps. We propose a quantum-pointers-based
quantum algorithm able to simulate LGCA while exhibiting an exponential
advantage in space complexity and a number of quantum operations independent
from the system size. We propose a collision circuit for the FHP lattice-gas
automata considering the 2-, 3-, and 4-body collisions. These are implemented
with two methodologies that suggest the procedure for finding quantum circuits
for LGCA with more collisions. We also propose a phase estimation algorithm to
retrieve information about a single cell, whose application can be expanded for
implementing other collisions. A general methodology to identify the invariants
associated to quantum LGCA is also proposed.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07371" title="Abstract">arXiv:2310.07371</a> (cross-list from quant-ph) [<a href="/pdf/2310.07371" title="Download PDF">pdf</a>, <a href="/format/2310.07371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental quantum natural gradient optimization in photonics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Yizhi Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xue%2C+S">Shichuan Xue</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Yaxuan Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ding%2C+J">Jiangfang Ding</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shi%2C+W">Weixu Shi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+D">Dongyang Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yingwen Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fu%2C+X">Xiang Fu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+G">Guangyao Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+A">Anqi Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Deng%2C+M">Mingtang Deng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+J">Junjie Wu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Optics Letters Vol. 48, Issue 14, pp. 3745-3748 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Optics (physics.optics)

</div>
<p class="mathjax">Variational quantum algorithms (VQAs) combining the advantages of
parameterized quantum circuits and classical optimizers, promise practical
quantum applications in the Noisy Intermediate-Scale Quantum era. The
performance of VQAs heavily depends on the optimization method. Compared with
gradient-free and ordinary gradient descent methods, the quantum natural
gradient (QNG), which mirrors the geometric structure of the parameter space,
can achieve faster convergence and avoid local minima more easily, thereby
reducing the cost of circuit executions. We utilized a fully programmable
photonic chip to experimentally estimate the QNG in photonics for the first
time. We obtained the dissociation curve of the He-H$^+$ cation and achieved
chemical accuracy, verifying the outperformance of QNG optimization on a
photonic device. Our work opens up a vista of utilizing QNG in photonics to
implement practical near-term quantum applications.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07372" title="Abstract">arXiv:2310.07372</a> (cross-list from math.CO) [<a href="/pdf/2310.07372" title="Download PDF">pdf</a>, <a href="/format/2310.07372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling triangulations of manifolds using Monte Carlo methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altmann%2C+E+G">Eduardo G. Altmann</a>, 
<a href="/search/math?searchtype=author&query=Spreer%2C+J">Jonathan Spreer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG); Geometric Topology (math.GT)

</div>
<p class="mathjax">We propose a Monte Carlo method to efficiently find, count, and sample
abstract triangulations of a given manifold M. The method is based on a biased
random walk through all possible triangulations of M (in the Pachner graph),
constructed by combining (bi-stellar) moves with suitable chosen accept/reject
probabilities (Metropolis-Hastings). Asymptotically, the method guarantees that
samples of triangulations are drawn at random from a chosen probability. This
enables us not only to sample (rare) triangulations of particular interest but
also to estimate the (extremely small) probability of obtaining them when
isomorphism types of triangulations are sampled uniformly at random. We
implement our general method for surface triangulations and 1-vertex
triangulations of 3-manifolds. To showcase its usefulness, we present a number
of experiments: (a) we recover asymptotic growth rates for the number of
isomorphism types of simplicial triangulations of the 2-dimensional sphere; (b)
we experimentally observe that the growth rate for the number of isomorphism
types of 1-vertex triangulations of the 3-dimensional sphere appears to be
singly exponential in the number of their tetrahedra; and (c) we present
experimental evidence that a randomly chosen isomorphism type of 1-vertex
n-tetrahedra 3-sphere triangulation, for n tending to infinity, almost surely
shows a fixed edge-degree distribution which decays exponentially for large
degrees, but shows non-monotonic behaviour for small degrees.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07401" title="Abstract">arXiv:2310.07401</a> (cross-list from eess.SP) [<a href="/pdf/2310.07401" title="Download PDF">pdf</a>, <a href="/ps/2310.07401" title="Download PostScript">ps</a>, <a href="/format/2310.07401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication enabled Doppler Frequency Shift  Estimation and Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jia%2C+J">Jinzhu Jia</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Ruiyun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,8 figures, IEEE/CIC ICCC conference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/CIC International Conference on Communications in China
  (ICCC). IEEE, 2023: 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Despite the millimeter wave technology fulfills the low-latency and high data
transmission, it will cause severe Doppler Frequency Shift (DFS) for high-speed
vehicular network, which tremendously damages the communication performance. In
this paper, we propose an Integrated Sensing and Communication (ISAC) enabled
DFS estimation and compensation algorithm. Firstly, the DFS is coarsely
estimated and compensated using radar detection. Then, the designed preamble
sequence is used to accurately estimate and compensate DFS. In addition, an
adaptive DFS estimator is designed to reduce the computational complexity.
Compared with the traditional DFS estimation algorithm, the improvement of the
proposed algorithm is verified in bit error rate and mean square error
performance by simulation results.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07421" title="Abstract">arXiv:2310.07421</a> (cross-list from math.GT) [<a href="/pdf/2310.07421" title="Download PDF">pdf</a>, <a href="/format/2310.07421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simpler algorithmically unrecognizable 4-manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tancer%2C+M">Martin Tancer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Computational Geometry (cs.CG); Group Theory (math.GR)

</div>
<p class="mathjax">Markov proved that there exists an unrecognizable 4-manifold, that is, a
4-manifold for which the homeomorphism problem is undecidable. In this paper we
consider the question how close we can get to S^4 with an unrecognizable
manifold. One of our achievements is that we show a way to remove so-called
Markov's trick from the proof of existence of such a manifold. This trick
contributes to the complexity of the resulting manifold. We also show how to
decrease the deficiency (or the number of relations) in so-called Adian-Rabin
set which is another ingredient that contributes to the complexity of the
resulting manifold. Altogether, our approach allows to show that the connected
sum #_9(S^2 x S^2) is unrecognizable while the previous best result is the
unrecognizability of #_12(S^2 x S^2) due to Gordon.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07437" title="Abstract">arXiv:2310.07437</a> (cross-list from physics.ao-ph) [<a href="/pdf/2310.07437" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Branched Deep Convolutional Network for Forecasting the Occurrence of  Hazes in Paris using Meteorological Maps with Different Characteristic  Spatial Scales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+C">Chien Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A deep learning platform has been developed to forecast the occurrence of the
low visibility events or hazes. It is trained by using multi-decadal daily
regional maps of various meteorological and hydrological variables as input
features and surface visibility observations as the targets. To better preserve
the characteristic spatial information of different input features for
training, two branched architectures have recently been developed for the case
of Paris hazes. These new architectures have improved the performance of the
network, producing reasonable scores in both validation and a blind forecasting
evaluation using the data of 2021 and 2022 that have not been used in the
training and validation.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07452" title="Abstract">arXiv:2310.07452</a> (cross-list from math.CO) [<a href="/pdf/2310.07452" title="Download PDF">pdf</a>, <a href="/format/2310.07452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $k$-vertex-edge domination of graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bhattacharya%2C+D">Debojyoti Bhattacharya</a>, 
<a href="/search/math?searchtype=author&query=Paul%2C+S">Subhabrata Paul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Let $G=(V,E)$ be a simple undirected graph. The open neighbourhood of a
vertex $v$ in $G$ is defined as $N_G(v)=\{u\in V~|~ uv\in E\}$; whereas the
closed neighbourhood is defined as $N_G[v]= N_G(v)\cup \{v\}$. For an integer
$k$, a subset $D\subseteq V$ is called a $k$-vertex-edge dominating set of $G$
if for every edge $uv\in E$, $|(N_G[u]\cup N_G[v]) \cap D|\geq k$. In
$k$-vertex-edge domination problem, our goal is to find a $k$-vertex-edge
dominating set of minimum cardinality of an input graph $G$. In this paper, we
first prove that the decision version of $k$-vertex-edge domination problem is
NP-complete for chordal graphs. On the positive side, we design a linear time
algorithm for finding a minimum $k$-vertex-edge dominating set of tree. We also
prove that there is a $O(\log(\Delta(G)))$-approximation algorithm for this
problem in general graph $G$, where $\Delta(G)$ is the maximum degree of $G$.
Then we show that for a graph $G$ with $n$ vertices, this problem cannot be
approximated within a factor of $(1-\epsilon) \ln n$ for any $\epsilon &gt;0$
unless $NP\subseteq DTIME(|V|^{O(\log\log|V|)})$. Finally, we prove that it is
APX-complete for graphs with bounded degree $k+3$.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07463" title="Abstract">arXiv:2310.07463</a> (cross-list from eess.SP) [<a href="/pdf/2310.07463" title="Download PDF">pdf</a>, <a href="/format/2310.07463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering ECG Changes during Healthy Aging using Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ott%2C+G">Gabriel Ott</a>, 
<a href="/search/eess?searchtype=author&query=Schaubelt%2C+Y">Yannik Schaubelt</a>, 
<a href="/search/eess?searchtype=author&query=Alcaraz%2C+J+M+L">Juan Miguel Lopez Alcaraz</a>, 
<a href="/search/eess?searchtype=author&query=Haverkamp%2C+W">Wilhelm Haverkamp</a>, 
<a href="/search/eess?searchtype=author&query=Strodthoff%2C+N">Nils Strodthoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, code available under <a href="https://github.com/AI4HealthUOL/ECG-aging">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Cardiovascular diseases remain the leading global cause of mortality. This
necessitates a profound understanding of heart aging processes to diagnose
constraints in cardiovascular fitness. Traditionally, most of such insights
have been drawn from the analysis of electrocardiogram (ECG) feature changes of
individuals as they age. However, these features, while informative, may
potentially obscure underlying data relationships. In this paper, we employ a
deep-learning model and a tree-based model to analyze ECG data from a robust
dataset of healthy individuals across varying ages in both raw signals and ECG
feature format. Explainable AI techniques are then used to identify ECG
features or raw signal characteristics are most discriminative for
distinguishing between age groups. Our analysis with tree-based classifiers
reveal age-related declines in inferred breathing rates and identifies notably
high SDANN values as indicative of elderly individuals, distinguishing them
from younger adults. Furthermore, the deep-learning model underscores the
pivotal role of the P-wave in age predictions across all age groups, suggesting
potential changes in the distribution of different P-wave types with age. These
findings shed new light on age-related ECG changes, offering insights that
transcend traditional feature-based approaches.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07464" title="Abstract">arXiv:2310.07464</a> (cross-list from eess.IV) [<a href="/pdf/2310.07464" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Predicts Biomarker Status and Discovers Related  Histomorphology Characteristics for Low-Grade Glioma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+Z">Zijie Fang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yihan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiangyang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+C">Changjing Cai</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yiyang Lin</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+Y">Ying Han</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+S">Shan Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+H">Hong Shen</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+J">Jun Tan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yongbing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Biomarker detection is an indispensable part in the diagnosis and treatment
of low-grade glioma (LGG). However, current LGG biomarker detection methods
rely on expensive and complex molecular genetic testing, for which
professionals are required to analyze the results, and intra-rater variability
is often reported. To overcome these challenges, we propose an interpretable
deep learning pipeline, a Multi-Biomarker Histomorphology Discoverer
(Multi-Beholder) model based on the multiple instance learning (MIL) framework,
to predict the status of five biomarkers in LGG using only hematoxylin and
eosin-stained whole slide images and slide-level biomarker status labels.
Specifically, by incorporating the one-class classification into the MIL
framework, accurate instance pseudo-labeling is realized for instance-level
supervision, which greatly complements the slide-level labels and improves the
biomarker prediction performance. Multi-Beholder demonstrates superior
prediction performance and generalizability for five LGG biomarkers
(AUROC=0.6469-0.9735) in two cohorts (n=607) with diverse races and scanning
protocols. Moreover, the excellent interpretability of Multi-Beholder allows
for discovering the quantitative and qualitative correlations between biomarker
status and histomorphology characteristics. Our pipeline not only provides a
novel approach for biomarker prediction, enhancing the applicability of
molecular treatments for LGG patients but also facilitates the discovery of new
mechanisms in molecular functionality and LGG progression.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07499" title="Abstract">arXiv:2310.07499</a> (cross-list from hep-th) [<a href="/pdf/2310.07499" title="Download PDF">pdf</a>, <a href="/format/2310.07499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional renormalization group for signal detection and stochastic  ergodicity breaking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-th?searchtype=author&query=Erbin%2C+H">Harold Erbin</a>, 
<a href="/search/hep-th?searchtype=author&query=Finotello%2C+R">Riccardo Finotello</a>, 
<a href="/search/hep-th?searchtype=author&query=Kpera%2C+B+W">Bio Wahabou Kpera</a>, 
<a href="/search/hep-th?searchtype=author&query=Lahoche%2C+V">Vincent Lahoche</a>, 
<a href="/search/hep-th?searchtype=author&query=Samary%2C+D+O">Dine Ousmane Samary</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Theory (hep-th)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Theory (cs.IT)

</div>
<p class="mathjax">Signal detection is one of the main challenges of data science. As it often
happens in data analysis, the signal in the data may be corrupted by noise.
There is a wide range of techniques aimed at extracting the relevant degrees of
freedom from data. However, some problems remain difficult. It is notably the
case of signal detection in almost continuous spectra when the signal-to-noise
ratio is small enough. This paper follows a recent bibliographic line which
tackles this issue with field-theoretical methods. Previous analysis focused on
equilibrium Boltzmann distributions for some effective field representing the
degrees of freedom of data. It was possible to establish a relation between
signal detection and $\mathbb{Z}_2$-symmetry breaking. In this paper, we
consider a stochastic field framework inspiring by the so-called "Model A", and
show that the ability to reach or not an equilibrium state is correlated with
the shape of the dataset. In particular, studying the renormalization group of
the model, we show that the weak ergodicity prescription is always broken for
signals small enough, when the data distribution is close to the
Marchenko-Pastur (MP) law. This, in particular, enables the definition of a
detection threshold in the regime where the signal-to-noise ratio is small
enough.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07504" title="Abstract">arXiv:2310.07504</a> (cross-list from eess.IV) [<a href="/pdf/2310.07504" title="Download PDF">pdf</a>, <a href="/format/2310.07504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PtychoDV: Vision Transformer-Based Deep Unrolling Network for  Ptychographic Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gan%2C+W">Weijie Gan</a>, 
<a href="/search/eess?searchtype=author&query=Zhai%2C+Q">Qiuchen Zhai</a>, 
<a href="/search/eess?searchtype=author&query=McCann%2C+M+T">Michael Thompson McCann</a>, 
<a href="/search/eess?searchtype=author&query=Cardona%2C+C+G">Cristina Garcia Cardona</a>, 
<a href="/search/eess?searchtype=author&query=Kamilov%2C+U+S">Ulugbek S. Kamilov</a>, 
<a href="/search/eess?searchtype=author&query=Wohlberg%2C+B">Brendt Wohlberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Ptychography is an imaging technique that captures multiple overlapping
snapshots of a sample, illuminated coherently by a moving localized probe. The
image recovery from ptychographic data is generally achieved via an iterative
algorithm that solves a nonlinear phase-field problem derived from measured
diffraction patterns. However, these approaches have high computational cost.
In this paper, we introduce PtychoDV, a novel deep model-based network designed
for efficient, high-quality ptychographic image reconstruction. PtychoDV
comprises a vision transformer that generates an initial image from the set of
raw measurements, taking into consideration their mutual correlations. This is
followed by a deep unrolling network that refines the initial image using
learnable convolutional priors and the ptychography measurement model.
Experimental results on simulated data demonstrate that PtychoDV is capable of
outperforming existing deep learning methods for this problem, and
significantly reduces computational cost compared to iterative methodologies,
while maintaining competitive performance.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07528" title="Abstract">arXiv:2310.07528</a> (cross-list from quant-ph) [<a href="/pdf/2310.07528" title="Download PDF">pdf</a>, <a href="/format/2310.07528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Advantage of Parameterized Quantum Circuit in Function  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yu%2C+Z">Zhan Yu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Q">Qiuhao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiao%2C+Y">Yuling Jiao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Y">Yinan Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lu%2C+X">Xiliang Lu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+J+Z">Jerry Zhijian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding the power of parameterized quantum circuits (PQCs) in
accomplishing machine learning tasks is one of the most important questions in
quantum machine learning. In this paper, we analyze the expressivity of PQCs
through the lens of function approximation. Previously established universal
approximation theorems for PQCs are mainly nonconstructive, leading us to the
following question: How large do the PQCs need to be to approximate the target
function up to a given error? We exhibit explicit constructions of data
re-uploading PQCs for approximating continuous and smooth functions and
establish quantitative approximation error bounds in terms of the width, the
depth and the number of trainable parameters of the PQCs. To achieve this, we
utilize techniques from quantum signal processing and linear combinations of
unitaries to construct PQCs that implement multivariate polynomials. We
implement global and local approximation techniques using Bernstein polynomials
and local Taylor expansion and analyze their performances in the quantum
setting. We also compare our proposed PQCs to nearly optimal deep neural
networks in approximating high-dimensional smooth functions, showing that the
ratio between model sizes of PQC and deep neural networks is exponentially
small with respect to the input dimension. This suggests a potentially novel
avenue for showcasing quantum advantages in quantum machine learning.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07558" title="Abstract">arXiv:2310.07558</a> (cross-list from stat.ML) [<a href="/pdf/2310.07558" title="Download PDF">pdf</a>, <a href="/ps/2310.07558" title="Download PostScript">ps</a>, <a href="/format/2310.07558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smootheness-Adaptive Dynamic Pricing with Nonparametric Demand Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ye%2C+Z">Zeqi Ye</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+H">Hansheng Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
<p class="mathjax">We study the dynamic pricing problem where the demand function is
nonparametric and H\"older smooth, and we focus on adaptivity to the unknown
H\"older smoothness parameter $\beta$ of the demand function. Traditionally the
optimal dynamic pricing algorithm heavily relies on the knowledge of $\beta$ to
achieve a minimax optimal regret of
$\widetilde{O}(T^{\frac{\beta+1}{2\beta+1}})$. However, we highlight the
challenge of adaptivity in this dynamic pricing problem by proving that no
pricing policy can adaptively achieve this minimax optimal regret without
knowledge of $\beta$. Motivated by the impossibility result, we propose a
self-similarity condition to enable adaptivity. Importantly, we show that the
self-similarity condition does not compromise the problem's inherent complexity
since it preserves the regret lower bound
$\Omega(T^{\frac{\beta+1}{2\beta+1}})$. Furthermore, we develop a
smoothness-adaptive dynamic pricing algorithm and theoretically prove that the
algorithm achieves this minimax optimal regret bound without the prior
knowledge $\beta$.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07570" title="Abstract">arXiv:2310.07570</a> (cross-list from math.AT) [<a href="/pdf/2310.07570" title="Download PDF">pdf</a>, <a href="/format/2310.07570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT for Computational Topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+G">Guo-Wei Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ChatGPT represents a significant milestone in the field of artificial
intelligence (AI), finding widespread applications across diverse domains.
However, its effectiveness in mathematical contexts has been somewhat
constrained by its susceptibility to conceptual errors. Concurrently,
topological data analysis (TDA), a relatively new discipline, has garnered
substantial interest in recent years. Nonetheless, the advancement of TDA is
impeded by the limited understanding of computational algorithms and coding
proficiency among theoreticians. This work endeavors to bridge the gap between
theoretical topological concepts and their practical implementation in
computational topology through the utilization of ChatGPT. We showcase how a
pure theoretician, devoid of computational experience and coding skills, can
effectively transform mathematical formulations and concepts into functional
code for computational topology with the assistance of ChatGPT. Our strategy
outlines a productive process wherein a mathematician trains ChatGPT on pure
mathematical concepts, steers ChatGPT towards generating computational topology
code, and subsequently validates the generated code using established examples.
Our specific case studies encompass the computation of Betti numbers, Laplacian
matrices, and Dirac matrices for simplicial complexes, as well as the
persistence of various homologies and Laplacians. Furthermore, we explore the
application of ChatGPT in computing recently developed topological theories for
hypergraphs and digraphs. This work serves as an initial step towards
effectively transforming pure mathematical theories into practical
computational tools, with the ultimate goal of enabling real applications
across diverse fields.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07577" title="Abstract">arXiv:2310.07577</a> (cross-list from econ.TH) [<a href="/pdf/2310.07577" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of resource availability and conformity effect on sustainability  of common-pool resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Tu%2C+C">Chengyi Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Sustainability of common-pool resources hinges on the interplay between human
and environmental systems. However, there is still a lack of a novel and
comprehensive framework for modelling extraction of common-pool resources and
cooperation of human agents that can account for different factors that shape
the system behavior and outcomes. In particular, we still lack a critical value
for ensuring resource sustainability under different scenarios. In this paper,
we present a novel framework for studying resource extraction and cooperation
in human-environmental systems for common-pool resources. We explore how
different factors, such as resource availability and conformity effect,
influence the players' decisions and the resource outcomes. We identify
critical values for ensuring resource sustainability under various scenarios.
We demonstrate the observed phenomena are robust to the complexity and
assumptions of the models and discuss implications of our study for policy and
practice, as well as the limitations and directions for future research.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07633" title="Abstract">arXiv:2310.07633</a> (cross-list from eess.IV) [<a href="/pdf/2310.07633" title="Download PDF">pdf</a>, <a href="/format/2310.07633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Map Augmentation for Hypercomplex Breast Cancer Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lopez%2C+E">Eleonora Lopez</a>, 
<a href="/search/eess?searchtype=author&query=Betello%2C+F">Filippo Betello</a>, 
<a href="/search/eess?searchtype=author&query=Carmignani%2C+F">Federico Carmignani</a>, 
<a href="/search/eess?searchtype=author&query=Grassucci%2C+E">Eleonora Grassucci</a>, 
<a href="/search/eess?searchtype=author&query=Comminiello%2C+D">Danilo Comminiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Breast cancer is the most widespread neoplasm among women and early detection
of this disease is critical. Deep learning techniques have become of great
interest to improve diagnostic performance. Nonetheless, discriminating between
malignant and benign masses from whole mammograms remains challenging due to
them being almost identical to an untrained eye and the region of interest
(ROI) occupying a minuscule portion of the entire image. In this paper, we
propose a framework, parameterized hypercomplex attention maps (PHAM), to
overcome these problems. Specifically, we deploy an augmentation step based on
computing attention maps. Then, the attention maps are used to condition the
classification step by constructing a multi-dimensional input comprised of the
original breast cancer image and the corresponding attention map. In this step,
a parameterized hypercomplex neural network (PHNN) is employed to perform
breast cancer classification. The framework offers two main advantages. First,
attention maps provide critical information regarding the ROI and allow the
neural model to concentrate on it. Second, the hypercomplex architecture has
the ability to model local relations between input dimensions thanks to
hypercomplex algebra rules, thus properly exploiting the information provided
by the attention map. We demonstrate the efficacy of the proposed framework on
both mammography images as well as histopathological ones, surpassing
attention-based state-of-the-art networks and the real-valued counterpart of
our method. The code of our work is available at
https://github.com/elelo22/AttentionBCS.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07658" title="Abstract">arXiv:2310.07658</a> (cross-list from eess.SP) [<a href="/pdf/2310.07658" title="Download PDF">pdf</a>, <a href="/format/2310.07658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The First Pathloss Radio Map Prediction Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yapar%2C+%C3%87">&#xc7;a&#x11f;kan Yapar</a>, 
<a href="/search/eess?searchtype=author&query=Jaensch%2C+F">Fabian Jaensch</a>, 
<a href="/search/eess?searchtype=author&query=Levie%2C+R">Ron Levie</a>, 
<a href="/search/eess?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">To foster research and facilitate fair comparisons among recently proposed
pathloss radio map prediction methods, we have launched the ICASSP 2023 First
Pathloss Radio Map Prediction Challenge. In this short overview paper, we
briefly describe the pathloss prediction problem, the provided datasets, the
challenge task and the challenge evaluation methodology. Finally, we present
the results of the challenge.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07663" title="Abstract">arXiv:2310.07663</a> (cross-list from eess.AS) [<a href="/pdf/2310.07663" title="Download PDF">pdf</a>, <a href="/format/2310.07663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Video Inpainting Guided by Audio-Visual Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+K">Kyuyeon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+J">Junsik Jung</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+W+J">Woo Jae Kim</a>, 
<a href="/search/eess?searchtype=author&query=Yoon%2C+S">Sung-Eui Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD)

</div>
<p class="mathjax">Humans can easily imagine a scene from auditory information based on their
prior knowledge of audio-visual events. In this paper, we mimic this innate
human ability in deep learning models to improve the quality of video
inpainting. To implement the prior knowledge, we first train the audio-visual
network, which learns the correspondence between auditory and visual
information. Then, the audio-visual network is employed as a guider that
conveys the prior knowledge of audio-visual correspondence to the video
inpainting network. This prior knowledge is transferred through our proposed
two novel losses: audio-visual attention loss and audio-visual pseudo-class
consistency loss. These two losses further improve the performance of the video
inpainting by encouraging the inpainting result to have a high correspondence
to its synchronized audio. Experimental results demonstrate that our proposed
method can restore a wider domain of video scenes and is particularly effective
when the sounding object in the scene is partially blinded.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07672" title="Abstract">arXiv:2310.07672</a> (cross-list from stat.ML) [<a href="/pdf/2310.07672" title="Download PDF">pdf</a>, <a href="/format/2310.07672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Estimates of Shapley Values with Control Variates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Goldwasser%2C+J">Jeremy Goldwasser</a>, 
<a href="/search/stat?searchtype=author&query=Hooker%2C+G">Giles Hooker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Shapley values are among the most popular tools for explaining predictions of
blackbox machine learning models. However, their high computational cost
motivates the use of sampling approximations, inducing a considerable degree of
uncertainty. To stabilize these model explanations, we propose ControlSHAP, an
approach based on the Monte Carlo technique of control variates. Our
methodology is applicable to any machine learning model and requires virtually
no extra computation or modeling effort. On several high-dimensional datasets,
we find it can produce dramatic reductions in the Monte Carlo variability of
Shapley estimates.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07687" title="Abstract">arXiv:2310.07687</a> (cross-list from astro-ph.HE) [<a href="/pdf/2310.07687" title="Download PDF">pdf</a>, <a href="/format/2310.07687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orbital Polarimetric Tomography of a Flare Near the Sagittarius A*  Supermassive Black Hole
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Levis%2C+A">Aviad Levis</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chael%2C+A+A">Andrew A. Chael</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bouman%2C+K+L">Katherine L. Bouman</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wielgus%2C+M">Maciek Wielgus</a>, 
<a href="/search/astro-ph?searchtype=author&query=Srinivasan%2C+P+P">Pratul P. Srinivasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Astrophysical Phenomena (astro-ph.HE)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The interaction between the supermassive black hole at the center of the
Milky Way, Sagittarius A$^*$, and its accretion disk, occasionally produces
high energy flares seen in X-ray, infrared and radio. One mechanism for
observed flares is the formation of compact bright regions that appear within
the accretion disk and close to the event horizon. Understanding these flares
can provide a window into black hole accretion processes. Although
sophisticated simulations predict the formation of these flares, their
structure has yet to be recovered by observations. Here we show the first
three-dimensional (3D) reconstruction of an emission flare in orbit recovered
from ALMA light curves observed on April 11, 2017. Our recovery results show
compact bright regions at a distance of roughly 6 times the event horizon.
Moreover, our recovery suggests a clockwise rotation in a low-inclination
orbital plane, a result consistent with prior studies by EHT and GRAVITY
collaborations. To recover this emission structure we solve a highly ill-posed
tomography problem by integrating a neural 3D representation (an emergent
artificial intelligence approach for 3D reconstruction) with a gravitational
model for black holes. Although the recovered 3D structure is subject, and
sometimes sensitive, to the model assumptions, under physically motivated
choices we find that our results are stable and our approach is successful on
simulated data. We anticipate that in the future, this approach could be used
to analyze a richer collection of time-series data that could shed light on the
mechanisms governing black hole and plasma dynamics.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07690" title="Abstract">arXiv:2310.07690</a> (cross-list from physics.optics) [<a href="/pdf/2310.07690" title="Download PDF">pdf</a>, <a href="/format/2310.07690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale photonic computing with nonlinear disordered media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/physics?searchtype=author&query=Hu%2C+J">Jianqi Hu</a>, 
<a href="/search/physics?searchtype=author&query=Morandi%2C+A">Andrea Morandi</a>, 
<a href="/search/physics?searchtype=author&query=Nardi%2C+A">Alfonso Nardi</a>, 
<a href="/search/physics?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+X">Xuanchen Li</a>, 
<a href="/search/physics?searchtype=author&query=Savo%2C+R">Romolo Savo</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Grange%2C+R">Rachel Grange</a>, 
<a href="/search/physics?searchtype=author&query=Gigan%2C+S">Sylvain Gigan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Neural networks find widespread use in scientific and technological
applications, yet their implementations in conventional computers have
encountered bottlenecks due to ever-expanding computational needs. Photonic
neuromorphic hardware, which manipulates information and represents data
continuously in the optical domain, is one of the promising platforms with
potential advantages of massive parallelism, ultralow latency, and reduced
energy consumption. While linear photonic neural networks are within reach,
photonic computing with large-scale optical nonlinear nodes remains largely
unexplored. Here, we demonstrate a large-scale, high-performance nonlinear
photonic neural system based on a disordered polycrystalline slab composed of
lithium niobate nanocrystals. Mediated by random quasi-phase-matching and
multiple scattering, linear and nonlinear optical speckle features are
generated as the interplay between the simultaneous linear random scattering
and the second-harmonic generation, defining a complex neural network in which
the second-order nonlinearity acts as internal nonlinear activation functions.
Benchmarked against linear random projection, such nonlinear mapping embedded
with rich physical computational operations shows improved performance across a
large collection of machine learning tasks in image classification, regression,
and graph classification with varying complexity. Demonstrating up to 27,648
input and 3,500 nonlinear output nodes, the combination of optical nonlinearity
and random scattering serves as a scalable computing engine for diverse
applications.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07711" title="Abstract">arXiv:2310.07711</a> (cross-list from q-bio.NC) [<a href="/pdf/2310.07711" title="Download PDF">pdf</a>, <a href="/format/2310.07711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Growing Brains: Co-emergence of Anatomical and Functional Modularity in  Recurrent Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Khona%2C+M">Mikail Khona</a>, 
<a href="/search/q-bio?searchtype=author&query=Fiete%2C+I+R">Ila R. Fiete</a>, 
<a href="/search/q-bio?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Recurrent neural networks (RNNs) trained on compositional tasks can exhibit
functional modularity, in which neurons can be clustered by activity similarity
and participation in shared computational subtasks. Unlike brains, these RNNs
do not exhibit anatomical modularity, in which functional clustering is
correlated with strong recurrent coupling and spatial localization of
functional clusters. Contrasting with functional modularity, which can be
ephemerally dependent on the input, anatomically modular networks form a robust
substrate for solving the same subtasks in the future. To examine whether it is
possible to grow brain-like anatomical modularity, we apply a recent machine
learning method, brain-inspired modular training (BIMT), to a network being
trained to solve a set of compositional cognitive tasks. We find that
functional and anatomical clustering emerge together, such that functionally
similar neurons also become spatially localized and interconnected. Moreover,
compared to standard $L_1$ or no regularization settings, the model exhibits
superior performance by optimally balancing task performance and network
sparsity. In addition to achieving brain-like organization in RNNs, our
findings also suggest that BIMT holds promise for applications in neuromorphic
computing and enhancing the interpretability of neural network architectures.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 12 Oct 23</h3>
<dl>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1505.01695" title="Abstract">arXiv:1505.01695</a> (replaced) [<a href="/pdf/1505.01695" title="Download PDF">pdf</a>, <a href="/ps/1505.01695" title="Download PostScript">ps</a>, <a href="/format/1505.01695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proving Termination of Graph Transformation Systems using Weighted Type  Graphs over Semirings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruggink%2C+H+J+S">H.J. Sander Bruggink</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6nig%2C+B">Barbara K&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Nolte%2C+D">Dennis Nolte</a>, 
<a href="/search/cs?searchtype=author&query=Zantema%2C+H">Hans Zantema</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.08883" title="Abstract">arXiv:1910.08883</a> (replaced) [<a href="/pdf/1910.08883" title="Download PDF">pdf</a>, <a href="/format/1910.08883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-dimensional and universally consistent k-sample tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Panda%2C+S">Sambit Panda</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+C">Cencheng Shen</a>, 
<a href="/search/stat?searchtype=author&query=Perry%2C+R">Ronan Perry</a>, 
<a href="/search/stat?searchtype=author&query=Zorn%2C+J">Jelle Zorn</a>, 
<a href="/search/stat?searchtype=author&query=Lutz%2C+A">Antoine Lutz</a>, 
<a href="/search/stat?searchtype=author&query=Priebe%2C+C+E">Carey E. Priebe</a>, 
<a href="/search/stat?searchtype=author&query=Vogelstein%2C+J+T">Joshua T. Vogelstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.11103" title="Abstract">arXiv:1910.11103</a> (replaced) [<a href="/pdf/1910.11103" title="Download PDF">pdf</a>, <a href="/ps/1910.11103" title="Download PostScript">ps</a>, <a href="/format/1910.11103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEC2: SPECtral SParsE CNN Accelerator on FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yue Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Hanqing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Ajitesh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Lakhotia%2C+K">Kartik Lakhotia</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a 10-page conference paper in 26TH IEEE International Conference On High Performance Computing, Data, and Analytics (HiPC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.01674" title="Abstract">arXiv:2008.01674</a> (replaced) [<a href="/pdf/2008.01674" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Machine Learning Approach for Modelling Parking Duration in Urban  Land-use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Parmar%2C+J">Janak Parmar</a>, 
<a href="/search/stat?searchtype=author&query=Das%2C+P">Pritikana Das</a>, 
<a href="/search/stat?searchtype=author&query=Dave%2C+S">Sanjaykumar Dave</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physica A: Statistical Mechanics and its Applications, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.09471" title="Abstract">arXiv:2010.09471</a> (replaced) [<a href="/pdf/2010.09471" title="Download PDF">pdf</a>, <a href="/format/2010.09471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Cut-Offs in Leaderless Rendez-Vous Protocols is Easy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+A+R">A. R. Balasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Esparza%2C+J">Javier Esparza</a>, 
<a href="/search/cs?searchtype=author&query=Raskin%2C+M">Mikhail Raskin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.00685" title="Abstract">arXiv:2011.00685</a> (replaced) [<a href="/pdf/2011.00685" title="Download PDF">pdf</a>, <a href="/format/2011.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Biconnectivity Restoration in Multi-Robot Systems for Robust  Communication Maintenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishat-E-Rabban%2C+M">Md Ishat-E-Rabban</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangyao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.15629" title="Abstract">arXiv:2103.15629</a> (replaced) [<a href="/pdf/2103.15629" title="Download PDF">pdf</a>, <a href="/format/2103.15629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability analysis of time-delay systems in the parametric space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Turkulov%2C+V">Vukan Turkulov</a>, 
<a href="/search/eess?searchtype=author&query=Rapaic%2C+M+R">Milan R. Rapaic</a>, 
<a href="/search/eess?searchtype=author&query=Malti%2C+R">Rachid Malti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.05859" title="Abstract">arXiv:2104.05859</a> (replaced) [<a href="/pdf/2104.05859" title="Download PDF">pdf</a>, <a href="/format/2104.05859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Exploration for Open-World Navigation with Latent Goal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Eysenbach%2C+B">Benjamin Eysenbach</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+G">Gregory Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Rhinehart%2C+N">Nicholas Rhinehart</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 5th Annual Conference on Robot Learning (CoRL 2021), London, UK as an Oral Talk. Project page and dataset release at <a href="https://sites.google.com/view/recon-robot">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.14349" title="Abstract">arXiv:2106.14349</a> (replaced) [<a href="/pdf/2106.14349" title="Download PDF">pdf</a>, <a href="/format/2106.14349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PNet -- A Deep Learning Based Photometry and Astrometry Bayesian  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jia%2C+P">Peng Jia</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sun%2C+Y">Yongyang Sun</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yang%2C+Z">Zhimin Yang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wei%2C+H">Hongyan Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the AJ and welcome to any comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Astrophysics of Galaxies (astro-ph.GA); Solar and Stellar Astrophysics (astro-ph.SR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.08898" title="Abstract">arXiv:2110.08898</a> (replaced) [<a href="/pdf/2110.08898" title="Download PDF">pdf</a>, <a href="/ps/2110.08898" title="Download PostScript">ps</a>, <a href="/format/2110.08898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms, hardness and graph products on a pursuit-evasion game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costa%2C+E">Eurinardo Costa</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+N">Nicolas Martins</a>, 
<a href="/search/cs?searchtype=author&query=Sampaio%2C+R">Rudini Sampaio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08117" title="Abstract">arXiv:2111.08117</a> (replaced) [<a href="/pdf/2111.08117" title="Download PDF">pdf</a>, <a href="/ps/2111.08117" title="Download PostScript">ps</a>, <a href="/format/2111.08117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural networks with linear threshold activations: structure and  algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalife%2C+S">Sammy Khalife</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hongyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Amitabh Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07597" title="Abstract">arXiv:2201.07597</a> (replaced) [<a href="/pdf/2201.07597" title="Download PDF">pdf</a>, <a href="/format/2201.07597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPHammer: A Device Identification Framework based on DRAM Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yangkun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Zhenyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianhong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version has been accepted by TrustCom-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.11383" title="Abstract">arXiv:2201.11383</a> (replaced) [<a href="/pdf/2201.11383" title="Download PDF">pdf</a>, <a href="/ps/2201.11383" title="Download PostScript">ps</a>, <a href="/format/2201.11383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Capacity of Zero-Drift First Arrival Position Channels in  Diffusive Molecular Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yen-Chi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+M">Min-Hsiu Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.07870" title="Abstract">arXiv:2202.07870</a> (replaced) [<a href="/pdf/2202.07870" title="Download PDF">pdf</a>, <a href="/format/2202.07870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPD:An Incremental Prototype based DBSCAN for large-scale data with  cluster representatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+J">Jayasree Saha</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+J">Jayanta Mukherjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04551" title="Abstract">arXiv:2203.04551</a> (replaced) [<a href="/pdf/2203.04551" title="Download PDF">pdf</a>, <a href="/format/2203.04551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Multi-Agent Planning for Discovering and Tracking  Multiple Mobile Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+H">Hoa Van Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+B">Ba-Ngu Vo</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+B">Ba-Tuong Vo</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+H">Hamid Rezatofighi</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+D+C">Damith C. Ranasinghe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06768" title="Abstract">arXiv:2203.06768</a> (replaced) [<a href="/pdf/2203.06768" title="Download PDF">pdf</a>, <a href="/format/2203.06768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistically Robust Recourse: Navigating the Trade-offs between  Costs and Robustness in Algorithmic Recourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pawelczyk%2C+M">Martin Pawelczyk</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+T">Teresa Datta</a>, 
<a href="/search/cs?searchtype=author&query=van-den-Heuvel%2C+J">Johannes van-den-Heuvel</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023, camera ready version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 11th International Conference on Learning Representations (ICLR)
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07941" title="Abstract">arXiv:2203.07941</a> (replaced) [<a href="/pdf/2203.07941" title="Download PDF">pdf</a>, <a href="/ps/2203.07941" title="Download PostScript">ps</a>, <a href="/format/2203.07941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reachability In Simple Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A4lzer%2C+M">Marco S&#xe4;lzer</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+M">Martin Lange</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2108.13179">arXiv:2108.13179</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11196" title="Abstract">arXiv:2203.11196</a> (replaced) [<a href="/pdf/2203.11196" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance of Deep Learning models with transfer learning for  multiple-step-ahead forecasts in monthly time series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sol%C3%ADs%2C+M">Mart&#xed;n Sol&#xed;s</a>, 
<a href="/search/cs?searchtype=author&query=Calvo-Valverde%2C+L">Luis-Alexander Calvo-Valverde</a> (Tecnol&#xf3;gico de Costa Rica)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07039" title="Abstract">arXiv:2204.07039</a> (replaced) [<a href="/pdf/2204.07039" title="Download PDF">pdf</a>, <a href="/format/2204.07039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods for Efficient Unfolding of Colored Petri Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bilgram%2C+A">Alexander Bilgram</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+P+G">Peter G. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+T">Thomas Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Srba%2C+J">Jiri Srba</a>, 
<a href="/search/cs?searchtype=author&query=Taankvist%2C+P+H">Peter H. Taankvist</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07994" title="Abstract">arXiv:2204.07994</a> (replaced) [<a href="/pdf/2204.07994" title="Download PDF">pdf</a>, <a href="/format/2204.07994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledgeable Salient Span Mask for Enhancing Language Models as  Knowledge Base
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cunxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fuli Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Runxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NLPCC-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09615" title="Abstract">arXiv:2205.09615</a> (replaced) [<a href="/pdf/2205.09615" title="Download PDF">pdf</a>, <a href="/format/2205.09615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EXACT: How to Train Your Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karpukhin%2C+I">Ivan Karpukhin</a>, 
<a href="/search/cs?searchtype=author&query=Dereka%2C+S">Stanislav Dereka</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14081" title="Abstract">arXiv:2205.14081</a> (replaced) [<a href="/pdf/2205.14081" title="Download PDF">pdf</a>, <a href="/format/2205.14081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Quantum Gravity in the Lab on Quantum Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shapoval%2C+I">Illya Shapoval</a>, 
<a href="/search/quant-ph?searchtype=author&query=Su%2C+V+P">Vincent Paul Su</a>, 
<a href="/search/quant-ph?searchtype=author&query=de+Jong%2C+W">Wibe de Jong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Urbanek%2C+M">Miro Urbanek</a>, 
<a href="/search/quant-ph?searchtype=author&query=Swingle%2C+B">Brian Swingle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures, 2 tables, 1 listing; updated to match journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07255" title="Abstract">arXiv:2206.07255</a> (replaced) [<a href="/pdf/2206.07255" title="Download PDF">pdf</a>, <a href="/format/2206.07255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRAM-HD: 3D-Consistent Image Generation at High Resolution with  Generative Radiance Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jianfeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 camera ready version (more results and method comparisons). Project page: <a href="https://jeffreyxiang.github.io/GRAM-HD/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12781" title="Abstract">arXiv:2206.12781</a> (replaced) [<a href="/pdf/2206.12781" title="Download PDF">pdf</a>, <a href="/format/2206.12781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Leveraging Multi-level User Intent for Session-based  Recommendation via Atten-Mixer Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiayan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaozhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yueqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeboum Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunghun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07068" title="Abstract">arXiv:2207.07068</a> (replaced) [<a href="/pdf/2207.07068" title="Download PDF">pdf</a>, <a href="/format/2207.07068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hort%2C+M">Max Hort</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenpeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>, 
<a href="/search/cs?searchtype=author&query=Sarro%2C+F">Federica Sarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08678" title="Abstract">arXiv:2207.08678</a> (replaced) [<a href="/pdf/2207.08678" title="Download PDF">pdf</a>, <a href="/format/2207.08678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quadratic-order problem kernel for the traveling salesman problem  parameterized by the vertex cover number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Bevern%2C+R">Ren&#xe9; van Bevern</a>, 
<a href="/search/cs?searchtype=author&query=Skachkov%2C+D+A">Daniel A. Skachkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Much shorter alternative proof compared to previous versions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10062" title="Abstract">arXiv:2207.10062</a> (replaced) [<a href="/pdf/2207.10062" title="Download PDF">pdf</a>, <a href="/format/2207.10062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataPerf: Benchmarks for Data-Centric AI Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+M">Mark Mazumder</a>, 
<a href="/search/cs?searchtype=author&query=Banbury%2C+C">Colby Banbury</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiaozhe Yao</a>, 
<a href="/search/cs?searchtype=author&query=Karla%C5%A1%2C+B">Bojan Karla&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+W+G">William Gaviria Rojas</a>, 
<a href="/search/cs?searchtype=author&query=Diamos%2C+S">Sudnya Diamos</a>, 
<a href="/search/cs?searchtype=author&query=Diamos%2C+G">Greg Diamos</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lynn He</a>, 
<a href="/search/cs?searchtype=author&query=Parrish%2C+A">Alicia Parrish</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Quaye%2C+J">Jessica Quaye</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Charvi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Kiela%2C+D">Douwe Kiela</a>, 
<a href="/search/cs?searchtype=author&query=Jurado%2C+D">David Jurado</a>, 
<a href="/search/cs?searchtype=author&query=Kanter%2C+D">David Kanter</a>, 
<a href="/search/cs?searchtype=author&query=Mosquera%2C+R">Rafael Mosquera</a>, 
<a href="/search/cs?searchtype=author&query=Ciro%2C+J">Juan Ciro</a>, 
<a href="/search/cs?searchtype=author&query=Aroyo%2C+L">Lora Aroyo</a>, 
<a href="/search/cs?searchtype=author&query=Acun%2C+B">Bilge Acun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingjiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Raje%2C+M+S">Mehul Smriti Raje</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+M">Max Bartolo</a>, 
<a href="/search/cs?searchtype=author&query=Eyuboglu%2C+S">Sabri Eyuboglu</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbani%2C+A">Amirata Ghorbani</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+E">Emmett Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Inel%2C+O">Oana Inel</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+T">Tariq Kane</a>, 
<a href="/search/cs?searchtype=author&query=Kirkpatrick%2C+C+R">Christine R. Kirkpatrick</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+T">Tzu-Sheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+J">Jonas Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Thrush%2C+T">Tristan Thrush</a>, 
<a href="/search/cs?searchtype=author&query=Vanschoren%2C+J">Joaquin Vanschoren</a>, 
<a href="/search/cs?searchtype=author&query=Warren%2C+M">Margaret Warren</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Serena Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Ardalani%2C+N">Newsha Ardalani</a>, 
<a href="/search/cs?searchtype=author&query=Paritosh%2C+P">Praveen Paritosh</a>, 
<a href="/search/cs?searchtype=author&query=Bath-Leah%2C+L">Lilith Bath-Leah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Carole-Jean Wu</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+C">Cody Coleman</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+A">Andrew Ng</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+P">Peter Mattson</a>, 
<a href="/search/cs?searchtype=author&query=Reddi%2C+V+J">Vijay Janapa Reddi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14367" title="Abstract">arXiv:2207.14367</a> (replaced) [<a href="/pdf/2207.14367" title="Download PDF">pdf</a>, <a href="/format/2207.14367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Equity-Aware Recommender System for Curating Art Exhibits Based on  Locally-Constrained Graph Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haensch%2C+A">Anna Haensch</a>, 
<a href="/search/cs?searchtype=author&query=Deitsch%2C+D">Dina Deitsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06829" title="Abstract">arXiv:2208.06829</a> (replaced) [<a href="/pdf/2208.06829" title="Download PDF">pdf</a>, <a href="/ps/2208.06829" title="Download PostScript">ps</a>, <a href="/format/2208.06829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analogical proportions in monounary algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07935" title="Abstract">arXiv:2208.07935</a> (replaced) [<a href="/pdf/2208.07935" title="Download PDF">pdf</a>, <a href="/format/2208.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstrating Software Reliability using Possibly Correlated Tests:  Insights from a Conservative Bayesian Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salako%2C+K">Kizito Salako</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Quality and Reliability Engineering International
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08628" title="Abstract">arXiv:2208.08628</a> (replaced) [<a href="/pdf/2208.08628" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Legitimacy, Authority, and Democratic Duties of Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazar%2C+S">Seth Lazar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13141" title="Abstract">arXiv:2208.13141</a> (replaced) [<a href="/pdf/2208.13141" title="Download PDF">pdf</a>, <a href="/format/2208.13141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning of Large Models at the Edge via Principal Sub-Model  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yue Niu</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+S">Saurav Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Souvik Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sunwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures. Accepted to Transactions on Machine Learning Research (TMLR) 2023 Code: <a href="https://github.com/yuehniu/modeldecomp-fl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14137" title="Abstract">arXiv:2208.14137</a> (replaced) [<a href="/pdf/2208.14137" title="Download PDF">pdf</a>, <a href="/format/2208.14137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trade-Off between Actionable Explanations and the Right to be  Forgotten
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pawelczyk%2C+M">Martin Pawelczyk</a>, 
<a href="/search/cs?searchtype=author&query=Leemann%2C+T">Tobias Leemann</a>, 
<a href="/search/cs?searchtype=author&query=Biega%2C+A">Asia Biega</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023 camera ready version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 11th International Conference on Learning Representations (ICLR)
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07758" title="Abstract">arXiv:2209.07758</a> (replaced) [<a href="/pdf/2209.07758" title="Download PDF">pdf</a>, <a href="/format/2209.07758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game-theoretic Objective Space Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hongrui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhijun Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Betz%2C+J">Johannes Betz</a>, 
<a href="/search/cs?searchtype=author&query=Mangharam%2C+R">Rahul Mangharam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12487" title="Abstract">arXiv:2209.12487</a> (replaced) [<a href="/pdf/2209.12487" title="Download PDF">pdf</a>, <a href="/format/2209.12487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tartarus: A Benchmarking Platform for Realistic And Practical Inverse  Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigam%2C+A">AkshatKumar Nigam</a>, 
<a href="/search/cs?searchtype=author&query=Pollice%2C+R">Robert Pollice</a>, 
<a href="/search/cs?searchtype=author&query=Tom%2C+G">Gary Tom</a>, 
<a href="/search/cs?searchtype=author&query=Jorner%2C+K">Kjell Jorner</a>, 
<a href="/search/cs?searchtype=author&query=Willes%2C+J">John Willes</a>, 
<a href="/search/cs?searchtype=author&query=Thiede%2C+L+A">Luca A. Thiede</a>, 
<a href="/search/cs?searchtype=author&query=Kundaje%2C+A">Anshul Kundaje</a>, 
<a href="/search/cs?searchtype=author&query=Aspuru-Guzik%2C+A">Alan Aspuru-Guzik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29+21 pages, 6+19 figures, 6+2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01751" title="Abstract">arXiv:2210.01751</a> (replaced) [<a href="/pdf/2210.01751" title="Download PDF">pdf</a>, <a href="/ps/2210.01751" title="Download PostScript">ps</a>, <a href="/format/2210.01751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proportional algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09809" title="Abstract">arXiv:2210.09809</a> (replaced) [<a href="/pdf/2210.09809" title="Download PDF">pdf</a>, <a href="/format/2210.09809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Convolutions, Non-linearity and Depth in Graph Neural  Networks using Neural Tangent Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabanayagam%2C+M">Mahalakshmi Sabanayagam</a>, 
<a href="/search/cs?searchtype=author&query=Esser%2C+P">Pascal Esser</a>, 
<a href="/search/cs?searchtype=author&query=Ghoshdastidar%2C+D">Debarghya Ghoshdastidar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 24 figures. Code available at <a href="https://github.com/mahalakshmi-sabanayagam/NTK_GCN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11442" title="Abstract">arXiv:2210.11442</a> (replaced) [<a href="/pdf/2210.11442" title="Download PDF">pdf</a>, <a href="/format/2210.11442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentative Topology Agents For Open-Ended Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasir%2C+M+U">Muhammad Umair Nasir</a>, 
<a href="/search/cs?searchtype=author&query=Beukman%2C+M">Michael Beukman</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Steven James</a>, 
<a href="/search/cs?searchtype=author&query=Cleghorn%2C+C+W">Christopher Wesley Cleghorn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The Proceedings of Genetic and Evolutionary Computation Conference (GECCO) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13660" title="Abstract">arXiv:2210.13660</a> (replaced) [<a href="/pdf/2210.13660" title="Download PDF">pdf</a>, <a href="/format/2210.13660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpacePhish: The Evasion-space of Adversarial Attacks against Phishing  Website Detectors using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ying Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Apruzzese%2C+G">Giovanni Apruzzese</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16628" title="Abstract">arXiv:2210.16628</a> (replaced) [<a href="/pdf/2210.16628" title="Download PDF">pdf</a>, <a href="/ps/2210.16628" title="Download PostScript">ps</a>, <a href="/format/2210.16628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure preserving schemes for Fokker-Planck equations of irreversible  processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiangxiong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01665" title="Abstract">arXiv:2211.01665</a> (replaced) [<a href="/pdf/2211.01665" title="Download PDF">pdf</a>, <a href="/ps/2211.01665" title="Download PostScript">ps</a>, <a href="/format/2211.01665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best-of-Both-Worlds Multiparty Quantum Computation with Publicly  Verifiable Identifiable Abort
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chung%2C+K">Kai-Min Chung</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+M">Mi-Ying Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tang%2C+E">Er-Cheng Tang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+J">Jiapeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03860" title="Abstract">arXiv:2211.03860</a> (replaced) [<a href="/pdf/2211.03860" title="Download PDF">pdf</a>, <a href="/ps/2211.03860" title="Download PostScript">ps</a>, <a href="/format/2211.03860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Change-Point Detection in Time Series via Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/stat?searchtype=author&query=Fearnhead%2C+P">Paul Fearnhead</a>, 
<a href="/search/stat?searchtype=author&query=Fryzlewicz%2C+P">Piotr Fryzlewicz</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+T">Tengyao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 15 figures and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08501" title="Abstract">arXiv:2211.08501</a> (replaced) [<a href="/pdf/2211.08501" title="Download PDF">pdf</a>, <a href="/ps/2211.08501" title="Download PostScript">ps</a>, <a href="/format/2211.08501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Mechanism Design: Making Maximally Acceptable Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abramowitz%2C+B">Ben Abramowitz</a>, 
<a href="/search/cs?searchtype=author&query=Mattei%2C+N">Nicholas Mattei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11856" title="Abstract">arXiv:2211.11856</a> (replaced) [<a href="/pdf/2211.11856" title="Download PDF">pdf</a>, <a href="/ps/2211.11856" title="Download PostScript">ps</a>, <a href="/format/2211.11856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> String Covering: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mhaskar%2C+N">Neerja Mhaskar</a>, 
<a href="/search/cs?searchtype=author&query=Smyth%2C+W+F">W. F. Smyth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12421" title="Abstract">arXiv:2211.12421</a> (replaced) [<a href="/pdf/2211.12421" title="Download PDF">pdf</a>, <a href="/format/2211.12421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Network Neuroscience: On Data Collection and Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Xu%2C+J">Jiaxing Xu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Y">Yunhan Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Huang%2C+D+T+J">David Tse Jung Huang</a>, 
<a href="/search/q-bio?searchtype=author&query=Gururajapathy%2C+S+S">Sophi Shilpa Gururajapathy</a>, 
<a href="/search/q-bio?searchtype=author&query=Ke%2C+Y">Yiping Ke</a>, 
<a href="/search/q-bio?searchtype=author&query=Qiao%2C+M">Miao Qiao</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+A">Alan Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Kumar%2C+H">Haribalan Kumar</a>, 
<a href="/search/q-bio?searchtype=author&query=McGeown%2C+J">Josh McGeown</a>, 
<a href="/search/q-bio?searchtype=author&query=Kwon%2C+E">Eryn Kwon</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15743" title="Abstract">arXiv:2211.15743</a> (replaced) [<a href="/pdf/2211.15743" title="Download PDF">pdf</a>, <a href="/format/2211.15743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reliable Item Sampling for Recommendation Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ruoming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> aaai2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15751" title="Abstract">arXiv:2211.15751</a> (replaced) [<a href="/pdf/2211.15751" title="Download PDF">pdf</a>, <a href="/format/2211.15751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Video Analytics: A Survey on Applications, Systems and Enabling  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Razavi%2C+S">Saiedeh Razavi</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rong Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Communications Surveys and Tutorials, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09289" title="Abstract">arXiv:2212.09289</a> (replaced) [<a href="/pdf/2212.09289" title="Download PDF">pdf</a>, <a href="/format/2212.09289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining User Privacy Concern Topics from App Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianzhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+J">Jinping Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+N">Nan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12180" title="Abstract">arXiv:2212.12180</a> (replaced) [<a href="/pdf/2212.12180" title="Download PDF">pdf</a>, <a href="/format/2212.12180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autothrottle: A Practical Bi-Level Approach to Resource Management for  SLO-Targeted Microservices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pinghe Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C+M">Chieh-Jan Mike Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+F+Y">Francis Y. Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by USENIX NSDI '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01696" title="Abstract">arXiv:2301.01696</a> (replaced) [<a href="/pdf/2301.01696" title="Download PDF">pdf</a>, <a href="/format/2301.01696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterised and Fine-grained Subgraph Counting, modulo $2$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+L+A">Leslie Ann Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+M">Marc Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03857" title="Abstract">arXiv:2301.03857</a> (replaced) [<a href="/pdf/2301.03857" title="Download PDF">pdf</a>, <a href="/ps/2301.03857" title="Download PostScript">ps</a>, <a href="/format/2301.03857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communication Signals Towards 5G-A and 6G: A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Hanyang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Ying Du</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kaifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures, 8 tables. IEEE Internet of Things Journal, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04043" title="Abstract">arXiv:2301.04043</a> (replaced) [<a href="/pdf/2301.04043" title="Download PDF">pdf</a>, <a href="/format/2301.04043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Analysis of Coarse-Grained Guidance for Traffic Flow  Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+R">Roy Dong</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05174" title="Abstract">arXiv:2301.05174</a> (replaced) [<a href="/pdf/2301.05174" title="Download PDF">pdf</a>, <a href="/format/2301.05174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene-centric vs. Object-centric Image-Text Cross-modal Retrieval: A  Reproducibility Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hendriksen%2C+M">Mariya Hendriksen</a>, 
<a href="/search/cs?searchtype=author&query=Vakulenko%2C+S">Svitlana Vakulenko</a>, 
<a href="/search/cs?searchtype=author&query=Kuiper%2C+E">Ernst Kuiper</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, accepted as a reproducibility paper at ECIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06577" title="Abstract">arXiv:2301.06577</a> (replaced) [<a href="/pdf/2301.06577" title="Download PDF">pdf</a>, <a href="/format/2301.06577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Very Little Data: On the Value of Landscape Analysis for  Predicting Software Project Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lustosa%2C+A">Andre Lustosa</a>, 
<a href="/search/cs?searchtype=author&query=Menzies%2C+T">Tim Menzies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07807" title="Abstract">arXiv:2301.07807</a> (replaced) [<a href="/pdf/2301.07807" title="Download PDF">pdf</a>, <a href="/format/2301.07807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring uncertainty in human visual segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vacher%2C+J">Jonathan Vacher</a>, 
<a href="/search/cs?searchtype=author&query=Launay%2C+C">Claire Launay</a>, 
<a href="/search/cs?searchtype=author&query=Mamassian%2C+P">Pascal Mamassian</a>, 
<a href="/search/cs?searchtype=author&query=Coen-Cagli%2C+R">Ruben Coen-Cagli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 9 figures, 5 appendix, 5 figures in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09966" title="Abstract">arXiv:2301.09966</a> (replaced) [<a href="/pdf/2301.09966" title="Download PDF">pdf</a>, <a href="/ps/2301.09966" title="Download PostScript">ps</a>, <a href="/format/2301.09966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word-Mappings of level $3$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A9nizergues%2C+G">G. S&#xe9;nizergues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages. 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11986" title="Abstract">arXiv:2301.11986</a> (replaced) [<a href="/pdf/2301.11986" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Face Recognition with Latent Space Data Augmentation and  Facial Posture Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemifar%2C+S">Soroush Hashemifar</a>, 
<a href="/search/cs?searchtype=author&query=Marefat%2C+A">Abdolreza Marefat</a>, 
<a href="/search/cs?searchtype=author&query=Joloudari%2C+J+H">Javad Hassannataj Joloudari</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+H">Hamid Hassanpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12920" title="Abstract">arXiv:2301.12920</a> (replaced) [<a href="/pdf/2301.12920" title="Download PDF">pdf</a>, <a href="/format/2301.12920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning for Multilingual Semantic Parser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EACL 2023 (findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02893" title="Abstract">arXiv:2302.02893</a> (replaced) [<a href="/pdf/2302.02893" title="Download PDF">pdf</a>, <a href="/format/2302.02893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A posteriori error estimation for parabolic problems with dynamic  boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altmann%2C+R">Robert Altmann</a>, 
<a href="/search/math?searchtype=author&query=Zimmer%2C+C">Christoph Zimmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10096" title="Abstract">arXiv:2302.10096</a> (replaced) [<a href="/pdf/2302.10096" title="Download PDF">pdf</a>, <a href="/ps/2302.10096" title="Download PostScript">ps</a>, <a href="/format/2302.10096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization-based similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11002" title="Abstract">arXiv:2302.11002</a> (replaced) [<a href="/pdf/2302.11002" title="Download PDF">pdf</a>, <a href="/format/2302.11002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Physical Models that Can Respect Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hansen%2C+D">Derek Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Maddix%2C+D+C">Danielle C. Maddix</a>, 
<a href="/search/cs?searchtype=author&query=Alizadeh%2C+S">Shima Alizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gaurav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023, Physica D: Nonlinear Phenomena, Accepted
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning (ICML 2023), PMLR 202:12469-12510
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11509" title="Abstract">arXiv:2302.11509</a> (replaced) [<a href="/pdf/2302.11509" title="Download PDF">pdf</a>, <a href="/format/2302.11509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of Knowledge Graphs: State and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hofer%2C+M">Marvin Hofer</a>, 
<a href="/search/cs?searchtype=author&query=Obraczka%2C+D">Daniel Obraczka</a>, 
<a href="/search/cs?searchtype=author&query=Saeedi%2C+A">Alieh Saeedi</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6pcke%2C+H">Hanna K&#xf6;pcke</a>, 
<a href="/search/cs?searchtype=author&query=Rahm%2C+E">Erhard Rahm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 5 figures, 4 tables, 328 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04707" title="Abstract">arXiv:2303.04707</a> (replaced) [<a href="/pdf/2303.04707" title="Download PDF">pdf</a>, <a href="/format/2303.04707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiM: Distilling Dataset into Generative Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jianyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daquan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Distilling datasets into generative models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05078" title="Abstract">arXiv:2303.05078</a> (replaced) [<a href="/pdf/2303.05078" title="Download PDF">pdf</a>, <a href="/format/2303.05078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Transformer-based 3D Object Detection with Dynamic Token  Halting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+G+P">Gregory P. Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yuning Chai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05674" title="Abstract">arXiv:2303.05674</a> (replaced) [<a href="/pdf/2303.05674" title="Download PDF">pdf</a>, <a href="/format/2303.05674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Applications of Pre-Trained Vision-Language Models to Various  Recognition Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Obinata%2C+Y">Yoshiki Obinata</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+N">Naoaki Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Humanoids2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07678" title="Abstract">arXiv:2303.07678</a> (replaced) [<a href="/pdf/2303.07678" title="Download PDF">pdf</a>, <a href="/format/2303.07678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query2doc: Query Expansion with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08268" title="Abstract">arXiv:2303.08268</a> (replaced) [<a href="/pdf/2303.08268" title="Download PDF">pdf</a>, <a href="/format/2303.08268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chat with the Environment: Interactive Multimodal Perception Using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xufeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengdi Li</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Hafez%2C+M+B">Muhammad Burhan Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS2023, Detroit. See the project website at <a href="https://matcha-agent.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08518" title="Abstract">arXiv:2303.08518</a> (replaced) [<a href="/pdf/2303.08518" title="Download PDF">pdf</a>, <a href="/format/2303.08518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Daixuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+J">Junyu Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yuefeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Denvy Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08896" title="Abstract">arXiv:2303.08896</a> (replaced) [<a href="/pdf/2303.08896" title="Download PDF">pdf</a>, <a href="/format/2303.08896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manakul%2C+P">Potsawee Manakul</a>, 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M+J+F">Mark J. F. Gales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (main conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09535" title="Abstract">arXiv:2303.09535</a> (replaced) [<a href="/pdf/2303.09535" title="Download PDF">pdf</a>, <a href="/format/2303.09535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FateZero: Fusing Attentions for Zero-shot Text-based Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chenyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chenyang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 as an Oral Presentation. Project page: <a href="https://fate-zero-edit.github.io">this https URL</a> ; GitHub repository: <a href="https://github.com/ChenyangQiQi/FateZero">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09902" title="Abstract">arXiv:2303.09902</a> (replaced) [<a href="/pdf/2303.09902" title="Download PDF">pdf</a>, <a href="/format/2303.09902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Self-supervised Learning in Recommender Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">Mengyuan Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yanmin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+T">Tianzi Zang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transactions on Information Systems (TOIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13093" title="Abstract">arXiv:2303.13093</a> (replaced) [<a href="/pdf/2303.13093" title="Download PDF">pdf</a>, <a href="/format/2303.13093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Probabilistic Stability of Stochastic Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziyin%2C+L">Liu Ziyin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Botao Li</a>, 
<a href="/search/cs?searchtype=author&query=Galanti%2C+T">Tomer Galanti</a>, 
<a href="/search/cs?searchtype=author&query=Ueda%2C+M">Masahito Ueda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> page layout fix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16254" title="Abstract">arXiv:2303.16254</a> (replaced) [<a href="/pdf/2303.16254" title="Download PDF">pdf</a>, <a href="/format/2303.16254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using  Transformer-based Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinhang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiakai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16570" title="Abstract">arXiv:2303.16570</a> (replaced) [<a href="/pdf/2303.16570" title="Download PDF">pdf</a>, <a href="/format/2303.16570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point2Vec for Self-Supervised Representation Learning on Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeid%2C+K+A">Karim Abou Zeid</a>, 
<a href="/search/cs?searchtype=author&query=Schult%2C+J">Jonas Schult</a>, 
<a href="/search/cs?searchtype=author&query=Hermans%2C+A">Alexander Hermans</a>, 
<a href="/search/cs?searchtype=author&query=Leibe%2C+B">Bastian Leibe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at GCPR 2023. Project page at <a href="https://vision.rwth-aachen.de/point2vec">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17063" title="Abstract">arXiv:2303.17063</a> (replaced) [<a href="/pdf/2303.17063" title="Download PDF">pdf</a>, <a href="/format/2303.17063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Colosseum as a Digital Twin: Bridging Real-World Experimentation and  Wireless Network Emulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villa%2C+D">Davide Villa</a>, 
<a href="/search/cs?searchtype=author&query=Tehrani-Moayyed%2C+M">Miead Tehrani-Moayyed</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+C+P">Clifton Paul Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Johari%2C+P">Pedram Johari</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Basagni%2C+S">Stefano Basagni</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 23 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17546" title="Abstract">arXiv:2303.17546</a> (replaced) [<a href="/pdf/2303.17546" title="Download PDF">pdf</a>, <a href="/format/2303.17546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAIR-Diffusion: A Comprehensive Multimodal Object-Level Image Editor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+V">Vidit Goel</a>, 
<a href="/search/cs?searchtype=author&query=Peruzzo%2C+E">Elia Peruzzo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingqian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages and 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00472" title="Abstract">arXiv:2304.00472</a> (replaced) [<a href="/pdf/2304.00472" title="Download PDF">pdf</a>, <a href="/format/2304.00472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Querying Large Language Models with SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saeed%2C+M">Mohammed Saeed</a>, 
<a href="/search/cs?searchtype=author&query=De+Cao%2C+N">Nicola De Cao</a>, 
<a href="/search/cs?searchtype=author&query=Papotti%2C+P">Paolo Papotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at EDBT 2024 as Vision paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01950" title="Abstract">arXiv:2304.01950</a> (replaced) [<a href="/pdf/2304.01950" title="Download PDF">pdf</a>, <a href="/format/2304.01950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP-FedCL: Multiprototype Federated Contrastive Learning for Edge  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Munir%2C+M+S">Md. Shirajum Munir</a>, 
<a href="/search/cs?searchtype=author&query=Adhikary%2C+A">Apurba Adhikary</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H+Q">Huy Q. Le</a>, 
<a href="/search/cs?searchtype=author&query=Raha%2C+A+D">Avi Deb Raha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Internet of Things
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03108" title="Abstract">arXiv:2304.03108</a> (replaced) [<a href="/pdf/2304.03108" title="Download PDF">pdf</a>, <a href="/format/2304.03108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FABRID: Flexible Attestation-Based Routing for Inter-Domain Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4henb%C3%BChl%2C+C">Cyrill Kr&#xe4;henb&#xfc;hl</a> (ETH Z&#xfc;rich), 
<a href="/search/cs?searchtype=author&query=Wyss%2C+M">Marc Wyss</a> (ETH Z&#xfc;rich), 
<a href="/search/cs?searchtype=author&query=Basin%2C+D">David Basin</a> (ETH Z&#xfc;rich), 
<a href="/search/cs?searchtype=author&query=Lenders%2C+V">Vincent Lenders</a> (armasuisse), 
<a href="/search/cs?searchtype=author&query=Perrig%2C+A">Adrian Perrig</a> (ETH Z&#xfc;rich), 
<a href="/search/cs?searchtype=author&query=Strohmeier%2C+M">Martin Strohmeier</a> (armasuisse)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03347" title="Abstract">arXiv:2304.03347</a> (replaced) [<a href="/pdf/2304.03347" title="Download PDF">pdf</a>, <a href="/format/2304.03347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Mental Health Analysis with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shaoxiong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Ziyan Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Ananiadou%2C+S">Sophia Ananiadou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 main conference as a long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03864" title="Abstract">arXiv:2304.03864</a> (replaced) [<a href="/pdf/2304.03864" title="Download PDF">pdf</a>, <a href="/format/2304.03864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGDP: A Stream-Graph Neural Network Based Data Prefetcher
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongshang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qiquan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Gang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingxuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Joint Conference on Neural Networks (IJCNN 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06325" title="Abstract">arXiv:2304.06325</a> (replaced) [<a href="/pdf/2304.06325" title="Download PDF">pdf</a>, <a href="/ps/2304.06325" title="Download PostScript">ps</a>, <a href="/format/2304.06325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Sign Quantum Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Barhoush%2C+M">Mohammed Barhoush</a>, 
<a href="/search/quant-ph?searchtype=author&query=Salvail%2C+L">Louis Salvail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06548" title="Abstract">arXiv:2304.06548</a> (replaced) [<a href="/pdf/2304.06548" title="Download PDF">pdf</a>, <a href="/format/2304.06548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-kernel Correntropy-based Orientation Estimation of IMUs: Gradient  Descent Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shilei Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lijing Li</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+D">Dawei Shi</a>, 
<a href="/search/eess?searchtype=author&query=Lou%2C+Y">Yunjiang Lou</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06558" title="Abstract">arXiv:2304.06558</a> (replaced) [<a href="/pdf/2304.06558" title="Download PDF">pdf</a>, <a href="/format/2304.06558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-kernel Correntropy Regression: Robustness, Optimality, and  Application on Magnetometer Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shilei Li</a>, 
<a href="/search/eess?searchtype=author&query=Lou%2C+Y">Yunjiang Lou</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+D">Dawei Shi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lijing Li</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06841" title="Abstract">arXiv:2304.06841</a> (replaced) [<a href="/pdf/2304.06841" title="Download PDF">pdf</a>, <a href="/format/2304.06841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video alignment using unsupervised learning of local and global features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fakhfour%2C+N">Niloufar Fakhfour</a>, 
<a href="/search/cs?searchtype=author&query=ShahverdiKondori%2C+M">Mohammad ShahverdiKondori</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadzade%2C+H">Hoda Mohammadzade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06855" title="Abstract">arXiv:2304.06855</a> (replaced) [<a href="/pdf/2304.06855" title="Download PDF">pdf</a>, <a href="/format/2304.06855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A static memory sparse spectral method for time-fractional PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gutleb%2C+T+S">Timon S. Gutleb</a>, 
<a href="/search/math?searchtype=author&query=Carrillo%2C+J+A">Jos&#xe9; A. Carrillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06925" title="Abstract">arXiv:2304.06925</a> (replaced) [<a href="/e-print/2304.06925" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLO-Drone:Airborne real-time detection of dense small objects from  high-altitude perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Li Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jiahui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+F">Feng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanzheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengnan Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some contributing authors are not signed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08718" title="Abstract">arXiv:2304.08718</a> (replaced) [<a href="/pdf/2304.08718" title="Download PDF">pdf</a>, <a href="/format/2304.08718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Implicit Factorization Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yansong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Nitaj%2C+A">Abderrahmane Nitaj</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yanbin Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11082" title="Abstract">arXiv:2304.11082</a> (replaced) [<a href="/pdf/2304.11082" title="Download PDF">pdf</a>, <a href="/format/2304.11082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental Limitations of Alignment in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+Y">Yotam Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Wies%2C+N">Noam Wies</a>, 
<a href="/search/cs?searchtype=author&query=Avnery%2C+O">Oshri Avnery</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+Y">Yoav Levine</a>, 
<a href="/search/cs?searchtype=author&query=Shashua%2C+A">Amnon Shashua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11161" title="Abstract">arXiv:2304.11161</a> (replaced) [<a href="/pdf/2304.11161" title="Download PDF">pdf</a>, <a href="/format/2304.11161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> altiro3D: Scene representation from single image and novel view  synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canessa%2C+E">E. Canessa</a>, 
<a href="/search/cs?searchtype=author&query=Tenze%2C+L">L. Tenze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In press (2023) Springer International Journal of Information Technology (IJIT) 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14767" title="Abstract">arXiv:2304.14767</a> (replaced) [<a href="/pdf/2304.14767" title="Download PDF">pdf</a>, <a href="/format/2304.14767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting Recall of Factual Associations in Auto-Regressive Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>, 
<a href="/search/cs?searchtype=author&query=Bastings%2C+J">Jasmijn Bastings</a>, 
<a href="/search/cs?searchtype=author&query=Filippova%2C+K">Katja Filippova</a>, 
<a href="/search/cs?searchtype=author&query=Globerson%2C+A">Amir Globerson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14933" title="Abstract">arXiv:2304.14933</a> (replaced) [<a href="/pdf/2304.14933" title="Download PDF">pdf</a>, <a href="/format/2304.14933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Multimodal Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sung%2C+Y">Yi-Lin Sung</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhe Gan</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00472" title="Abstract">arXiv:2305.00472</a> (replaced) [<a href="/pdf/2305.00472" title="Download PDF">pdf</a>, <a href="/format/2305.00472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient MILP Decomposition in Quantum Computing for ReLU Network  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Franco%2C+N">Nicola Franco</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wollschl%C3%A4ger%2C+T">Tom Wollschl&#xe4;ger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Poggel%2C+B">Benedikt Poggel</a>, 
<a href="/search/quant-ph?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lorenz%2C+J+M">Jeanette Miriam Lorenz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03989" title="Abstract">arXiv:2305.03989</a> (replaced) [<a href="/pdf/2305.03989" title="Download PDF">pdf</a>, <a href="/format/2305.03989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEO: Generative Latent Image Animator for Human Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dantcheva%2C+A">Antitza Dantcheva</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://wyhsirius.github.io/LEO-project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04080" title="Abstract">arXiv:2305.04080</a> (replaced) [<a href="/pdf/2305.04080" title="Download PDF">pdf</a>, <a href="/format/2305.04080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Tensor CUR Decompositions: Rapid Low-Tucker-Rank Tensor Recovery  with Sparse Corruption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cai%2C+H">HanQin Cai</a>, 
<a href="/search/math?searchtype=author&query=Chao%2C+Z">Zehan Chao</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+L">Longxiu Huang</a>, 
<a href="/search/math?searchtype=author&query=Needell%2C+D">Deanna Needell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05658" title="Abstract">arXiv:2305.05658</a> (replaced) [<a href="/pdf/2305.05658" title="Download PDF">pdf</a>, <a href="/format/2305.05658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TidyBot: Personalized Robot Assistance with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jimmy Wu</a>, 
<a href="/search/cs?searchtype=author&query=Antonova%2C+R">Rika Antonova</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+A">Adam Kan</a>, 
<a href="/search/cs?searchtype=author&query=Lepert%2C+M">Marion Lepert</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>, 
<a href="/search/cs?searchtype=author&query=Bohg%2C+J">Jeannette Bohg</a>, 
<a href="/search/cs?searchtype=author&query=Rusinkiewicz%2C+S">Szymon Rusinkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Funkhouser%2C+T">Thomas Funkhouser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Autonomous Robots (AuRo) - Special Issue: Large Language Models in Robotics, 2023 and IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023. Project page: <a href="https://tidybot.cs.princeton.edu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05862" title="Abstract">arXiv:2305.05862</a> (replaced) [<a href="/pdf/2305.05862" title="Download PDF">pdf</a>, <a href="/format/2305.05862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text  Analytics? A Study on Several Typical Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Samuel Chan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaodan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yulong Pei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiqiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaomo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sameena Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add more experiments, accepted to EMNLP 2023 Industry track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08703" title="Abstract">arXiv:2305.08703</a> (replaced) [<a href="/pdf/2305.08703" title="Download PDF">pdf</a>, <a href="/format/2305.08703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Schema-adaptable Knowledge Graph Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hongbin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+H">Honghao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08732" title="Abstract">arXiv:2305.08732</a> (replaced) [<a href="/pdf/2305.08732" title="Download PDF">pdf</a>, <a href="/format/2305.08732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Rumination for Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shengyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuanqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09900" title="Abstract">arXiv:2305.09900</a> (replaced) [<a href="/pdf/2305.09900" title="Download PDF">pdf</a>, <a href="/format/2305.09900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Equivariant Transfer Learning from Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basu%2C+S">Sourya Basu</a>, 
<a href="/search/cs?searchtype=author&query=Katdare%2C+P">Pulkit Katdare</a>, 
<a href="/search/cs?searchtype=author&query=Sattigeri%2C+P">Prasanna Sattigeri</a>, 
<a href="/search/cs?searchtype=author&query=Chenthamarakshan%2C+V">Vijil Chenthamarakshan</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P">Payel Das</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11141" title="Abstract">arXiv:2305.11141</a> (replaced) [<a href="/pdf/2305.11141" title="Download PDF">pdf</a>, <a href="/format/2305.11141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clifford Group Equivariant Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruhe%2C+D">David Ruhe</a>, 
<a href="/search/cs?searchtype=author&query=Brandstetter%2C+J">Johannes Brandstetter</a>, 
<a href="/search/cs?searchtype=author&query=Forr%C3%A9%2C+P">Patrick Forr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12534" title="Abstract">arXiv:2305.12534</a> (replaced) [<a href="/pdf/2305.12534" title="Download PDF">pdf</a>, <a href="/format/2305.12534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BertRLFuzzer: A BERT and Reinforcement Learning based Fuzzer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Piyush Jha</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+J">Joseph Scott</a>, 
<a href="/search/cs?searchtype=author&query=Ganeshna%2C+J+S">Jaya Sriram Ganeshna</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mudit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+V">Vijay Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13172" title="Abstract">arXiv:2305.13172</a> (replaced) [<a href="/pdf/2305.13172" title="Download PDF">pdf</a>, <a href="/format/2305.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing Large Language Models: Problems, Methods, and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yunzhi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoubo Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023. Updated with new experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13311" title="Abstract">arXiv:2305.13311</a> (replaced) [<a href="/pdf/2305.13311" title="Download PDF">pdf</a>, <a href="/format/2305.13311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VDT: General-purpose Video Diffusion Transformers via Mask Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haoyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guoxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+N">Nanyi Fei</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuqi Huo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiwu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13847" title="Abstract">arXiv:2305.13847</a> (replaced) [<a href="/pdf/2305.13847" title="Download PDF">pdf</a>, <a href="/format/2305.13847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discontinuous Galerkin approach for atmospheric flows with implicit  condensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Doppler%2C+S">Sabine Doppler</a>, 
<a href="/search/math?searchtype=author&query=Lederer%2C+P+L">Philip L. Lederer</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6berl%2C+J">Joachim Sch&#xf6;berl</a>, 
<a href="/search/math?searchtype=author&query=von+Wahl%2C+H">Henry von Wahl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14251" title="Abstract">arXiv:2305.14251</a> (replaced) [<a href="/pdf/2305.14251" title="Download PDF">pdf</a>, <a href="/format/2305.14251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long  Form Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Sewon Min</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K">Kalpesh Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinxi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Yih%2C+W">Wen-tau Yih</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+P+W">Pang Wei Koh</a>, 
<a href="/search/cs?searchtype=author&query=Iyyer%2C+M">Mohit Iyyer</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages; 7 figures. Published as a main conference paper at EMNLP 2023. Code available at <a href="https://github.com/shmsw25/FActScore">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14718" title="Abstract">arXiv:2305.14718</a> (replaced) [<a href="/pdf/2305.14718" title="Download PDF">pdf</a>, <a href="/format/2305.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Language Models with Advantage-based Offline Policy Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baheti%2C+A">Ashutosh Baheti</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Bras%2C+R+L">Ronan Le Bras</a>, 
<a href="/search/cs?searchtype=author&query=Sap%2C+M">Maarten Sap</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M">Mark Riedl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14761" title="Abstract">arXiv:2305.14761</a> (replaced) [<a href="/pdf/2305.14761" title="Download PDF">pdf</a>, <a href="/format/2305.14761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniChart: A Universal Vision-language Pretrained Model for Chart  Comprehension and Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masry%2C+A">Ahmed Masry</a>, 
<a href="/search/cs?searchtype=author&query=Kavehzadeh%2C+P">Parsa Kavehzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+E">Enamul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15074" title="Abstract">arXiv:2305.15074</a> (replaced) [<a href="/pdf/2305.15074" title="Download PDF">pdf</a>, <a href="/format/2305.15074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+D">Daman Arora</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H+G">Himanshu Gaurav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mausam">Mausam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16340" title="Abstract">arXiv:2305.16340</a> (replaced) [<a href="/pdf/2305.16340" title="Download PDF">pdf</a>, <a href="/format/2305.16340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yinghan Long</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+S">Sayeed Shafayet Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16612" title="Abstract">arXiv:2305.16612</a> (replaced) [<a href="/e-print/2305.16612" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Transformer-Based Reinforcement Learning for Robot Crowd  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haodong He</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The duplication rate is too high and the manuscript needs to be withdrawn
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17139" title="Abstract">arXiv:2305.17139</a> (replaced) [<a href="/pdf/2305.17139" title="Download PDF">pdf</a>, <a href="/format/2305.17139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Measure-Theoretic Axiomatisation of Causality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junhyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Buchholz%2C+S">Simon Buchholz</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Muandet%2C+K">Krikamol Muandet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17382" title="Abstract">arXiv:2305.17382</a> (replaced) [<a href="/pdf/2305.17382" title="Download PDF">pdf</a>, <a href="/format/2305.17382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APRIL-GAN: A Zero-/Few-Shot Anomaly Classification and Segmentation  Method for CVPR 2023 VAND Workshop Challenge Tracks 1&amp;2: 1st Place on  Zero-shot AD and 4th Place on Few-shot AD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yue Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17924" title="Abstract">arXiv:2305.17924</a> (replaced) [<a href="/pdf/2305.17924" title="Download PDF">pdf</a>, <a href="/format/2305.17924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rhe Second Order Asymptotics of Covert Communication over AWGN Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinchun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuangqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shao-Lun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00816" title="Abstract">arXiv:2306.00816</a> (replaced) [<a href="/pdf/2306.00816" title="Download PDF">pdf</a>, <a href="/format/2306.00816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Backdoor Attack with Visible, Semantic, Sample-Specific, and  Compatible Triggers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruotong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yanbo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01194" title="Abstract">arXiv:2306.01194</a> (replaced) [<a href="/pdf/2306.01194" title="Download PDF">pdf</a>, <a href="/format/2306.01194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating WebRTC Video QoE Metrics Without Using Application Headers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Taveesh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mangla%2C+T">Tarun Mangla</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junchen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Feamster%2C+N">Nick Feamster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01276" title="Abstract">arXiv:2306.01276</a> (replaced) [<a href="/pdf/2306.01276" title="Download PDF">pdf</a>, <a href="/format/2306.01276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Sample Efficiency in Black-box Combinatorial Optimization via  Symmetric Replay Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungsoo Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages (including 6 pages of the appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01984" title="Abstract">arXiv:2306.01984</a> (replaced) [<a href="/pdf/2306.01984" title="Download PDF">pdf</a>, <a href="/format/2306.01984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cachay%2C+S+R">Salva R&#xfc;hling Cachay</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Joren%2C+H">Hailey Joren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023; Code is available at: <a href="https://github.com/Rose-STL-Lab/dyffusion">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems (NeurIPS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03329" title="Abstract">arXiv:2306.03329</a> (replaced) [<a href="/pdf/2306.03329" title="Download PDF">pdf</a>, <a href="/format/2306.03329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVIDa-hIL6: A Large-Scale VHH Dataset Produced from an Immunized Alpaca  for Predicting Antigen-Antibody Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsuruta%2C+H">Hirofumi Tsuruta</a>, 
<a href="/search/cs?searchtype=author&query=Yamazaki%2C+H">Hiroyuki Yamazaki</a>, 
<a href="/search/cs?searchtype=author&query=Maeda%2C+R">Ryota Maeda</a>, 
<a href="/search/cs?searchtype=author&query=Tamura%2C+R">Ryotaro Tamura</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J+N">Jennifer N. Wei</a>, 
<a href="/search/cs?searchtype=author&query=Mariet%2C+Z">Zelda Mariet</a>, 
<a href="/search/cs?searchtype=author&query=Phloyphisut%2C+P">Poomarin Phloyphisut</a>, 
<a href="/search/cs?searchtype=author&query=Shimokawa%2C+H">Hidetoshi Shimokawa</a>, 
<a href="/search/cs?searchtype=author&query=Ledsam%2C+J+R">Joseph R. Ledsam</a>, 
<a href="/search/cs?searchtype=author&query=Colwell%2C+L">Lucy Colwell</a>, 
<a href="/search/cs?searchtype=author&query=Imura%2C+A">Akihiro Imura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04865" title="Abstract">arXiv:2306.04865</a> (replaced) [<a href="/pdf/2306.04865" title="Download PDF">pdf</a>, <a href="/format/2306.04865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MyStyle++: A Controllable Personalized Generative Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Libing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lele Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kalantari%2C+N">Nima Kalantari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05768" title="Abstract">arXiv:2306.05768</a> (replaced) [<a href="/pdf/2306.05768" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Range Anxiety Among Battery Electric Vehicle Users: Both Distance and  Waiting Time Matter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chunxi Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dengbo He</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+R">Ran Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Human Factors and Ergonomics Society International Annual Meeting 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09442" title="Abstract">arXiv:2306.09442</a> (replaced) [<a href="/pdf/2306.09442" title="Download PDF">pdf</a>, <a href="/format/2306.09442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore, Establish, Exploit: Red Teaming Language Models from Scratch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casper%2C+S">Stephen Casper</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jason Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+J">Joe Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Culp%2C+G">Gatlen Culp</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10347" title="Abstract">arXiv:2306.10347</a> (replaced) [<a href="/pdf/2306.10347" title="Download PDF">pdf</a>, <a href="/format/2306.10347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCdetector: Dual Attention Contrastive Representation Learning for Time  Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12424" title="Abstract">arXiv:2306.12424</a> (replaced) [<a href="/pdf/2306.12424" title="Download PDF">pdf</a>, <a href="/format/2306.12424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisoGender: A dataset for benchmarking gender bias in image-text pronoun  resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hall%2C+S+M">Siobhan Mackenzie Hall</a>, 
<a href="/search/cs?searchtype=author&query=Abrantes%2C+F+G">Fernanda Gon&#xe7;alves Abrantes</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanwen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sodunke%2C+G">Grace Sodunke</a>, 
<a href="/search/cs?searchtype=author&query=Shtedritski%2C+A">Aleksandar Shtedritski</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Data and code available at <a href="https://github.com/oxai/visogender">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12511" title="Abstract">arXiv:2306.12511</a> (replaced) [<a href="/pdf/2306.12511" title="Download PDF">pdf</a>, <a href="/format/2306.12511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Implicit Denoising Diffusion Models (SIDDMs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Mingming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaoan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Grundmann%2C+M">Matthias Grundmann</a>, 
<a href="/search/cs?searchtype=author&query=Batmanghelich%2C+K">Kayhan Batmanghelich</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingbo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12898" title="Abstract">arXiv:2306.12898</a> (replaced) [<a href="/pdf/2306.12898" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-Learning-Assisted and Real-Time-Feedback-Controlled Growth of  InAs/GaAs Quantum Dots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Shen%2C+C">Chao Shen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhan%2C+W">Wenkang Zhan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xin%2C+K">Kaiyao Xin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+M">Manyang Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+Z">Zhenyu Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cong%2C+H">Hui Cong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+C">Chi Xu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wu%2C+Z">Zhaofeng Wu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wei%2C+Z">Zhongming Wei</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xue%2C+C">Chunlai Xue</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhao%2C+C">Chao Zhao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+Z">Zhanguo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13047" title="Abstract">arXiv:2306.13047</a> (replaced) [<a href="/pdf/2306.13047" title="Download PDF">pdf</a>, <a href="/format/2306.13047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the Cambridge Multiple-Choice Questions Reading Dataset with  a Focus on Candidate Response Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vatsal Raina</a>, 
<a href="/search/cs?searchtype=author&query=Mullooly%2C+A">Andrew Mullooly</a>, 
<a href="/search/cs?searchtype=author&query=Knill%2C+K">Kate Knill</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M+J+F">Mark J. F. Gales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13505" title="Abstract">arXiv:2306.13505</a> (replaced) [<a href="/pdf/2306.13505" title="Download PDF">pdf</a>, <a href="/format/2306.13505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Reality Sickness Reduces Attention During Immersive Experiences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mimnaugh%2C+K+J">Katherine J. Mimnaugh</a>, 
<a href="/search/cs?searchtype=author&query=Center%2C+E+G">Evan G. Center</a>, 
<a href="/search/cs?searchtype=author&query=Suomalainen%2C+M">Markku Suomalainen</a>, 
<a href="/search/cs?searchtype=author&query=Becerra%2C+I">Israel Becerra</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+E">Eliezer Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Murrieta-Cid%2C+R">Rafael Murrieta-Cid</a>, 
<a href="/search/cs?searchtype=author&query=Ojala%2C+T">Timo Ojala</a>, 
<a href="/search/cs?searchtype=author&query=LaValle%2C+S+M">Steven M. LaValle</a>, 
<a href="/search/cs?searchtype=author&query=Federmeier%2C+K+D">Kara D. Federmeier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13720" title="Abstract">arXiv:2306.13720</a> (replaced) [<a href="/pdf/2306.13720" title="Download PDF">pdf</a>, <a href="/format/2306.13720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupled Diffusion Models: Image to Zero and Zero to Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15142" title="Abstract">arXiv:2306.15142</a> (replaced) [<a href="/pdf/2306.15142" title="Download PDF">pdf</a>, <a href="/format/2306.15142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRANet: Towards Accurate and Efficient Scene Text Detection with  Low-Rank Approximation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuchen Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhineng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhiwen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuning Du</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15681" title="Abstract">arXiv:2306.15681</a> (replaced) [<a href="/pdf/2306.15681" title="Download PDF">pdf</a>, <a href="/format/2306.15681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECG-QA: A Comprehensive Question Answering Dataset Combined With  Electrocardiogram
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Oh%2C+J">Jungwoo Oh</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+G">Gyubok Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Bae%2C+S">Seongsu Bae</a>, 
<a href="/search/q-bio?searchtype=author&query=Kwon%2C+J">Joon-myoung Kwon</a>, 
<a href="/search/q-bio?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Datasets and Benchmarks Track (10 pages for main text, 2 pages for references, 28 pages for supplementary materials)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00040" title="Abstract">arXiv:2307.00040</a> (replaced) [<a href="/pdf/2307.00040" title="Download PDF">pdf</a>, <a href="/format/2307.00040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DisCo: Disentangled Control for Realistic Human Dance Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuanhao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chung-Ching Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://disco-dance.github.io/">this https URL</a> ; Add temporal module ; Synchronize FVD computation with MCVD ; More baselines and visualizations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00773" title="Abstract">arXiv:2307.00773</a> (replaced) [<a href="/pdf/2307.00773" title="Download PDF">pdf</a>, <a href="/format/2307.00773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DifFSS: Diffusion Model for Few-Shot Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code is available at <a href="https://github.com/TrinitialChan/DifFSS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02484" title="Abstract">arXiv:2307.02484</a> (replaced) [<a href="/pdf/2307.02484" title="Download PDF">pdf</a>, <a href="/format/2307.02484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elastic Decision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yueh-Hua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hamaya%2C+M">Masashi Hamaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02688" title="Abstract">arXiv:2307.02688</a> (replaced) [<a href="/pdf/2307.02688" title="Download PDF">pdf</a>, <a href="/ps/2307.02688" title="Download PostScript">ps</a>, <a href="/format/2307.02688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic systems and Flagg and Friedman&#x27;s translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Inou%C3%A9%2C+T">Takao Inou&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02796" title="Abstract">arXiv:2307.02796</a> (replaced) [<a href="/pdf/2307.02796" title="Download PDF">pdf</a>, <a href="/format/2307.02796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VerifAI: Verified Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+N">Nan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Ju Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuyu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Halevy%2C+A">Alon Halevy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02869" title="Abstract">arXiv:2307.02869</a> (replaced) [<a href="/pdf/2307.02869" title="Download PDF">pdf</a>, <a href="/format/2307.02869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MomentDiff: Generative Video Moment Retrieval from Random to Real
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pandeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chen-Wei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hongtao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05491" title="Abstract">arXiv:2307.05491</a> (replaced) [<a href="/pdf/2307.05491" title="Download PDF">pdf</a>, <a href="/ps/2307.05491" title="Download PostScript">ps</a>, <a href="/format/2307.05491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parametric roll oscillations of a hydrodynamic Chaplygin sleigh
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Loya%2C+K">Kartik Loya</a>, 
<a href="/search/physics?searchtype=author&query=Tallapragada%2C+P">Phanindra Tallapragada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures, submitted to Nonlinear Dynamics journal by Springer
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Robotics (cs.RO); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06555" title="Abstract">arXiv:2307.06555</a> (replaced) [<a href="/pdf/2307.06555" title="Download PDF">pdf</a>, <a href="/format/2307.06555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Network Approximation: Beyond ReLU to Diverse Activation Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongkai Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08123" title="Abstract">arXiv:2307.08123</a> (replaced) [<a href="/pdf/2307.08123" title="Download PDF">pdf</a>, <a href="/format/2307.08123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Inverse Problems with Latent Diffusion Models via Hard Data  Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Bowen Song</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S+M">Soo Min Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zecheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liyue Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09447" title="Abstract">arXiv:2307.09447</a> (replaced) [<a href="/pdf/2307.09447" title="Download PDF">pdf</a>, <a href="/format/2307.09447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Aggregation for Recommending Items to Group of Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Due%C3%B1as-Ler%C3%ADn%2C+J">Jorge Due&#xf1;as-Ler&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Lara-Cabrera%2C+R">Ra&#xfa;l Lara-Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+F">Fernando Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Bobadilla%2C+J">Jes&#xfa;s Bobadilla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09531" title="Abstract">arXiv:2307.09531</a> (replaced) [<a href="/pdf/2307.09531" title="Download PDF">pdf</a>, <a href="/format/2307.09531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOG-LIO: A LiDAR-Inertial Odometry with Efficient Local Geometric  Information Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junqiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhongyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tiantian Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09855" title="Abstract">arXiv:2307.09855</a> (replaced) [<a href="/pdf/2307.09855" title="Download PDF">pdf</a>, <a href="/ps/2307.09855" title="Download PostScript">ps</a>, <a href="/format/2307.09855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-thread critical sections and efficient dynamic race prediction  methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulzmann%2C+M">Martin Sulzmann</a>, 
<a href="/search/cs?searchtype=author&query=Thiemann%2C+P">Peter Thiemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised POPL'24 submission. 1. WCP is sound and show that WCP soundness proof can be adapted. 2. Cross-thread critical sections arise in practice, though the impact is not drastic. This in line with other works (like WCP) that advance the state of the art
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12813" title="Abstract">arXiv:2307.12813</a> (replaced) [<a href="/pdf/2307.12813" title="Download PDF">pdf</a>, <a href="/format/2307.12813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Described Object Detection: Liberating Object Detection with Flexible  Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shuang Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13149" title="Abstract">arXiv:2307.13149</a> (replaced) [<a href="/pdf/2307.13149" title="Download PDF">pdf</a>, <a href="/format/2307.13149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+B">Bahador Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+H+S">Hyoung Suk Suh</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">WaiChing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14290" title="Abstract">arXiv:2307.14290</a> (replaced) [<a href="/pdf/2307.14290" title="Download PDF">pdf</a>, <a href="/format/2307.14290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cumulative Information Generating Function and Generalized Gini  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capaldo%2C+M">Marco Capaldo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Crescenzo%2C+A">Antonio Di Crescenzo</a>, 
<a href="/search/cs?searchtype=author&query=Meoli%2C+A">Alessandra Meoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 1 figure, revision submitted on September 19, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14539" title="Abstract">arXiv:2307.14539</a> (replaced) [<a href="/pdf/2307.14539" title="Download PDF">pdf</a>, <a href="/format/2307.14539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shayegani%2C+E">Erfan Shayegani</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14721" title="Abstract">arXiv:2307.14721</a> (replaced) [<a href="/pdf/2307.14721" title="Download PDF">pdf</a>, <a href="/format/2307.14721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singularity Distance Computations for 3-RPR Manipulators Using Intrinsic  Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapilavai%2C+A">Aditya Kapilavai</a>, 
<a href="/search/cs?searchtype=author&query=Nawratil%2C+G">Georg Nawratil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15770" title="Abstract">arXiv:2307.15770</a> (replaced) [<a href="/pdf/2307.15770" title="Download PDF">pdf</a>, <a href="/format/2307.15770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHATREPORT: Democratizing Sustainability Disclosure Analysis through  LLM-based Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jingwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Bingler%2C+J">Julia Bingler</a>, 
<a href="/search/cs?searchtype=author&query=Colesanti-Senni%2C+C">Chiara Colesanti-Senni</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+M">Mathias Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Gostlow%2C+G">Glen Gostlow</a>, 
<a href="/search/cs?searchtype=author&query=Schimanski%2C+T">Tobias Schimanski</a>, 
<a href="/search/cs?searchtype=author&query=Stammbach%2C+D">Dominik Stammbach</a>, 
<a href="/search/cs?searchtype=author&query=Vaghefi%2C+S+A">Saeid Ashraf Vaghefi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Webersinke%2C+N">Nicolas Webersinke</a>, 
<a href="/search/cs?searchtype=author&query=Wekhof%2C+T">Tobias Wekhof</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tingyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Leippold%2C+M">Markus Leippold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. arXiv admin note: text overlap with <a href="/abs/2306.15518">arXiv:2306.15518</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07327" title="Abstract">arXiv:2308.07327</a> (replaced) [<a href="/pdf/2308.07327" title="Download PDF">pdf</a>, <a href="/format/2308.07327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant  Poker Game Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, submission to IEEE Transactions on Games
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08313" title="Abstract">arXiv:2308.08313</a> (replaced) [<a href="/pdf/2308.08313" title="Download PDF">pdf</a>, <a href="/format/2308.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECPC-IDS:A benchmark endometrail cancer PET/CT image dataset for  evaluation of semantic segmentation and detection of hypermetabolic regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+D">Dechao Tang</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+T">Tianming Du</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+D">Deguo Ma</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zhiyu Ma</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongzan Sun</a>, 
<a href="/search/eess?searchtype=author&query=Grzegorzek%2C+M">Marcin Grzegorzek</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Huiyan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11785" title="Abstract">arXiv:2308.11785</a> (replaced) [<a href="/pdf/2308.11785" title="Download PDF">pdf</a>, <a href="/ps/2308.11785" title="Download PostScript">ps</a>, <a href="/format/2308.11785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe Automated Refactoring of Imperative Deep Learning Programs  to Graph Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khatchadourian%2C+R">Raffi Khatchadourian</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A9lez%2C+T+C">Tatiana Castro V&#xe9;lez</a>, 
<a href="/search/cs?searchtype=author&query=Bagherzadeh%2C+M">Mehdi Bagherzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+N">Nan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+A">Anita Raja</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the NIER track of the IEEE/ACM International Conference on Automated Software Engineering, ASE '23, Kirchberg, Luxembourg, September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11838" title="Abstract">arXiv:2308.11838</a> (replaced) [<a href="/pdf/2308.11838" title="Download PDF">pdf</a>, <a href="/format/2308.11838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark Study on Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Linwei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Younan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haolan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Minjing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12067" title="Abstract">arXiv:2308.12067</a> (replaced) [<a href="/pdf/2308.12067" title="Download PDF">pdf</a>, <a href="/format/2308.12067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zihao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12088" title="Abstract">arXiv:2308.12088</a> (replaced) [<a href="/pdf/2308.12088" title="Download PDF">pdf</a>, <a href="/format/2308.12088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Tracking Control of Dual-PAM Soft Actuator with Hysteresis  Compensator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Miyazaki%2C+T">Tetsuro Miyazaki</a>, 
<a href="/search/cs?searchtype=author&query=Ohno%2C+S">Shingo Ohno</a>, 
<a href="/search/cs?searchtype=author&query=Sogabe%2C+M">Maina Sogabe</a>, 
<a href="/search/cs?searchtype=author&query=Kawashima%2C+K">Kenji Kawashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Robotics and Automation Letters (RA-L)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14638" title="Abstract">arXiv:2308.14638</a> (replaced) [<a href="/pdf/2308.14638" title="Download PDF">pdf</a>, <a href="/format/2308.14638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The USTC-NERCSLIP Systems for the CHiME-7 DASR Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+M">Maokui He</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Hengshun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+S">Shutong Niu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+Y">Yanyan Yue</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Gaobin Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shilong Wu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+L">Lei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+Y">Yanhui Tu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+H">Haitao Tang</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+S">Shuangqing Qian</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+T">Tian Gao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Mengzhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+G">Genshun Wan</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+J">Jia Pan</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jianqing Gao</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+C">Chin-Hui Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 CHiME Workshop, Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15321" title="Abstract">arXiv:2308.15321</a> (replaced) [<a href="/pdf/2308.15321" title="Download PDF">pdf</a>, <a href="/format/2308.15321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elucidating the Exposure Bias in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Mang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jianlin Su</a>, 
<a href="/search/cs?searchtype=author&query=Salah%2C+A+A">Albert Ali Salah</a>, 
<a href="/search/cs?searchtype=author&query=Ertugrul%2C+I+O">Itir Onal Ertugrul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15854" title="Abstract">arXiv:2308.15854</a> (replaced) [<a href="/pdf/2308.15854" title="Download PDF">pdf</a>, <a href="/format/2308.15854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Inversion Process for Image Attribute Editing with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhanbo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zenan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Ci Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R+C">Robert C. Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01012" title="Abstract">arXiv:2309.01012</a> (replaced) [<a href="/pdf/2309.01012" title="Download PDF">pdf</a>, <a href="/format/2309.01012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Day-to-Day Experiences of Users with Traumatic Brain  Injury with Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hajin Lim</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+H+L">Hailey L. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shaughnessy%2C+J+M">Josephine M. O&#x27;Shaughnessy</a>, 
<a href="/search/cs?searchtype=author&query=Kakonge%2C+L">Lisa Kakonge</a>, 
<a href="/search/cs?searchtype=author&query=Turkstra%2C+L+S">Lyn S. Turkstra</a>, 
<a href="/search/cs?searchtype=author&query=Duff%2C+M+C">Melissa C. Duff</a>, 
<a href="/search/cs?searchtype=author&query=Toma%2C+C+L">Catalina L. Toma</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+B">Bilge Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings The 25th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01808" title="Abstract">arXiv:2309.01808</a> (replaced) [<a href="/pdf/2309.01808" title="Download PDF">pdf</a>, <a href="/format/2309.01808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiscoverPath: A Knowledge Refinement and Retrieval System for  Interdisciplinarity on Biomedical Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yu-Neng Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanchu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chia-Yuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kwei-Herng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Reyes%2C+A+C">Alfredo Costilla Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoqian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03805" title="Abstract">arXiv:2309.03805</a> (replaced) [<a href="/pdf/2309.03805" title="Download PDF">pdf</a>, <a href="/format/2309.03805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping of CNNs on multi-core RRAM-based CIM architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelke%2C+R">Rebecca Pelke</a>, 
<a href="/search/cs?searchtype=author&query=Bosbach%2C+N">Nils Bosbach</a>, 
<a href="/search/cs?searchtype=author&query=Cubero%2C+J">Jose Cubero</a>, 
<a href="/search/cs?searchtype=author&query=Staudigl%2C+F">Felix Staudigl</a>, 
<a href="/search/cs?searchtype=author&query=Leupers%2C+R">Rainer Leupers</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+J+M">Jan Moritz Joseph</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05242" title="Abstract">arXiv:2309.05242</a> (replaced) [<a href="/pdf/2309.05242" title="Download PDF">pdf</a>, <a href="/format/2309.05242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6G Unleashed: Transforming Broadcast via service based architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R">Rashmi Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Kamran%2C+R">Rashmi Kamran</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Pranav Jha</a>, 
<a href="/search/cs?searchtype=author&query=Karandikar%2C+A">Abhay Karandikar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06055" title="Abstract">arXiv:2309.06055</a> (replaced) [<a href="/pdf/2309.06055" title="Download PDF">pdf</a>, <a href="/format/2309.06055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attacks and Countermeasures in Natural Language Processing  Models: A Comprehensive Security Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengzhou Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haodong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10187" title="Abstract">arXiv:2309.10187</a> (replaced) [<a href="/pdf/2309.10187" title="Download PDF">pdf</a>, <a href="/format/2309.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Interviewer or Augmented Survey? Collecting Social Data with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villalba%2C+A+C">Alejandro Cuevas Villalba</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+E+M">Eva M. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Scurrell%2C+J+V">Jennifer V. Scurrell</a>, 
<a href="/search/cs?searchtype=author&query=Entenmann%2C+J">Jason Entenmann</a>, 
<a href="/search/cs?searchtype=author&query=Daepp%2C+M+I+G">Madeleine I. G. Daepp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10620" title="Abstract">arXiv:2309.10620</a> (replaced) [<a href="/pdf/2309.10620" title="Download PDF">pdf</a>, <a href="/format/2309.10620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Factors for Environmental Modeling in Robotic Active  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morilla-Cabello%2C+D">David Morilla-Cabello</a>, 
<a href="/search/cs?searchtype=author&query=Westheider%2C+J">Jonas Westheider</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Marija Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Montijano%2C+E">Eduardo Montijano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures, under review for IEEE ICRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11942" title="Abstract">arXiv:2309.11942</a> (replaced) [<a href="/pdf/2309.11942" title="Download PDF">pdf</a>, <a href="/format/2309.11942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Probability of Immunity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pe%C3%B1a%2C+J+M">Jose M. Pe&#xf1;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13078" title="Abstract">arXiv:2309.13078</a> (replaced) [<a href="/pdf/2309.13078" title="Download PDF">pdf</a>, <a href="/format/2309.13078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LPML: LLM-Prompting Markup Language for Mathematical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamauchi%2C+R">Ryutaro Yamauchi</a>, 
<a href="/search/cs?searchtype=author&query=Sonoda%2C+S">Sho Sonoda</a>, 
<a href="/search/cs?searchtype=author&query=Sannai%2C+A">Akiyoshi Sannai</a>, 
<a href="/search/cs?searchtype=author&query=Kumagai%2C+W">Wataru Kumagai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13438" title="Abstract">arXiv:2309.13438</a> (replaced) [<a href="/pdf/2309.13438" title="Download PDF">pdf</a>, <a href="/format/2309.13438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Superpixel Segmentation from Biologically Inspired Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Daipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenguang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13678" title="Abstract">arXiv:2309.13678</a> (replaced) [<a href="/pdf/2309.13678" title="Download PDF">pdf</a>, <a href="/ps/2309.13678" title="Download PostScript">ps</a>, <a href="/format/2309.13678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query complexity of Boolean functions on the middle slice of the cube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gerbner%2C+D">D&#xe1;niel Gerbner</a>, 
<a href="/search/math?searchtype=author&query=Keszegh%2C+B">Bal&#xe1;zs Keszegh</a>, 
<a href="/search/math?searchtype=author&query=Nagy%2C+D+T">D&#xe1;niel T. Nagy</a>, 
<a href="/search/math?searchtype=author&query=Nagy%2C+K">Kartal Nagy</a>, 
<a href="/search/math?searchtype=author&query=P%C3%A1lv%C3%B6lgyi%2C+D">D&#xf6;m&#xf6;t&#xf6;r P&#xe1;lv&#xf6;lgyi</a>, 
<a href="/search/math?searchtype=author&query=Patk%C3%B3s%2C+B">Bal&#xe1;zs Patk&#xf3;s</a>, 
<a href="/search/math?searchtype=author&query=Wiener%2C+G">G&#xe1;bor Wiener</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14065" title="Abstract">arXiv:2309.14065</a> (replaced) [<a href="/pdf/2309.14065" title="Download PDF">pdf</a>, <a href="/format/2309.14065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Siqi Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Renzhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shengjun Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14718" title="Abstract">arXiv:2309.14718</a> (replaced) [<a href="/pdf/2309.14718" title="Download PDF">pdf</a>, <a href="/format/2309.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing delegation between human and AI collaborative agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+A">Andrew Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Passarella%2C+A">Andrea Passarella</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Marco Conti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted to the 'Towards Hybrid Human-Machine Learning and Decision Making (HLDM)' workshop at ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15709" title="Abstract">arXiv:2309.15709</a> (replaced) [<a href="/pdf/2309.15709" title="Download PDF">pdf</a>, <a href="/ps/2309.15709" title="Download PostScript">ps</a>, <a href="/format/2309.15709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Pilot Assignment for Distributed Massive-MIMO Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+S+A">Mohd Saif Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Agnihotri%2C+S">Samar Agnihotri</a>, 
<a href="/search/cs?searchtype=author&query=M.%2C+K+R">Karthik R. M.</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16598" title="Abstract">arXiv:2309.16598</a> (replaced) [<a href="/pdf/2309.16598" title="Download PDF">pdf</a>, <a href="/format/2309.16598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Prediction-Powered Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>, 
<a href="/search/stat?searchtype=author&query=Cand%C3%A8s%2C+E+J">Emmanuel J. Cand&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16918" title="Abstract">arXiv:2309.16918</a> (replaced) [<a href="/pdf/2309.16918" title="Download PDF">pdf</a>, <a href="/format/2309.16918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianlong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yifei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shafiabady%2C+N">Niusha Shafiabady</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17382" title="Abstract">arXiv:2309.17382</a> (replaced) [<a href="/pdf/2309.17382" title="Download PDF">pdf</a>, <a href="/format/2309.17382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reason for Future, Act for Now: A Principled Framework for Autonomous  LLM Agents with Provable Sample Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+S">Shuqi Ke</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Boyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17421" title="Abstract">arXiv:2309.17421</a> (replaced) [<a href="/pdf/2309.17421" title="Download PDF">pdf</a>, <a href="/format/2309.17421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chung-Ching Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00113" title="Abstract">arXiv:2310.00113</a> (replaced) [<a href="/pdf/2310.00113" title="Download PDF">pdf</a>, <a href="/format/2310.00113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ksi%C4%85%C5%BCek%2C+K">Kamil Ksi&#x105;&#x17c;ek</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00704" title="Abstract">arXiv:2310.00704</a> (replaced) [<a href="/pdf/2310.00704" title="Download PDF">pdf</a>, <a href="/format/2310.00704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniAudio: An Audio Foundation Model Toward Universal Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00772" title="Abstract">arXiv:2310.00772</a> (replaced) [<a href="/pdf/2310.00772" title="Download PDF">pdf</a>, <a href="/format/2310.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMOOT: Saliency Guided Mask Optimized Online Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karkehabadi%2C+A">Ali Karkehabadi</a>, 
<a href="/search/cs?searchtype=author&query=Homayoun%2C+H">Houman Homayoun</a>, 
<a href="/search/cs?searchtype=author&query=Sasan%2C+A">Avesta Sasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01213" title="Abstract">arXiv:2310.01213</a> (replaced) [<a href="/pdf/2310.01213" title="Download PDF">pdf</a>, <a href="/format/2310.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure and growth of $\mathbb{R}$-bonacci words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dovgal%2C+S">Sergey Dovgal</a>, 
<a href="/search/math?searchtype=author&query=Kirgizov%2C+S">Sergey Kirgizov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01636" title="Abstract">arXiv:2310.01636</a> (replaced) [<a href="/pdf/2310.01636" title="Download PDF">pdf</a>, <a href="/format/2310.01636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Visual Scene Understanding: Incremental Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+N">Naitik Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01905" title="Abstract">arXiv:2310.01905</a> (replaced) [<a href="/pdf/2310.01905" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Driven Design in Software Development: A Systematic Literature  Review on Implementation, Challenges, and Effectiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96zkan%2C+O">Ozan &#xd6;zkan</a>, 
<a href="/search/cs?searchtype=author&query=Babur%2C+%C3%96">&#xd6;nder Babur</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+M">Mark van den Brand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review: Submitted to ACM Computing Surveys on 14 August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02044" title="Abstract">arXiv:2310.02044</a> (replaced) [<a href="/pdf/2310.02044" title="Download PDF">pdf</a>, <a href="/format/2310.02044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Transformers under Occlusion: How Physics and Background  Attributes Impact Large Models for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shutong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zahid%2C+M">Muhammad Zahid</a>, 
<a href="/search/cs?searchtype=author&query=Pokorny%2C+F+T">Florian T. Pokorny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at IEEE ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02800" title="Abstract">arXiv:2310.02800</a> (replaced) [<a href="/pdf/2310.02800" title="Download PDF">pdf</a>, <a href="/format/2310.02800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everest: GPU-Accelerated System For Mining Temporal Motifs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yichao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haojie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Vedula%2C+S">Sanketh Vedula</a>, 
<a href="/search/cs?searchtype=author&query=Kaza%2C+W">Wynn Kaza</a>, 
<a href="/search/cs?searchtype=author&query=Talati%2C+N">Nishil Talati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03057" title="Abstract">arXiv:2310.03057</a> (replaced) [<a href="/pdf/2310.03057" title="Download PDF">pdf</a>, <a href="/ps/2310.03057" title="Download PostScript">ps</a>, <a href="/format/2310.03057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm for finding new identifiable reparametrizations of parametric  ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meshkat%2C+N">Nicolette Meshkat</a>, 
<a href="/search/eess?searchtype=author&query=Ovchinnikov%2C+A">Alexey Ovchinnikov</a>, 
<a href="/search/eess?searchtype=author&query=Scanlon%2C+T">Thomas Scanlon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> corrected abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Algebraic Geometry (math.AG); Dynamical Systems (math.DS); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03131" title="Abstract">arXiv:2310.03131</a> (replaced) [<a href="/pdf/2310.03131" title="Download PDF">pdf</a>, <a href="/ps/2310.03131" title="Download PostScript">ps</a>, <a href="/format/2310.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axiomatic Aggregations of Abductive Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biradar%2C+G">Gagan Biradar</a>, 
<a href="/search/cs?searchtype=author&query=Izza%2C+Y">Yacine Izza</a>, 
<a href="/search/cs?searchtype=author&query=Lobo%2C+E">Elita Lobo</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Vignesh Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Zick%2C+Y">Yair Zick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03344" title="Abstract">arXiv:2310.03344</a> (replaced) [<a href="/pdf/2310.03344" title="Download PDF">pdf</a>, <a href="/format/2310.03344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Benders Decomposition with Continual Learning for Hybrid  Model Predictive Control in Dynamic Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuan Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A correction of the author name in the metadata
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03533" title="Abstract">arXiv:2310.03533</a> (replaced) [<a href="/pdf/2310.03533" title="Download PDF">pdf</a>, <a href="/format/2310.03533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Software Engineering: Survey and Open Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+A">Angela Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gokkaya%2C+B">Beliz Gokkaya</a>, 
<a href="/search/cs?searchtype=author&query=Harman%2C+M">Mark Harman</a>, 
<a href="/search/cs?searchtype=author&query=Lyubarskiy%2C+M">Mitya Lyubarskiy</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Shubho Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03748" title="Abstract">arXiv:2310.03748</a> (replaced) [<a href="/pdf/2310.03748" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Synchrony Component Self-Organization in Brain Computer Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Niu%2C+X">Xu Niu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+N">Na Lu</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+H">Huan Luo</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+R">Ruofan Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04189" title="Abstract">arXiv:2310.04189</a> (replaced) [<a href="/pdf/2310.04189" title="Download PDF">pdf</a>, <a href="/format/2310.04189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap between Human Motion and Action Semantics via Kinematic  Phrases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zizheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Yong-Lu Li and Cewu Lu are the corresponding authors. Project page is available at <a href="https://foruck.github.io/KP/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04286" title="Abstract">arXiv:2310.04286</a> (replaced) [<a href="/pdf/2310.04286" title="Download PDF">pdf</a>, <a href="/format/2310.04286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-constrained symbolic model discovery for polyconvex  incompressible hyperelastic materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+B">Bahador Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">WaiChing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Soft Condensed Matter (cond-mat.soft)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04381" title="Abstract">arXiv:2310.04381</a> (replaced) [<a href="/pdf/2310.04381" title="Download PDF">pdf</a>, <a href="/format/2310.04381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hermes: Unlocking Security Analysis of Cellular Network Protocols by  Synthesizing Finite State Machines from Natural Language Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishtiaq%2C+A+A">Abdullah Al Ishtiaq</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S+S+S">Sarkar Snigdha Sarathi Das</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+S+M+M">Syed Md Mukit Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Ranjbar%2C+A">Ali Ranjbar</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+K">Kai Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhezheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Akon%2C+M">Mujtahid Akon</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+S+R">Syed Rafiul Hussain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at USENIX Security 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04395" title="Abstract">arXiv:2310.04395</a> (replaced) [<a href="/pdf/2310.04395" title="Download PDF">pdf</a>, <a href="/format/2310.04395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Self-Consistency for Data-Efficient Amortized Bayesian  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+M">Marvin Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+D">Daniel Habermann</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+S+T">Stefan T. Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04513" title="Abstract">arXiv:2310.04513</a> (replaced) [<a href="/pdf/2310.04513" title="Download PDF">pdf</a>, <a href="/ps/2310.04513" title="Download PostScript">ps</a>, <a href="/format/2310.04513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Data Security: Practices from Cybersecurity and Challenges  of Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+P">Padmaksha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+J">Jaganmohan Chandrasekaran</a>, 
<a href="/search/cs?searchtype=author&query=Lanus%2C+E">Erin Lanus</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+L">Laura Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Werner%2C+J">Jeremy Werner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04673" title="Abstract">arXiv:2310.04673</a> (replaced) [<a href="/pdf/2310.04673" title="Download PDF">pdf</a>, <a href="/format/2310.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhihao Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y">Yunfei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhifu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zerui Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kai Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaohuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Siqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhijie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04675" title="Abstract">arXiv:2310.04675</a> (replaced) [<a href="/pdf/2310.04675" title="Download PDF">pdf</a>, <a href="/format/2310.04675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain-Aware Quadrupedal Locomotion via Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haojie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lei Han</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+W">Wanchao Chi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tingguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04764" title="Abstract">arXiv:2310.04764</a> (replaced) [<a href="/pdf/2310.04764" title="Download PDF">pdf</a>, <a href="/format/2310.04764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizations of Definable Context-Free Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iosif%2C+R">Radu Iosif</a>, 
<a href="/search/cs?searchtype=author&query=Zuleger%2C+F">Florian Zuleger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04780" title="Abstract">arXiv:2310.04780</a> (replaced) [<a href="/pdf/2310.04780" title="Download PDF">pdf</a>, <a href="/format/2310.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenglin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xianan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Na Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaomei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04874" title="Abstract">arXiv:2310.04874</a> (replaced) [<a href="/pdf/2310.04874" title="Download PDF">pdf</a>, <a href="/format/2310.04874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AirIMU: Learning Uncertainty Propagation for Inertial Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xunfei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Youjie Xia</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04895" title="Abstract">arXiv:2310.04895</a> (replaced) [<a href="/pdf/2310.04895" title="Download PDF">pdf</a>, <a href="/format/2310.04895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell Tracking-by-detection using Elliptical Bounding Boxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirsten%2C+L+N">Lucas N. Kirsten</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+C+R">Cl&#xe1;udio R. Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper under review on IEEE/ACM Transactions on Computational Biology and Bioinformatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04937" title="Abstract">arXiv:2310.04937</a> (replaced) [<a href="/pdf/2310.04937" title="Download PDF">pdf</a>, <a href="/format/2310.04937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Computing and Visualization: A Disruptive Technological Change  Ahead
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bethel%2C+E+W">E. Wes Bethel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Amankwah%2C+M+G">Mercy G. Amankwah</a>, 
<a href="/search/quant-ph?searchtype=author&query=Balewski%2C+J">Jan Balewski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Van+Beeumen%2C+R">Roel Van Beeumen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Camps%2C+D">Daan Camps</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+D">Daniel Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perciano%2C+T">Talita Perciano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Computer Graphics and Applications, 43(6), Nov/Dec, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04991" title="Abstract">arXiv:2310.04991</a> (replaced) [<a href="/pdf/2310.04991" title="Download PDF">pdf</a>, <a href="/format/2310.04991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Teller: Enhancing Cross-Modal Generation with Fusion and  Decoupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haogeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qihang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tingkai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yunzhe Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05015" title="Abstract">arXiv:2310.05015</a> (replaced) [<a href="/pdf/2310.05015" title="Download PDF">pdf</a>, <a href="/format/2310.05015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compresso: Structured Pruning with Collaborative Prompting Learns  Compact Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiahang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+L">Li Lyna Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05028" title="Abstract">arXiv:2310.05028</a> (replaced) [<a href="/pdf/2310.05028" title="Download PDF">pdf</a>, <a href="/format/2310.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Large Language Models as Zero-shot Relation Extractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guozheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wenjun Ke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05052" title="Abstract">arXiv:2310.05052</a> (replaced) [<a href="/pdf/2310.05052" title="Download PDF">pdf</a>, <a href="/format/2310.05052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Intra- and Inter-Cell Differences for Accurate Battery Lifespan  Prediction across Diverse Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+S">Shun Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Gui%2C+X">Xiaofan Gui</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05057" title="Abstract">arXiv:2310.05057</a> (replaced) [<a href="/pdf/2310.05057" title="Download PDF">pdf</a>, <a href="/format/2310.05057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BRAINTEASER: Lateral Thinking Puzzles for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05136" title="Abstract">arXiv:2310.05136</a> (replaced) [<a href="/e-print/2310.05136" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructDET: Diversifying Referring Object Detection with Generalized  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+R">Ronghao Dang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiangyan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lin Song</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Lijun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengju Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yibing Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Adjust the subject
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05280" title="Abstract">arXiv:2310.05280</a> (replaced) [<a href="/pdf/2310.05280" title="Download PDF">pdf</a>, <a href="/format/2310.05280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona  Biases in Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05341" title="Abstract">arXiv:2310.05341</a> (replaced) [<a href="/pdf/2310.05341" title="Download PDF">pdf</a>, <a href="/format/2310.05341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Look at Classic Test-Time Adaptation Methods in Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+C">Chang&#x27;an Yi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haotian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yonghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Lizhen Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05350" title="Abstract">arXiv:2310.05350</a> (replaced) [<a href="/pdf/2310.05350" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Studies for Efficient Parameter Search and Parallelism for Large  Language Model Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benington%2C+M">Michael Benington</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+L">Leo Phan</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+C+P">Chris Pierre Paul</a>, 
<a href="/search/cs?searchtype=author&query=Shoemaker%2C+E">Evan Shoemaker</a>, 
<a href="/search/cs?searchtype=author&query=Ranade%2C+P">Priyanka Ranade</a>, 
<a href="/search/cs?searchtype=author&query=Collett%2C+T">Torstein Collett</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+G+H">Grant Hodgson Perez</a>, 
<a href="/search/cs?searchtype=author&query=Krieger%2C+C">Christopher Krieger</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Supercomputing 2023 (SC23) Student Research Poster Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05353" title="Abstract">arXiv:2310.05353</a> (replaced) [<a href="/pdf/2310.05353" title="Download PDF">pdf</a>, <a href="/ps/2310.05353" title="Download PostScript">ps</a>, <a href="/format/2310.05353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity of null dynamical systems and Sauer--Shelah lemmas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+G">Guorong Gao</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+J">Jie Ma</a>, 
<a href="/search/math?searchtype=author&query=Rong%2C+M">Mingyuan Rong</a>, 
<a href="/search/math?searchtype=author&query=Tran%2C+T">Tuan Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05447" title="Abstract">arXiv:2310.05447</a> (replaced) [<a href="/pdf/2310.05447" title="Download PDF">pdf</a>, <a href="/format/2310.05447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fair and Comprehensive Comparisons for Image-Based 3D Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinzhu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhiyi Xia</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV23, code will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05469" title="Abstract">arXiv:2310.05469</a> (replaced) [<a href="/pdf/2310.05469" title="Download PDF">pdf</a>, <a href="/format/2310.05469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vibroacoustic Frequency Response Prediction with Query-based Operator  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Delden%2C+J">Jan van Delden</a>, 
<a href="/search/cs?searchtype=author&query=Schultz%2C+J">Julius Schultz</a>, 
<a href="/search/cs?searchtype=author&query=Blech%2C+C">Christopher Blech</a>, 
<a href="/search/cs?searchtype=author&query=Langer%2C+S+C">Sabine C. Langer</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCddecke%2C+T">Timo L&#xfc;ddecke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05672" title="Abstract">arXiv:2310.05672</a> (replaced) [<a href="/pdf/2310.05672" title="Download PDF">pdf</a>, <a href="/format/2310.05672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-timestep models for Model-based Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benechehab%2C+A">Abdelhakim Benechehab</a>, 
<a href="/search/cs?searchtype=author&query=Paolo%2C+G">Giuseppe Paolo</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+A">Albert Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Filippone%2C+M">Maurizio Filippone</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A9gl%2C+B">Bal&#xe1;zs K&#xe9;gl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05680" title="Abstract">arXiv:2310.05680</a> (replaced) [<a href="/pdf/2310.05680" title="Download PDF">pdf</a>, <a href="/ps/2310.05680" title="Download PostScript">ps</a>, <a href="/format/2310.05680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Argument Generation from Legal Facts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuvey%2C+O">Oscar Tuvey</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+P">Procheta Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05682" title="Abstract">arXiv:2310.05682</a> (replaced) [<a href="/pdf/2310.05682" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Rainfall Variability and Water Extent of Selected Hydropower  Reservoir Using Google Earth Engine (GEE): A Case Study from Two Tropical  Countries, Sri Lanka and Vietnam
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajakaruna%2C+P">Punsisi Rajakaruna</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Surajit Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Holmatov%2C+B">Bunyod Holmatov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05728" title="Abstract">arXiv:2310.05728</a> (replaced) [<a href="/pdf/2310.05728" title="Download PDF">pdf</a>, <a href="/format/2310.05728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidden Permutations to the Rescue: Multi-Pass Semi-Streaming Lower  Bounds for Approximate Matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assadi%2C+S">Sepehr Assadi</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+J">Janani Sundaresan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 84 pages, 19 figures; to appear in FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05765" title="Abstract">arXiv:2310.05765</a> (replaced) [<a href="/pdf/2310.05765" title="Download PDF">pdf</a>, <a href="/format/2310.05765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the simulation-to-reality gap of a wheel loader digging in  deformable terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aoshima%2C+K">Koji Aoshima</a>, 
<a href="/search/cs?searchtype=author&query=Servin%2C+M">Martin Servin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05797" title="Abstract">arXiv:2310.05797</a> (replaced) [<a href="/pdf/2310.05797" title="Download PDF">pdf</a>, <a href="/format/2310.05797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Large Language Models Post Hoc Explainers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kroeger%2C+N">Nicholas Kroeger</a>, 
<a href="/search/cs?searchtype=author&query=Ley%2C+D">Dan Ley</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Satyapriya Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+C">Chirag Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05869" title="Abstract">arXiv:2310.05869</a> (replaced) [<a href="/pdf/2310.05869" title="Download PDF">pdf</a>, <a href="/format/2310.05869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperAttention: Long-context Attention in Near-Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+I">Insu Han</a>, 
<a href="/search/cs?searchtype=author&query=Jayaram%2C+R">Rajesh Jayaram</a>, 
<a href="/search/cs?searchtype=author&query=Karbasi%2C+A">Amin Karbasi</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P. Woodruff</a>, 
<a href="/search/cs?searchtype=author&query=Zandieh%2C+A">Amir Zandieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05917" title="Abstract">arXiv:2310.05917</a> (replaced) [<a href="/pdf/2310.05917" title="Download PDF">pdf</a>, <a href="/format/2310.05917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drivable Avatar Clothing: Faithful Full-Body Telepresence with Dynamic  Clothing Driven by Sparse RGB-D Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+D">Donglai Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Prada%2C+F">Fabian Prada</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhe Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kaiwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenglei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hodgins%2C+J">Jessica Hodgins</a>, 
<a href="/search/cs?searchtype=author&query=Bagautdinov%2C+T">Timur Bagautdinov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 Conference Paper. Project website: <a href="https://xiangdonglai.github.io/www-sa23-drivable-clothing/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06066" title="Abstract">arXiv:2310.06066</a> (replaced) [<a href="/pdf/2310.06066" title="Download PDF">pdf</a>, <a href="/ps/2310.06066" title="Download PostScript">ps</a>, <a href="/format/2310.06066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilized finite elements for the solution of the Reynolds equation  considering cavitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gravenkamp%2C+H">Hauke Gravenkamp</a>, 
<a href="/search/math?searchtype=author&query=Pfeil%2C+S">Simon Pfeil</a>, 
<a href="/search/math?searchtype=author&query=Codina%2C+R">Ramon Codina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted version published in CMAME
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering, vol. 418,
  p. 116488, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06200" title="Abstract">arXiv:2310.06200</a> (replaced) [<a href="/pdf/2310.06200" title="Download PDF">pdf</a>, <a href="/format/2310.06200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Prompt Tuning for Automated Neuron Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Justin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oikarinen%2C+T">Tuomas Oikarinen</a>, 
<a href="/search/cs?searchtype=author&query=Chatha%2C+A">Arjun Chatha</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Keng-Chi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yilan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Tsui-Wei Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06282" title="Abstract">arXiv:2310.06282</a> (replaced) [<a href="/pdf/2310.06282" title="Download PDF">pdf</a>, <a href="/format/2310.06282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuseChat: A Conversational Music Recommendation System for Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhikang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiulong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+P">Pawel Polak</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06306" title="Abstract">arXiv:2310.06306</a> (replaced) [<a href="/pdf/2310.06306" title="Download PDF">pdf</a>, <a href="/format/2310.06306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Active Learning by Contextual Bandits for AI Incubation in  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yingyan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Ran Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06450" title="Abstract">arXiv:2310.06450</a> (replaced) [<a href="/pdf/2310.06450" title="Download PDF">pdf</a>, <a href="/format/2310.06450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive Large Language Models Alignment with Diverse Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianshu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Ting-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06692" title="Abstract">arXiv:2310.06692</a> (replaced) [<a href="/pdf/2310.06692" title="Download PDF">pdf</a>, <a href="/format/2310.06692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task  Scenarios with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">Anni Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item393">Cross-lists</a></li>
<li><a href="#item444">Replacements</a></li>
</ul>
<small>[ total of 670 entries:  <b>1-670</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2310">2310</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
