<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 12 Oct 23  to  Fri 13 Oct 23, announced Mon, 16 Oct 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item304">Cross-lists</a></li>
<li><a href="#item342">Replacements</a></li>
</ul>
<small>[ total of 566 entries:  <b>1-566</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 16 Oct 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08595" title="Abstract">arXiv:2310.08595</a> [<a href="/pdf/2310.08595" title="Download PDF">pdf</a>, <a href="/format/2310.08595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Autonomous Vehicle Intersection  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elallid%2C+B+B">Badr Ben Elallid</a>, 
<a href="/search/cs?searchtype=author&query=Alaoui%2C+H+E">Hamza El Alaoui</a>, 
<a href="/search/cs?searchtype=author&query=Benamar%2C+N">Nabil Benamar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 2023 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies (3ICT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we explore the challenges associated with navigating complex
T-intersections in dense traffic scenarios for autonomous vehicles (AVs).
Reinforcement learning algorithms have emerged as a promising approach to
address these challenges by enabling AVs to make safe and efficient decisions
in real-time. Here, we address the problem of efficiently and safely navigating
T-intersections using a lower-cost, single-agent approach based on the Twin
Delayed Deep Deterministic Policy Gradient (TD3) reinforcement learning
algorithm. We show that our TD3-based method, when trained and tested in the
CARLA simulation platform, demonstrates stable convergence and improved safety
performance in various traffic densities. Our results reveal that the proposed
approach enables the AV to effectively navigate T-intersections, outperforming
previous methods in terms of travel delays, collision minimization, and overall
cost. This study contributes to the growing body of knowledge on reinforcement
learning applications in autonomous driving and highlights the potential of
single-agent, cost-effective methods for addressing more complex driving
scenarios and advancing reinforcement learning algorithms in the future.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08597" title="Abstract">arXiv:2310.08597</a> [<a href="/pdf/2310.08597" title="Download PDF">pdf</a>, <a href="/format/2310.08597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method for Multi-Robot Asynchronous Trajectory Execution in MoveIt2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoop%2C+P">Pascal Stoop</a>, 
<a href="/search/cs?searchtype=author&query=Ratnayake%2C+T">Tharaka Ratnayake</a>, 
<a href="/search/cs?searchtype=author&query=Toffetti%2C+G">Giovanni Toffetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the "IROS 2023 Workshop on Task and Motion Planning: from Theory to Practice" -- <a href="https://dyalab.mines.edu/2023/iros-workshop/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work presents an extension to the MoveIt2 planning library supporting
asynchronous execution for multi-robot / multi-arm robotic setups. The proposed
method introduces a unified way for the execution of both synchronous and
asynchronous trajectories by implementing a simple scheduler and guarantees
collision-free operation by continuous collision checking while the robots are
moving.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08599" title="Abstract">arXiv:2310.08599</a> [<a href="/pdf/2310.08599" title="Download PDF">pdf</a>, <a href="/format/2310.08599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Multi-Robot Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+H">Hoang-Dung Bui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the extension of my Ph.D. comprehensive exam report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-robot Motion Planning (MRMP) is an active research field which has
gained attention over the years. MRMP has significant roles to improve the
efficiency and reliability of multi-robot system in a wide range of
applications from delivery robots to collaborative assembly lines. This survey
provides an overview of MRMP taxonomy, state-of-the-art algorithms, and
approaches which have been developed for multi-robot systems. This study also
discusses the strengths and limitations of each algorithm and their
applications in various scenarios. Moreover, based on this, we can draw out
open problems for future research.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08602" title="Abstract">arXiv:2310.08602</a> [<a href="/pdf/2310.08602" title="Download PDF">pdf</a>, <a href="/format/2310.08602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Deep Policy Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wenli Xiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tairan He</a>, 
<a href="/search/cs?searchtype=author&query=Dolan%2C+J">John Dolan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A critical goal of autonomy and artificial intelligence is enabling
autonomous robots to rapidly adapt in dynamic and uncertain environments.
Classic adaptive control and safe control provide stability and safety
guarantees but are limited to specific system classes. In contrast, policy
adaptation based on reinforcement learning (RL) offers versatility and
generalizability but presents safety and robustness challenges. We propose
SafeDPA, a novel RL and control framework that simultaneously tackles the
problems of policy adaptation and safe reinforcement learning. SafeDPA jointly
learns adaptive policy and dynamics models in simulation, predicts environment
configurations, and fine-tunes dynamics models with few-shot real-world data. A
safety filter based on the Control Barrier Function (CBF) on top of the RL
policy is introduced to ensure safety during real-world deployment. We provide
theoretical safety guarantees of SafeDPA and show the robustness of SafeDPA
against learning errors and extra perturbations. Comprehensive experiments on
(1) classic control problems (Inverted Pendulum), (2) simulation benchmarks
(Safety Gym), and (3) a real-world agile robotics platform (RC Car) demonstrate
great superiority of SafeDPA in both safety and task performance, over
state-of-the-art baselines. Particularly, SafeDPA demonstrates notable
generalizability, achieving a 300% increase in safety rate compared to the
baselines, under unseen disturbances in real-world experiments.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08617" title="Abstract">arXiv:2310.08617</a> [<a href="/pdf/2310.08617" title="Download PDF">pdf</a>, <a href="/format/2310.08617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Explanations on Fairness in Human-AI Decision-Making:  Protected vs Proxy Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+N">Navita Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Baumler%2C+C">Connor Baumler</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tin Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Daum%C3%A9%2C+H">Hal Daum&#xe9; III</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">AI systems have been known to amplify biases in real world data. Explanations
may help human-AI teams address these biases for fairer decision-making.
Typically, explanations focus on salient input features. If a model is biased
against some protected group, explanations may include features that
demonstrate this bias, but when biases are realized through proxy features, the
relationship between this proxy feature and the protected one may be less clear
to a human. In this work, we study the effect of the presence of protected and
proxy features on participants' perception of model fairness and their ability
to improve demographic parity over an AI alone. Further, we examine how
different treatments -- explanations, model bias disclosure and proxy
correlation disclosure -- affect fairness perception and parity. We find that
explanations help people detect direct biases but not indirect biases.
Additionally, regardless of bias type, explanations tend to increase agreement
with model biases. Disclosures can help mitigate this effect for indirect
biases, improving both unfairness recognition and the decision-making fairness.
We hope that our findings can help guide further research into advancing
explanations in support of fair human-AI decision-making.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08620" title="Abstract">arXiv:2310.08620</a> [<a href="/pdf/2310.08620" title="Download PDF">pdf</a>, <a href="/format/2310.08620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divorce Prediction with Machine Learning: Insights and LIME  Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+M+M">Md Manjurul Ahsan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Divorce is one of the most common social issues in developed countries like
in the United States. Almost 50% of the recent marriages turn into an
involuntary divorce or separation. While it is evident that people vary to a
different extent, and even over time, an incident like Divorce does not
interrupt the individual's daily activities; still, Divorce has a severe effect
on the individual's mental health, and personal life. Within the scope of this
research, the divorce prediction was carried out by evaluating a dataset named
by the 'divorce predictor dataset' to correctly classify between married and
Divorce people using six different machine learning algorithms- Logistic
Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN),
Classification and Regression Trees (CART), Gaussian Na\"ive Bayes (NB), and,
Support Vector Machines (SVM). Preliminary computational results show that
algorithms such as SVM, KNN, and LDA, can perform that task with an accuracy of
98.57%. This work's additional novel contribution is the detailed and
comprehensive explanation of prediction probabilities using Local Interpretable
Model-Agnostic Explanations (LIME). Utilizing LIME to analyze test results
illustrates the possibility of differentiating between divorced and married
couples. Finally, we have developed a divorce predictor app considering ten
most important features that potentially affect couples in making decisions in
their divorce, such tools can be used by any one in order to identify their
relationship condition.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08644" title="Abstract">arXiv:2310.08644</a> [<a href="/pdf/2310.08644" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of  Geoscientific Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan-Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+H+V">Hoshin V. Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 7 figures, 10 figures, and tables in supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although decades of effort have been devoted to building Physical-Conceptual
(PC) models for predicting the time-series evolution of geoscientific systems,
recent work shows that Machine Learning (ML) based Gated Recurrent Neural
Network technology can be used to develop models that are much more accurate.
However, the difficulty of extracting physical understanding from ML-based
models complicates their utility for enhancing scientific knowledge regarding
system structure and function. Here, we propose a physically-interpretable Mass
Conserving Perceptron (MCP) as a way to bridge the gap between PC-based and
ML-based modeling approaches. The MCP exploits the inherent isomorphism between
the directed graph structures underlying both PC models and GRNNs to explicitly
represent the mass-conserving nature of physical processes while enabling the
functional nature of such processes to be directly learned (in an interpretable
manner) from available data using off-the-shelf ML technology. As a proof of
concept, we investigate the functional expressivity (capacity) of the MCP,
explore its ability to parsimoniously represent the rainfall-runoff (RR)
dynamics of the Leaf River Basin, and demonstrate its utility for scientific
hypothesis testing. To conclude, we discuss extensions of the concept to enable
ML-based physical-conceptual representation of the coupled nature of
mass-energy-information flows through geoscientific systems.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08645" title="Abstract">arXiv:2310.08645</a> [<a href="/pdf/2310.08645" title="Download PDF">pdf</a>, <a href="/format/2310.08645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defect Analysis of 3D Printed Cylinder Object Using Transfer Learning  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+M+M">Md Manjurul Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+S">Shivakumar Raman</a>, 
<a href="/search/cs?searchtype=author&query=Siddique%2C+Z">Zahed Siddique</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Additive manufacturing (AM) is gaining attention across various industries
like healthcare, aerospace, and automotive. However, identifying defects early
in the AM process can reduce production costs and improve productivity - a key
challenge. This study explored the effectiveness of machine learning (ML)
approaches, specifically transfer learning (TL) models, for defect detection in
3D-printed cylinders. Images of cylinders were analyzed using models including
VGG16, VGG19, ResNet50, ResNet101, InceptionResNetV2, and MobileNetV2.
Performance was compared across two datasets using accuracy, precision, recall,
and F1-score metrics. In the first study, VGG16, InceptionResNetV2, and
MobileNetV2 achieved perfect scores. In contrast, ResNet50 had the lowest
performance, with an average F1-score of 0.32. Similarly, in the second study,
MobileNetV2 correctly classified all instances, while ResNet50 struggled with
more false positives and fewer true positives, resulting in an F1-score of
0.75. Overall, the findings suggest certain TL models like MobileNetV2 can
deliver high accuracy for AM defect classification, although performance varies
across algorithms. The results provide insights into model optimization and
integration needs for reliable automated defect analysis during 3D printing. By
identifying the top-performing TL techniques, this study aims to enhance AM
product quality through robust image-based monitoring and inspection.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08646" title="Abstract">arXiv:2310.08646</a> [<a href="/pdf/2310.08646" title="Download PDF">pdf</a>, <a href="/format/2310.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circular Average Filtering and Circular Linear Interpolation in Complex  Color Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Agarwall%2C+S">Shubham Agarwall</a>, 
<a href="/search/cs?searchtype=author&query=House%2C+D+H">Donald H. House</a>, 
<a href="/search/cs?searchtype=author&query=Yildiz%2C+T+T">Tolga Talha Yildiz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In color spaces where the chromatic term is given in polar coordinates, the
shortest distance between colors of the same value is circular. By converting
such a space into a complex polar form with a real-valued value axis, a color
algebra for combining colors is immediately available. In this work, we
introduce two complex space operations utilizing this observation: circular
average filtering and circular linear interpolation. These operations produce
Archimedean Spirals, thus guaranteeing that they operate along the shortest
paths. We demonstrate that these operations provide an intuitive way to work in
certain color spaces and that they are particularly useful for obtaining better
filtering and interpolation results. We present a set of examples based on the
perceptually uniform color space CIELAB or L*a*b* with its polar form CIEHLC.
We conclude that representing colors in a complex space with circular
operations can provide better visual results by exploitation of the strong
algebraic properties of complex space C.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08649" title="Abstract">arXiv:2310.08649</a> [<a href="/pdf/2310.08649" title="Download PDF">pdf</a>, <a href="/format/2310.08649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-vectorized numerical integration for systems of ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Messner%2C+M+C">Mark C. Messner</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+T">Tianchen Hu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tianju Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Stiff systems of ordinary differential equations (ODEs) and sparse training
data are common in scientific problems. This paper describes efficient,
implicit, vectorized methods for integrating stiff systems of ordinary
differential equations through time and calculating parameter gradients with
the adjoint method. The main innovation is to vectorize the problem both over
the number of independent times series and over a batch or "chunk" of
sequential time steps, effectively vectorizing the assembly of the implicit
system of ODEs. The block-bidiagonal structure of the linearized implicit
system for the backward Euler method allows for further vectorization using
parallel cyclic reduction (PCR). Vectorizing over both axes of the input data
provides a higher bandwidth of calculations to the computing device, allowing
even problems with comparatively sparse data to fully utilize modern GPUs and
achieving speed ups of greater than 100x, compared to standard, sequential time
integration. We demonstrate the advantages of implicit, vectorized time
integration with several example problems, drawn from both analytical stiff and
non-stiff ODE models as well as neural ODE models. We also describe and provide
a freely available open-source implementation of the methods developed here.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08650" title="Abstract">arXiv:2310.08650</a> [<a href="/pdf/2310.08650" title="Download PDF">pdf</a>, <a href="/format/2310.08650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electrical Grid Anomaly Detection via Tensor Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Most%2C+A">Alexander Most</a>, 
<a href="/search/cs?searchtype=author&query=Eren%2C+M">Maksim Eren</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+N">Nigel Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+B">Boian Alexandrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures. In IEEE Military Communications Conference, Artificial Intelligence for Cyber Workshop (MILCOM), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Supervisory Control and Data Acquisition (SCADA) systems often serve as the
nervous system for substations within power grids. These systems facilitate
real-time monitoring, data acquisition, control of equipment, and ensure smooth
and efficient operation of the substation and its connected devices. Previous
work has shown that dimensionality reduction-based approaches, such as
Principal Component Analysis (PCA), can be used for accurate identification of
anomalies in SCADA systems. While not specifically applied to SCADA,
non-negative matrix factorization (NMF) has shown strong results at detecting
anomalies in wireless sensor networks. These unsupervised approaches model the
normal or expected behavior and detect the unseen types of attacks or anomalies
by identifying the events that deviate from the expected behavior. These
approaches; however, do not model the complex and multi-dimensional
interactions that are naturally present in SCADA systems. Differently,
non-negative tensor decomposition is a powerful unsupervised machine learning
(ML) method that can model the complex and multi-faceted activity details of
SCADA events. In this work, we novelly apply the tensor decomposition method
Canonical Polyadic Alternating Poisson Regression (CP-APR) with a probabilistic
framework, which has previously shown state-of-the-art anomaly detection
results on cyber network data, to identify anomalies in SCADA systems. We
showcase that the use of statistical behavior analysis of SCADA communication
with tensor decomposition improves the specificity and accuracy of identifying
anomalies in electrical grid systems. In our experiments, we model real-world
SCADA system data collected from the electrical grid operated by Los Alamos
National Laboratory (LANL) which provides transmission and distribution service
through a partnership with Los Alamos County, and detect synthetically
generated anomalies.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08653" title="Abstract">arXiv:2310.08653</a> [<a href="/pdf/2310.08653" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Textual Data for Fatality Classification in Afghanistan&#x27;s  Armed Conflicts: A BERT Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+H">Hikmatullah Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Momand%2C+Z">Ziaullah Momand</a>, 
<a href="/search/cs?searchtype=author&query=Habibi%2C+P">Parwin Habibi</a>, 
<a href="/search/cs?searchtype=author&query=Ramaki%2C+N">Nazifa Ramaki</a>, 
<a href="/search/cs?searchtype=author&query=Fazli%2C+B+S">Bibi Storay Fazli</a>, 
<a href="/search/cs?searchtype=author&query=Rohany%2C+S+Z">Sayed Zobair Rohany</a>, 
<a href="/search/cs?searchtype=author&query=Samsoor%2C+I">Iqbal Samsoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Afghanistan has witnessed many armed conflicts throughout history, especially
in the past 20 years; these events have had a significant impact on human
lives, including military and civilians, with potential fatalities. In this
research, we aim to leverage state-of-the-art machine learning techniques to
classify the outcomes of Afghanistan armed conflicts to either fatal or
non-fatal based on their textual descriptions provided by the Armed Conflict
Location &amp; Event Data Project (ACLED) dataset. The dataset contains
comprehensive descriptions of armed conflicts in Afghanistan that took place
from August 2021 to March 2023. The proposed approach leverages the power of
BERT (Bidirectional Encoder Representations from Transformers), a cutting-edge
language representation model in natural language processing. The classifier
utilizes the raw textual description of an event to estimate the likelihood of
the event resulting in a fatality. The model achieved impressive performance on
the test set with an accuracy of 98.8%, recall of 98.05%, precision of 99.6%,
and an F1 score of 98.82%. These results highlight the model's robustness and
indicate its potential impact in various areas such as resource allocation,
policymaking, and humanitarian aid efforts in Afghanistan. The model indicates
a machine learning-based text classification approach using the ACLED dataset
to accurately classify fatality in Afghanistan armed conflicts, achieving
robust performance with the BERT model and paving the way for future endeavors
in predicting event severity in Afghanistan.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08654" title="Abstract">arXiv:2310.08654</a> [<a href="/pdf/2310.08654" title="Download PDF">pdf</a>, <a href="/format/2310.08654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Histogram- and Diffusion-Based Medical Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huijben%2C+E+M+C">Evi M.C. Huijben</a>, 
<a href="/search/cs?searchtype=author&query=Amirrajab%2C+S">Sina Amirrajab</a>, 
<a href="/search/cs?searchtype=author&query=Pluim%2C+J+P+W">Josien P.W. Pluim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, submission to Medical Out-of-Distribution (MOOD) challenge at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Out-of-distribution (OOD) detection is crucial for the safety and reliability
of artificial intelligence algorithms, especially in the medical domain. In the
context of the Medical OOD (MOOD) detection challenge 2023, we propose a
pipeline that combines a histogram-based method and a diffusion-based method.
The histogram-based method is designed to accurately detect homogeneous
anomalies in the toy examples of the challenge, such as blobs with constant
intensity values. The diffusion-based method is based on one of the latest
methods for unsupervised anomaly detection, called DDPM-OOD. We explore this
method and propose extensive post-processing steps for pixel-level and
sample-level anomaly detection on brain MRI and abdominal CT data provided by
the challenge. Our results show that the proposed DDPM method is sensitive to
blur and bias field samples, but faces challenges with anatomical deformation,
black slice, and swapped patches. These findings suggest that further research
is needed to improve the performance of DDPM for OOD detection in medical
images.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08656" title="Abstract">arXiv:2310.08656</a> [<a href="/pdf/2310.08656" title="Download PDF">pdf</a>, <a href="/format/2310.08656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SplitBeam: Effective and Efficient Beamforming in Wi-Fi Networks Through  Split Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahadori%2C+N">Niloofar Bahadori</a>, 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
<a href="/search/cs?searchtype=author&query=Levorato%2C+M">Marco Levorato</a>, 
<a href="/search/cs?searchtype=author&query=Restuccia%2C+F">Francesco Restuccia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 43rd IEEE International Conference on Distributed Computing Systems (ICDCS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Modern IEEE 802.11 (Wi-Fi) networks extensively rely on multiple-input
multiple-output (MIMO) to significantly improve throughput. To correctly
beamform MIMO transmissions, the access point needs to frequently acquire a
beamforming matrix (BM) from each connected station. However, the size of the
matrix grows with the number of antennas and subcarriers, resulting in an
increasing amount of airtime overhead and computational load at the station.
Conventional approaches come with either excessive computational load or loss
of beamforming precision. For this reason, we propose SplitBeam, a new
framework where we train a split deep neural network (DNN) to directly output
the BM given the channel state information (CSI) matrix as input. We formulate
and solve a bottleneck optimization problem (BOP) to keep computation, airtime
overhead, and bit error rate (BER) below application requirements. We perform
extensive experimental CSI collection with off-the-shelf Wi-Fi devices in two
distinct environments and compare the performance of SplitBeam with the
standard IEEE 802.11 algorithm for BM feedback and the state-of-the-art
DNN-based approach LB-SciFi. Our experimental results show that SplitBeam
reduces the beamforming feedback size and computational complexity by
respectively up to 81% and 84% while maintaining BER within about 10^-3 of
existing approaches. We also implement the SplitBeam DNNs on FPGA hardware to
estimate the end-to-end BM reporting delay, and show that the latter is less
than 10 milliseconds in the most complex scenario, which is the target channel
sounding frequency in realistic multi-user MIMO scenarios.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08659" title="Abstract">arXiv:2310.08659</a> [<a href="/pdf/2310.08659" title="Download PDF">pdf</a>, <a href="/format/2310.08659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Karampatziakis%2C+N">Nikos Karampatziakis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantization is an indispensable technique for serving Large Language Models
(LLMs) and has recently found its way into LoRA fine-tuning. In this work we
focus on the scenario where quantization and LoRA fine-tuning are applied
together on a pre-trained model. In such cases it is common to observe a
consistent gap in the performance on downstream tasks between full fine-tuning
and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ
(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that
simultaneously quantizes an LLM and finds a proper low-rank initialization for
LoRA fine-tuning. Such an initialization alleviates the discrepancy between the
quantized and full-precision model and significantly improves the
generalization in downstream tasks. We evaluate our method on natural language
understanding, question answering, summarization, and natural language
generation tasks. Experiments show that our method is highly effective and
outperforms existing quantization methods, especially in the challenging 2-bit
and 2/4-bit mixed precision regimes. We will release our code.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08660" title="Abstract">arXiv:2310.08660</a> [<a href="/pdf/2310.08660" title="Download PDF">pdf</a>, <a href="/format/2310.08660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning RL-Policies for Joint Beamforming Without Exploration: A Batch  Constrained Off-Policy Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heasung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ankireddy%2C+S">Sravan Ankireddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this project, we consider the problem of network parameter optimization
for rate maximization. We frame this as a joint optimization problem of power
control, beam forming, and interference cancellation. We consider the setting
where multiple Base Stations (BSs) are communicating with multiple user
equipments (UEs). Because of the exponential computational complexity of brute
force search, we instead solve this non-convex optimization problem using deep
reinforcement learning (RL) techniques. The modern communication systems are
notorious for their difficulty in exactly modeling their behaviour. This limits
us in using RL based algorithms as interaction with the environment is needed
for the agent to explore and learn efficiently. Further, it is ill advised to
deploy the algorithm in real world for exploration and learning because of the
high cost of failure. In contrast to the previous RL-based solutions proposed,
such as deep-Q network (DQN) based control, we propose taking an offline model
based approach. We specifically consider discrete batch constrained deep
Q-learning (BCQ) and show that performance similar to DQN can be acheived with
only a fraction of the data and without the need for exploration. This results
in maximizing sample efficiency and minimizing risk in the deployment of a new
algorithm to commercial networks. We provide the entire resource of the
project, including code and data, at the following link:
https://github.com/Heasung-Kim/ safe-rl-deployment-for-5g.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08661" title="Abstract">arXiv:2310.08661</a> [<a href="/pdf/2310.08661" title="Download PDF">pdf</a>, <a href="/format/2310.08661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting and Algorithmic Generalization with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouellette%2C+S">Simon Ouellette</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+R">Rolf Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Jud%2C+H">Hansueli Jud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, submitted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Algorithmic generalization in machine learning refers to the ability to learn
the underlying algorithm that generates data in a way that generalizes
out-of-distribution. This is generally considered a difficult task for most
machine learning algorithms. Here, we analyze algorithmic generalization when
counting is required, either implicitly or explicitly. We show that standard
Transformers are based on architectural decisions that hinder
out-of-distribution performance for such tasks. In particular, we discuss the
consequences of using layer normalization and of normalizing the attention
weights via softmax. With ablation of the problematic operations, we
demonstrate that a modified transformer can exhibit a good algorithmic
generalization performance on counting while using a very lightweight
architecture.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08662" title="Abstract">arXiv:2310.08662</a> [<a href="/pdf/2310.08662" title="Download PDF">pdf</a>, <a href="/ps/2310.08662" title="Download PostScript">ps</a>, <a href="/format/2310.08662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Stability of Active Disturbance Rejection Control for Linear  SISO Plants with Low Observer Gains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Berneburg%2C+J">James Berneburg</a>, 
<a href="/search/eess?searchtype=author&query=Shishika%2C+D">Daigo Shishika</a>, 
<a href="/search/eess?searchtype=author&query=Nowzari%2C+C">Cameron Nowzari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper theoretically investigates the closed-loop performance of active
disturbance rejection control (ADRC) on a third-order linear plant with
relative degree 3, subject to a class of exogenous disturbances. While PID
control cannot be guaranteed to be capable of stabilizing such plants, ADRC
offers a model-free alternative. However, many existing works on ADRC consider
the observer gains to be taken arbitrarily large, in order to guarantee desired
performance, such as works which consider parameterizing ADRC by bandwidth.
This work finds that, for constant exogenous disturbances, arbitrary eigenvalue
assignment is possible for the closed-loop system under linear ADRC, thus
guaranteeing the existence of an ADRC controller for desired performance
without taking any gains arbitrarily large. We also find that stabilization is
possible when the exogenous disturbance is stable, and show how ADRC can
recover the performance of model-based observers. We demonstrate aspects of the
resulting closed-loop systems under ADRC in simulations.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08669" title="Abstract">arXiv:2310.08669</a> [<a href="/pdf/2310.08669" title="Download PDF">pdf</a>, <a href="/format/2310.08669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Large Language Model for Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y+H">Yao-Hung Hubert Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Dhar%2C+V">Vansh Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Recent efforts to enable visual navigation using large language models have
mainly focused on developing complex prompt systems. These systems incorporate
instructions, observations, and history into massive text prompts, which are
then combined with pre-trained large language models to facilitate visual
navigation. In contrast, our approach aims to fine-tune large language models
for visual navigation without extensive prompt engineering. Our design involves
a simple text prompt, current observations, and a history collector model that
gathers information from previous observations as input. For output, our design
provides a probability distribution of possible actions that the agent can take
during navigation. We train our model using human demonstrations and collision
signals from the Habitat-Matterport 3D Dataset (HM3D). Experimental results
demonstrate that our method outperforms state-of-the-art behavior cloning
methods and effectively reduces collision rates.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08670" title="Abstract">arXiv:2310.08670</a> [<a href="/pdf/2310.08670" title="Download PDF">pdf</a>, <a href="/format/2310.08670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Every Parameter Matters: Ensuring the Convergence of Federated Learning  with Dynamic Heterogeneous Models Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanhan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Venkataramani%2C+G">Guru Venkataramani</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenbo Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. arXiv admin note: text overlap with <a href="/abs/2201.11803">arXiv:2201.11803</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Cross-device Federated Learning (FL) faces significant challenges where
low-end clients that could potentially make unique contributions are excluded
from training large models due to their resource bottlenecks. Recent research
efforts have focused on model-heterogeneous FL, by extracting reduced-size
models from the global model and applying them to local clients accordingly.
Despite the empirical success, general theoretical guarantees of convergence on
this method remain an open question. In this paper, we present a unifying
framework for heterogeneous FL algorithms with online model extraction and
provide a general convergence analysis. In particular, we prove that under
certain sufficient conditions and for both IID and non-IID data, these
algorithms converge to a stationary point of standard FL for general smooth
cost functions. Moreover, we illuminate two key factors impacting its
convergence: model-extraction noise and minimum coverage index, advocating a
joint design of local model extraction for efficient heterogeneous FL.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08671" title="Abstract">arXiv:2310.08671</a> [<a href="/pdf/2310.08671" title="Download PDF">pdf</a>, <a href="/format/2310.08671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSG2: A new modelling paradigm for semantic segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakogiannis%2C+F+I">Foivos I. Diakogiannis</a>, 
<a href="/search/cs?searchtype=author&query=Furby%2C+S">Suzanne Furby</a>, 
<a href="/search/cs?searchtype=author&query=Caccetta%2C+P">Peter Caccetta</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoliang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ibata%2C+R">Rodrigo Ibata</a>, 
<a href="/search/cs?searchtype=author&query=Hlinka%2C+O">Ondrej Hlinka</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+J">John Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">State-of-the-art models in semantic segmentation primarily operate on single,
static images, generating corresponding segmentation masks. This one-shot
approach leaves little room for error correction, as the models lack the
capability to integrate multiple observations for enhanced accuracy. Inspired
by work on semantic change detection, we address this limitation by introducing
a methodology that leverages a sequence of observables generated for each
static input image. By adding this "temporal" dimension, we exploit strong
signal correlations between successive observations in the sequence to reduce
error rates. Our framework, dubbed SSG2 (Semantic Segmentation Generation 2),
employs a dual-encoder, single-decoder base network augmented with a sequence
model. The base model learns to predict the set intersection, union, and
difference of labels from dual-input images. Given a fixed target input image
and a set of support images, the sequence model builds the predicted mask of
the target by synthesizing the partial views from each sequence step and
filtering out noise. We evaluate SSG2 across three diverse datasets:
UrbanMonitor, featuring orthoimage tiles from Darwin, Australia with five
spectral bands and 0.2m spatial resolution; ISPRS Potsdam, which includes true
orthophoto images with multiple spectral bands and a 5cm ground sampling
distance; and ISIC2018, a medical dataset focused on skin lesion segmentation,
particularly melanoma. The SSG2 model demonstrates rapid convergence within the
first few tens of epochs and significantly outperforms UNet-like baseline
models with the same number of gradient updates. However, the addition of the
temporal dimension results in an increased memory footprint. While this could
be a limitation, it is offset by the advent of higher-memory GPUs and coding
optimizations.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08674" title="Abstract">arXiv:2310.08674</a> [<a href="/pdf/2310.08674" title="Download PDF">pdf</a>, <a href="/ps/2310.08674" title="Download PostScript">ps</a>, <a href="/format/2310.08674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pay Attention to How You Drive: Safe and Adaptive Model-Based  Reinforcement Learning for Off-Road Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S+J">Sean J. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Honghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous off-road driving is challenging as risky actions taken by the
robot may lead to catastrophic damage. As such, developing controllers in
simulation is often desirable as it provides a safer and more economical
alternative. However, accurately modeling robot dynamics is difficult due to
the complex robot dynamics and terrain interactions in unstructured
environments. Domain randomization addresses this problem by randomizing
simulation dynamics parameters, however this approach sacrifices performance
for robustness leading to policies that are sub-optimal for any target
dynamics. We introduce a novel model-based reinforcement learning approach that
aims to balance robustness with adaptability. Our approach trains a System
Identification Transformer (SIT) and an Adaptive Dynamics Model (ADM) under a
variety of simulated dynamics. The SIT uses attention mechanisms to distill
state-transition observations from the target system into a context vector,
which provides an abstraction for its target dynamics. Conditioned on this, the
ADM probabilistically models the system's dynamics. Online, we use a Risk-Aware
Model Predictive Path Integral controller (MPPI) to safely control the robot
under its current understanding of the dynamics. We demonstrate in simulation
as well as in multiple real-world environments that this approach enables safer
behaviors upon initialization and becomes less conservative (i.e. faster) as
its understanding of the target system dynamics improves with more
observations. In particular, our approach results in an approximately 41%
improvement in lap-time over the non-adaptive baseline while remaining safe
across different environments.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08677" title="Abstract">arXiv:2310.08677</a> [<a href="/pdf/2310.08677" title="Download PDF">pdf</a>, <a href="/format/2310.08677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GDL-DS: A Benchmark for Geometric Deep Learning under Distribution  Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Deyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+S">Siqi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+V">Victor Fung</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data are available at <a href="https://github.com/Graph-COM/GDL_DS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Geometric deep learning (GDL) has gained significant attention in various
scientific fields, chiefly for its proficiency in modeling data with intricate
geometric structures. Yet, very few works have delved into its capability of
tackling the distribution shift problem, a prevalent challenge in many relevant
applications. To bridge this gap, we propose GDL-DS, a comprehensive benchmark
designed for evaluating the performance of GDL models in scenarios with
distribution shifts. Our evaluation datasets cover diverse scientific domains
from particle physics and materials science to biochemistry, and encapsulate a
broad spectrum of distribution shifts including conditional, covariate, and
concept shifts. Furthermore, we study three levels of information access from
the out-of-distribution (OOD) testing data, including no OOD information, only
OOD features without labels, and OOD features with a few labels. Overall, our
benchmark results in 30 different experiment settings, and evaluates 3 GDL
backbones and 11 learning algorithms in each setting. A thorough analysis of
the evaluation results is provided, poised to illuminate insights for DGL
researchers and domain practitioners who are to use DGL in their applications.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08678" title="Abstract">arXiv:2310.08678</a> [<a href="/pdf/2310.08678" title="Download PDF">pdf</a>, <a href="/format/2310.08678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4  on mock CFA Exams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Callanan%2C+E">Ethan Callanan</a>, 
<a href="/search/cs?searchtype=author&query=Mbakwe%2C+A">Amarachi Mbakwe</a>, 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+A">Antony Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yulong Pei</a>, 
<a href="/search/cs?searchtype=author&query=Sibue%2C+M">Mathieu Sibue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaodan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiqiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaomo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sameena Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); General Finance (q-fin.GN)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable performance on a
wide range of Natural Language Processing (NLP) tasks, often matching or even
beating state-of-the-art task-specific models. This study aims at assessing the
financial reasoning capabilities of LLMs. We leverage mock exam questions of
the Chartered Financial Analyst (CFA) Program to conduct a comprehensive
evaluation of ChatGPT and GPT-4 in financial analysis, considering Zero-Shot
(ZS), Chain-of-Thought (CoT), and Few-Shot (FS) scenarios. We present an
in-depth analysis of the models' performance and limitations, and estimate
whether they would have a chance at passing the CFA exams. Finally, we outline
insights into potential strategies and improvements to enhance the
applicability of LLMs in finance. In this perspective, we hope this work paves
the way for future studies to continue enhancing LLMs for financial reasoning
through rigorous evaluation.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08679" title="Abstract">arXiv:2310.08679</a> [<a href="/pdf/2310.08679" title="Download PDF">pdf</a>, <a href="/ps/2310.08679" title="Download PostScript">ps</a>, <a href="/format/2310.08679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Invariance for Reference Governors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kashani%2C+A">Ali Kashani</a>, 
<a href="/search/eess?searchtype=author&query=Danielson%2C+C">Claus Danielson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a novel approach to synthesizing positive invariant sets
for unmodeled nonlinear systems using direct data-driven techniques. The
data-driven invariant sets are used to design a data-driven reference governor
that selects a reference for the closed-loop system to enforce constraints.
Using kernel-basis functions, we solve a semi-definite program to learn a
sum-of-squares Lyapunov-like function whose unity level-set is a constraint
admissible positive invariant set, which determines the constraint admissible
states as well as reference inputs. Leveraging Lipschitz properties of the
system, we prove that tightening the model-based design ensures robustness of
the data-driven invariant set to the inherent plant uncertainty in a
data-driven framework. To mitigate the curse-of-dimensionality, we repose the
semi-definite program into a linear program. We validate our approach through
two examples: First, we present an illustrative example where we can
analytically compute the maximum positive invariant set and compare with the
presented data-driven invariant set. Second, we present a practical autonomous
driving scenario to demonstrate the utility of the presented method for
nonlinear systems.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08680" title="Abstract">arXiv:2310.08680</a> [<a href="/pdf/2310.08680" title="Download PDF">pdf</a>, <a href="/format/2310.08680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Resilient MPC Scheme via Constraint Tightening against  Cyberattacks: Application to Vehicle Cruise Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Farsi%2C+M">Milad Farsi</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+S">Shuhao Bian</a>, 
<a href="/search/eess?searchtype=author&query=Azad%2C+N+L">Nasser L. Azad</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+X">Xiaobing Shi</a>, 
<a href="/search/eess?searchtype=author&query=Walenstein%2C+A">Andrew Walenstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in ICINCO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose a novel framework for designing a resilient Model Predictive
Control (MPC) targeting uncertain linear systems under cyber attack. Assuming a
periodic attack scenario, we model the system under Denial of Service (DoS)
attack, also with measurement noise, as an uncertain linear system with
parametric and additive uncertainty. To detect anomalies, we employ a Kalman
filter-based approach. Then, through our observations of the intensity of the
launched attack, we determine a range of possible values for the system
matrices, as well as establish bounds of the additive uncertainty for the
equivalent uncertain system. Leveraging a recent constraint tightening robust
MPC method, we present an optimization-based resilient algorithm. Accordingly,
we compute the uncertainty bounds and corresponding constraints offline for
various attack magnitudes. Then, this data can be used efficiently in the MPC
computations online. We demonstrate the effectiveness of the developed
framework on the Adaptive Cruise Control (ACC) problem.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08681" title="Abstract">arXiv:2310.08681</a> [<a href="/pdf/2310.08681" title="Download PDF">pdf</a>, <a href="/format/2310.08681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-Safe: Securing Federated Learning in Healthcare Against Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darzi%2C+E">Erfan Darzi</a>, 
<a href="/search/cs?searchtype=author&query=Sijtsema%2C+N+M">Nanna M. Sijtsema</a>, 
<a href="/search/cs?searchtype=author&query=van+Ooijen%2C+P+M+A">P.M.A van Ooijen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper explores the security aspects of federated learning applications
in medical image analysis. Current robustness-oriented methods like adversarial
training, secure aggregation, and homomorphic encryption often risk privacy
compromises. The central aim is to defend the network against potential privacy
breaches while maintaining model robustness against adversarial manipulations.
We show that incorporating distributed noise, grounded in the privacy
guarantees in federated settings, enables the development of a adversarially
robust model that also meets federated privacy standards. We conducted
comprehensive evaluations across diverse attack scenarios, parameters, and use
cases in cancer imaging, concentrating on pathology, meningioma, and glioma.
The results reveal that the incorporation of distributed noise allows for the
attainment of security levels comparable to those of conventional adversarial
training while requiring fewer retraining samples to establish a robust model.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08683" title="Abstract">arXiv:2310.08683</a> [<a href="/pdf/2310.08683" title="Download PDF">pdf</a>, <a href="/ps/2310.08683" title="Download PostScript">ps</a>, <a href="/format/2310.08683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Augmented Reality for Atari Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schiller%2C+C+A">Christian A. Schiller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages (thereof 13 in appendix), 4 figures, 15 tables (thereof 12 in appendix), 12 Atari games explored
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement Learning (RL) has achieved significant milestones in the gaming
domain, most notably Google DeepMind's AlphaGo defeating human Go champion Ken
Jie. This victory was also made possible through the Atari Learning Environment
(ALE): The ALE has been foundational in RL research, facilitating significant
RL algorithm developments such as AlphaGo and others. In current Atari video
game RL research, RL agents' perceptions of its environment is based on raw
pixel data from the Atari video game screen with minimal image preprocessing.
Contrarily, cutting-edge ML research, external to the Atari video game RL
research domain, is focusing on enhancing image perception. A notable example
is Meta Research's "Segment Anything Model" (SAM), a foundation model capable
of segmenting images without prior training (zero-shot). This paper addresses a
novel methodical question: Can state-of-the-art image segmentation models such
as SAM improve the performance of RL agents playing Atari video games? The
results suggest that SAM can serve as a "virtual augmented reality" for the RL
agent, boosting its Atari video game playing performance under certain
conditions. Comparing RL agent performance results from raw and augmented pixel
inputs provides insight into these conditions. Although this paper was limited
by computational constraints, the findings show improved RL agent performance
for augmented pixel inputs and can inform broader research agendas in the
domain of "virtual augmented reality for video game playing RL agents".
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08685" title="Abstract">arXiv:2310.08685</a> [<a href="/pdf/2310.08685" title="Download PDF">pdf</a>, <a href="/format/2310.08685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel-Elastic Autoencoder for Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haote Li</a>, 
<a href="/search/cs?searchtype=author&query=Shee%2C+Y">Yu Shee</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+B">Brandon Allen</a>, 
<a href="/search/cs?searchtype=author&query=Maschietto%2C+F">Federica Maschietto</a>, 
<a href="/search/cs?searchtype=author&query=Batista%2C+V">Victor Batista</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce the Kernel-Elastic Autoencoder (KAE), a self-supervised
generative model based on the transformer architecture with enhanced
performance for molecular design. KAE is formulated based on two novel loss
functions: modified maximum mean discrepancy and weighted reconstruction. KAE
addresses the long-standing challenge of achieving valid generation and
accurate reconstruction at the same time. KAE achieves remarkable diversity in
molecule generation while maintaining near-perfect reconstructions on the
independent testing dataset, surpassing previous molecule-generating models.
KAE enables conditional generation and allows for decoding based on beam search
resulting in state-of-the-art performance in constrained optimizations.
Furthermore, KAE can generate molecules conditional to favorable binding
affinities in docking applications as confirmed by AutoDock Vina and Glide
scores, outperforming all existing candidates from the training dataset. Beyond
molecular design, we anticipate KAE could be applied to solve problems by
generation in a wide range of applications.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08686" title="Abstract">arXiv:2310.08686</a> [<a href="/pdf/2310.08686" title="Download PDF">pdf</a>, <a href="/format/2310.08686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot IMU Preintegration in the Presence of Bias and Communication  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shalaby%2C+M+A">Mohammed Ayman Shalaby</a>, 
<a href="/search/cs?searchtype=author&query=Cossette%2C+C+C">Charles Champagne Cossette</a>, 
<a href="/search/cs?searchtype=author&query=Ny%2C+J+L">Jerome Le Ny</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+J+R">James Richard Forbes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This document is in supplement to the paper titled "Multi-Robot Relative Pose
Estimation and IMU Preintegration Using Passive UWB Transceivers", available at
[1]. The purpose of this document is to show how IMU biases can be incorporated
into the framework presented in [1], while maintaining the differential
Sylvester equation form of the process model.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08687" title="Abstract">arXiv:2310.08687</a> [<a href="/pdf/2310.08687" title="Download PDF">pdf</a>, <a href="/format/2310.08687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding How to Inform Blind and Low-Vision Users about Data  Privacy through Privacy Question Answering Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuanyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yaxing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rex Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+S">Shomir Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Sadeh%2C+N">Norman Sadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research paper is accepted by USENIX Security '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Understanding and managing data privacy in the digital world can be
challenging for sighted users, let alone blind and low-vision (BLV) users.
There is limited research on how BLV users, who have special accessibility
needs, navigate data privacy, and how potential privacy tools could assist
them. We conducted an in-depth qualitative study with 21 US BLV participants to
understand their data privacy risk perception and mitigation, as well as their
information behaviors related to data privacy. We also explored BLV users'
attitudes towards potential privacy question answering (Q&amp;A) assistants that
enable them to better navigate data privacy information. We found that BLV
users face heightened security and privacy risks, but their risk mitigation is
often insufficient. They do not necessarily seek data privacy information but
clearly recognize the benefits of a potential privacy Q&amp;A assistant. They also
expect privacy Q&amp;A assistants to possess cross-platform compatibility, support
multi-modality, and demonstrate robust functionality. Our study sheds light on
BLV users' expectations when it comes to usability, accessibility, trust and
equity issues regarding digital data privacy.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08689" title="Abstract">arXiv:2310.08689</a> [<a href="/pdf/2310.08689" title="Download PDF">pdf</a>, <a href="/format/2310.08689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Craig Interpolation for Decidable First-Order Fragments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cate%2C+B+t">Balder ten Cate</a>, 
<a href="/search/cs?searchtype=author&query=Comer%2C+J">Jesse Comer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for FoSSaCS 2024. arXiv admin note: substantial text overlap with <a href="/abs/2304.08086">arXiv:2304.08086</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We show that the guarded-negation fragment (GNFO) is, in a precise sense, the
smallest extension of the guarded fragment (GFO) with Craig interpolation. In
contrast, we show that the smallest extension of the two-variable fragment
(FO2), and of the forward fragment (FF) with Craig interpolation, is full
first-order logic. Similarly, we also show that all extensions of FO2 and of
the fluted fragment (FL) with Craig interpolation are undecidable.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08691" title="Abstract">arXiv:2310.08691</a> [<a href="/pdf/2310.08691" title="Download PDF">pdf</a>, <a href="/format/2310.08691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Transmission: A Comprehensive Review of Concepts, Technologies,  and Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mirzapour%2C+O">Omid Mirzapour</a>, 
<a href="/search/eess?searchtype=author&query=Rui%2C+X">Xinyang Rui</a>, 
<a href="/search/eess?searchtype=author&query=Pruneau%2C+B">Brittany Pruneau</a>, 
<a href="/search/eess?searchtype=author&query=Sahraei-Ardakani%2C+M">Mostafa Sahraei-Ardakani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As global concerns regarding climate change are increasing worldwide, the
transition towards clean energy sources has accelerated. Accounting for a large
share of energy consumption, the electricity sector is experiencing a
significant shift towards renewable energy sources. To accommodate this rapid
shift, the transmission system requires major upgrades. Although enhancing grid
capacity through transmission system expansion is always a solution, this
solution is very costly and requires a protracted permitting process. The
concept of flexible transmission encompasses a broad range of technologies and
market tools that enable effective reconfiguration and manipulation of the
power grid for leveraged dispatch of renewable energy resources. The
proliferation of such technologies allows for enhanced transfer capability over
the current transmission network, thus reducing the need for grid expansion
projects. This paper comprehensively reviews flexible transmission technologies
and their role in achieving a net-zero carbon emission grid vision. Flexible
transmission definitions from different viewpoints are discussed, and
mathematical measures to quantify grid flexibility are reviewed. An extensive
range of technologies enhancing flexibility across the grid is introduced and
explored in detail. The environmental impacts of flexible transmission,
including renewable energy utilization and carbon emission reduction, are
presented. Finally, market models required for creating proper incentives for
the deployment of flexible transmission and regulatory barriers and challenges
are discussed.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08697" title="Abstract">arXiv:2310.08697</a> [<a href="/pdf/2310.08697" title="Download PDF">pdf</a>, <a href="/format/2310.08697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Data Lakehouse: Data Warehousing and More
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+D">Dipankar Mazumdar</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+J">Jason Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Onofre%2C+J">JB Onofre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Relational Database Management Systems designed for Online Analytical
Processing (RDBMS-OLAP) have been foundational to democratizing data and
enabling analytical use cases such as business intelligence and reporting for
many years. However, RDBMS-OLAP systems present some well-known challenges.
They are primarily optimized only for relational workloads, lead to
proliferation of data copies which can become unmanageable, and since the data
is stored in proprietary formats, it can lead to vendor lock-in, restricting
access to engines, tools, and capabilities beyond what the vendor offers. As
the demand for data-driven decision making surges, the need for a more robust
data architecture to address these challenges becomes ever more critical. Cloud
data lakes have addressed some of the shortcomings of RDBMS-OLAP systems, but
they present their own set of challenges. More recently, organizations have
often followed a two-tier architectural approach to take advantage of both
these platforms, leveraging both cloud data lakes and RDBMS-OLAP systems.
However, this approach brings additional challenges, complexities, and
overhead. This paper discusses how a data lakehouse, a new architectural
approach, achieves the same benefits of an RDBMS-OLAP and cloud data lake
combined, while also providing additional advantages. We take today's data
warehousing and break it down into implementation independent components,
capabilities, and practices. We then take these aspects and show how a
lakehouse architecture satisfies them. Then, we go a step further and discuss
what additional capabilities and benefits a lakehouse architecture provides
over an RDBMS-OLAP.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08699" title="Abstract">arXiv:2310.08699</a> [<a href="/pdf/2310.08699" title="Download PDF">pdf</a>, <a href="/format/2310.08699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLadder: Supporting Programmers with Hierarchical Code Generation in  Multi-Level Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yen%2C+R">Ryan Yen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiawen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+S">Sangho Suh</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haijun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Programmers increasingly rely on Large Language Models (LLMs) for code
generation. However, they now have to deal with issues like having to
constantly switch between generating and verifying code, caused by misalignment
between programmers' prompts and the generated code. Unfortunately, current
LLM-driven code assistants provide insufficient support during the prompt
authoring process to help programmers tackle these challenges emerging from the
new workflow. To address these challenges, we employed an iterative design
process to understand programmers' strategies when programming with LLMs. Based
on our findings, we developed CoLadder, a system that assists programmers by
enabling hierarchical task decomposition, incremental code generation, and
verification of results during prompt authoring. A user study with 12
experienced programmers showed that CoLadder is effective in helping
programmers externalize their mental models flexibly, improving their ability
to navigate and edit code across various abstraction levels, from initial
intent to final code implementation.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08701" title="Abstract">arXiv:2310.08701</a> [<a href="/pdf/2310.08701" title="Download PDF">pdf</a>, <a href="/format/2310.08701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biased news sharing and partisan polarization on social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=del+Pozo%2C+S+M">Sof&#xed;a M del Pozo</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+S">Sebasti&#xe1;n Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Serafino%2C+M">Matteo Serafino</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+L">Lucio Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Makse%2C+H+A">Hern&#xe1;n A Makse</a>, 
<a href="/search/cs?searchtype=author&query=Balenzuela%2C+P">Pablo Balenzuela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">In the ever-connected digital landscape, news dissemination on social media
platforms serves as a vital source of information for the public. However, this
flow of information is far from unbiased. It is deeply influenced by the
political inclinations of the users who share news as well as the inherent
biases present in the news outlets themselves. These biases in news consumption
play a significant role in the creation of echo chambers and the reinforcement
of beliefs. This phenomenon, in turn, influences the voting intentions of the
population during critical electoral periods. In this study, we use a metric
called "Sentiment Bias", a tool designed to classify news outlets according to
their biases. We explore the impact of this metric on various levels, ranging
from news outlets to individual user biases. Our metric, while simple, unveils
a well-known trend: users prefer news aligning with their political beliefs.
Its power lies in extending this insight to specific topics. Users consistently
share articles related to subjects that echo their favored candidates,
illuminating a deeper layer of political alignment in online discourse.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08702" title="Abstract">arXiv:2310.08702</a> [<a href="/pdf/2310.08702" title="Download PDF">pdf</a>, <a href="/format/2310.08702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELDEN: Exploration via Local Dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zizhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/cs?searchtype=author&query=Martin-Martin%2C+R">Roberto Martin-Martin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Tasks with large state space and sparse rewards present a longstanding
challenge to reinforcement learning. In these tasks, an agent needs to explore
the state space efficiently until it finds a reward. To deal with this problem,
the community has proposed to augment the reward function with intrinsic
reward, a bonus signal that encourages the agent to visit interesting states.
In this work, we propose a new way of defining interesting states for
environments with factored state spaces and complex chained dependencies, where
an agent's actions may change the value of one entity that, in order, may
affect the value of another entity. Our insight is that, in these environments,
interesting states for exploration are states where the agent is uncertain
whether (as opposed to how) entities such as the agent or objects have some
influence on each other. We present ELDEN, Exploration via Local DepENdencies,
a novel intrinsic reward that encourages the discovery of new interactions
between entities. ELDEN utilizes a novel scheme -- the partial derivative of
the learned dynamics to model the local dependencies between entities
accurately and computationally efficiently. The uncertainty of the predicted
dependencies is then used as an intrinsic reward to encourage exploration
toward new interactions. We evaluate the performance of ELDEN on four different
domains with complex dependencies, ranging from 2D grid worlds to 3D robotic
tasks. In all domains, ELDEN correctly identifies local dependencies and learns
successful policies, significantly outperforming previous state-of-the-art
exploration methods.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08705" title="Abstract">arXiv:2310.08705</a> [<a href="/pdf/2310.08705" title="Download PDF">pdf</a>, <a href="/format/2310.08705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmarking Protocol for SAR Colorization: From Regression to Deep  Learning Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kangqing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Vivone%2C+G">Gemine Vivone</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lolli%2C+S">Simone Lolli</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+M">Michael Schmitt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Synthetic aperture radar (SAR) images are widely used in remote sensing.
Interpreting SAR images can be challenging due to their intrinsic speckle noise
and grayscale nature. To address this issue, SAR colorization has emerged as a
research direction to colorize gray scale SAR images while preserving the
original spatial information and radiometric information. However, this
research field is still in its early stages, and many limitations can be
highlighted. In this paper, we propose a full research line for supervised
learning-based approaches to SAR colorization. Our approach includes a protocol
for generating synthetic color SAR images, several baselines, and an effective
method based on the conditional generative adversarial network (cGAN) for SAR
colorization. We also propose numerical assessment metrics for the problem at
hand. To our knowledge, this is the first attempt to propose a research line
for SAR colorization that includes a protocol, a benchmark, and a complete
performance evaluation. Our extensive tests demonstrate the effectiveness of
our proposed cGAN-based network for SAR colorization. The code will be made
publicly available.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08708" title="Abstract">arXiv:2310.08708</a> [<a href="/pdf/2310.08708" title="Download PDF">pdf</a>, <a href="/format/2310.08708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial Time Cryptanalytic Extraction of Neural Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shamir%2C+A">Adi Shamir</a>, 
<a href="/search/cs?searchtype=author&query=Canales-Martinez%2C+I">Isaac Canales-Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Hambitzer%2C+A">Anna Hambitzer</a>, 
<a href="/search/cs?searchtype=author&query=Chavez-Saab%2C+J">Jorge Chavez-Saab</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigez-Henriquez%2C+F">Francisco Rodrigez-Henriquez</a>, 
<a href="/search/cs?searchtype=author&query=Satpute%2C+N">Nitin Satpute</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Billions of dollars and countless GPU hours are currently spent on training
Deep Neural Networks (DNNs) for a variety of tasks. Thus, it is essential to
determine the difficulty of extracting all the parameters of such neural
networks when given access to their black-box implementations. Many versions of
this problem have been studied over the last 30 years, and the best current
attack on ReLU-based deep neural networks was presented at Crypto 2020 by
Carlini, Jagielski, and Mironov. It resembles a differential chosen plaintext
attack on a cryptosystem, which has a secret key embedded in its black-box
implementation and requires a polynomial number of queries but an exponential
amount of time (as a function of the number of neurons). In this paper, we
improve this attack by developing several new techniques that enable us to
extract with arbitrarily high precision all the real-valued parameters of a
ReLU-based DNN using a polynomial number of queries and a polynomial amount of
time. We demonstrate its practical efficiency by applying it to a full-sized
neural network for classifying the CIFAR10 dataset, which has 3072 inputs, 8
hidden layers with 256 neurons each, and over million neuronal parameters. An
attack following the approach by Carlini et al. requires an exhaustive search
over 2 to the power 256 possibilities. Our attack replaces this with our new
techniques, which require only 30 minutes on a 256-core computer.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08710" title="Abstract">arXiv:2310.08710</a> [<a href="/pdf/2310.08710" title="Download PDF">pdf</a>, <a href="/format/2310.08710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Waymax: An Accelerated, Data-Driven Simulator for Large-Scale Autonomous  Driving Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gulino%2C+C">Cole Gulino</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Justin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+G">George Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+E">Eli Bronstein</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yiren Lu</a>, 
<a href="/search/cs?searchtype=author&query=Harb%2C+J">Jean Harb</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xinlei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Co-Reyes%2C+J+D">John D. Co-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Roelofs%2C+R">Rebecca Roelofs</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Montali%2C+N">Nico Montali</a>, 
<a href="/search/cs?searchtype=author&query=Mougin%2C+P">Paul Mougin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zoey Yang</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+B">Brandyn White</a>, 
<a href="/search/cs?searchtype=author&query=Faust%2C+A">Aleksandra Faust</a>, 
<a href="/search/cs?searchtype=author&query=McAllister%2C+R">Rowan McAllister</a>, 
<a href="/search/cs?searchtype=author&query=Anguelov%2C+D">Dragomir Anguelov</a>, 
<a href="/search/cs?searchtype=author&query=Sapp%2C+B">Benjamin Sapp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Simulation is an essential tool to develop and benchmark autonomous vehicle
planning software in a safe and cost-effective manner. However, realistic
simulation requires accurate modeling of nuanced and complex multi-agent
interactive behaviors. To address these challenges, we introduce Waymax, a new
data-driven simulator for autonomous driving in multi-agent scenes, designed
for large-scale simulation and testing. Waymax uses publicly-released,
real-world driving data (e.g., the Waymo Open Motion Dataset) to initialize or
play back a diverse set of multi-agent simulated scenarios. It runs entirely on
hardware accelerators such as TPUs/GPUs and supports in-graph simulation for
training, making it suitable for modern large-scale, distributed machine
learning workflows. To support online training and evaluation, Waymax includes
several learned and hard-coded behavior models that allow for realistic
interaction within simulation. To supplement Waymax, we benchmark a suite of
popular imitation and reinforcement learning algorithms with ablation studies
on different design decisions, where we highlight the effectiveness of routes
as guidance for planning agents and the ability of RL to overfit against
simulated agents.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08712" title="Abstract">arXiv:2310.08712</a> [<a href="/pdf/2310.08712" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Equilibrium of Joint Day-ahead Electricity Markets and Forward  Contracts in Congested Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Banaei%2C+M">Mohsen Banaei</a>, 
<a href="/search/eess?searchtype=author&query=Buygi%2C+M+O">Majid Oloomi Buygi</a>, 
<a href="/search/eess?searchtype=author&query=Raouf-Sheybani%2C+H">Hani Raouf-Sheybani</a>, 
<a href="/search/eess?searchtype=author&query=Ebrahimy%2C+R">Razgar Ebrahimy</a>, 
<a href="/search/eess?searchtype=author&query=Madsen%2C+H">Henrik Madsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Uncertainty in the output power of large-scale wind power plants (WPPs) can
face the electricity market players with undesirable profit variations. Market
players can hedge themselves against these risks by participating in forward
contracts markets alongside the day-ahead markets. The participation of market
players in these two markets affects their profits and also the prices and
power quantities of each market. Moreover, limitations in the transmission grid
can affect the optimal behavior of market players. In this paper, a Cournot
Nash equilibrium model is proposed to study the behavior of market players in
the forward contract market and the day-ahead electricity market in a congested
power system with large-scale integration of WPPs. The proposed method is
applied to a test system, and the results are discussed.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08714" title="Abstract">arXiv:2310.08714</a> [<a href="/pdf/2310.08714" title="Download PDF">pdf</a>, <a href="/format/2310.08714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Flexible and Efficient Temporal Logic Tool for Python: PyTeLo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardona%2C+G+A">Gustavo A. Cardona</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+K">Kevin Leahy</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+M">Makai Mann</a>, 
<a href="/search/cs?searchtype=author&query=Vasile%2C+C">Cristian-Ioan Vasile</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Temporal logic is an important tool for specifying complex behaviors of
systems. It can be used to define properties for verification and monitoring,
as well as goals for synthesis tools, allowing users to specify rich missions
and tasks. Some of the most popular temporal logics include Metric Temporal
Logic (MTL), Signal Temporal Logic (STL), and weighted STL (wSTL), which also
allow the definition of timing constraints. In this work, we introduce PyTeLo,
a modular and versatile Python-based software that facilitates working with
temporal logic languages, specifically MTL, STL, and wSTL. Applying PyTeLo
requires only a string representation of the temporal logic specification and,
optionally, the dynamics of the system of interest. Next, PyTeLo reads the
specification using an ANTLR-generated parser and generates an Abstract Syntax
Tree (AST) that captures the structure of the formula. For synthesis, the AST
serves to recursively encode the specification into a Mixed Integer Linear
Program (MILP) that is solved using a commercial solver such as Gurobi. We
describe the architecture and capabilities of PyTeLo and provide example
applications highlighting its adaptability and extensibility for various
research problems.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08715" title="Abstract">arXiv:2310.08715</a> [<a href="/pdf/2310.08715" title="Download PDF">pdf</a>, <a href="/format/2310.08715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Joint Language Modeling for Speech Units and Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+J">Ju-Chieh Chou</a>, 
<a href="/search/cs?searchtype=author&query=Chien%2C+C">Chung-Ming Chien</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wei-Ning Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Livescu%2C+K">Karen Livescu</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A">Arun Babu</a>, 
<a href="/search/cs?searchtype=author&query=Conneau%2C+A">Alexis Conneau</a>, 
<a href="/search/cs?searchtype=author&query=Baevski%2C+A">Alexei Baevski</a>, 
<a href="/search/cs?searchtype=author&query=Auli%2C+M">Michael Auli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech and text are two major forms of human language. The research community
has been focusing on mapping speech to text or vice versa for many years.
However, in the field of language modeling, very little effort has been made to
model them jointly. In light of this, we explore joint language modeling for
speech units and text. Specifically, we compare different speech tokenizers to
transform continuous speech signals into discrete units and use different
methods to construct mixed speech-text data. We introduce automatic metrics to
evaluate how well the joint LM mixes speech and text. We also fine-tune the LM
on downstream spoken language understanding (SLU) tasks with different
modalities (speech or text) and test its performance to assess the model's
learning of shared representations. Our results show that by mixing speech
units and text with our proposed mixing techniques, the joint LM improves over
a speech-only baseline on SLU tasks and shows zero-shot cross-modal
transferability.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08716" title="Abstract">arXiv:2310.08716</a> [<a href="/pdf/2310.08716" title="Download PDF">pdf</a>, <a href="/format/2310.08716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Choice Net: A Transformer Neural Network for Choice  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaocheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Talluri%2C+K">Kalyan Talluri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Discrete-choice models, such as Multinomial Logit, Probit, or Mixed-Logit,
are widely used in Marketing, Economics, and Operations Research: given a set
of alternatives, the customer is modeled as choosing one of the alternatives to
maximize a (latent) utility function. However, extending such models to
situations where the customer chooses more than one item (such as in e-commerce
shopping) has proven problematic. While one can construct reasonable models of
the customer's behavior, estimating such models becomes very challenging
because of the combinatorial explosion in the number of possible subsets of
items. In this paper we develop a transformer neural network architecture, the
Transformer Choice Net, that is suitable for predicting multiple choices.
Transformer networks turn out to be especially suitable for this task as they
take into account not only the features of the customer and the items but also
the context, which in this case could be the assortment as well as the
customer's past choices. On a range of benchmark datasets, our architecture
shows uniformly superior out-of-sample prediction performance compared to the
leading models in the literature, without requiring any custom modeling or
tuning for each instance.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08725" title="Abstract">arXiv:2310.08725</a> [<a href="/pdf/2310.08725" title="Download PDF">pdf</a>, <a href="/ps/2310.08725" title="Download PostScript">ps</a>, <a href="/format/2310.08725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterophily-Based Graph Neural Network for Imbalanced Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zirui Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianjin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+A">Akrati Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yulong Pei</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Twelfth International Conference on Complex Networks &amp; Their Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have shown promise in addressing graph-related
problems, including node classification. However, conventional GNNs assume an
even distribution of data across classes, which is often not the case in
real-world scenarios, where certain classes are severely underrepresented. This
leads to suboptimal performance of standard GNNs on imbalanced graphs. In this
paper, we introduce a unique approach that tackles imbalanced classification on
graphs by considering graph heterophily. We investigate the intricate
relationship between class imbalance and graph heterophily, revealing that
minority classes not only exhibit a scarcity of samples but also manifest lower
levels of homophily, facilitating the propagation of erroneous information
among neighboring nodes. Drawing upon this insight, we propose an efficient
method, called Fast Im-GBK, which integrates an imbalance classification
strategy with heterophily-aware GNNs to effectively address the class imbalance
problem while significantly reducing training time. Our experiments on
real-world graphs demonstrate our model's superiority in classification
performance and efficiency for node classification tasks compared to existing
baselines.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08731" title="Abstract">arXiv:2310.08731</a> [<a href="/pdf/2310.08731" title="Download PDF">pdf</a>, <a href="/format/2310.08731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Way to Incorporate Novelty Detection in World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zollicoffer%2C+G">Geigh Zollicoffer</a>, 
<a href="/search/cs?searchtype=author&query=Eaton%2C+K">Kenneth Eaton</a>, 
<a href="/search/cs?searchtype=author&query=Balloch%2C+J">Jonathan Balloch</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Julia Kim</a>, 
<a href="/search/cs?searchtype=author&query=Riedl%2C+M+O">Mark O. Riedl</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+R">Robert Wright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement learning (RL) using world models has found significant recent
successes. However, when a sudden change to world mechanics or properties
occurs then agent performance and reliability can dramatically decline. We
refer to the sudden change in visual properties or state transitions as {\em
novelties}. Implementing novelty detection within generated world model
frameworks is a crucial task for protecting the agent when deployed. In this
paper, we propose straightforward bounding approaches to incorporate novelty
detection into world model RL agents, by utilizing the misalignment of the
world model's hallucinated states and the true observed states as an anomaly
score. We first provide an ontology of novelty detection relevant to sequential
decision making, then we provide effective approaches to detecting novelties in
a distribution of transitions learned by an agent in a world model. Finally, we
show the advantage of our work in a novel environment compared to traditional
machine learning novelty detection methods as well as currently accepted RL
focused novelty detection algorithms.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08732" title="Abstract">arXiv:2310.08732</a> [<a href="/pdf/2310.08732" title="Download PDF">pdf</a>, <a href="/format/2310.08732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Robust Cost-Sensitive Learning via Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yuan Xin</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We focus on learning adversarially robust classifiers under a cost-sensitive
scenario, where the potential harm of different classwise adversarial
transformations is encoded in a binary cost matrix. Existing methods are either
empirical that cannot certify robustness or suffer from inherent scalability
issues. In this work, we study whether randomized smoothing, a more scalable
robustness certification framework, can be leveraged to certify cost-sensitive
robustness. Built upon a notion of cost-sensitive certified radius, we show how
to adapt the standard randomized smoothing certification pipeline to produce
tight robustness guarantees for any cost matrix. In addition, with fine-grained
certified radius optimization schemes specifically designed for different data
subgroups, we propose an algorithm to train smoothed classifiers that are
optimized for cost-sensitive robustness. Extensive experiments on image
benchmarks and a real-world medical dataset demonstrate the superiority of our
method in achieving significantly improved performance of certified
cost-sensitive robustness while having a negligible impact on overall accuracy.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08737" title="Abstract">arXiv:2310.08737</a> [<a href="/pdf/2310.08737" title="Download PDF">pdf</a>, <a href="/format/2310.08737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Event Detection with Random Forests and Temporal Convolutional  Networks for More Sustainable Petroleum Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yuanwei Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Baifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Waaler%2C+A">Arild Waaler</a>, 
<a href="/search/cs?searchtype=author&query=Cameron%2C+D">David Cameron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at PRICAI 2023 AI-Impact Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The petroleum industry is crucial for modern society, but the production
process is complex and risky. During the production, accidents or failures,
resulting from undesired production events, can cause severe environmental and
economic damage. Previous studies have investigated machine learning (ML)
methods for undesired event detection. However, the prediction of event
probability in real-time was insufficiently addressed, which is essential since
it is important to undertake early intervention when an event is expected to
happen. This paper proposes two ML approaches, random forests and temporal
convolutional networks, to detect undesired events in real-time. Results show
that our approaches can effectively classify event types and predict the
probability of their appearance, addressing the challenges uncovered in
previous studies and providing a more effective solution for failure event
management during the production.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08738" title="Abstract">arXiv:2310.08738</a> [<a href="/pdf/2310.08738" title="Download PDF">pdf</a>, <a href="/format/2310.08738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splicing Up Your Predictions with RNA Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fradkin%2C+P">Philip Fradkin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+B">Brendan Frey</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+L+J">Leo J. Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN)

</div>
<p class="mathjax">In the face of rapidly accumulating genomic data, our understanding of the
RNA regulatory code remains incomplete. Recent self-supervised methods in other
domains have demonstrated the ability to learn rules underlying the
data-generating process such as sentence structure in language. Inspired by
this, we extend contrastive learning techniques to genomic data by utilizing
functional similarities between sequences generated through alternative
splicing and gene duplication. Our novel dataset and contrastive objective
enable the learning of generalized RNA isoform representations. We validate
their utility on downstream tasks such as RNA half-life and mean ribosome load
prediction. Our pre-training strategy yields competitive results using linear
probing on both tasks, along with up to a two-fold increase in Pearson
correlation in low-data conditions. Importantly, our exploration of the learned
latent space reveals that our contrastive objective yields semantically
meaningful representations, underscoring its potential as a valuable
initialization technique for RNA property prediction.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08739" title="Abstract">arXiv:2310.08739</a> [<a href="/pdf/2310.08739" title="Download PDF">pdf</a>, <a href="/format/2310.08739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks  on DFL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Celdran%2C+A+H">Alberto Huertas Celdran</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+M">Michael Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Bovet%2C+G">Gerome Bovet</a>, 
<a href="/search/cs?searchtype=author&query=Stiller%2C+B">Burkhard Stiller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The growing concern over malicious attacks targeting the robustness of both
centralized and decentralized federated learning (FL) necessitates novel
defensive strategies. In contrast to the centralized approach, decentralized FL
(DFL) has the advantage of utilizing network topology and local dataset,
enabling the exploration of moving target defense (MTD) based approaches. This
work presents a theoretical analysis of the influence of network topology on
the rubostness of DFL models. Drawing inspiration from these findings, a
three-stage MTD-based aggregation protocol, called as Voyager, is proposed to
improve the resilience of DFL against poisoning attacks through the
manipulation of network topology connectivity. Voyager has three main
components: an anomaly detector, a network topology explorer, and a connection
deployer. When an abnormal model is detected in the network, the topology
explorer responds strategically by forming connections with more trustworthy
participants to secure the model. Experimental evaluations show that Voyager
effectively mitigates various poisoning attacks without imposing significant
resource and computational burdens on participants. These findings highlight
the proposed reactive MTD as a potent defense mechanism in the context of DFL.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08740" title="Abstract">arXiv:2310.08740</a> [<a href="/pdf/2310.08740" title="Download PDF">pdf</a>, <a href="/format/2310.08740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Zero-Shot Language Agent for Computer Control with Structured  Reflection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bryan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Large language models (LLMs) have shown increasing capacity at planning and
executing a high-level goal in a live computer environment (e.g. MiniWoB++). To
perform a task, recent works often require a model to learn from trace examples
of the task via either supervised learning or few/many-shot prompting. Without
these trace examples, it remains a challenge how an agent can autonomously
learn and improve its control on a computer, which limits the ability of an
agent to perform a new task. We approach this problem with a zero-shot agent
that requires no given expert traces. Our agent plans for executable actions on
a partially observed environment, and iteratively progresses a task by
identifying and learning from its mistakes via self-reflection and structured
thought management. On the easy tasks of MiniWoB++, we show that our zero-shot
agent often outperforms recent SoTAs, with more efficient reasoning. For tasks
with more complexity, our reflective agent performs on par with prior best
models, even though previous works had the advantages of accessing expert
traces or additional screen information.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08743" title="Abstract">arXiv:2310.08743</a> [<a href="/pdf/2310.08743" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and Validation of a Deep Learning-Based Microsatellite  Instability Predictor from Prostate Cancer Whole-Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+A+A">Abbas A. Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Schau%2C+G">Geoffery Schau</a>, 
<a href="/search/cs?searchtype=author&query=Ingale%2C+K">Kshitij Ingale</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+Y">Yoni Muller</a>, 
<a href="/search/cs?searchtype=author&query=Baits%2C+R">Rachel Baits</a>, 
<a href="/search/cs?searchtype=author&query=Pretzer%2C+S">Sebastian Pretzer</a>, 
<a href="/search/cs?searchtype=author&query=BenTaieb%2C+A">A&#xef;cha BenTaieb</a>, 
<a href="/search/cs?searchtype=author&query=Gordhamer%2C+A">Abigail Gordhamer</a>, 
<a href="/search/cs?searchtype=author&query=Nussenzveig%2C+R">Roberto Nussenzveig</a>, 
<a href="/search/cs?searchtype=author&query=Cole%2C+A">Adam Cole</a>, 
<a href="/search/cs?searchtype=author&query=Leavitt%2C+M+O">Matthew O. Leavitt</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R+P">Rohan P. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Beaubier%2C+N">Nike Beaubier</a>, 
<a href="/search/cs?searchtype=author&query=Stumpe%2C+M+C">Martin C. Stumpe</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+K">Kunal Nagpal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Microsatellite instability-high (MSI-H) is a tumor agnostic biomarker for
immune checkpoint inhibitor therapy. However, MSI status is not routinely
tested in prostate cancer, in part due to low prevalence and assay cost. As
such, prediction of MSI status from hematoxylin and eosin (H&amp;E) stained
whole-slide images (WSIs) could identify prostate cancer patients most likely
to benefit from confirmatory testing and becoming eligible for immunotherapy.
Prostate biopsies and surgical resections from de-identified records of
consecutive prostate cancer patients referred to our institution were analyzed.
Their MSI status was determined by next generation sequencing. Patients before
a cutoff date were split into an algorithm development set (n=4015, MSI-H 1.8%)
and a paired validation set (n=173, MSI-H 19.7%) that consisted of two serial
sections from each sample, one stained and scanned internally and the other at
an external site. Patients after the cutoff date formed the temporal validation
set (n=1350, MSI-H 2.3%). Attention-based multiple instance learning models
were trained to predict MSI-H from H&amp;E WSIs. The MSI-H predictor achieved area
under the receiver operating characteristic curve values of 0.78 (95% CI
[0.69-0.86]), 0.72 (95% CI [0.63-0.81]), and 0.72 (95% CI [0.62-0.82]) on the
internally prepared, externally prepared, and temporal validation sets,
respectively. While MSI-H status is significantly correlated with Gleason
score, the model remained predictive within each Gleason score subgroup. In
summary, we developed and validated an AI-based MSI-H diagnostic model on a
large real-world cohort of routine H&amp;E slides, which effectively generalized to
externally stained and scanned samples and a temporally independent validation
cohort. This algorithm has the potential to direct prostate cancer patients
toward immunotherapy and to identify MSI-H cases secondary to Lynch syndrome.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08744" title="Abstract">arXiv:2310.08744</a> [<a href="/pdf/2310.08744" title="Download PDF">pdf</a>, <a href="/format/2310.08744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circuit Component Reuse Across Tasks in Transformer Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merullo%2C+J">Jack Merullo</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+C">Carsten Eickhoff</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work in mechanistic interpretability has shown that behaviors in
language models can be successfully reverse-engineered through circuit
analysis. A common criticism, however, is that each circuit is task-specific,
and thus such analysis cannot contribute to understanding the models at a
higher level. In this work, we present evidence that insights (both low-level
findings about specific heads and higher-level findings about general
algorithms) can indeed generalize across tasks. Specifically, we study the
circuit discovered in Wang et al. (2022) for the Indirect Object Identification
(IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that
it is mostly reused to solve a seemingly different task: Colored Objects
(Ippolito &amp; Callison-Burch, 2023). We provide evidence that the process
underlying both tasks is functionally very similar, and contains about a 78%
overlap in in-circuit attention heads. We further present a proof-of-concept
intervention experiment, in which we adjust four attention heads in middle
layers in order to 'repair' the Colored Objects circuit and make it behave like
the IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the
Colored Objects task and explain most sources of error. The intervention
affects downstream attention heads in specific ways predicted by their
interactions in the IOI circuit, indicating that this subcircuit behavior is
invariant to the different task inputs. Overall, our results provide evidence
that it may yet be possible to explain large language models' behavior in terms
of a relatively small number of interpretable task-general algorithmic building
blocks and computational components.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08745" title="Abstract">arXiv:2310.08745</a> [<a href="/pdf/2310.08745" title="Download PDF">pdf</a>, <a href="/format/2310.08745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AcTExplore: Active Tactile Exploration on Unknown Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahidzadeh%2C+A">Amir-Hossein Shahidzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S+J">Seong Jong Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Mantripragada%2C+P">Pavan Mantripragada</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+C+D">Chahat Deep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ferm%C3%BCller%2C+C">Cornelia Ferm&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Aloimonos%2C+Y">Yiannis Aloimonos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Tactile exploration plays a crucial role in understanding object structures
for fundamental robotics tasks such as grasping and manipulation. However,
efficiently exploring such objects using tactile sensors is challenging,
primarily due to the large-scale unknown environments and limited sensing
coverage of these sensors. To this end, we present AcTExplore, an active
tactile exploration method driven by reinforcement learning for object
reconstruction at scales that automatically explores the object surfaces in a
limited number of steps. Through sufficient exploration, our algorithm
incrementally collects tactile data and reconstructs 3D shapes of the objects
as well, which can serve as a representation for higher-level downstream tasks.
Our method achieves an average of 95.97% IoU coverage on unseen YCB objects
while just being trained on primitive shapes.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08746" title="Abstract">arXiv:2310.08746</a> [<a href="/pdf/2310.08746" title="Download PDF">pdf</a>, <a href="/format/2310.08746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness to Multi-Modal Environment Uncertainty in MARL using  Curriculum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Aakriti Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Aralikatti%2C+R">Rohith Aralikatti</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanchao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-agent reinforcement learning (MARL) plays a pivotal role in tackling
real-world challenges. However, the seamless transition of trained policies
from simulations to real-world requires it to be robust to various
environmental uncertainties. Existing works focus on finding Nash Equilibrium
or the optimal policy under uncertainty in one environment variable (i.e.
action, state or reward). This is because a multi-agent system itself is highly
complex and unstationary. However, in real-world situation uncertainty can
occur in multiple environment variables simultaneously. This work is the first
to formulate the generalised problem of robustness to multi-modal environment
uncertainty in MARL. To this end, we propose a general robust training approach
for multi-modal uncertainty based on curriculum learning techniques. We handle
two distinct environmental uncertainty simultaneously and present extensive
results across both cooperative and competitive MARL environments,
demonstrating that our approach achieves state-of-the-art levels of robustness.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08748" title="Abstract">arXiv:2310.08748</a> [<a href="/pdf/2310.08748" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Dynamic Optimization and Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boulesnane%2C+A">Abdennour Boulesnane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Evolutionary Computation (EC) has emerged as a powerful field of Artificial
Intelligence, inspired by nature's mechanisms of gradual development. However,
EC approaches often face challenges such as stagnation, diversity loss,
computational complexity, population initialization, and premature convergence.
To overcome these limitations, researchers have integrated learning algorithms
with evolutionary techniques. This integration harnesses the valuable data
generated by EC algorithms during iterative searches, providing insights into
the search space and population dynamics. Similarly, the relationship between
evolutionary algorithms and Machine Learning (ML) is reciprocal, as EC methods
offer exceptional opportunities for optimizing complex ML tasks characterized
by noisy, inaccurate, and dynamic objective functions. These hybrid techniques,
known as Evolutionary Machine Learning (EML), have been applied at various
stages of the ML process. EC techniques play a vital role in tasks such as data
balancing, feature selection, and model training optimization. Moreover, ML
tasks often require dynamic optimization, for which Evolutionary Dynamic
Optimization (EDO) is valuable. This paper presents the first comprehensive
exploration of reciprocal integration between EDO and ML. The study aims to
stimulate interest in the evolutionary learning community and inspire
innovative contributions in this domain.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08750" title="Abstract">arXiv:2310.08750</a> [<a href="/pdf/2310.08750" title="Download PDF">pdf</a>, <a href="/format/2310.08750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search-Adaptor: Text Embedding Customization for Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jinsung Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Arik%2C+S+O">Sercan O Arik</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Text embeddings extracted by pre-trained Large Language Models (LLMs) have
significant potential to improve information retrieval and search. Beyond the
zero-shot setup in which they are being conventionally used, being able to take
advantage of the information from the relevant query-corpus paired data has the
power to further boost the LLM capabilities. In this paper, we propose a novel
method, Search-Adaptor, for customizing LLMs for information retrieval in an
efficient and robust way. Search-Adaptor modifies the original text embedding
generated by pre-trained LLMs, and can be integrated with any LLM, including
those only available via APIs. On multiple real-world English and multilingual
retrieval datasets, we show consistent and significant performance benefits for
Search-Adaptor -- e.g., more than 5.2% improvements over the Google Embedding
APIs in nDCG@10 averaged over 13 BEIR datasets.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08751" title="Abstract">arXiv:2310.08751</a> [<a href="/pdf/2310.08751" title="Download PDF">pdf</a>, <a href="/format/2310.08751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Bayesian Optimization with Adaptive Active Learning of  Unknown Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fengxue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zejie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Optimizing objectives under constraints, where both the objectives and
constraints are black box functions, is a common scenario in real-world
applications such as scientific experimental design, design of medical
therapies, and industrial process optimization. One popular approach to
handling these complex scenarios is Bayesian Optimization (BO). In terms of
theoretical behavior, BO is relatively well understood in the unconstrained
setting, where its principles have been well explored and validated. However,
when it comes to constrained Bayesian optimization (CBO), the existing
framework often relies on heuristics or approximations without the same level
of theoretical guarantees.
<br />In this paper, we delve into the theoretical and practical aspects of
constrained Bayesian optimization, where the objective and constraints can be
independently evaluated and are subject to noise. By recognizing that both the
objective and constraints can help identify high-confidence regions of interest
(ROI), we propose an efficient CBO framework that intersects the ROIs
identified from each aspect to determine the general ROI. The ROI, coupled with
a novel acquisition function that adaptively balances the optimization of the
objective and the identification of feasible regions, enables us to derive
rigorous theoretical justifications for its performance. We showcase the
efficiency and robustness of our proposed CBO framework through empirical
evidence and discuss the fundamental challenge of deriving practical regret
bounds for CBO algorithms.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08752" title="Abstract">arXiv:2310.08752</a> [<a href="/pdf/2310.08752" title="Download PDF">pdf</a>, <a href="/ps/2310.08752" title="Download PostScript">ps</a>, <a href="/format/2310.08752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-free Massive MIMO and SWIPT: Access Point Operation Mode Selection  and Power Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mohammadali Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Le-Nam Tran</a>, 
<a href="/search/cs?searchtype=author&query=Mobini%2C+Z">Zahra Mobini</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, to be presented at GLOBECOM 2023, Kuala Lumpur
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies cell-free massive multiple-input multiple-output
(CF-mMIMO) systems incorporating simultaneous wireless information and power
transfer (SWIPT) for separate information users (IUs) and energy users (EUs) in
Internet of Things (IoT) networks. To optimize both the spectral efficiency
(SE) of IUs and harvested energy (HE) of EUs, we propose a joint access point
(AP) operation mode selection and power control design, wherein certain APs are
designated for energy transmission to EUs, while others are dedicated to
information transmission to IUs. We investigate the problem of maximizing the
total HE for EUs, considering constraints on SE for individual IUs and minimum
HE for individual EUs. Our numerical results showcase that the proposed AP
operation mode selection algorithm can provide up to $76\%$ and $130\%$
performance gains over random AP operation mode selection with and without
power control, respectively.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08753" title="Abstract">arXiv:2310.08753</a> [<a href="/pdf/2310.08753" title="Download PDF">pdf</a>, <a href="/format/2310.08753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompA: Addressing the Gap in Compositional Reasoning in Audio-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sreyan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+A">Ashish Seth</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sonal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+U">Utkarsh Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Evuru%2C+C+K">Chandra Kiran Evuru</a>, 
<a href="/search/cs?searchtype=author&query=Ramaneswaran%2C+S">S. Ramaneswaran</a>, 
<a href="/search/cs?searchtype=author&query=Sakshi%2C+S">S. Sakshi</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+O">Oriol Nieto</a>, 
<a href="/search/cs?searchtype=author&query=Duraiswami%2C+R">Ramani Duraiswami</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A fundamental characteristic of audio is its compositional nature.
Audio-language models (ALMs) trained using a contrastive approach (e.g., CLAP)
that learns a shared representation between audio and language modalities have
improved performance in many downstream applications, including zero-shot audio
classification, audio retrieval, etc. However, the ability of these models to
effectively perform compositional reasoning remains largely unexplored and
necessitates additional research. In this paper, we propose CompA, a collection
of two expert-annotated benchmarks with a majority of real-world audio samples,
to evaluate compositional reasoning in ALMs. Our proposed CompA-order evaluates
how well an ALM understands the order or occurrence of acoustic events in
audio, and CompA-attribute evaluates attribute binding of acoustic events. An
instance from either benchmark consists of two audio-caption pairs, where both
audios have the same acoustic events but with different compositions. An ALM is
evaluated on how well it matches the right audio to the right caption. Using
this benchmark, we first show that current ALMs perform only marginally better
than random chance, thereby struggling with compositional reasoning. Next, we
propose CompA-CLAP, where we fine-tune CLAP using a novel learning method to
improve its compositional reasoning abilities. To train CompA-CLAP, we first
propose improvements to contrastive training with composition-aware hard
negatives, allowing for more focused training. Next, we propose a novel modular
contrastive loss that helps the model learn fine-grained compositional
understanding and overcomes the acute scarcity of openly available
compositional audios. CompA-CLAP significantly improves over all our baseline
models on the CompA benchmark, indicating its superior compositional reasoning
capabilities.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08754" title="Abstract">arXiv:2310.08754</a> [<a href="/pdf/2310.08754" title="Download PDF">pdf</a>, <a href="/format/2310.08754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tokenizer Choice For LLM Training: Negligible or Crucial?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mehdi Ali</a>, 
<a href="/search/cs?searchtype=author&query=Fromm%2C+M">Michael Fromm</a>, 
<a href="/search/cs?searchtype=author&query=Thellmann%2C+K">Klaudia Thellmann</a>, 
<a href="/search/cs?searchtype=author&query=Rutmann%2C+R">Richard Rutmann</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCbbering%2C+M">Max L&#xfc;bbering</a>, 
<a href="/search/cs?searchtype=author&query=Leveling%2C+J">Johannes Leveling</a>, 
<a href="/search/cs?searchtype=author&query=Klug%2C+K">Katrin Klug</a>, 
<a href="/search/cs?searchtype=author&query=Ebert%2C+J">Jan Ebert</a>, 
<a href="/search/cs?searchtype=author&query=Doll%2C+N">Niclas Doll</a>, 
<a href="/search/cs?searchtype=author&query=Buschhoff%2C+J+S">Jasper Schulze Buschhoff</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+C">Charvi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+A+A">Alexander Arno Weber</a>, 
<a href="/search/cs?searchtype=author&query=Jurkschat%2C+L">Lena Jurkschat</a>, 
<a href="/search/cs?searchtype=author&query=Abdelwahab%2C+H">Hammam Abdelwahab</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+C">Chelsea John</a>, 
<a href="/search/cs?searchtype=author&query=Suarez%2C+P+O">Pedro Ortiz Suarez</a>, 
<a href="/search/cs?searchtype=author&query=Ostendorff%2C+M">Malte Ostendorff</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>, 
<a href="/search/cs?searchtype=author&query=Kesselheim%2C+S">Stefan Kesselheim</a>, 
<a href="/search/cs?searchtype=author&query=Flores-Herr%2C+N">Nicolas Flores-Herr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The recent success of LLMs has been predominantly driven by curating the
training dataset composition, scaling of model architectures and dataset sizes
and advancements in pretraining objectives, leaving tokenizer influence as a
blind spot. Shedding light on this underexplored area, we conduct a
comprehensive study on the influence of tokenizer choice on LLM downstream
performance by training 24 mono- and multilingual LLMs at a 2.6B parameter
scale, ablating different tokenizer algorithms and parameterizations. Our
studies highlight that the tokenizer choice can significantly impact the
model's downstream performance, training and inference costs. In particular, we
find that the common tokenizer evaluation metrics fertility and parity are not
always predictive of model downstream performance, rendering these metrics a
questionable choice for tokenizer evaluation. Furthermore, we show that
multilingual tokenizers trained on the five most frequent European languages
require vocabulary size increases of factor three in comparison to English.
While English-only tokenizers have been applied to the training of
multi-lingual LLMs in the past, we find that this approach results in a severe
downstream performance degradation and additional training costs of up to 68%,
due to an inefficient tokenization vocabulary.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08755" title="Abstract">arXiv:2310.08755</a> [<a href="/pdf/2310.08755" title="Download PDF">pdf</a>, <a href="/format/2310.08755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PU-Ray: Point Cloud Upsampling via Ray Marching on Implicit Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Sangwon Lim</a>, 
<a href="/search/cs?searchtype=author&query=El-Basyouny%2C+K">Karim El-Basyouny</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y+H">Yee Hong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages (10 main + 3 supplement), 19 figures (10 main + 9 supplement), 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">While the recent advancements in deep-learning-based point cloud upsampling
methods improve the input to autonomous driving systems, they still suffer from
the uncertainty of denser point generation resulting from end-to-end learning.
For example, due to the vague training objectives of the models, their
performance depends on the point distributions of the input and the ground
truth. This causes problems of domain dependency between synthetic and
real-scanned point clouds and issues with substantial model sizes and dataset
requirements. Additionally, many existing methods upsample point clouds with a
fixed scaling rate, making them inflexible and computationally redundant. This
paper addresses the above problems by proposing a ray-based upsampling approach
with an arbitrary rate, where a depth prediction is made for each query ray.
The method simulates the ray marching algorithm to achieve more precise and
stable ray-depth predictions through implicit surface learning. The rule-based
mid-point query sampling method enables a uniform output point distribution
without requiring model training using the Chamfer distance loss function,
which can exhibit bias towards the training dataset. Self-supervised learning
becomes possible with accurate ground truths within the input point cloud. The
results demonstrate the method's versatility across different domains and
training scenarios with limited computational resources and training data. This
allows the upsampling task to transition from academic research to real-world
applications.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08757" title="Abstract">arXiv:2310.08757</a> [<a href="/pdf/2310.08757" title="Download PDF">pdf</a>, <a href="/format/2310.08757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and prediction of clopidogrel treatment failures using  longitudinal structured electronic health records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Samuel Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I+G+S">In Gu Sean Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+M+I">Mijeong Irene Ban</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+J">Jane Chiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose machine learning algorithms to automatically detect and predict
clopidogrel treatment failure using longitudinal structured electronic health
records (EHR). By drawing analogies between natural language and structured
EHR, we introduce various machine learning algorithms used in natural language
processing (NLP) applications to build models for treatment failure detection
and prediction. In this regard, we generated a cohort of patients with
clopidogrel prescriptions from UK Biobank and annotated if the patients had
treatment failure events within one year of the first clopidogrel prescription;
out of 502,527 patients, 1,824 patients were identified as treatment failure
cases, and 6,859 patients were considered as control cases. From the dataset,
we gathered diagnoses, prescriptions, and procedure records together per
patient and organized them into visits with the same date to build models. The
models were built for two different tasks, i.e., detection and prediction, and
the experimental results showed that time series models outperform bag-of-words
approaches in both tasks. In particular, a Transformer-based model, namely
BERT, could reach 0.928 AUC in detection tasks and 0.729 AUC in prediction
tasks. BERT also showed competence over other time series models when there is
not enough training data, because it leverages the pre-training procedure using
large unlabeled data.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08759" title="Abstract">arXiv:2310.08759</a> [<a href="/pdf/2310.08759" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question Answering for Electronic Health Records: A Scoping Review of  datasets and models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bardhan%2C+J">Jayetri Bardhan</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+K">Kirk Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D+Z">Daisy Zhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Question Answering (QA) systems on patient-related data can assist both
clinicians and patients. They can, for example, assist clinicians in
decision-making and enable patients to have a better understanding of their
medical history. Significant amounts of patient data are stored in Electronic
Health Records (EHRs), making EHR QA an important research area. In EHR QA, the
answer is obtained from the medical record of the patient. Because of the
differences in data format and modality, this differs greatly from other
medical QA tasks that employ medical websites or scientific papers to retrieve
answers, making it critical to research EHR question answering. This study
aimed to provide a methodological review of existing works on QA over EHRs. We
searched for articles from January 1st, 2005 to September 30th, 2023 in four
digital sources including Google Scholar, ACL Anthology, ACM Digital Library,
and PubMed to collect relevant publications on EHR QA. 4111 papers were
identified for our study, and after screening based on our inclusion criteria,
we obtained a total of 47 papers for further study. Out of the 47 papers, 25
papers were about EHR QA datasets, and 37 papers were about EHR QA models. It
was observed that QA on EHRs is relatively new and unexplored. Most of the
works are fairly recent. Also, it was observed that emrQA is by far the most
popular EHR QA dataset, both in terms of citations and usage in other papers.
Furthermore, we identified the different models used in EHR QA along with the
evaluation metrics used for these models.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08762" title="Abstract">arXiv:2310.08762</a> [<a href="/pdf/2310.08762" title="Download PDF">pdf</a>, <a href="/format/2310.08762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Subject Transfer in EEG Classification with Divergence  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smedemark-Margulies%2C+N">Niklas Smedemark-Margulies</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Koike-Akino%2C+T">Toshiaki Koike-Akino</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Parsons%2C+K">Kieran Parsons</a>, 
<a href="/search/cs?searchtype=author&query=Bicer%2C+Y">Yunus Bicer</a>, 
<a href="/search/cs?searchtype=author&query=Erdogmus%2C+D">Deniz Erdogmus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Classification models for electroencephalogram (EEG) data show a large
decrease in performance when evaluated on unseen test sub jects. We reduce this
performance decrease using new regularization techniques during model training.
We propose several graphical models to describe an EEG classification task.
From each model, we identify statistical relationships that should hold true in
an idealized training scenario (with infinite data and a globally-optimal
model) but that may not hold in practice. We design regularization penalties to
enforce these relationships in two stages. First, we identify suitable proxy
quantities (divergences such as Mutual Information and Wasserstein-1) that can
be used to measure statistical independence and dependence relationships.
Second, we provide algorithms to efficiently estimate these quantities during
training using secondary neural network models. We conduct extensive
computational experiments using a large benchmark EEG dataset, comparing our
proposed techniques with a baseline method that uses an adversarial classifier.
We find our proposed methods significantly increase balanced accuracy on test
subjects and decrease overfitting. The proposed methods exhibit a larger
benefit over a greater range of hyperparameters than the baseline method, with
only a small computational cost at training time. These benefits are largest
when used for a fixed training period, though there is still a significant
benefit for a subset of hyperparameters when our techniques are used in
conjunction with early stopping regularization.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08764" title="Abstract">arXiv:2310.08764</a> [<a href="/pdf/2310.08764" title="Download PDF">pdf</a>, <a href="/format/2310.08764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating Likelihoods towards Consistency in Summarization Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zablotskaia%2C+P">Polina Zablotskaia</a>, 
<a href="/search/cs?searchtype=author&query=Khalman%2C+M">Misha Khalman</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Rishabh Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+L+B">Livio Baldini Soares</a>, 
<a href="/search/cs?searchtype=author&query=Jakobovits%2C+S">Shoshana Jakobovits</a>, 
<a href="/search/cs?searchtype=author&query=Maynez%2C+J">Joshua Maynez</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+S">Shashi Narayan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the recent advances in abstractive text summarization, current
summarization models still suffer from generating factually inconsistent
summaries, reducing their utility for real-world application. We argue that the
main reason for such behavior is that the summarization models trained with
maximum likelihood objective assign high probability to plausible sequences
given the context, but they often do not accurately rank sequences by their
consistency. In this work, we solve this problem by calibrating the likelihood
of model generated sequences to better align with a consistency metric measured
by natural language inference (NLI) models. The human evaluation study and
automatic metrics show that the calibrated models generate more consistent and
higher-quality summaries. We also show that the models trained using our method
return probabilities that are better aligned with the NLI scores, which
significantly increase reliability of summarization models.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08772" title="Abstract">arXiv:2310.08772</a> [<a href="/pdf/2310.08772" title="Download PDF">pdf</a>, <a href="/format/2310.08772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Robustness and Properties of Detection Transformers  (DETR) Toward Difficult Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z+N">Zhao Ning Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+R">Robert Wijaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transformer-based object detectors (DETR) have shown significant performance
across machine vision tasks, ultimately in object detection. This detector is
based on a self-attention mechanism along with the transformer encoder-decoder
architecture to capture the global context in the image. The critical issue to
be addressed is how this model architecture can handle different image
nuisances, such as occlusion and adversarial perturbations. We studied this
issue by measuring the performance of DETR with different experiments and
benchmarking the network with convolutional neural network (CNN) based
detectors like YOLO and Faster-RCNN. We found that DETR performs well when it
comes to resistance to interference from information loss in occlusion images.
Despite that, we found that the adversarial stickers put on the image require
the network to produce a new unnecessary set of keys, queries, and values,
which in most cases, results in a misdirection of the network. DETR also
performed poorer than YOLOv5 in the image corruption benchmark. Furthermore, we
found that DETR depends heavily on the main query when making a prediction,
which leads to imbalanced contributions between queries since the main query
receives most of the gradient flow.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08773" title="Abstract">arXiv:2310.08773</a> [<a href="/pdf/2310.08773" title="Download PDF">pdf</a>, <a href="/format/2310.08773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Potential and Pitfalls of ChatGPT in Science and  Engineering Problem-Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K+D">Karen D. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Burkholder%2C+E">Eric Burkholder</a>, 
<a href="/search/cs?searchtype=author&query=Wieman%2C+C">Carl Wieman</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+S">Shima Salehi</a>, 
<a href="/search/cs?searchtype=author&query=Haber%2C+N">Nick Haber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The study explores the capabilities of OpenAI's ChatGPT in solving different
types of physics problems. ChatGPT (with GPT-4) was queried to solve a total of
40 problems from a college-level engineering physics course. These problems
ranged from well-specified problems, where all data required for solving the
problem was provided, to under-specified, real-world problems where not all
necessary data were given. Our findings show that ChatGPT could successfully
solve 62.5\% of the well-specified problems, but its accuracy drops to 8.3\%
for under-specified problems. Analysis of the model's incorrect solutions
revealed three distinct failure modes: 1) failure to construct accurate models
of the physical world, 2) failure to make reasonable assumptions about missing
data, and 3) calculation errors. The study offers implications for how to
leverage LLM-augmented instructional materials to enhance STEM education. The
insights also contribute to the broader discourse on AI's strengths and
limitations, serving both educators aiming to leverage the technology and
researchers investigating human-AI collaboration frameworks for problem-solving
and decision-making.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08775" title="Abstract">arXiv:2310.08775</a> [<a href="/pdf/2310.08775" title="Download PDF">pdf</a>, <a href="/ps/2310.08775" title="Download PostScript">ps</a>, <a href="/format/2310.08775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Machine Learning Models Leak: An Exploration of Synthetic Training  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slokom%2C+M">Manel Slokom</a>, 
<a href="/search/cs?searchtype=author&query=de+Wolf%2C+P">Peter-Paul de Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+M">Martha Larson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We investigate an attack on a machine learning model that predicts whether a
person or household will relocate in the next two years, i.e., a
propensity-to-move classifier. The attack assumes that the attacker can query
the model to obtain predictions and that the marginal distribution of the data
on which the model was trained is publicly available. The attack also assumes
that the attacker has obtained the values of non-sensitive attributes for a
certain number of target individuals. The objective of the attack is to infer
the values of sensitive attributes for these target individuals. We explore how
replacing the original data with synthetic data when training the model impacts
how successfully the attacker can infer sensitive attributes.\footnote{Original
paper published at PSD 2022. The paper was subsequently updated.}
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08778" title="Abstract">arXiv:2310.08778</a> [<a href="/pdf/2310.08778" title="Download PDF">pdf</a>, <a href="/format/2310.08778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Self-Localization of Drones using a Single Millimeter-Wave Anchor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lam%2C+M">Maisy Lam</a>, 
<a href="/search/cs?searchtype=author&query=Dodds%2C+L">Laura Dodds</a>, 
<a href="/search/cs?searchtype=author&query=Eid%2C+A">Aline Eid</a>, 
<a href="/search/cs?searchtype=author&query=Hester%2C+J">Jimmy Hester</a>, 
<a href="/search/cs?searchtype=author&query=Adib%2C+F">Fadel Adib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present the design, implementation, and evaluation of MiFly, a
self-localization system for autonomous drones that works across indoor and
outdoor environments, including low-visibility, dark, and GPS-denied settings.
MiFly performs 6DoF self-localization by leveraging a single millimeter-wave
(mmWave) anchor in its vicinity - even if that anchor is visually occluded.
MmWave signals are used in radar and 5G systems and can operate in the dark and
through occlusions. MiFly introduces a new mmWave anchor design and mounts
light-weight high-resolution mmWave radars on a drone. By jointly designing the
localization algorithms and the novel low-power mmWave anchor hardware
(including its polarization and modulation), the drone is capable of high-speed
3D localization. Furthermore, by intelligently fusing the location estimates
from its mmWave radars and its IMUs, it can accurately and robustly track its
6DoF trajectory. We implemented and evaluated MiFly on a DJI drone. We
demonstrate a median localization error of 7cm and a 90th percentile less than
15cm, even when the anchor is fully occluded (visually) from the drone.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08779" title="Abstract">arXiv:2310.08779</a> [<a href="/pdf/2310.08779" title="Download PDF">pdf</a>, <a href="/ps/2310.08779" title="Download PostScript">ps</a>, <a href="/format/2310.08779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Completeness Theorem for Probabilistic Regular Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B3%C5%BCowski%2C+W">Wojciech R&#xf3;&#x17c;owski</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Alexandra Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We introduce Probabilistic Regular Expressions (PRE), a probabilistic
analogue of regular expressions denoting probabilistic languages in which every
word is assigned a probability of being generated. We present and prove the
completeness of an inference system for reasoning about probabilistic language
equivalence of PRE based on Salomaa's axiomatisation of Kleene Algebra.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08780" title="Abstract">arXiv:2310.08780</a> [<a href="/pdf/2310.08780" title="Download PDF">pdf</a>, <a href="/format/2310.08780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Im not Racist but...&quot;: Discovering Bias in the Internal Knowledge of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salinas%2C+A">Abel Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Penafiel%2C+L">Louis Penafiel</a>, 
<a href="/search/cs?searchtype=author&query=McCormack%2C+R">Robert McCormack</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Warning: This paper discusses and contains content that is offensive or upsetting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have garnered significant attention for their
remarkable performance in a continuously expanding set of natural language
processing tasks. However, these models have been shown to harbor inherent
societal biases, or stereotypes, which can adversely affect their performance
in their many downstream applications. In this paper, we introduce a novel,
purely prompt-based approach to uncover hidden stereotypes within any arbitrary
LLM. Our approach dynamically generates a knowledge representation of internal
stereotypes, enabling the identification of biases encoded within the LLM's
internal knowledge. By illuminating the biases present in LLMs and offering a
systematic methodology for their analysis, our work contributes to advancing
transparency and promoting fairness in natural language processing systems.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08782" title="Abstract">arXiv:2310.08782</a> [<a href="/pdf/2310.08782" title="Download PDF">pdf</a>, <a href="/format/2310.08782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selectivity Drives Productivity: Efficient Dataset Pruning for Enhanced  Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yimeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aochuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinghan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiancheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Massive data is often considered essential for deep learning applications,
but it also incurs significant computational and infrastructural costs.
Therefore, dataset pruning (DP) has emerged as an effective way to improve data
efficiency by identifying and removing redundant training samples without
sacrificing performance. In this work, we aim to address the problem of DP for
transfer learning, i.e., how to prune a source dataset for improved pretraining
efficiency and lossless finetuning accuracy on downstream target tasks. To our
best knowledge, the problem of DP for transfer learning remains open, as
previous studies have primarily addressed DP and transfer learning as separate
problems. By contrast, we establish a unified viewpoint to integrate DP with
transfer learning and find that existing DP methods are not suitable for the
transfer learning paradigm. We then propose two new DP methods, label mapping
and feature mapping, for supervised and self-supervised pretraining settings
respectively, by revisiting the DP problem through the lens of source-target
domain mapping. Furthermore, we demonstrate the effectiveness of our approach
on numerous transfer learning tasks. We show that source data classes can be
pruned by up to 40% ~ 80% without sacrificing downstream performance, resulting
in a significant 2 ~ 5 times speed-up during the pretraining stage. Besides,
our proposal exhibits broad applicability and can improve other computationally
intensive transfer learning techniques, such as adversarial pretraining. Codes
are available at https://github.com/OPTML-Group/DP4TL.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08784" title="Abstract">arXiv:2310.08784</a> [<a href="/pdf/2310.08784" title="Download PDF">pdf</a>, <a href="/format/2310.08784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Shape and Appearance Priors for Few-Shot Full Head  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caselles%2C+P">Pol Caselles</a>, 
<a href="/search/cs?searchtype=author&query=Ramon%2C+E">Eduard Ramon</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+J">Jaime Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Triginer%2C+G">Gil Triginer</a>, 
<a href="/search/cs?searchtype=author&query=Moreno-Noguer%2C+F">Francesc Moreno-Noguer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in learning techniques that employ coordinate-based
neural representations have yielded remarkable results in multi-view 3D
reconstruction tasks. However, these approaches often require a substantial
number of input views (typically several tens) and computationally intensive
optimization procedures to achieve their effectiveness. In this paper, we
address these limitations specifically for the problem of few-shot full 3D head
reconstruction. We accomplish this by incorporating a probabilistic shape and
appearance prior into coordinate-based representations, enabling faster
convergence and improved generalization when working with only a few input
images (even as low as a single image). During testing, we leverage this prior
to guide the fitting process of a signed distance function using a
differentiable renderer. By incorporating the statistical prior alongside
parallelizable ray tracing and dynamic caching strategies, we achieve an
efficient and accurate approach to few-shot full 3D head reconstruction.
Moreover, we extend the H3DS dataset, which now comprises 60 high-resolution 3D
full head scans and their corresponding posed images and masks, which we use
for evaluation purposes. By leveraging this dataset, we demonstrate the
remarkable capabilities of our approach in achieving state-of-the-art results
in geometry reconstruction while being an order of magnitude faster than
previous approaches.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08785" title="Abstract">arXiv:2310.08785</a> [<a href="/pdf/2310.08785" title="Download PDF">pdf</a>, <a href="/format/2310.08785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided  Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yueming Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages. arXiv admin note: text overlap with <a href="/abs/2303.06285">arXiv:2303.06285</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-guided image editing faces significant challenges to training and
inference flexibility. Much literature collects large amounts of annotated
image-text pairs to train text-conditioned generative models from scratch,
which is expensive and not efficient. After that, some approaches that leverage
pre-trained vision-language models are put forward to avoid data collection,
but they are also limited by either per text-prompt optimization or
inference-time hyper-parameters tuning. To address these issues, we investigate
and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP
visual feature difference of two images is semantically aligned with the CLIP
textual feature difference of their corresponding text descriptions. Based on
DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP
visual feature differences to the latent space directions of a generative model
during the training phase, and predicts the latent space directions from the
CLIP textual feature differences during the inference phase. And this design
endows DeltaEdit with two advantages: (1) text-free training; (2)
generalization to various text prompts for zero-shot inference. Extensive
experiments validate the effectiveness and versatility of DeltaEdit with
different generative models, including both the GAN model and the diffusion
model, in achieving flexible text-guided image editing. Code is available at
https://github.com/Yueming6568/DeltaEdit.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08788" title="Abstract">arXiv:2310.08788</a> [<a href="/pdf/2310.08788" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensory Manipulation as a Countermeasure to Robot Teleoperation Delays:  System and Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jing Du</a>, 
<a href="/search/cs?searchtype=author&query=Vann%2C+W">William Vann</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In the field of robotics, robot teleoperation for remote or hazardous
environments has become increasingly vital. A major challenge is the lag
between command and action, negatively affecting operator awareness,
performance, and mental strain. Even with advanced technology, mitigating these
delays, especially in long-distance operations, remains challenging. Current
solutions largely focus on machine-based adjustments. Yet, there's a gap in
using human perceptions to improve the teleoperation experience. This paper
presents a unique method of sensory manipulation to help humans adapt to such
delays. Drawing from motor learning principles, it suggests that modifying
sensory stimuli can lessen the perception of these delays. Instead of
introducing new skills, the approach uses existing motor coordination
knowledge. The aim is to minimize the need for extensive training or complex
automation. A study with 41 participants explored the effects of altered haptic
cues in delayed teleoperations. These cues were sourced from advanced physics
engines and robot sensors. Results highlighted benefits like reduced task time
and improved perceptions of visual delays. Real-time haptic feedback
significantly contributed to reduced mental strain and increased confidence.
This research emphasizes human adaptation as a key element in robot
teleoperation, advocating for improved teleoperation efficiency via swift human
adaptation, rather than solely optimizing robots for delay adjustment.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08790" title="Abstract">arXiv:2310.08790</a> [<a href="/pdf/2310.08790" title="Download PDF">pdf</a>, <a href="/format/2310.08790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Price of Stability in Quality-Aware Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yizhou Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xinyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE GLOBECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Learning (FL) is a distributed machine learning scheme that enables
clients to train a shared global model without exchanging local data. The
presence of label noise can severely degrade the FL performance, and some
existing studies have focused on algorithm design for label denoising. However,
they ignored the important issue that clients may not apply costly label
denoising strategies due to them being self-interested and having heterogeneous
valuations on the FL performance. To fill this gap, we model the clients'
interactions as a novel label denoising game and characterize its equilibrium.
We also analyze the price of stability, which quantifies the difference in the
system performance (e.g., global model accuracy, social welfare) between the
equilibrium outcome and the socially optimal solution. We prove that the
equilibrium outcome always leads to a lower global model accuracy than the
socially optimal solution does. We further design an efficient algorithm to
compute the socially optimal solution. Numerical experiments on MNIST dataset
show that the price of stability increases as the clients' data become noisier,
calling for an effective incentive mechanism.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08792" title="Abstract">arXiv:2310.08792</a> [<a href="/pdf/2310.08792" title="Download PDF">pdf</a>, <a href="/format/2310.08792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive Mechanism Design for Distributed Ensemble Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengchao Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE GLOBECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Distributed ensemble learning (DEL) involves training multiple models at
distributed learners, and then combining their predictions to improve
performance. Existing related studies focus on DEL algorithm design and
optimization but ignore the important issue of incentives, without which
self-interested learners may be unwilling to participate in DEL. We aim to fill
this gap by presenting a first study on the incentive mechanism design for DEL.
Our proposed mechanism specifies both the amount of training data and reward
for learners with heterogeneous computation and communication costs. One design
challenge is to have an accurate understanding regarding how learners'
diversity (in terms of training data) affects the ensemble accuracy. To this
end, we decompose the ensemble accuracy into a diversity-precision tradeoff to
guide the mechanism design. Another challenge is that the mechanism design
involves solving a mixed-integer program with a large search space. To this
end, we propose an alternating algorithm that iteratively updates each
learner's training data size and reward. We prove that under mild conditions,
the algorithm converges. Numerical results using MNIST dataset show an
interesting result: our proposed mechanism may prefer a lower level of learner
diversity to achieve a higher ensemble accuracy.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08793" title="Abstract">arXiv:2310.08793</a> [<a href="/pdf/2310.08793" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Weather and Time Features in Machine Learning-aided ERCOT  Load Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jonathan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tuo%2C+M">Mingjian Tuo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingpeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Accurate load forecasting is critical for efficient and reliable operations
of the electric power system. A large part of electricity consumption is
affected by weather conditions, making weather information an important
determinant of electricity usage. Personal appliances and industry equipment
also contribute significantly to electricity demand with temporal patterns,
making time a useful factor to consider in load forecasting. This work develops
several machine learning (ML) models that take various time and weather
information as part of the input features to predict the short-term system-wide
total load. Ablation studies were also performed to investigate and compare the
impacts of different weather factors on the prediction accuracy. Actual load
and historical weather data for the same region were processed and then used to
train the ML models. It is interesting to observe that using all available
features, each of which may be correlated to the load, is unlikely to achieve
the best forecasting performance; features with redundancy may even decrease
the inference capabilities of ML models. This indicates the importance of
feature selection for ML models. Overall, case studies demonstrated the
effectiveness of ML models trained with different weather and time input
features for ERCOT load forecasting.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08794" title="Abstract">arXiv:2310.08794</a> [<a href="/pdf/2310.08794" title="Download PDF">pdf</a>, <a href="/format/2310.08794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning in Competitive EV Charging Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+B">Biying Shou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ISGT EUROPE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Federated Learning (FL) has demonstrated a significant potential to improve
the quality of service (QoS) of EV charging stations. While existing studies
have primarily focused on developing FL algorithms, the effect of FL on the
charging stations' operation in terms of price competition has yet to be fully
understood. This paper aims to fill this gap by modeling the strategic
interactions between two charging stations and EV owners as a multi-stage game.
Each station first decides its FL participation strategy and charging price,
and then individual EV owners decide their charging strategies. The game
analysis involves solving a non-concave problem and by decomposing it into a
piece-wise concave program we manage to fully characterize the equilibrium.
Based on real-world datasets, our numerical results reveal an interesting
insight: even if FL improves QoS, it can lead to smaller profits for both
stations. The key reason is that FL intensifies the price competition between
charging stations by improving stations' QoS to a similar level. We further
show that the stations will participate in FL when their data distributions are
mildly dissimilar.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08795" title="Abstract">arXiv:2310.08795</a> [<a href="/pdf/2310.08795" title="Download PDF">pdf</a>, <a href="/format/2310.08795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Bias for Question Answering Models by Tracking Bias Influence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+M+D">Mingyu Derek Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+J">Jiun-Yu Kao</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Hsiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+T">Tagyoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Models of various NLP tasks have been shown to exhibit stereotypes, and the
bias in the question answering (QA) models is especially harmful as the output
answers might be directly consumed by the end users. There have been datasets
to evaluate bias in QA models, while bias mitigation technique for the QA
models is still under-explored. In this work, we propose BMBI, an approach to
mitigate the bias of multiple-choice QA models. Based on the intuition that a
model would lean to be more biased if it learns from a biased example, we
measure the bias level of a query instance by observing its influence on
another instance. If the influenced instance is more biased, we derive that the
query instance is biased. We then use the bias level detected as an
optimization objective to form a multi-task learning setting in addition to the
original QA task. We further introduce a new bias evaluation metric to quantify
bias in a comprehensive and sensitive way. We show that our method could be
applied to multiple QA formulations across multiple bias categories. It can
significantly reduce the bias level in all 9 bias categories in the BBQ dataset
while maintaining comparable QA accuracy.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08796" title="Abstract">arXiv:2310.08796</a> [<a href="/pdf/2310.08796" title="Download PDF">pdf</a>, <a href="/ps/2310.08796" title="Download PostScript">ps</a>, <a href="/format/2310.08796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Story Plot Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanlin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Andrew Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kevin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Story plots, while short, carry most of the essential information of a full
story that may contain tens of thousands of words. We study the problem of
automatic generation of story plots, which includes story premise, character
descriptions, plot outlines, etc. To generate a single engaging plot, existing
plot generators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands
of calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot,
which is costly and takes at least several minutes. Moreover, the hard-wired
nature of the method makes the pipeline non-differentiable, blocking fast
specialization and personalization of the plot generator. In this paper, we
propose three models, $\texttt{OpenPlot}$, $\texttt{E2EPlot}$ and
$\texttt{RLPlot}$, to address these challenges. $\texttt{OpenPlot}$ replaces
expensive OpenAI API calls with LLaMA2 (Touvron et al., 2023) calls via careful
prompt designs, which leads to inexpensive generation of high-quality training
datasets of story plots. We then train an end-to-end story plot generator,
$\texttt{E2EPlot}$, by supervised fine-tuning (SFT) using approximately 13000
story plots generated by $\texttt{OpenPlot}$. $\texttt{E2EPlot}$ generates
story plots of comparable quality to $\texttt{OpenPlot}$, and is &gt; 10$\times$
faster (1k tokens in only 30 seconds on average). Finally, we obtain
$\texttt{RLPlot}$ that is further fine-tuned with RLHF on several different
reward models for different aspects of story quality, which yields 60.0$\%$
winning rate against $\texttt{E2EPlot}$ along the aspect of suspense and
surprise.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08797" title="Abstract">arXiv:2310.08797</a> [<a href="/pdf/2310.08797" title="Download PDF">pdf</a>, <a href="/format/2310.08797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Task-Agnostic Distillation Methods for  Compressing Transformer Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udagawa%2C+T">Takuma Udagawa</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Aashka Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Merler%2C+M">Michele Merler</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+B">Bishwaranjan Bhattacharjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models have become a vital component in modern NLP, achieving
state of the art performance in a variety of tasks. However, they are often
inefficient for real-world deployment due to their expensive inference costs.
Knowledge distillation is a promising technique to improve their efficiency
while retaining most of their effectiveness. In this paper, we reproduce,
compare and analyze several representative methods for task-agnostic
(general-purpose) distillation of Transformer language models. Our target of
study includes Output Distribution (OD) transfer, Hidden State (HS) transfer
with various layer mapping strategies, and Multi-Head Attention (MHA) transfer
based on MiniLMv2. Through our extensive experiments, we study the
effectiveness of each method for various student architectures in both
monolingual (English) and multilingual settings. Overall, we show that MHA
transfer based on MiniLMv2 is generally the best option for distillation and
explain the potential reasons behind its success. Moreover, we show that HS
transfer remains as a competitive baseline, especially under a sophisticated
layer mapping strategy, while OD transfer consistently lags behind other
approaches. Findings from this study helped us deploy efficient yet effective
student models for latency-critical applications.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08800" title="Abstract">arXiv:2310.08800</a> [<a href="/pdf/2310.08800" title="Download PDF">pdf</a>, <a href="/format/2310.08800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time  Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chaocheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tingyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xuanhui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Anomaly detection in multivariate time series has emerged as a crucial
challenge in time series research, with significant research implications in
various fields such as fraud detection, fault diagnosis, and system state
estimation. Reconstruction-based models have shown promising potential in
recent years for detecting anomalies in time series data. However, due to the
rapid increase in data scale and dimensionality, the issues of noise and Weak
Identity Mapping (WIM) during time series reconstruction have become
increasingly pronounced. To address this, we introduce a novel Adaptive Dynamic
Neighbor Mask (ADNM) mechanism and integrate it with the Transformer and
Denoising Diffusion Model, creating a new framework for multivariate time
series anomaly detection, named Denoising Diffusion Mask Transformer (DDMT).
The ADNM module is introduced to mitigate information leakage between input and
output features during data reconstruction, thereby alleviating the problem of
WIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs
the Transformer as an internal neural network structure for Denoising Diffusion
Model. It learns the stepwise generation process of time series data to model
the probability distribution of the data, capturing normal data patterns and
progressively restoring time series data by removing noise, resulting in a
clear recovery of anomalies. To the best of our knowledge, this is the first
model that combines Denoising Diffusion Model and the Transformer for
multivariate time series anomaly detection. Experimental evaluations were
conducted on five publicly available multivariate time series anomaly detection
datasets. The results demonstrate that the model effectively identifies
anomalies in time series data, achieving state-of-the-art performance in
anomaly detection.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08802" title="Abstract">arXiv:2310.08802</a> [<a href="/pdf/2310.08802" title="Download PDF">pdf</a>, <a href="/format/2310.08802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Geometric Task-and-Motion Planning for Collaborative  Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hejia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Shao-Hung Chan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jie Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kolapo%2C+P">Peter Kolapo</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+S">Sven Koenig</a>, 
<a href="/search/cs?searchtype=author&query=Agioutantis%2C+Z">Zach Agioutantis</a>, 
<a href="/search/cs?searchtype=author&query=Schafrik%2C+S">Steven Schafrik</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 12 figures, accepted at Autonomous Robots (AURO). arXiv admin note: substantial text overlap with <a href="/abs/2210.08005">arXiv:2210.08005</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We address multi-robot geometric task-and-motion planning (MR-GTAMP) problems
in synchronous, monotone setups. The goal of the MR-GTAMP problem is to move
objects with multiple robots to goal regions in the presence of other movable
objects. We focus on collaborative manipulation tasks where the robots have to
adopt intelligent collaboration strategies to be successful and effective,
i.e., decide which robot should move which objects to which positions, and
perform collaborative actions, such as handovers. To endow robots with these
collaboration capabilities, we propose to first collect occlusion and
reachability information for each robot by calling motion-planning algorithms.
We then propose a method that uses the collected information to build a graph
structure which captures the precedence of the manipulations of different
objects and supports the implementation of a mixed-integer program to guide the
search for highly effective collaborative task-and-motion plans. The search
process for collaborative task-and-motion plans is based on a Monte-Carlo Tree
Search (MCTS) exploration strategy to achieve exploration-exploitation balance.
We evaluate our framework in two challenging MR-GTAMP domains and show that it
outperforms two state-of-the-art baselines with respect to the planning time,
the resulting plan length and the number of objects moved. We also show that
our framework can be applied to underground mining operations where a robotic
arm needs to coordinate with an autonomous roof bolter. We demonstrate plan
execution in two roof-bolting scenarios both in simulation and on robots.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08803" title="Abstract">arXiv:2310.08803</a> [<a href="/pdf/2310.08803" title="Download PDF">pdf</a>, <a href="/format/2310.08803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Perception in Artificial Intelligence through Principles of  Cognitive Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Palaash Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheston Tan</a>, 
<a href="/search/cs?searchtype=author&query=Rathore%2C+H">Heena Rathore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Summary: a detailed review of the current state of perception models through the lens of cognitive AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Although artificial intelligence (AI) has achieved many feats at a rapid
pace, there still exist open problems and fundamental shortcomings related to
performance and resource efficiency. Since AI researchers benchmark a
significant proportion of performance standards through human intelligence,
cognitive sciences-inspired AI is a promising domain of research. Studying
cognitive science can provide a fresh perspective to building fundamental
blocks in AI research, which can lead to improved performance and efficiency.
In this review paper, we focus on the cognitive functions of perception, which
is the process of taking signals from one's surroundings as input, and
processing them to understand the environment. Particularly, we study and
compare its various processes through the lens of both cognitive sciences and
AI. Through this study, we review all current major theories from various
sub-disciplines of cognitive science (specifically neuroscience, psychology and
linguistics), and draw parallels with theories and techniques from current
practices in AI. We, hence, present a detailed collection of methods in AI for
researchers to build AI systems inspired by cognitive science. Further, through
the process of reviewing the state of cognitive-inspired AI, we point out many
gaps in the current state of AI (with respect to the performance of the human
brain), and hence present potential directions for researchers to develop
better perception systems in AI.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08808" title="Abstract">arXiv:2310.08808</a> [<a href="/pdf/2310.08808" title="Download PDF">pdf</a>, <a href="/format/2310.08808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacks Meet Interpretability (AmI) Evaluation and Findings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Mehnaz%2C+S">Shagufta Mehnaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">To investigate the effectiveness of the model explanation in detecting
adversarial examples, we reproduce the results of two papers, Attacks Meet
Interpretability: Attribute-steered Detection of Adversarial Samples and Is AmI
(Attacks Meet Interpretability) Robust to Adversarial Examples. And then
conduct experiments and case studies to identify the limitations of both works.
We find that Attacks Meet Interpretability(AmI) is highly dependent on the
selection of hyperparameters. Therefore, with a different hyperparameter
choice, AmI is still able to detect Nicholas Carlini's attack. Finally, we
propose recommendations for future work on the evaluation of defense techniques
such as AmI.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08809" title="Abstract">arXiv:2310.08809</a> [<a href="/pdf/2310.08809" title="Download PDF">pdf</a>, <a href="/format/2310.08809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DexCatch: Learning to Catch Arbitrary Objects with Dexterous Hands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+F">Fengbo Lan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haotian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Oseni%2C+O">Oluwatosin Oseni</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Achieving human-like dexterous manipulation remains a crucial area of
research in robotics. Current research focuses on improving the success rate of
pick-and-place tasks. Compared with pick-and-place, throw-catching behavior has
the potential to increase picking speed without transporting objects to their
destination. However, dynamic dexterous manipulation poses a major challenge
for stable control due to a large number of dynamic contacts. In this paper, we
propose a Stability-Constrained Reinforcement Learning (SCRL) algorithm to
learn to catch diverse objects with dexterous hands. The SCRL algorithm
outperforms baselines by a large margin, and the learned policies show strong
zero-shot transfer performance on unseen objects. Remarkably, even though the
object in a hand facing sideward is extremely unstable due to the lack of
support from the palm, our method can still achieve a high level of success in
the most challenging task. Video demonstrations of learned behaviors and the
code can be found on the supplementary website.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08811" title="Abstract">arXiv:2310.08811</a> [<a href="/pdf/2310.08811" title="Download PDF">pdf</a>, <a href="/format/2310.08811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An enhanced and highly efficient semi-implicit combined Lagrange  multiplier approach with preserving original energy law for dissipative  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhengguang Liu</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+N">Nan Zheng</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiaoli Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">Recently, a new Lagrange multiplier approach was introduced by Cheng, Liu and
Shen in \cite{cheng2020new}, which has been broadly used to solve various
challenging phase field problems. To design original energy stable schemes,
they have to solve a nonlinear algebraic equation to determine the introduced
Lagrange multiplier, which can be computationally expensive, especially for
large-scale and long-time simulations involving complex nonlinear terms. This
paper presents an essential improved technique to modify this issue, which can
be seen as a semi-implicit combined Lagrange multiplier approach. In general,
the new constructed schemes keep all the advantages of the Lagrange multiplier
method and significantly reduce the computation costs. Besides, the new
proposed BDF2 scheme dissipates the original energy, as opposed to a modified
energy for the classical Lagrange multiplier approach in \cite{cheng2020new}.
We further construct high-order BDF$k$ schemes based on the new proposed
approach. In addition, we establish a general framework for extending our
constructed method to dissipative systems. Finally several examples have been
presented to demonstrate the effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08815" title="Abstract">arXiv:2310.08815</a> [<a href="/pdf/2310.08815" title="Download PDF">pdf</a>, <a href="/format/2310.08815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Object Detection with CLIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yupeng He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the incremental detection task, unlike the incremental classification
task, data ambiguity exists due to the possibility of an image having different
labeled bounding boxes in multiple continuous learning stages. This phenomenon
often impairs the model's ability to learn new classes. However, the forward
compatibility of the model is less considered in existing work, which hinders
the model's suitability for incremental learning. To overcome this obstacle, we
propose to use a language-visual model such as CLIP to generate text feature
embeddings for different class sets, which enhances the feature space globally.
We then employ the broad classes to replace the unavailable novel classes in
the early learning stage to simulate the actual incremental scenario. Finally,
we use the CLIP image encoder to identify potential objects in the proposals,
which are classified into the background by the model. We modify the background
labels of those proposals to known classes and add the boxes to the training
set to alleviate the problem of data ambiguity. We evaluate our approach on
various incremental learning settings on the PASCAL VOC 2007 dataset, and our
approach outperforms state-of-the-art methods, particularly for the new
classes.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08817" title="Abstract">arXiv:2310.08817</a> [<a href="/pdf/2310.08817" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the relationship between response time sequence in scale  answering process and severity of insomnia: a machine learning approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhao Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rongxun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Keyin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinru Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zexin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuanchen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenzhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xizhe Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objectives: The study aims to investigate the relationship between insomnia
and response time. Additionally, it aims to develop a machine learning model to
predict the presence of insomnia in participants using response time data.
Methods: A mobile application was designed to administer scale tests and
collect response time data from 2729 participants. The relationship between
symptom severity and response time was explored, and a machine learning model
was developed to predict the presence of insomnia. Results: The result revealed
a statistically significant difference (p&lt;.001) in the total response time
between participants with or without insomnia symptoms. A correlation was
observed between the severity of specific insomnia aspects and response times
at the individual questions level. The machine learning model demonstrated a
high predictive accuracy of 0.743 in predicting insomnia symptoms based on
response time data. Conclusions: These findings highlight the potential utility
of response time data to evaluate cognitive and psychological measures,
demonstrating the effectiveness of using response time as a diagnostic tool in
the assessment of insomnia.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08818" title="Abstract">arXiv:2310.08818</a> [<a href="/pdf/2310.08818" title="Download PDF">pdf</a>, <a href="/format/2310.08818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm xxxx: HiPPIS A High-Order Positivity-Preserving Mapping  Software for Structured Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ouermi%2C+T+A+J">Timbwaoga A. J. Ouermi</a>, 
<a href="/search/math?searchtype=author&query=Kirby%2C+R+M">Robert M Kirby</a>, 
<a href="/search/math?searchtype=author&query=Berzins%2C+M">Martin Berzins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Polynomial interpolation is an important component of many computational
problems. In several of these computational problems, failure to preserve
positivity when using polynomials to approximate or map data values between
meshes can lead to negative unphysical quantities. Currently, most
polynomial-based methods for enforcing positivity are based on splines and
polynomial rescaling. The spline-based approaches build interpolants that are
positive over the intervals in which they are defined and may require solving a
minimization problem and/or system of equations. The linear polynomial
rescaling methods allow for high-degree polynomials but enforce positivity only
at limited locations (e.g., quadrature nodes). This work introduces open-source
software (HiPPIS) for high-order data-bounded interpolation (DBI) and
positivity-preserving interpolation (PPI) that addresses the limitations of
both the spline and polynomial rescaling methods. HiPPIS is suitable for
approximating and mapping physical quantities such as mass, density, and
concentration between meshes while preserving positivity. This work provides
Fortran and Matlab implementations of the DBI and PPI methods, presents an
analysis of the mapping error in the context of PDEs, and uses several 1D and
2D numerical examples to demonstrate the benefits and limitations of HiPPIS.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08820" title="Abstract">arXiv:2310.08820</a> [<a href="/pdf/2310.08820" title="Download PDF">pdf</a>, <a href="/format/2310.08820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-guided Unsupervised Domain Adaptation for 3D Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xidong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+F">Feng Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Youquan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptation (UDA) in 3D segmentation tasks presents a
formidable challenge, primarily stemming from the sparse and unordered nature
of point cloud data. Especially for LiDAR point clouds, the domain discrepancy
becomes obvious across varying capture scenes, fluctuating weather conditions,
and the diverse array of LiDAR devices in use. While previous UDA methodologies
have often sought to mitigate this gap by aligning features between source and
target domains, this approach falls short when applied to 3D segmentation due
to the substantial domain variations. Inspired by the remarkable generalization
capabilities exhibited by the vision foundation model, SAM, in the realm of
image segmentation, our approach leverages the wealth of general knowledge
embedded within SAM to unify feature representations across diverse 3D domains
and further solves the 3D domain adaptation problem. Specifically, we harness
the corresponding images associated with point clouds to facilitate knowledge
transfer and propose an innovative hybrid feature augmentation methodology,
which significantly enhances the alignment between the 3D feature space and
SAM's feature space, operating at both the scene and instance levels. Our
method is evaluated on many widely-recognized datasets and achieves
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08821" title="Abstract">arXiv:2310.08821</a> [<a href="/pdf/2310.08821" title="Download PDF">pdf</a>, <a href="/format/2310.08821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Political Elites in False Statements on the Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuai%2C+Y">Yuwei Chuai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jichang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C3%B6llochs%2C+N">Nicolas Pr&#xf6;llochs</a>, 
<a href="/search/cs?searchtype=author&query=Lenzini%2C+G">Gabriele Lenzini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Political elites play a critical role in driving engagement with
misinformation on the internet. However, an understanding of the strategies
with which the political left and right attempt to harness animosity toward
political elites in their misinformation stories is missing. To this end, we
collected a comprehensive dataset consisting of 35,014 true and false
statements that have been fact-checked by renowned fact-checking organizations
(e.g., snopes.com) between 2008 and 2023, i.e., within an observation period of
15 years. Subsequently, we perform content analysis and explanatory regression
modeling to analyze how veracity is linked to mentions of US political elites
(Republicans and Democrats) in fact-checked statements. Our analysis yields
four main findings: (i) False statements are, on average, 20% more likely to
mention political elites than true statements. (ii) However, there is a
partisan asymmetry such that false statements are 88.1% more likely to mention
Democrats, but 26.5% less likely to mention Republicans. (iii) Mentions of
political elites in false statements reach the highest level during the months
preceding elections. (iiii) False statements that mention political elites
carry stronger other-condemning emotions. In sum, these empirical findings shed
new light on the connection between online misinformation and political elites
-- and suggest that authors of misinformation frequently harness animosity
toward the political out-groups in their misinformation stories.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08822" title="Abstract">arXiv:2310.08822</a> [<a href="/pdf/2310.08822" title="Download PDF">pdf</a>, <a href="/format/2310.08822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A High-throughput and Secure Coded Blockchain for IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taherpour%2C+A">Amirhossein Taherpour</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaodong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We propose a new coded blockchain scheme suitable for the Internet-of-Things
(IoT) network. In contrast to existing works for coded blockchains, especially
blockchain-of-things, the proposed scheme is more realistic, practical, and
secure while achieving high throughput. This is accomplished by: 1) modeling
the variety of transactions using a reward model, based on which an
optimization problem is solved to select transactions that are more accessible
and cheaper computational-wise to be processed together; 2) a transaction-based
and lightweight consensus algorithm that emphasizes on using the minimum
possible number of miners for processing the transactions; and 3) employing the
raptor codes with linear-time encoding and decoding which results in requiring
lower storage to maintain the blockchain and having a higher throughput. We
provide detailed analysis and simulation results on the proposed scheme and
compare it with the state-of-the-art coded IoT blockchain schemes including
Polyshard and LCB, to show the advantages of our proposed scheme in terms of
security, storage, decentralization, and throughput.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08823" title="Abstract">arXiv:2310.08823</a> [<a href="/pdf/2310.08823" title="Download PDF">pdf</a>, <a href="/format/2310.08823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-rank Aware Sequential Reward Learning for Inverse Reinforcement  Learning with Sub-optimal Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuxin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruobing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Inverse reinforcement learning (IRL) aims to explicitly infer an underlying
reward function based on collected expert demonstrations. Considering that
obtaining expert demonstrations can be costly, the focus of current IRL
techniques is on learning a better-than-demonstrator policy using a reward
function derived from sub-optimal demonstrations. However, existing IRL
algorithms primarily tackle the challenge of trajectory ranking ambiguity when
learning the reward function. They overlook the crucial role of considering the
degree of difference between trajectories in terms of their returns, which is
essential for further removing reward ambiguity. Additionally, it is important
to note that the reward of a single transition is heavily influenced by the
context information within the trajectory. To address these issues, we
introduce the Distance-rank Aware Sequential Reward Learning (DRASRL)
framework. Unlike existing approaches, DRASRL takes into account both the
ranking of trajectories and the degrees of dissimilarity between them to
collaboratively eliminate reward ambiguity when learning a sequence of
contextually informed reward signals. Specifically, we leverage the distance
between policies, from which the trajectories are generated, as a measure to
quantify the degree of differences between traces. This distance-aware
information is then used to infer embeddings in the representation space for
reward learning, employing the contrastive learning technique. Meanwhile, we
integrate the pairwise ranking loss function to incorporate ranking information
into the latent features. Moreover, we resort to the Transformer architecture
to capture the contextual dependencies within the trajectories in the latent
space, leading to more accurate reward estimation. Through extensive
experimentation, our DRASRL framework demonstrates significant performance
improvements over previous SOTA methods.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08824" title="Abstract">arXiv:2310.08824</a> [<a href="/pdf/2310.08824" title="Download PDF">pdf</a>, <a href="/format/2310.08824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confounding-Robust Policy Improvement with Human-AI Teams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruijiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Mingzhang Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Human-AI collaboration has the potential to transform various domains by
leveraging the complementary strengths of human experts and Artificial
Intelligence (AI) systems. However, unobserved confounding can undermine the
effectiveness of this collaboration, leading to biased and unreliable outcomes.
In this paper, we propose a novel solution to address unobserved confounding in
human-AI collaboration by employing the marginal sensitivity model (MSM). Our
approach combines domain expertise with AI-driven statistical modeling to
account for potential confounders that may otherwise remain hidden. We present
a deferral collaboration framework for incorporating the MSM into policy
learning from observational data, enabling the system to control for the
influence of unobserved confounding factors. In addition, we propose a
personalized deferral collaboration system to leverage the diverse expertise of
different human decision-makers. By adjusting for potential biases, our
proposed solution enhances the robustness and reliability of collaborative
outcomes. The empirical and theoretical analyses demonstrate the efficacy of
our approach in mitigating unobserved confounding and improving the overall
performance of human-AI collaborations.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08825" title="Abstract">arXiv:2310.08825</a> [<a href="/pdf/2310.08825" title="Download PDF">pdf</a>, <a href="/format/2310.08825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongsheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-modal Large Language Models (MLLMs) have made significant strides in
expanding the capabilities of Large Language Models (LLMs) through the
incorporation of visual perception interfaces. Despite the emergence of
exciting applications and the availability of diverse instruction tuning data,
existing approaches often rely on CLIP or its variants as the visual branch,
and merely extract features from the deep layers. However, these methods lack a
comprehensive analysis of the visual encoders in MLLMs. In this paper, we
conduct an extensive investigation into the effectiveness of different vision
encoders within MLLMs. Our findings reveal that the shallow layer features of
CLIP offer particular advantages for fine-grained tasks such as grounding and
region understanding. Surprisingly, the vision-only model DINO, which is not
pretrained with text-image alignment, demonstrates promising performance as a
visual branch within MLLMs. By simply equipping it with an MLP layer for
alignment, DINO surpasses CLIP in fine-grained related perception tasks.
Building upon these observations, we propose a simple yet effective feature
merging strategy, named COMM, that integrates CLIP and DINO with Multi-level
features Merging, to enhance the visual capabilities of MLLMs. We evaluate COMM
through comprehensive experiments on a wide range of benchmarks, including
image captioning, visual question answering, visual grounding, and object
hallucination. Experimental results demonstrate the superior performance of
COMM compared to existing methods, showcasing its enhanced visual capabilities
within MLLMs. Code will be made available at
https://github.com/YuchenLiu98/COMM.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08826" title="Abstract">arXiv:2310.08826</a> [<a href="/pdf/2310.08826" title="Download PDF">pdf</a>, <a href="/format/2310.08826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Multi-modal 3D Semantic Segmentation in Real-world Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Chaoping Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hanqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Di Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jian Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR and camera are two critical sensors for multi-modal 3D semantic
segmentation and are supposed to be fused efficiently and robustly to promise
safety in various real-world scenarios. However, existing multi-modal methods
face two key challenges: 1) difficulty with efficient deployment and real-time
execution; and 2) drastic performance degradation under weak calibration
between LiDAR and cameras. To address these challenges, we propose CPGNet-LCF,
a new multi-modal fusion framework extending the LiDAR-only CPGNet. CPGNet-LCF
solves the first challenge by inheriting the easy deployment and real-time
capabilities of CPGNet. For the second challenge, we introduce a novel weak
calibration knowledge distillation strategy during training to improve the
robustness against the weak calibration. CPGNet-LCF achieves state-of-the-art
performance on the nuScenes and SemanticKITTI benchmarks. Remarkably, it can be
easily deployed to run in 20ms per frame on a single Tesla V100 GPU using
TensorRT TF16 mode. Furthermore, we benchmark performance over four weak
calibration levels, demonstrating the robustness of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08830" title="Abstract">arXiv:2310.08830</a> [<a href="/pdf/2310.08830" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Urban Drone Navigation: Autoencoder Learning Fusion for Aerodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaohao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jing Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Drones are vital for urban emergency search and rescue (SAR) due to the
challenges of navigating dynamic environments with obstacles like buildings and
wind. This paper presents a method that combines multi-objective reinforcement
learning (MORL) with a convolutional autoencoder to improve drone navigation in
urban SAR. The approach uses MORL to achieve multiple goals and the autoencoder
for cost-effective wind simulations. By utilizing imagery data of urban
layouts, the drone can autonomously make navigation decisions, optimize paths,
and counteract wind effects without traditional sensors. Tested on a New York
City model, this method enhances drone SAR operations in complex urban
settings.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08833" title="Abstract">arXiv:2310.08833</a> [<a href="/pdf/2310.08833" title="Download PDF">pdf</a>, <a href="/ps/2310.08833" title="Download PostScript">ps</a>, <a href="/format/2310.08833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Sample Complexity for Average Reward Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Blanchet%2C+J">Jose Blanchet</a>, 
<a href="/search/cs?searchtype=author&query=Glynn%2C+P">Peter Glynn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We settle the sample complexity of policy learning for the maximization of
the long run average reward associated with a uniformly ergodic Markov decision
process (MDP), assuming a generative model. In this context, the existing
literature provides a sample complexity upper bound of $\widetilde
O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$ and a lower bound of
$\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$. In these expressions, $|S|$ and
$|A|$ denote the cardinalities of the state and action spaces respectively,
$t_{\text{mix}}$ serves as a uniform upper limit for the total variation mixing
times, and $\epsilon$ signifies the error tolerance. Therefore, a notable gap
of $t_{\text{mix}}$ still remains to be bridged. Our primary contribution is to
establish an estimator for the optimal policy of average reward MDPs with a
sample complexity of $\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$,
effectively reaching the lower bound in the literature. This is achieved by
combining algorithmic ideas in Jin and Sidford (2021) with those of Li et al.
(2020).
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08836" title="Abstract">arXiv:2310.08836</a> [<a href="/pdf/2310.08836" title="Download PDF">pdf</a>, <a href="/format/2310.08836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Few-Shot Policy Transfer through Observation Mapping and  Behavior Cloning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukla%2C+Y">Yash Shukla</a>, 
<a href="/search/cs?searchtype=author&query=Kesari%2C+B">Bharat Kesari</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+S">Shivam Goel</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+R">Robert Wright</a>, 
<a href="/search/cs?searchtype=author&query=Sinapov%2C+J">Jivko Sinapov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted to the IROS 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite recent progress in Reinforcement Learning for robotics applications,
many tasks remain prohibitively difficult to solve because of the expensive
interaction cost. Transfer learning helps reduce the training time in the
target domain by transferring knowledge learned in a source domain. Sim2Real
transfer helps transfer knowledge from a simulated robotic domain to a physical
target domain. Knowledge transfer reduces the time required to train a task in
the physical world, where the cost of interactions is high. However, most
existing approaches assume exact correspondence in the task structure and the
physical properties of the two domains. This work proposes a framework for
Few-Shot Policy Transfer between two domains through Observation Mapping and
Behavior Cloning. We use Generative Adversarial Networks (GANs) along with a
cycle-consistency loss to map the observations between the source and target
domains and later use this learned mapping to clone the successful source task
behavior policy to the target domain. We observe successful behavior policy
transfer with limited target task interactions and in cases where the source
and target task are semantically dissimilar.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08837" title="Abstract">arXiv:2310.08837</a> [<a href="/pdf/2310.08837" title="Download PDF">pdf</a>, <a href="/format/2310.08837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Static Code Analysis in the AI Era: An In-depth Exploration of the  Concept, Function, and Potential of Intelligent Code Analysis Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Gang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaoheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xunjin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yinan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+P">Peng Di</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The escalating complexity of software systems and accelerating development
cycles pose a significant challenge in managing code errors and implementing
business logic. Traditional techniques, while cornerstone for software quality
assurance, exhibit limitations in handling intricate business logic and
extensive codebases. To address these challenges, we introduce the Intelligent
Code Analysis Agent (ICAA), a novel concept combining AI models, engineering
process designs, and traditional non-AI components. The ICAA employs the
capabilities of large language models (LLMs) such as GPT-3 or GPT-4 to
automatically detect and diagnose code errors and business logic
inconsistencies. In our exploration of this concept, we observed a substantial
improvement in bug detection accuracy, reducing the false-positive rate to 66\%
from the baseline's 85\%, and a promising recall rate of 60.8\%. However, the
token consumption cost associated with LLMs, particularly the average cost for
analyzing each line of code, remains a significant consideration for widespread
adoption. Despite this challenge, our findings suggest that the ICAA holds
considerable potential to revolutionize software quality assurance,
significantly enhancing the efficiency and accuracy of bug detection in the
software development process. We hope this pioneering work will inspire further
research and innovation in this field, focusing on refining the ICAA concept
and exploring ways to mitigate the associated costs.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08839" title="Abstract">arXiv:2310.08839</a> [<a href="/pdf/2310.08839" title="Download PDF">pdf</a>, <a href="/format/2310.08839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HybridChain: Fast, Accurate, and Secure Transaction Processing with  Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taherpour%2C+A">Amirhossein Taherpour</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaodong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In order to fully unlock the transformative power of distributed ledgers and
blockchains, it is crucial to develop innovative consensus algorithms that can
overcome the obstacles of security, scalability, and interoperability, which
currently hinder their widespread adoption. This paper introduces HybridChain
that combines the advantages of sharded blockchain and DAG distributed ledger,
and a consensus algorithm that leverages decentralized learning. Our approach
involves validators exchanging perceptions as votes to assess potential
conflicts between transactions and the witness set, representing input
transactions in the UTXO model. These perceptions collectively contribute to an
intermediate belief regarding the validity of transactions. By integrating
their beliefs with those of other validators, localized decisions are made to
determine validity. Ultimately, a final consensus is achieved through a
majority vote, ensuring precise and efficient validation of transactions. Our
proposed approach is compared to the existing DAG-based scheme IOTA and the
sharded blockchain Omniledger through extensive simulations. The results show
that IOTA has high throughput and low latency but sacrifices accuracy and is
vulnerable to orphanage attacks especially with low transaction rates.
Omniledger achieves stable accuracy by increasing shards but has increased
latency. In contrast, the proposed HybridChain exhibits fast, accurate, and
secure transaction processing, and excellent scalability.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08840" title="Abstract">arXiv:2310.08840</a> [<a href="/pdf/2310.08840" title="Download PDF">pdf</a>, <a href="/format/2310.08840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Source Planner for Personalized  Knowledge-grounded Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Minda Hu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+F">Fei Mi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+W">Wai-Chung Kwan</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Open-domain dialogue system usually requires different sources of knowledge
to generate more informative and evidential responses. However, existing
knowledge-grounded dialogue systems either focus on a single knowledge source
or overlook the dependency between multiple sources of knowledge, which may
result in generating inconsistent or even paradoxical responses. To incorporate
multiple knowledge sources and dependencies between them, we propose SAFARI, a
novel framework that leverages the exceptional capabilities of large language
models (LLMs) in planning, understanding, and incorporating under both
supervised and unsupervised settings. Specifically, SAFARI decouples the
knowledge grounding into multiple sources and response generation, which allows
easy extension to various knowledge sources including the possibility of not
using any sources. To study the problem, we construct a personalized
knowledge-grounded dialogue dataset \textit{\textbf{K}nowledge \textbf{B}ehind
\textbf{P}ersona}~(\textbf{KBP}), which is the first to consider the dependency
between persona and implicit knowledge. Experimental results on the KBP dataset
demonstrate that the SAFARI framework can effectively produce
persona-consistent and knowledge-enhanced responses.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08841" title="Abstract">arXiv:2310.08841</a> [<a href="/pdf/2310.08841" title="Download PDF">pdf</a>, <a href="/format/2310.08841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Optimal Transport for Enhanced Offline Reinforcement Learning  in Surgical Robotic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zare%2C+M">Maryam Zare</a>, 
<a href="/search/cs?searchtype=author&query=Kebria%2C+P+M">Parham M. Kebria</a>, 
<a href="/search/cs?searchtype=author&query=Khosravi%2C+A">Abbas Khosravi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Most Reinforcement Learning (RL) methods are traditionally studied in an
active learning setting, where agents directly interact with their
environments, observe action outcomes, and learn through trial and error.
However, allowing partially trained agents to interact with real physical
systems poses significant challenges, including high costs, safety risks, and
the need for constant supervision. Offline RL addresses these cost and safety
concerns by leveraging existing datasets and reducing the need for
resource-intensive real-time interactions. Nevertheless, a substantial
challenge lies in the demand for these datasets to be meticulously annotated
with rewards. In this paper, we introduce Optimal Transport Reward (OTR)
labelling, an innovative algorithm designed to assign rewards to offline
trajectories, using a small number of high-quality expert demonstrations. The
core principle of OTR involves employing Optimal Transport (OT) to calculate an
optimal alignment between an unlabeled trajectory from the dataset and an
expert demonstration. This alignment yields a similarity measure that is
effectively interpreted as a reward signal. An offline RL algorithm can then
utilize these reward signals to learn a policy. This approach circumvents the
need for handcrafted rewards, unlocking the potential to harness vast datasets
for policy learning. Leveraging the SurRoL simulation platform tailored for
surgical robot learning, we generate datasets and employ them to train policies
using the OTR algorithm. By demonstrating the efficacy of OTR in a different
domain, we emphasize its versatility and its potential to expedite RL
deployment across a wide range of fields.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08842" title="Abstract">arXiv:2310.08842</a> [<a href="/pdf/2310.08842" title="Download PDF">pdf</a>, <a href="/ps/2310.08842" title="Download PostScript">ps</a>, <a href="/format/2310.08842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case-Based Persistent Memory for a Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watson%2C+I">Ian Watson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Case-based reasoning (CBR) as a methodology for problem-solving can use any
appropriate computational technique. This position paper argues that CBR
researchers have somewhat overlooked recent developments in deep learning and
large language models (LLMs). The underlying technical developments that have
enabled the recent breakthroughs in AI have strong synergies with CBR and could
be used to provide a persistent memory for LLMs to make progress towards
Artificial General Intelligence.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08844" title="Abstract">arXiv:2310.08844</a> [<a href="/pdf/2310.08844" title="Download PDF">pdf</a>, <a href="/format/2310.08844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Stricter Content Moderation on Parler&#x27;s Users&#x27; Discourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumarswamy%2C+N">Nihal Kumarswamy</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+M">Mohit Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Nilizadeh%2C+S">Shirin Nilizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Social media platforms employ various content moderation techniques to remove
harmful, offensive, and hate speech content. The moderation level varies across
platforms; even over time, it can evolve in a platform. For example, Parler, a
fringe social media platform popular among conservative users, was known to
have the least restrictive moderation policies, claiming to have open
discussion spaces for their users. However, after linking the 2021 US Capitol
Riots and the activity of some groups on Parler, such as QAnon and Proud Boys,
on January 12, 2021, Parler was removed from the Apple and Google App Store and
suspended from Amazon Cloud hosting service. Parler would have to modify their
moderation policies to return to these online stores. After a month of
downtime, Parler was back online with a new set of user guidelines, which
reflected stricter content moderation, especially regarding the \emph{hate
speech} policy.
<br />In this paper, we studied the moderation changes performed by Parler and
their effect on the toxicity of its content. We collected a large longitudinal
Parler dataset with 17M parleys from 432K active users from February 2021 to
January 2022, after its return to the Internet and App Store. To the best of
our knowledge, this is the first study investigating the effectiveness of
content moderation techniques using data-driven approaches and also the first
Parler dataset after its brief hiatus. Our quasi-experimental time series
analysis indicates that after the change in Parler's moderation, the severe
forms of toxicity (above a threshold of 0.5) immediately decreased and
sustained. In contrast, the trend did not change for less severe threats and
insults (a threshold between 0.5 - 0.7). Finally, we found an increase in the
factuality of the news sites being shared, as well as a decrease in the number
of conspiracy or pseudoscience sources being shared.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08847" title="Abstract">arXiv:2310.08847</a> [<a href="/pdf/2310.08847" title="Download PDF">pdf</a>, <a href="/format/2310.08847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Over-Memorization During Natural, Robust and Catastrophic  Overfitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Runqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chaojian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Overfitting negatively impacts the generalization ability of deep neural
networks (DNNs) in both natural and adversarial training. Existing methods
struggle to consistently address different types of overfitting, typically
designing strategies that focus separately on either natural or adversarial
patterns. In this work, we adopt a unified perspective by solely focusing on
natural patterns to explore different types of overfitting. Specifically, we
examine the memorization effect in DNNs and reveal a shared behaviour termed
over-memorization, which impairs their generalization capacity. This behaviour
manifests as DNNs suddenly becoming high-confidence in predicting certain
training patterns and retaining a persistent memory for them. Furthermore, when
DNNs over-memorize an adversarial pattern, they tend to simultaneously exhibit
high-confidence prediction for the corresponding natural pattern. These
findings motivate us to holistically mitigate different types of overfitting by
hindering the DNNs from over-memorization natural patterns. To this end, we
propose a general framework, Distraction Over-Memorization (DOM), which
explicitly prevents over-memorization by either removing or augmenting the
high-confidence natural patterns. Extensive experiments demonstrate the
effectiveness of our proposed method in mitigating overfitting across various
training paradigms.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08848" title="Abstract">arXiv:2310.08848</a> [<a href="/pdf/2310.08848" title="Download PDF">pdf</a>, <a href="/format/2310.08848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised End-To-End Contrastive Learning For Time Series  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Huili Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series classification is a critical task in various domains, such as
finance, healthcare, and sensor data analysis. Unsupervised contrastive
learning has garnered significant interest in learning effective
representations from time series data with limited labels. The prevalent
approach in existing contrastive learning methods consists of two separate
stages: pre-training the encoder on unlabeled datasets and fine-tuning the
well-trained model on a small-scale labeled dataset. However, such two-stage
approaches suffer from several shortcomings, such as the inability of
unsupervised pre-training contrastive loss to directly affect downstream
fine-tuning classifiers, and the lack of exploiting the classification loss
which is guided by valuable ground truth. In this paper, we propose an
end-to-end model called SLOTS (Semi-supervised Learning fOr Time
clasSification). SLOTS receives semi-labeled datasets, comprising a large
number of unlabeled samples and a small proportion of labeled samples, and maps
them to an embedding space through an encoder. We calculate not only the
unsupervised contrastive loss but also measure the supervised contrastive loss
on the samples with ground truth. The learned embeddings are fed into a
classifier, and the classification loss is calculated using the available true
labels. The unsupervised, supervised contrastive losses and classification loss
are jointly used to optimize the encoder and classifier. We evaluate SLOTS by
comparing it with ten state-of-the-art methods across five datasets. The
results demonstrate that SLOTS is a simple yet effective framework. When
compared to the two-stage framework, our end-to-end SLOTS utilizes the same
input data, consumes a similar computational cost, but delivers significantly
improved performance. We release code and datasets at
https://anonymous.4open.science/r/SLOTS-242E.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08849" title="Abstract">arXiv:2310.08849</a> [<a href="/pdf/2310.08849" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path To Gain Functional Transparency In Artificial Intelligence With  Meaningful Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosain%2C+M+T">Md. Tanzib Hosain</a>, 
<a href="/search/cs?searchtype=author&query=Anik%2C+M+H">Mehedi Hasan Anik</a>, 
<a href="/search/cs?searchtype=author&query=Rafi%2C+S">Sadman Rafi</a>, 
<a href="/search/cs?searchtype=author&query=Tabassum%2C+R">Rana Tabassum</a>, 
<a href="/search/cs?searchtype=author&query=Insia%2C+K">Khaleque Insia</a>, 
<a href="/search/cs?searchtype=author&query=Siddiky%2C+M+M">Md. Mehrab Siddiky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Hosain, M. T. , Anik, M. H. , Rafi, S. , Tabassum, R. , Insia, K. &amp; S{\i}dd{\i}ky, M. M. (). Path To Gain Functional Transparency In Artificial Intelligence With Meaningful Explainability . Journal of Metaverse , 3 (2) , 166-180 . DOI: 10.57019/jmv.1306685
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial Intelligence (AI) is rapidly integrating into various aspects of
our daily lives, influencing decision-making processes in areas such as
targeted advertising and matchmaking algorithms. As AI systems become
increasingly sophisticated, ensuring their transparency and explainability
becomes crucial. Functional transparency is a fundamental aspect of algorithmic
decision-making systems, allowing stakeholders to comprehend the inner workings
of these systems and enabling them to evaluate their fairness and accuracy.
However, achieving functional transparency poses significant challenges that
need to be addressed. In this paper, we propose a design for user-centered
compliant-by-design transparency in transparent systems. We emphasize that the
development of transparent and explainable AI systems is a complex and
multidisciplinary endeavor, necessitating collaboration among researchers from
diverse fields such as computer science, artificial intelligence, ethics, law,
and social science. By providing a comprehensive understanding of the
challenges associated with transparency in AI systems and proposing a
user-centered design framework, we aim to facilitate the development of AI
systems that are accountable, trustworthy, and aligned with societal values.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08853" title="Abstract">arXiv:2310.08853</a> [<a href="/pdf/2310.08853" title="Download PDF">pdf</a>, <a href="/format/2310.08853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially Continuous Non-Contact Cold Sensation Presentation Based on  Low-Temperature Airflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makino%2C+K">Koyo Makino</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiayi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+A">Akiko Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Ienaga%2C+N">Naoto Ienaga</a>, 
<a href="/search/cs?searchtype=author&query=Kuroda%2C+Y">Yoshihiro Kuroda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE World Haptics Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Our perception of cold enriches our understanding of the world and allows us
to interact with it. Therefore, the presentation of cold sensations will be
beneficial in improving the sense of immersion and presence in virtual reality
and the metaverse. This study proposed a novel method for spatially continuous
cold sensation presentation based on low-temperature airflows. We defined the
shortest distance between two airflows perceived as different cold stimuli as a
local cold stimulus group discrimination threshold (LCSGDT). By setting the
distance between airflows within the LCSGDT, spatially continuous cold
sensations can be achieved with an optimal number of cold airflows. We
hypothesized that the LCSGDTs are related to the heat-transfer capability of
airflows and developed a model to relate them. We investigated the LCSGDTs at a
flow rate of 25 L/min and presentation distances ranging from 10 to 50 mm. The
results showed that under these conditions, the LCSGDTs are 131.4 $\pm$ 1.9 mm,
and the heat-transfer capacity of the airflow corresponding to these LCSGDTs is
an almost constant value, that is, 0.92.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08854" title="Abstract">arXiv:2310.08854</a> [<a href="/pdf/2310.08854" title="Download PDF">pdf</a>, <a href="/format/2310.08854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank-DETR for High Quality Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yifan Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Weicong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yiduo Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yukang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern detection transformers (DETRs) use a set of object queries to predict
a list of bounding boxes, sort them by their classification confidence scores,
and select the top-ranked predictions as the final detection results for the
given input image. A highly performant object detector requires accurate
ranking for the bounding box predictions. For DETR-based detectors, the
top-ranked bounding boxes suffer from less accurate localization quality due to
the misalignment between classification scores and localization accuracy, thus
impeding the construction of high-quality detectors. In this work, we introduce
a simple and highly performant DETR-based object detector by proposing a series
of rank-oriented designs, combinedly called Rank-DETR. Our key contributions
include: (i) a rank-oriented architecture design that can prompt positive
predictions and suppress the negative ones to ensure lower false positive
rates, as well as (ii) a rank-oriented loss function and matching cost design
that prioritizes predictions of more accurate localization accuracy during
ranking to boost the AP under high IoU thresholds. We apply our method to
improve the recent SOTA methods (e.g., H-DETR and DINO-DETR) and report strong
COCO object detection results when using different backbones such as
ResNet-$50$, Swin-T, and Swin-L, demonstrating the effectiveness of our
approach. Code is available at \url{https://github.com/LeapLabTHU/Rank-DETR}.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08855" title="Abstract">arXiv:2310.08855</a> [<a href="/pdf/2310.08855" title="Download PDF">pdf</a>, <a href="/format/2310.08855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Recency Bias of Normalization Statistics in Continual  Learning: Balance and Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yilin Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zicheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liping Jing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Continual learning entails learning a sequence of tasks and balancing their
knowledge appropriately. With limited access to old training samples, much of
the current work in deep neural networks has focused on overcoming catastrophic
forgetting of old tasks in gradient-based optimization. However, the
normalization layers provide an exception, as they are updated interdependently
by the gradient and statistics of currently observed training samples, which
require specialized strategies to mitigate recency bias. In this work, we focus
on the most popular Batch Normalization (BN) and provide an in-depth
theoretical analysis of its sub-optimality in continual learning. Our analysis
demonstrates the dilemma between balance and adaptation of BN statistics for
incremental tasks, which potentially affects training stability and
generalization. Targeting on these particular challenges, we propose Adaptive
Balance of BN (AdaB$^2$N), which incorporates appropriately a Bayesian-based
strategy to adapt task-wise contributions and a modified momentum to balance BN
statistics, corresponding to the training and testing stages. By implementing
BN in a continual learning fashion, our approach achieves significant
performance gains across a wide range of benchmarks, particularly for the
challenging yet realistic online scenarios (e.g., up to 7.68%, 6.86% and 4.26%
on Split CIFAR-10, Split CIFAR-100 and Split Mini-ImageNet, respectively). Our
code is available at https://github.com/lvyilin/AdaB2N.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08857" title="Abstract">arXiv:2310.08857</a> [<a href="/pdf/2310.08857" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transmission Planning for Climate-impacted Renewable Energy Grid: Data  Preparation, Model Improvement, and Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jin Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingpeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As renewable energy is becoming the major resource in future grids, the
weather and climate can have higher impact on the grid reliability.
Transmission expansion planning (TEP) has the potential to reinforce a
transmission network that is suitable for climate-impacted grids. In this
paper, we propose a systematic TEP procedure for climate-impacted renewable
energy-enriched grids. Particularly, this work developed an improved model for
TEP considering climate impact (TEP-CI) and evaluated the system reliability
with the obtained transmission investment plan. Firstly, we created
climate-impacted spatio temporal future grid data to facilitate the TEP-CI
study, which includes the future climate-dependent renewable production as well
as the dynamic rating profiles of the Texas 123-bus backbone transmission
system (TX-123BT). Secondly, we proposed the TEP-CI which considers the
variation in renewable production and dynamic line rating, and obtained the
investment plan for future TX-123BT. Thirdly, we presented a customized
security-constrained unit commitment (SCUC) specifically for climate-impacted
grids. The future grid reliability under various investment scenarios is
analyzed, based on the daily operation conditions from SCUC simulations. The
whole procedure presented in this paper enables numerical studies on grid
planning considering climate-impacts. It can also serve as a benchmark for
other TEP-CI research and performance evaluation.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08860" title="Abstract">arXiv:2310.08860</a> [<a href="/pdf/2310.08860" title="Download PDF">pdf</a>, <a href="/format/2310.08860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding AMR Parsing with Reverse Graph Linearization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bofei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Baobao Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Abstract Meaning Representation (AMR) parsing aims to extract an abstract
semantic graph from a given sentence. The sequence-to-sequence approaches,
which linearize the semantic graph into a sequence of nodes and edges and
generate the linearized graph directly, have achieved good performance.
However, we observed that these approaches suffer from structure loss
accumulation during the decoding process, leading to a much lower F1-score for
nodes and edges decoded later compared to those decoded earlier. To address
this issue, we propose a novel Reverse Graph Linearization (RGL) enhanced
framework. RGL defines both default and reverse linearization orders of an AMR
graph, where most structures at the back part of the default order appear at
the front part of the reversed order and vice versa. RGL incorporates the
reversed linearization to the original AMR parser through a two-pass
self-distillation mechanism, which guides the model when generating the default
linearizations. Our analysis shows that our proposed method significantly
mitigates the problem of structure loss accumulation, outperforming the
previously best AMR parsing model by 0.8 and 0.5 Smatch scores on the AMR 2.0
and AMR 3.0 dataset, respectively. The code are available at
https://github.com/pkunlp-icler/AMR_reverse_graph_linearization.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08861" title="Abstract">arXiv:2310.08861</a> [<a href="/pdf/2310.08861" title="Download PDF">pdf</a>, <a href="/format/2310.08861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-initialization-free Level Set Method via Molecular Beam Epitaxy  Equation Regularization for Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fanghui Song</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiebao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shengzhu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhichang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dazhi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Variational level set method has become a powerful tool in image segmentation
due to its ability to handle complex topological changes and maintain
continuity and smoothness in the process of evolution. However its evolution
process can be unstable, which results in over flatted or over sharpened
contours and segmentation failure. To improve the accuracy and stability of
evolution, we propose a high-order level set variational segmentation method
integrated with molecular beam epitaxy (MBE) equation regularization. This
method uses the crystal growth in the MBE process to limit the evolution of the
level set function, and thus can avoid the re-initialization in the evolution
process and regulate the smoothness of the segmented curve. It also works for
noisy images with intensity inhomogeneity, which is a challenge in image
segmentation. To solve the variational model, we derive the gradient flow and
design scalar auxiliary variable (SAV) scheme coupled with fast Fourier
transform (FFT), which can significantly improve the computational efficiency
compared with the traditional semi-implicit and semi-explicit scheme. Numerical
experiments show that the proposed method can generate smooth segmentation
curves, retain fine segmentation targets and obtain robust segmentation results
of small objects. Compared to existing level set methods, this model is
state-of-the-art in both accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08863" title="Abstract">arXiv:2310.08863</a> [<a href="/pdf/2310.08863" title="Download PDF">pdf</a>, <a href="/format/2310.08863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Learning for Few-Shot Molecular Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fifty%2C+C">Christopher Fifty</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/cs?searchtype=author&query=Thrun%2C+S">Sebastian Thrun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In-context learning has become an important approach for few-shot learning in
Large Language Models because of its ability to rapidly adapt to new tasks
without fine-tuning model parameters. However, it is restricted to applications
in natural language and inapplicable to other domains. In this paper, we adapt
the concepts underpinning in-context learning to develop a new algorithm for
few-shot molecular property prediction. Our approach learns to predict
molecular properties from a context of (molecule, property measurement) pairs
and rapidly adapts to new properties without fine-tuning. On the FS-Mol and
BACE molecular property prediction benchmarks, we find this method surpasses
the performance of recent meta-learning algorithms at small support sizes and
is competitive with the best methods at large support sizes.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08864" title="Abstract">arXiv:2310.08864</a> [<a href="/pdf/2310.08864" title="Download PDF">pdf</a>, <a href="/format/2310.08864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open X-Embodiment: Robotic Learning Datasets and RT-X Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padalkar%2C+A">Abhishek Padalkar</a>, 
<a href="/search/cs?searchtype=author&query=Pooley%2C+A">Acorn Pooley</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ajinkya Jain</a>, 
<a href="/search/cs?searchtype=author&query=Bewley%2C+A">Alex Bewley</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+A">Alex Herzog</a>, 
<a href="/search/cs?searchtype=author&query=Irpan%2C+A">Alex Irpan</a>, 
<a href="/search/cs?searchtype=author&query=Khazatsky%2C+A">Alexander Khazatsky</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Anant Rai</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anikait Singh</a>, 
<a href="/search/cs?searchtype=author&query=Brohan%2C+A">Anthony Brohan</a>, 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Wahid%2C+A">Ayzaan Wahid</a>, 
<a href="/search/cs?searchtype=author&query=Burgess-Limerick%2C+B">Ben Burgess-Limerick</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomjoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+C">Cheng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenguang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Christine Chan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chuer Pan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chuyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Devin%2C+C">Coline Devin</a>, 
<a href="/search/cs?searchtype=author&query=Driess%2C+D">Danny Driess</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchler%2C+D">Dieter B&#xfc;chler</a>, 
<a href="/search/cs?searchtype=author&query=Kalashnikov%2C+D">Dmitry Kalashnikov</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Johns%2C+E">Edward Johns</a>, 
<a href="/search/cs?searchtype=author&query=Ceola%2C+F">Federico Ceola</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+F">Freek Stulp</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Gaoyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>, 
<a href="/search/cs?searchtype=author&query=Salhotra%2C+G">Gautam Salhotra</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Ge Yan</a>, 
<a href="/search/cs?searchtype=author&query=Schiavi%2C+G">Giulio Schiavi</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+G">Gregory Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao-Shu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+H">Hiroki Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Walke%2C+H">Homer Walke</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hongjie Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cs?searchtype=author&query=Radosavovic%2C+I">Ilija Radosavovic</a>, 
<a href="/search/cs?searchtype=author&query=Leal%2C+I">Isabel Leal</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jacky Liang</a>, 
<a href="/search/cs?searchtype=author&query=Abou-Chakra%2C+J">Jad Abou-Chakra</a>,  et al. (121 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Large, high-capacity models trained on diverse datasets have shown remarkable
successes on efficiently tackling downstream applications. In domains from NLP
to Computer Vision, this has led to a consolidation of pretrained models, with
general pretrained backbones serving as a starting point for many applications.
Can such a consolidation happen in robotics? Conventionally, robotic learning
methods train a separate model for every application, every robot, and even
every environment. Can we instead train generalist X-robot policy that can be
adapted efficiently to new robots, tasks, and environments? In this paper, we
provide datasets in standardized data formats and models to make it possible to
explore this possibility in the context of robotic manipulation, alongside
experimental results that provide an example of effective X-robot policies. We
assemble a dataset from 22 different robots collected through a collaboration
between 21 institutions, demonstrating 527 skills (160266 tasks). We show that
a high-capacity model trained on this data, which we call RT-X, exhibits
positive transfer and improves the capabilities of multiple robots by
leveraging experience from other platforms.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08866" title="Abstract">arXiv:2310.08866</a> [<a href="/pdf/2310.08866" title="Download PDF">pdf</a>, <a href="/format/2310.08866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptivity and Modularity for Efficient Generalization Over Task  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abnar%2C+S">Samira Abnar</a>, 
<a href="/search/cs?searchtype=author&query=Saremi%2C+O">Omid Saremi</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+L">Laurent Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+S">Shantel Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Bautista%2C+M+A">Miguel Angel Bautista</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Thilak%2C+V">Vimal Thilak</a>, 
<a href="/search/cs?searchtype=author&query=Littwin%2C+E">Etai Littwin</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiatao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J">Josh Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+S">Samy Bengio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Can transformers generalize efficiently on problems that require dealing with
examples with different levels of difficulty? We introduce a new task tailored
to assess generalization over different complexities and present results that
indicate that standard transformers face challenges in solving these tasks.
These tasks are variations of pointer value retrieval previously introduced by
Zhang et al. (2021). We investigate how the use of a mechanism for adaptive and
modular computation in transformers facilitates the learning of tasks that
demand generalization over the number of sequential computation steps (i.e.,
the depth of the computation graph). Based on our observations, we propose a
transformer-based architecture called Hyper-UT, which combines dynamic function
generation from hyper networks with adaptive depth from Universal Transformers.
This model demonstrates higher accuracy and a fairer allocation of
computational resources when generalizing to higher numbers of computation
steps. We conclude that mechanisms for adaptive depth and modularity complement
each other in improving efficient generalization concerning example complexity.
Additionally, to emphasize the broad applicability of our findings, we
illustrate that in a standard image recognition task, Hyper- UT's performance
matches that of a ViT model but with considerably reduced computational demands
(achieving over 70\% average savings by effectively using fewer layers).
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08867" title="Abstract">arXiv:2310.08867</a> [<a href="/pdf/2310.08867" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Methods for Handling Disk Data Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuangshuang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Class imbalance exists in many classification problems, and since the data is
designed for accuracy, imbalance in data classes can lead to classification
challenges with a few classes having higher misclassification costs. The
Backblaze dataset, a widely used dataset related to hard discs, has a small
amount of failure data and a large amount of health data, which exhibits a
serious class imbalance. This paper provides a comprehensive overview of
research in the field of imbalanced data classification. The discussion is
organized into three main aspects: data-level methods, algorithmic-level
methods, and hybrid methods. For each type of method, we summarize and analyze
the existing problems, algorithmic ideas, strengths, and weaknesses.
Additionally, the challenges of unbalanced data classification are discussed,
along with strategies to address them. It is convenient for researchers to
choose the appropriate method according to their needs.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08868" title="Abstract">arXiv:2310.08868</a> [<a href="/pdf/2310.08868" title="Download PDF">pdf</a>, <a href="/format/2310.08868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeCoNet: A Heterosexual Contact Network Growth Model for Human  Papillomavirus Disease Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Piraveenan%2C+M">Mahendra Piraveenan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Human Papillomavirus infection is the most common sexually transmitted
infection, and causes serious complications such as cervical cancer in
vulnerable female populations in regions such as East Africa. Due to the
scarcity of empirical data about sexual relationships in varying demographics,
computationally modelling the underlying sexual contact networks is important
to understand Human Papillomavirus infection dynamics and prevention
strategies. In this work we present SeCoNet, a heterosexual contact network
growth model for Human Papillomavirus disease simulation. The growth model
consists of three mechanisms that closely imitate real-world relationship
forming and discontinuation processes in sexual contact networks. We
demonstrate that the networks grown from this model are scale-free, as are the
real world sexual contact networks, and we demonstrate that the model can be
calibrated to fit different demographic contexts by using a range of
parameters. We also undertake disease dynamics analysis of Human Papillomavirus
infection using a compartmental epidemic model on the grown networks. The
presented SeCoNet growth model is useful to computational epidemiologists who
study sexually transmitted infections in general and Human Papillomavirus
infection in particular.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08869" title="Abstract">arXiv:2310.08869</a> [<a href="/pdf/2310.08869" title="Download PDF">pdf</a>, <a href="/format/2310.08869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Behave Like Clean Speech: Dual-Branch Knowledge Distillation  for Noise-Robust Fake Audio Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cunhang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiangyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhengqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhao Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Most research in fake audio detection (FAD) focuses on improving performance
on standard noise-free datasets. However, in actual situations, there is
usually noise interference, which will cause significant performance
degradation in FAD systems. To improve the noise robustness, we propose a
dual-branch knowledge distillation fake audio detection (DKDFAD) method.
Specifically, a parallel data flow of the clean teacher branch and the noisy
student branch is designed, and interactive fusion and response-based
teacher-student paradigms are proposed to guide the training of noisy data from
the data distribution and decision-making perspectives. In the noise branch,
speech enhancement is first introduced for denoising, which reduces the
interference of strong noise. The proposed interactive fusion combines
denoising features and noise features to reduce the impact of speech distortion
and seek consistency with the data distribution of clean branch. The
teacher-student paradigm maps the student's decision space to the teacher's
decision space, making noisy speech behave as clean. In addition, a joint
training method is used to optimize the two branches to achieve global
optimality. Experimental results based on multiple datasets show that the
proposed method performs well in noisy environments and maintains performance
in cross-dataset experiments.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08872" title="Abstract">arXiv:2310.08872</a> [<a href="/pdf/2310.08872" title="Download PDF">pdf</a>, <a href="/format/2310.08872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R&amp;B: Region and Boundary Aware Zero-shot Grounded Text-to-image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiayu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Henglei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent text-to-image (T2I) diffusion models have achieved remarkable progress
in generating high-quality images given text-prompts as input. However, these
models fail to convey appropriate spatial composition specified by a layout
instruction. In this work, we probe into zero-shot grounded T2I generation with
diffusion models, that is, generating images corresponding to the input layout
information without training auxiliary modules or finetuning diffusion models.
We propose a Region and Boundary (R&amp;B) aware cross-attention guidance approach
that gradually modulates the attention maps of diffusion model during
generative process, and assists the model to synthesize images (1) with high
fidelity, (2) highly compatible with textual input, and (3) interpreting layout
instructions accurately. Specifically, we leverage the discrete sampling to
bridge the gap between consecutive attention maps and discrete layout
constraints, and design a region-aware loss to refine the generative layout
during diffusion process. We further propose a boundary-aware loss to
strengthen object discriminability within the corresponding regions.
Experimental results show that our method outperforms existing state-of-the-art
zero-shot grounded T2I generation methods by a large margin both qualitatively
and quantitatively on several benchmarks.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08873" title="Abstract">arXiv:2310.08873</a> [<a href="/pdf/2310.08873" title="Download PDF">pdf</a>, <a href="/format/2310.08873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Navigation in Environments with Traversable Obstacles Using  Large Language and Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A">Anran Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C+W">Chun Wai Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangyu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>, 
<a href="/search/cs?searchtype=author&query=Au%2C+K+W+S">K. W. Samuel Au</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes an interactive navigation framework by using large
language and vision-language models, allowing robots to navigate in
environments with traversable obstacles. We utilize the large language model
(GPT-3.5) and the open-set Vision-language Model (Grounding DINO) to create an
action-aware costmap to perform effective path planning without fine-tuning.
With the large models, we can achieve an end-to-end system from textual
instructions like "Can you pass through the curtains to deliver medicines to
me?", to bounding boxes (e.g., curtains) with action-aware attributes. They can
be used to segment LiDAR point clouds into two parts: traversable and
untraversable parts, and then an action-aware costmap is constructed for
generating a feasible path. The pre-trained large models have great
generalization ability and do not require additional annotated data for
training, allowing fast deployment in the interactive navigation tasks. We
choose to use multiple traversable objects such as curtains and grasses for
verification by instructing the robot to traverse them. Besides, traversing
curtains in a medical scenario was tested. All experimental results
demonstrated the proposed framework's effectiveness and adaptability to diverse
environments.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08876" title="Abstract">arXiv:2310.08876</a> [<a href="/pdf/2310.08876" title="Download PDF">pdf</a>, <a href="/format/2310.08876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gesture Recognition for FMCW Radar on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strobel%2C+M">Maximilian Strobel</a>, 
<a href="/search/cs?searchtype=author&query=Schoenfeldt%2C+S">Stephan Schoenfeldt</a>, 
<a href="/search/cs?searchtype=author&query=Daugalas%2C+J">Jonas Daugalas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures, submitted to 2024 IEEE Topical Conference on Wireless Sensors and Sensor Networks (WiSNeT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces a lightweight gesture recognition system based on 60
GHz frequency modulated continuous wave (FMCW) radar. We show that gestures can
be characterized efficiently by a set of five features, and propose a slim
radar processing algorithm to extract these features. In contrast to previous
approaches, we avoid heavy 2D processing, i.e. range-Doppler imaging, and
perform instead an early target detection - this allows us to port the system
to fully embedded platforms with tight constraints on memory, compute and power
consumption. A recurrent neural network (RNN) based architecture exploits these
features to jointly detect and classify five different gestures. The proposed
system recognizes gestures with an F1 score of 98.4% on our hold-out test
dataset, it runs on an Arm Cortex-M4 microcontroller requiring less than 280 kB
of flash memory, 120 kB of RAM, and consuming 75 mW of power.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08877" title="Abstract">arXiv:2310.08877</a> [<a href="/pdf/2310.08877" title="Download PDF">pdf</a>, <a href="/format/2310.08877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weizhou Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yingqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Canbin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Developing an efficient retriever to retrieve knowledge from a large-scale
knowledge base (KB) is critical for task-oriented dialogue systems to
effectively handle localized and specialized tasks. However, widely used
generative models such as T5 and ChatGPT often struggle to differentiate subtle
differences among the retrieved KB records when generating responses, resulting
in suboptimal quality of generated responses. In this paper, we propose the
application of maximal marginal likelihood to train a perceptive retriever by
utilizing signals from response generation for supervision. In addition, our
approach goes beyond considering solely retrieved entities and incorporates
various meta knowledge to guide the generator, thus improving the utilization
of knowledge. We evaluate our approach on three task-oriented dialogue datasets
using T5 and ChatGPT as the backbone models. The results demonstrate that when
combined with meta knowledge, the response generator can effectively leverage
high-quality knowledge records from the retriever and enhance the quality of
generated responses. The codes and models of this paper are available at
https://github.com/shenwzh3/MK-TOD.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08878" title="Abstract">arXiv:2310.08878</a> [<a href="/pdf/2310.08878" title="Download PDF">pdf</a>, <a href="/ps/2310.08878" title="Download PostScript">ps</a>, <a href="/format/2310.08878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convexification for a Coefficient Inverse Problem of Mean Field Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klibanov%2C+M+V">Michael V. Klibanov</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jingzhi Li</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Z">Zhipeng Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The globally convergent convexification numerical method is constructed for a
Coefficient Inverse Problem for the Mean Field Games System. A coefficient
characterizing the global interaction term is recovered from the single
measurement data. In particular, a new Carleman estimate for the Volterra
integral operator is proven, and it stronger than the previously known one.
Numerical results demonstrate accurate reconstructions from noisy data.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08879" title="Abstract">arXiv:2310.08879</a> [<a href="/pdf/2310.08879" title="Download PDF">pdf</a>, <a href="/format/2310.08879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Review of Large Language Model on Software Engineering: An  Example from ChatGPT and Automated Program Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tongke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Juan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have been gaining increasing attention and
demonstrated promising performance across a variety of Software Engineering
(SE) tasks, such as Automated Program Repair (APR), code summarization, and
code completion. For example, ChatGPT, the latest black-box LLM, has been
investigated by numerous recent research studies and has shown impressive
performance in various tasks. However, there exists a potential risk of data
leakage since these LLMs are usually close-sourced with unknown specific
training details, e.g., pre-training datasets.
<br />In this paper, we seek to review the bug-fixing capabilities of ChatGPT on a
clean APR benchmark with different research objectives. We first introduce
{\benchmark}, a new benchmark with buggy and the corresponding fixed programs
from competitive programming problems starting from 2023, after the training
cutoff point of ChatGPT. The results on {\benchmark} show that ChatGPT is able
to fix 109 out of 151 buggy programs using the basic prompt within 35
independent rounds, outperforming state-of-the-art LLMs CodeT5 and PLBART by
27.5\% and 62.4\% prediction accuracy. We also investigate the impact of three
types of prompts, i.e., problem description, error feedback, and bug
localization, leading to additional 34 fixed bugs. Besides, we provide
additional discussion from the interactive nature of ChatGPT to illustrate the
capacity of a dialog-based repair workflow with 9 additional fixed bugs.
Inspired by the findings, we further pinpoint various challenges and
opportunities for advanced SE study equipped with such LLMs (e.g.,~ChatGPT) in
the near future. More importantly, our work calls for more research on the
reevaluation of the achievements obtained by existing black-box LLMs across
various SE tasks, not limited to ChatGPT on APR.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08881" title="Abstract">arXiv:2310.08881</a> [<a href="/pdf/2310.08881" title="Download PDF">pdf</a>, <a href="/format/2310.08881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Resource Sharing via Dynamic Max-Min Fairness: Efficiency,  Robustness and Non-Stationarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fikioris%2C+G">Giannis Fikioris</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Siddhartha Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Tardos%2C+%C3%89">&#xc9;va Tardos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the allocation of shared resources over multiple rounds among
competing agents, via a dynamic max-min fair (DMMF) mechanism: the good in each
round is allocated to the requesting agent with the least number of allocations
received to date. Previous work has shown that when an agent has i.i.d. values
across rounds, then in the worst case, she can never get more than a constant
strictly less than $1$ fraction of her ideal utility -- her highest achievable
utility given her nominal share of resources. Moreover, an agent can achieve at
least half her utility under carefully designed `pseudo-market' mechanisms,
even though other agents may act in an arbitrary (possibly adversarial and
collusive) manner.
<br />We show that this robustness guarantee also holds under the much simpler DMMF
mechanism. More significantly, under mild assumptions on the value
distribution, we show that DMMF in fact allows each agent to realize a $1 -
o(1)$ fraction of her ideal utility, despite arbitrary behavior by other
agents. We achieve this by characterizing the utility achieved under a richer
space of strategies, wherein an agent can tune how aggressive to be in
requesting the item. Our new strategies also allow us to handle settings where
an agent's values are correlated across rounds, thereby allowing an adversary
to predict and block her future values. We prove that again by tuning one's
aggressiveness, an agent can guarantee $\Omega(\gamma)$ fraction of her ideal
utility, where $\gamma\in [0, 1]$ is a parameter that quantifies dependence
across rounds (with $\gamma = 1$ indicating full independence and lower values
indicating more correlation). Finally, we extend our efficiency results to the
case of reusable resources, where an agent might need to hold the item over
multiple rounds to receive utility.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08884" title="Abstract">arXiv:2310.08884</a> [<a href="/pdf/2310.08884" title="Download PDF">pdf</a>, <a href="/format/2310.08884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Multi-modal Contrastive Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Tao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at <a href="https://github.com/MCR-PEFT/Ex-MCR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-modal contrastive representation (MCR) of more than three modalities is
critical in multi-modal learning. Although recent methods showcase impressive
achievements, the high dependence on large-scale, high-quality paired data and
the expensive training costs limit their further development. Inspired by
recent C-MCR, this paper proposes Extending Multimodal Contrastive
Representation (Ex-MCR), a training-efficient and paired-data-free method to
flexibly learn unified contrastive representation space for more than three
modalities by integrating the knowledge of existing MCR spaces. Specifically,
Ex-MCR aligns multiple existing MCRs into the same based MCR, which can
effectively preserve the original semantic alignment of the based MCR. Besides,
we comprehensively enhance the entire learning pipeline for aligning MCR spaces
from the perspectives of training data, architecture, and learning objectives.
With the preserved original modality alignment and the enhanced space
alignment, Ex-MCR shows superior representation learning performance and
excellent modality extensibility. To demonstrate the effectiveness of Ex-MCR,
we align the MCR spaces of CLAP (audio-text) and ULIP (3D-vision) into the CLIP
(vision-text), leveraging the overlapping text and image modality,
respectively. Remarkably, without using any paired data, Ex-MCR learns a
3D-image-text-audio unified contrastive representation, and it achieves
state-of-the-art performance on audio-visual, 3D-image, audio-text, visual-text
retrieval, and 3D object classification tasks. More importantly, extensive
qualitative results further demonstrate the emergent semantic alignment between
the extended modalities (e.g., audio and 3D), which highlights the great
potential of modality extensibility.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08885" title="Abstract">arXiv:2310.08885</a> [<a href="/pdf/2310.08885" title="Download PDF">pdf</a>, <a href="/format/2310.08885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructTODS: Large Language Models for End-to-End Task-Oriented  Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+W">Willy Chung</a>, 
<a href="/search/cs?searchtype=author&query=Cahyawijaya%2C+S">Samuel Cahyawijaya</a>, 
<a href="/search/cs?searchtype=author&query=Wilie%2C+B">Bryan Wilie</a>, 
<a href="/search/cs?searchtype=author&query=Lovenia%2C+H">Holy Lovenia</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have been used for diverse tasks in natural
language processing (NLP), yet remain under-explored for task-oriented dialogue
systems (TODS), especially for end-to-end TODS. We present InstructTODS, a
novel off-the-shelf framework for zero-shot end-to-end task-oriented dialogue
systems that can adapt to diverse domains without fine-tuning. By leveraging
LLMs, InstructTODS generates a proxy belief state that seamlessly translates
user intentions into dynamic queries for efficient interaction with any KB. Our
extensive experiments demonstrate that InstructTODS achieves comparable
performance to fully fine-tuned TODS in guiding dialogues to successful
completion without prior knowledge or task-specific data. Furthermore, a
rigorous human evaluation of end-to-end TODS shows that InstructTODS produces
dialogue responses that notably outperform both the gold responses and the
state-of-the-art TODS in terms of helpfulness, informativeness, and humanness.
Moreover, the effectiveness of LLMs in TODS is further supported by our
comprehensive evaluations on TODS subtasks: dialogue state tracking, intent
classification, and response generation. Code and implementations could be
found here https://github.com/WillyHC22/InstructTODS/
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08887" title="Abstract">arXiv:2310.08887</a> [<a href="/pdf/2310.08887" title="Download PDF">pdf</a>, <a href="/format/2310.08887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> METRA: Scalable Unsupervised RL with Metric-Aware Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seohong Park</a>, 
<a href="/search/cs?searchtype=author&query=Rybkin%2C+O">Oleh Rybkin</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Unsupervised pre-training strategies have proven to be highly effective in
natural language processing and computer vision. Likewise, unsupervised
reinforcement learning (RL) holds the promise of discovering a variety of
potentially useful behaviors that can accelerate the learning of a wide array
of downstream tasks. Previous unsupervised RL approaches have mainly focused on
pure exploration and mutual information skill learning. However, despite the
previous attempts, making unsupervised RL truly scalable still remains a major
open challenge: pure exploration approaches might struggle in complex
environments with large state spaces, where covering every possible transition
is infeasible, and mutual information skill learning approaches might
completely fail to explore the environment due to the lack of incentives. To
make unsupervised RL scalable to complex, high-dimensional environments, we
propose a novel unsupervised RL objective, which we call Metric-Aware
Abstraction (METRA). Our main idea is, instead of directly covering the entire
state space, to only cover a compact latent space $Z$ that is metrically
connected to the state space $S$ by temporal distances. By learning to move in
every direction in the latent space, METRA obtains a tractable set of diverse
behaviors that approximately cover the state space, being scalable to
high-dimensional environments. Through our experiments in five locomotion and
manipulation environments, we demonstrate that METRA can discover a variety of
useful behaviors even in complex, pixel-based environments, being the first
unsupervised RL method that discovers diverse locomotion behaviors in
pixel-based Quadruped and Humanoid. Our code and videos are available at
https://seohong.me/projects/metra/
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08888" title="Abstract">arXiv:2310.08888</a> [<a href="/pdf/2310.08888" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Transfer Learning Assisted Decision Support System for Accurate  Prediction of Alzheimer Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahadi%2C+M+K">Mahin Khan Mahadi</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A">Abdullah Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Uddin%2C+J">Jamal Uddin</a>, 
<a href="/search/cs?searchtype=author&query=Newaz%2C+A">Asif Newaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Alzheimer's disease (AD) is the most common long-term illness in elderly
people. In recent years, deep learning has become popular in the area of
medical imaging and has had a lot of success there. It has become the most
effective way to look at medical images. When it comes to detecting AD, the
deep neural model is more accurate and effective than general machine learning.
Our research contributes to the development of a more comprehensive
understanding and detection of the disease by identifying four distinct classes
that are predictive of AD with a high weighted accuracy of 98.91%. A unique
strategy has been proposed to improve the accuracy of the imbalance dataset
classification problem via the combination of ensemble averaging models and
five different transfer learning models in this study.
EfficientNetB0+Resnet152(effnet+res152) and
InceptionV3+EfficientNetB0+Resnet50(incep+effnet+res50) models have been
fine-tuned and have reached the highest weighted accuracy for multi-class AD
stage classifications.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08889" title="Abstract">arXiv:2310.08889</a> [<a href="/pdf/2310.08889" title="Download PDF">pdf</a>, <a href="/format/2310.08889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerturbScore: Connecting Discrete and Continuous Perturbations in NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Ke Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yunfan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Findings of EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the rapid development of neural network applications in NLP, model
robustness problem is gaining more attention. Different from computer vision,
the discrete nature of texts makes it more challenging to explore robustness in
NLP. Therefore, in this paper, we aim to connect discrete perturbations with
continuous perturbations, therefore we can use such connections as a bridge to
help understand discrete perturbations in NLP models. Specifically, we first
explore how to connect and measure the correlation between discrete
perturbations and continuous perturbations. Then we design a regression task as
a PerturbScore to learn the correlation automatically. Through experimental
results, we find that we can build a connection between discrete and continuous
perturbations and use the proposed PerturbScore to learn such correlation,
surpassing previous methods used in discrete perturbation measuring. Further,
the proposed PerturbScore can be well generalized to different datasets,
perturbation methods, indicating that we can use it as a powerful tool to study
model robustness in NLP.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08891" title="Abstract">arXiv:2310.08891</a> [<a href="/pdf/2310.08891" title="Download PDF">pdf</a>, <a href="/format/2310.08891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHI: End-to-end Learning of Hierarchical Index for Efficient Dense  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ramnath Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Anshul Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nilesh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kusupati%2C+A">Aditya Kusupati</a>, 
<a href="/search/cs?searchtype=author&query=Dhillon%2C+I">Inderjit Dhillon</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Prateek Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Dense embedding-based retrieval is now the industry standard for semantic
search and ranking problems, like obtaining relevant web documents for a given
query. Such techniques use a two-stage process: (a) contrastive learning to
train a dual encoder to embed both the query and documents and (b) approximate
nearest neighbor search (ANNS) for finding similar documents for a given query.
These two stages are disjoint; the learned embeddings might be ill-suited for
the ANNS method and vice-versa, leading to suboptimal performance. In this
work, we propose End-to-end Hierarchical Indexing -- EHI -- that jointly learns
both the embeddings and the ANNS structure to optimize retrieval performance.
EHI uses a standard dual encoder model for embedding queries and documents
while learning an inverted file index (IVF) style tree structure for efficient
ANNS. To ensure stable and efficient learning of discrete tree-based ANNS
structure, EHI introduces the notion of dense path embedding that captures the
position of a query/document in the tree. We demonstrate the effectiveness of
EHI on several benchmarks, including de-facto industry standard MS MARCO (Dev
set and TREC DL19) datasets. For example, with the same compute budget, EHI
outperforms state-of-the-art (SOTA) in by 0.6% (MRR@10) on MS MARCO dev set and
by 4.2% (nDCG@10) on TREC DL19 benchmarks.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08892" title="Abstract">arXiv:2310.08892</a> [<a href="/pdf/2310.08892" title="Download PDF">pdf</a>, <a href="/format/2310.08892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Cropping under Design Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishiyasu%2C+T">Takumi Nishiyasu</a>, 
<a href="/search/cs?searchtype=author&query=Shimoda%2C+W">Wataru Shimoda</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACMMM Asia accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image cropping is essential in image editing for obtaining a compositionally
enhanced image. In display media, image cropping is a prospective technique for
automatically creating media content. However, image cropping for media
contents is often required to satisfy various constraints, such as an aspect
ratio and blank regions for placing texts or objects. We call this problem
image cropping under design constraints. To achieve image cropping under design
constraints, we propose a score function-based approach, which computes scores
for cropped results whether aesthetically plausible and satisfies design
constraints. We explore two derived approaches, a proposal-based approach, and
a heatmap-based approach, and we construct a dataset for evaluating the
performance of the proposed approaches on image cropping under design
constraints. In experiments, we demonstrate that the proposed approaches
outperform a baseline, and we observe that the proposal-based approach is
better than the heatmap-based approach under the same computation cost, but the
heatmap-based approach leads to better scores by increasing computation cost.
The experimental results indicate that balancing aesthetically plausible
regions and satisfying design constraints is not a trivial problem and requires
sensitive balance, and both proposed approaches are reasonable alternatives.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08893" title="Abstract">arXiv:2310.08893</a> [<a href="/pdf/2310.08893" title="Download PDF">pdf</a>, <a href="/format/2310.08893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-efficiency and positivity-preserving stabilized SAV methods for  gradient flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhengguang Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yanrong Zhang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiaoli Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The scalar auxiliary variable (SAV)-type methods are very popular techniques
for solving various nonlinear dissipative systems. Compared to the
semi-implicit method, the baseline SAV method can keep a modified energy
dissipation law but doubles the computational cost. The general SAV approach
does not add additional computation but needs to solve a semi-implicit solution
in advance, which may potentially compromise the accuracy and stability. In
this paper, we construct a novel first- and second-order unconditional energy
stable and positivity-preserving stabilized SAV (PS-SAV) schemes for $L^2$ and
$H^{-1}$ gradient flows. The constructed schemes can reduce nearly half
computational cost of the baseline SAV method and preserve its accuracy and
stability simultaneously. Meanwhile, the introduced auxiliary variable is
always positive while the baseline SAV cannot guarantee this
positivity-preserving property. Unconditionally energy dissipation laws are
derived for the proposed numerical schemes. We also establish a rigorous error
analysis of the first-order scheme for the Allen-Cahn type equation in
$l^{\infty}(0,T; H^1(\Omega) ) $ norm. In addition we propose an energy
optimization technique to optimize the modified energy close to the original
energy. Several interesting numerical examples are presented to demonstrate the
accuracy and effectiveness of the proposed methods.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08894" title="Abstract">arXiv:2310.08894</a> [<a href="/pdf/2310.08894" title="Download PDF">pdf</a>, <a href="/ps/2310.08894" title="Download PostScript">ps</a>, <a href="/format/2310.08894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Antenna Coded Caching for Multi-Access Networks with Cyclic  Wrap-Around
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peter%2C+E">Elizabath Peter</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+K+K+K">K. K. Krishnan Namboodiri</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+B+S">B. Sundar Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages (double column), 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This work explores a multiple transmit antenna setting in a multi-access
coded caching (MACC) network where each user accesses more than one cache. A
MACC network has $K$ users and $K$ caches, and each user has access to $r &lt; K$
consecutive caches in a cyclic wrap-around manner. There are $L$ antennas at
the server, and each cache has a normalized size of $M/N \leq 1$. The cyclic
wrap-around MACC network with a single antenna at the server has been a
well-investigated topic, and several coded caching schemes and improved lower
bounds on the performance are known for the same. However, this MACC network
has not yet been studied under multi-antenna settings in the coded caching
literature. We study the multi-antenna MACC problem and propose a solution for
the same by constructing a pair of arrays called caching and delivery arrays.
We present three constructions of caching and delivery arrays for different
scenarios and obtain corresponding multi-antenna MACC schemes for the same. Two
schemes resulting from the above constructions achieve optimal performance
under uncoded placement and one-shot delivery. The optimality is shown by
matching the performance of the multi-antenna MACC scheme to that of an optimal
multi-antenna scheme for a dedicated cache network having an identical number
of users, and each user has a normalized cache size of $rM/N$. Further, as a
special case, one of the proposed schemes subsumes an existing optimal MACC
scheme for the single-antenna setting.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08895" title="Abstract">arXiv:2310.08895</a> [<a href="/pdf/2310.08895" title="Download PDF">pdf</a>, <a href="/format/2310.08895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Rationally Select Your Delegatee in PoS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">This paper centers around a simple yet crucial question for everyday users:
How should one choose their delegated validators within proof-of-stake (PoS)
protocols, particularly in the context of Ethereum 2.0? This has been a
long-overlooked gap, as existing studies have primarily focused on
inter-committee (validator set) behaviors and activities, while neglecting the
dynamic formation of committees, especially for individual stakeholders seeking
reliable validators. Our study bridges this gap by diving into the delegation
process (normal users delegate their small-value tokens to delegatees who later
act as validators) before entering an actual consensus phase.
<br />We propose a Bayesian model to quantify normal users' trust in delegatees,
which we further incorporate into a game-theoretical model to simulate users'
reactions against a set of critical factors identified through extensive
research (including 10+ staking service provider as well as 30+ PoS
blockchains). Our results reveal that users tend to choose their delegatees and
utilize their tokens by carefully weighing the delegation cost, the behaviors
of other users, and the reputation of delegatees, ultimately reaching a Nash
equilibrium. Unfortunately, the collective trend significantly increases the
likelihood of token concentration on a small number of delegatees.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08896" title="Abstract">arXiv:2310.08896</a> [<a href="/pdf/2310.08896" title="Download PDF">pdf</a>, <a href="/format/2310.08896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Migrant Resettlement by Evolutionary Multi-objective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dan-Xuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu-Ran Gu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xin Mu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Migration has been a universal phenomenon, which brings opportunities as well
as challenges for global development. As the number of migrants (e.g.,
refugees) increases rapidly in recent years, a key challenge faced by each
country is the problem of migrant resettlement. This problem has attracted
scientific research attention, from the perspective of maximizing the
employment rate. Previous works mainly formulated migrant resettlement as an
approximately submodular optimization problem subject to multiple matroid
constraints and employed the greedy algorithm, whose performance, however, may
be limited due to its greedy nature. In this paper, we propose a new framework
MR-EMO based on Evolutionary Multi-objective Optimization, which reformulates
Migrant Resettlement as a bi-objective optimization problem that maximizes the
expected number of employed migrants and minimizes the number of dispatched
migrants simultaneously, and employs a Multi-Objective Evolutionary Algorithm
(MOEA) to solve the bi-objective problem. We implement MR-EMO using three
MOEAs, the popular NSGA-II, MOEA/D as well as the theoretically grounded GSEMO.
To further improve the performance of MR-EMO, we propose a specific MOEA,
called GSEMO-SR, using matrix-swap mutation and repair mechanism, which has a
better ability to search for feasible solutions. We prove that MR-EMO using
either GSEMO or GSEMO-SR can achieve better theoretical guarantees than the
previous greedy algorithm. Experimental results under the interview and
coordination migration models clearly show the superiority of MR-EMO (with
either NSGA-II, MOEA/D, GSEMO or GSEMO-SR) over previous algorithms, and that
using GSEMO-SR leads to the best performance of MR-EMO.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08899" title="Abstract">arXiv:2310.08899</a> [<a href="/pdf/2310.08899" title="Download PDF">pdf</a>, <a href="/format/2310.08899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration with Principles for Diverse AI Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Training large transformers using next-token prediction has given rise to
groundbreaking advancements in AI. While this generative AI approach has
produced impressive results, it heavily leans on human supervision. Even
state-of-the-art AI models like ChatGPT depend on fine-tuning through human
demonstrations, demanding extensive human input and domain expertise. This
strong reliance on human oversight poses a significant hurdle to the
advancement of AI innovation. To address this limitation, we propose a novel
paradigm termed Exploratory AI (EAI) aimed at autonomously generating
high-quality training data. Drawing inspiration from unsupervised reinforcement
learning (RL) pretraining, EAI achieves exploration within the natural language
space. We accomplish this by harnessing large language models to assess the
novelty of generated content. Our approach employs two key components: an actor
that generates novel content following exploration principles and a critic that
evaluates the generated content, offering critiques to guide the actor.
Empirical evaluations demonstrate that EAI significantly boosts model
performance on complex reasoning tasks, addressing the limitations of
human-intensive supervision.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08901" title="Abstract">arXiv:2310.08901</a> [<a href="/pdf/2310.08901" title="Download PDF">pdf</a>, <a href="/format/2310.08901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Welfare Diplomacy: Benchmarking Language Model Cooperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukobi%2C+G">Gabriel Mukobi</a>, 
<a href="/search/cs?searchtype=author&query=Erlebach%2C+H">Hannah Erlebach</a>, 
<a href="/search/cs?searchtype=author&query=Lauffer%2C+N">Niklas Lauffer</a>, 
<a href="/search/cs?searchtype=author&query=Hammond%2C+L">Lewis Hammond</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">Alan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+J">Jesse Clifton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The growing capabilities and increasingly widespread deployment of AI systems
necessitate robust benchmarks for measuring their cooperative capabilities.
Unfortunately, most multi-agent benchmarks are either zero-sum or purely
cooperative, providing limited opportunities for such measurements. We
introduce a general-sum variant of the zero-sum board game Diplomacy -- called
Welfare Diplomacy -- in which players must balance investing in military
conquest and domestic welfare. We argue that Welfare Diplomacy facilitates both
a clearer assessment of and stronger training incentives for cooperative
capabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules
and implementing them via an open-source Diplomacy engine; (2) constructing
baseline agents using zero-shot prompted language models; and (3) conducting
experiments where we find that baselines using state-of-the-art models attain
high social welfare but are exploitable. Our work aims to promote societal
safety by aiding researchers in developing and assessing multi-agent AI
systems. Code to evaluate Welfare Diplomacy and reproduce our experiments is
available at https://github.com/mukobi/welfare-diplomacy.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08903" title="Abstract">arXiv:2310.08903</a> [<a href="/pdf/2310.08903" title="Download PDF">pdf</a>, <a href="/format/2310.08903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeqXGPT: Sentence-Level AI-Generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Ke Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Botian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Widely applied large language models (LLMs) can generate human-like content,
raising concerns about the abuse of LLMs. Therefore, it is important to build
strong AI-generated text (AIGT) detectors. Current works only consider
document-level AIGT detection, therefore, in this paper, we first introduce a
sentence-level detection challenge by synthesizing a dataset that contains
documents that are polished with LLMs, that is, the documents contain sentences
written by humans and sentences modified by LLMs. Then we propose
\textbf{Seq}uence \textbf{X} (Check) \textbf{GPT}, a novel method that utilizes
log probability lists from white-box LLMs as features for sentence-level AIGT
detection. These features are composed like \textit{waves} in speech processing
and cannot be studied by LLMs. Therefore, we build SeqXGPT based on convolution
and self-attention networks. We test it in both sentence and document-level
detection challenges. Experimental results show that previous methods struggle
in solving sentence-level AIGT detection, while our method not only
significantly surpasses baseline methods in both sentence and document-level
detection challenges but also exhibits strong generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08904" title="Abstract">arXiv:2310.08904</a> [<a href="/pdf/2310.08904" title="Download PDF">pdf</a>, <a href="/format/2310.08904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Understanding of Deformable Linear Objects: Datasets and  Transferability Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%BDagar%2C+B+L">Bare Luka &#x17d;agar</a>, 
<a href="/search/cs?searchtype=author&query=Hertel%2C+T">Tim Hertel</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yurtsever%2C+E">Ekim Yurtsever</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A+C">ALois C. Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deformable linear objects are vastly represented in our everyday lives. It is
often challenging even for humans to visually understand them, as the same
object can be entangled so that it appears completely different. Examples of
deformable linear objects include blood vessels and wiring harnesses, vital to
the functioning of their corresponding systems, such as the human body and a
vehicle. However, no point cloud datasets exist for studying 3D deformable
linear objects. Therefore, we are introducing two point cloud datasets,
PointWire and PointVessel. We evaluated state-of-the-art methods on the
proposed large-scale 3D deformable linear object benchmarks. Finally, we
analyzed the generalization capabilities of these methods by conducting
transferability experiments on the PointWire and PointVessel datasets.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08908" title="Abstract">arXiv:2310.08908</a> [<a href="/pdf/2310.08908" title="Download PDF">pdf</a>, <a href="/format/2310.08908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-in-the-loop Machine Translation with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+R">Runzhe Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+D+F">Derek F. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junchao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+L+S">Lidia S. Chao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to MT Summit 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The large language model (LLM) has garnered significant attention due to its
in-context learning mechanisms and emergent capabilities. The research
community has conducted several pilot studies to apply LLMs to machine
translation tasks and evaluate their performance from diverse perspectives.
However, previous research has primarily focused on the LLM itself and has not
explored human intervention in the inference process of LLM. The
characteristics of LLM, such as in-context learning and prompt engineering,
closely mirror human cognitive abilities in language tasks, offering an
intuitive solution for human-in-the-loop generation. In this study, we propose
a human-in-the-loop pipeline that guides LLMs to produce customized outputs
with revision instructions. The pipeline initiates by prompting the LLM to
produce a draft translation, followed by the utilization of automatic retrieval
or human feedback as supervision signals to enhance the LLM's translation
through in-context learning. The human-machine interactions generated in this
pipeline are also stored in an external database to expand the in-context
retrieval database, enabling us to leverage human supervision in an offline
setting. We evaluate the proposed pipeline using GPT-3.5-turbo API on five
domain-specific benchmarks for German-English translation. The results
demonstrate the effectiveness of the pipeline in tailoring in-domain
translations and improving translation performance compared to direct
translation. Additionally, we discuss the results from the following
perspectives: 1) the effectiveness of different in-context retrieval methods;
2) the construction of a retrieval database under low-resource scenarios; 3)
the observed domains differences; 4) the quantitative analysis of linguistic
statistics; and 5) the qualitative analysis of translation cases. The code and
data are available at https://github.com/NLP2CT/HIL-MT/.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08909" title="Abstract">arXiv:2310.08909</a> [<a href="/pdf/2310.08909" title="Download PDF">pdf</a>, <a href="/format/2310.08909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Community Membership Hiding as Counterfactual Graph Search via Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernini%2C+A">Andrea Bernini</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>, 
<a href="/search/cs?searchtype=author&query=Tolomei%2C+G">Gabriele Tolomei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Community detection techniques are useful tools for social media platforms to
discover tightly connected groups of users who share common interests. However,
this functionality often comes at the expense of potentially exposing
individuals to privacy breaches by inadvertently revealing their tastes or
preferences. Therefore, some users may wish to safeguard their anonymity and
opt out of community detection for various reasons, such as affiliation with
political or religious organizations.
<br />In this study, we address the challenge of community membership hiding, which
involves strategically altering the structural properties of a network graph to
prevent one or more nodes from being identified by a given community detection
algorithm. We tackle this problem by formulating it as a constrained
counterfactual graph objective, and we solve it via deep reinforcement
learning. We validate the effectiveness of our method through two distinct
tasks: node and community deception. Extensive experiments show that our
approach overall outperforms existing baselines in both tasks.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08910" title="Abstract">arXiv:2310.08910</a> [<a href="/pdf/2310.08910" title="Download PDF">pdf</a>, <a href="/format/2310.08910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalarization for Multi-Task and Multi-Domain Learning at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Royer%2C+A">Amelie Royer</a>, 
<a href="/search/cs?searchtype=author&query=Blankevoort%2C+T">Tijmen Blankevoort</a>, 
<a href="/search/cs?searchtype=author&query=Bejnordi%2C+B+E">Babak Ehteshami Bejnordi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; <a href="https://openreview.net/forum?id=TSuq3debnD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Training a single model on multiple input domains and/or output tasks allows
for compressing information from multiple sources into a unified backbone hence
improves model efficiency. It also enables potential positive knowledge
transfer across tasks/domains, leading to improved accuracy and data-efficient
training. However, optimizing such networks is a challenge, in particular due
to discrepancies between the different tasks or domains: Despite several
hypotheses and solutions proposed over the years, recent work has shown that
uniform scalarization training, i.e., simply minimizing the average of the task
losses, yields on-par performance with more costly SotA optimization methods.
This raises the issue of how well we understand the training dynamics of
multi-task and multi-domain networks. In this work, we first devise a
large-scale unified analysis of multi-domain and multi-task learning to better
understand the dynamics of scalarization across varied task/domain combinations
and model sizes. Following these insights, we then propose to leverage
population-based training to efficiently search for the optimal scalarization
weights when dealing with a large number of tasks or domains.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08914" title="Abstract">arXiv:2310.08914</a> [<a href="/pdf/2310.08914" title="Download PDF">pdf</a>, <a href="/ps/2310.08914" title="Download PostScript">ps</a>, <a href="/format/2310.08914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Evolution Algorithm based Hyper-Parameters Selection of  Convolutional Neural Network for Speech Command Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhar%2C+S">Sandipan Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+A">Anuvab Sen</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+A">Aritra Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+N+D">Nanda Dulal Jana</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Arjun Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Sarayloo%2C+Z">Zahra Sarayloo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 7 Figures, 4 Tables, Accepted by the 15th International Joint Conference on Computational Intelligence (IJCCI 2023), November 13-15, 2023, Rome, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Neural and Evolutionary Computing (cs.NE); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech Command Recognition (SCR), which deals with identification of short
uttered speech commands, is crucial for various applications, including IoT
devices and assistive technology. Despite the promise shown by Convolutional
Neural Networks (CNNs) in SCR tasks, their efficacy relies heavily on
hyper-parameter selection, which is typically laborious and time-consuming when
done manually. This paper introduces a hyper-parameter selection method for
CNNs based on the Differential Evolution (DE) algorithm, aiming to enhance
performance in SCR tasks. Training and testing with the Google Speech Command
(GSC) dataset, the proposed approach showed effectiveness in classifying speech
commands. Moreover, a comparative analysis with Genetic Algorithm based
selections and other deep CNN (DCNN) models highlighted the efficiency of the
proposed DE algorithm in hyper-parameter selection for CNNs in SCR tasks.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08915" title="Abstract">arXiv:2310.08915</a> [<a href="/pdf/2310.08915" title="Download PDF">pdf</a>, <a href="/format/2310.08915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingbao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yiwu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xingjia Han</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+J">Jared Tanner</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The ever-increasing large language models (LLMs), though opening a potential
path for the upcoming artificial general intelligence, sadly drops a daunting
obstacle on the way towards their on-device deployment. As one of the most
well-established pre-LLMs approaches in reducing model complexity, network
pruning appears to lag behind in the era of LLMs, due mostly to its costly
fine-tuning (or re-training) necessity under the massive volumes of model
parameter and training data. To close this industry-academia gap, we introduce
Dynamic Sparse No Training (DSnoT), a training-free fine-tuning approach that
slightly updates sparse LLMs without the expensive backpropagation and any
weight updates. Inspired by the Dynamic Sparse Training, DSnoT minimizes the
reconstruction error between the dense and sparse LLMs, in the fashion of
performing iterative weight pruning-and-growing on top of sparse LLMs. To
accomplish this purpose, DSnoT particularly takes into account the anticipated
reduction in reconstruction error for pruning and growing, as well as the
variance w.r.t. different input data for growing each weight. This practice can
be executed efficiently in linear time since its obviates the need of
backpropagation for fine-tuning LLMs. Extensive experiments on LLaMA-V1/V2,
Vicuna, and OPT across various benchmarks demonstrate the effectiveness of
DSnoT in enhancing the performance of sparse LLMs, especially at high sparsity
levels. For instance, DSnoT is able to outperform the state-of-the-art Wanda by
26.79 perplexity at 70% sparsity with LLaMA-7B. Our paper offers fresh insights
into how to fine-tune sparse LLMs in an efficient training-free manner and open
new venues to scale the great potential of sparsity to LLMs. Codes are
available at https://github.com/zxyxmu/DSnoT.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08917" title="Abstract">arXiv:2310.08917</a> [<a href="/pdf/2310.08917" title="Download PDF">pdf</a>, <a href="/format/2310.08917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation-aware Ensemble Learning for Knowledge Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Ling Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Quanming Yao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenxi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This short paper has been accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Knowledge graph (KG) embedding is a fundamental task in natural language
processing, and various methods have been proposed to explore semantic patterns
in distinctive ways. In this paper, we propose to learn an ensemble by
leveraging existing methods in a relation-aware manner. However, exploring
these semantics using relation-aware ensemble leads to a much larger search
space than general ensemble methods. To address this issue, we propose a
divide-search-combine algorithm RelEns-DSC that searches the relation-wise
ensemble weights independently. This algorithm has the same computation cost as
general ensemble methods but with much better performance. Experimental results
on benchmark datasets demonstrate the effectiveness of the proposed method in
efficiently searching relation-aware ensemble weights and achieving
state-of-the-art embedding performance. The code is public at
https://github.com/LARS-research/RelEns.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08920" title="Abstract">arXiv:2310.08920</a> [<a href="/pdf/2310.08920" title="Download PDF">pdf</a>, <a href="/format/2310.08920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embarrassingly Simple Text Watermarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+R">Ryoma Sato</a>, 
<a href="/search/cs?searchtype=author&query=Takezawa%2C+Y">Yuki Takezawa</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Han Bao</a>, 
<a href="/search/cs?searchtype=author&query=Niwa%2C+K">Kenta Niwa</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+M">Makoto Yamada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We propose Easymark, a family of embarrassingly simple yet effective
watermarks. Text watermarking is becoming increasingly important with the
advent of Large Language Models (LLM). LLMs can generate texts that cannot be
distinguished from human-written texts. This is a serious problem for the
credibility of the text. Easymark is a simple yet effective solution to this
problem. Easymark can inject a watermark without changing the meaning of the
text at all while a validator can detect if a text was generated from a system
that adopted Easymark or not with high credibility. Easymark is extremely easy
to implement so that it only requires a few lines of code. Easymark does not
require access to LLMs, so it can be implemented on the user-side when the LLM
providers do not offer watermarked LLMs. In spite of its simplicity, it
achieves higher detection accuracy and BLEU scores than the state-of-the-art
text watermarking methods. We also prove the impossibility theorem of perfect
watermarking, which is valuable in its own right. This theorem shows that no
matter how sophisticated a watermark is, a malicious user could remove it from
the text, which motivate us to use a simple watermark such as Easymark. We
carry out experiments with LLM-generated texts and confirm that Easymark can be
detected reliably without any degradation of BLEU and perplexity, and
outperform state-of-the-art watermarks in terms of both quality and
reliability.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08921" title="Abstract">arXiv:2310.08921</a> [<a href="/pdf/2310.08921" title="Download PDF">pdf</a>, <a href="/format/2310.08921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Proliferation -- the &quot;Cancer&quot; in StyleGAN and its Treatments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuang Song</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuanbang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yipeng Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the success of StyleGAN in image synthesis, the images it synthesizes
are not always perfect and the well-known truncation trick has become a
standard post-processing technique for StyleGAN to synthesize high-quality
images. Although effective, it has long been noted that the truncation trick
tends to reduce the diversity of synthesized images and unnecessarily
sacrifices many distinct image features. To address this issue, in this paper,
we first delve into the StyleGAN image synthesis mechanism and discover an
important phenomenon, namely Feature Proliferation, which demonstrates how
specific features reproduce with forward propagation. Then, we show how the
occurrence of Feature Proliferation results in StyleGAN image artifacts. As an
analogy, we refer to it as the" cancer" in StyleGAN from its proliferating and
malignant nature. Finally, we propose a novel feature rescaling method that
identifies and modulates risky features to mitigate feature proliferation.
Thanks to our discovery of Feature Proliferation, the proposed feature
rescaling method is less destructive and retains more useful image features
than the truncation trick, as it is more fine-grained and works in a
lower-level feature space rather than a high-level latent space. Experimental
results justify the validity of our claims and the effectiveness of the
proposed feature rescaling method. Our code is available at https://github.
com/songc42/Feature-proliferation.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08922" title="Abstract">arXiv:2310.08922</a> [<a href="/pdf/2310.08922" title="Download PDF">pdf</a>, <a href="/format/2310.08922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaMA Rider: Spurring Large Language Models to Explore the Open World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yicheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiazheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sipeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, various studies have leveraged Large Language Models (LLMs) to help
decision-making and planning in environments, and try to align the LLMs'
knowledge with the world conditions. Nonetheless, the capacity of LLMs to
continuously acquire environmental knowledge and adapt in an open world remains
uncertain. In this paper, we propose an approach to spur LLMs to explore the
open world, gather experiences, and learn to improve their task-solving
capabilities. In this approach, a multi-round feedback-revision mechanism is
utilized to encourage LLMs to actively select appropriate revision actions
guided by feedback information from the environment. This facilitates
exploration and enhances the model's performance. Besides, we integrate
sub-task relabeling to assist LLMs in maintaining consistency in sub-task
planning and help the model learn the combinatorial nature between tasks,
enabling it to complete a wider range of tasks through training based on the
acquired exploration experiences. By evaluation in Minecraft, an open-ended
sandbox world, we demonstrate that our approach LLaMA-Rider enhances the
efficiency of the LLM in exploring the environment, and effectively improves
the LLM's ability to accomplish more tasks through fine-tuning with merely 1.3k
instances of collected data, showing minimal training costs compared to the
baseline using reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08923" title="Abstract">arXiv:2310.08923</a> [<a href="/pdf/2310.08923" title="Download PDF">pdf</a>, <a href="/format/2310.08923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Informative Few-Shot Prompt with Maximum Information Gain for  In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongfu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language models (LLMs) possess the capability to engage In-context
Learning (ICL) by leveraging a few demonstrations pertaining to a new
downstream task as conditions. However, this particular learning paradigm
suffers from high instability stemming from substantial variances induced by
factors such as the input distribution of selected examples, their ordering,
and prompt formats. In this work, we demonstrate that even when all these
factors are held constant, the random selection of examples still results in
high variance. Consequently, we aim to explore the informative ability of data
examples by quantifying the Information Gain (IG) obtained in prediction after
observing a given example candidate. Then we propose to sample those with
maximum IG. Additionally, we identify the presence of template bias, which can
lead to unfair evaluations of IG during the sampling process. To mitigate this
bias, we introduce Calibration Before Sampling strategy. The experimental
results illustrate that our proposed method can yield an average relative
improvement of 14.3% across six classification tasks using three LLMs.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08924" title="Abstract">arXiv:2310.08924</a> [<a href="/pdf/2310.08924" title="Download PDF">pdf</a>, <a href="/format/2310.08924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking The Assortativity Coefficient Under A Rewiring Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shuo Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Degree correlation is an important characteristic of networks, which is
usually quantified by the assortativity coefficient. However, concerns arise
about changing the assortativity coefficient of a network when networks suffer
from adversarial attacks. In this paper, we analyze the factors that affect the
assortativity coefficient and study the optimization problem of maximizing or
minimizing the assortativity coefficient (r) in rewired networks with $k$ pairs
of edges. We propose a greedy algorithm and formulate the optimization problem
using integer programming to obtain the optimal solution for this problem.
Through experiments, we demonstrate the reasonableness and effectiveness of our
proposed algorithm. For example, rewired edges 10% in the ER network, the
assortativity coefficient improved by 60%.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08928" title="Abstract">arXiv:2310.08928</a> [<a href="/pdf/2310.08928" title="Download PDF">pdf</a>, <a href="/format/2310.08928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIDE: Self-supervised Intermediate Domain Exploration for Source-free  Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Han Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yizhen Jia</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jie Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huiyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ningzhong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code at <a href="https://github.com/se111/SIDE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain adaptation aims to alleviate the domain shift when transferring the
knowledge learned from the source domain to the target domain. Due to privacy
issues, source-free domain adaptation (SFDA), where source data is unavailable
during adaptation, has recently become very demanding yet challenging. Existing
SFDA methods focus on either self-supervised learning of target samples or
reconstruction of virtual source data. The former overlooks the transferable
knowledge in the source model, whilst the latter introduces even more
uncertainty. To address the above issues, this paper proposes self-supervised
intermediate domain exploration (SIDE) that effectively bridges the domain gap
with an intermediate domain, where samples are cyclically filtered out in a
self-supervised fashion. First, we propose cycle intermediate domain filtering
(CIDF) to cyclically select intermediate samples with similar distributions
over source and target domains. Second, with the aid of those intermediate
samples, an inter-domain gap transition (IDGT) module is developed to mitigate
possible distribution mismatches between the source and target data. Finally,
we introduce cross-view consistency learning (CVCL) to maintain the intrinsic
class discriminability whilst adapting the model to the target domain.
Extensive experiments on three popular benchmarks, i.e. Office-31, Office-Home
and VisDA-C, show that our proposed SIDE achieves competitive performance
against state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08929" title="Abstract">arXiv:2310.08929</a> [<a href="/pdf/2310.08929" title="Download PDF">pdf</a>, <a href="/format/2310.08929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Controllability in Object-Centric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Janghyuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaehyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Ho-Jin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Seon Joo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The binding problem in artificial neural networks is actively explored with
the goal of achieving human-level recognition skills through the comprehension
of the world in terms of symbol-like entities. Especially in the field of
computer vision, object-centric learning (OCL) is extensively researched to
better understand complex scenes by acquiring object representations or slots.
While recent studies in OCL have made strides with complex images or videos,
the interpretability and interactivity over object representation remain
largely uncharted, still holding promise in the field of OCL. In this paper, we
introduce a novel method, Slot Attention with Image Augmentation (SlotAug), to
explore the possibility of learning interpretable controllability over slots in
a self-supervised manner by utilizing an image augmentation strategy. We also
devise the concept of sustainability in controllable slots by introducing
iterative and reversible controls over slots with two proposed submethods:
Auxiliary Identity Manipulation and Slot Consistency Loss. Extensive empirical
studies and theoretical validation confirm the effectiveness of our approach,
offering a novel capability for interpretable and sustainable control of object
representations. Code will be available soon.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08930" title="Abstract">arXiv:2310.08930</a> [<a href="/pdf/2310.08930" title="Download PDF">pdf</a>, <a href="/format/2310.08930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When $D$-companion matrix meets incomplete polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+T">Teng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)

</div>
<p class="mathjax">In this paper, by using methods of $D$-companion matrix, we reprove a
generalization of the Guass-Lucas theorem and get the majorization relationship
between the zeros of convex combinations of incomplete polynomials and an
origin polynomial. Moreover, we prove that the set of all zeros of all convex
combinations of incomplete polynomials coincides with the closed convex hull of
zeros of the original polynomial. The location of zeros of convex combinations
of incomplete polynomials is determined.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08931" title="Abstract">arXiv:2310.08931</a> [<a href="/pdf/2310.08931" title="Download PDF">pdf</a>, <a href="/format/2310.08931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven aerodynamic shape design with distributionally robust  optimization approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rottmayer%2C+J">Jan Rottmayer</a>, 
<a href="/search/cs?searchtype=author&query=Kusch%2C+L">Lisa Kusch</a>, 
<a href="/search/cs?searchtype=author&query=Gauger%2C+N+R">Nicolas R. Gauger</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yinyu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We formulate and solve data-driven aerodynamic shape design problems with
distributionally robust optimization (DRO) approaches. Building on the findings
of the work \cite{gotoh2018robust}, we study the connections between a class of
DRO and the Taguchi method in the context of robust design optimization. Our
preliminary computational experiments on aerodynamic shape optimization in
transonic turbulent flow show promising design results.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08932" title="Abstract">arXiv:2310.08932</a> [<a href="/pdf/2310.08932" title="Download PDF">pdf</a>, <a href="/format/2310.08932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIDE: Temporally Incremental Disparity Estimation via Pattern Flow in  Structured Light System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+R">Rukun Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Kawasaki%2C+H">Hiroshi Kawasaki</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+H">Hongbin Zha</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters ( Volume: 7, Issue: 2, April
  2022). pp 5111 - 5118
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduced Temporally Incremental Disparity Estimation Network (TIDE-Net),
a learning-based technique for disparity computation in mono-camera structured
light systems. In our hardware setting, a static pattern is projected onto a
dynamic scene and captured by a monocular camera. Different from most former
disparity estimation methods that operate in a frame-wise manner, our network
acquires disparity maps in a temporally incremental way. Specifically, We
exploit the deformation of projected patterns (named pattern flow ) on captured
image sequences, to model the temporal information. Notably, this newly
proposed pattern flow formulation reflects the disparity changes along the
epipolar line, which is a special form of optical flow. Tailored for pattern
flow, the TIDE-Net, a recurrent architecture, is proposed and implemented. For
each incoming frame, our model fuses correlation volumes (from current frame)
and disparity (from former frame) warped by pattern flow. From fused features,
the final stage of TIDE-Net estimates the residual disparity rather than the
full disparity, as conducted by many previous methods. Interestingly, this
design brings clear empirical advantages in terms of efficiency and
generalization ability. Using only synthetic data for training, our extensitve
evaluation results (w.r.t. both accuracy and efficienty metrics) show superior
performance than several SOTA models on unseen real data. The code is available
on https://github.com/CodePointer/TIDENet.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08934" title="Abstract">arXiv:2310.08934</a> [<a href="/pdf/2310.08934" title="Download PDF">pdf</a>, <a href="/format/2310.08934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Adaptive Disparity Estimation for Dynamic Scenes in Structured  Light Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+R">Rukun Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Kawasaki%2C+H">Hiroshi Kawasaki</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+H">Hongbin Zha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpeted by 36th IEEE/RSJ International Conference on Intelligent Robots and Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, deep neural networks have shown remarkable progress in dense
disparity estimation from dynamic scenes in monocular structured light systems.
However, their performance significantly drops when applied in unseen
environments. To address this issue, self-supervised online adaptation has been
proposed as a solution to bridge this performance gap. Unlike traditional
fine-tuning processes, online adaptation performs test-time optimization to
adapt networks to new domains. Therefore, achieving fast convergence during the
adaptation process is critical for attaining satisfactory accuracy. In this
paper, we propose an unsupervised loss function based on long sequential
inputs. It ensures better gradient directions and faster convergence. Our loss
function is designed using a multi-frame pattern flow, which comprises a set of
sparse trajectories of the projected pattern along the sequence. We estimate
the sparse pseudo ground truth with a confidence mask using a filter-based
method, which guides the online adaptation process. Our proposed framework
significantly improves the online adaptation speed and achieves superior
performance on unseen data.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08942" title="Abstract">arXiv:2310.08942</a> [<a href="/pdf/2310.08942" title="Download PDF">pdf</a>, <a href="/format/2310.08942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted sparsity and sparse tensor networks for least squares  approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Trunschke%2C+P">Philipp Trunschke</a>, 
<a href="/search/math?searchtype=author&query=Nouy%2C+A">Anthony Nouy</a>, 
<a href="/search/math?searchtype=author&query=Eigel%2C+M">Martin Eigel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Approximation of high-dimensional functions is a problem in many scientific
fields that is only feasible if advantageous structural properties, such as
sparsity in a given basis, can be exploited. A relevant tool for analysing
sparse approximations is Stechkin's lemma. In its standard form, however, this
lemma does not allow to explain convergence rates for a wide range of relevant
function classes.
<br />This work presents a new weighted version of Stechkin's lemma that improves
the best $n$-term rates for weighted $\ell^p$-spaces and associated function
classes such as Sobolev or Besov spaces. For the class of holomorphic
functions, which occur as solutions of common high-dimensional
parameter-dependent PDEs, we recover exponential rates that are not directly
obtainable with Stechkin's lemma.
<br />Since weighted $\ell^p$-summability induces weighted sparsity, compressed
sensing algorithms can be used to approximate the associated functions. To
break the curse of dimensionality, which these algorithms suffer, we recall
that sparse approximations can be encoded efficiently using tensor networks
with sparse component tensors. We also demonstrate that weighted
$\ell^p$-summability induces low ranks, which motivates a second tensor train
format with low ranks and a single weighted sparse core. We present new
alternating algorithms for best $n$-term approximation in both formats.
<br />To analyse the sample complexity for the new model classes, we derive a novel
result of independent interest that allows the transfer of the restricted
isometry property from one set to another sufficiently close set. Although they
lead up to the analysis of our final model class, our contributions on weighted
Stechkin and the restricted isometry property are of independent interest and
can be read independently.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08943" title="Abstract">arXiv:2310.08943</a> [<a href="/pdf/2310.08943" title="Download PDF">pdf</a>, <a href="/format/2310.08943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level Adaptive Contrastive Learning for Knowledge Internalization  in Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenxu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge-grounded dialogue generation aims to mitigate the issue of text
degeneration by incorporating external knowledge to supplement the context.
However, the model often fails to internalize this information into responses
in a human-like manner. Instead, it simply inserts segments of the provided
knowledge into generic responses. As a result, the generated responses tend to
be tedious, incoherent, and in lack of interactivity which means the
degeneration problem is still unsolved. In this work, we first find that such
copying-style degeneration is primarily due to the weak likelihood objective,
which allows the model to "cheat" the objective by merely duplicating knowledge
segments in a superficial pattern matching based on overlap. To overcome this
challenge, we then propose a Multi-level Adaptive Contrastive Learning (MACL)
framework that dynamically samples negative examples and subsequently penalizes
degeneration behaviors at both the token-level and sequence-level. Extensive
experiments on the WoW dataset demonstrate the effectiveness of our approach
across various pre-trained models.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08944" title="Abstract">arXiv:2310.08944</a> [<a href="/pdf/2310.08944" title="Download PDF">pdf</a>, <a href="/format/2310.08944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMELL: Confidence-based Acquisition Model for Efficient Self-supervised  Active Learning with Label Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Niekerk%2C+C">Carel van Niekerk</a>, 
<a href="/search/cs?searchtype=author&query=Geishauser%2C+C">Christian Geishauser</a>, 
<a href="/search/cs?searchtype=author&query=Heck%2C+M">Michael Heck</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsien-chin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lubis%2C+N">Nurul Lubis</a>, 
<a href="/search/cs?searchtype=author&query=Ruppik%2C+B">Benjamin Ruppik</a>, 
<a href="/search/cs?searchtype=author&query=Vukovic%2C+R">Renato Vukovic</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1i%C4%87%2C+M">Milica Ga&#x161;i&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Supervised neural approaches are hindered by their dependence on large,
meticulously annotated datasets, a requirement that is particularly cumbersome
for sequential tasks. The quality of annotations tends to deteriorate with the
transition from expert-based to crowd-sourced labelling. To address these
challenges, we present \textbf{CAMELL} (Confidence-based Acquisition Model for
Efficient self-supervised active Learning with Label validation), a pool-based
active learning framework tailored for sequential multi-output problems. CAMELL
possesses three core features: (1) it requires expert annotators to label only
a fraction of a chosen sequence, (2) it facilitates self-supervision for the
remainder of the sequence, and (3) it employs a label validation mechanism to
prevent erroneous labels from contaminating the dataset and harming model
performance. We evaluate CAMELL on sequential tasks, with a special emphasis on
dialogue belief tracking, a task plagued by the constraints of limited and
noisy datasets. Our experiments demonstrate that CAMELL outperforms the
baselines in terms of efficiency. Furthermore, the data corrections suggested
by our method contribute to an overall improvement in the quality of the
resulting datasets.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08946" title="Abstract">arXiv:2310.08946</a> [<a href="/pdf/2310.08946" title="Download PDF">pdf</a>, <a href="/ps/2310.08946" title="Download PostScript">ps</a>, <a href="/format/2310.08946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An example of goal-directed proof
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Backhouse%2C+R">Roland Backhouse</a>, 
<a href="/search/cs?searchtype=author&query=Guttmann%2C+W">Walter Guttmann</a>, 
<a href="/search/cs?searchtype=author&query=Winter%2C+M">Michael Winter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages. Submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We prove a non-trivial property of relations in a way that emphasises the
creative process in its construction.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08948" title="Abstract">arXiv:2310.08948</a> [<a href="/pdf/2310.08948" title="Download PDF">pdf</a>, <a href="/format/2310.08948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Class-Incremental Learning with Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiale Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yu-Wei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong-Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhen-Duo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin-Shun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As Web technology continues to develop, it has become increasingly common to
use data stored on different clients. At the same time, federated learning has
received widespread attention due to its ability to protect data privacy when
let models learn from data which is distributed across various clients.
However, most existing works assume that the client's data are fixed. In
real-world scenarios, such an assumption is most likely not true as data may be
continuously generated and new classes may also appear. To this end, we focus
on the practical and challenging federated class-incremental learning (FCIL)
problem. For FCIL, the local and global models may suffer from catastrophic
forgetting on old classes caused by the arrival of new classes and the data
distributions of clients are non-independent and identically distributed
(non-iid).
<br />In this paper, we propose a novel method called Federated Class-Incremental
Learning with PrompTing (FCILPT). Given the privacy and limited memory, FCILPT
does not use a rehearsal-based buffer to keep exemplars of old data. We choose
to use prompts to ease the catastrophic forgetting of the old classes.
Specifically, we encode the task-relevant and task-irrelevant knowledge into
prompts, preserving the old and new knowledge of the local clients and solving
the problem of catastrophic forgetting. We first sort the task information in
the prompt pool in the local clients to align the task information on different
clients before global aggregation. It ensures that the same task's knowledge
are fully integrated, solving the problem of non-iid caused by the lack of
classes among different clients in the same incremental task. Experiments on
CIFAR-100, Mini-ImageNet, and Tiny-ImageNet demonstrate that FCILPT achieves
significant accuracy improvements over the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08949" title="Abstract">arXiv:2310.08949</a> [<a href="/pdf/2310.08949" title="Download PDF">pdf</a>, <a href="/format/2310.08949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Multimodal Generation Easier: When Diffusion Models Meet LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present EasyGen, an efficient model designed to enhance multimodal
understanding and generation by harnessing the capabilities of diffusion models
and large language models (LLMs). Unlike existing multimodal models that
predominately depend on encoders like CLIP or ImageBind and need ample amounts
of training data to bridge the gap between modalities, EasyGen is built upon a
bidirectional conditional diffusion model named BiDiffuser, which promotes more
efficient interactions between modalities. EasyGen handles image-to-text
generation by integrating BiDiffuser and an LLM via a simple projection layer.
Unlike most existing multimodal models that are limited to generating text
responses, EasyGen can also facilitate text-to-image generation by leveraging
the LLM to create textual descriptions, which can be interpreted by BiDiffuser
to generate appropriate visual responses. Extensive quantitative and
qualitative experiments demonstrate the effectiveness of EasyGen, whose
training can be easily achieved in a lab setting. The source code is available
at https://github.com/zxy556677/EasyGen.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08950" title="Abstract">arXiv:2310.08950</a> [<a href="/pdf/2310.08950" title="Download PDF">pdf</a>, <a href="/ps/2310.08950" title="Download PostScript">ps</a>, <a href="/format/2310.08950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Autoencoder with ID Constraint for Unsupervised  Anomalous Sound Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jian Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Youde Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qiuqiang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Feiyang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qiaoxi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiantong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EURASIP Journal on Audio, Speech, and Music Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Unsupervised anomalous sound detection (ASD) aims to detect unknown anomalous
sounds of devices when only normal sound data is available. The autoencoder
(AE) and self-supervised learning based methods are two mainstream methods.
However, the AE-based methods could be limited as the feature learned from
normal sounds can also fit with anomalous sounds, reducing the ability of the
model in detecting anomalies from sound. The self-supervised methods are not
always stable and perform differently, even for machines of the same type. In
addition, the anomalous sound may be short-lived, making it even harder to
distinguish from normal sound. This paper proposes an ID constrained
Transformer-based autoencoder (IDC-TransAE) architecture with weighted anomaly
score computation for unsupervised ASD. Machine ID is employed to constrain the
latent space of the Transformer-based autoencoder (TransAE) by introducing a
simple ID classifier to learn the difference in the distribution for the same
machine type and enhance the ability of the model in distinguishing anomalous
sound. Moreover, weighted anomaly score computation is introduced to highlight
the anomaly scores of anomalous events that only appear for a short time.
Experiments performed on DCASE 2020 Challenge Task2 development dataset
demonstrate the effectiveness and superiority of our proposed method.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08951" title="Abstract">arXiv:2310.08951</a> [<a href="/pdf/2310.08951" title="Download PDF">pdf</a>, <a href="/format/2310.08951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log Anomaly Detection on EuXFEL Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulc%2C+A">Antonin Sulc</a>, 
<a href="/search/cs?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>, 
<a href="/search/cs?searchtype=author&query=Wilksen%2C+T">Tim Wilksen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This article introduces a method to detect anomalies in the log data
generated by control system nodes at the European XFEL accelerator. The primary
aim of this proposed method is to provide operators a comprehensive
understanding of the availability, status, and problems specific to each node.
This information is vital for ensuring the smooth operation. The sequential
nature of logs and the absence of a rich text corpus that is specific to our
nodes poses significant limitations for traditional and learning-based
approaches for anomaly detection. To overcome this limitation, we propose a
method that uses word embedding and models individual nodes as a sequence of
these vectors that commonly co-occur, using a Hidden Markov Model (HMM). We
score individual log entries by computing a probability ratio between the
probability of the full log sequence including the new entry and the
probability of just the previous log entries, without the new entry. This ratio
indicates how probable the sequence becomes when the new entry is added. The
proposed approach can detect anomalies by scoring and ranking log entries from
EuXFEL nodes where entries that receive high scores are potential anomalies
that do not fit the routine of the node. This method provides a warning system
to alert operators about these irregular log events that may indicate issues.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08954" title="Abstract">arXiv:2310.08954</a> [<a href="/pdf/2310.08954" title="Download PDF">pdf</a>, <a href="/format/2310.08954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textual Analysis of ICALEPCS and IPAC Conference Proceedings: Revealing  Research Trends, Topics, and Collaborations for Future Insights and Advanced  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulc%2C+A">Antonin Sulc</a>, 
<a href="/search/cs?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>, 
<a href="/search/cs?searchtype=author&query=Wilksen%2C+T">Tim Wilksen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we show a textual analysis of past ICALEPCS and IPAC
conference proceedings to gain insights into the research trends and topics
discussed in the field. We use natural language processing techniques to
extract meaningful information from the abstracts and papers of past conference
proceedings. We extract topics to visualize and identify trends, analyze their
evolution to identify emerging research directions, and highlight interesting
publications based solely on their content with an analysis of their network.
Additionally, we will provide an advanced search tool to better search the
existing papers to prevent duplication and easier reference findings. Our
analysis provides a comprehensive overview of the research landscape in the
field and helps researchers and practitioners to better understand the
state-of-the-art and identify areas for future research.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08956" title="Abstract">arXiv:2310.08956</a> [<a href="/pdf/2310.08956" title="Download PDF">pdf</a>, <a href="/format/2310.08956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRRU: Long-short Range Recurrent Updating Networks for Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing deep learning-based depth completion methods generally employ
massive stacked layers to predict the dense depth map from sparse input data.
Although such approaches greatly advance this task, their accompanied huge
computational complexity hinders their practical applications. To accomplish
depth completion more efficiently, we propose a novel lightweight deep network
framework, the Long-short Range Recurrent Updating (LRRU) network. Without
learning complex feature representations, LRRU first roughly fills the sparse
input to obtain an initial dense depth map, and then iteratively updates it
through learned spatially-variant kernels. Our iterative update process is
content-adaptive and highly flexible, where the kernel weights are learned by
jointly considering the guidance RGB images and the depth map to be updated,
and large-to-small kernel scopes are dynamically adjusted to capture
long-to-short range dependencies. Our initial depth map has coarse but complete
scene depth information, which helps relieve the burden of directly regressing
the dense depth from sparse ones, while our proposed method can effectively
refine it to an accurate depth map with less learnable parameters and inference
time. Experimental results demonstrate that our proposed LRRU variants achieve
state-of-the-art performance across different parameter regimes. In particular,
the LRRU-Base model outperforms competing approaches on the NYUv2 dataset, and
ranks 1st on the KITTI depth completion benchmark at the time of submission.
Project page: https://npucvr.github.io/LRRU/.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08958" title="Abstract">arXiv:2310.08958</a> [<a href="/pdf/2310.08958" title="Download PDF">pdf</a>, <a href="/format/2310.08958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=D%27Haro%2C+L+F">Luis Fernando D&#x27;Haro</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chengguang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Ke Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+G">Guohua Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP-2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in reference-free learned metrics for open-domain
dialogue evaluation have been driven by the progress in pre-trained language
models and the availability of dialogue data with high-quality human
annotations. However, current studies predominantly concentrate on English
dialogues, and the generalization of these metrics to other languages has not
been fully examined. This is largely due to the absence of a multilingual
dialogue evaluation benchmark. To address the issue, we introduce xDial-Eval,
built on top of open-source English dialogue evaluation datasets. xDial-Eval
includes 12 turn-level and 6 dialogue-level English datasets, comprising 14930
annotated turns and 8691 annotated dialogues respectively. The English dialogue
data are extended to nine other languages with commercial machine translation
systems. On xDial-Eval, we conduct comprehensive analyses of previous
BERT-based metrics and the recently-emerged large language models. Lastly, we
establish strong self-supervised and multilingual baselines. In terms of
average Pearson correlations over all datasets and languages, the best baseline
outperforms OpenAI's ChatGPT by absolute improvements of 6.5% and 4.6% at the
turn and dialogue levels respectively, albeit with much fewer parameters. The
data and code are publicly available at https://github.com/e0397123/xDial-Eval.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08961" title="Abstract">arXiv:2310.08961</a> [<a href="/pdf/2310.08961" title="Download PDF">pdf</a>, <a href="/format/2310.08961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAGE: Equilibrate Personalization and Generalization in Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiaqi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Haonan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaodong Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) is becoming a major driving force behind machine
learning as a service, where customers (clients) collaboratively benefit from
shared local updates under the orchestration of the service provider (server).
Representing clients' current demands and the server's future demand, local
model personalization and global model generalization are separately
investigated, as the ill-effects of data heterogeneity enforce the community to
focus on one over the other. However, these two seemingly competing goals are
of equal importance rather than black and white issues, and should be achieved
simultaneously. In this paper, we propose the first algorithm to balance
personalization and generalization on top of game theory, dubbed PAGE, which
reshapes FL as a co-opetition game between clients and the server. To explore
the equilibrium, PAGE further formulates the game as Markov decision processes,
and leverages the reinforcement learning algorithm, which simplifies the
solving complexity. Extensive experiments on four widespread datasets show that
PAGE outperforms state-of-the-art FL baselines in terms of global and local
prediction accuracy simultaneously, and the accuracy can be improved by up to
35.20% and 39.91%, respectively. In addition, biased variants of PAGE imply
promising adaptiveness to demand shifts in practice.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08962" title="Abstract">arXiv:2310.08962</a> [<a href="/pdf/2310.08962" title="Download PDF">pdf</a>, <a href="/ps/2310.08962" title="Download PostScript">ps</a>, <a href="/format/2310.08962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Injective Rank Metric Trapdoor Functions with Homogeneous Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burle%2C+%C3%89">&#xc9;tienne Burle</a>, 
<a href="/search/cs?searchtype=author&query=Gaborit%2C+P">Philippe Gaborit</a>, 
<a href="/search/cs?searchtype=author&query=Hatri%2C+Y">Younes Hatri</a>, 
<a href="/search/cs?searchtype=author&query=Otmani%2C+A">Ayoub Otmani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In rank-metric cryptography, a vector from a finite dimensional linear space
over a finite field is viewed as the linear space spanned by its entries. The
rank decoding problem which is the analogue of the problem of decoding a random
linear code consists in recovering a basis of a random noise vector that was
used to perturb a set of random linear equations sharing a secret solution.
Assuming the intractability of this problem, we introduce a new construction of
injective one-way trapdoor functions. Our solution departs from the frequent
way of building public key primitives from error-correcting codes where, to
establish the security, ad hoc assumptions about a hidden structure are made.
Our method produces a hard-to-distinguish linear code together with low weight
vectors which constitute the secret that helps recover the inputs.The key idea
is to focus on trapdoor functions that take sufficiently enough input vectors
sharing the same support. Applying then the error correcting algorithm designed
for Low Rank Parity Check (LRPC) codes, we obtain an inverting algorithm that
recovers the inputs with overwhelming probability.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08967" title="Abstract">arXiv:2310.08967</a> [<a href="/pdf/2310.08967" title="Download PDF">pdf</a>, <a href="/format/2310.08967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Example-Based NMT with Multi-Levenshtein Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouthors%2C+M">Maxime Bouthors</a>, 
<a href="/search/cs?searchtype=author&query=Crego%2C+J">Josep Crego</a>, 
<a href="/search/cs?searchtype=author&query=Yvon%2C+F">Fran&#xe7;ois Yvon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, EMNLP 2023 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieval-Augmented Machine Translation (RAMT) is attracting growing
attention. This is because RAMT not only improves translation metrics, but is
also assumed to implement some form of domain adaptation. In this contribution,
we study another salient trait of RAMT, its ability to make translation
decisions more transparent by allowing users to go back to examples that
contributed to these decisions.
<br />For this, we propose a novel architecture aiming to increase this
transparency. This model adapts a retrieval-augmented version of the
Levenshtein Transformer and makes it amenable to simultaneously edit multiple
fuzzy matches found in memory. We discuss how to perform training and inference
in this model, based on multi-way alignment algorithms and imitation learning.
Our experiments show that editing several examples positively impacts
translation scores, notably increasing the number of target spans that are
copied from existing instances.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08969" title="Abstract">arXiv:2310.08969</a> [<a href="/pdf/2310.08969" title="Download PDF">pdf</a>, <a href="/format/2310.08969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization of splitting methods based on modified potentials to  nonlinear evolution equations of parabolic and Schr&#xf6;dinger type
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blanes%2C+S">Sergio Blanes</a>, 
<a href="/search/math?searchtype=author&query=Casas%2C+F">Fernando Casas</a>, 
<a href="/search/math?searchtype=author&query=Gonz%C3%A1lez%2C+C">Ces&#xe1;reo Gonz&#xe1;lez</a>, 
<a href="/search/math?searchtype=author&query=Thalhammer%2C+M">Mechthild Thalhammer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">The present work is concerned with the extension of modified potential
operator splitting methods to specific classes of nonlinear evolution
equations. The considered partial differential equations of Schr{\"o}dinger and
parabolic type comprise the Laplacian, a potential acting as multiplication
operator, and a cubic nonlinearity. Moreover, an invariance principle is
deduced that has a significant impact on the efficient realisation of the
resulting modified operator splitting methods for the Schr{\"o}dinger case.}
<br />Numerical illustrations for the time-dependent Gross--Pitaevskii equation in
the physically most relevant case of three space dimensions and for its
parabolic counterpart related to ground state and excited state computations
confirm the benefits of the proposed fourth-order modified operator splitting
method in comparison with standard splitting methods.
<br />The presented results are novel and of particular interest from both, a
theoretical perspective to inspire future investigations of modified operator
splitting methods for other classes of nonlinear evolution equations and a
practical perspective to advance the reliable and efficient simulation of
Gross--Pitaevskii systems in real and imaginary time.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08975" title="Abstract">arXiv:2310.08975</a> [<a href="/pdf/2310.08975" title="Download PDF">pdf</a>, <a href="/format/2310.08975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question  Answering with Fine-tuned Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haoran Luo</a>, 
<a href="/search/cs?searchtype=author&query=E%2C+H">Haihong E</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zichen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shiyao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yikai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chenghao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Meina Song</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge Base Question Answering (KBQA) aims to derive answers to natural
language questions over large-scale knowledge bases (KBs), which are generally
divided into two research components: knowledge retrieval and semantic parsing.
However, three core challenges remain, including inefficient knowledge
retrieval, retrieval errors adversely affecting semantic parsing, and the
complexity of previous KBQA methods. In the era of large language models
(LLMs), we introduce ChatKBQA, a novel generate-then-retrieve KBQA framework
built on fine-tuning open-source LLMs such as Llama-2, ChatGLM2 and Baichuan2.
ChatKBQA proposes generating the logical form with fine-tuned LLMs first, then
retrieving and replacing entities and relations through an unsupervised
retrieval method, which improves both generation and retrieval more
straightforwardly. Experimental results reveal that ChatKBQA achieves new
state-of-the-art performance on standard KBQA datasets, WebQSP, and
ComplexWebQuestions (CWQ). This work also provides a new paradigm for combining
LLMs with knowledge graphs (KGs) for interpretable and knowledge-required
question answering. Our code is publicly available.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08977" title="Abstract">arXiv:2310.08977</a> [<a href="/pdf/2310.08977" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Purpose NLP Chatbot : Design, Methodology &amp; Conclusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+S">Shivom Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Mehra%2C+S">Shourya Mehra</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Pritha Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Multilingual , Voice Conversion , Emotion Recognition , Offline Service , Financial Advisor , Product Preference , Customer Reaction Prediction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">With a major focus on its history, difficulties, and promise, this research
paper provides a thorough analysis of the chatbot technology environment as it
exists today. It provides a very flexible chatbot system that makes use of
reinforcement learning strategies to improve user interactions and
conversational experiences. Additionally, this system makes use of sentiment
analysis and natural language processing to determine user moods. The chatbot
is a valuable tool across many fields thanks to its amazing characteristics,
which include voice-to-voice conversation, multilingual support [12], advising
skills, offline functioning, and quick help features. The complexity of chatbot
technology development is also explored in this study, along with the causes
that have propelled these developments and their far-reaching effects on a
range of sectors. According to the study, three crucial elements are crucial:
1) Even without explicit profile information, the chatbot system is built to
adeptly understand unique consumer preferences and fluctuating satisfaction
levels. With the use of this capacity, user interactions are made to meet their
wants and preferences. 2) Using a complex method that interlaces Multiview
voice chat information, the chatbot may precisely simulate users' actual
experiences. This aids in developing more genuine and interesting discussions.
3) The study presents an original method for improving the black-box deep
learning models' capacity for prediction. This improvement is made possible by
introducing dynamic satisfaction measurements that are theory-driven, which
leads to more precise forecasts of consumer reaction.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08981" title="Abstract">arXiv:2310.08981</a> [<a href="/pdf/2310.08981" title="Download PDF">pdf</a>, <a href="/format/2310.08981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-latency Speech Enhancement via Speech Token Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Huaying Xue</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiulian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Existing deep learning based speech enhancement mainly employ a data-driven
approach, which leverage large amounts of data with a variety of noise types to
achieve noise removal from noisy signal. However, the high dependence on the
data limits its generalization on the unseen complex noises in real-life
environment. In this paper, we focus on the low-latency scenario and regard
speech enhancement as a speech generation problem conditioned on the noisy
signal, where we generate clean speech instead of identifying and removing
noises. Specifically, we propose a conditional generative framework for speech
enhancement, which models clean speech by acoustic codes of a neural speech
codec and generates the speech codes conditioned on past noisy frames in an
auto-regressive way. Moreover, we propose an explicit-alignment approach to
align noisy frames with the generated speech tokens to improve the robustness
and scalability to different input lengths. Different from other methods that
leverage multiple stages to generate speech codes, we leverage a single-stage
speech generation approach based on the TF-Codec neural codec to achieve high
speech quality with low latency. Extensive results on both synthetic and
real-recorded test set show its superiority over data-driven approaches in
terms of noise robustness and temporal speech coherence.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08982" title="Abstract">arXiv:2310.08982</a> [<a href="/pdf/2310.08982" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big data-driven prediction of airspace congestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayhan%2C+S">Samet Ayhan</a>, 
<a href="/search/cs?searchtype=author&query=de+Oliveira%2C+%C3%8D+R">&#xcd;talo Romani de Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Balvedi%2C+G">Glaucia Balvedi</a>, 
<a href="/search/cs?searchtype=author&query=Costas%2C+P">Pablo Costas</a>, 
<a href="/search/cs?searchtype=author&query=Leite%2C+A">Alexandre Leite</a>, 
<a href="/search/cs?searchtype=author&query=de+Azevedo%2C+F+C+F">Felipe C. F. de Azevedo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 2023 IEEE/AIAA Digital Aviation Systems Conference (DASC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
<p class="mathjax">Air Navigation Service Providers (ANSP) worldwide have been making a
considerable effort for the development of a better method to measure and
predict aircraft counts within a particular airspace, also referred to as
airspace density. An accurate measurement and prediction of airspace density is
crucial for a better managed airspace, both strategically and tactically,
yielding a higher level of automation and thereby reducing the air traffic
controller's workload. Although the prior approaches have been able to address
the problem to some extent, data management and query processing of
ever-increasing vast volume of air traffic data at high rates, for various
analytics purposes such as predicting aircraft counts, still remains a
challenge especially when only linear prediction models are used.
<br />In this paper, we present a novel data management and prediction system that
accurately predicts aircraft counts for a particular airspace sector within the
National Airspace System (NAS). The incoming Traffic Flow Management (TFM) data
is streaming, big, uncorrelated and noisy. In the preprocessing step, the
system continuously processes the incoming raw data, reduces it to a compact
size, and stores it in a NoSQL database, where it makes the data available for
efficient query processing. In the prediction step, the system learns from
historical trajectories and uses their segments to collect key features such as
sector boundary crossings, weather parameters, and other air traffic data. The
features are fed into various regression models, including linear, non-linear
and ensemble models, and the best performing model is used for prediction.
Evaluation on an extensive set of real track, weather, and air traffic data
including boundary crossings in the U.S. verify that our system efficiently and
accurately predicts aircraft counts in each airspace sector.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08984" title="Abstract">arXiv:2310.08984</a> [<a href="/pdf/2310.08984" title="Download PDF">pdf</a>, <a href="/format/2310.08984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniParser: Multi-Human Parsing with Unified Correlation Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Jiaming Chu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Junliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-human parsing is an image segmentation task necessitating both
instance-level and fine-grained category-level information. However, prior
research has typically processed these two types of information through
separate branches and distinct output formats, leading to inefficient and
redundant frameworks. This paper introduces UniParser, which integrates
instance-level and category-level representations in three key aspects: 1) we
propose a unified correlation representation learning approach, allowing our
network to learn instance and category features within the cosine space; 2) we
unify the form of outputs of each modules as pixel-level segmentation results
while supervising instance and category features using a homogeneous label
accompanied by an auxiliary loss; and 3) we design a joint optimization
procedure to fuse instance and category representations. By virtual of unifying
instance-level and category-level output, UniParser circumvents manually
designed post-processing techniques and surpasses state-of-the-art methods,
achieving 49.3% AP on MHPv2.0 and 60.4% AP on CIHP. We will release our source
code, pretrained models, and online demos to facilitate future studies.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08986" title="Abstract">arXiv:2310.08986</a> [<a href="/pdf/2310.08986" title="Download PDF">pdf</a>, <a href="/format/2310.08986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VCL Challenges 2023 at ICCV 2023 Technical Report: Bi-level Adaptation  Method for Test-time Adaptive Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yusheng He</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhengqing Zang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chenwei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This report outlines our team's participation in VCL Challenges B Continual
Test_time Adaptation, focusing on the technical details of our approach. Our
primary focus is Testtime Adaptation using bi_level adaptations, encompassing
image_level and detector_level adaptations. At the image level, we employ
adjustable parameterbased image filters, while at the detector level, we
leverage adjustable parameterbased mean teacher modules. Ultimately, through
the utilization of these bi_level adaptations, we have achieved a remarkable
38.3% mAP on the target domain of the test set within VCL Challenges B. It is
worth noting that the minimal drop in mAP, is mearly 4.2%, and the overall
performance is 32.5% mAP.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08988" title="Abstract">arXiv:2310.08988</a> [<a href="/pdf/2310.08988" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reroute Prediction Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Oliveira%2C+%C3%8D+R">&#xcd;talo Romani de Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Ayhan%2C+S">Samet Ayhan</a>, 
<a href="/search/cs?searchtype=author&query=Biglin%2C+M">Michael Biglin</a>, 
<a href="/search/cs?searchtype=author&query=Costas%2C+P">Pablo Costas</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+E+C+P">Euclides C. Pinto Neto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 2023 IEEE/AIAA Digital Aviation Systems Conference (DASC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The cost of delays was estimated as 33 billion US dollars only in 2019 for
the US National Airspace System, a peak value following a growth trend in past
years. Aiming to address this huge inefficiency, we designed and developed a
novel Data Analytics and Machine Learning system, which aims at reducing delays
by proactively supporting re-routing decisions.
<br />Given a time interval up to a few days in the future, the system predicts if
a reroute advisory for a certain Air Route Traffic Control Center or for a
certain advisory identifier will be issued, which may impact the pertinent
routes. To deliver such predictions, the system uses historical reroute data,
collected from the System Wide Information Management (SWIM) data services
provided by the FAA, and weather data, provided by the US National Centers for
Environmental Prediction (NCEP). The data is huge in volume, and has many items
streamed at high velocity, uncorrelated and noisy. The system continuously
processes the incoming raw data and makes it available for the next step where
an interim data store is created and adaptively maintained for efficient query
processing. The resulting data is fed into an array of ML algorithms, which
compete for higher accuracy. The best performing algorithm is used in the final
prediction, generating the final results. Mean accuracy values higher than 90%
were obtained in our experiments with this system.
<br />Our algorithm divides the area of interest in units of aggregation and uses
temporal series of the aggregate measures of weather forecast parameters in
each geographical unit, in order to detect correlations with reroutes and where
they will most likely occur. Aiming at practical application, the system is
formed by a number of microservices, which are deployed in the cloud, making
the system distributed, scalable and highly available.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08992" title="Abstract">arXiv:2310.08992</a> [<a href="/pdf/2310.08992" title="Download PDF">pdf</a>, <a href="/format/2310.08992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeChain: Towards Modular Code Generation Through Chain of  Self-revisions with Representative Sub-modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hailin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Amrita Saha</a>, 
<a href="/search/cs?searchtype=author&query=Gokul%2C+A">Akash Gokul</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+D">Doyen Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">Large Language Models (LLMs) have already become quite proficient at solving
simpler programming tasks like those in HumanEval or MBPP benchmarks. However,
solving more complex and competitive programming tasks is still quite
challenging for these models - possibly due to their tendency to generate
solutions as monolithic code blocks instead of decomposing them into logical
sub-tasks and sub-modules. On the other hand, experienced programmers
instinctively write modularized code with abstraction for solving complex
tasks, often reusing previously developed modules. To address this gap, we
propose CodeChain, a novel framework for inference that elicits modularized
code generation through a chain of self-revisions, each being guided by some
representative sub-modules generated in previous iterations. Concretely,
CodeChain first instructs the LLM to generate modularized codes through
chain-of-thought prompting. Then it applies a chain of self-revisions by
iterating the two steps: 1) extracting and clustering the generated sub-modules
and selecting the cluster representatives as the more generic and re-usable
implementations, and 2) augmenting the original chain-of-thought prompt with
these selected module-implementations and instructing the LLM to re-generate
new modularized solutions. We find that by naturally encouraging the LLM to
reuse the previously developed and verified sub-modules, CodeChain can
significantly boost both modularity as well as correctness of the generated
solutions, achieving relative pass@1 improvements of 35% on APPS and 76% on
CodeContests. It is shown to be effective on both OpenAI LLMs as well as
open-sourced LLMs like WizardCoder. We also conduct comprehensive ablation
studies with different methods of prompting, number of clusters, model sizes,
program qualities, etc., to provide useful insights that underpin CodeChain's
success.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08996" title="Abstract">arXiv:2310.08996</a> [<a href="/pdf/2310.08996" title="Download PDF">pdf</a>, <a href="/format/2310.08996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qualitative Analysis for Validating IEC 62443-4-2 Requirements in  DevSecOps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B6ttel%2C+C">Christian G&#xf6;ttel</a>, 
<a href="/search/cs?searchtype=author&query=Kabir-Querrec%2C+M">Ma&#xeb;lle Kabir-Querrec</a>, 
<a href="/search/cs?searchtype=author&query=Kozhaya%2C+D">David Kozhaya</a>, 
<a href="/search/cs?searchtype=author&query=Sivanthi%2C+T">Thanikesavan Sivanthi</a>, 
<a href="/search/cs?searchtype=author&query=Vukovi%C4%87%2C+O">Ognjen Vukovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Validation of conformance to cybersecurity standards for industrial
automation and control systems is an expensive and time consuming process which
can delay the time to market. It is therefore crucial to introduce conformance
validation stages into the continuous integration/continuous delivery pipeline
of products. However, designing such conformance validation in an automated
fashion is a highly non-trivial task that requires expert knowledge and depends
upon the available security tools, ease of integration into the DevOps
pipeline, as well as support for IT and OT interfaces and protocols.
<br />This paper addresses the aforementioned problem focusing on the automated
validation of ISA/IEC 62443-4-2 standard component requirements. We present an
extensive qualitative analysis of the standard requirements and the current
tooling landscape to perform validation. Our analysis demonstrates the coverage
established by the currently available tools and sheds light on current gaps to
achieve full automation and coverage. Furthermore, we showcase for every
component requirement where in the CI/CD pipeline stage it is recommended to
test it and the tools to do so.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08997" title="Abstract">arXiv:2310.08997</a> [<a href="/pdf/2310.08997" title="Download PDF">pdf</a>, <a href="/format/2310.08997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parallel Feature-preserving Mesh Variable Offsetting Method with  Dynamic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hongyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Renshu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinlan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rabczuk%2C+T">Timon Rabczuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Mesh offsetting plays an important role in discrete geometric processing. In
this paper, we propose a parallel feature-preserving mesh offsetting framework
with variable distance. Different from the traditional method based on distance
and normal vector, a new calculation of offset position is proposed by using
dynamic programming and quadratic programming, and the sharp feature can be
preserved after offsetting. Instead of distance implicit field, a spatial
coverage region represented by polyhedral for computing offsets is proposed.
Our method can generate an offsetting model with smaller mesh size, and also
can achieve high quality without gaps, holes, and self-intersections. Moreover,
several acceleration techniques are proposed for the efficient mesh offsetting,
such as the parallel computing with grid, AABB tree and rays computing. In
order to show the efficiency and robustness of the proposed framework, we have
tested our method on the quadmesh dataset, which is available at
[https://www.quadmesh.cloud]. The source code of the proposed algorithm is
available on GitHub at [https://github.com/iGame-Lab/PFPOffset].
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09000" title="Abstract">arXiv:2310.09000</a> [<a href="/pdf/2310.09000" title="Download PDF">pdf</a>, <a href="/format/2310.09000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Stability of Process Outcome Predictions in Online  Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suhwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Comuzzi%2C+M">Marco Comuzzi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xixi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Reijers%2C+H+A">Hajo A. Reijers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, Proceedings of the 5th International Conference on Process Mining (ICPM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Predictive Process Monitoring aims to forecast the future progress of process
instances using historical event data. As predictive process monitoring is
increasingly applied in online settings to enable timely interventions,
evaluating the performance of the underlying models becomes crucial for
ensuring their consistency and reliability over time. This is especially
important in high risk business scenarios where incorrect predictions may have
severe consequences. However, predictive models are currently usually evaluated
using a single, aggregated value or a time-series visualization, which makes it
challenging to assess their performance and, specifically, their stability over
time. This paper proposes an evaluation framework for assessing the stability
of models for online predictive process monitoring. The framework introduces
four performance meta-measures: the frequency of significant performance drops,
the magnitude of such drops, the recovery rate, and the volatility of
performance. To validate this framework, we applied it to two artificial and
two real-world event logs. The results demonstrate that these meta-measures
facilitate the comparison and selection of predictive models for different
risk-taking scenarios. Such insights are of particular value to enhance
decision-making in dynamic business environments.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09002" title="Abstract">arXiv:2310.09002</a> [<a href="/pdf/2310.09002" title="Download PDF">pdf</a>, <a href="/format/2310.09002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Meta-Learning for Few-Shot Fault Diagnosis with Representation  Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jixuan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Z">Zhen Mei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Sha Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning-based fault diagnosis (FD) approaches require a large amount of
training data, which are difficult to obtain since they are located across
different entities. Federated learning (FL) enables multiple clients to
collaboratively train a shared model with data privacy guaranteed. However, the
domain discrepancy and data scarcity problems among clients deteriorate the
performance of the global FL model. To tackle these issues, we propose a novel
framework called representation encoding-based federated meta-learning (REFML)
for few-shot FD. First, a novel training strategy based on representation
encoding and meta-learning is developed. It harnesses the inherent
heterogeneity among training clients, effectively transforming it into an
advantage for out-of-distribution generalization on unseen working conditions
or equipment types. Additionally, an adaptive interpolation method that
calculates the optimal combination of local and global models as the
initialization of local training is proposed. This helps to further utilize
local information to mitigate the negative effects of domain discrepancy. As a
result, high diagnostic accuracy can be achieved on unseen working conditions
or equipment types with limited training data. Compared with the
state-of-the-art methods, such as FedProx, the proposed REFML framework
achieves an increase in accuracy by 2.17%-6.50% when tested on unseen working
conditions of the same equipment type and 13.44%-18.33% when tested on totally
unseen equipment types, respectively.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09003" title="Abstract">arXiv:2310.09003</a> [<a href="/pdf/2310.09003" title="Download PDF">pdf</a>, <a href="/format/2310.09003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#x3bc;-DDRL: A QoS-Aware Distributed Deep Reinforcement Learning  Technique for Service Offloading in Fog computing Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goudarzi%2C+M">Mohammad Goudarzi</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+M+A">Maria A. Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Sarvi%2C+M">Majid Sarvi</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Fog and Edge computing extend cloud services to the proximity of end users,
allowing many Internet of Things (IoT) use cases, particularly latency-critical
applications. Smart devices, such as traffic and surveillance cameras, often do
not have sufficient resources to process computation-intensive and
latency-critical services. Hence, the constituent parts of services can be
offloaded to nearby Edge/Fog resources for processing and storage. However,
making offloading decisions for complex services in highly stochastic and
dynamic environments is an important, yet difficult task. Recently, Deep
Reinforcement Learning (DRL) has been used in many complex service offloading
problems; however, existing techniques are most suitable for centralized
environments, and their convergence to the best-suitable solutions is slow. In
addition, constituent parts of services often have predefined data dependencies
and quality of service constraints, which further intensify the complexity of
service offloading. To solve these issues, we propose a distributed DRL
technique following the actor-critic architecture based on Asynchronous
Proximal Policy Optimization (APPO) to achieve efficient and diverse
distributed experience trajectory generation. Also, we employ PPO clipping and
V-trace techniques for off-policy correction for faster convergence to the most
suitable service offloading solutions. The results obtained demonstrate that
our technique converges quickly, offers high scalability and adaptability, and
outperforms its counterparts by improving the execution time of heterogeneous
services.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09004" title="Abstract">arXiv:2310.09004</a> [<a href="/pdf/2310.09004" title="Download PDF">pdf</a>, <a href="/ps/2310.09004" title="Download PostScript">ps</a>, <a href="/format/2310.09004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nondeterminism and Guarded Commands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apt%2C+K+R">Krzysztof R. Apt</a>, 
<a href="/search/cs?searchtype=author&query=Olderog%2C+E">Ernst-R&#xfc;diger Olderog</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages. This is authors' version of Chapter 8 of the book K.R. Apt and C.A.R. Hoare (editors), Edsger Wybe Dijkstra: His Life, Work, and Legacy, volume 45 of ACM Books. ACM/Morgan &amp; Claypool, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The purpose of this paper is to discuss the relevance of nondeterminism in
computer science, with a special emphasis on Dijkstra's guarded commands
language.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09006" title="Abstract">arXiv:2310.09006</a> [<a href="/pdf/2310.09006" title="Download PDF">pdf</a>, <a href="/format/2310.09006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Liveness Checking of the HotStuff Protocol Family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Decouchant%2C+J">J&#xe9;r&#xe9;mie Decouchant</a>, 
<a href="/search/cs?searchtype=author&query=Ozkan%2C+B+K">Burcu Kulahcioglu Ozkan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanzhuo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of a paper accepted at IEEE PRDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Byzantine consensus protocols aim at maintaining safety guarantees under any
network synchrony model and at providing liveness in partially or fully
synchronous networks. However, several Byzantine consensus protocols have been
shown to violate liveness properties under certain scenarios. Existing testing
methods for checking the liveness of consensus protocols check for time-bounded
liveness violations, which generate a large number of false positives. In this
work, for the first time, we check the liveness of Byzantine consensus
protocols using the temperature and lasso detection methods, which require the
definition of ad-hoc system state abstractions. We focus on the HotStuff
protocol family that has been recently developed for blockchain consensus. In
this family, the HotStuff protocol is both safe and live under the partial
synchrony assumption, while the 2-Phase Hotstuff and Sync HotStuff protocols
are known to violate liveness in subtle fault scenarios. We implemented our
liveness checking methods on top of the Twins automated unit test generator to
test the HotStuff protocol family. Our results indicate that our methods
successfully detect all known liveness violations and produce fewer false
positives than the traditional time-bounded liveness checks.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09008" title="Abstract">arXiv:2310.09008</a> [<a href="/pdf/2310.09008" title="Download PDF">pdf</a>, <a href="/format/2310.09008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Lower Bounds for Reachability in Vector Addition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czerwi%C5%84ski%2C+W">Wojciech Czerwi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Jecker%2C+I">Isma&#xeb;l Jecker</a>, 
<a href="/search/cs?searchtype=author&query=Lasota%2C+S">S&#x142;awomir Lasota</a>, 
<a href="/search/cs?searchtype=author&query=Leroux%2C+J">J&#xe9;r&#xf4;me Leroux</a>, 
<a href="/search/cs?searchtype=author&query=Orlikowski%2C+%C5%81">&#x141;ukasz Orlikowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We investigate the dimension-parametric complexity of the reachability
problem in vector addition systems with states (VASS) and its extension with
pushdown stack (pushdown VASS). Up to now, the problem is known to be
$\mathcal{F}_k$-hard for VASS of dimension $3k+2$ (the complexity class
$\mathcal{F}_k$ corresponds to the $k$th level of the fast-growing hierarchy),
and no essentially better bound is known for pushdown VASS. We provide a new
construction that improves the lower bound for VASS: $\mathcal{F}_k$-hardness
in dimension $2k+3$. Furthermore, building on our new insights we show a new
lower bound for pushdown VASS: $\mathcal{F}_k$-hardness in dimension $\frac k 2
+ 4$. This dimension-parametric lower bound is strictly stronger than the upper
bound for VASS, which suggests that the (still unknown) complexity of the
reachability problem in pushdown VASS is higher than in plain VASS (where it is
Ackermann-complete).
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09009" title="Abstract">arXiv:2310.09009</a> [<a href="/pdf/2310.09009" title="Download PDF">pdf</a>, <a href="/format/2310.09009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Homomorphism Reconstructibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ker%2C+J">Jan B&#xf6;ker</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4rtel%2C+L">Louis H&#xe4;rtel</a>, 
<a href="/search/cs?searchtype=author&query=Runde%2C+N">Nina Runde</a>, 
<a href="/search/cs?searchtype=author&query=Seppelt%2C+T">Tim Seppelt</a>, 
<a href="/search/cs?searchtype=author&query=Standke%2C+C">Christoph Standke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Representing graphs by their homomorphism counts has led to the beautiful
theory of homomorphism indistinguishability in recent years. Moreover,
homomorphism counts have promising applications in database theory and machine
learning, where one would like to answer queries or classify graphs solely
based on the representation of a graph $G$ as a finite vector of homomorphism
counts from some fixed finite set of graphs to $G$. We study the computational
complexity of the arguably most fundamental computational problem associated to
these representations, the homomorphism reconstructability problem: given a
finite sequence of graphs and a corresponding vector of natural numbers, decide
whether there exists a graph $G$ that realises the given vector as the
homomorphism counts from the given graphs.
<br />We show that this problem yields a natural example of an
$\mathsf{NP}^{#\mathsf{P}}$-hard problem, which still can be $\mathsf{NP}$-hard
when restricted to a fixed number of input graphs of bounded treewidth and a
fixed input vector of natural numbers, or alternatively, when restricted to a
finite input set of graphs. We further show that, when restricted to a finite
input set of graphs and given an upper bound on the order of the graph $G$ as
additional input, the problem cannot be $\mathsf{NP}$-hard unless $\mathsf{P} =
\mathsf{NP}$. For this regime, we obtain partial positive results. We also
investigate the problem's parameterised complexity and provide fpt-algorithms
for the case that a single graph is given and that multiple graphs of the same
order with subgraph instead of homomorphism counts are given.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09016" title="Abstract">arXiv:2310.09016</a> [<a href="/pdf/2310.09016" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spatial-Temporal Dual-Mode Mixed Flow Network for Panoramic Video  Salient Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaolei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengcheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zelong Du</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I">Ishfaq Ahmad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Salient object detection (SOD) in panoramic video is still in the initial
exploration stage. The indirect application of 2D video SOD method to the
detection of salient objects in panoramic video has many unmet challenges, such
as low detection accuracy, high model complexity, and poor generalization
performance. To overcome these hurdles, we design an Inter-Layer Attention
(ILA) module, an Inter-Layer weight (ILW) module, and a Bi-Modal Attention
(BMA) module. Based on these modules, we propose a Spatial-Temporal Dual-Mode
Mixed Flow Network (STDMMF-Net) that exploits the spatial flow of panoramic
video and the corresponding optical flow for SOD. First, the ILA module
calculates the attention between adjacent level features of consecutive frames
of panoramic video to improve the accuracy of extracting salient object
features from the spatial flow. Then, the ILW module quantifies the salient
object information contained in the features of each level to improve the
fusion efficiency of the features of each level in the mixed flow. Finally, the
BMA module improves the detection accuracy of STDMMF-Net. A large number of
subjective and objective experimental results testify that the proposed method
demonstrates better detection accuracy than the state-of-the-art (SOTA)
methods. Moreover, the comprehensive performance of the proposed method is
better in terms of memory required for model inference, testing time,
complexity, and generalization performance.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09017" title="Abstract">arXiv:2310.09017</a> [<a href="/pdf/2310.09017" title="Download PDF">pdf</a>, <a href="/format/2310.09017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dont Add, dont Miss: Effective Content Preserving Generation from  Pre-Selected Text Spans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slobodkin%2C+A">Aviv Slobodkin</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Hirsch%2C+E">Eran Hirsch</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+I">Ido Dagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023, findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recently introduced Controlled Text Reduction (CTR) task isolates the
text generation step within typical summarization-style tasks. It does so by
challenging models to generate coherent text conforming to pre-selected content
within the input text ("highlights").
<br />This framing enables increased modularity in summarization-like tasks,
allowing to couple a single CTR model with various content-selection setups and
modules.
<br />However, there are currently no reliable CTR models, while the performance of
the existing baseline for the task is mediocre, falling short of practical
utility.
<br />Here, we address this gap by introducing a high-quality, open-source CTR
model that tackles two prior key limitations: inadequate enforcement of the
content-preservation constraint, and suboptimal silver training data.
<br />Addressing these, we amplify the content-preservation constraint in both
training, via RL, and inference, via a controlled decoding strategy.
<br />Further, we substantially improve the silver training data quality via GPT-4
distillation.
<br />Overall, pairing the distilled dataset with the highlight-adherence
strategies yields marked gains over the current baseline, of up to 30 ROUGE-L
points, providing a reliable CTR model for downstream use.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09020" title="Abstract">arXiv:2310.09020</a> [<a href="/pdf/2310.09020" title="Download PDF">pdf</a>, <a href="/format/2310.09020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Credit Blockchain for Faster Transactions in P2P Energy Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+A+k">Amit kumar Vishwakarma</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+Y+N">Yatindra Nath Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">P2P trading of energy can be a good alternative to incentivize distributed
non-conventional energy production and meet the burgeoning energy demand. For
efficient P2P trading, a free market for trading needs to be established while
ensuring the information reliability, security, and privacy. Blockchain has
been used to provide this framework, but it consumes very high energy and is
slow. Further, until now, no blockchain model has considered the role of
conventional electric utility companies in P2P trading. In this paper, we have
introduced a credit blockchain that reduces energy consumption by employing a
new mechanism to update transactions and increases speed by providing interest
free loans to buyers. This model also integrates the electric utility companies
within the P2P trading framework, thereby increasing members trading options.
We have also discussed the pricing strategies for trading. All the above
assertions have been verified through simulations, demonstrating that this
model will promote P2P trading by providing enhanced security, speed, and
greater trading options. The proposed model will also help trade energy at
prices beneficial for both sellers and buyers.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09021" title="Abstract">arXiv:2310.09021</a> [<a href="/pdf/2310.09021" title="Download PDF">pdf</a>, <a href="/format/2310.09021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI-driven Semantic Communication Framework for NextG Wireless  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raha%2C+A+D">Avi Deb Raha</a>, 
<a href="/search/cs?searchtype=author&query=Munir%2C+M+S">Md. Shirajum Munir</a>, 
<a href="/search/cs?searchtype=author&query=Adhikary%2C+A">Apurba Adhikary</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This work designs a novel semantic communication (SemCom) framework for the
next-generation wireless network to tackle the challenges of unnecessary
transmission of vast amounts that cause high bandwidth consumption, more
latency, and experience with bad quality of services (QoS). In particular,
these challenges hinder applications like intelligent transportation systems
(ITS), metaverse, mixed reality, and the Internet of Everything, where
real-time and efficient data transmission is paramount. Therefore, to reduce
communication overhead and maintain the QoS of emerging applications such as
metaverse, ITS, and digital twin creation, this work proposes a novel semantic
communication framework. First, an intelligent semantic transmitter is designed
to capture the meaningful information (e.g., the rode-side image in ITS) by
designing a domain-specific Mobile Segment Anything Model (MSAM)-based
mechanism to reduce the potential communication traffic while QoS remains
intact. Second, the concept of generative AI is introduced for building the
SemCom to reconstruct and denoise the received semantic data frame at the
receiver end. In particular, the Generative Adversarial Network (GAN) mechanism
is designed to maintain a superior quality reconstruction under different
signal-to-noise (SNR) channel conditions. Finally, we have tested and evaluated
the proposed semantic communication (SemCom) framework with the real-world 6G
scenario of ITS; in particular, the base station equipped with an RGB camera
and a mmWave phased array. Experimental results demonstrate the efficacy of the
proposed SemCom framework by achieving high-quality reconstruction across
various SNR channel conditions, resulting in 93.45% data reduction in
communication.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09023" title="Abstract">arXiv:2310.09023</a> [<a href="/pdf/2310.09023" title="Download PDF">pdf</a>, <a href="/format/2310.09023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Suffix and LCP Array: Simple, Direct, Small, and Fast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayad%2C+L+A+K">Lorraine A. K. Ayad</a>, 
<a href="/search/cs?searchtype=author&query=Loukides%2C+G">Grigorios Loukides</a>, 
<a href="/search/cs?searchtype=author&query=Pissis%2C+S+P">Solon P. Pissis</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+H">Hilde Verbeek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Sparse suffix sorting is the problem of sorting $b=o(n)$ suffixes of a string
of length $n$. Efficient sparse suffix sorting algorithms have existed for more
than a decade. Despite the multitude of works and their justified claims for
applications in text indexing, the existing algorithms have not been employed
by practitioners. Arguably this is because there are no simple, direct, and
efficient algorithms for sparse suffix array construction. We provide two new
algorithms for constructing the sparse suffix and LCP arrays that are
simultaneously simple, direct, small, and fast. In particular, our algorithms
are: simple in the sense that they can be implemented using only basic data
structures; direct in the sense that the output arrays are not a byproduct of
constructing the sparse suffix tree or an LCE data structure; fast in the sense
that they run in $\mathcal{O}(n\log b)$ time, in the worst case, or in
$\mathcal{O}(n)$ time, when the total number of suffixes with an LCP value
greater than $2^{\lfloor \log \frac{n}{b} \rfloor + 1}-1$ is in
$\mathcal{O}(b/\log b)$, matching the time of the optimal yet much more
complicated algorithms [Gawrychowski and Kociumaka, SODA 2017; Birenzwige et
al., SODA 2020]; and small in the sense that they can be implemented using only
$8b+o(b)$ machine words. Our algorithms are simplified, yet non-trivial,
space-efficient adaptations of the Monte Carlo algorithm by I et al. for
constructing the sparse suffix tree in $\mathcal{O}(n\log b)$ time [STACS
2014]. We also provide proof-of-concept experiments to justify our claims on
simplicity and efficiency.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09025" title="Abstract">arXiv:2310.09025</a> [<a href="/pdf/2310.09025" title="Download PDF">pdf</a>, <a href="/format/2310.09025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Near-Space Information Networks: Channel Modeling, Networking,  and Transmission Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xianbin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiaoning Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Near-space information networks (NSIN) composed of high-altitude platforms
(HAPs), high- and low-altitude unmanned aerial vehicles (UAVs) are a new regime
for providing quickly, robustly, and cost-efficiently sensing and communication
services. Precipitated by innovations and breakthroughs in manufacturing,
materials, communications, electronics, and control technologies, NSIN have
emerged as an essential component of the emerging sixth-generation of mobile
communication systems. This article aims at providing and discussing the latest
advances in NSIN in the research areas of channel modeling, networking, and
transmission from a forward-looking, comparative, and technological
evolutionary perspective. In this article, we highlight the characteristics of
NSIN and present the promising use-cases of NSIN. The impact of airborne
platforms' unstable movements on the phase delays of onboard antenna arrays
with diverse structures is mathematically analyzed. The recent advancements in
HAP channel modeling are elaborated on, along with the significant differences
between HAP and UAV channel modeling. A comprehensive review of the networking
technologies of NSIN in network deployment, handoff management, and network
management aspects is provided. Besides, the promising technologies and
communication protocols of the physical layer, medium access control (MAC)
layer, network layer, and transport layer of NSIN for achieving efficient
transmission over NSIN are overviewed. Finally, we outline some open issues and
promising directions of NSIN deserved for future study and discuss the
corresponding challenges.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09028" title="Abstract">arXiv:2310.09028</a> [<a href="/pdf/2310.09028" title="Download PDF">pdf</a>, <a href="/format/2310.09028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace Adaptation Prior for Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huisman%2C+M">Mike Huisman</a>, 
<a href="/search/cs?searchtype=author&query=Plaat%2C+A">Aske Plaat</a>, 
<a href="/search/cs?searchtype=author&query=van+Rijn%2C+J+N">Jan N. van Rijn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Machine Learning Journal, Special Issue of the ECML PKDD 2023 Journal Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Gradient-based meta-learning techniques aim to distill useful prior knowledge
from a set of training tasks such that new tasks can be learned more
efficiently with gradient descent. While these methods have achieved successes
in various scenarios, they commonly adapt all parameters of trainable layers
when learning new tasks. This neglects potentially more efficient learning
strategies for a given task distribution and may be susceptible to overfitting,
especially in few-shot learning where tasks must be learned from a limited
number of examples. To address these issues, we propose Subspace Adaptation
Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns
good initialization parameters (prior knowledge) and layer-wise parameter
subspaces in the form of operation subsets that should be adaptable. In this
way, SAP can learn which operation subsets to adjust with gradient descent
based on the underlying task distribution, simultaneously decreasing the risk
of overfitting when learning new tasks. We demonstrate that this ability is
helpful as SAP yields superior or competitive performance in few-shot image
classification settings (gains between 0.1% and 3.9% in accuracy). Analysis of
the learned subspaces demonstrates that low-dimensional operations often yield
high activation strengths, indicating that they may be important for achieving
good few-shot learning performance. For reproducibility purposes, we publish
all our research code publicly.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09031" title="Abstract">arXiv:2310.09031</a> [<a href="/pdf/2310.09031" title="Download PDF">pdf</a>, <a href="/format/2310.09031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MINDE: Mutual Information Neural Diffusion Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franzese%2C+G">Giulio Franzese</a>, 
<a href="/search/cs?searchtype=author&query=Bounoua%2C+M">Mustapha Bounoua</a>, 
<a href="/search/cs?searchtype=author&query=Michiardi%2C+P">Pietro Michiardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this work we present a new method for the estimation of Mutual Information
(MI) between random variables. Our approach is based on an original
interpretation of the Girsanov theorem, which allows us to use score-based
diffusion models to estimate the Kullback Leibler divergence between two
densities as a difference between their score functions. As a by-product, our
method also enables the estimation of the entropy of random variables. Armed
with such building blocks, we present a general recipe to measure MI, which
unfolds in two directions: one uses conditional diffusion process, whereas the
other uses joint diffusion processes that allow simultaneous modelling of two
random variables. Our results, which derive from a thorough experimental
protocol over all the variants of our approach, indicate that our method is
more accurate than the main alternatives from the literature, especially for
challenging distributions. Furthermore, our methods pass MI self-consistency
tests, including data processing and additivity under independence, which
instead are a pain-point of existing methods.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09032" title="Abstract">arXiv:2310.09032</a> [<a href="/pdf/2310.09032" title="Download PDF">pdf</a>, <a href="/ps/2310.09032" title="Download PostScript">ps</a>, <a href="/format/2310.09032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-Free Massive MIMO for ISAC: Access Point Operation Mode Selection  and Power Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elfiatoure%2C+M">Mohamed Elfiatoure</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mohammadali Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the IEEE GLOBECOM 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers a cell-free massive multipleinput multiple-output (MIMO)
integrated sensing and communication (ISAC) system, where distributed MIMO
access points (APs) are used to jointly serve the communication users and
detect the presence of a single target. We investigate the problem of AP
operation mode selection, wherein some APs are dedicated for downlink
communication, while the remaining APs are used for sensing purposes.
Closed-form expressions for the individual spectral efficiency (SE) and
mainlobe-to-average-sidelobe ratio (MASR) are derived, which are respectively
utilized to assess the communication and sensing performances. Accordingly, a
maxmin fairness problem is formulated and solved, where the minimum SE of the
users is maximized, subject to the per-AP power constraints as well as sensing
MASR constraint. Our numerical results show that the proposed AP operation mode
selection with power control can significantly improve the communication
performance for given sensing requirements.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09036" title="Abstract">arXiv:2310.09036</a> [<a href="/pdf/2310.09036" title="Download PDF">pdf</a>, <a href="/format/2310.09036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-BigBench: Evaluating Multimodal Models on Multimodal Content  Comprehension Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaocui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Ming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiaoming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Underview
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The popularity of multimodal large language models (MLLMs) has triggered a
recent surge in research efforts dedicated to evaluating these models.
Nevertheless, existing evaluation studies of MLLMs primarily focus on the
comprehension and reasoning of unimodal (vision) content, neglecting
performance evaluations in the domain of multimodal (vision-language) content
understanding. Beyond multimodal reasoning, tasks related to multimodal content
comprehension necessitate a profound understanding of multimodal contexts,
achieved through the multimodal interaction to obtain a final answer. In this
paper, we introduce a comprehensive assessment framework called MM-BigBench,
which incorporates a diverse range of metrics to offer an extensive evaluation
of the performance of various models and instructions across a wide spectrum of
diverse multimodal content comprehension tasks. Consequently, our work
complements research on the performance of MLLMs in multimodal comprehension
tasks, achieving a more comprehensive and holistic evaluation of MLLMs. To
begin, we employ the Best Performance metric to ascertain each model's
performance upper bound on different datasets. Subsequently, the Mean Relative
Gain metric offers an assessment of the overall performance of various models
and instructions, while the Stability metric measures their sensitivity.
Furthermore, previous research centers on evaluating models independently or
solely assessing instructions, neglecting the adaptability between models and
instructions. We propose the Adaptability metric to quantify the adaptability
between models and instructions. Our paper evaluates a total of 20 language
models (14 MLLMs) on 14 multimodal datasets spanning 6 tasks, with 10
instructions for each task, and derives novel insights. Our code will be
released at https://github.com/declare-lab/MM-BigBench.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09038" title="Abstract">arXiv:2310.09038</a> [<a href="/pdf/2310.09038" title="Download PDF">pdf</a>, <a href="/ps/2310.09038" title="Download PostScript">ps</a>, <a href="/format/2310.09038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The exponential logic of sequentialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alcolei%2C+A">Aurore Alcolei</a>, 
<a href="/search/cs?searchtype=author&query=Pellissier%2C+L">Luc Pellissier</a>, 
<a href="/search/cs?searchtype=author&query=Saurin%2C+A">Alexis Saurin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, submitted to MFPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Linear logic has provided new perspectives on proof-theory, denotational
semantics and the study of programming languages. One of its main successes are
proof-nets, canonical representations of proofs that lie at the intersection
between logic and graph theory. In the case of the minimalist proof-system of
multiplicative linear logic without units (MLL), these two aspects are
completely fused: proof-nets for this system are graphs satisfying a
correctness criterion that can be fully expressed in the language of graphs.
<br />For more expressive logical systems (containing logical constants,
quantifiers and exponential modalities), this is not completely the case. The
purely graphical approach of proof-nets deprives them of any sequential
structure that is crucial to represent the order in which arguments are
presented, which is necessary for these extensions. Rebuilding this order of
presentation - sequentializing the graph - is thus a requirement for a graph to
be logical. Presentations and study of the artifacts ensuring that
sequentialization can be done, such as boxes or jumps, are an integral part of
researches on linear logic.
<br />Jumps, extensively studied by Faggian and di Giamberardino, can express
intermediate degrees of sequentialization between a sequent calculus proof and
a fully desequentialized proof-net. We propose to analyze the logical strength
of jumps by internalizing them in an extention of MLL where axioms on a
specific formula, the jumping formula, introduce constrains on the possible
sequentializations. The jumping formula needs to be treated non-linearly, which
we do either axiomatically, or by embedding it in a very controlled fragment of
multiplicative-exponential linear logic, uncovering the exponential logic of
sequentialization.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09040" title="Abstract">arXiv:2310.09040</a> [<a href="/pdf/2310.09040" title="Download PDF">pdf</a>, <a href="/format/2310.09040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Scheduling of Electric Vehicle Charging with Deep Reinforcement  Learning considering End Users Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menos-Aikateriniadis%2C+C">Christoforos Menos-Aikateriniadis</a>, 
<a href="/search/cs?searchtype=author&query=Sykiotis%2C+S">Stavros Sykiotis</a>, 
<a href="/search/cs?searchtype=author&query=Georgilakis%2C+P+S">Pavlos S. Georgilakis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 13th Mediterranean Conference on Power Generation, Transmission,
  Distribution and Energy Conversion (MEDPOWER 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid growth of decentralized energy resources and especially Electric
Vehicles (EV), that are expected to increase sharply over the next decade, will
put further stress on existing power distribution networks, increasing the need
for higher system reliability and flexibility. In an attempt to avoid
unnecessary network investments and to increase the controllability over
distribution networks, network operators develop demand response (DR) programs
that incentivize end users to shift their consumption in return for financial
or other benefits. Artificial intelligence (AI) methods are in the research
forefront for residential load scheduling applications, mainly due to their
high accuracy, high computational speed and lower dependence on the physical
characteristics of the models under development. The aim of this work is to
identify households' EV cost-reducing charging policy under a Time-of-Use
tariff scheme, with the use of Deep Reinforcement Learning, and more
specifically Deep Q-Networks (DQN). A novel end users flexibility potential
reward is inferred from historical data analysis, where households with solar
power generation have been used to train and test the designed algorithm. The
suggested DQN EV charging policy can lead to more than 20% of savings in end
users electricity bills.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09044" title="Abstract">arXiv:2310.09044</a> [<a href="/pdf/2310.09044" title="Download PDF">pdf</a>, <a href="/format/2310.09044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level  Hallucination Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sehyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianqing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable human-level natural
language generation capabilities. However, their potential to generate
misinformation, often called the hallucination problem, poses a significant
risk to their deployment. A common approach to address this issue is to
retrieve relevant knowledge and fine-tune the LLM with the knowledge in its
input. Unfortunately, this method incurs high training costs and may cause
catastrophic forgetting for multi-tasking models. To overcome these
limitations, we propose a knowledge-constrained decoding method called KCTS
(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text
aligned with the reference knowledge at each decoding step using a knowledge
classifier score and MCTS (Monte-Carlo Tree Search). To adapt the
sequence-level knowledge classifier to token-level guidance, we also propose a
novel token-level hallucination detection method called RIPA (Reward Inflection
Point Approximation). Our empirical results on knowledge-grounded dialogue and
abstractive summarization demonstrate the strength of KCTS as a plug-and-play,
model-agnostic decoding method that can effectively reduce hallucinations in
natural language generation.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09049" title="Abstract">arXiv:2310.09049</a> [<a href="/pdf/2310.09049" title="Download PDF">pdf</a>, <a href="/format/2310.09049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAI: Solving AI Tasks with Systematic Artificial Intelligence in  Communication Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zilong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jialu Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the rapid development of artificial intelligence, solving complex AI tasks
is a crucial technology in intelligent mobile networks. Despite the good
performance of specialized AI models in intelligent mobile networks, they are
unable to handle complicated AI tasks. To address this challenge, we propose
Systematic Artificial Intelligence (SAI), which is a framework designed to
solve AI tasks by leveraging Large Language Models (LLMs) and JSON-format
intent-based input to connect self-designed model library and database.
Specifically, we first design a multi-input component, which simultaneously
integrates Large Language Models (LLMs) and JSON-format intent-based inputs to
fulfill the diverse intent requirements of different users. In addition, we
introduce a model library module based on model cards which employ model cards
to pairwise match between different modules for model composition. Model cards
contain the corresponding model's name and the required performance metrics.
Then when receiving user network requirements, we execute each subtask for
multiple selected model combinations and provide output based on the execution
results and LLM feedback. By leveraging the language capabilities of LLMs and
the abundant AI models in the model library, SAI can complete numerous complex
AI tasks in the communication network, achieving impressive results in network
optimization, resource allocation, and other challenging tasks.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09051" title="Abstract">arXiv:2310.09051</a> [<a href="/pdf/2310.09051" title="Download PDF">pdf</a>, <a href="/format/2310.09051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bots, Elections, and Controversies: Twitter Insights from Brazil&#x27;s  Polarised Elections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacheco%2C+D">Diogo Pacheco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">From 2018 to 2023, Brazil experienced its most fiercely contested elections
in history, resulting in the election of far-right candidate Jair Bolsonaro
followed by the left-wing, Lula da Silva. This period was marked by a murder
attempt, a coup attempt, the pandemic, and a plethora of conspiracy theories
and controversies. This paper analyses 437 million tweets originating from 13
million accounts associated with Brazilian politics during these two
presidential election cycles. We focus on accounts' behavioural patterns. We
noted a quasi-monotonic escalation in bot engagement, marked by notable surges
both during COVID-19 and in the aftermath of the 2022 election. The data
revealed a strong correlation between bot engagement and the number of replies
during a single day ($r=0.66$, $p&lt;0.01$). Furthermore, we identified a range of
suspicious activities, including an unusually high number of accounts being
created on the same day, with some days witnessing over 20,000 new accounts and
super-prolific accounts generating close to 100,000 tweets. Lastly, we
uncovered a sprawling network of accounts sharing Twitter handles, with a
select few managing to utilise more than 100 distinct handles. This work can be
instrumental in dismantling coordinated campaigns and offer valuable insights
for the enhancement of bot detection algorithms.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09053" title="Abstract">arXiv:2310.09053</a> [<a href="/pdf/2310.09053" title="Download PDF">pdf</a>, <a href="/format/2310.09053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kevin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+R">Rwik Rana</a>, 
<a href="/search/cs?searchtype=author&query=Spitzer%2C+A">Alexander Spitzer</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Precise arbitrary trajectory tracking for quadrotors is challenging due to
unknown nonlinear dynamics, trajectory infeasibility, and actuation limits. To
tackle these challenges, we present Deep Adaptive Trajectory Tracking (DATT), a
learning-based approach that can precisely track arbitrary, potentially
infeasible trajectories in the presence of large disturbances in the real
world. DATT builds on a novel feedforward-feedback-adaptive control structure
trained in simulation using reinforcement learning. When deployed on real
hardware, DATT is augmented with a disturbance estimator using L1 adaptive
control in closed-loop, without any fine-tuning. DATT significantly outperforms
competitive adaptive nonlinear and model predictive controllers for both
feasible smooth and infeasible trajectories in unsteady wind fields, including
challenging scenarios where baselines completely fail. Moreover, DATT can
efficiently run online with an inference time less than 3.2 ms, less than 1/4
of the adaptive nonlinear model predictive control baseline
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09054" title="Abstract">arXiv:2310.09054</a> [<a href="/pdf/2310.09054" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison between Conventional Load Flow, QSTS Simulation, and Dynamic  Simulation to Assess the Operation of Step Voltage Regulators in Active  Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Souza%2C+V+M">V. M. Souza</a>, 
<a href="/search/eess?searchtype=author&query=Brito%2C+H+R">H. R. Brito</a>, 
<a href="/search/eess?searchtype=author&query=Vieira%2C+J+P+A">J. P. A. Vieira</a>, 
<a href="/search/eess?searchtype=author&query=Tostes%2C+M+E+L">M. E. L. Tostes</a>, 
<a href="/search/eess?searchtype=author&query=Bezerra%2C+U+H">U. H. Bezerra</a>, 
<a href="/search/eess?searchtype=author&query=Cardoso%2C+H+N+S">H. N. S. Cardoso</a>, 
<a href="/search/eess?searchtype=author&query=Costa%2C+M+S">M. S. Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures, submitted to XVIII ERIAC 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The assessment of step voltage regulator (SVR) operation in active
distribution networks requires computational analysis tools capable of tackling
the emerging technical challenges. Conventional load flow (CLF), quasi-static
time series (QSTS) and dynamic simulations are typically employed to
investigate high-penetration distributed generation (DG) interconnection
impacts. Regarding the SVR runaway condition phenomenon, however, a consensus
has yet to be reached on the most cost-effective simulation technique for
capturing and reproducing the correct sequence of events. This work presents a
comparative study of the CLF, QSTS and dynamic simulation techniques through
modelling and analysis of two SVR-controlled test-feeders, in order to evaluate
each approach performance in addressing scenarios of DG-caused reverse active
power flow. Detailed descriptions of feeder voltage profile and SVR tap
operations are provided to facilitate understanding of the mechanisms that
characterize SVR runaway condition, as well as the advantages and drawbacks of
each of the studied simulation techniques.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09066" title="Abstract">arXiv:2310.09066</a> [<a href="/pdf/2310.09066" title="Download PDF">pdf</a>, <a href="/format/2310.09066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pose-format: Library for Viewing, Augmenting, and Handling .pose Files
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moryossef%2C+A">Amit Moryossef</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Mathias M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Fahrni%2C+R">Rebecka Fahrni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Managing and analyzing pose data is a complex task, with challenges ranging
from handling diverse file structures and data types to facilitating effective
data manipulations such as normalization and augmentation. This paper presents
\texttt{pose-format}, a comprehensive toolkit designed to address these
challenges by providing a unified, flexible, and easy-to-use interface. The
library includes a specialized file format that encapsulates various types of
pose data, accommodating multiple individuals and an indefinite number of time
frames, thus proving its utility for both image and video data. Furthermore, it
offers seamless integration with popular numerical libraries such as NumPy,
PyTorch, and TensorFlow, thereby enabling robust machine-learning applications.
Through benchmarking, we demonstrate that our \texttt{.pose} file format offers
vastly superior performance against prevalent formats like OpenPose, with added
advantages like self-contained pose specification. Additionally, the library
includes features for data normalization, augmentation, and easy-to-use
visualization capabilities, both in Python and Browser environments.
\texttt{pose-format} emerges as a one-stop solution, streamlining the
complexities of pose data management and analysis.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09068" title="Abstract">arXiv:2310.09068</a> [<a href="/pdf/2310.09068" title="Download PDF">pdf</a>, <a href="/format/2310.09068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Combine OTFS and OFDM Modulations in Massive MIMO?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chong%2C+R">Ruoxi Chong</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mohammadali Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Cotton%2C+S+L">Simon L. Cotton</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we consider a downlink (DL) massive multiple-input
multiple-output (MIMO) system, where different users have different mobility
profiles. To support this system, we propose to use a hybrid orthogonal time
frequency space (OTFS)/orthogonal frequency division multiplexing (OFDM)
modulation scheme, where OTFS is applied for high-mobility users and OFDM is
used for low-mobility users. Two precoding designs, namely full zero-forcing
(FZF) precoding and partial zero-forcing (PZF) precoding, are considered and
analyzed in terms of per-user spectral efficiency (SE). With FZF, interference
among users is totally eliminated at the cost of high computational complexity,
while PZF can be used to provide a trade-off between complexity and
performance. To apply PZF precoding, users are grouped into two disjoint groups
according to their mobility profile or channel gain. Then, zero-forcing (ZF) is
utilized for high-mobility or strong channel gain users to completely cancel
the inter-group interference, while maximum ratio transmission (MRT) is applied
for low-mobility users or users with weak channel gain. To shed light on the
system performance, the SE for high-mobility and low-mobility users with a
minimum-mean-square-error (MMSE)-successive interference cancellation (SIC)
detector is investigated. Our numerical results reveal that the PZF precoding
with channel gain grouping can guarantee a similar quality of service for all
users. In addition, with mobility-based grouping, the hybrid OTFS/OFDM
modulation outperforms the conventional OFDM modulation for high-mobility
users.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09069" title="Abstract">arXiv:2310.09069</a> [<a href="/pdf/2310.09069" title="Download PDF">pdf</a>, <a href="/format/2310.09069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImageManip: Image-based Robotic Manipulation with Affordance-guided Next  View Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Iaroslav%2C+P">Ponomarenko Iaroslav</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haoran Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Boshi An</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of future home-assistant robots, 3D articulated object
manipulation is essential for enabling robots to interact with their
environment. Many existing studies make use of 3D point clouds as the primary
input for manipulation policies. However, this approach encounters challenges
due to data sparsity and the significant cost associated with acquiring point
cloud data, which can limit its practicality. In contrast, RGB images offer
high-resolution observations using cost effective devices but lack spatial 3D
geometric information. To overcome these limitations, we present a novel
image-based robotic manipulation framework. This framework is designed to
capture multiple perspectives of the target object and infer depth information
to complement its geometry. Initially, the system employs an eye-on-hand RGB
camera to capture an overall view of the target object. It predicts the initial
depth map and a coarse affordance map. The affordance map indicates actionable
areas on the object and serves as a constraint for selecting subsequent
viewpoints. Based on the global visual prior, we adaptively identify the
optimal next viewpoint for a detailed observation of the potential manipulation
success area. We leverage geometric consistency to fuse the views, resulting in
a refined depth map and a more precise affordance map for robot manipulation
decisions. By comparing with prior works that adopt point clouds or RGB images
as inputs, we demonstrate the effectiveness and practicality of our method. In
the project webpage (https://sites.google.com/view/imagemanip), real world
experiments further highlight the potential of our method for practical
deployment.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09070" title="Abstract">arXiv:2310.09070</a> [<a href="/pdf/2310.09070" title="Download PDF">pdf</a>, <a href="/format/2310.09070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three-Dimensional Sonification as a Surgical Guidance Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziemer%2C+T">Tim Ziemer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> research paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Interactive Sonification is a well-known guidance method in navigation tasks.
Researchers have repeatedly suggested the use of interactive sonification in
neuronavigation and image-guided surgery. The hope is to reduce clinicians'
cognitive load through a relief of the visual channel, while preserving the
precision provided through image guidance. In this paper, we present a surgical
use case, simulating a craniotomy preparation with a skull phantom. Through
auditory, visual, and audiovisual guidance, non-clinicians successfully find
targets on a skull that provides hardly any visual or haptic landmarks. The
results show that interactive sonification enables novice users to navigate
through three-dimensional space with a high precision. The precision along the
depth axis is highest in the audiovisual guidance mode, but adding audio leads
to higher durations and longer motion trajectories.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09071" title="Abstract">arXiv:2310.09071</a> [<a href="/pdf/2310.09071" title="Download PDF">pdf</a>, <a href="/format/2310.09071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Relocating and Matching of Ride-Hailing Services: A Model-Based  Modular Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fang He</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xindi Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This study proposes an innovative model-based modular approach (MMA) to
dynamically optimize order matching and vehicle relocation in a ride-hailing
platform. MMA utilizes a two-layer and modular modeling structure. The upper
layer determines the spatial transfer patterns of vehicle flow within the
system to maximize the total revenue of the current and future stages. With the
guidance provided by the upper layer, the lower layer performs rapid
vehicle-to-order matching and vehicle relocation. MMA is interpretable, and
equipped with the customized and polynomial-time algorithm, which, as an online
order-matching and vehicle-relocation algorithm, can scale past thousands of
vehicles. We theoretically prove that the proposed algorithm can achieve the
global optimum in stylized networks, while the numerical experiments based on
both the toy network and realistic dataset demonstrate that MMA is capable of
achieving superior systematic performance compared to batch matching and
reinforcement-learning based methods. Moreover, its modular and lightweight
modeling structure further enables it to achieve a high level of robustness
against demand variation while maintaining a relatively low computational cost.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09074" title="Abstract">arXiv:2310.09074</a> [<a href="/pdf/2310.09074" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Distributed Generation on the Bidirectional Operation of  Cascaded Step Voltage Regulators: Case Study of a Real 34.5 kV Distribution  Feeder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Brito%2C+H+R">Hugo Rodrigues de Brito</a>, 
<a href="/search/eess?searchtype=author&query=de+Souza%2C+V+M">Val&#xe9;ria Monteiro de Souza</a>, 
<a href="/search/eess?searchtype=author&query=Vieira%2C+J+P+A">Jo&#xe3;o Paulo Abreu Vieira</a>, 
<a href="/search/eess?searchtype=author&query=de+Lima+Tostes%2C+M+E">Maria Em&#xed;lia de Lima Tostes</a>, 
<a href="/search/eess?searchtype=author&query=Bezerra%2C+U+H">Ubiratan Holanda Bezerra</a>, 
<a href="/search/eess?searchtype=author&query=de+Souza%2C+V+C">Vanderson Carvalho de Souza</a>, 
<a href="/search/eess?searchtype=author&query=da+Concei%C3%A7%C3%A3o+Pinheiro%2C+D">Daniel da Concei&#xe7;&#xe3;o Pinheiro</a>, 
<a href="/search/eess?searchtype=author&query=Barata%2C+H+A">Heitor Alves Barata</a>, 
<a href="/search/eess?searchtype=author&query=de+Souza+Cardoso%2C+H+N">Hugo Nazareno de Souza Cardoso</a>, 
<a href="/search/eess?searchtype=author&query=Costa%2C+M+S">Marcelo Sousa Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, submitted to XXV SNPTEE 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work investigates the impact of feeder bidirectional active power flow
on the operation of two cascaded step voltage regulators (SVRs) located at a
34.5 kV rural distribution feeder. It shows that, when active power flow
reversal is possible both by network reconfiguration and by high penetration
levels of distributed generation (DG), typical SVR control mode settings are
unable to prevent the occurrence of runaway condition, a phenomenon
characterized by loss of SVR voltage control capabilities. Such developments
are the basis for a DG pre-dispatch control strategy that aims to avoid the
adverse effects of the described power flow reversal scenarios, as well as to
ensure reliable operation of the utility distribution network.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09078" title="Abstract">arXiv:2310.09078</a> [<a href="/pdf/2310.09078" title="Download PDF">pdf</a>, <a href="/format/2310.09078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNFS-VNE: Deep Neuro-Fuzzy System-Driven Virtual Network Embedding  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Ailing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shigen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weiping Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiying Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">By decoupling substrate resources, network virtualization (NV) is a promising
solution for meeting diverse demands and ensuring differentiated quality of
service (QoS). In particular, virtual network embedding (VNE) is a critical
enabling technology that enhances the flexibility and scalability of network
deployment by addressing the coupling of Internet processes and services.
However, in the existing works, the black-box nature of deep neural networks
(DNNs) limits the analysis, development, and improvement of systems. In recent
times, interpretable deep learning (DL) represented by deep neuro-fuzzy systems
(DNFS) combined with fuzzy inference has shown promising interpretability to
further exploit the hidden value in the data. Motivated by this, we propose a
DNFS-based VNE algorithm that aims to provide an interpretable NV scheme.
Specifically, data-driven convolutional neural networks (CNNs) are used as
fuzzy implication operators to compute the embedding probabilities of candidate
substrate nodes through entailment operations. And, the identified fuzzy rule
patterns are cached into the weights by forward computation and gradient
back-propagation (BP). In addition, the fuzzy rule base is constructed based on
Mamdani-type linguistic rules using linguistic labels. Finally, the
effectiveness of evaluation indicators and fuzzy rules is verified by
experiments.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09088" title="Abstract">arXiv:2310.09088</a> [<a href="/pdf/2310.09088" title="Download PDF">pdf</a>, <a href="/format/2310.09088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dialect Transfer for Swiss German Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paonessa%2C+C">Claudio Paonessa</a>, 
<a href="/search/cs?searchtype=author&query=Schraner%2C+Y">Yanick Schraner</a>, 
<a href="/search/cs?searchtype=author&query=Deriu%2C+J">Jan Deriu</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCrlimann%2C+M">Manuela H&#xfc;rlimann</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+M">Manfred Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Cieliebak%2C+M">Mark Cieliebak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper investigates the challenges in building Swiss German speech
translation systems, specifically focusing on the impact of dialect diversity
and differences between Swiss German and Standard German. Swiss German is a
spoken language with no formal writing system, it comprises many diverse
dialects and is a low-resource language with only around 5 million speakers.
The study is guided by two key research questions: how does the inclusion and
exclusion of dialects during the training of speech translation models for
Swiss German impact the performance on specific dialects, and how do the
differences between Swiss German and Standard German impact the performance of
the systems? We show that dialect diversity and linguistic differences pose
significant challenges to Swiss German speech translation, which is in line
with linguistic hypotheses derived from empirical investigations.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09089" title="Abstract">arXiv:2310.09089</a> [<a href="/pdf/2310.09089" title="Download PDF">pdf</a>, <a href="/format/2310.09089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qichen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+D">Dading Chong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yining Hua</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Andrew Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Integrating large language models (LLMs) into healthcare presents potential
but faces challenges. Directly pre-training LLMs for domains like medicine is
resource-heavy and sometimes unfeasible. Sole reliance on Supervised
Fine-tuning (SFT) can result in overconfident predictions and may not tap into
domain specific insights. Addressing these challenges, we present a multi-stage
training method combining Domain-specific Continued Pre-training (DCPT), SFT,
and Direct Preference Optimization (DPO). A notable contribution of our study
is the introduction of a 3Gb Chinese Medicine (ChiMed) dataset, encompassing
medical question answering, plain texts, knowledge graphs, and dialogues,
segmented into three training stages. The medical LLM trained with our
pipeline, Qilin-Med, exhibits significant performance boosts. In the CPT and
SFT phases, it achieves 38.4% and 40.0% accuracy on the CMExam, surpassing
Baichuan-7B's 33.5%. In the DPO phase, on the Huatuo-26M test set, it scores
16.66 in BLEU-1 and 27.44 in ROUGE1, outperforming the SFT's 12.69 and 24.21.
This highlights the strength of our training approach in refining LLMs for
medical applications.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09091" title="Abstract">arXiv:2310.09091</a> [<a href="/pdf/2310.09091" title="Download PDF">pdf</a>, <a href="/format/2310.09091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insightful analysis of historical sources at scales beyond human  capabilities using unsupervised Machine Learning and XAI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eberle%2C+O">Oliver Eberle</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCttner%2C+J">Jochen B&#xfc;ttner</a>, 
<a href="/search/cs?searchtype=author&query=El-Hajj%2C+H">Hassan El-Hajj</a>, 
<a href="/search/cs?searchtype=author&query=Montavon%2C+G">Gr&#xe9;goire Montavon</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Valleriani%2C+M">Matteo Valleriani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Digital Libraries (cs.DL)

</div>
<p class="mathjax">Historical materials are abundant. Yet, piecing together how human knowledge
has evolved and spread both diachronically and synchronically remains a
challenge that can so far only be very selectively addressed. The vast volume
of materials precludes comprehensive studies, given the restricted number of
human specialists. However, as large amounts of historical materials are now
available in digital form there is a promising opportunity for AI-assisted
historical analysis. In this work, we take a pivotal step towards analyzing
vast historical corpora by employing innovative machine learning (ML)
techniques, enabling in-depth historical insights on a grand scale. Our study
centers on the evolution of knowledge within the `Sacrobosco Collection' -- a
digitized collection of 359 early modern printed editions of textbooks on
astronomy used at European universities between 1472 and 1650 -- roughly 76,000
pages, many of which contain astronomic, computational tables. An ML based
analysis of these tables helps to unveil important facets of the
spatio-temporal evolution of knowledge and innovation in the field of
mathematical astronomy in the period, as taught at European universities.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09092" title="Abstract">arXiv:2310.09092</a> [<a href="/pdf/2310.09092" title="Download PDF">pdf</a>, <a href="/format/2310.09092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iPUNet:Iterative Cross Field Guided Point Cloud Upsampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guangshun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shaojie Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjian Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point clouds acquired by 3D scanning devices are often sparse, noisy, and
non-uniform, causing a loss of geometric features. To facilitate the usability
of point clouds in downstream applications, given such input, we present a
learning-based point upsampling method, i.e., iPUNet, which generates dense and
uniform points at arbitrary ratios and better captures sharp features. To
generate feature-aware points, we introduce cross fields that are aligned to
sharp geometric features by self-supervision to guide point generation. Given
cross field defined frames, we enable arbitrary ratio upsampling by learning at
each input point a local parameterized surface. The learned surface consumes
the neighboring points and 2D tangent plane coordinates as input, and maps onto
a continuous surface in 3D where arbitrary ratios of output points can be
sampled. To solve the non-uniformity of input points, on top of the cross field
guided upsampling, we further introduce an iterative strategy that refines the
point distribution by moving sparse points onto the desired continuous 3D
surface in each iteration. Within only a few iterations, the sparse points are
evenly distributed and their corresponding dense samples are more uniform and
better capture geometric features. Through extensive evaluations on diverse
scans of objects and scenes, we demonstrate that iPUNet is robust to handle
noisy and non-uniformly distributed inputs, and outperforms state-of-the-art
point cloud upsampling methods.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09094" title="Abstract">arXiv:2310.09094</a> [<a href="/pdf/2310.09094" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A RISC-V MCU with adaptive reverse body bias and ultra-low-power  retention mode in 22 nm FD-SOI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+H">Heiner Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Stolba%2C+M">Marco Stolba</a>, 
<a href="/search/cs?searchtype=author&query=Scholze%2C+S">Stefan Scholze</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+D">Dennis Walter</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+C">Christian Mayr</a>, 
<a href="/search/cs?searchtype=author&query=Oefelein%2C+A">Alexander Oefelein</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6ppner%2C+S">Sebastian H&#xf6;ppner</a>, 
<a href="/search/cs?searchtype=author&query=Scharfe%2C+A">Andr&#xe9; Scharfe</a>, 
<a href="/search/cs?searchtype=author&query=Schraut%2C+F">Flo Schraut</a>, 
<a href="/search/cs?searchtype=author&query=Eisenreich%2C+H">Holger Eisenreich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ISOCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">We present a low-power, energy efficient 32-bit RISC-V microprocessor unit
(MCU) in 22 nm FD-SOI. It achieves ultra-low leakage,even at high temperatures,
by using an adaptive reverse body biasing aware sign-off approach, a low-power
optimized physical implementation, and custom SRAM macros with retention mode.
We demonstrate the robustness of the chip with measurements over the full
industrial temperature range, from -40 {\deg}C to 125 {\deg}C. Our results
match the state of the art (SOTA) with 4.8 uW / MHz at 50 MHz in active mode
and surpass the SOTA in ultra-low-power retention mode.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09101" title="Abstract">arXiv:2310.09101</a> [<a href="/pdf/2310.09101" title="Download PDF">pdf</a>, <a href="/format/2310.09101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Encrypted Low-Dose CT Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huangfu%2C+H">Huijie Huangfu</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+M">Maosong Ran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning (DL) has made significant advancements in tomographic imaging,
particularly in low-dose computed tomography (LDCT) denoising. A recent trend
involves servers training powerful models with large amounts of self-collected
private data and providing application programming interfaces (APIs) for users,
such as Chat-GPT. To avoid model leakage, users are required to upload their
data to the server model, but this way raises public concerns about the
potential risk of privacy disclosure, especially for medical data. Hence, to
alleviate related concerns, in this paper, we propose to directly denoise LDCT
in the encrypted domain to achieve privacy-preserving cloud services without
exposing private data to the server. To this end, we employ homomorphic
encryption to encrypt private LDCT data, which is then transferred to the
server model trained with plaintext LDCT for further denoising. However, since
traditional operations, such as convolution and linear transformation, in DL
methods cannot be directly used in the encrypted domain, we transform the
fundamental mathematic operations in the plaintext domain into the operations
in the encrypted domain. In addition, we present two interactive frameworks for
linear and nonlinear models in this paper, both of which can achieve lossless
operating. In this way, the proposed methods can achieve two merits, the data
privacy is well protected and the server model is free from the risk of model
leakage. Moreover, we provide theoretical proof to validate the lossless
property of our framework. Finally, experiments were conducted to demonstrate
that the transferred contents are well protected and cannot be reconstructed.
The code will be released once the paper is accepted.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09107" title="Abstract">arXiv:2310.09107</a> [<a href="/pdf/2310.09107" title="Download PDF">pdf</a>, <a href="/format/2310.09107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLoRE: Evaluating Logical Reasoning of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=liu%2C+H">Hanmeng liu</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhiyang Teng</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+R">Ruoxi Ning</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiji Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, large language models (LLMs), including notable models such as
GPT-4 and burgeoning community models, have showcased significant general
language understanding abilities. However, there has been a scarcity of
attempts to assess the logical reasoning capacities of these LLMs, an essential
facet of natural language understanding. To encourage further investigation in
this area, we introduce GLoRE, a meticulously assembled General Logical
Reasoning Evaluation benchmark comprised of 12 datasets that span three
different types of tasks. Our experimental results show that compared to the
performance of human and supervised fine-tuning, the logical reasoning
capabilities of open LLM models necessitate additional improvement; ChatGPT and
GPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing
ChatGPT by a large margin. We propose a self-consistency probing method to
enhance the accuracy of ChatGPT and a fine-tuned method to boost the
performance of an open LLM. We release the datasets and evaluation programs to
facilitate future research.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09109" title="Abstract">arXiv:2310.09109</a> [<a href="/pdf/2310.09109" title="Download PDF">pdf</a>, <a href="/format/2310.09109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Integer-Complete Synthesis for Bounded Parametric Timed Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+%C3%89">&#xc9;tienne Andr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Lime%2C+D">Didier Lime</a>, 
<a href="/search/cs?searchtype=author&query=Roux%2C+O+H">Olivier H. Roux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of the paper by the same authors published in the proceedings of the 9th International Workshop on Reachability Problems (RP 2015)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Ensuring the correctness of critical real-time systems, involving concurrent
behaviors and timing requirements, is crucial. Timed automata extend
finite-state automata with clocks, compared in guards and invariants with
integer constants. Parametric timed automata (PTAs) extend timed automata with
timing parameters. Parameter synthesis aims at computing dense sets of
valuations for the timing parameters, guaranteeing a good behavior. However, in
most cases, the emptiness problem for reachability (i.e., whether the emptiness
of the parameter valuations set for which some location is reachable) is
undecidable for PTAs and, as a consequence, synthesis procedures do not
terminate in general, even for bounded parameters. In this paper, we introduce
a parametric extrapolation, that allows us to derive an underapproximation in
the form of linear constraints containing not only all the integer points
ensuring reachability, but also all the (non-necessarily integer) convex
combinations of these integer points, for general PTAs with a bounded parameter
domain. We also propose two further algorithms synthesizing parameter
valuations guaranteeing unavoidability, and preservation of the untimed
behavior w.r.t. a reference parameter valuation, respectively. Our algorithms
terminate and can output constraints arbitrarily close to the complete result.
We demonstrate their applicability and efficiency using the tool Rom\'eo on two
classical benchmarks.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09114" title="Abstract">arXiv:2310.09114</a> [<a href="/pdf/2310.09114" title="Download PDF">pdf</a>, <a href="/format/2310.09114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timestamp-supervised Wearable-based Activity Segmentation and  Recognition with Contrastive Learning and Order-Preserving Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Songpengcheng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+L">Lei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+L">Ling Pei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiarui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R+C">Robert C. Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review (submitted to IEEE TMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human activity recognition (HAR) with wearables is one of the serviceable
technologies in ubiquitous and mobile computing applications. The
sliding-window scheme is widely adopted while suffering from the multi-class
windows problem. As a result, there is a growing focus on joint segmentation
and recognition with deep-learning methods, aiming at simultaneously dealing
with HAR and time-series segmentation issues. However, obtaining the full
activity annotations of wearable data sequences is resource-intensive or
time-consuming, while unsupervised methods yield poor performance. To address
these challenges, we propose a novel method for joint activity segmentation and
recognition with timestamp supervision, in which only a single annotated sample
is needed in each activity segment. However, the limited information of sparse
annotations exacerbates the gap between recognition and segmentation tasks,
leading to sub-optimal model performance. Therefore, the prototypes are
estimated by class-activation maps to form a sample-to-prototype contrast
module for well-structured embeddings. Moreover, with the optimal transport
theory, our approach generates the sample-level pseudo-labels that take
advantage of unlabeled data between timestamp annotations for further
performance improvement. Comprehensive experiments on four public HAR datasets
demonstrate that our model trained with timestamp supervision is superior to
the state-of-the-art weakly-supervised methods and achieves comparable
performance to the fully-supervised approaches.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09115" title="Abstract">arXiv:2310.09115</a> [<a href="/pdf/2310.09115" title="Download PDF">pdf</a>, <a href="/ps/2310.09115" title="Download PostScript">ps</a>, <a href="/format/2310.09115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determinization of Integral Discounted-Sum Automata is Decidable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almagor%2C+S">Shaull Almagor</a>, 
<a href="/search/cs?searchtype=author&query=Dafni%2C+N">Neta Dafni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Nondeterministic Discounted-Sum Automata (NDAs) are nondeterministic finite
automata equipped with a discounting factor $\lambda&gt;1$, and whose transitions
are labelled by weights. The value of a run of an NDA is the discounted sum of
the edge weights, where the $i$-th weight is divided by $\lambda^{i}$. NDAs are
a useful tool for modelling systems where the values of future events are less
influential than immediate ones.
<br />While several problems are undecidable or open for NDA, their deterministic
fragment (DDA) admits more tractable algorithms. Therefore, determinization of
NDAs (i.e., deciding if an NDA has a functionally-equivalent DDA) is desirable.
<br />Previous works establish that when $\lambda\in \mathbb{N}$, then every
complete NDA, namely an NDA whose states are all accepting and its transition
function is complete, is determinizable. This, however, no longer holds when
the completeness assumption is dropped.
<br />We show that the problem of whether an NDA has an equivalent DDA is decidable
when $\lambda\in \mathbb{N}$.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09118" title="Abstract">arXiv:2310.09118</a> [<a href="/pdf/2310.09118" title="Download PDF">pdf</a>, <a href="/format/2310.09118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSG: An End-to-End Document Structure Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rausch%2C+J">Johannes Rausch</a>, 
<a href="/search/cs?searchtype=author&query=Rashiti%2C+G">Gentiana Rashiti</a>, 
<a href="/search/cs?searchtype=author&query=Gusev%2C+M">Maxim Gusev</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Information in industry, research, and the public sector is widely stored as
rendered documents (e.g., PDF files, scans). Hence, to enable downstream tasks,
systems are needed that map rendered documents onto a structured hierarchical
format. However, existing systems for this task are limited by heuristics and
are not end-to-end trainable. In this work, we introduce the Document Structure
Generator (DSG), a novel system for document parsing that is fully end-to-end
trainable. DSG combines a deep neural network for parsing (i) entities in
documents (e.g., figures, text blocks, headers, etc.) and (ii) relations that
capture the sequence and nested structure between entities. Unlike existing
systems that rely on heuristics, our DSG is trained end-to-end, making it
effective and flexible for real-world applications. We further contribute a
new, large-scale dataset called E-Periodica comprising real-world magazines
with complex document structures for evaluation. Our results demonstrate that
our DSG outperforms commercial OCR tools and, on top of that, achieves
state-of-the-art performance. To the best of our knowledge, our DSG system is
the first end-to-end trainable system for hierarchical document parsing.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09119" title="Abstract">arXiv:2310.09119</a> [<a href="/pdf/2310.09119" title="Download PDF">pdf</a>, <a href="/format/2310.09119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for  Chinese Spelling Check
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haojing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jingheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, Chinese Spelling Check (CSC) has been greatly improved by
designing task-specific pre-training methods or introducing auxiliary tasks,
which mostly solve this task in an end-to-end fashion. In this paper, we
propose to decompose the CSC workflow into detection, reasoning, and searching
subtasks so that the rich external knowledge about the Chinese language can be
leveraged more directly and efficiently. Specifically, we design a
plug-and-play detection-and-reasoning module that is compatible with existing
SOTA non-autoregressive CSC models to further boost their performance. We find
that the detection-and-reasoning module trained for one model can also benefit
other models. We also study the primary interpretability provided by the task
decomposition. Extensive experiments and detailed analyses demonstrate the
effectiveness and competitiveness of the proposed module.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09122" title="Abstract">arXiv:2310.09122</a> [<a href="/pdf/2310.09122" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equirectangular image construction method for standard CNNs for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghe Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kaiwen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Rencheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yi Sui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">360{\deg} spherical images have advantages of wide view field, and are
typically projected on a planar plane for processing, which is known as
equirectangular image. The object shape in equirectangular images can be
distorted and lack translation invariance. In addition, there are few publicly
dataset of equirectangular images with labels, which presents a challenge for
standard CNNs models to process equirectangular images effectively. To tackle
this problem, we propose a methodology for converting a perspective image into
equirectangular image. The inverse transformation of the spherical center
projection and the equidistant cylindrical projection are employed. This
enables the standard CNNs to learn the distortion features at different
positions in the equirectangular image and thereby gain the ability to
semantically the equirectangular image. The parameter, {\phi}, which determines
the projection position of the perspective image, has been analyzed using
various datasets and models, such as UNet, UNet++, SegNet, PSPNet, and DeepLab
v3+. The experiments demonstrate that an optimal value of {\phi} for effective
semantic segmentation of equirectangular images is 6{\pi}/16 for standard CNNs.
Compared with the other three types of methods (supervised learning,
unsupervised learning and data augmentation), the method proposed in this paper
has the best average IoU value of 43.76%. This value is 23.85%, 10.7% and
17.23% higher than those of other three methods, respectively.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09124" title="Abstract">arXiv:2310.09124</a> [<a href="/pdf/2310.09124" title="Download PDF">pdf</a>, <a href="/format/2310.09124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking the Shortcut: Actively Incorporating the Virtual Memory Index of  the OS to Hardware-Accelerate Database Indexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuhknecht%2C+F">Felix Schuhknecht</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">Index structures often materialize one or multiple levels of explicit
indirections (aka pointers) to allow for a quick traversal to the data of
interest. Unfortunately, dereferencing a pointer to go from one level to the
other is costly since additionally to following the address, it involves two
address translations from virtual memory to physical memory under the hood. In
the worst case, such an address translation is resolved by an index access
itself, namely by a lookup into the page table, a central hardware-accelerated
index structure of the OS. However, if the page table is anyways constantly
queried, it raises the question whether we can actively incorporate it into our
database indexes and make it work for us. Precisely, instead of materializing
indirections in form of pointers, we propose to express these indirections
directly in the page table wherever possible. By introducing such shortcuts, we
(a) effectively reduce the height of traversal during lookups and (b) exploit
the hardware-acceleration of lookups in the page table. In this work, we
analyze the strengths and considerations of this approach and showcase its
effectiveness at the case of the real-world indexing scheme extendible hashing.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09125" title="Abstract">arXiv:2310.09125</a> [<a href="/pdf/2310.09125" title="Download PDF">pdf</a>, <a href="/format/2310.09125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training and Predicting Visual Error for Real-Time Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J+L">Jo&#xe3;o Lib&#xf3;rio Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Kerbl%2C+B">Bernhard Kerbl</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Uralsky%2C+Y">Yury Uralsky</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+M">Michael Wimmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Proceedings of the ACM in Computer Graphics and Interactive Techniques. 14 Pages, 16 Figures, 3 Tables. For paper website and higher quality figures, see <a href="https://jaliborc.github.io/rt-percept/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM on Computer Graphics and Interactive
  Techniques, Volume 5 (2022), Issue 1, Article 11, Pages 1 to 17
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Visual error metrics play a fundamental role in the quantification of
perceived image similarity. Most recently, use cases for them in real-time
applications have emerged, such as content-adaptive shading and shading reuse
to increase performance and improve efficiency. A wide range of different
metrics has been established, with the most sophisticated being capable of
capturing the perceptual characteristics of the human visual system. However,
their complexity, computational expense, and reliance on reference images to
compare against prevent their generalized use in real-time, restricting such
applications to using only the simplest available metrics. In this work, we
explore the abilities of convolutional neural networks to predict a variety of
visual metrics without requiring either reference or rendered images.
Specifically, we train and deploy a neural network to estimate the visual error
resulting from reusing shading or using reduced shading rates. The resulting
models account for 70%-90% of the variance while achieving up to an order of
magnitude faster computation times. Our solution combines image-space
information that is readily available in most state-of-the-art deferred shading
pipelines with reprojection from previous frames to enable an adequate estimate
of visual errors, even in previously unseen regions. We describe a suitable
convolutional network architecture and considerations for data preparation for
training. We demonstrate the capability of our network to predict complex error
metrics at interactive rates in a real-time application that implements
content-adaptive shading in a deferred pipeline. Depending on the portion of
unseen image regions, our approach can achieve up to $2\times$ performance
compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09127" title="Abstract">arXiv:2310.09127</a> [<a href="/pdf/2310.09127" title="Download PDF">pdf</a>, <a href="/format/2310.09127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Generalization Bounds for Projective Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bucarelli%2C+M+S">Maria Sofia Bucarelli</a>, 
<a href="/search/cs?searchtype=author&query=Larsen%2C+M+F">Matilde Fjelds&#xf8; Larsen</a>, 
<a href="/search/cs?searchtype=author&query=Schwiegelshohn%2C+C">Chris Schwiegelshohn</a>, 
<a href="/search/cs?searchtype=author&query=Toftrup%2C+M+B">Mads Bech Toftrup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Given a set of points, clustering consists of finding a partition of a point
set into $k$ clusters such that the center to which a point is assigned is as
close as possible. Most commonly, centers are points themselves, which leads to
the famous $k$-median and $k$-means objectives. One may also choose centers to
be $j$ dimensional subspaces, which gives rise to subspace clustering. In this
paper, we consider learning bounds for these problems. That is, given a set of
$n$ samples $P$ drawn independently from some unknown, but fixed distribution
$\mathcal{D}$, how quickly does a solution computed on $P$ converge to the
optimal clustering of $\mathcal{D}$? We give several near optimal results. In
particular,
<br />For center-based objectives, we show a convergence rate of
$\tilde{O}\left(\sqrt{{k}/{n}}\right)$. This matches the known optimal bounds
of [Fefferman, Mitter, and Narayanan, Journal of the Mathematical Society 2016]
and [Bartlett, Linder, and Lugosi, IEEE Trans. Inf. Theory 1998] for $k$-means
and extends it to other important objectives such as $k$-median.
<br />For subspace clustering with $j$-dimensional subspaces, we show a convergence
rate of $\tilde{O}\left(\sqrt{\frac{kj^2}{n}}\right)$. These are the first
provable bounds for most of these problems. For the specific case of projective
clustering, which generalizes $k$-means, we show a convergence rate of
$\Omega\left(\sqrt{\frac{kj}{n}}\right)$ is necessary, thereby proving that the
bounds from [Fefferman, Mitter, and Narayanan, Journal of the Mathematical
Society 2016] are essentially optimal.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09129" title="Abstract">arXiv:2310.09129</a> [<a href="/pdf/2310.09129" title="Download PDF">pdf</a>, <a href="/format/2310.09129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Marginal and Conditional Divergences between Decomposable  Models with Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+L+K">Loong Kuan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+D+F">Daniel F. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Piatkowski%2C+N">Nico Piatkowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, Accepted at the IEEE International Conference on Data Mining (ICDM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The ability to compute the exact divergence between two high-dimensional
distributions is useful in many applications but doing so naively is
intractable. Computing the alpha-beta divergence -- a family of divergences
that includes the Kullback-Leibler divergence and Hellinger distance -- between
the joint distribution of two decomposable models, i.e chordal Markov networks,
can be done in time exponential in the treewidth of these models. However,
reducing the dissimilarity between two high-dimensional objects to a single
scalar value can be uninformative. Furthermore, in applications such as
supervised learning, the divergence over a conditional distribution might be of
more interest. Therefore, we propose an approach to compute the exact
alpha-beta divergence between any marginal or conditional distribution of two
decomposable models. Doing so tractably is non-trivial as we need to decompose
the divergence between these distributions and therefore, require a
decomposition over the marginal and conditional distributions of these models.
Consequently, we provide such a decomposition and also extend existing work to
compute the marginal and conditional alpha-beta divergence between these
decompositions. We then show how our method can be used to analyze
distributional changes by first applying it to a benchmark image dataset.
Finally, based on our framework, we propose a novel way to quantify the error
in contemporary superconducting quantum computers. Code for all experiments is
available at: https://lklee.dev/pub/2023-icdm/code
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09130" title="Abstract">arXiv:2310.09130</a> [<a href="/pdf/2310.09130" title="Download PDF">pdf</a>, <a href="/format/2310.09130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split-and-Denoise: Protect large language model inference with local  differential privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+P">Peihua Mai</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Ran Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Youjia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yan Pang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Large Language Models (LLMs) shows powerful capability in natural language
understanding by capturing hidden semantics in vector space. This process
enriches the value of the text embeddings for various downstream tasks, thereby
fostering the Embedding-as-a-Service (EaaS) business model. However, the direct
transmission of text to servers poses a largely unaddressed risk of privacy
leakage. To mitigate this issue, we introduce Split-N-Denoise (SnD), an
innovative framework that split the model to execute the token embedding layer
on the client side at minimal computational cost. This allows the client to
introduce noise prior to transmitting the embeddings to the server, and
subsequently receive and denoise the perturbed output embeddings for downstream
tasks. Our approach is designed for the inference stage of LLMs and requires no
modifications to the model parameters. Extensive experiments demonstrate SnD's
effectiveness in optimizing the privacy-utility tradeoff across various LLM
architectures and diverse downstream tasks. The results reveal a significant
performance improvement under the same privacy budget compared to the baseline,
offering clients a privacy-preserving solution for local privacy protection.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09135" title="Abstract">arXiv:2310.09135</a> [<a href="/pdf/2310.09135" title="Download PDF">pdf</a>, <a href="/format/2310.09135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework  for Cross-Domain Zero-Shot Slot Filling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In task-oriented dialogue scenarios, cross-domain zero-shot slot filling
plays a vital role in leveraging source domain knowledge to learn a model with
high generalization ability in unknown target domain where annotated data is
unavailable. However, the existing state-of-the-art zero-shot slot filling
methods have limited generalization ability in target domain, they only show
effective knowledge transfer on seen slots and perform poorly on unseen slots.
To alleviate this issue, we present a novel Hierarchical Contrastive Learning
Framework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse-
to fine-grained contrastive learning based on Gaussian-distributed embedding to
learn the generalized deep semantic relations between utterance-tokens, by
optimizing inter- and intra-token distribution distance. This encourages HiCL
to generalize to the slot types unseen at training phase. Furthermore, we
present a new iterative label set semantics inference method to unbiasedly and
separately evaluate the performance of unseen slot types which entangled with
their counterparts (i.e., seen slot types) in the previous zero-shot slot
filling evaluation methods. The extensive empirical experiments on four
datasets demonstrate that the proposed method achieves comparable or even
better performance than the current state-of-the-art zero-shot slot filling
approaches.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09136" title="Abstract">arXiv:2310.09136</a> [<a href="/pdf/2310.09136" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocCert: Nostrification, Document Verification and Authenticity  Blockchain Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aldwairi%2C+M">Monther Aldwairi</a>, 
<a href="/search/cs?searchtype=author&query=Badra%2C+M">Mohamad Badra</a>, 
<a href="/search/cs?searchtype=author&query=Borghol%2C+R">Rouba Borghol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The Fifth International Conference on Blockchain Computing and Applications (BCCA 2023), held in Conjunction with Kuwait Fintech and Blockchain Summit 2023, 24,26 Oct 2023, Kuwait City, Kuwait
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Many institutions and organizations require nostrification and verification
of qualification as a prerequisite for hiring. The idea is to recognize the
authenticity of a copy or digital document issued by an institution in a
foreign country and detect forgeries. Certificates, financial records, health
records, official papers and others are often required to be attested from
multiple entities in distinct locations. However, in this digital era where
most applications happen online, and document copies are uploaded, the
traditional signature and seal methods are obsolete. In a matter of minutes and
with a simple photo editor, a certificate or document copy may be plagiarized
or forged. Blockchain technology offers a decentralized approach to record and
verify transactions without the need for huge infrastructure investment. In
this paper, we propose a blockchain based nostrification system, where awarding
institutions generate a digital certificate, store in a public but permissioned
blockchain, where students and other stakeholders may verify. We present a
thorough discussion and formal evaluation of the proposed system.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09137" title="Abstract">arXiv:2310.09137</a> [<a href="/pdf/2310.09137" title="Download PDF">pdf</a>, <a href="/format/2310.09137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Performance of Serverless Edge Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michalke%2C+M">Marc Michalke</a>, 
<a href="/search/cs?searchtype=author&query=Carpio%2C+F">Francisco Carpio</a>, 
<a href="/search/cs?searchtype=author&query=Jukan%2C+A">Admela Jukan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Current serverless solutions are primarily designed to run on cloud centric
environments. While bringing these solutions to the edge is its further
evolution, it introduces new challenges, due to resource constraints, different
CPU architectures, network topology and latency. Specifically, when clustering
devices at the edge, inter-node latency plays an important role. In this paper,
we experimentally examine the impact that latency has on scalablity by
measuring the throughput of distributed serverless applications. We deploy
Knative over a Kubernetes cluster of nodes and emulate latencies between them
to compare the performance of serverless functions when deployed over
centralized versus distributed computing sites. The results show how scaling
over edge achieves half the throughput as compared to a centralized deployment
in the cloud when the processing times are low, but more than two thirds the
improved performance of cloud with increased processing delays.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09139" title="Abstract">arXiv:2310.09139</a> [<a href="/pdf/2310.09139" title="Download PDF">pdf</a>, <a href="/format/2310.09139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Consensus Game: Language Model Generation via Equilibrium Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacob%2C+A+P">Athul Paul Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Gabriele Farina</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">When applied to question answering and other text generation tasks, language
models (LMs) may be queried generatively (by sampling answers from their output
distribution) or discriminatively (by using them to score or rank a set of
candidate outputs). These procedures sometimes yield very different
predictions. How do we reconcile mutually incompatible scoring procedures to
obtain coherent LM predictions? We introduce a new, a training-free,
game-theoretic procedure for language model decoding. Our approach casts
language model decoding as a regularized imperfect-information sequential
signaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks
to communicate an abstract correctness parameter using natural language
sentences to a DISCRIMINATOR. We develop computational procedures for finding
approximate equilibria of this game, resulting in a decoding algorithm we call
EQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading
comprehension, commonsense reasoning, mathematical problem-solving, and
dialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,
improves performance over existing LM decoding procedures - on multiple
benchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B
outperforms the much larger LLaMA-65B and PaLM-540B models. These results
highlight the promise of game-theoretic tools for addressing fundamental
challenges of truthfulness and consistency in LMs.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09141" title="Abstract">arXiv:2310.09141</a> [<a href="/pdf/2310.09141" title="Download PDF">pdf</a>, <a href="/ps/2310.09141" title="Download PostScript">ps</a>, <a href="/format/2310.09141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PuoBERTa: Training and evaluation of a curated language model for  Setswana
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marivate%2C+V">Vukosi Marivate</a>, 
<a href="/search/cs?searchtype=author&query=Mots%27Oehli%2C+M">Moseli Mots&#x27;Oehli</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+V">Valencia Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Lastrucci%2C+R">Richard Lastrucci</a>, 
<a href="/search/cs?searchtype=author&query=Dzingirai%2C+I">Isheanesu Dzingirai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Natural language processing (NLP) has made significant progress for
well-resourced languages such as English but lagged behind for low-resource
languages like Setswana. This paper addresses this gap by presenting PuoBERTa,
a customised masked language model trained specifically for Setswana. We cover
how we collected, curated, and prepared diverse monolingual texts to generate a
high-quality corpus for PuoBERTa's training. Building upon previous efforts in
creating monolingual resources for Setswana, we evaluated PuoBERTa across
several NLP tasks, including part-of-speech (POS) tagging, named entity
recognition (NER), and news categorisation. Additionally, we introduced a new
Setswana news categorisation dataset and provided the initial benchmarks using
PuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP
capabilities for understudied languages like Setswana and paves the way for
future research directions.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09143" title="Abstract">arXiv:2310.09143</a> [<a href="/pdf/2310.09143" title="Download PDF">pdf</a>, <a href="/format/2310.09143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intrinsic Integrity-Driven Rating Model for a Sustainable Reputation  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">H. Wen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">T. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+D">D. Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages,13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In the era of digital markets, the challenge for consumers is discerning
quality amidst information asymmetry. While traditional markets use brand
mechanisms to address this issue, transferring such systems to internet-based
P2P markets, where misleading practices like fake ratings are rampant, remains
challenging. Current internet platforms strive to counter this through
verification algorithms, but these efforts find themselves in a continuous
tug-of-war with counterfeit actions.
<br />Exploiting the transparency, immutability, and traceability of blockchain
technology, this paper introduces a robust reputation voting system grounded in
it. Unlike existing blockchain-based reputation systems, our model harnesses an
intrinsically economically incentivized approach to bolster agent integrity. We
optimize this model to mirror real-world user behavior, preserving the
reputation system's foundational sustainability. Through Monte-Carlo
simulations, using both uniform and power-law distributions enabled by an
innovative inverse transform method, we traverse a broad parameter landscape,
replicating real-world complexity. The findings underscore the promise of a
sustainable, transparent, and formidable reputation mechanism. Given its
structure, our framework can potentially function as a universal, sustainable
oracle for offchain-onchain bridging, aiding entities in perpetually
cultivating their reputation. Future integration with technologies like Ring
Signature and Zero Knowledge Proof could amplify the system's privacy facets,
rendering it particularly influential in the ever-evolving digital domain.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09144" title="Abstract">arXiv:2310.09144</a> [<a href="/pdf/2310.09144" title="Download PDF">pdf</a>, <a href="/format/2310.09144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goodhart&#x27;s Law in Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karwowski%2C+J">Jacek Karwowski</a>, 
<a href="/search/cs?searchtype=author&query=Hayman%2C+O">Oliver Hayman</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xingjian Bai</a>, 
<a href="/search/cs?searchtype=author&query=Kiendlhofer%2C+K">Klaus Kiendlhofer</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+C">Charlie Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Skalse%2C+J">Joar Skalse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Implementing a reward function that perfectly captures a complex task in the
real world is impractical. As a result, it is often appropriate to think of the
reward function as a proxy for the true objective rather than as its
definition. We study this phenomenon through the lens of Goodhart's law, which
predicts that increasing optimisation of an imperfect proxy beyond some
critical point decreases performance on the true objective. First, we propose a
way to quantify the magnitude of this effect and show empirically that
optimising an imperfect proxy reward often leads to the behaviour predicted by
Goodhart's law for a wide range of environments and reward functions. We then
provide a geometric explanation for why Goodhart's law occurs in Markov
decision processes. We use these theoretical insights to propose an optimal
early stopping method that provably avoids the aforementioned pitfall and
derive theoretical regret bounds for this method. Moreover, we derive a
training method that maximises worst-case reward, for the setting where there
is uncertainty about the true reward function. Finally, we evaluate our early
stopping method experimentally. Our results support a foundation for a
theoretically-principled study of reinforcement learning under reward
misspecification.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09145" title="Abstract">arXiv:2310.09145</a> [<a href="/pdf/2310.09145" title="Download PDF">pdf</a>, <a href="/format/2310.09145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lincoln AI Computing Survey (LAICS) Update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reuther%2C+A">Albert Reuther</a>, 
<a href="/search/cs?searchtype=author&query=Michaleas%2C+P">Peter Michaleas</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M">Michael Jones</a>, 
<a href="/search/cs?searchtype=author&query=Gadepally%2C+V">Vijay Gadepally</a>, 
<a href="/search/cs?searchtype=author&query=Samsi%2C+S">Siddharth Samsi</a>, 
<a href="/search/cs?searchtype=author&query=Kepner%2C+J">Jeremy Kepner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures, 2023 IEEE High Performance Extreme Computing (HPEC) conference, September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">This paper is an update of the survey of AI accelerators and processors from
past four years, which is now called the Lincoln AI Computing Survey - LAICS
(pronounced "lace"). As in past years, this paper collects and summarizes the
current commercial accelerators that have been publicly announced with peak
performance and peak power consumption numbers. The performance and power
values are plotted on a scatter graph, and a number of dimensions and
observations from the trends on this plot are again discussed and analyzed.
Market segments are highlighted on the scatter plot, and zoomed plots of each
segment are also included. Finally, a brief description of each of the new
accelerators that have been added in the survey this year is included.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09147" title="Abstract">arXiv:2310.09147</a> [<a href="/pdf/2310.09147" title="Download PDF">pdf</a>, <a href="/format/2310.09147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Sparse Spatial Relation in Graph Inference for Text-Based VQA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Text-based visual question answering (TextVQA) faces the significant
challenge of avoiding redundant relational inference. To be specific, a large
number of detected objects and optical character recognition (OCR) tokens
result in rich visual relationships. Existing works take all visual
relationships into account for answer prediction. However, there are three
observations: (1) a single subject in the images can be easily detected as
multiple objects with distinct bounding boxes (considered repetitive objects).
The associations between these repetitive objects are superfluous for answer
reasoning; (2) two spatially distant OCR tokens detected in the image
frequently have weak semantic dependencies for answer reasoning; and (3) the
co-existence of nearby objects and tokens may be indicative of important visual
cues for predicting answers. Rather than utilizing all of them for answer
prediction, we make an effort to identify the most important connections or
eliminate redundant ones. We propose a sparse spatial graph network (SSGN) that
introduces a spatially aware relation pruning technique to this task. As
spatial factors for relation measurement, we employ spatial distance, geometric
dimension, overlap area, and DIoU for spatially aware pruning. We consider
three visual relationships for graph learning: object-object, OCR-OCR tokens,
and object-OCR token relationships. SSGN is a progressive graph learning
architecture that verifies the pivotal relations in the correlated object-token
sparse graph, and then in the respective object-based sparse graph and
token-based sparse graph. Experiment results on TextVQA and ST-VQA datasets
demonstrate that SSGN achieves promising performances. And some visualization
results further demonstrate the interpretability of our method.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09151" title="Abstract">arXiv:2310.09151</a> [<a href="/pdf/2310.09151" title="Download PDF">pdf</a>, <a href="/format/2310.09151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BibRank: Automatic Keyphrase Extraction Platform Using~Metadata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldallal%2C+A">Abdelrhman Eldallal</a>, 
<a href="/search/cs?searchtype=author&query=Barbu%2C+E">Eduard Barbu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages , 4 figures, 8 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information 2023, 14(10), 549
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic Keyphrase Extraction involves identifying essential phrases in a
document. These keyphrases are crucial in various tasks such as document
classification, clustering, recommendation, indexing, searching, summarization,
and text simplification. This paper introduces a platform that integrates
keyphrase datasets and facilitates the evaluation of keyphrase extraction
algorithms. The platform includes BibRank, an automatic keyphrase extraction
algorithm that leverages a rich dataset obtained by parsing bibliographic data
in BibTeX format. BibRank combines innovative weighting techniques with
positional, statistical, and word co-occurrence information to extract
keyphrases from documents. The platform proves valuable for researchers and
developers seeking to enhance their keyphrase extraction algorithms and advance
the field of natural language processing.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09158" title="Abstract">arXiv:2310.09158</a> [<a href="/pdf/2310.09158" title="Download PDF">pdf</a>, <a href="/format/2310.09158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning To Teach Large Language Models Logical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Meiqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yubo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large language models (LLMs) have gained enormous attention from both
academia and industry, due to their exceptional ability in language generation
and extremely powerful generalization. However, current LLMs still output
unreliable content in practical reasoning tasks due to their inherent issues
(e.g., hallucination). To better disentangle this problem, in this paper, we
conduct an in-depth investigation to systematically explore the capability of
LLMs in logical reasoning. More in detail, we first investigate the deficiency
of LLMs in logical reasoning on different tasks, including event relation
extraction and deductive reasoning. Our study demonstrates that LLMs are not
good reasoners in solving tasks with rigorous reasoning and will produce
counterfactual answers, which require us to iteratively refine. Therefore, we
comprehensively explore different strategies to endow LLMs with logical
reasoning ability, and thus enable them to generate more logically consistent
answers across different scenarios. Based on our approach, we also contribute a
synthesized dataset (LLM-LR) involving multi-hop reasoning for evaluation and
pre-training. Extensive quantitative and qualitative analyses on different
tasks also validate the effectiveness and necessity of teaching LLMs with logic
and provide insights for solving practical tasks with LLMs in future work.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09162" title="Abstract">arXiv:2310.09162</a> [<a href="/pdf/2310.09162" title="Download PDF">pdf</a>, <a href="/format/2310.09162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Machine Learning in Climate Change and Sustainability: a Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nammouchi%2C+A">Amal Nammouchi</a>, 
<a href="/search/cs?searchtype=author&query=Kassler%2C+A">Andreas Kassler</a>, 
<a href="/search/cs?searchtype=author&query=Theorachis%2C+A">Andreas Theorachis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages Accepted for publication in AAAI proceedings (AAAI Fall symposium 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Climate change and its impact on global sustainability are critical
challenges, demanding innovative solutions that combine cutting-edge
technologies and scientific insights. Quantum machine learning (QML) has
emerged as a promising paradigm that harnesses the power of quantum computing
to address complex problems in various domains including climate change and
sustainability. In this work, we survey existing literature that applies
quantum machine learning to solve climate change and sustainability-related
problems. We review promising QML methodologies that have the potential to
accelerate decarbonization including energy systems, climate data forecasting,
climate monitoring, and hazardous events predictions. We discuss the challenges
and current limitations of quantum machine learning approaches and provide an
overview of potential opportunities and future work to leverage QML-based
methods in the important area of climate change research.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09163" title="Abstract">arXiv:2310.09163</a> [<a href="/pdf/2310.09163" title="Download PDF">pdf</a>, <a href="/format/2310.09163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly-Learned Exit and Inference for a Dynamic Neural Network :  JEI-DNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Regol%2C+F">Florence Regol</a>, 
<a href="/search/cs?searchtype=author&query=Chataoui%2C+J">Joud Chataoui</a>, 
<a href="/search/cs?searchtype=author&query=Coates%2C+M">Mark Coates</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Large pretrained models, coupled with fine-tuning, are slowly becoming
established as the dominant architecture in machine learning. Even though these
models offer impressive performance, their practical application is often
limited by the prohibitive amount of resources required for every inference.
Early-exiting dynamic neural networks (EDNN) circumvent this issue by allowing
a model to make some of its predictions from intermediate layers (i.e.,
early-exit). Training an EDNN architecture is challenging as it consists of two
intertwined components: the gating mechanism (GM) that controls early-exiting
decisions and the intermediate inference modules (IMs) that perform inference
from intermediate representations. As a result, most existing approaches rely
on thresholding confidence metrics for the gating mechanism and strive to
improve the underlying backbone network and the inference modules. Although
successful, this approach has two fundamental shortcomings: 1) the GMs and the
IMs are decoupled during training, leading to a train-test mismatch; and 2) the
thresholding gating mechanism introduces a positive bias into the predictive
probabilities, making it difficult to readily extract uncertainty information.
We propose a novel architecture that connects these two modules. This leads to
significant performance improvements on classification datasets and enables
better uncertainty characterization capabilities.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09165" title="Abstract">arXiv:2310.09165</a> [<a href="/pdf/2310.09165" title="Download PDF">pdf</a>, <a href="/format/2310.09165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust UAV Tracking in GNSS-Denied Environments: A Multi-LiDAR  Multi-UAV Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Catalano%2C+I">Iacopo Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xianjia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Queralta%2C+J+P">Jorge Pena Queralta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With the increasing prevalence of drones in various industries, the
navigation and tracking of unmanned aerial vehicles (UAVs) in challenging
environments, particularly GNSS-denied areas, have become crucial concerns. To
address this need, we present a novel multi-LiDAR dataset specifically designed
for UAV tracking. Our dataset includes data from a spinning LiDAR, two
solid-state LiDARs with different Field of View (FoV) and scan patterns, and an
RGB-D camera. This diverse sensor suite allows for research on new challenges
in the field, including limited FoV adaptability and multi-modality data
processing.
<br />The dataset facilitates the evaluation of existing algorithms and the
development of new ones, paving the way for advances in UAV tracking
techniques. Notably, we provide data in both indoor and outdoor environments.
We also consider variable UAV sizes, from micro-aerial vehicles to more
standard commercial UAV platforms. The outdoor trajectories are selected with
close proximity to buildings, targeting research in UAV detection in urban
areas, e.g., within counter-UAV systems or docking for UAV logistics.
<br />In addition to the dataset, we provide a baseline comparison with recent
LiDAR-based UAV tracking algorithms, benchmarking the performance with
different sensors, UAVs, and algorithms. Importantly, our dataset shows that
current methods have shortcomings and are unable to track UAVs consistently
across different scenarios.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09166" title="Abstract">arXiv:2310.09166</a> [<a href="/pdf/2310.09166" title="Download PDF">pdf</a>, <a href="/format/2310.09166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Natural Language Understanding Model to Characterize Cable  News Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benson%2C+S+P">Seth P. Benson</a>, 
<a href="/search/cs?searchtype=author&query=Cruickshank%2C+I+J">Iain J. Cruickshank</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Media bias has been extensively studied by both social and computational
sciences. However, current work still has a large reliance on human input and
subjective assessment to label biases. This is especially true for cable news
research. To address these issues, we develop an unsupervised machine learning
method to characterize the bias of cable news programs without any human input.
This method relies on the analysis of what topics are mentioned through Named
Entity Recognition and how those topics are discussed through Stance Analysis
in order to cluster programs with similar biases together. Applying our method
to 2020 cable news transcripts, we find that program clusters are consistent
over time and roughly correspond to the cable news network of the program. This
method reveals the potential for future tools to objectively assess media bias
and characterize unfamiliar media environments.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09168" title="Abstract">arXiv:2310.09168</a> [<a href="/pdf/2310.09168" title="Download PDF">pdf</a>, <a href="/format/2310.09168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through  Active Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Main Conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction-tuning can be substantially optimized through enhanced diversity,
resulting in models capable of handling a broader spectrum of tasks. However,
existing data employed for such tuning often exhibit an inadequate coverage of
individual domains, limiting the scope for nuanced comprehension and
interactions within these areas. To address this deficiency, we propose
Explore-Instruct, a novel approach to enhance the data coverage to be used in
domain-specific instruction-tuning through active exploration via Large
Language Models (LLMs). Built upon representative domain use cases,
Explore-Instruct explores a multitude of variations or possibilities by
implementing a search algorithm to obtain diversified and domain-focused
instruction-tuning data. Our data-centric analysis validates the effectiveness
of this proposed approach in improving domain-specific instruction coverage.
Moreover, our model's performance demonstrates considerable advancements over
multiple baselines, including those utilizing domain-specific data enhancement.
Our findings offer a promising opportunity to improve instruction coverage,
especially in domain-specific contexts, thereby advancing the development of
adaptable language models. Our code, model weights, and data are public at
\url{https://github.com/fanqiwan/Explore-Instruct}.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09170" title="Abstract">arXiv:2310.09170</a> [<a href="/pdf/2310.09170" title="Download PDF">pdf</a>, <a href="/format/2310.09170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mnmDTW: An extension to Dynamic Time Warping for Camera-based Movement  Error Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dill%2C+S">Sebastian Dill</a>, 
<a href="/search/cs?searchtype=author&query=Rohr%2C+M">Maurice Rohr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster Prague 2023 Conference, 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this proof of concept, we use Computer Vision (CV) methods to extract pose
information out of exercise videos. We then employ a modified version of
Dynamic Time Warping (DTW) to calculate the deviation from a gold standard
execution of the exercise. Specifically, we calculate the distance between each
body part individually to get a more precise measure for exercise accuracy. We
can show that exercise mistakes are clearly visible, identifiable and
localizable through this metric.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09177" title="Abstract">arXiv:2310.09177</a> [<a href="/pdf/2310.09177" title="Download PDF">pdf</a>, <a href="/ps/2310.09177" title="Download PostScript">ps</a>, <a href="/format/2310.09177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis on IoT Communication Protocols for Future  Internet Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mahbubul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Jamil%2C+H+M+M">Hossain Md. Mubashshir Jamil</a>, 
<a href="/search/cs?searchtype=author&query=Pranto%2C+S+A">Samiul Ahsan Pranto</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R+K">Rupak Kumar Das</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+A">Al Amin</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Arshia Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">With the emergence of 5G, the Internet of Things (IoT) will bring about the
next industrial revolution in the name of Industry 4.0. The communication
aspect of IoT devices is one of the most important factors in choosing the
right device for the right usage. So far, the IoT physical layer communication
challenges have been met with various communications protocols that provide
varying strengths and weaknesses. And most of them are wireless protocols due
to the sheer number of device requirements for IoT. In this paper, we summarize
the network architectures of some of the most popular IoT wireless
communications protocols. We also present them side by side and provide a
comparative analysis revolving around some key features, including power
consumption, coverage, data rate, security, cost, and Quality of Service (QoS).
This comparative study shows that LTE-based protocols like NB-IoT and LTE-M can
offer better QoS and robustness, while the Industrial, Scientific, and Medical
(ISM) Band based protocols like LoRa, Sigfox, and Z-wave claim their place in
usage where lower power consumption and lesser device complexity are desired.
Based on their respective strengths and weaknesses, the study also presents an
application perspective of the suitability of each protocol in a certain type
of scenario and addresses some open issues that need to be researched in the
future. Thus, this study can assist in the decision making regarding choosing
the most suitable protocol for a certain field.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09179" title="Abstract">arXiv:2310.09179</a> [<a href="/pdf/2310.09179" title="Download PDF">pdf</a>, <a href="/ps/2310.09179" title="Download PostScript">ps</a>, <a href="/format/2310.09179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> B-series for SDEs with application to exponential integrators for  non-autonomous semi-linear problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arara%2C+A+A">Alemayehu Adugna Arara</a>, 
<a href="/search/math?searchtype=author&query=Debrabant%2C+K">Kristian Debrabant</a>, 
<a href="/search/math?searchtype=author&query=Kv%C3%A6rn%C3%B8%2C+A">Anne Kv&#xe6;rn&#xf8;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">In this paper a set of previous general results for the development of
B--series for a broad class of stochastic differential equations has been
collected. The applicability of these results is demonstrated by the derivation
of B--series for non-autonomous semi-linear SDEs and exponential Runge-Kutta
methods applied to this class of SDEs, which is a significant generalization of
existing theory on such methods.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09180" title="Abstract">arXiv:2310.09180</a> [<a href="/pdf/2310.09180" title="Download PDF">pdf</a>, <a href="/format/2310.09180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUPG-stabilized stabilization-free VEM: a numerical investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Borio%2C+A">Andrea Borio</a>, 
<a href="/search/math?searchtype=author&query=Busetto%2C+M">Martina Busetto</a>, 
<a href="/search/math?searchtype=author&query=Marcon%2C+F">Francesca Marcon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We numerically investigate the possibility of defining stabilization-free
Virtual Element (VEM) discretizations of advection-diffusion problems in the
advection-dominated regime. To this end, we consider a SUPG stabilized
formulation of the scheme. Numerical tests comparing the proposed method with
standard VEM show that the lack of an additional arbitrary stabilization term,
typical of VEM schemes, that adds artificial diffusion to the discrete
solution, allows to better approximate boundary layers, in particular in the
case of a low order scheme.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09183" title="Abstract">arXiv:2310.09183</a> [<a href="/pdf/2310.09183" title="Download PDF">pdf</a>, <a href="/format/2310.09183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIOR: Personalized Prior for Reactivating the Information Overlooked in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Mingjia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shudong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiangcheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Classical federated learning (FL) enables training machine learning models
without sharing data for privacy preservation, but heterogeneous data
characteristic degrades the performance of the localized model. Personalized FL
(PFL) addresses this by synthesizing personalized models from a global model
via training on local data. Such a global model may overlook the specific
information that the clients have been sampled. In this paper, we propose a
novel scheme to inject personalized prior knowledge into the global model in
each client, which attempts to mitigate the introduced incomplete information
problem in PFL. At the heart of our proposed approach is a framework, the PFL
with Bregman Divergence (pFedBreD), decoupling the personalized prior from the
local objective function regularized by Bregman divergence for greater
adaptability in personalized scenarios. We also relax the mirror descent (RMD)
to extract the prior explicitly to provide optional strategies. Additionally,
our pFedBreD is backed up by a convergence analysis. Sufficient experiments
demonstrate that our method reaches the state-of-the-art performances on 5
datasets and outperforms other methods by up to 3.5% across 8 benchmarks.
Extensive analyses verify the robustness and necessity of proposed designs.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09192" title="Abstract">arXiv:2310.09192</a> [<a href="/pdf/2310.09192" title="Download PDF">pdf</a>, <a href="/format/2310.09192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Graph Distillation See Like Vision Dataset Counterpart?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Beining Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+C">Cheng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training on large-scale graphs has achieved remarkable results in graph
representation learning, but its cost and storage have attracted increasing
concerns. Existing graph condensation methods primarily focus on optimizing the
feature matrices of condensed graphs while overlooking the impact of the
structure information from the original graphs. To investigate the impact of
the structure information, we conduct analysis from the spectral domain and
empirically identify substantial Laplacian Energy Distribution (LED) shifts in
previous works. Such shifts lead to poor performance in cross-architecture
generalization and specific tasks, including anomaly detection and link
prediction. In this paper, we propose a novel Structure-broadcasting Graph
Dataset Distillation (SGDD) scheme for broadcasting the original structure
information to the generation of the synthetic one, which explicitly prevents
overlooking the original structure information. Theoretically, the synthetic
graphs by SGDD are expected to have smaller LED shifts than previous works,
leading to superior performance in both cross-architecture settings and
specific tasks. We validate the proposed SGDD across 9 datasets and achieve
state-of-the-art results on all of them: for example, on the YelpChi dataset,
our approach maintains 98.6% test accuracy of training on the original graph
dataset with 1,000 times saving on the scale of the graph. Moreover, we
empirically evaluate there exist 17.6% ~ 31.4% reductions in LED shift crossing
9 datasets. Extensive experiments and analysis verify the effectiveness and
necessity of the proposed designs. The code is available in the GitHub
repository: https://github.com/RingBDStack/SGDD.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09193" title="Abstract">arXiv:2310.09193</a> [<a href="/pdf/2310.09193" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tikuna: An Ethereum Blockchain Network Security Monitoring System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+A+G">Andres Gomez Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Sardy%2C+L+A">Loui Al Sardy</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+F+G">Francis Gomez Ramirez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures, submitted to ISPEC 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Blockchain security is becoming increasingly relevant in today's cyberspace
as it extends its influence in many industries. This paper focuses on
protecting the lowest level layer in the blockchain, particularly the P2P
network that allows the nodes to communicate and share information. The P2P
network layer may be vulnerable to several families of attacks, such as
Distributed Denial of Service (DDoS), eclipse attacks, or Sybil attacks. This
layer is prone to threats inherited from traditional P2P networks, and it must
be analyzed and understood by collecting data and extracting insights from the
network behavior to reduce those risks. We introduce Tikuna, an open-source
tool for monitoring and detecting potential attacks on the Ethereum blockchain
P2P network, at an early stage. Tikuna employs an unsupervised Long Short-Term
Memory (LSTM) method based on Recurrent Neural Network (RNN) to detect attacks
and alert users. Empirical results indicate that the proposed approach
significantly improves detection performance, with the ability to detect and
classify attacks, including eclipse attacks, Covert Flash attacks, and others
that target the Ethereum blockchain P2P network layer, with high accuracy. Our
research findings demonstrate that Tikuna is a valuable security tool for
assisting operators to efficiently monitor and safeguard the status of Ethereum
validators and the wider P2P network
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09194" title="Abstract">arXiv:2310.09194</a> [<a href="/pdf/2310.09194" title="Download PDF">pdf</a>, <a href="/format/2310.09194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational autoencoder with weighted samples for high-dimensional  non-parametric adaptive importance sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demange-Chryst%2C+J">Julien Demange-Chryst</a>, 
<a href="/search/cs?searchtype=author&query=Bachoc%2C+F">Fran&#xe7;ois Bachoc</a>, 
<a href="/search/cs?searchtype=author&query=Morio%2C+J">J&#xe9;r&#xf4;me Morio</a>, 
<a href="/search/cs?searchtype=author&query=Krauth%2C+T">Timoth&#xe9; Krauth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Probability density function estimation with weighted samples is the main
foundation of all adaptive importance sampling algorithms. Classically, a
target distribution is approximated either by a non-parametric model or within
a parametric family. However, these models suffer from the curse of
dimensionality or from their lack of flexibility. In this contribution, we
suggest to use as the approximating model a distribution parameterised by a
variational autoencoder. We extend the existing framework to the case of
weighted samples by introducing a new objective function. The flexibility of
the obtained family of distributions makes it as expressive as a non-parametric
model, and despite the very high number of parameters to estimate, this family
is much more efficient in high dimension than the classical Gaussian or
Gaussian mixture families. Moreover, in order to add flexibility to the model
and to be able to learn multimodal distributions, we consider a learnable prior
distribution for the variational autoencoder latent variables. We also
introduce a new pre-training procedure for the variational autoencoder to find
good starting weights of the neural networks to prevent as much as possible the
posterior collapse phenomenon to happen. At last, we explicit how the resulting
distribution can be combined with importance sampling, and we exploit the
proposed procedure in existing adaptive importance sampling algorithms to draw
points from a target distribution and to estimate a rare event probability in
high dimension on two multimodal problems.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09195" title="Abstract">arXiv:2310.09195</a> [<a href="/pdf/2310.09195" title="Download PDF">pdf</a>, <a href="/format/2310.09195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMSwarmX: Safe Swarm Coordination in CompleX Environments via Implicit  Non-Convex Decomposition of the Obstacle-Free Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adajania%2C+V+K">Vivek K. Adajania</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Arun Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Quadrotor motion planning in complex environments leverage the concept of
safe flight corridor (SFC) to facilitate static obstacle avoidance. Typically,
SFCs are constructed through convex decomposition of the environment's free
space into cuboids, convex polyhedra, or spheres. However, when dealing with a
quadrotor swarm, such SFCs can be overly conservative, substantially limiting
the available free space for quadrotors to coordinate. This paper presents an
Alternating Minimization-based approach that does not require building a
conservative free-space approximation. Instead, both static and dynamic
collision constraints are treated in a unified manner. Dynamic collisions are
handled based on shared position trajectories of the quadrotors. Static
obstacle avoidance is coupled with distance queries from the Octomap, providing
an implicit non-convex decomposition of free space. As a result, our approach
is scalable to arbitrary complex environments. Through extensive comparisons in
simulation, we demonstrate a $60\%$ improvement in success rate, an average
$1.8\times$ reduction in mission completion time, and an average $23\times$
reduction in per-agent computation time compared to SFC-based approaches. We
also experimentally validated our approach using a Crazyflie quadrotor swarm of
up to 12 quadrotors in obstacle-rich environments. The code, supplementary
materials, and videos are released for reference.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09196" title="Abstract">arXiv:2310.09196</a> [<a href="/pdf/2310.09196" title="Download PDF">pdf</a>, <a href="/format/2310.09196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 4-approximation algorithm for min max correlation clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heidrich%2C+H">Holger Heidrich</a>, 
<a href="/search/cs?searchtype=author&query=Irmai%2C+J">Jannik Irmai</a>, 
<a href="/search/cs?searchtype=author&query=Andres%2C+B">Bjoern Andres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a lower bounding technique for the min max correlation
clustering problem and, based on this technique, a combinatorial
4-approximation algorithm for complete graphs. This improves upon the previous
best known approximation guarantees of 5, using a linear program formulation
(Kalhan et al., 2019), and 4, for a combinatorial algorithm (Davies et al.,
2023). We extend this algorithm by a greedy joining heuristic and show
empirically that it improves the state of the art in solution quality and
runtime on several benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09199" title="Abstract">arXiv:2310.09199</a> [<a href="/pdf/2310.09199" title="Download PDF">pdf</a>, <a href="/format/2310.09199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaLI-3 Vision Language Models: Smaller, Faster, Stronger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+A">Alexander Kolesnikov</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Voigtlaender%2C+P">Paul Voigtlaender</a>, 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+B">Basil Mustafa</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+S">Sebastian Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Alabdulmohsin%2C+I">Ibrahim Alabdulmohsin</a>, 
<a href="/search/cs?searchtype=author&query=Padlewski%2C+P">Piotr Padlewski</a>, 
<a href="/search/cs?searchtype=author&query=Salz%2C+D">Daniel Salz</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Vlasic%2C+D">Daniel Vlasic</a>, 
<a href="/search/cs?searchtype=author&query=Pavetic%2C+F">Filip Pavetic</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+K">Keran Rong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianli Yu</a>, 
<a href="/search/cs?searchtype=author&query=Keysers%2C+D">Daniel Keysers</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Soricut%2C+R">Radu Soricut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents PaLI-3, a smaller, faster, and stronger vision language
model (VLM) that compares favorably to similar models that are 10x larger. As
part of arriving at this strong performance, we compare Vision Transformer
(ViT) models pretrained using classification objectives to contrastively
(SigLIP) pretrained ones. We find that, while slightly underperforming on
standard image classification benchmarks, SigLIP-based PaLI shows superior
performance across various multimodal benchmarks, especially on localization
and visually-situated text understanding. We scale the SigLIP image encoder up
to 2 billion parameters, and achieves a new state-of-the-art on multilingual
cross-modal retrieval. We hope that PaLI-3, at only 5B parameters, rekindles
research on fundamental pieces of complex VLMs, and could fuel a new generation
of scaled-up models.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09201" title="Abstract">arXiv:2310.09201</a> [<a href="/pdf/2310.09201" title="Download PDF">pdf</a>, <a href="/format/2310.09201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FingerTac -- An Interchangeable and Wearable Tactile Sensor for the  Fingertips of Human and Robot Hands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sathe%2C+P">Prathamesh Sathe</a>, 
<a href="/search/cs?searchtype=author&query=Schmitz%2C+A">Alexander Schmitz</a>, 
<a href="/search/cs?searchtype=author&query=Funabashi%2C+S">Satoshi Funabashi</a>, 
<a href="/search/cs?searchtype=author&query=Tomo%2C+T+P">Tito Pradhono Tomo</a>, 
<a href="/search/cs?searchtype=author&query=Somlor%2C+S">Sophon Somlor</a>, 
<a href="/search/cs?searchtype=author&query=Shigeki%2C+S">Sugano Shigeki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Skill transfer from humans to robots is challenging. Presently, many
researchers focus on capturing only position or joint angle data from humans to
teach the robots. Even though this approach has yielded impressive results for
grasping applications, reconstructing motion for object handling or fine
manipulation from a human hand to a robot hand has been sparsely explored.
Humans use tactile feedback to adjust their motion to various objects, but
capturing and reproducing the applied forces is an open research question. In
this paper we introduce a wearable fingertip tactile sensor, which captures the
distributed 3-axis force vectors on the fingertip. The fingertip tactile sensor
is interchangeable between the human hand and the robot hand, meaning that it
can also be assembled to fit on a robot hand such as the Allegro hand. This
paper presents the structural aspects of the sensor as well as the methodology
and approach used to design, manufacture, and calibrate the sensor. The sensor
is able to measure forces accurately with a mean absolute error of 0.21, 0.16,
and 0.44 Newtons in X, Y, and Z directions, respectively.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09202" title="Abstract">arXiv:2310.09202</a> [<a href="/pdf/2310.09202" title="Download PDF">pdf</a>, <a href="/format/2310.09202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Condensation via Eigenbasis Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+D">Deyu Bo</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The increasing amount of graph data places requirements on the efficiency and
scalability of graph neural networks (GNNs), despite their effectiveness in
various graph-related applications. Recently, the emerging graph condensation
(GC) sheds light on reducing the computational cost of GNNs from a data
perspective. It aims to replace the real large graph with a significantly
smaller synthetic graph so that GNNs trained on both graphs exhibit comparable
performance. However, our empirical investigation reveals that existing GC
methods suffer from poor generalization, i.e., different GNNs trained on the
same synthetic graph have obvious performance gaps. What factors hinder the
generalization of GC and how can we mitigate it? To answer this question, we
commence with a detailed analysis and observe that GNNs will inject spectrum
bias into the synthetic graph, resulting in a distribution shift. To tackle
this issue, we propose eigenbasis matching for spectrum-free graph
condensation, named GCEM, which has two key steps: First, GCEM matches the
eigenbasis of the real and synthetic graphs, rather than the graph structure,
which eliminates the spectrum bias of GNNs. Subsequently, GCEM leverages the
spectrum of the real graph and the synthetic eigenbasis to construct the
synthetic graph, thereby preserving the essential structural information. We
theoretically demonstrate that the synthetic graph generated by GCEM maintains
the spectral similarity, i.e., total variation, of the real graph. Extensive
experiments conducted on five graph datasets verify that GCEM not only achieves
state-of-the-art performance over baselines but also significantly narrows the
performance gaps between different GNNs.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09203" title="Abstract">arXiv:2310.09203</a> [<a href="/pdf/2310.09203" title="Download PDF">pdf</a>, <a href="/format/2310.09203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiamAF: Learning Shared Information from ECG and PPG Signals for Robust  Atrial Fibrillation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Cheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+D+H">Duc H. Do</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Amit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+J">Randall J. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Atrial fibrillation (AF) is the most common type of cardiac arrhythmia. It is
associated with an increased risk of stroke, heart failure, and other
cardiovascular complications, but can be clinically silent. Passive AF
monitoring with wearables may help reduce adverse clinical outcomes related to
AF. Detecting AF in noisy wearable data poses a significant challenge, leading
to the emergence of various deep learning techniques. Previous deep learning
models learn from a single modality, either electrocardiogram (ECG) or
photoplethysmography (PPG) signals. However, deep learning models often
struggle to learn generalizable features and rely on features that are more
susceptible to corruption from noise, leading to sub-optimal performances in
certain scenarios, especially with low-quality signals. Given the increasing
availability of ECG and PPG signal pairs from wearables and bedside monitors,
we propose a new approach, SiamAF, leveraging a novel Siamese network
architecture and joint learning loss function to learn shared information from
both ECG and PPG signals. At inference time, the proposed model is able to
predict AF from either PPG or ECG and outperforms baseline methods on three
external test sets. It learns medically relevant features as a result of our
novel architecture design. The proposed model also achieves comparable
performance to traditional learning regimes while requiring much fewer training
labels, providing a potential approach to reduce future reliance on manual
labeling.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09204" title="Abstract">arXiv:2310.09204</a> [<a href="/pdf/2310.09204" title="Download PDF">pdf</a>, <a href="/format/2310.09204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary Element Methods for the Laplace Hypersingular Integral Equation  on Multiscreens: a two-level Substructuring Preconditioner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Averseng%2C+M">Martin Averseng</a>, 
<a href="/search/math?searchtype=author&query=Claeys%2C+X">Xavier Claeys</a>, 
<a href="/search/math?searchtype=author&query=Hiptmair%2C+R">Ralf Hiptmair</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a preconditioning method for the linear systems arising from the
boundary element discretization of the Laplace hypersingular equation on a
$2$-dimensional triangulated surface $\Gamma$ in $\mathbb{R}^3$. We allow
$\Gamma$ to belong to a large class of geometries that we call polygonal
multiscreens, which can be non-manifold. After introducing a new, simple
conforming Galerkin discretization, we analyze a substructuring
domain-decomposition preconditioner based on ideas originally developed for the
Finite Element Method. The surface $\Gamma$ is subdivided into non-overlapping
regions, and the application of the preconditioner is obtained via the solution
of the hypersingular equation on each patch, plus a coarse subspace correction.
We prove that the condition number of the preconditioned linear system grows
poly-logarithmically with $H/h$, the ratio of the coarse mesh and fine mesh
size, and our numerical results indicate that this bound is sharp. This
domain-decomposition algorithm therefore guarantees significant speedups for
iterative solvers, even when a large number of subdomains is used.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09210" title="Abstract">arXiv:2310.09210</a> [<a href="/pdf/2310.09210" title="Download PDF">pdf</a>, <a href="/format/2310.09210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization-Based Methods for Ordinal Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bunse%2C+M">Mirko Bunse</a>, 
<a href="/search/cs?searchtype=author&query=Moreo%2C+A">Alejandro Moreo</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+F">Fabrizio Sebastiani</a>, 
<a href="/search/cs?searchtype=author&query=Senz%2C+M">Martin Senz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Quantification, i.e., the task of training predictors of the class prevalence
values in sets of unlabeled data items, has received increased attention in
recent years. However, most quantification research has concentrated on
developing algorithms for binary and multiclass problems in which the classes
are not ordered. Here, we study the ordinal case, i.e., the case in which a
total order is defined on the set of n&gt;2 classes. We give three main
contributions to this field. First, we create and make available two datasets
for ordinal quantification (OQ) research that overcome the inadequacies of the
previously available ones. Second, we experimentally compare the most important
OQ algorithms proposed in the literature so far. To this end, we bring together
algorithms proposed by authors from very different research fields, such as
data mining and astrophysics, who were unaware of each others' developments.
Third, we propose a novel class of regularized OQ algorithms, which outperforms
existing algorithms in our experiments. The key to this gain in performance is
that our regularization prevents ordinally implausible estimates, assuming that
ordinal distributions tend to be smooth in practice. We informally verify this
assumption for several real-world applications.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09213" title="Abstract">arXiv:2310.09213</a> [<a href="/pdf/2310.09213" title="Download PDF">pdf</a>, <a href="/format/2310.09213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unseen Image Synthesis with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Ye Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Russakovsky%2C+O">Olga Russakovsky</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages including appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While the current trend in the generative field is scaling up towards larger
models and more training data for generalized domain representations, we go the
opposite direction in this work by synthesizing unseen domain images without
additional training. We do so via latent sampling and geometric optimization
using pre-trained and frozen Denoising Diffusion Probabilistic Models (DDPMs)
on single-domain datasets. Our key observation is that DDPMs pre-trained even
just on single-domain images are already equipped with sufficient
representation abilities to reconstruct arbitrary images from the inverted
latent encoding following bi-directional deterministic diffusion and denoising
trajectories. This motivates us to investigate the statistical and geometric
behaviors of the Out-Of-Distribution (OOD) samples from unseen image domains in
the latent spaces along the denoising chain. Notably, we theoretically and
empirically show that the inverted OOD samples also establish Gaussians that
are distinguishable from the original In-Domain (ID) samples in the
intermediate latent spaces, which allows us to sample from them directly.
Geometrical domain-specific and model-dependent information of the unseen
subspace (e.g., sample-wise distance and angles) is used to further optimize
the sampled OOD latent encodings from the estimated Gaussian prior. We conduct
extensive analysis and experiments using pre-trained diffusion models (DDPM,
iDDPM) on different datasets (AFHQ, CelebA-HQ, LSUN-Church, and LSUN-Bedroom),
proving the effectiveness of this novel perspective to explore and re-think the
diffusion models' data synthesis generalization ability.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09217" title="Abstract">arXiv:2310.09217</a> [<a href="/pdf/2310.09217" title="Download PDF">pdf</a>, <a href="/format/2310.09217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multinational AGI Consortium (MAGIC): A Proposal for International  Coordination on AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hausenloy%2C+J">Jason Hausenloy</a>, 
<a href="/search/cs?searchtype=author&query=Miotti%2C+A">Andrea Miotti</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+C">Claire Dennis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper proposes a Multinational Artificial General Intelligence
Consortium (MAGIC) to mitigate existential risks from advanced artificial
intelligence (AI). MAGIC would be the only institution in the world permitted
to develop advanced AI, enforced through a global moratorium by its signatory
members on all other advanced AI development. MAGIC would be exclusive,
safety-focused, highly secure, and collectively supported by member states,
with benefits distributed equitably among signatories. MAGIC would allow narrow
AI models to flourish while significantly reducing the possibility of
misaligned, rogue, breakout, or runaway outcomes of general-purpose systems. We
do not address the political feasibility of implementing a moratorium or
address the specific legislative strategies and rules needed to enforce a ban
on high-capacity AGI training runs. Instead, we propose one positive vision of
the future, where MAGIC, as a global governance regime, can lay the groundwork
for long-term, safe regulation of advanced AI.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09219" title="Abstract">arXiv:2310.09219</a> [<a href="/pdf/2310.09219" title="Download PDF">pdf</a>, <a href="/format/2310.09219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Kelly is a Warm Person, Joseph is a Role Model&quot;: Gender Biases in  LLM-Generated Reference Letters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">George Pu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Garimella%2C+A">Aparna Garimella</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As generative language models advance, users have started to utilize Large
Language Models (LLMs) to assist in writing various types of content, including
professional documents such as recommendation letters. Despite their
convenience, these applications introduce unprecedented fairness concerns. As
generated reference letters might be directly utilized by users in professional
or academic scenarios, they have the potential to cause direct social harms,
such as lowering success rates for female applicants. Therefore, it is imminent
and necessary to comprehensively study fairness issues and associated harms in
such real-world use cases for future mitigation and monitoring. In this paper,
we critically examine gender bias in LLM-generated reference letters. Inspired
by findings in social science, we design evaluation methods to manifest gender
biases in LLM-generated letters through 2 dimensions: biases in language style
and biases in lexical content. Furthermore, we investigate the extent of bias
propagation by separately analyze bias amplification in model-hallucinated
contents, which we define to be the hallucination bias of model-generated
documents. Through benchmarking evaluation on 4 popular LLMs, including
ChatGPT, Alpaca, Vicuna and StableLM, our study reveals significant gender
biases in LLM-generated recommendation letters. Our findings further point
towards the importance and imminence to recognize biases in LLM-generated
professional documents.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09222" title="Abstract">arXiv:2310.09222</a> [<a href="/pdf/2310.09222" title="Download PDF">pdf</a>, <a href="/format/2310.09222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast &amp; Efficient Learning of Bayesian Networks from Data: Knowledge  Discovery and Causality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sein%2C+M">Minn Sein</a>, 
<a href="/search/cs?searchtype=author&query=Shunkai%2C+F">Fu Shunkai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICDM 2023:CXAI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Structure learning is essential for Bayesian networks (BNs) as it uncovers
causal relationships, and enables knowledge discovery, predictions, inferences,
and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN,
based on the PC algorithm, employ local search strategy and conditional
independence tests to learn the causal network structure from data. They
incorporate d-separation to infer additional topology information, prioritize
conditioning sets, and terminate the search immediately and efficiently. FSBN
achieves up to 52% computation cost reduction, while SSBN surpasses it with a
remarkable 72% reduction for a 200-node network. SSBN demonstrates further
efficiency gains due to its intelligent strategy. Experimental studies show
that both algorithms match the induction quality of the PC algorithm while
significantly reducing computation costs. This enables them to offer
interpretability and adaptability while reducing the computational burden,
making them valuable for various applications in big data analytics.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09223" title="Abstract">arXiv:2310.09223</a> [<a href="/pdf/2310.09223" title="Download PDF">pdf</a>, <a href="/format/2310.09223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Claim Matching with Large Language Models: Empowering  Fact-Checkers in the Fight Against Misinformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+E+C">Eun Cheol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In today's digital era, the rapid spread of misinformation poses threats to
public well-being and societal trust. As online misinformation proliferates,
manual verification by fact checkers becomes increasingly challenging. We
introduce FACT-GPT (Fact-checking Augmentation with Claim matching
Task-oriented Generative Pre-trained Transformer), a framework designed to
automate the claim matching phase of fact-checking using Large Language Models
(LLMs). This framework identifies new social media content that either supports
or contradicts claims previously debunked by fact-checkers. Our approach
employs GPT-4 to generate a labeled dataset consisting of simulated social
media posts. This data set serves as a training ground for fine-tuning more
specialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media
content related to public health. The results indicate that our fine-tuned LLMs
rival the performance of larger pre-trained LLMs in claim matching tasks,
aligning closely with human annotations. This study achieves three key
milestones: it provides an automated framework for enhanced fact-checking;
demonstrates the potential of LLMs to complement human expertise; offers public
resources, including datasets and models, to further research and applications
in the fact-checking domain.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09229" title="Abstract">arXiv:2310.09229</a> [<a href="/pdf/2310.09229" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insuring Smiles: Predicting routine dental coverage using Spark ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aishwarya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bhogale%2C+R+S">Rahul S. Bhogale</a>, 
<a href="/search/cs?searchtype=author&query=Thota%2C+P">Priyanka Thota</a>, 
<a href="/search/cs?searchtype=author&query=Dathuri%2C+P">Prathushkumar Dathuri</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jongwook Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Finding suitable health insurance coverage can be challenging for individuals
and small enterprises in the USA. The Health Insurance Exchange Public Use
Files (Exchange PUFs) dataset provided by CMS offers valuable information on
health and dental policies [1]. In this paper, we leverage machine learning
algorithms to predict if a health insurance plan covers routine dental services
for adults. By analyzing plan type, region, deductibles, out-of-pocket
maximums, and copayments, we employ Logistic Regression, Decision Tree, Random
Forest, Gradient Boost, Factorization Model and Support Vector Machine
algorithms. Our goal is to provide a clinical strategy for individuals and
families to select the most suitable insurance plan based on income and
expenses.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09232" title="Abstract">arXiv:2310.09232</a> [<a href="/pdf/2310.09232" title="Download PDF">pdf</a>, <a href="/ps/2310.09232" title="Download PostScript">ps</a>, <a href="/format/2310.09232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds on Guessing Numbers and Secret Sharing Combining Information  Theory Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCrp%C4%B1nar%2C+E">Emirhan G&#xfc;rp&#x131;nar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of the results presented in section 4 (bounds on the information ratio of access structures for secret sharing schemes) was published in proceedings of IEEE ISIT, the text of which is available as <a href="/abs/2201.11656">arXiv:2201.11656</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper is on developing some computer-assisted proof methods involving
non-classical inequalities for Shannon entropy. Two areas of the applications
of information inequalities are studied: Secret sharing schemes and hat
guessing games. In the former a random secret value is transformed into shares
distributed among several participants in such a way that only the qualified
groups of participants can recover the secret value. In the latter each
participant is assigned a hat colour and they try to guess theirs while seeing
only some of the others'. The aim is to maximize the probability that every
player guesses correctly, the optimal probability depends on the underlying
sight graph. We use for both problems the method of non-Shannon-type
information inequalities going back to Z. Zhang and R. W. Yeung. We employ the
linear programming technique that allows to apply new information inequalities
indirectly, without even writing them down explicitly. To reduce the complexity
of the problems of linear programming involved in the bounds we extensively use
symmetry considerations. Using these tools, we improve lower bounds on the
ratio of key size to secret size for the former problem and an upper bound for
one of the ten vertex graphs related to an open question by Riis for the latter
problem.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09233" title="Abstract">arXiv:2310.09233</a> [<a href="/pdf/2310.09233" title="Download PDF">pdf</a>, <a href="/format/2310.09233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgentCF: Collaborative Learning with Autonomous Language Agents for  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yupeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Leyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, there has been an emergence of employing LLM-powered agents as
believable human proxies, based on their remarkable decision-making capability.
However, existing studies mainly focus on simulating human dialogue. Human
non-verbal behaviors, such as item clicking in recommender systems, although
implicitly exhibiting user preferences and could enhance the modeling of users,
have not been deeply explored. The main reasons lie in the gap between language
modeling and behavior modeling, as well as the incomprehension of LLMs about
user-item relations.
<br />To address this issue, we propose AgentCF for simulating user-item
interactions in recommender systems through agent-based collaborative
filtering. We creatively consider not only users but also items as agents, and
develop a collaborative learning approach that optimizes both kinds of agents
together. Specifically, at each time step, we first prompt the user and item
agents to interact autonomously. Then, based on the disparities between the
agents' decisions and real-world interaction records, user and item agents are
prompted to reflect on and adjust the misleading simulations collaboratively,
thereby modeling their two-sided relations. The optimized agents can also
propagate their preferences to other agents in subsequent interactions,
implicitly capturing the collaborative filtering idea. Overall, the optimized
agents exhibit diverse interaction behaviors within our framework, including
user-item, user-user, item-item, and collective interactions. The results show
that these agents can demonstrate personalized behaviors akin to those of
real-world individuals, sparking the development of next-generation user
behavior simulation.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09234" title="Abstract">arXiv:2310.09234</a> [<a href="/pdf/2310.09234" title="Download PDF">pdf</a>, <a href="/format/2310.09234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClickPrompt: CTR Models are Strong Prompt Generators for Adapting  Language Models to CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Y">Yunjia Xi</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanru Qu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xinyi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Click-through rate (CTR) prediction has become increasingly indispensable for
various Internet applications. Traditional CTR models convert the multi-field
categorical data into ID features via one-hot encoding, and extract the
collaborative signals among features. Such a paradigm suffers from the problem
of semantic information loss. Another line of research explores the potential
of pretrained language models (PLMs) for CTR prediction by converting input
data into textual sentences through hard prompt templates. Although semantic
signals are preserved, they generally fail to capture the collaborative
information (e.g., feature interactions, pure ID features), not to mention the
unacceptable inference overhead brought by the huge model size. In this paper,
we aim to model both the semantic knowledge and collaborative knowledge for
accurate CTR estimation, and meanwhile address the inference inefficiency
issue. To benefit from both worlds and close their gaps, we propose a novel
model-agnostic framework (i.e., ClickPrompt), where we incorporate CTR models
to generate interaction-aware soft prompts for PLMs. We design a
prompt-augmented masked language modeling (PA-MLM) pretraining task, where PLM
has to recover the masked tokens based on the language context, as well as the
soft prompts generated by CTR model. The collaborative and semantic knowledge
from ID and textual features would be explicitly aligned and interacted via the
prompt interface. Then, we can either tune the CTR model with PLM for superior
performance, or solely tune the CTR model without PLM for inference efficiency.
Experiments on four real-world datasets validate the effectiveness of
ClickPrompt compared with existing baselines.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09235" title="Abstract">arXiv:2310.09235</a> [<a href="/pdf/2310.09235" title="Download PDF">pdf</a>, <a href="/format/2310.09235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoPrompt: Supporting Prompt Sharing and Referring in Collaborative  Natural Language Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+F+L">Felicia Li Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+R">Ryan Yen</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yuzhe You</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhicong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Natural language (NL) programming has become more approachable due to the
powerful code-generation capability of large language models (LLMs). This shift
to using NL to program enhances collaborative programming by reducing
communication barriers and context-switching among programmers from varying
backgrounds. However, programmers may face challenges during prompt engineering
in a collaborative setting as they need to actively keep aware of their
collaborators' progress and intents. In this paper, we aim to investigate ways
to assist programmers' prompt engineering in a collaborative context. We first
conducted a formative study to understand the workflows and challenges of
programmers when using NL for collaborative programming. Based on our findings,
we implemented a prototype, CoPrompt, to support collaborative prompt
engineering by providing referring, requesting, sharing, and linking
mechanisms. Our user study indicates that CoPrompt assists programmers in
comprehending collaborators' prompts and building on their collaborators' work,
reducing repetitive updates and communication costs.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09236" title="Abstract">arXiv:2310.09236</a> [<a href="/pdf/2310.09236" title="Download PDF">pdf</a>, <a href="/format/2310.09236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time CNN and Graph Convolution Network for Epileptic Spike Detection in  MEG Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mouches%2C+P">Pauline Mouches</a>, 
<a href="/search/cs?searchtype=author&query=Dejean%2C+T">Thibaut Dejean</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Julien Jung</a>, 
<a href="/search/cs?searchtype=author&query=Bouet%2C+R">Romain Bouet</a>, 
<a href="/search/cs?searchtype=author&query=Lartizien%2C+C">Carole Lartizien</a>, 
<a href="/search/cs?searchtype=author&query=Quentin%2C+R">Romain Quentin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE ISBI 2024 for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Magnetoencephalography (MEG) recordings of patients with epilepsy exhibit
spikes, a typical biomarker of the pathology. Detecting those spikes allows
accurate localization of brain regions triggering seizures. Spike detection is
often performed manually. However, it is a burdensome and error prone task due
to the complexity of MEG data. To address this problem, we propose a 1D
temporal convolutional neural network (Time CNN) coupled with a graph
convolutional network (GCN) to classify short time frames of MEG recording as
containing a spike or not. Compared to other recent approaches, our models have
fewer parameters to train and we propose to use a GCN to account for MEG
sensors spatial relationships. Our models produce clinically relevant results
and outperform deep learning-based state-of-the-art methods reaching a
classification f1-score of 76.7% on a balanced dataset and of 25.5% on a
realistic, highly imbalanced dataset, for the spike class.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09237" title="Abstract">arXiv:2310.09237</a> [<a href="/pdf/2310.09237" title="Download PDF">pdf</a>, <a href="/format/2310.09237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Machine Perception of Indigeneity: An Analysis of ChatGPT&#x27;s  Perceptions of Indigenous Roles in Diverse Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solorzano%2C+C+D">Cecilia Delgado Solorzano</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez%2C+C+T">Carlos Toxtli Hernandez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Large Language Models (LLMs), like ChatGPT, are fundamentally tools trained
on vast data, reflecting diverse societal impressions. This paper aims to
investigate LLMs' self-perceived bias concerning indigeneity when simulating
scenarios of indigenous people performing various roles. Through generating and
analyzing multiple scenarios, this work offers a unique perspective on how
technology perceives and potentially amplifies societal biases related to
indigeneity in social computing. The findings offer insights into the broader
implications of indigeneity in critical computing.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09238" title="Abstract">arXiv:2310.09238</a> [<a href="/pdf/2310.09238" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models  for Sentiment Analysis of Bangla Social Media Posts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Saumajit Saha</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+A">Albert Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Bangla is the 7th most widely spoken language globally, with a staggering 234
million native speakers primarily hailing from India and Bangladesh. This
morphologically rich language boasts a rich literary tradition, encompassing
diverse dialects and language-specific challenges. Despite its linguistic
richness and history, Bangla remains categorized as a low-resource language
within the natural language processing (NLP) and speech community. This paper
presents our submission to Task 2 (Sentiment Analysis of Bangla Social Media
Posts) of the BLP Workshop. We experiment with various Transformer-based
architectures to solve this task. Our quantitative results show that transfer
learning really helps in better learning of the models in this low-resource
language scenario. This becomes evident when we further finetune a model which
has already been finetuned on twitter data for sentiment analysis task and that
finetuned model performs the best among all other models. We also perform a
detailed error analysis where we find some instances where ground truth labels
need to be relooked at. We obtain a micro-F1 of 67.02\% on the test set and our
performance in this shared task is ranked at 21 in the leaderboard.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09241" title="Abstract">arXiv:2310.09241</a> [<a href="/pdf/2310.09241" title="Download PDF">pdf</a>, <a href="/format/2310.09241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weiming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yating Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changlong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Legal Judgment Prediction (LJP) has become an increasingly crucial task in
Legal AI, i.e., predicting the judgment of the case in terms of case fact
description. Precedents are the previous legal cases with similar facts, which
are the basis for the judgment of the subsequent case in national legal
systems. Thus, it is worthwhile to explore the utilization of precedents in the
LJP. Recent advances in deep learning have enabled a variety of techniques to
be used to solve the LJP task. These can be broken down into two categories:
large language models (LLMs) and domain-specific models. LLMs are capable of
interpreting and generating complex natural language, while domain models are
efficient in learning task-specific information. In this paper, we propose the
precedent-enhanced LJP framework (PLJP), a system that leverages the strength
of both LLM and domain models in the context of precedents. Specifically, the
domain models are designed to provide candidate labels and find the proper
precedents efficiently, and the large models will make the final prediction
with an in-context precedents comprehension. Experiments on the real-world
dataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a
promising direction for LLM and domain-model collaboration that can be
generalized to other vertical domains.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09242" title="Abstract">arXiv:2310.09242</a> [<a href="/pdf/2310.09242" title="Download PDF">pdf</a>, <a href="/format/2310.09242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multifaceted Look at Starlink Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohan%2C+N">Nitinder Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+A">Andrew Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Cech%2C+H">Hendrik Cech</a>, 
<a href="/search/cs?searchtype=author&query=Renatin%2C+P+R">Prakita Rayyan Renatin</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+R">Rohan Bose</a>, 
<a href="/search/cs?searchtype=author&query=Marina%2C+M">Mahesh Marina</a>, 
<a href="/search/cs?searchtype=author&query=Ott%2C+J">J&#xf6;rg Ott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In recent years, Low-Earth Orbit (LEO) mega-constellations have emerged as a
promising network technology and have ushered in a new era for democratizing
Internet access. The Starlink network from SpaceX stands out as the only
consumer-facing LEO network with over 2M+ customers and more than 4000
operational satellites. In this paper, we conduct the first-of-its-kind
extensive multi-faceted analysis of Starlink network performance leveraging
several measurement sources. First, based on 19.2M crowdsourced M-Lab speed
test measurements from 34 countries since 2021, we analyze Starlink global
performance relative to terrestrial cellular networks. Second, we examine
Starlink's ability to support real-time web-based latency and
bandwidth-critical applications by analyzing the performance of (i) Zoom video
conferencing, and (ii) Luna cloud gaming, comparing it to 5G and terrestrial
fiber. Third, we orchestrate targeted measurements from Starlink-enabled RIPE
Atlas probes to shed light on the last-mile Starlink access and other factors
affecting its performance globally. Finally, we conduct controlled experiments
from Starlink dishes in two countries and analyze the impact of globally
synchronized "15-second reconfiguration intervals" of the links that cause
substantial latency and throughput variations. Our unique analysis provides
revealing insights on global Starlink functionality and paints the most
comprehensive picture of the LEO network's operation to date.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09243" title="Abstract">arXiv:2310.09243</a> [<a href="/pdf/2310.09243" title="Download PDF">pdf</a>, <a href="/format/2310.09243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Computational Design: Methodical Application of Artificial  Intelligence in Generative Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nourian%2C+P">Pirouz Nourian</a>, 
<a href="/search/cs?searchtype=author&query=Azadi%2C+S">Shervin Azadi</a>, 
<a href="/search/cs?searchtype=author&query=Uijtendaal%2C+R">Roy Uijtendaal</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+N">Nan Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the author's version of the book chapter Augmented Computational Design: Methodical Application of Artificial Intelligence in Generative Design. In Artificial Intelligence in Performance-Driven Design: Theories, Methods, and Tools Towards Sustainability, edited by Narjes Abbasabadi and Mehdi Ashayeri. Wiley, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">This chapter presents methodological reflections on the necessity and utility
of artificial intelligence in generative design. Specifically, the chapter
discusses how generative design processes can be augmented by AI to deliver in
terms of a few outcomes of interest or performance indicators while dealing
with hundreds or thousands of small decisions. The core of the
performance-based generative design paradigm is about making statistical or
simulation-driven associations between these choices and consequences for
mapping and navigating such a complex decision space. This chapter will discuss
promising directions in Artificial Intelligence for augmenting decision-making
processes in architectural design for mapping and navigating complex design
spaces.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09247" title="Abstract">arXiv:2310.09247</a> [<a href="/pdf/2310.09247" title="Download PDF">pdf</a>, <a href="/format/2310.09247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet  Hierarchy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baryshnikov%2C+A">Anton Baryshnikov</a>, 
<a href="/search/cs?searchtype=author&query=Ryabinin%2C+M">Max Ryabinin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image synthesis has recently attracted widespread attention due to
rapidly improving quality and numerous practical applications. However, the
language understanding capabilities of text-to-image models are still poorly
understood, which makes it difficult to reason about prompt formulations that a
given model would understand well. In this work, we measure the capability of
popular text-to-image models to understand $\textit{hypernymy}$, or the "is-a"
relation between words. We design two automatic metrics based on the WordNet
semantic hierarchy and existing image classifiers pretrained on ImageNet. These
metrics both enable broad quantitative comparison of linguistic capabilities
for text-to-image models and offer a way of finding fine-grained qualitative
differences, such as words that are unknown to models and thus are difficult
for them to draw. We comprehensively evaluate popular text-to-image models,
including GLIDE, Latent Diffusion, and Stable Diffusion, showing how our
metrics can provide a better understanding of the individual strengths and
weaknesses of these models.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09250" title="Abstract">arXiv:2310.09250</a> [<a href="/pdf/2310.09250" title="Download PDF">pdf</a>, <a href="/format/2310.09250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It&#x27;s an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lukasik%2C+M">Michal Lukasik</a>, 
<a href="/search/cs?searchtype=author&query=Jitkrittum%2C+W">Wittawat Jitkrittum</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chong You</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Classical wisdom in machine learning holds that the generalization error can
be decomposed into bias and variance, and these two terms exhibit a
\emph{trade-off}. However, in this paper, we show that for an ensemble of deep
learning based classification models, bias and variance are \emph{aligned} at a
sample level, where squared bias is approximately \emph{equal} to variance for
correctly classified sample points. We present empirical evidence confirming
this phenomenon in a variety of deep learning models and datasets. Moreover, we
study this phenomenon from two theoretical perspectives: calibration and neural
collapse. We first show theoretically that under the assumption that the models
are well calibrated, we can observe the bias-variance alignment. Second,
starting from the picture provided by the neural collapse theory, we show an
approximate correlation between bias and variance.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09256" title="Abstract">arXiv:2310.09256</a> [<a href="/pdf/2310.09256" title="Download PDF">pdf</a>, <a href="/format/2310.09256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Political claim identification and categorization in a multilingual  setting: First experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaberer%2C+U">Urs Zaberer</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C3%B3%2C+S">Sebastian Pad&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Lapesa%2C+G">Gabriella Lapesa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at KONVENS 2023, Ingolstadt, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The identification and classification of political claims is an important
step in the analysis of political newspaper reports; however, resources for
this task are few and far between. This paper explores different strategies for
the cross-lingual projection of political claims analysis. We conduct
experiments on a German dataset, DebateNet2.0, covering the policy debate
sparked by the 2015 refugee crisis. Our evaluation involves two tasks (claim
identification and categorization), three languages (German, English, and
French) and two methods (machine translation -- the best method in our
experiments -- and multilingual embeddings).
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09259" title="Abstract">arXiv:2310.09259</a> [<a href="/pdf/2310.09259" title="Download PDF">pdf</a>, <a href="/format/2310.09259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-to-end 4-Bit Inference on Generative Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashkboos%2C+S">Saleh Ashkboos</a>, 
<a href="/search/cs?searchtype=author&query=Markov%2C+I">Ilia Markov</a>, 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tingxuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xincheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We show that the majority of the inference computations for large generative
models such as LLaMA and OPT can be performed with both weights and activations
being cast to 4 bits, in a way that leads to practical speedups while at the
same time maintaining good accuracy. We achieve this via a hybrid quantization
strategy called QUIK, which compresses most of the weights and activations to
4-bit, while keeping some outlier weights and activations in higher-precision.
Crucially, our scheme is designed with computational efficiency in mind: we
provide GPU kernels with highly-efficient layer-wise runtimes, which lead to
practical end-to-end throughput improvements of up to 3.1x relative to FP16
execution. Code and models are provided at https://github.com/IST-DASLab/QUIK.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09260" title="Abstract">arXiv:2310.09260</a> [<a href="/pdf/2310.09260" title="Download PDF">pdf</a>, <a href="/format/2310.09260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A lowest order stabilization-free mixed Virtual Element Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Borio%2C+A">Andrea Borio</a>, 
<a href="/search/math?searchtype=author&query=Lovadina%2C+C">Carlo Lovadina</a>, 
<a href="/search/math?searchtype=author&query=Marcon%2C+F">Francesca Marcon</a>, 
<a href="/search/math?searchtype=author&query=Visinoni%2C+M">Michele Visinoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We initiate the design and the analysis of stabilization-free Virtual Element
Methods for the laplacian problem written in mixed form. A Virtual Element
version of the lowest order Raviart-Thomas Finite Element is considered. To
reduce the computational costs, a suitable projection on the gradients of
harmonic polynomials is employed. A complete theoretical analysis of stability
and convergence is developed in the case of quadrilateral meshes. Some
numerical tests highlighting the actual behaviour of the scheme are also
provided.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09263" title="Abstract">arXiv:2310.09263</a> [<a href="/pdf/2310.09263" title="Download PDF">pdf</a>, <a href="/format/2310.09263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Table-GPT: Table-tuned GPT for Diverse Table Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yeye He</a>, 
<a href="/search/cs?searchtype=author&query=Yashar%2C+D">Dror Yashar</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weiwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Song Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fainman%2C+D+R">Danielle Rifinski Fainman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Surajit Chaudhuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
<p class="mathjax">Language models, such as GPT-3.5 and ChatGPT, demonstrate remarkable
abilities to follow diverse human instructions and perform a wide range of
tasks. However, when probing language models using a range of basic
table-understanding tasks, we observe that today's language models are still
sub-optimal in many table-related tasks, likely because they are pre-trained
predominantly on \emph{one-dimensional} natural-language texts, whereas
relational tables are \emph{two-dimensional} objects.
<br />In this work, we propose a new "\emph{table-tuning}" paradigm, where we
continue to train/fine-tune language models like GPT-3.5 and ChatGPT, using
diverse table-tasks synthesized from real tables as training data, with the
goal of enhancing language models' ability to understand tables and perform
table tasks. We show that our resulting Table-GPT models demonstrate (1) better
\emph{table-understanding} capabilities, by consistently outperforming the
vanilla GPT-3.5 and ChatGPT, on a wide-range of table tasks, including holdout
unseen tasks, and (2) strong \emph{generalizability}, in its ability to respond
to diverse human instructions to perform new table-tasks, in a manner similar
to GPT-3.5 and ChatGPT.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09265" title="Abstract">arXiv:2310.09265</a> [<a href="/pdf/2310.09265" title="Download PDF">pdf</a>, <a href="/format/2310.09265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptRE: Weakly-Supervised Document-Level Relation Extraction via  Prompting-Based Data Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chufan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xulin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Relation extraction aims to classify the relationships between two entities
into pre-defined categories. While previous research has mainly focused on
sentence-level relation extraction, recent studies have expanded the scope to
document-level relation extraction. Traditional relation extraction methods
heavily rely on human-annotated training data, which is time-consuming and
labor-intensive. To mitigate the need for manual annotation, recent
weakly-supervised approaches have been developed for sentence-level relation
extraction while limited work has been done on document-level relation
extraction. Weakly-supervised document-level relation extraction faces
significant challenges due to an imbalanced number "no relation" instances and
the failure of directly probing pretrained large language models for document
relation extraction. To address these challenges, we propose PromptRE, a novel
weakly-supervised document-level relation extraction method that combines
prompting-based techniques with data programming. Furthermore, PromptRE
incorporates the label distribution and entity types as prior knowledge to
improve the performance. By leveraging the strengths of both prompting and data
programming, PromptRE achieves improved performance in relation classification
and effectively handles the "no relation" problem. Experimental results on
ReDocRED, a benchmark dataset for document-level relation extraction,
demonstrate the superiority of PromptRE over baseline approaches.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09266" title="Abstract">arXiv:2310.09266</a> [<a href="/pdf/2310.09266" title="Download PDF">pdf</a>, <a href="/format/2310.09266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Inference Attacks on Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kandpal%2C+N">Nikhil Kandpal</a>, 
<a href="/search/cs?searchtype=author&query=Pillutla%2C+K">Krishna Pillutla</a>, 
<a href="/search/cs?searchtype=author&query=Oprea%2C+A">Alina Oprea</a>, 
<a href="/search/cs?searchtype=author&query=Kairouz%2C+P">Peter Kairouz</a>, 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fine-tuning is a common and effective method for tailoring large language
models (LLMs) to specialized tasks and applications. In this paper, we study
the privacy implications of fine-tuning LLMs on user data. To this end, we
define a realistic threat model, called user inference, wherein an attacker
infers whether or not a user's data was used for fine-tuning. We implement
attacks for this threat model that require only a small set of samples from a
user (possibly different from the samples used for training) and black-box
access to the fine-tuned LLM. We find that LLMs are susceptible to user
inference attacks across a variety of fine-tuning datasets, at times with near
perfect attack success rates. Further, we investigate which properties make
users vulnerable to user inference, finding that outlier users (i.e. those with
data distributions sufficiently different from other users) and users who
contribute large quantities of data are most susceptible to attack. Finally, we
explore several heuristics for mitigating privacy attacks. We find that
interventions in the training algorithm, such as batch or per-example gradient
clipping and early stopping fail to prevent user inference. However, limiting
the number of fine-tuning samples from a single user can reduce attack
effectiveness, albeit at the cost of reducing the total amount of fine-tuning
data.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09267" title="Abstract">arXiv:2310.09267</a> [<a href="/pdf/2310.09267" title="Download PDF">pdf</a>, <a href="/ps/2310.09267" title="Download PostScript">ps</a>, <a href="/format/2310.09267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic algorithms are strong baselines for molecule generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripp%2C+A">Austin Tripp</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review. Code will be made available at a later date
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Generating molecules, both in a directed and undirected fashion, is a huge
part of the drug discovery pipeline. Genetic algorithms (GAs) generate
molecules by randomly modifying known molecules. In this paper we show that GAs
are very strong algorithms for such tasks, outperforming many complicated
machine learning methods: a result which many researchers may find surprising.
We therefore propose insisting during peer review that new algorithms must have
some clear advantage over GAs, which we call the GA criterion. Ultimately our
work suggests that a lot of research in molecule generation should be
re-assessed.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09270" title="Abstract">arXiv:2310.09270</a> [<a href="/pdf/2310.09270" title="Download PDF">pdf</a>, <a href="/format/2310.09270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retro-fallback: retrosynthetic planning in an uncertain world
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripp%2C+A">Austin Tripp</a>, 
<a href="/search/cs?searchtype=author&query=Maziarz%2C+K">Krzysztof Maziarz</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+S">Sarah Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Segler%2C+M">Marwin Segler</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages (including appendices). Currently undergoing peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Retrosynthesis is the task of proposing a series of chemical reactions to
create a desired molecule from simpler, buyable molecules. While previous works
have proposed algorithms to find optimal solutions for a range of metrics (e.g.
shortest, lowest-cost), these works generally overlook the fact that we have
imperfect knowledge of the space of possible reactions, meaning plans created
by the algorithm may not work in a laboratory. In this paper we propose a novel
formulation of retrosynthesis in terms of stochastic processes to account for
this uncertainty. We then propose a novel greedy algorithm called
retro-fallback which maximizes the probability that at least one synthesis plan
can be executed in the lab. Using in-silico benchmarks we demonstrate that
retro-fallback generally produces better sets of synthesis plans than the
popular MCTS and retro* algorithms.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09271" title="Abstract">arXiv:2310.09271</a> [<a href="/pdf/2310.09271" title="Download PDF">pdf</a>, <a href="/format/2310.09271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiency of Non-Truthful Auctions in Auto-bidding with Budget  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liaw%2C+C">Christopher Liaw</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Aranyak Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wennan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the efficiency of non-truthful auctions for auto-bidders with both
return on spend (ROS) and budget constraints. The efficiency of a mechanism is
measured by the price of anarchy (PoA), which is the worst case ratio between
the liquid welfare of any equilibrium and the optimal (possibly randomized)
allocation. Our first main result is that the first-price auction (FPA) is
optimal, among deterministic mechanisms, in this setting. Without any
assumptions, the PoA of FPA is $n$ which we prove is tight for any
deterministic mechanism. However, under a mild assumption that a bidder's value
for any query does not exceed their total budget, we show that the PoA is at
most $2$. This bound is also tight as it matches the optimal PoA without a
budget constraint. We next analyze two randomized mechanisms: randomized FPA
(rFPA) and "quasi-proportional" FPA. We prove two results that highlight the
efficacy of randomization in this setting. First, we show that the PoA of rFPA
for two bidders is at most $1.8$ without requiring any assumptions. This
extends prior work which focused only on an ROS constraint. Second, we show
that quasi-proportional FPA has a PoA of $2$ for any number of bidders, without
any assumptions. Both of these bypass lower bounds in the deterministic
setting. Finally, we study the setting where bidders are assumed to bid
uniformly. We show that uniform bidding can be detrimental for efficiency in
deterministic mechanisms while being beneficial for randomized mechanisms,
which is in stark contrast with the settings without budget constraints.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09275" title="Abstract">arXiv:2310.09275</a> [<a href="/pdf/2310.09275" title="Download PDF">pdf</a>, <a href="/format/2310.09275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Modeling the Effects of Task and Context on Drivers&#x27;  Gaze Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotseruba%2C+I">Iuliia Kotseruba</a>, 
<a href="/search/cs?searchtype=author&query=Tsotsos%2C+J+K">John K. Tsotsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding what drivers look at is important for many applications,
including driver training, monitoring, and assistance, as well as self-driving.
Traditionally, factors affecting human visual attention have been divided into
bottom-up (involuntary attraction to salient regions) and top-down (task- and
context-driven). Although both play a role in drivers' gaze allocation, most of
the existing modeling approaches apply techniques developed for bottom-up
saliency and do not consider task and context influences explicitly. Likewise,
common driving attention benchmarks lack relevant task and context annotations.
Therefore, to enable analysis and modeling of these factors for drivers' gaze
prediction, we propose the following: 1) address some shortcomings of the
popular DR(eye)VE dataset and extend it with per-frame annotations for driving
task and context; 2) benchmark a number of baseline and SOTA models for
saliency and driver gaze prediction and analyze them w.r.t. the new
annotations; and finally, 3) a novel model that modulates drivers' gaze
prediction with explicit action and context information, and as a result
significantly improves SOTA performance on DR(eye)VE overall (by 24\% KLD and
89\% NSS) and on a subset of action and safety-critical intersection scenarios
(by 10--30\% KLD). Extended annotations, code for model and evaluation will be
made publicly available.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09276" title="Abstract">arXiv:2310.09276</a> [<a href="/pdf/2310.09276" title="Download PDF">pdf</a>, <a href="/format/2310.09276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Multimodal Change Detection with Multitask Consistency  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Biyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M+Y">Michael Ying Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Change detection plays a fundamental role in Earth observation for analyzing
temporal iterations over time. However, recent studies have largely neglected
the utilization of multimodal data that presents significant practical and
technical advantages compared to single-modal approaches. This research focuses
on leveraging digital surface model (DSM) data and aerial images captured at
different times for detecting change beyond 2D. We observe that the current
change detection methods struggle with the multitask conflicts between semantic
and height change detection tasks. To address this challenge, we propose an
efficient Transformer-based network that learns shared representation between
cross-dimensional inputs through cross-attention. It adopts a consistency
constraint to establish the multimodal relationship, which involves obtaining
pseudo change through height change thresholding and minimizing the difference
between semantic and pseudo change within their overlapping regions. A
DSM-to-image multimodal dataset encompassing three cities in the Netherlands
was constructed. It lays a new foundation for beyond-2D change detection from
cross-dimensional inputs. Compared to five state-of-the-art change detection
methods, our model demonstrates consistent multitask superiority in terms of
semantic and height change detection. Furthermore, the consistency strategy can
be seamlessly adapted to the other methods, yielding promising improvements.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09277" title="Abstract">arXiv:2310.09277</a> [<a href="/pdf/2310.09277" title="Download PDF">pdf</a>, <a href="/format/2310.09277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Approach for Depression Classification: Random Forest-ANN  Ensemble on Motor Activity Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+A">Anket Patil</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhairya Shah</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Abhishek Shah</a>, 
<a href="/search/cs?searchtype=author&query=Gala%2C+M">Mokshit Gala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Regarding the rising number of people suffering from mental health illnesses
in today's society, the importance of mental health cannot be overstated.
Wearable sensors, which are increasingly widely available, provide a potential
way to track and comprehend mental health issues. These gadgets not only
monitor everyday activities but also continuously record vital signs like heart
rate, perhaps providing information on a person's mental state. Recent research
has used these sensors in conjunction with machine learning methods to identify
patterns relating to different mental health conditions, highlighting the
immense potential of this data beyond simple activity monitoring. In this
research, we present a novel algorithm called the Hybrid Random forest - Neural
network that has been tailored to evaluate sensor data from depressed patients.
Our method has a noteworthy accuracy of 80\% when evaluated on a special
dataset that included both unipolar and bipolar depressive patients as well as
healthy controls. The findings highlight the algorithm's potential for reliably
determining a person's depression condition using sensor data, making a
substantial contribution to the area of mental health diagnostics.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09278" title="Abstract">arXiv:2310.09278</a> [<a href="/pdf/2310.09278" title="Download PDF">pdf</a>, <a href="/format/2310.09278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skenderi%2C+G">Geri Skenderi</a>, 
<a href="/search/cs?searchtype=author&query=Capogrosso%2C+L">Luigi Capogrosso</a>, 
<a href="/search/cs?searchtype=author&query=Toaiari%2C+A">Andrea Toaiari</a>, 
<a href="/search/cs?searchtype=author&query=Denitto%2C+M">Matteo Denitto</a>, 
<a href="/search/cs?searchtype=author&query=Fummi%2C+F">Franco Fummi</a>, 
<a href="/search/cs?searchtype=author&query=Melzi%2C+S">Simone Melzi</a>, 
<a href="/search/cs?searchtype=author&query=Cristani%2C+M">Marco Cristani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In deep learning, auxiliary objectives are often used to facilitate learning
in situations where data is scarce, or the principal task is extremely complex.
This idea is primarily inspired by the improved generalization capability
induced by solving multiple tasks simultaneously, which leads to a more robust
shared representation. Nevertheless, finding optimal auxiliary tasks that give
rise to the desired improvement is a crucial problem that often requires
hand-crafted solutions or expensive meta-learning approaches. In this paper, we
propose a novel framework, dubbed Detaux, whereby a weakly supervised
disentanglement procedure is used to discover new unrelated classification
tasks and the associated labels that can be exploited with the principal task
in any Multi-Task Learning (MTL) model. The disentanglement procedure works at
a representation level, isolating a subspace related to the principal task,
plus an arbitrary number of orthogonal subspaces. In the most disentangled
subspaces, through a clustering procedure, we generate the additional
classification tasks, and the associated labels become their representatives.
Subsequently, the original data, the labels associated with the principal task,
and the newly discovered ones can be fed into any MTL framework. Extensive
validation on both synthetic and real data, along with various ablation
studies, demonstrate promising results, revealing the potential in what has
been, so far, an unexplored connection between learning disentangled
representations and MTL. The code will be made publicly available upon
acceptance.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09279" title="Abstract">arXiv:2310.09279</a> [<a href="/pdf/2310.09279" title="Download PDF">pdf</a>, <a href="/ps/2310.09279" title="Download PostScript">ps</a>, <a href="/format/2310.09279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control of Vehicle Platoons with Collision Avoidance Using  Noncooperative Differential Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jond%2C+H+B">Hossein B. Jond</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented at IEEE ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper considers a differential game approach to the
predecessor-following vehicle platoon control problem without and with
collision avoidance. In this approach, each vehicle tries to minimize the
performance index (PI) of its control objective, which is reaching consensual
velocity with the predecessor vehicle while maintaining a small inter-vehicle
distance from it. Two differential games were formulated. The differential game
problem for platoon control without collision avoidance is solved for the
open-loop Nash equilibrium and its associated state trajectories. The second
differential game problem for platoon control with collision avoidance has a
non-quadratic PI, which poses a greater challenge to obtaining its open-loop
Nash equilibrium. Since the exact solution is unavailable, we propose an
estimated Nash strategy approach that is greatly simplified for implementation.
An illustrative example of a vehicle platoon control problem was solved under
both the without and with collision avoidance scenarios. The results showed the
effectiveness of the models and their solutions for both scenarios.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09285" title="Abstract">arXiv:2310.09285</a> [<a href="/pdf/2310.09285" title="Download PDF">pdf</a>, <a href="/format/2310.09285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAIR: Learning Semantic-aware Implicit Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Canyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Implicit representation of an image can map arbitrary coordinates in the
continuous domain to their corresponding color values, presenting a powerful
capability for image reconstruction. Nevertheless, existing implicit
representation approaches only focus on building continuous appearance mapping,
ignoring the continuities of the semantic information across pixels. As a
result, they can hardly achieve desired reconstruction results when the
semantic information within input images is corrupted, for example, a large
region misses. To address the issue, we propose to learn semantic-aware
implicit representation (SAIR), that is, we make the implicit representation of
each pixel rely on both its appearance and semantic information (\eg, which
object does the pixel belong to). To this end, we propose a framework with two
modules: (1) building a semantic implicit representation (SIR) for a corrupted
image whose large regions miss. Given an arbitrary coordinate in the continuous
domain, we can obtain its respective text-aligned embedding indicating the
object the pixel belongs. (2) building an appearance implicit representation
(AIR) based on the SIR. Given an arbitrary coordinate in the continuous domain,
we can reconstruct its color whether or not the pixel is missed in the input.
We validate the novel semantic-aware implicit representation method on the
image inpainting task, and the extensive experiments demonstrate that our
method surpasses state-of-the-art approaches by a significant margin.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09289" title="Abstract">arXiv:2310.09289</a> [<a href="/pdf/2310.09289" title="Download PDF">pdf</a>, <a href="/format/2310.09289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Unbiased Look at Datasets for Visuo-Motor Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dasari%2C+S">Sudeep Dasari</a>, 
<a href="/search/cs?searchtype=author&query=Srirama%2C+M+K">Mohan Kumar Srirama</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+U">Unnat Jain</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhinav Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Visual representation learning hold great promise for robotics, but is
severely hampered by the scarcity and homogeneity of robotics datasets. Recent
works address this problem by pre-training visual representations on
large-scale but out-of-domain data (e.g., videos of egocentric interactions)
and then transferring them to target robotics tasks. While the field is heavily
focused on developing better pre-training algorithms, we find that dataset
choice is just as important to this paradigm's success. After all, the
representation can only learn the structures or priors present in the
pre-training dataset. To this end, we flip the focus on algorithms, and instead
conduct a dataset centric analysis of robotic pre-training. Our findings call
into question some common wisdom in the field. We observe that traditional
vision datasets (like ImageNet, Kinetics and 100 Days of Hands) are
surprisingly competitive options for visuo-motor representation learning, and
that the pre-training dataset's image distribution matters more than its size.
Finally, we show that common simulation benchmarks are not a reliable proxy for
real world performance and that simple regularization strategies can
dramatically improve real world policy learning.
https://data4robotics.github.io
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09291" title="Abstract">arXiv:2310.09291</a> [<a href="/pdf/2310.09291" title="Download PDF">pdf</a>, <a href="/format/2310.09291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-by-Language for Training-Free Compositional Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karthik%2C+S">Shyamgopal Karthik</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+K">Karsten Roth</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+M">Massimiliano Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given an image and a target modification (e.g an image of the Eiffel tower
and the text "without people and at night-time"), Compositional Image Retrieval
(CIR) aims to retrieve the relevant target image in a database. While
supervised approaches rely on annotating triplets that is costly (i.e. query
image, textual modification, and target image), recent research sidesteps this
need by using large-scale vision-language models (VLMs), performing Zero-Shot
CIR (ZS-CIR). However, state-of-the-art approaches in ZS-CIR still require
training task-specific, customized models over large amounts of image-text
pairs. In this work, we propose to tackle CIR in a training-free manner via our
Compositional Image Retrieval through Vision-by-Language (CIReVL), a simple,
yet human-understandable and scalable pipeline that effectively recombines
large-scale VLMs with large language models (LLMs). By captioning the reference
image using a pre-trained generative VLM and asking a LLM to recompose the
caption based on the textual target modification for subsequent retrieval via
e.g. CLIP, we achieve modular language reasoning. In four ZS-CIR benchmarks, we
find competitive, in-part state-of-the-art performance - improving over
supervised methods. Moreover, the modularity of CIReVL offers simple
scalability without re-training, allowing us to both investigate scaling laws
and bottlenecks for ZS-CIR while easily scaling up to in parts more than double
of previously reported results. Finally, we show that CIReVL makes CIR
human-understandable by composing image and text in a modular fashion in the
language domain, thereby making it intervenable, allowing to post-hoc re-align
failure cases. Code will be released upon acceptance.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 16 Oct 23</h3>
<dl>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10739" title="Abstract">arXiv:2212.10739</a> (cross-list from hep-ph) [<a href="/pdf/2212.10739" title="Download PDF">pdf</a>, <a href="/format/2212.10739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decay of the Mediator Particle at Threshold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Matsumoto%2C+S">Shigeki Matsumoto</a>, 
<a href="/search/hep-ph?searchtype=author&query=Watanabe%2C+Y">Yu Watanabe</a>, 
<a href="/search/hep-ph?searchtype=author&query=Watanabe%2C+Y">Yuki Watanabe</a>, 
<a href="/search/hep-ph?searchtype=author&query=White%2C+G">Graham White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">A light mediator particle is often predicted in the dark sector scenario,
which weakly interacts with the standard model (SM) particles. The weakness of
the interaction is usually described by a small coupling; however, the small
coupling does not always guarantee the weakness of the interaction. When the
mass of the mediator particle lies in a threshold region, the so-called
threshold singularity may emerge, and then the perturbative calculation fails.
This singularity causes several effects, e.g., the mixing between the mediator
particle and bound states, the Sommerfeld effect on the final state of the
mediator particle decay, etc. Taking the minimal model of the vector mediator
particle decaying mainly into the SM particles as an example, we develop a
method to describe the singularity quantitatively. We also calculate some
physical quantities using this method, such as the lifetime of the mediator
particle, and find that those could be significantly altered compared with the
result of the perturbative calculation.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08596" title="Abstract">arXiv:2310.08596</a> (cross-list from eess.IV) [<a href="/pdf/2310.08596" title="Download PDF">pdf</a>, <a href="/format/2310.08596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Lung Cancer&#x27;s Metastats&#x27; Locations Using Bioclinical Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>, 
<a href="/search/eess?searchtype=author&query=Bunimovich-Mendrazitsky%2C+S">Svetlana Bunimovich-Mendrazitsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Information Retrieval (cs.IR); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Lung cancer is a leading cause of cancer-related deaths worldwide. The spread
of the disease from its primary site to other parts of the lungs, known as
metastasis, significantly impacts the course of treatment. Early identification
of metastatic lesions is crucial for prompt and effective treatment, but
conventional imaging techniques have limitations in detecting small metastases.
In this study, we develop a bioclinical model for predicting the spatial spread
of lung cancer's metastasis using a three-dimensional computed tomography (CT)
scan. We used a three-layer biological model of cancer spread to predict
locations with a high probability of metastasis colonization. We validated the
bioclinical model on real-world data from 10 patients, showing promising 74%
accuracy in the metastasis location prediction. Our study highlights the
potential of the combination of biophysical and ML models to advance the way
that lung cancer is diagnosed and treated, by providing a more comprehensive
understanding of the spread of the disease and informing treatment decisions.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08598" title="Abstract">arXiv:2310.08598</a> (cross-list from eess.IV) [<a href="/pdf/2310.08598" title="Download PDF">pdf</a>, <a href="/format/2310.08598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization for Medical Image Analysis: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yoon%2C+J+S">Jee Seok Yoon</a>, 
<a href="/search/eess?searchtype=author&query=Oh%2C+K">Kwanseok Oh</a>, 
<a href="/search/eess?searchtype=author&query=Shin%2C+Y">Yooseung Shin</a>, 
<a href="/search/eess?searchtype=author&query=Mazurowski%2C+M+A">Maciej A. Mazurowski</a>, 
<a href="/search/eess?searchtype=author&query=Suk%2C+H">Heung-Il Suk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Medical Image Analysis (MedIA) has become an essential tool in medicine and
healthcare, aiding in disease diagnosis, prognosis, and treatment planning, and
recent successes in deep learning (DL) have made significant contributions to
its advances. However, DL models for MedIA remain challenging to deploy in
real-world situations, failing for generalization under the distributional gap
between training and testing samples, known as a distribution shift problem.
Researchers have dedicated their efforts to developing various DL methods to
adapt and perform robustly on unknown and out-of-distribution data
distributions. This paper comprehensively reviews domain generalization studies
specifically tailored for MedIA. We provide a holistic view of how domain
generalization techniques interact within the broader MedIA system, going
beyond methodologies to consider the operational implications on the entire
MedIA workflow. Specifically, we categorize domain generalization methods into
data-level, feature-level, model-level, and analysis-level methods. We show how
those methods can be used in various stages of the MedIA workflow with DL
equipped from data acquisition to model prediction and analysis. Furthermore,
we include benchmark datasets and applications used to evaluate these
approaches and analyze the strengths and weaknesses of various methods,
unveiling future research opportunities.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08600" title="Abstract">arXiv:2310.08600</a> (cross-list from math.OC) [<a href="/pdf/2310.08600" title="Download PDF">pdf</a>, <a href="/ps/2310.08600" title="Download PostScript">ps</a>, <a href="/format/2310.08600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ill-posedness of time-dependent inverse problems in Lebesgue-Bochner  spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burger%2C+M">Martin Burger</a>, 
<a href="/search/math?searchtype=author&query=Schuster%2C+T">Thomas Schuster</a>, 
<a href="/search/math?searchtype=author&query=Wald%2C+A">Anne Wald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider time-dependent inverse problems in a mathematical setting using
Lebesgue-Bochner spaces. Such problems arise when one aims to recover
parameters from given observations where the parameters or the data depend on
time. There are various important applications being subject of current
research that belong to this class of problems. Typically inverse problems are
ill-posed in the sense that already small noise in the data causes tremendous
errors in the solution. In this article we present two different concepts of
ill-posedness: temporally (pointwise) ill-posedness and uniform ill-posedness
with respect to the Lebesgue-Bochner setting. We investigate the two concepts
by means of a typical setting consisting of a time-depending observation
operator composed by a compact operator. Furthermore we develop regularization
methods that are adapted to the respective class of ill-posedness.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08601" title="Abstract">arXiv:2310.08601</a> (cross-list from math.OC) [<a href="/pdf/2310.08601" title="Download PDF">pdf</a>, <a href="/format/2310.08601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unit Commitment Predictor With a Performance Guarantee: A Support Vector  Machine Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pourahmadi%2C+F">Farzaneh Pourahmadi</a>, 
<a href="/search/math?searchtype=author&query=Kazempour%2C+J">Jalal Kazempour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">The system operators usually need to solve large-scale unit commitment
problems within limited time frame for computation. This paper provides a
pragmatic solution, showing how by learning and predicting the on/off
commitment decisions of conventional units, there is a potential for system
operators to warm start their solver and speed up their computation
significantly. For the prediction, we train linear and kernelized support
vector machine classifiers, providing an out-of-sample performance guarantee if
properly regularized, converting to distributionally robust classifiers. For
the unit commitment problem, we solve a mixed-integer second-order cone
problem. Our results based on the IEEE 6-bus and 118-bus test systems show that
the kernelized SVM with proper regularization outperforms other classifiers,
reducing the computational time by a factor of 1.7. In addition, if there is a
tight computational limit, while the unit commitment problem without warm start
is far away from the optimal solution, its warmly started version can be solved
to optimality within the time limit.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08608" title="Abstract">arXiv:2310.08608</a> (cross-list from eess.IV) [<a href="/pdf/2310.08608" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainVoxGen: Deep learning framework for synthesis of Ultrasound to MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+S">Shubham Singh</a>, 
<a href="/search/eess?searchtype=author&query=Bewoor%2C+D+M">Dr. Mrunal Bewoor</a>, 
<a href="/search/eess?searchtype=author&query=Ranapurwala%2C+A">Ammar Ranapurwala</a>, 
<a href="/search/eess?searchtype=author&query=Rai%2C+S">Satyam Rai</a>, 
<a href="/search/eess?searchtype=author&query=Patil%2C+S">Sheetal Patil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The study presents a deep learning framework aimed at synthesizing 3D MRI
volumes from three-dimensional ultrasound images of the brain utilizing the
Pix2Pix GAN model. The process involves inputting a 3D volume of ultrasounds
into a UNET generator and patch discriminator, generating a corresponding 3D
volume of MRI. Model performance was evaluated using losses on the
discriminator and generator applied to a dataset of 3D ultrasound and MRI
images. The results indicate that the synthesized MRI images exhibit some
similarity to the expected outcomes. Despite challenges related to dataset
size, computational resources, and technical complexities, the method
successfully generated MRI volume with a satisfactory similarity score meant to
serve as a baseline for further research. It underscores the potential of deep
learning-based volume synthesis techniques for ultrasound to MRI conversion,
showcasing their viability for medical applications. Further refinement and
exploration are warranted for enhanced clinical relevance.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08609" title="Abstract">arXiv:2310.08609</a> (cross-list from math.OC) [<a href="/pdf/2310.08609" title="Download PDF">pdf</a>, <a href="/format/2310.08609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized shock-protecting microstructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+Z">Zizhou Huang</a>, 
<a href="/search/math?searchtype=author&query=Panozzo%2C+D">Daniele Panozzo</a>, 
<a href="/search/math?searchtype=author&query=Zorin%2C+D">Denis Zorin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Mechanical shock is a common occurrence in various settings, there are two
different scenarios for shock protection: catastrophic protection (e.g. car
collisions and falls) and routine protection (e.g. shoe soles and shock
absorbers for car seats). The former protects against one-time events, the
latter against periodic shocks and loads. Common shock absorbers based on
plasticity and fracturing materials are suitable for the former, while our
focus is on the latter, where elastic structures are useful. Improved elastic
materials protecting against shock can be used in applications such as
automotive suspension, furniture like sofas and mattresses, landing gear
systems, etc. Materials offering optimal protection against shock have a highly
non-linear elastic response: their reaction force needs to be as close as
possible to constant with respect to deformation. In this paper, we use shape
optimization and topology search to design 2D families of microstructures
approximating the ideal behavior across a range of deformations, leading to
superior shock protection. We present an algorithmic pipeline for the optimal
design of such families combining differentiable nonlinear homogenization with
self-contact and an optimization algorithm. These advanced 2D designs can be
extruded and fabricated with existing 3D printing technologies. We validate
their effectiveness through experimental testing.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08613" title="Abstract">arXiv:2310.08613</a> (cross-list from q-bio.PE) [<a href="/pdf/2310.08613" title="Download PDF">pdf</a>, <a href="/format/2310.08613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individual Variation Affects Outbreak Magnitude and Predictability in an  Extended Multi-Pathogen SIR Model of Pigeons Vising Dairy Farms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>, 
<a href="/search/q-bio?searchtype=author&query=Spiegel%2C+O">Orr Spiegel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Computational Engineering, Finance, and Science (cs.CE); Information Retrieval (cs.IR); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Zoonotic disease transmission between animals and humans is a growing risk
and the agricultural context acts as a likely point of transition, with
individual heterogeneity acting as an important contributor. Thus,
understanding the dynamics of disease spread in the wildlife-livestock
interface is crucial for mitigating these risks of transmission. Specifically,
the interactions between pigeons and in-door cows at dairy farms can lead to
significant disease transmission and economic losses for farmers; putting
livestock, adjacent human populations, and other wildlife species at risk. In
this paper, we propose a novel spatio-temporal multi-pathogen model with
continuous spatial movement. The model expands on the
Susceptible-Exposed-Infected-Recovered-Dead (SEIRD) framework and accounts for
both within-species and cross-species transmission of pathogens, as well as the
exploration-exploitation movement dynamics of pigeons, which play a critical
role in the spread of infection agents. In addition to model formulation, we
also implement it as an agent-based simulation approach and use empirical field
data to investigate different biologically realistic scenarios, evaluating the
effect of various parameters on the epidemic spread. Namely, in agreement with
theoretical expectations, the model predicts that the heterogeneity of the
pigeons' movement dynamics can drastically affect both the magnitude and
stability of outbreaks. In addition, joint infection by multiple pathogens can
have an interactive effect unobservable in single-pathogen SIR models,
reflecting a non-intuitive inhibition of the outbreak. Our findings highlight
the impact of heterogeneity in host behavior on their pathogens and allow
realistic predictions of outbreak dynamics in the multi-pathogen
wildlife-livestock interface with consequences to zoonotic diseases in various
systems.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08614" title="Abstract">arXiv:2310.08614</a> (cross-list from eess.SP) [<a href="/pdf/2310.08614" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing of 3D MIMO Communication Beamforming in Linear and Planar  Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Roshanzamir%2C+A">Amirsadegh Roshanzamir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Massive multiple-input multiple-output (MIMO) systems are expected to play a
crucial role in the 5G wireless communication systems. These advanced systems,
which are being deployed since 2021, offer significant advantages over
conventional communications generations. Unlike previous versions of
communication, MIMO systems can transmit various probing signals through their
antennas, which may or may not be correlated with each other. This waveform
diversity provided by MIMO communication enables enhanced capabilities and
improved performance. Numerous research papers have proposed different
approaches for beamforming in MIMO communication. We anticipate that our
research will provide valuable insights into the performance of different
beamforming techniques for MIMO communication systems with planar arrays. We
will investigate the 3D beam patterns generated by these constellations using
the covariance-based MIMO communication waveform method. MATLAB simulations
will be utilized to analyze and evaluate the performance of these methods.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08663" title="Abstract">arXiv:2310.08663</a> (cross-list from math.CO) [<a href="/pdf/2310.08663" title="Download PDF">pdf</a>, <a href="/format/2310.08663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One n Remains to Settle the Tree Conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dippel%2C+J">Jack Dippel</a>, 
<a href="/search/math?searchtype=author&query=Vetta%2C+A">Adrian Vetta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In the famous network creation game of Fabrikant et al. a set of agents play
a game to build a connected graph. The $n$ agents form the vertex set $V$ of
the graph and each vertex $v\in V$ buys a set $E_v$ of edges inducing a graph
$G=(V,\bigcup\limits_{v\in V} E_v)$. The private objective of each vertex is to
minimize the sum of its building cost (the cost of the edges it buys) plus its
connection cost (the total distance from itself to every other vertex). Given a
cost of $\alpha$ for each individual edge, a long-standing conjecture, called
the tree conjecture, states that if $\alpha &gt; n$ then every Nash equilibrium
graph in the game is a spanning tree. After a plethora of work, it is known
that the conjecture holds for any $\alpha&gt;3n-3$. In this paper we prove the
tree conjecture holds for $\alpha&gt;2n$. This reduces by half the open range for
$\alpha$ with only $[n, 2n)$ remaining in order to settle the conjecture.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08672" title="Abstract">arXiv:2310.08672</a> (cross-list from econ.EM) [<a href="/pdf/2310.08672" title="Download PDF">pdf</a>, <a href="/format/2310.08672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Who to Nudge: Causal vs Predictive Targeting in a Field  Experiment on Student Financial Aid Renewal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Athey%2C+S">Susan Athey</a>, 
<a href="/search/econ?searchtype=author&query=Keleher%2C+N">Niall Keleher</a>, 
<a href="/search/econ?searchtype=author&query=Spiess%2C+J">Jann Spiess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">In many settings, interventions may be more effective for some individuals
than others, so that targeting interventions may be beneficial. We analyze the
value of targeting in the context of a large-scale field experiment with over
53,000 college students, where the goal was to use "nudges" to encourage
students to renew their financial-aid applications before a non-binding
deadline. We begin with baseline approaches to targeting. First, we target
based on a causal forest that estimates heterogeneous treatment effects and
then assigns students to treatment according to those estimated to have the
highest treatment effects. Next, we evaluate two alternative targeting
policies, one targeting students with low predicted probability of renewing
financial aid in the absence of the treatment, the other targeting those with
high probability. The predicted baseline outcome is not the ideal criterion for
targeting, nor is it a priori clear whether to prioritize low, high, or
intermediate predicted probability. Nonetheless, targeting on low baseline
outcomes is common in practice, for example because the relationship between
individual characteristics and treatment effects is often difficult or
impossible to estimate with historical data. We propose hybrid approaches that
incorporate the strengths of both predictive approaches (accurate estimation)
and causal approaches (correct criterion); we show that targeting intermediate
baseline outcomes is most effective, while targeting based on low baseline
outcomes is detrimental. In one year of the experiment, nudging all students
improved early filing by an average of 6.4 percentage points over a baseline
average of 37% filing, and we estimate that targeting half of the students
using our preferred policy attains around 75% of this benefit.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08696" title="Abstract">arXiv:2310.08696</a> (cross-list from eess.AS) [<a href="/pdf/2310.08696" title="Download PDF">pdf</a>, <a href="/format/2310.08696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Online Speaker Diarization with Target Speaker Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Weiqing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">This paper proposes an online target speaker voice activity detection system
for speaker diarization tasks, which does not require a priori knowledge from
the clustering-based diarization system to obtain the target speaker
embeddings. By adapting the conventional target speaker voice activity
detection for real-time operation, this framework can identify speaker
activities using self-generated embeddings, resulting in consistent performance
without permutation inconsistencies in the inference phase. During the
inference process, we employ a front-end model to extract the frame-level
speaker embeddings for each coming block of a signal. Next, we predict the
detection state of each speaker based on these frame-level speaker embeddings
and the previously estimated target speaker embedding. Then, the target speaker
embeddings are updated by aggregating these frame-level speaker embeddings
according to the predictions in the current block. Our model predicts the
results for each block and updates the target speakers' embeddings until
reaching the end of the signal. Experimental results show that the proposed
method outperforms the offline clustering-based diarization system on the
DIHARD III and AliMeeting datasets. The proposed method is further extended to
multi-channel data, which achieves similar performance with the
state-of-the-art offline diarization systems.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08717" title="Abstract">arXiv:2310.08717</a> (cross-list from physics.data-an) [<a href="/pdf/2310.08717" title="Download PDF">pdf</a>, <a href="/format/2310.08717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Observables for Measurements with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Long%2C+O">Owen Long</a>, 
<a href="/search/physics?searchtype=author&query=Nachman%2C+B">Benjamin Nachman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to EPJC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">Many analyses in particle and nuclear physics use simulations to infer
fundamental, effective, or phenomenological parameters of the underlying
physics models. When the inference is performed with unfolded cross sections,
the observables are designed using physics intuition and heuristics. We propose
to design optimal observables with machine learning. Unfolded, differential
cross sections in a neural network output contain the most information about
parameters of interest and can be well-measured by construction. We demonstrate
this idea using two physics models for inclusive measurements in deep inelastic
scattering.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08756" title="Abstract">arXiv:2310.08756</a> (cross-list from eess.IV) [<a href="/pdf/2310.08756" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Scoliosis Screening and Diagnosis: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhenlin%2C+Z">Zhang Zhenlin</a>, 
<a href="/search/eess?searchtype=author&query=Lixin%2C+P">Pu Lixin</a>, 
<a href="/search/eess?searchtype=author&query=Ang%2C+L">Li Ang</a>, 
<a href="/search/eess?searchtype=author&query=Jun%2C+Z">Zhang Jun</a>, 
<a href="/search/eess?searchtype=author&query=Xianjie%2C+L">Li Xianjie</a>, 
<a href="/search/eess?searchtype=author&query=Jipeng%2C+F">Fan Jipeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Scoliosis is a three-dimensional spinal deformity, which may lead to abnormal
morphologies, such as thoracic deformity, and pelvic tilt. Severe patients may
suffer from nerve damage and urinary abnormalities. At present, the number of
scoliosis patients in primary and secondary schools has exceeded five million
in China, the incidence rate is about 3% to 5% which is growing every year. The
research on scoliosis, therefore, has important clinical value. This paper
systematically introduces computer-assisted scoliosis screening and diagnosis
as well as analyzes the advantages and limitations of different algorithm
models in the current issue field. Moreover, the paper also discusses the
current development bottlenecks in this field and looks forward to future
development trends.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08767" title="Abstract">arXiv:2310.08767</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2310.08767" title="Download PDF">pdf</a>, <a href="/format/2310.08767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Fission Gas Release at the Mesoscale using Multiscale DenseNet  Regression with Attention Mechanism and Inception Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Toma%2C+P">Peter Toma</a>, 
<a href="/search/cond-mat?searchtype=author&query=Muntaha%2C+M+A">Md Ali Muntaha</a>, 
<a href="/search/cond-mat?searchtype=author&query=Harley%2C+J+B">Joel B. Harley</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tonks%2C+M+R">Michael R. Tonks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted at Journal of Nuclear Materials, 20 pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mesoscale simulations of fission gas release (FGR) in nuclear fuel provide a
powerful tool for understanding how microstructure evolution impacts FGR, but
they are computationally intensive. In this study, we present an alternate,
data-driven approach, using deep learning to predict instantaneous FGR flux
from 2D nuclear fuel microstructure images. Four convolutional neural network
(CNN) architectures with multiscale regression are trained and evaluated on
simulated FGR data generated using a hybrid phase field/cluster dynamics model.
All four networks show high predictive power, with $R^{2}$ values above 98%.
The best performing network combine a Convolutional Block Attention Module
(CBAM) and InceptionNet mechanisms to provide superior accuracy (mean absolute
percentage error of 4.4%), training stability, and robustness on very low
instantaneous FGR flux values.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08774" title="Abstract">arXiv:2310.08774</a> (cross-list from q-bio.PE) [<a href="/pdf/2310.08774" title="Download PDF">pdf</a>, <a href="/format/2310.08774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhyloGFN: Phylogenetic inference with generative flow networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+M">Mingyang Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+Z">Zichao Yan</a>, 
<a href="/search/q-bio?searchtype=author&query=Layne%2C+E">Elliot Layne</a>, 
<a href="/search/q-bio?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+D">Dinghuai Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Jain%2C+M">Moksh Jain</a>, 
<a href="/search/q-bio?searchtype=author&query=Blanchette%2C+M">Mathieu Blanchette</a>, 
<a href="/search/q-bio?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Phylogenetics is a branch of computational biology that studies the
evolutionary relationships among biological entities. Its long history and
numerous applications notwithstanding, inference of phylogenetic trees from
sequence data remains challenging: the high complexity of tree space poses a
significant obstacle for the current combinatorial and probabilistic
techniques. In this paper, we adopt the framework of generative flow networks
(GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and
Bayesian phylogenetic inference. Because GFlowNets are well-suited for sampling
complex combinatorial structures, they are a natural choice for exploring and
sampling from the multimodal posterior distribution over tree topologies and
evolutionary distances. We demonstrate that our amortized posterior sampler,
PhyloGFN, produces diverse and high-quality evolutionary hypotheses on real
benchmark datasets. PhyloGFN is competitive with prior works in marginal
likelihood estimation and achieves a closer fit to the target distribution than
state-of-the-art variational inference methods.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08789" title="Abstract">arXiv:2310.08789</a> (cross-list from eess.SP) [<a href="/pdf/2310.08789" title="Download PDF">pdf</a>, <a href="/format/2310.08789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quickest Change Detection in Autoregressive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhongchang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+S">Shaofeng Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The problem of quickest change detection (QCD) in autoregressive (AR) models
is investigated. A system is being monitored with sequentially observed
samples. At some unknown time, a disturbance signal occurs and changes the
distribution of the observations. The disturbance signal follows an AR model,
which is dependent over time. Before the change, observations only consist of
measurement noise, and are independent and identically distributed (i.i.d.).
After the change, observations consist of the disturbance signal and the
measurement noise, are dependent over time, which essentially follow a
continuous-state hidden Markov model (HMM). The goal is to design a stopping
time to detect the disturbance signal as quickly as possible subject to false
alarm constraints. Existing approaches for general non-i.i.d. settings and
discrete-state HMMs cannot be applied due to their high computational
complexity and memory consumption, and they usually assume some asymptotic
stability condition. In this paper, the asymptotic stability condition is
firstly theoretically proved for the AR model by a novel design of forward
variable and auxiliary Markov chain. A computationally efficient Ergodic CuSum
algorithm that can be updated recursively is then constructed and is further
shown to be asymptotically optimal. The data-driven setting where the
disturbance signal parameters are unknown is further investigated, and an
online and computationally efficient gradient ascent CuSum algorithm is
designed. The algorithm is constructed by iteratively updating the estimate of
the unknown parameters based on the maximum likelihood principle and the
gradient ascent approach. The lower bound on its average running length to
false alarm is also derived for practical false alarm control. Simulation
results are provided to demonstrate the performance of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08805" title="Abstract">arXiv:2310.08805</a> (cross-list from eess.IV) [<a href="/pdf/2310.08805" title="Download PDF">pdf</a>, <a href="/format/2310.08805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Stage Deep Learning Framework for Quality Assessment of Left Atrial  Late Gadolinium Enhanced MRI Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sultan%2C+K+M+A">K M Arefeen Sultan</a>, 
<a href="/search/eess?searchtype=author&query=Orkild%2C+B">Benjamin Orkild</a>, 
<a href="/search/eess?searchtype=author&query=Morris%2C+A">Alan Morris</a>, 
<a href="/search/eess?searchtype=author&query=Kholmovski%2C+E">Eugene Kholmovski</a>, 
<a href="/search/eess?searchtype=author&query=Bieging%2C+E">Erik Bieging</a>, 
<a href="/search/eess?searchtype=author&query=Kwan%2C+E">Eugene Kwan</a>, 
<a href="/search/eess?searchtype=author&query=Ranjan%2C+R">Ravi Ranjan</a>, 
<a href="/search/eess?searchtype=author&query=DiBella%2C+E">Ed DiBella</a>, 
<a href="/search/eess?searchtype=author&query=Elhabian%2C+S">Shireen Elhabian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to STACOM 2023. 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate assessment of left atrial fibrosis in patients with atrial
fibrillation relies on high-quality 3D late gadolinium enhancement (LGE) MRI
images. However, obtaining such images is challenging due to patient motion,
changing breathing patterns, or sub-optimal choice of pulse sequence
parameters. Automated assessment of LGE-MRI image diagnostic quality is
clinically significant as it would enhance diagnostic accuracy, improve
efficiency, ensure standardization, and contributes to better patient outcomes
by providing reliable and high-quality LGE-MRI scans for fibrosis
quantification and treatment planning. To address this, we propose a two-stage
deep-learning approach for automated LGE-MRI image diagnostic quality
assessment. The method includes a left atrium detector to focus on relevant
regions and a deep network to evaluate diagnostic quality. We explore two
training strategies, multi-task learning, and pretraining using contrastive
learning, to overcome limited annotated data in medical imaging. Contrastive
Learning result shows about $4\%$, and $9\%$ improvement in F1-Score and
Specificity compared to Multi-Task learning when there's limited data.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08812" title="Abstract">arXiv:2310.08812</a> (cross-list from stat.ME) [<a href="/pdf/2310.08812" title="Download PDF">pdf</a>, <a href="/format/2310.08812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nonlinear Method for time series forecasting using VMD-GARCH-LSTM  model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gui%2C+Z">Zhengtao Gui</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+S">Sijie Xu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Time series forecasting represents a significant and challenging task across
various fields. Recently, methods based on mode decomposition have dominated
the forecasting of complex time series because of the advantages of capturing
local characteristics and extracting intrinsic modes from data. Unfortunately,
most models fail to capture the implied volatilities that contain significant
information. To enhance the forecasting of current, rapidly evolving, and
volatile time series, we propose a novel decomposition-ensemble paradigm, the
VMD-LSTM-GARCH model. The Variational Mode Decomposition algorithm is employed
to decompose the time series into K sub-modes. Subsequently, the GARCH model
extracts the volatility information from these sub-modes, which serve as the
input for the LSTM. The numerical and volatility information of each sub-mode
is utilized to train a Long Short-Term Memory network. This network predicts
the sub-mode, and then we aggregate the predictions from all sub-modes to
produce the output. By integrating econometric and artificial intelligence
methods, and taking into account both the numerical and volatility information
of the time series, our proposed model demonstrates superior performance in
time series forecasting, as evidenced by the significant decrease in MSE, RMSE,
and MAPE in our comparative experimental results.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08814" title="Abstract">arXiv:2310.08814</a> (cross-list from physics.optics) [<a href="/pdf/2310.08814" title="Download PDF">pdf</a>, <a href="/format/2310.08814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PT-symmetry enabled stable modes in multi-core fiber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gratcheva%2C+T">Tamara Gratcheva</a>, 
<a href="/search/physics?searchtype=author&query=Joglekar%2C+Y+N">Yogesh N. Joglekar</a>, 
<a href="/search/physics?searchtype=author&query=Gopalakrishnan%2C+J">Jay Gopalakrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Numerical Analysis (math.NA); Spectral Theory (math.SP)

</div>
<p class="mathjax">Open systems with balanced gain and loss, described by parity-time
(PT-symmetric) Hamiltonians have been deeply explored over the past decade.
Most explorations are limited to finite discrete models (in real or reciprocal
spaces) or continuum problems in one dimension. As a result, these models do
not leverage the complexity and variability of two-dimensional continuum
problems on a compact support. Here, we investigate eigenvalues of
non-relativistic Schrodinger equation on a disk with open boundary condition,
in the presence of constant, PT-symmetric, gain-loss potential that is confined
to two mirror-symmetric disks. We find a rich variety of exceptional points,
re-entrant PT-symmetric phases, and a non-monotonic dependence of the
PT-symmetry breaking threshold on the system parameters. By comparing results
of two model variations, we show that this simple model of a multi-core fiber
supports propagating modes in the presence of gain and loss.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08834" title="Abstract">arXiv:2310.08834</a> (cross-list from physics.med-ph) [<a href="/pdf/2310.08834" title="Download PDF">pdf</a>, <a href="/format/2310.08834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D Slice-driven Physics-based 3D Motion Estimation Framework for  Pancreatic Radiotherapy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hara%2C+Y">Yuki Hara</a>, 
<a href="/search/physics?searchtype=author&query=Kadoya%2C+N">Noriyuki Kadoya</a>, 
<a href="/search/physics?searchtype=author&query=Mitsume%2C+N">Naoto Mitsume</a>, 
<a href="/search/physics?searchtype=author&query=Ienaga%2C+N">Naoto Ienaga</a>, 
<a href="/search/physics?searchtype=author&query=Umezawa%2C+R">Rei Umezawa</a>, 
<a href="/search/physics?searchtype=author&query=Jingu%2C+K">Keiichi Jingu</a>, 
<a href="/search/physics?searchtype=author&query=Kuroda%2C+Y">Yoshihiro Kuroda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Pancreatic diseases are difficult to treat with high doses of radiation, as
they often present both periodic and aperiodic deformations. Nevertheless, we
expect that these difficulties can be overcome, and treatment results may be
improved with the practical use of a device that can capture 2D slices of
organs during irradiation. However, since only a few 2D slices can be taken,
the 3D motion needs to be estimated from partially observed information. In
this study, we propose a physics-based framework for estimating the 3D motion
of organs, regardless of periodicity, from motion information obtained by 2D
slices in one or more directions and a regression model that estimates the
accuracy of the proposed framework to select the optimal slice. Using
information obtained by slice-to-slice registration and setting the surrounding
organs as boundaries, the framework drives the physical models for estimating
3D motion. The R2 score of the proposed regression model was greater than 0.9,
and the RMSE was 0.357 mm. The mean errors were 5.11 $\pm$ 1.09 mm using an
axial slice and 2.13 $\pm$ 0.598 mm using concurrent axial, sagittal, and
coronal slices. Our results suggest that the proposed framework is comparable
to volume-to-volume registration, and is feasible.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08858" title="Abstract">arXiv:2310.08858</a> (cross-list from math.OC) [<a href="/pdf/2310.08858" title="Download PDF">pdf</a>, <a href="/format/2310.08858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adam-family Methods with Decoupled Weight Decay in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ding%2C+K">Kuangyu Ding</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+N">Nachuan Xiao</a>, 
<a href="/search/math?searchtype=author&query=Toh%2C+K">Kim-Chuan Toh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we investigate the convergence properties of a wide class of
Adam-family methods for minimizing quadratically regularized nonsmooth
nonconvex optimization problems, especially in the context of training
nonsmooth neural networks with weight decay. Motivated by the AdamW method, we
propose a novel framework for Adam-family methods with decoupled weight decay.
Within our framework, the estimators for the first-order and second-order
moments of stochastic subgradients are updated independently of the weight
decay term. Under mild assumptions and with non-diminishing stepsizes for
updating the primary optimization variables, we establish the convergence
properties of our proposed framework. In addition, we show that our proposed
framework encompasses a wide variety of well-known Adam-family methods, hence
offering convergence guarantees for these methods in the training of nonsmooth
neural networks. More importantly, we show that our proposed framework
asymptotically approximates the SGD method, thereby providing an explanation
for the empirical observation that decoupled weight decay enhances
generalization performance for Adam-family methods. As a practical application
of our proposed framework, we propose a novel Adam-family method named Adam
with Decoupled Weight Decay (AdamD), and establish its convergence properties
under mild conditions. Numerical experiments demonstrate that AdamD outperforms
Adam and is comparable to AdamW, in the aspects of both generalization
performance and efficiency.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08870" title="Abstract">arXiv:2310.08870</a> (cross-list from quant-ph) [<a href="/pdf/2310.08870" title="Download PDF">pdf</a>, <a href="/format/2310.08870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A one-query lower bound for unitary synthesis and breaking quantum  cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lombardi%2C+A">Alex Lombardi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ma%2C+F">Fermi Ma</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wright%2C+J">John Wright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The Unitary Synthesis Problem (Aaronson-Kuperberg 2007) asks whether any
$n$-qubit unitary $U$ can be implemented by an efficient quantum algorithm $A$
augmented with an oracle that computes an arbitrary Boolean function $f$. In
other words, can the task of implementing any unitary be efficiently reduced to
the task of implementing any Boolean function?
<br />In this work, we prove a one-query lower bound for unitary synthesis. We show
that there exist unitaries $U$ such that no quantum polynomial-time oracle
algorithm $A^f$ can implement $U$, even approximately, if it only makes one
(quantum) query to $f$. Our approach also has implications for quantum
cryptography: we prove (relative to a random oracle) the existence of quantum
cryptographic primitives that remain secure against all one-query adversaries
$A^{f}$. Since such one-query algorithms can decide any language, solve any
classical search problem, and even prepare any quantum state, our result
suggests that implementing random unitaries and breaking quantum cryptography
may be harder than all of these tasks.
<br />To prove this result, we formulate unitary synthesis as an efficient
challenger-adversary game, which enables proving lower bounds by analyzing the
maximum success probability of an adversary $A^f$. Our main technical insight
is to identify a natural spectral relaxation of the one-query optimization
problem, which we bound using tools from random matrix theory.
<br />We view our framework as a potential avenue to rule out polynomial-query
unitary synthesis, and we state conjectures in this direction.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08897" title="Abstract">arXiv:2310.08897</a> (cross-list from eess.IV) [<a href="/pdf/2310.08897" title="Download PDF">pdf</a>, <a href="/format/2310.08897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self supervised convolutional kernel based handcrafted feature  harmonization: Enhanced left ventricle hypertension disease phenotyping on  echocardiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jina Lee</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+Y">Youngtaek Hong</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+D">Dawun Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Jang%2C+Y">Yeonggul Jang</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+S">Sihyeon Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+T">Taekgeun Jung</a>, 
<a href="/search/eess?searchtype=author&query=Yoon%2C+Y+E">Yeonyee E. Yoon</a>, 
<a href="/search/eess?searchtype=author&query=Moon%2C+I">Inki Moon</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seung-Ah Lee</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+H">Hyuk-Jae Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Radiomics, a medical imaging technique, extracts quantitative handcrafted
features from images to predict diseases. Harmonization in those features
ensures consistent feature extraction across various imaging devices and
protocols. Methods for harmonization include standardized imaging protocols,
statistical adjustments, and evaluating feature robustness. Myocardial diseases
such as Left Ventricular Hypertrophy (LVH) and Hypertensive Heart Disease (HHD)
are diagnosed via echocardiography, but variable imaging settings pose
challenges. Harmonization techniques are crucial for applying handcrafted
features in disease diagnosis in such scenario. Self-supervised learning (SSL)
enhances data understanding within limited datasets and adapts to diverse data
settings. ConvNeXt-V2 integrates convolutional layers into SSL, displaying
superior performance in various tasks. This study focuses on convolutional
filters within SSL, using them as preprocessing to convert images into feature
maps for handcrafted feature harmonization. Our proposed method excelled in
harmonization evaluation and exhibited superior LVH classification performance
compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08935" title="Abstract">arXiv:2310.08935</a> (cross-list from math.PR) [<a href="/pdf/2310.08935" title="Download PDF">pdf</a>, <a href="/ps/2310.08935" title="Download PostScript">ps</a>, <a href="/format/2310.08935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proofs of the Ethier and Lee slot machine conjectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liang%2C+H">Huaijin Liang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zengjing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Suppose a gambler pays one coin per coup to play a two-armed Futurity slot
machine, an antique casinos, and two coins are refunded for every two
consecutive gambler losses. This payoff is called the Futurity award. The
casino owner honestly advertises that each arm on his/her two-armed machine is
fair in the sense that the asymptotic expected profit of both gambler and
dealer is 0 if the gambler only plays either arm. The gambler is allowed to
play either arm on each coup alternatively in some deterministic order or at
random. For almost 90 years, since Futurity slot machines is designed in 1936,
an open problem that has not been solved for a long time is whether the slot
machine will obey the so-called "long bet will lose" phenomenon so common to
casino games. Ethier and Lee [Ann. Appl. Proba. 20(2010), pp.1098-1125]
conjectured that a player will also definitely lose in the long run by applying
any non-random-mixture strategy. In this paper, we shall prove Ethier and Lee's
conjecture. Our result with Ethier and Lee's conclusion straightforwardly
demonstrates that players decide to use either random or non-random two-arm
strategies before playing and then repeated without interruption, the casino
owners are always profitable even when the Futurity award is taken into
account. The contribution of this work is that it helps complete the
demystification of casino profitability. Moreover, it paves the way for casino
owners to improve casino game design and for players to participate effectively
in gambling.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08968" title="Abstract">arXiv:2310.08968</a> (cross-list from physics.soc-ph) [<a href="/pdf/2310.08968" title="Download PDF">pdf</a>, <a href="/format/2310.08968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The academic Great Gatsby Curve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sun%2C+Y">Ye Sun</a>, 
<a href="/search/physics?searchtype=author&query=Caccioli%2C+F">Fabio Caccioli</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+X">Xiancheng Li</a>, 
<a href="/search/physics?searchtype=author&query=Livan%2C+G">Giacomo Livan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">The Great Gatsby Curve measures the relationship between income inequality
and intergenerational income persistence. By utilizing genealogical data of
over 245,000 mentor-mentee pairs and their academic publications from 22
different disciplines, this study demonstrates that an academic Great Gatsby
Curve exists as well, in the form of a positive correlation between academic
impact inequality and the persistence of impact across academic generations. We
also provide a detailed breakdown of academic persistence, showing that the
correlation between the impact of mentors and that of their mentees has
increased over time, indicating an overall decrease in academic
intergenerational mobility. We analyze such persistence across a variety of
dimensions, including mentorship types, gender, and institutional prestige.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08974" title="Abstract">arXiv:2310.08974</a> (cross-list from physics.ins-det) [<a href="/pdf/2310.08974" title="Download PDF">pdf</a>, <a href="/format/2310.08974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Track Lab: extensible data acquisition software for fast pixel  detectors, online analysis and automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=M%C3%A1nek%2C+P">Petr M&#xe1;nek</a>, 
<a href="/search/physics?searchtype=author&query=Burian%2C+P">Petr Burian</a>, 
<a href="/search/physics?searchtype=author&query=David-Bosne%2C+E">Eric David-Bosne</a>, 
<a href="/search/physics?searchtype=author&query=Smolyanskiy%2C+P">Petr Smolyanskiy</a>, 
<a href="/search/physics?searchtype=author&query=Bergmann%2C+B">Benedikt Bergmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 24th International Workshop on Radiation Imaging Detectors (IWORID 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Fast, incremental evolution of physics instrumentation raises the question of
efficient software abstraction and transferability of algorithms across similar
technologies. This contribution aims to provide an answer by introducing Track
Lab, a modern data acquisition program focusing on extensibility and high
performance. Shipping with documented API and more than 20 standard modules,
Track Lab allows complex analysis pipelines to be constructed from simple,
reusable building blocks. Thanks to multi-threaded infrastructure, data can be
clustered, filtered, aggregated and plotted concurrently in real-time. In
addition, full hardware support for Timepix2, Timepix3 pixel detectors and
embedded photomultiplier systems enables such analysis to be carried out online
during data acquisition. Repetitive procedures can be automated with support
for motorized stages and X-ray tubes. Freely distributed on 7 popular operating
systems and 2 CPU architectures, Track Lab is a versatile tool for high energy
physics research.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09099" title="Abstract">arXiv:2310.09099</a> (cross-list from eess.IV) [<a href="/pdf/2310.09099" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster 3D cardiac CT segmentation with Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jollans%2C+L">Lee Jollans</a>, 
<a href="/search/eess?searchtype=author&query=Bustamante%2C+M">Mariana Bustamante</a>, 
<a href="/search/eess?searchtype=author&query=Henriksson%2C+L">Lilian Henriksson</a>, 
<a href="/search/eess?searchtype=author&query=Persson%2C+A">Anders Persson</a>, 
<a href="/search/eess?searchtype=author&query=Ebbers%2C+T">Tino Ebbers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate segmentation of the heart is essential for personalized blood flow
simulations and surgical intervention planning. A recent advancement in image
recognition is the Vision Transformer (ViT), which expands the field of view to
encompass a greater portion of the global image context. We adapted ViT for
three-dimensional volume inputs. Cardiac computed tomography (CT) volumes from
39 patients, featuring up to 20 timepoints representing the complete cardiac
cycle, were utilized. Our network incorporates a modified ResNet50 block as
well as a ViT block and employs cascade upsampling with skip connections.
Despite its increased model complexity, our hybrid Transformer-Residual U-Net
framework, termed TRUNet, converges in significantly less time than residual
U-Net while providing comparable or superior segmentations of the left
ventricle, left atrium, left atrial appendage, ascending aorta, and pulmonary
veins. TRUNet offers more precise vessel boundary segmentation and better
captures the heart's overall anatomical structure compared to residual U-Net,
as confirmed by the absence of extraneous clusters of missegmented voxels. In
terms of both performance and training speed, TRUNet exceeded U-Net, a commonly
used segmentation architecture, making it a promising tool for 3D semantic
segmentation tasks in medical imaging. The code for TRUNet is available at
github.com/ljollans/TRUNet.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09123" title="Abstract">arXiv:2310.09123</a> (cross-list from stat.ML) [<a href="/pdf/2310.09123" title="Download PDF">pdf</a>, <a href="/format/2310.09123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Music Playlist Generation via Simulation-based Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tomasi%2C+F">Federico Tomasi</a>, 
<a href="/search/stat?searchtype=author&query=Cauteruccio%2C+J">Joseph Cauteruccio</a>, 
<a href="/search/stat?searchtype=author&query=Kanoria%2C+S">Surya Kanoria</a>, 
<a href="/search/stat?searchtype=author&query=Ciosek%2C+K">Kamil Ciosek</a>, 
<a href="/search/stat?searchtype=author&query=Rinaldi%2C+M">Matteo Rinaldi</a>, 
<a href="/search/stat?searchtype=author&query=Dai%2C+Z">Zhenwen Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. KDD 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Personalization of playlists is a common feature in music streaming services,
but conventional techniques, such as collaborative filtering, rely on explicit
assumptions regarding content quality to learn how to make recommendations.
Such assumptions often result in misalignment between offline model objectives
and online user satisfaction metrics. In this paper, we present a reinforcement
learning framework that solves for such limitations by directly optimizing for
user satisfaction metrics via the use of a simulated playlist-generation
environment. Using this simulator we develop and train a modified Deep
Q-Network, the action head DQN (AH-DQN), in a manner that addresses the
challenges imposed by the large state and action space of our RL formulation.
The resulting policy is capable of making recommendations from large and
dynamic sets of candidate items with the expectation of maximizing consumption
metrics. We analyze and evaluate agents offline via simulations that use
environment models trained on both public and proprietary streaming datasets.
We show how these agents lead to better user-satisfaction metrics compared to
baseline methods during online A/B tests. Finally, we demonstrate that
performance assessments produced from our simulator are strongly correlated
with observed online metric results.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09126" title="Abstract">arXiv:2310.09126</a> (cross-list from eess.IV) [<a href="/pdf/2310.09126" title="Download PDF">pdf</a>, <a href="/format/2310.09126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-guided Noise Neural Proxy for Low-light Raw Image Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+H">Hansen Feng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiqi Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuzhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Hua Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Low-light raw image denoising plays a crucial role in mobile photography, and
learning-based methods have become the mainstream approach. Training the
learning-based methods with synthetic data emerges as an efficient and
practical alternative to paired real data. However, the quality of synthetic
data is inherently limited by the low accuracy of the noise model, which
decreases the performance of low-light raw image denoising. In this paper, we
develop a novel framework for accurate noise modeling that learns a
physics-guided noise neural proxy (PNNP) from dark frames. PNNP integrates
three efficient techniques: physics-guided noise decoupling (PND),
physics-guided proxy model (PPM), and differentiable distribution-oriented loss
(DDL). The PND decouples the dark frame into different components and handles
different levels of noise in a flexible manner, which reduces the complexity of
the noise neural proxy. The PPM incorporates physical priors to effectively
constrain the generated noise, which promotes the accuracy of the noise neural
proxy. The DDL provides explicit and reliable supervision for noise modeling,
which promotes the precision of the noise neural proxy. Extensive experiments
on public low-light raw image denoising datasets and real low-light imaging
scenarios demonstrate the superior performance of our PNNP framework.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09128" title="Abstract">arXiv:2310.09128</a> (cross-list from math.CO) [<a href="/pdf/2310.09128" title="Download PDF">pdf</a>, <a href="/ps/2310.09128" title="Download PostScript">ps</a>, <a href="/format/2310.09128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isolation of squares in graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartolo%2C+K">Karl Bartolo</a>, 
<a href="/search/math?searchtype=author&query=Borg%2C+P">Peter Borg</a>, 
<a href="/search/math?searchtype=author&query=Scicluna%2C+D">Dayle Scicluna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure. arXiv admin note: text overlap with <a href="/abs/2110.03773">arXiv:2110.03773</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Given a set $\mathcal{F}$ of graphs, we call a copy of a graph in
$\mathcal{F}$ an $\mathcal{F}$-graph. The $\mathcal{F}$-isolation number of a
graph $G$, denoted by $\iota(G,\mathcal{F})$, is the size of a smallest subset
$D$ of the vertex set $V(G)$ such that the closed neighbourhood of $D$
intersects the vertex sets of the $\mathcal{F}$-graphs contained by $G$
(equivalently, $G - N[D]$ contains no $\mathcal{F}$-graph). Thus,
$\iota(G,\{K_1\})$ is the domination number of $G$. The second author showed
that if $\mathcal{F}$ is the set of cycles and $G$ is a connected $n$-vertex
graph that is not a triangle, then $\iota(G,\mathcal{F}) \leq \left \lfloor
\frac{n}{4} \right \rfloor$. This bound is attainable for every $n$ and solved
a problem of Caro and Hansberg. A question that arises immediately is how
smaller an upper bound can be if $\mathcal{F} = \{C_k\}$ for some $k \geq 3$,
where $C_k$ is a cycle of length $k$. The problem is to determine the smallest
real number $c_k$ (if it exists) such that for some finite set $\mathcal{E}_k$
of graphs, $\iota(G, \{C_k\}) \leq c_k |V(G)|$ for every connected graph $G$
that is not an $\mathcal{E}_k$-graph. The above-mentioned result yields $c_3 =
\frac{1}{4}$ and $\mathcal{E}_3 = \{C_3\}$. The second author also showed that
if $k \geq 5$ and $c_k$ exists, then $c_k \geq \frac{2}{2k + 1}$. We prove that
$c_4 = \frac{1}{5}$ and determine $\mathcal{E}_4$, which consists of three
$4$-vertex graphs and six $9$-vertex graphs. The $9$-vertex graphs in
$\mathcal{E}_4$ were fully determined by means of a computer program. A method
that has the potential of yielding similar results is introduced.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09131" title="Abstract">arXiv:2310.09131</a> (cross-list from physics.soc-ph) [<a href="/pdf/2310.09131" title="Download PDF">pdf</a>, <a href="/format/2310.09131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning-based prediction of Q-voter model in complex networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pineda%2C+A+M">Aruane M. Pineda</a>, 
<a href="/search/physics?searchtype=author&query=Kent%2C+P">Paul Kent</a>, 
<a href="/search/physics?searchtype=author&query=Connaughton%2C+C">Colm Connaughton</a>, 
<a href="/search/physics?searchtype=author&query=Rodrigues%2C+F+A">Francisco A. Rodrigues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Statistical Mechanics: Theory and Experiment (JSTAT),
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this article, we consider machine learning algorithms to accurately
predict two variables associated with the $Q$-voter model in complex networks,
i.e., (i) the consensus time and (ii) the frequency of opinion changes.
Leveraging nine topological measures of the underlying networks, we verify that
the clustering coefficient (C) and information centrality (IC) emerge as the
most important predictors for these outcomes. Notably, the machine learning
algorithms demonstrate accuracy across three distinct initialization methods of
the $Q$-voter model, including random selection and the involvement of high-
and low-degree agents with positive opinions. By unraveling the intricate
interplay between network structure and dynamics, this research sheds light on
the underlying mechanisms responsible for polarization effects and other
dynamic patterns in social systems. Adopting a holistic approach that
comprehends the complexity of network systems, this study offers insights into
the intricate dynamics associated with polarization effects and paves the way
for investigating the structure and dynamics of complex systems through modern
machine learning methods.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09149" title="Abstract">arXiv:2310.09149</a> (cross-list from stat.ML) [<a href="/pdf/2310.09149" title="Download PDF">pdf</a>, <a href="/ps/2310.09149" title="Download PostScript">ps</a>, <a href="/format/2310.09149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice Approximations in Wasserstein Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hamm%2C+K">Keaton Hamm</a>, 
<a href="/search/stat?searchtype=author&query=Khurana%2C+V">Varun Khurana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider structured approximation of measures in Wasserstein space
$W_p(\mathbb{R}^d)$ for $p\in[1,\infty)$ by discrete and piecewise constant
measures based on a scaled Voronoi partition of $\mathbb{R}^d$. We show that if
a full rank lattice $\Lambda$ is scaled by a factor of $h\in(0,1]$, then
approximation of a measure based on the Voronoi partition of $h\Lambda$ is
$O(h)$ regardless of $d$ or $p$. We then use a covering argument to show that
$N$-term approximations of compactly supported measures is $O(N^{-\frac1d})$
which matches known rates for optimal quantizers and empirical measure
approximation in most instances. Finally, we extend these results to
noncompactly supported measures with sufficient decay.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09157" title="Abstract">arXiv:2310.09157</a> (cross-list from math.OC) [<a href="/pdf/2310.09157" title="Download PDF">pdf</a>, <a href="/format/2310.09157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Computational Complexity of Finding Stationary Points in Non-Convex  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hollender%2C+A">Alexandros Hollender</a>, 
<a href="/search/math?searchtype=author&query=Zampetakis%2C+M">Manolis Zampetakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of COLT 2023 extended abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Finding approximate stationary points, i.e., points where the gradient is
approximately zero, of non-convex but smooth objective functions $f$ over
unrestricted $d$-dimensional domains is one of the most fundamental problems in
classical non-convex optimization. Nevertheless, the computational and query
complexity of this problem are still not well understood when the dimension $d$
of the problem is independent of the approximation error. In this paper, we
show the following computational and query complexity results:
<br />1. The problem of finding approximate stationary points over unrestricted
domains is PLS-complete.
<br />2. For $d = 2$, we provide a zero-order algorithm for finding
$\varepsilon$-approximate stationary points that requires at most
$O(1/\varepsilon)$ value queries to the objective function.
<br />3. We show that any algorithm needs at least $\Omega(1/\varepsilon)$ queries
to the objective function and/or its gradient to find $\varepsilon$-approximate
stationary points when $d=2$. Combined with the above, this characterizes the
query complexity of this problem to be $\Theta(1/\varepsilon)$.
<br />4. For $d = 2$, we provide a zero-order algorithm for finding
$\varepsilon$-KKT points in constrained optimization problems that requires at
most $O(1/\sqrt{\varepsilon})$ value queries to the objective function. This
closes the gap between the works of Bubeck and Mikulincer [2020] and Vavasis
[1993] and characterizes the query complexity of this problem to be
$\Theta(1/\sqrt{\varepsilon})$.
<br />5. Combining our results with the recent result of Fearnley et al. [2022], we
show that finding approximate KKT points in constrained optimization is
reducible to finding approximate stationary points in unconstrained
optimization but the converse is impossible.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09167" title="Abstract">arXiv:2310.09167</a> (cross-list from q-bio.QM) [<a href="/pdf/2310.09167" title="Download PDF">pdf</a>, <a href="/format/2310.09167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Neural Network -- Mechanistic Hybrid Model to Predict  Pharmacokinetics in Rat
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=F%C3%BChrer%2C+F">Florian F&#xfc;hrer</a>, 
<a href="/search/q-bio?searchtype=author&query=Gruber%2C+A">Andrea Gruber</a>, 
<a href="/search/q-bio?searchtype=author&query=Diedam%2C+H">Holger Diedam</a>, 
<a href="/search/q-bio?searchtype=author&query=G%C3%B6ller%2C+A+H">Andreas H. G&#xf6;ller</a>, 
<a href="/search/q-bio?searchtype=author&query=Menz%2C+S">Stephan Menz</a>, 
<a href="/search/q-bio?searchtype=author&query=Schneckener%2C+S">Sebastian Schneckener</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Computer-Aided Molecular Design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">An important aspect in the development of small molecules as drugs or
agro-chemicals is their systemic availability after intravenous and oral
administration.The prediction of the systemic availability from the chemical
structure of a poten-tial candidate is highly desirable, as it allows to focus
the drug or agrochemicaldevelopment on compounds with a favorable kinetic
profile. However, such pre-dictions are challenging as the availability is the
result of the complex interplaybetween molecular properties, biology and
physiology and training data is rare.In this work we improve the hybrid model
developed earlier [34]. We reducethe median fold change error for the total
oral exposure from 2.85 to 2.35 andfor intravenous administration from 1.95 to
1.62. This is achieved by trainingon a larger data set, improving the neural
network architecture as well as theparametrization of mechanistic model.
Further, we extend our approach to predictadditional endpoints and to handle
different covariates, like sex and dosage form.In contrast to a pure machine
learning model, our model is able to predict newend points on which it has not
been trained. We demonstrate this feature by1predicting the exposure over the
first 24h, while the model has only been trainedon the total exposure.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09220" title="Abstract">arXiv:2310.09220</a> (cross-list from math.CT) [<a href="/pdf/2310.09220" title="Download PDF">pdf</a>, <a href="/format/2310.09220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Univalent Double Categories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=van+der+Weide%2C+N">Niels van der Weide</a>, 
<a href="/search/math?searchtype=author&query=Rasekh%2C+N">Nima Rasekh</a>, 
<a href="/search/math?searchtype=author&query=Ahrens%2C+B">Benedikt Ahrens</a>, 
<a href="/search/math?searchtype=author&query=North%2C+P+R">Paige Randall North</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Category theory is a branch of mathematics that provides a formal framework
for understanding the relationship between mathematical structures. To this
end, a category not only incorporates the data of the desired objects, but also
"morphisms", which capture how different objects interact with each other.
Category theory has found many applications in mathematics and in computer
science, for example in functional programming. Double categories are a natural
generalization of categories which incorporate the data of two separate classes
of morphisms, allowing a more nuanced representation of relationships and
interactions between objects. Similar to category theory, double categories
have been successfully applied to various situations in mathematics and
computer science, in which objects naturally exhibit two types of morphisms.
Examples include categories themselves, but also lenses, petri nets, and spans.
While categories have already been formalized in a variety of proof assistants,
double categories have received far less attention. In this paper we remedy
this situation by presenting a formalization of double categories via the proof
assistant Coq, relying on the Coq UniMath library. As part of this work we
present two equivalent formalizations of the definition of a double category,
an unfolded explicit definition and a second definition which exhibits
excellent formal properties via 2-sided displayed categories. As an application
of the formal approach we establish a notion of univalent double category along
with a univalence principle: equivalences of univalent double categories
coincide with their identities
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09221" title="Abstract">arXiv:2310.09221</a> (cross-list from eess.IV) [<a href="/pdf/2310.09221" title="Download PDF">pdf</a>, <a href="/format/2310.09221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrasound Image Segmentation of Thyroid Nodule via Latent Semantic  Feature Co-Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xuewei Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yaqiao Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+X">Xi Wei</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Ruixuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+M">Mei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Segmentation of nodules in thyroid ultrasound imaging plays a crucial role in
the detection and treatment of thyroid cancer. However, owing to the diversity
of scanner vendors and imaging protocols in different hospitals, the automatic
segmentation model, which has already demonstrated expert-level accuracy in the
field of medical image segmentation, finds its accuracy reduced as the result
of its weak generalization performance when being applied in clinically
realistic environments. To address this issue, the present paper proposes ASTN,
a framework for thyroid nodule segmentation achieved through a new type
co-registration network. By extracting latent semantic information from the
atlas and target images and utilizing in-depth features to accomplish the
co-registration of nodules in thyroid ultrasound images, this framework can
ensure the integrity of anatomical structure and reduce the impact on
segmentation as the result of overall differences in image caused by different
devices. In addition, this paper also provides an atlas selection algorithm to
mitigate the difficulty of co-registration. As shown by the evaluation results
collected from the datasets of different devices, thanks to the method we
proposed, the model generalization has been greatly improved while maintaining
a high level of segmentation accuracy.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09254" title="Abstract">arXiv:2310.09254</a> (cross-list from stat.ML) [<a href="/pdf/2310.09254" title="Download PDF">pdf</a>, <a href="/format/2310.09254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Entropic Neural Optimal Transport To Map Within and Across  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Klein%2C+D">Dominik Klein</a>, 
<a href="/search/stat?searchtype=author&query=Uscidda%2C+T">Th&#xe9;o Uscidda</a>, 
<a href="/search/stat?searchtype=author&query=Theis%2C+F">Fabian Theis</a>, 
<a href="/search/stat?searchtype=author&query=Cuturi%2C+M">Marco Cuturi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning measure-to-measure mappings is a crucial task in machine learning,
featured prominently in generative modeling. Recent years have witnessed a
surge of techniques that draw inspiration from optimal transport (OT) theory.
Combined with neural network models, these methods collectively known as
\textit{Neural OT} use optimal transport as an inductive bias: such mappings
should be optimal w.r.t. a given cost function, in the sense that they are able
to move points in a thrifty way, within (by minimizing displacements) or across
spaces (by being isometric). This principle, while intuitive, is often
confronted with several practical challenges that require adapting the OT
toolbox: cost functions other than the squared-Euclidean cost can be
challenging to handle, the deterministic formulation of Monge maps leaves
little flexibility, mapping across incomparable spaces raises multiple
challenges, while the mass conservation constraint inherent to OT can provide
too much credit to outliers. While each of these mismatches between practice
and theory has been addressed independently in various works, we propose in
this work an elegant framework to unify them, called \textit{generative
entropic neural optimal transport} (GENOT). GENOT can accommodate any cost
function; handles randomness using conditional generative models; can map
points across incomparable spaces, and can be used as an \textit{unbalanced}
solver. We evaluate our approach through experiments conducted on various
synthetic datasets and demonstrate its practicality in single-cell biology. In
this domain, GENOT proves to be valuable for tasks such as modeling cell
development, predicting cellular responses to drugs, and translating between
different data modalities of cells.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 16 Oct 23</h3>
<dl>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1404.5510" title="Abstract">arXiv:1404.5510</a> (replaced) [<a href="/pdf/1404.5510" title="Download PDF">pdf</a>, <a href="/format/1404.5510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Online Mobile Facility Location on General Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghodselahi%2C+A">Abdolhamid Ghodselahi</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+F">Fabian Kuhn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Theory of Computing Systems (TOCS) (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1806.07722" title="Abstract">arXiv:1806.07722</a> (replaced) [<a href="/pdf/1806.07722" title="Download PDF">pdf</a>, <a href="/format/1806.07722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stylized innovation: generating timelines by interrogating incrementally  available randomised dictionaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kinsler%2C+P">Paul Kinsler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.10189" title="Abstract">arXiv:2006.10189</a> (replaced) [<a href="/pdf/2006.10189" title="Download PDF">pdf</a>, <a href="/format/2006.10189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting minimum description length complexity in overparameterized  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+R">Raaz Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+C">Chandan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wainwright%2C+M+J">Martin J. Wainwright</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.15734" title="Abstract">arXiv:2007.15734</a> (replaced) [<a href="/pdf/2007.15734" title="Download PDF">pdf</a>, <a href="/format/2007.15734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the inverse scattering problem for radially-symmetric domains in two  dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gopal%2C+A">Abinand Gopal</a>, 
<a href="/search/math?searchtype=author&query=Hoskins%2C+J">Jeremy Hoskins</a>, 
<a href="/search/math?searchtype=author&query=Rokhlin%2C+V">Vladimir Rokhlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.08451" title="Abstract">arXiv:2008.08451</a> (replaced) [<a href="/pdf/2008.08451" title="Download PDF">pdf</a>, <a href="/ps/2008.08451" title="Download PostScript">ps</a>, <a href="/format/2008.08451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axioms for Defeat in Democratic Elections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Holliday%2C+W+H">Wesley H. Holliday</a>, 
<a href="/search/econ?searchtype=author&query=Pacuit%2C+E">Eric Pacuit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added missing edges in first graph in Remark 4.10
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Theoretical Politics, Vol. 33(4), 475-524, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.12600" title="Abstract">arXiv:2010.12600</a> (replaced) [<a href="/pdf/2010.12600" title="Download PDF">pdf</a>, <a href="/format/2010.12600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasibility Assessment of an Optically Powered Digital Retinal  Prosthesis Architecture for Retinal Ganglion Cell Stimulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lemaire%2C+W">William Lemaire</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Benhouria%2C+M">Maher Benhouria</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Koua%2C+K">Konin Koua</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Tong%2C+W">Wei Tong</a> (2), 
<a href="/search/q-bio?searchtype=author&query=Martin-Hardy%2C+G">Gabriel Martin-Hardy</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Stamp%2C+M">Melanie Stamp</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Ganesan%2C+K">Kumaravelu Ganesan</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Gauthier%2C+L">Louis-Philippe Gauthier</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Besrour%2C+M">Marwan Besrour</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Ahnood%2C+A">Arman Ahnood</a> (4), 
<a href="/search/q-bio?searchtype=author&query=Garrett%2C+D+J">David John Garrett</a> (4), 
<a href="/search/q-bio?searchtype=author&query=Roy%2C+S">S&#xe9;bastien Roy</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Ibbotson%2C+M">Michael Ibbotson</a> (2,5), 
<a href="/search/q-bio?searchtype=author&query=Prawer%2C+S">Steven Prawer</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Fontaine%2C+R">R&#xe9;jean Fontaine</a> (1) ((1) Interdisciplinary Institute for Technological Innovation (3IT), Universit&#xe9; de Sherbrooke, Sherbrooke, Quebec, Canada, (2) National Vision Research Institute, Australian College of Optometry, Carlton, Victoria, Australia, (3) School of Physics, The University of Melbourne, Parkville, Victoria, Australia, (4) School of Engineering, RMIT University, Melbourne, Victoria, Australia, (5) Department of Optometry and Vision Sciences, The University of Melbourne, Parkville, Victoria, Australia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.08022" title="Abstract">arXiv:2103.08022</a> (replaced) [<a href="/pdf/2103.08022" title="Download PDF">pdf</a>, <a href="/format/2103.08022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Success Weighted by Completion Time: A Dynamics-Aware Evaluation  Criteria for Embodied Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+N">Naoki Yokoyama</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.03216" title="Abstract">arXiv:2104.03216</a> (replaced) [<a href="/pdf/2104.03216" title="Download PDF">pdf</a>, <a href="/ps/2104.03216" title="Download PostScript">ps</a>, <a href="/format/2104.03216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Valued rank-metric codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maazouz%2C+Y+E">Yassine El Maazouz</a>, 
<a href="/search/math?searchtype=author&query=Hahn%2C+M+A">Marvin Anas Hahn</a>, 
<a href="/search/math?searchtype=author&query=Neri%2C+A">Alessandro Neri</a>, 
<a href="/search/math?searchtype=author&query=Stanojkovski%2C+M">Mima Stanojkovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Information Theory (cs.IT); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.08753" title="Abstract">arXiv:2104.08753</a> (replaced) [<a href="/pdf/2104.08753" title="Download PDF">pdf</a>, <a href="/ps/2104.08753" title="Download PostScript">ps</a>, <a href="/format/2104.08753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot quantum state redistribution and quantum Markov chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Anshu%2C+A">Anurag Anshu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hadiashar%2C+S+B">Shima Bab Hadiashar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jain%2C+R">Rahul Jain</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>, 
<a href="/search/quant-ph?searchtype=author&query=Touchette%2C+D">Dave Touchette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: Exposition improved, references added, typos corrected. 32 pages, 2 figures. v1: 26 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, vol. 69, no. 9, pp.
  5788--5804, Sept. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.06755" title="Abstract">arXiv:2107.06755</a> (replaced) [<a href="/pdf/2107.06755" title="Download PDF">pdf</a>, <a href="/ps/2107.06755" title="Download PostScript">ps</a>, <a href="/format/2107.06755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIT4BEARs Smart Roads Internship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="/search/cs?searchtype=author&query=Krutsylo%2C+A">Andrii Krutsylo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.01239" title="Abstract">arXiv:2109.01239</a> (replaced) [<a href="/pdf/2109.01239" title="Download PDF">pdf</a>, <a href="/format/2109.01239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Max-Min Task Offloading Algorithm for Mobile Edge Computing Using  Non-Orthogonal Multiple Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vaibhav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Hanif%2C+M+F">Muhammad Fainan Hanif</a>, 
<a href="/search/cs?searchtype=author&query=Juntti%2C+M">Markku Juntti</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Le-Nam Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Vehicular Technology, vol. 72, no. 9, pp.
  12332-12337, Sept. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.10493" title="Abstract">arXiv:2109.10493</a> (replaced) [<a href="/pdf/2109.10493" title="Download PDF">pdf</a>, <a href="/format/2109.10493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Augmentation Methods for Learning Robust Navigation Agents:  the Winning Entry of the 2021 iGibson Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+N">Naoki Yokoyama</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Q">Qian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.04066" title="Abstract">arXiv:2111.04066</a> (replaced) [<a href="/pdf/2111.04066" title="Download PDF">pdf</a>, <a href="/ps/2111.04066" title="Download PostScript">ps</a>, <a href="/format/2111.04066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast sampling via spectral independence beyond bounded-degree graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bez%C3%A1kov%C3%A1%2C+I">Ivona Bez&#xe1;kov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Galanis%2C+A">Andreas Galanis</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+L+A">Leslie Ann Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0tefankovi%C4%8D%2C+D">Daniel &#x160;tefankovi&#x10d;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TALG, To Appear
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.09726" title="Abstract">arXiv:2112.09726</a> (replaced) [<a href="/pdf/2112.09726" title="Download PDF">pdf</a>, <a href="/format/2112.09726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soundify: Matching Sound Effects to Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+D+C">David Chuan-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Germanidis%2C+A">Anastasis Germanidis</a>, 
<a href="/search/cs?searchtype=author&query=Valenzuela%2C+C">Crist&#xf3;bal Valenzuela</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yining Shi</a>, 
<a href="/search/cs?searchtype=author&query=Martelaro%2C+N">Nikolas Martelaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper in UIST 2023; Short paper in NeurIPS 2021 ML4CD Workshop; Online demo: <a href="http://soundify.cc">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.03454" title="Abstract">arXiv:2201.03454</a> (replaced) [<a href="/pdf/2201.03454" title="Download PDF">pdf</a>, <a href="/format/2201.03454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Face Morphing Attacks: Generation, Vulnerability and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+J+M">Jag Mohan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandra%2C+R">Raghavendra Ramachandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted at IEEE Transactions on Biometrics, Behavior and Identity Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.05021" title="Abstract">arXiv:2201.05021</a> (replaced) [<a href="/pdf/2201.05021" title="Download PDF">pdf</a>, <a href="/format/2201.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness against Read Committed for Transaction Templates with  Functional Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vandevoort%2C+B">Brecht Vandevoort</a>, 
<a href="/search/cs?searchtype=author&query=Ketsman%2C+B">Bas Ketsman</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+C">Christoph Koch</a>, 
<a href="/search/cs?searchtype=author&query=Neven%2C+F">Frank Neven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New version of lmcs.cls and fixed some typos 50 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06533" title="Abstract">arXiv:2201.06533</a> (replaced) [<a href="/pdf/2201.06533" title="Download PDF">pdf</a>, <a href="/format/2201.06533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Algorithms for Approximating Quantum Partition Functions at  Low Temperature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Helmuth%2C+T">Tyler Helmuth</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mann%2C+R+L">Ryan L. Mann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 0 figures, published version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.03574" title="Abstract">arXiv:2202.03574</a> (replaced) [<a href="/pdf/2202.03574" title="Download PDF">pdf</a>, <a href="/format/2202.03574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Prediction Problem Archive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swoboda%2C+P">Paul Swoboda</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Ahmed Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Hornakova%2C+A">Andrea Hornakova</a>, 
<a href="/search/cs?searchtype=author&query=Roetzer%2C+P">Paul Roetzer</a>, 
<a href="/search/cs?searchtype=author&query=Savchynskyy%2C+B">Bogdan Savchynskyy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added new shape matching instances based of learned descriptors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.08246" title="Abstract">arXiv:2202.08246</a> (replaced) [<a href="/pdf/2202.08246" title="Download PDF">pdf</a>, <a href="/ps/2202.08246" title="Download PostScript">ps</a>, <a href="/format/2202.08246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Galois connecting call-by-value and call-by-name
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDermott%2C+D">Dylan McDermott</a>, 
<a href="/search/cs?searchtype=author&query=Mycroft%2C+A">Alan Mycroft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FSCD 2022 special issue of Logical Methods in Computer Science; minor changes incorporating reviewers' comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.12045" title="Abstract">arXiv:2202.12045</a> (replaced) [<a href="/pdf/2202.12045" title="Download PDF">pdf</a>, <a href="/format/2202.12045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing Blocks by Sweeping Lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Akitaya%2C+H+A">Hugo A. Akitaya</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B6ffler%2C+M">Maarten L&#xf6;ffler</a>, 
<a href="/search/math?searchtype=author&query=Viglietta%2C+G">Giovanni Viglietta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11886" title="Abstract">arXiv:2204.11886</a> (replaced) [<a href="/pdf/2204.11886" title="Download PDF">pdf</a>, <a href="/ps/2204.11886" title="Download PostScript">ps</a>, <a href="/format/2204.11886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutually Unbiased Measurements, Hadamard Matrices, and Superdense Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Farkas%2C+M">M&#xe1;t&#xe9; Farkas</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kaniewski%2C+J">J&#x119;drzej Kaniewski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: Added some references and related discussion. v1: 20 pages. Comments welcome!
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, vol. 69, no. 6, pp.
  3814--3824, June 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05649" title="Abstract">arXiv:2205.05649</a> (replaced) [<a href="/pdf/2205.05649" title="Download PDF">pdf</a>, <a href="/format/2205.05649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Any-k Algorithms for Enumerating Ranked Answers to Conjunctive Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tziavelis%2C+N">Nikolaos Tziavelis</a>, 
<a href="/search/cs?searchtype=author&query=Gatterbauer%2C+W">Wolfgang Gatterbauer</a>, 
<a href="/search/cs?searchtype=author&query=Riedewald%2C+M">Mirek Riedewald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10977" title="Abstract">arXiv:2205.10977</a> (replaced) [<a href="/pdf/2205.10977" title="Download PDF">pdf</a>, <a href="/format/2205.10977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What should I Ask: A Knowledge-driven Approach for Follow-up Questions  Generation in Conversational Surveys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yubin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Ziang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Diesner%2C+J">Jana Diesner</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Karahalios%2C+K">Karrie Karahalios</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+H">Hari Sundaram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00371" title="Abstract">arXiv:2206.00371</a> (replaced) [<a href="/e-print/2206.00371" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Complexity of Group Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Samir Datta</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shivdutt Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Vasudev%2C+Y">Yadu Vasudev</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+S+R">Shankar Ram Vasudevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been withdrawn since some crucial lemmas are wrong (Theorem 1, Lemma 10) related to cube bases. Please refer to <a href="/abs/2308.10073">arXiv:2308.10073</a> for the follow up with updated results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02755" title="Abstract">arXiv:2206.02755</a> (replaced) [<a href="/pdf/2206.02755" title="Download PDF">pdf</a>, <a href="/format/2206.02755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New lower bounds on crossing numbers of $K_{m,n}$ from semidefinite  programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brosch%2C+D">Daniel Brosch</a>, 
<a href="/search/math?searchtype=author&query=Polak%2C+S">Sven Polak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, 3 tables. Revisions have been made based on comments of the referees. Accepted for publication in Mathematical Programming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Optimization and Control (math.OC); Representation Theory (math.RT)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12403" title="Abstract">arXiv:2206.12403</a> (replaced) [<a href="/pdf/2206.12403" title="Download PDF">pdf</a>, <a href="/format/2206.12403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Arjun Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+G">Gunjan Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Devnani%2C+B">Bhavika Devnani</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code: <a href="https://github.com/gunagg/zson">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14697" title="Abstract">arXiv:2206.14697</a> (replaced) [<a href="/pdf/2206.14697" title="Download PDF">pdf</a>, <a href="/format/2206.14697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidden Parameter Recurrent State Space Models For Changing Dynamics  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaj%2C+V">Vaisakh Shaj</a>, 
<a href="/search/cs?searchtype=author&query=Buchler%2C+D">Dieter Buchler</a>, 
<a href="/search/cs?searchtype=author&query=Sonker%2C+R">Rohit Sonker</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+P">Philipp Becker</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+G">Gerhard Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the International Conference on Learning Representations, ICLR 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.09768" title="Abstract">arXiv:2207.09768</a> (replaced) [<a href="/pdf/2207.09768" title="Download PDF">pdf</a>, <a href="/format/2207.09768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Counterfactually Invariant Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quinzan%2C+F">Francesco Quinzan</a>, 
<a href="/search/cs?searchtype=author&query=Casolo%2C+C">Cecilia Casolo</a>, 
<a href="/search/cs?searchtype=author&query=Muandet%2C+K">Krikamol Muandet</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yucen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Kilbertus%2C+N">Niki Kilbertus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10062" title="Abstract">arXiv:2207.10062</a> (replaced) [<a href="/pdf/2207.10062" title="Download PDF">pdf</a>, <a href="/format/2207.10062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataPerf: Benchmarks for Data-Centric AI Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+M">Mark Mazumder</a>, 
<a href="/search/cs?searchtype=author&query=Banbury%2C+C">Colby Banbury</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiaozhe Yao</a>, 
<a href="/search/cs?searchtype=author&query=Karla%C5%A1%2C+B">Bojan Karla&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+W+G">William Gaviria Rojas</a>, 
<a href="/search/cs?searchtype=author&query=Diamos%2C+S">Sudnya Diamos</a>, 
<a href="/search/cs?searchtype=author&query=Diamos%2C+G">Greg Diamos</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lynn He</a>, 
<a href="/search/cs?searchtype=author&query=Parrish%2C+A">Alicia Parrish</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Quaye%2C+J">Jessica Quaye</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Charvi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Kiela%2C+D">Douwe Kiela</a>, 
<a href="/search/cs?searchtype=author&query=Jurado%2C+D">David Jurado</a>, 
<a href="/search/cs?searchtype=author&query=Kanter%2C+D">David Kanter</a>, 
<a href="/search/cs?searchtype=author&query=Mosquera%2C+R">Rafael Mosquera</a>, 
<a href="/search/cs?searchtype=author&query=Ciro%2C+J">Juan Ciro</a>, 
<a href="/search/cs?searchtype=author&query=Aroyo%2C+L">Lora Aroyo</a>, 
<a href="/search/cs?searchtype=author&query=Acun%2C+B">Bilge Acun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingjiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Raje%2C+M+S">Mehul Smriti Raje</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+M">Max Bartolo</a>, 
<a href="/search/cs?searchtype=author&query=Eyuboglu%2C+S">Sabri Eyuboglu</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbani%2C+A">Amirata Ghorbani</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+E">Emmett Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Inel%2C+O">Oana Inel</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+T">Tariq Kane</a>, 
<a href="/search/cs?searchtype=author&query=Kirkpatrick%2C+C+R">Christine R. Kirkpatrick</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+T">Tzu-Sheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+J">Jonas Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Thrush%2C+T">Tristan Thrush</a>, 
<a href="/search/cs?searchtype=author&query=Vanschoren%2C+J">Joaquin Vanschoren</a>, 
<a href="/search/cs?searchtype=author&query=Warren%2C+M">Margaret Warren</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A">Adina Williams</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Serena Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Ardalani%2C+N">Newsha Ardalani</a>, 
<a href="/search/cs?searchtype=author&query=Paritosh%2C+P">Praveen Paritosh</a>, 
<a href="/search/cs?searchtype=author&query=Bat-Leah%2C+L">Lilith Bat-Leah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Carole-Jean Wu</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+C">Cody Coleman</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+A">Andrew Ng</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+P">Peter Mattson</a>, 
<a href="/search/cs?searchtype=author&query=Reddi%2C+V+J">Vijay Janapa Reddi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10171" title="Abstract">arXiv:2207.10171</a> (replaced) [<a href="/pdf/2207.10171" title="Download PDF">pdf</a>, <a href="/format/2207.10171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudoperiodic Words and a Question of Shevelev
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Meleshko%2C+J">Joseph Meleshko</a>, 
<a href="/search/math?searchtype=author&query=Ochem%2C+P">Pascal Ochem</a>, 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="/search/math?searchtype=author&query=Shan%2C+S+L">Sonja Linghui Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14356" title="Abstract">arXiv:2208.14356</a> (replaced) [<a href="/pdf/2208.14356" title="Download PDF">pdf</a>, <a href="/ps/2208.14356" title="Download PostScript">ps</a>, <a href="/format/2208.14356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The syntactic side of autonomous categories enriched over generalised  metric spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dahlqvist%2C+F">Fredrik Dahlqvist</a>, 
<a href="/search/cs?searchtype=author&query=Neves%2C+R">Renato Neves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal version of "An Internal Language for Categories Enriched over Generalised Metric Spaces" [<a href="/abs/2105.08473">arXiv:2105.08473</a>] (<a href="https://doi.org/10.4230/LIPIcs.CSL.2022.16">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01594" title="Abstract">arXiv:2209.01594</a> (replaced) [<a href="/pdf/2209.01594" title="Download PDF">pdf</a>, <a href="/format/2209.01594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On convergence and optimality of maximum-likelihood APA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalali%2C+S">Shirin Jalali</a>, 
<a href="/search/cs?searchtype=author&query=Nuzman%2C+C">Carl Nuzman</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12127" title="Abstract">arXiv:2209.12127</a> (replaced) [<a href="/pdf/2209.12127" title="Download PDF">pdf</a>, <a href="/format/2209.12127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpeedLimit: Neural Architecture Search for Quantized Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yuji Chai</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+L">Luke Bailey</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yunho Jin</a>, 
<a href="/search/cs?searchtype=author&query=Karle%2C+M">Matthew Karle</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+G+G">Glenn G. Ko</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+D">David Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Gu-Yeon Wei</a>, 
<a href="/search/cs?searchtype=author&query=Kung%2C+H+T">H. T. Kung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02671" title="Abstract">arXiv:2210.02671</a> (replaced) [<a href="/pdf/2210.02671" title="Download PDF">pdf</a>, <a href="/format/2210.02671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Logic for Expressing Log-Precision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merrill%2C+W">William Merrill</a>, 
<a href="/search/cs?searchtype=author&query=Sabharwal%2C+A">Ashish Sabharwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> May 24, 2023: Restructured version of old preprint. Oct 12, 2023: To appear at NeurIPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03029" title="Abstract">arXiv:2210.03029</a> (replaced) [<a href="/pdf/2210.03029" title="Download PDF">pdf</a>, <a href="/format/2210.03029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Enhancing Zero-Shot Performance of Instruction Following  Model via Retrieval of Soft Prompt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Seonghyeon Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Joel Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yongrae Jo</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minjoon Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03485" title="Abstract">arXiv:2210.03485</a> (replaced) [<a href="/pdf/2210.03485" title="Download PDF">pdf</a>, <a href="/format/2210.03485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-based optimisation of the conditional-value-at-risk using the  multi-level Monte Carlo method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ganesh%2C+S">Sundar Ganesh</a>, 
<a href="/search/math?searchtype=author&query=Nobile%2C+F">Fabio Nobile</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 18 figures, 1 table, Related to <a href="/abs/2208.07252">arXiv:2208.07252</a>, Data available at <a href="https://zenodo.org/record/7193448">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational Physics, Volume 495, 112523 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05633" title="Abstract">arXiv:2210.05633</a> (replaced) [<a href="/pdf/2210.05633" title="Download PDF">pdf</a>, <a href="/format/2210.05633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Habitat-Matterport 3D Semantics Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+K">Karmesh Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Ramrakhya%2C+R">Ram Ramrakhya</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+S+K">Santhosh Kumar Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Gervet%2C+T">Theo Gervet</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+J">John Turner</a>, 
<a href="/search/cs?searchtype=author&query=Gokaslan%2C+A">Aaron Gokaslan</a>, 
<a href="/search/cs?searchtype=author&query=Maestre%2C+N">Noah Maestre</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel Xuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Clegg%2C+A+W">Alexander William Clegg</a>, 
<a href="/search/cs?searchtype=author&query=Chaplot%2C+D+S">Devendra Singh Chaplot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 Pages, 11 Figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06366" title="Abstract">arXiv:2210.06366</a> (replaced) [<a href="/pdf/2210.06366" title="Download PDF">pdf</a>, <a href="/format/2210.06366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalist Framework for Panoptic Segmentation of Images and Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lala Li</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Saurabh Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Hinton%2C+G">Geoffrey Hinton</a>, 
<a href="/search/cs?searchtype=author&query=Fleet%2C+D+J">David J. Fleet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV'23. Code at <a href="https://github.com/google-research/pix2seq">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09017" title="Abstract">arXiv:2210.09017</a> (replaced) [<a href="/pdf/2210.09017" title="Download PDF">pdf</a>, <a href="/ps/2210.09017" title="Download PostScript">ps</a>, <a href="/format/2210.09017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wolff%2C+T+M">Tobias M. Wolff</a>, 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10001" title="Abstract">arXiv:2210.10001</a> (replaced) [<a href="/pdf/2210.10001" title="Download PDF">pdf</a>, <a href="/ps/2210.10001" title="Download PostScript">ps</a>, <a href="/format/2210.10001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic and context-free subsets of subgroups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carvalho%2C+A">Andr&#xe9; Carvalho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13020" title="Abstract">arXiv:2210.13020</a> (replaced) [<a href="/pdf/2210.13020" title="Download PDF">pdf</a>, <a href="/format/2210.13020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Tools for Completeness of Kleene Algebra with Hypotheses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pous%2C+D">Damien Pous</a>, 
<a href="/search/cs?searchtype=author&query=Rot%2C+J">Jurriaan Rot</a>, 
<a href="/search/cs?searchtype=author&query=Wagemaker%2C+J">Jana Wagemaker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14791" title="Abstract">arXiv:2210.14791</a> (replaced) [<a href="/pdf/2210.14791" title="Download PDF">pdf</a>, <a href="/format/2210.14791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViNL: Visual Navigation and Locomotion Over Obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kareer%2C+S">Simar Kareer</a>, 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+N">Naoki Yokoyama</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+J">Joanne Truong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17329" title="Abstract">arXiv:2210.17329</a> (replaced) [<a href="/pdf/2210.17329" title="Download PDF">pdf</a>, <a href="/format/2210.17329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification for random domains using periodic random  variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hakula%2C+H">Harri Hakula</a>, 
<a href="/search/math?searchtype=author&query=Harbrecht%2C+H">Helmut Harbrecht</a>, 
<a href="/search/math?searchtype=author&query=Kaarnioja%2C+V">Vesa Kaarnioja</a>, 
<a href="/search/math?searchtype=author&query=Kuo%2C+F+Y">Frances Y. Kuo</a>, 
<a href="/search/math?searchtype=author&query=Sloan%2C+I+H">Ian H. Sloan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03462" title="Abstract">arXiv:2211.03462</a> (replaced) [<a href="/pdf/2211.03462" title="Download PDF">pdf</a>, <a href="/format/2211.03462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tengxun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=van+Genabith%2C+J">Josef van Genabith</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zan%2C+H">Hongying Zan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08007" title="Abstract">arXiv:2211.08007</a> (replaced) [<a href="/pdf/2211.08007" title="Download PDF">pdf</a>, <a href="/format/2211.08007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Gait Recognition via Learning from Dirichlet  Distribution-based Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Beibei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Ming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lincheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shunli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11000" title="Abstract">arXiv:2211.11000</a> (replaced) [<a href="/pdf/2211.11000" title="Download PDF">pdf</a>, <a href="/ps/2211.11000" title="Download PostScript">ps</a>, <a href="/format/2211.11000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Distance Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bullinger%2C+M">Martin Bullinger</a>, 
<a href="/search/cs?searchtype=author&query=Suksompong%2C+W">Warut Suksompong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 37th AAAI Conference on Artificial Intelligence (AAAI), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11744" title="Abstract">arXiv:2211.11744</a> (replaced) [<a href="/pdf/2211.11744" title="Download PDF">pdf</a>, <a href="/format/2211.11744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Dexterity: In-hand Dexterous Manipulation from Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tippur%2C+M">Megha Tippur</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Adelson%2C+E">Edward Adelson</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16908" title="Abstract">arXiv:2211.16908</a> (replaced) [<a href="/pdf/2211.16908" title="Download PDF">pdf</a>, <a href="/ps/2211.16908" title="Download PostScript">ps</a>, <a href="/format/2211.16908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Smoothed Analysis of 2-Opt for the Euclidean TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manthey%2C+B">Bodo Manthey</a>, 
<a href="/search/cs?searchtype=author&query=van+Rhijn%2C+J">Jesse van Rhijn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 3 figures. Accepted for presentation at ISAAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09849" title="Abstract">arXiv:2212.09849</a> (replaced) [<a href="/pdf/2212.09849" title="Download PDF">pdf</a>, <a href="/format/2212.09849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataless Knowledge Fusion by Merging Weights of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xisen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Preotiuc-Pietro%2C+D">Daniel Preotiuc-Pietro</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengxiang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023; The code is available at <a href="https://github.com/bloomberg/dataless-model-merging">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13531" title="Abstract">arXiv:2212.13531</a> (replaced) [<a href="/pdf/2212.13531" title="Download PDF">pdf</a>, <a href="/format/2212.13531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics informed neural networks for elliptic equations with oscillatory  differential operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gangal%2C+A">Arnav Gangal</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+L">Luis Kim</a>, 
<a href="/search/math?searchtype=author&query=Carney%2C+S+P">Sean P. Carney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00051" title="Abstract">arXiv:2301.00051</a> (replaced) [<a href="/pdf/2301.00051" title="Download PDF">pdf</a>, <a href="/format/2301.00051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Guided Play: Improving Exploration for Adversarial  Imitation Learning with Simple Auxiliary Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ablett%2C+T">Trevor Ablett</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+B">Bryan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'23), Detroit, MI, USA, Oct. 1-5, 2023. arXiv admin note: substantial text overlap with <a href="/abs/2112.08932">arXiv:2112.08932</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RA-L), Vol. 8, No. 3, pp.
  1263-1270, Jan. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00521" title="Abstract">arXiv:2301.00521</a> (replaced) [<a href="/pdf/2301.00521" title="Download PDF">pdf</a>, <a href="/format/2301.00521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Policy Optimization Method Towards Optimal-time Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+F">Fengbo Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuxue Cao</a>, 
<a href="/search/cs?searchtype=author&query=Oseni%2C+O">Oluwatosin Oseni</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haotian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figues. 7th Annual Conference on Robot Learning. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08141" title="Abstract">arXiv:2301.08141</a> (replaced) [<a href="/pdf/2301.08141" title="Download PDF">pdf</a>, <a href="/format/2301.08141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning for Segmentation and Quantification of Dopamine  Neurons in Parkinson&#x27;s Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haghighi%2C+F">Fatemeh Haghighi</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Soumitra Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Ngu%2C+H">Hai Ngu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+S">Sarah Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Han Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hejrati%2C+M">Mohsen Hejrati</a>, 
<a href="/search/cs?searchtype=author&query=Bingol%2C+B">Baris Bingol</a>, 
<a href="/search/cs?searchtype=author&query=Hashemifar%2C+S">Somaye Hashemifar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09918" title="Abstract">arXiv:2301.09918</a> (replaced) [<a href="/e-print/2301.09918" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart tutor to provide feedback in programming courses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rold%C3%A1n-%C3%81lvarez%2C+D">David Rold&#xe1;n-&#xc1;lvarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper was used in order to participate in a call for projects. The project was denied so this paper does not make any sense
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10034" title="Abstract">arXiv:2301.10034</a> (replaced) [<a href="/pdf/2301.10034" title="Download PDF">pdf</a>, <a href="/format/2301.10034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-World Multi-Task Control Through Goal-Aware Representation Learning  and Adaptive Horizon Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaofei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by CVPR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10880" title="Abstract">arXiv:2301.10880</a> (replaced) [<a href="/pdf/2301.10880" title="Download PDF">pdf</a>, <a href="/format/2301.10880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Golden Age: Conspiracy Theories&#x27; Relationship with Misinformation  Outlets, News Media, and the Wider Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanley%2C+H+W+A">Hans W. A. Hanley</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Deepak Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CSCW 2023; CSCW version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12814" title="Abstract">arXiv:2301.12814</a> (replaced) [<a href="/pdf/2301.12814" title="Download PDF">pdf</a>, <a href="/format/2301.12814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating lossy Gaussian boson sampling with matrix product operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+M">Minzhao Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Oh%2C+C">Changhun Oh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+L">Liang Jiang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alexeev%2C+Y">Yuri Alexeev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures. To appear in PRA. This article supersedes <a href="/abs/2303.11409">arXiv:2303.11409</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00779" title="Abstract">arXiv:2302.00779</a> (replaced) [<a href="/pdf/2302.00779" title="Download PDF">pdf</a>, <a href="/ps/2302.00779" title="Download PostScript">ps</a>, <a href="/format/2302.00779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Eulerian finite element method for tangential Navier-Stokes equations  on evolving surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Olshanskii%2C+M+A">Maxim A. Olshanskii</a>, 
<a href="/search/math?searchtype=author&query=Reusken%2C+A">Arnold Reusken</a>, 
<a href="/search/math?searchtype=author&query=Schwering%2C+P">Paul Schwering</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01704" title="Abstract">arXiv:2302.01704</a> (replaced) [<a href="/pdf/2302.01704" title="Download PDF">pdf</a>, <a href="/format/2302.01704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation via Alignment of Operation Profile for Remaining  Useful Lifetime Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nejjar%2C+I">Ismail Nejjar</a>, 
<a href="/search/cs?searchtype=author&query=Geissmann%2C+F">Fabian Geissmann</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Taal%2C+C">Cees Taal</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04062" title="Abstract">arXiv:2302.04062</a> (replaced) [<a href="/pdf/2302.04062" title="Download PDF">pdf</a>, <a href="/format/2302.04062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning for Synthetic Data Generation: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yingzhou Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Minjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huazheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=van+Rechem%2C+C">Capucine van Rechem</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenqi Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04863" title="Abstract">arXiv:2302.04863</a> (replaced) [<a href="/pdf/2302.04863" title="Download PDF">pdf</a>, <a href="/format/2302.04863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge is a Region in Weight Space for Fine-tuned Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gueta%2C+A">Almog Gueta</a>, 
<a href="/search/cs?searchtype=author&query=Venezian%2C+E">Elad Venezian</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Slonim%2C+N">Noam Slonim</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+Y">Yoav Katz</a>, 
<a href="/search/cs?searchtype=author&query=Choshen%2C+L">Leshem Choshen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06180" title="Abstract">arXiv:2302.06180</a> (replaced) [<a href="/pdf/2302.06180" title="Download PDF">pdf</a>, <a href="/format/2302.06180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDPTrace: Locally Differentially Private Trajectory Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuntao Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yujia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Ziquan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Baihua Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunjun Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by VLDB 2023. Code is available: <a href="https://github.com/zealscott/LDPTrace">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06887" title="Abstract">arXiv:2302.06887</a> (replaced) [<a href="/pdf/2302.06887" title="Download PDF">pdf</a>, <a href="/format/2302.06887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Graph ARMA Processes from Time-Vertex Spectra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Guneyi%2C+E+T">Eylem Tugce Guneyi</a>, 
<a href="/search/stat?searchtype=author&query=Yaldiz%2C+B">Berkay Yaldiz</a>, 
<a href="/search/stat?searchtype=author&query=Canbolat%2C+A">Abdullah Canbolat</a>, 
<a href="/search/stat?searchtype=author&query=Vural%2C+E">Elif Vural</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08370" title="Abstract">arXiv:2302.08370</a> (replaced) [<a href="/pdf/2302.08370" title="Download PDF">pdf</a>, <a href="/format/2302.08370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Specialization of Third-Party Java Dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soto-Valero%2C+C">C&#xe9;sar Soto-Valero</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+D">Deepika Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Toady%2C+T">Tim Toady</a>, 
<a href="/search/cs?searchtype=author&query=Baudry%2C+B">Benoit Baudry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, 4 tables, 1 algorithm, 2 code listings, 3 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11026" title="Abstract">arXiv:2302.11026</a> (replaced) [<a href="/pdf/2302.11026" title="Download PDF">pdf</a>, <a href="/format/2302.11026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsourced Multiple Access with Common Alarm Messages: Network Slicing  for Massive and Critical IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngo%2C+K">Khac-Hoang Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Durisi%2C+G">Giuseppe Durisi</a>, 
<a href="/search/cs?searchtype=author&query=Amat%2C+A+G+i">Alexandre Graell i Amat</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Kalor%2C+A+E">Anders E. Kalor</a>, 
<a href="/search/cs?searchtype=author&query=Soret%2C+B">Beatriz Soret</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12422" title="Abstract">arXiv:2302.12422</a> (replaced) [<a href="/pdf/2302.12422" title="Download PDF">pdf</a>, <a href="/format/2302.12422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MimicPlay: Long-Horizon Imitation Learning by Watching Human Play
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Linxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Danfei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7th Conference on Robot Learning (CoRL 2023 oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12759" title="Abstract">arXiv:2302.12759</a> (replaced) [<a href="/pdf/2302.12759" title="Download PDF">pdf</a>, <a href="/ps/2302.12759" title="Download PostScript">ps</a>, <a href="/format/2302.12759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularity-based approach for tracking communities in dynamic social  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazza%2C+M">Michele Mazza</a>, 
<a href="/search/cs?searchtype=author&query=Cola%2C+G">Guglielmo Cola</a>, 
<a href="/search/cs?searchtype=author&query=Tesconi%2C+M">Maurizio Tesconi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Knowledge-Based Systems (Elsevier), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13619" title="Abstract">arXiv:2302.13619</a> (replaced) [<a href="/pdf/2302.13619" title="Download PDF">pdf</a>, <a href="/format/2302.13619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading  Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongguang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junqing He</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yinan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xinshi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13934" title="Abstract">arXiv:2302.13934</a> (replaced) [<a href="/pdf/2302.13934" title="Download PDF">pdf</a>, <a href="/format/2302.13934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Learning under Heterogenous Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simchowitz%2C+M">Max Simchowitz</a>, 
<a href="/search/cs?searchtype=author&query=Ajay%2C+A">Anurag Ajay</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Akshay Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00233" title="Abstract">arXiv:2303.00233</a> (replaced) [<a href="/pdf/2303.00233" title="Download PDF">pdf</a>, <a href="/format/2303.00233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Cell Multimodal Prediction via Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+W">Wenzhuo Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wen%2C+H">Hongzhi Wen</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+R">Renming Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+J">Jiayuan Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Jin%2C+W">Wei Jin</a>, 
<a href="/search/q-bio?searchtype=author&query=Xie%2C+Y">Yuying Xie</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 32nd ACM International Conference on
  Information and Knowledge Management (CIKM 23), 2023, Birmingham, United
  Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00807" title="Abstract">arXiv:2303.00807</a> (replaced) [<a href="/pdf/2303.00807" title="Download PDF">pdf</a>, <a href="/format/2303.00807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and  Distillation of Rerankers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saad-Falcon%2C+J">Jon Saad-Falcon</a>, 
<a href="/search/cs?searchtype=author&query=Khattab%2C+O">Omar Khattab</a>, 
<a href="/search/cs?searchtype=author&query=Santhanam%2C+K">Keshav Santhanam</a>, 
<a href="/search/cs?searchtype=author&query=Florian%2C+R">Radu Florian</a>, 
<a href="/search/cs?searchtype=author&query=Franz%2C+M">Martin Franz</a>, 
<a href="/search/cs?searchtype=author&query=Roukos%2C+S">Salim Roukos</a>, 
<a href="/search/cs?searchtype=author&query=Sil%2C+A">Avirup Sil</a>, 
<a href="/search/cs?searchtype=author&query=Sultan%2C+M+A">Md Arafat Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+C">Christopher Potts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long Paper at Empirical Methods in Natural Language Processing (EMNLP) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01248" title="Abstract">arXiv:2303.01248</a> (replaced) [<a href="/pdf/2303.01248" title="Download PDF">pdf</a>, <a href="/format/2303.01248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT Assess Human Personalities? A General Evaluation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+H">Haocong Rao</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+C">Cyril Leung</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023. Our codes are available at <a href="https://github.com/Kali-Hac/ChatGPT-MBTI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05050" title="Abstract">arXiv:2303.05050</a> (replaced) [<a href="/pdf/2303.05050" title="Download PDF">pdf</a>, <a href="/format/2303.05050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifelong-MonoDepth: Lifelong Learning for Multi-Domain Monocular Metric  Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenyou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Liguang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Honghai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+T+L">Tin Lun Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06171" title="Abstract">arXiv:2303.06171</a> (replaced) [<a href="/pdf/2303.06171" title="Download PDF">pdf</a>, <a href="/format/2303.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-Fast MH: Private, Fast, and Accurate Metropolis-Hastings for  Large-Scale Bayesian Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqi Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> published at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06827" title="Abstract">arXiv:2303.06827</a> (replaced) [<a href="/pdf/2303.06827" title="Download PDF">pdf</a>, <a href="/format/2303.06827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Density Bayesian Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandyam%2C+A">Aishwarya Mandyam</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Didong Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Diana Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+A">Andrew Jones</a>, 
<a href="/search/cs?searchtype=author&query=Engelhardt%2C+B+E">Barbara E. Engelhardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08320" title="Abstract">arXiv:2303.08320</a> (replaced) [<a href="/pdf/2303.08320" title="Download PDF">pdf</a>, <a href="/format/2303.08320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoFusion: Decomposed Diffusion Models for High-Quality Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhengxiong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dayou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08627" title="Abstract">arXiv:2303.08627</a> (replaced) [<a href="/pdf/2303.08627" title="Download PDF">pdf</a>, <a href="/format/2303.08627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Images to Features: Unbiased Morphology Classification via  Variational Auto-Encoders and Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Xu%2C+Q">Quanfeng Xu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Shen%2C+S">Shiyin Shen</a>, 
<a href="/search/astro-ph?searchtype=author&query=de+Souza%2C+R+S">Rafael S. de Souza</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chen%2C+M">Mi Chen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ye%2C+R">Renhao Ye</a>, 
<a href="/search/astro-ph?searchtype=author&query=She%2C+Y">Yumei She</a>, 
<a href="/search/astro-ph?searchtype=author&query=Chen%2C+Z">Zhu Chen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ishida%2C+E+E+O">Emille E. O. Ishida</a>, 
<a href="/search/astro-ph?searchtype=author&query=Krone-Martins%2C+A">Alberto Krone-Martins</a>, 
<a href="/search/astro-ph?searchtype=author&query=Durgesh%2C+R">Rupesh Durgesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MNRAS 2023 October 12. 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08667" title="Abstract">arXiv:2303.08667</a> (replaced) [<a href="/pdf/2303.08667" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZTBus: A Large Dataset of Time-Resolved City Bus Driving Missions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Widmer%2C+F">Fabio Widmer</a>, 
<a href="/search/eess?searchtype=author&query=Ritter%2C+A">Andreas Ritter</a>, 
<a href="/search/eess?searchtype=author&query=Onder%2C+C+H">Christopher H. Onder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Data 10, 687 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09716" title="Abstract">arXiv:2303.09716</a> (replaced) [<a href="/pdf/2303.09716" title="Download PDF">pdf</a>, <a href="/ps/2303.09716" title="Download PostScript">ps</a>, <a href="/format/2303.09716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum  Markov Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winnicki%2C+A">Anna Winnicki</a>, 
<a href="/search/cs?searchtype=author&query=Srikant%2C+R">R. Srikant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10959" title="Abstract">arXiv:2303.10959</a> (replaced) [<a href="/pdf/2303.10959" title="Download PDF">pdf</a>, <a href="/format/2303.10959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Metric-Semantic Maps using Floor Plan Priors for Long-Term  Indoor Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+N">Nicky Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Sodano%2C+M">Matteo Sodano</a>, 
<a href="/search/cs?searchtype=author&query=Marks%2C+E">Elias Marks</a>, 
<a href="/search/cs?searchtype=author&query=Behley%2C+J">Jens Behley</a>, 
<a href="/search/cs?searchtype=author&query=Stachniss%2C+C">Cyrill Stachniss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, accepted to IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11793" title="Abstract">arXiv:2303.11793</a> (replaced) [<a href="/pdf/2303.11793" title="Download PDF">pdf</a>, <a href="/format/2303.11793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OTJR: Optimal Transport Meets Optimal Jacobian Regularization for  Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+B+M">Binh M. Le</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+S">Shahroz Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13937" title="Abstract">arXiv:2303.13937</a> (replaced) [<a href="/pdf/2303.13937" title="Download PDF">pdf</a>, <a href="/format/2303.13937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Reconstruction of Particle Physics Processes using Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Ehrke%2C+L">Lukas Ehrke</a>, 
<a href="/search/hep-ph?searchtype=author&query=Raine%2C+J+A">John Andrew Raine</a>, 
<a href="/search/hep-ph?searchtype=author&query=Zoch%2C+K">Knut Zoch</a>, 
<a href="/search/hep-ph?searchtype=author&query=Guth%2C+M">Manuel Guth</a>, 
<a href="/search/hep-ph?searchtype=author&query=Golling%2C+T">Tobias Golling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 24 figures, 8 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. D 107 (2023) 116019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15833" title="Abstract">arXiv:2303.15833</a> (replaced) [<a href="/pdf/2303.15833" title="Download PDF">pdf</a>, <a href="/format/2303.15833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complementary Domain Adaptation and Generalization for Unsupervised  Continual Domain Shift Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+W">Wonguk Cho</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinha Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesup Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01575" title="Abstract">arXiv:2304.01575</a> (replaced) [<a href="/pdf/2304.01575" title="Download PDF">pdf</a>, <a href="/format/2304.01575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The expressive power of pooling in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+F+M">Filippo Maria Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Lachi%2C+V">Veronica Lachi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02401" title="Abstract">arXiv:2304.02401</a> (replaced) [<a href="/pdf/2304.02401" title="Download PDF">pdf</a>, <a href="/format/2304.02401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrivGraph: Differentially Private Graph Data Publication by Exploiting  Community Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Q">Quan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Linkang Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingyang Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The extended version of the USENIX Security '23 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03550" title="Abstract">arXiv:2304.03550</a> (replaced) [<a href="/pdf/2304.03550" title="Download PDF">pdf</a>, <a href="/format/2304.03550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Disentanglement-Alignment Network for Robust SAR Vehicle  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06385" title="Abstract">arXiv:2304.06385</a> (replaced) [<a href="/pdf/2304.06385" title="Download PDF">pdf</a>, <a href="/format/2304.06385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransHP: Image Classification with Hierarchical Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08960" title="Abstract">arXiv:2304.08960</a> (replaced) [<a href="/pdf/2304.08960" title="Download PDF">pdf</a>, <a href="/format/2304.08960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative modeling of living cells with SO(3)-equivariant implicit  neural representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+D">David Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Suk%2C+J">Julian Suk</a>, 
<a href="/search/cs?searchtype=author&query=Dummer%2C+S">Sven Dummer</a>, 
<a href="/search/cs?searchtype=author&query=Ne%C4%8Dasov%C3%A1%2C+T">Tereza Ne&#x10d;asov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Ulman%2C+V">Vladim&#xed;r Ulman</a>, 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+D">David Svoboda</a>, 
<a href="/search/cs?searchtype=author&query=Wolterink%2C+J+M">Jelmer M. Wolterink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Medical Image Analysis (MedIA) 2023 (Accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09653" title="Abstract">arXiv:2304.09653</a> (replaced) [<a href="/pdf/2304.09653" title="Download PDF">pdf</a>, <a href="/format/2304.09653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReelFramer: Human-AI Co-Creation for News-to-Video Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+S">Samia Menon</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Tao Long</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+K">Keren Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dingzeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Crowston%2C+K">Kevin Crowston</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+M">Mark Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Nickerson%2C+J+V">Jeffrey V. Nickerson</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L+B">Lydia B. Chilton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11486" title="Abstract">arXiv:2304.11486</a> (replaced) [<a href="/pdf/2304.11486" title="Download PDF">pdf</a>, <a href="/ps/2304.11486" title="Download PostScript">ps</a>, <a href="/format/2304.11486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfectionism Search Algorithm (PSA): An Efficient Meta-Heuristic  Optimization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ghodousian%2C+A">A. Ghodousian</a>, 
<a href="/search/math?searchtype=author&query=Mollakazemiha%2C+M">M. Mollakazemiha</a>, 
<a href="/search/math?searchtype=author&query=Karimian%2C+N">N. Karimian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12152" title="Abstract">arXiv:2304.12152</a> (replaced) [<a href="/pdf/2304.12152" title="Download PDF">pdf</a>, <a href="/format/2304.12152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Halftoning via Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haitian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Dongliang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Image Processing (TIP), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12372" title="Abstract">arXiv:2304.12372</a> (replaced) [<a href="/pdf/2304.12372" title="Download PDF">pdf</a>, <a href="/format/2304.12372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Pixel: a Photometrically Calibrated HDR Dataset for Luminance  and Color Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolduc%2C+C">Christophe Bolduc</a>, 
<a href="/search/cs?searchtype=author&query=Giroux%2C+J">Justine Giroux</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A9bert%2C+M">Marc H&#xe9;bert</a>, 
<a href="/search/cs?searchtype=author&query=Demers%2C+C">Claude Demers</a>, 
<a href="/search/cs?searchtype=author&query=Lalonde%2C+J">Jean-Fran&#xe7;ois Lalonde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02034" title="Abstract">arXiv:2305.02034</a> (replaced) [<a href="/pdf/2305.02034" title="Download PDF">pdf</a>, <a href="/format/2305.02034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMRS: Scaling-up Remote Sensing Segmentation Dataset with Segment  Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangpei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02615" title="Abstract">arXiv:2305.02615</a> (replaced) [<a href="/pdf/2305.02615" title="Download PDF">pdf</a>, <a href="/format/2305.02615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Enhance Causal Discrimination of Utterances: A Case on Affective  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenjing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted via EMNLP2023-main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05738" title="Abstract">arXiv:2305.05738</a> (replaced) [<a href="/pdf/2305.05738" title="Download PDF">pdf</a>, <a href="/format/2305.05738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on  Wearable Medical Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chia-Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+N+K">Niraj K. Jha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 figures. This work has been submitted to the ACM for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05829" title="Abstract">arXiv:2305.05829</a> (replaced) [<a href="/pdf/2305.05829" title="Download PDF">pdf</a>, <a href="/ps/2305.05829" title="Download PostScript">ps</a>, <a href="/format/2305.05829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant Approximation for Network Revenue Management with  Markovian-Correlated Customer Arrivals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiashuo Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08960" title="Abstract">arXiv:2305.08960</a> (replaced) [<a href="/pdf/2305.08960" title="Download PDF">pdf</a>, <a href="/format/2305.08960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Forward is Enough for Neural Network Training via Likelihood Ratio  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jinyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaofei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yijie Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11484" title="Abstract">arXiv:2305.11484</a> (replaced) [<a href="/pdf/2305.11484" title="Download PDF">pdf</a>, <a href="/format/2305.11484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dive into the Power of Neuronal Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13026" title="Abstract">arXiv:2305.13026</a> (replaced) [<a href="/pdf/2305.13026" title="Download PDF">pdf</a>, <a href="/ps/2305.13026" title="Download PostScript">ps</a>, <a href="/format/2305.13026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUMB: A Benchmark for Smart Evaluation of Dutch Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+W">Wietse de Vries</a>, 
<a href="/search/cs?searchtype=author&query=Wieling%2C+M">Martijn Wieling</a>, 
<a href="/search/cs?searchtype=author&query=Nissim%2C+M">Malvina Nissim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13066" title="Abstract">arXiv:2305.13066</a> (replaced) [<a href="/pdf/2305.13066" title="Download PDF">pdf</a>, <a href="/format/2305.13066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biomedical Named Entity Recognition via Dictionary-based Synonym  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zihao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yixuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zaiqiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Collier%2C+N">Nigel Collier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14600" title="Abstract">arXiv:2305.14600</a> (replaced) [<a href="/pdf/2305.14600" title="Download PDF">pdf</a>, <a href="/format/2305.14600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Semantic Role Labeling from Compatible Label Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Kazeminejad%2C+G">Ghazaleh Kazeminejad</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+S+W">Susan W. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Palmer%2C+M">Martha Palmer</a>, 
<a href="/search/cs?searchtype=author&query=Srikumar%2C+V">Vivek Srikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14642" title="Abstract">arXiv:2305.14642</a> (replaced) [<a href="/pdf/2305.14642" title="Download PDF">pdf</a>, <a href="/format/2305.14642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newton-Cotes Graph Neural Networks: On the Time Evolution of Dynamic  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lingbing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zequn Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yixuan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14707" title="Abstract">arXiv:2305.14707</a> (replaced) [<a href="/pdf/2305.14707" title="Download PDF">pdf</a>, <a href="/format/2305.14707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciFix: Outperforming GPT3 on Scientific Factual Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashok%2C+D">Dhananjay Ashok</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Atharva Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H">Hai Pham</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%B3czos%2C+B">Barnab&#xe1;s P&#xf3;czos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in proceedings of EMNLP2023 (findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15523" title="Abstract">arXiv:2305.15523</a> (replaced) [<a href="/pdf/2305.15523" title="Download PDF">pdf</a>, <a href="/format/2305.15523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-aware Distributed Source Coding under Dynamic Bandwidth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Po-han Li</a>, 
<a href="/search/cs?searchtype=author&query=Ankireddy%2C+S+K">Sravan Kumar Ankireddy</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mahjoub%2C+H+N">Hossein Nourkhiz Mahjoub</a>, 
<a href="/search/cs?searchtype=author&query=Moradi-Pari%2C+E">Ehsan Moradi-Pari</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>, 
<a href="/search/cs?searchtype=author&query=Chinchali%2C+S">Sandeep Chinchali</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeji Kim</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15710" title="Abstract">arXiv:2305.15710</a> (replaced) [<a href="/pdf/2305.15710" title="Download PDF">pdf</a>, <a href="/format/2305.15710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUEING: a lightweight model to Capture hUman attEntion In driviNG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Linfeng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianchao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Q">Quanzheng Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xi Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15742" title="Abstract">arXiv:2305.15742</a> (replaced) [<a href="/pdf/2305.15742" title="Download PDF">pdf</a>, <a href="/format/2305.15742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Generative Models for Time-Varying Treatments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+S">Shenghao Wu</a>, 
<a href="/search/stat?searchtype=author&query=Zhou%2C+W">Wenbin Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+M">Minshuo Chen</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+S">Shixiang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16130" title="Abstract">arXiv:2305.16130</a> (replaced) [<a href="/pdf/2305.16130" title="Download PDF">pdf</a>, <a href="/format/2305.16130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mechanism for Solving Relational Tasks in Transformer Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merullo%2C+J">Jack Merullo</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+C">Carsten Eickhoff</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17216" title="Abstract">arXiv:2305.17216</a> (replaced) [<a href="/pdf/2305.17216" title="Download PDF">pdf</a>, <a href="/format/2305.17216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Images with Multimodal Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+J+Y">Jing Yu Koh</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+D">Daniel Fried</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page: <a href="http://jykoh.com/gill">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17625" title="Abstract">arXiv:2305.17625</a> (replaced) [<a href="/pdf/2305.17625" title="Download PDF">pdf</a>, <a href="/format/2305.17625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Domain Policy Adaptation via Value-Guided Data Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Chenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoteng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19008" title="Abstract">arXiv:2305.19008</a> (replaced) [<a href="/pdf/2305.19008" title="Download PDF">pdf</a>, <a href="/format/2305.19008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bottleneck Structure in Learned Features: Low-Dimension vs Regularity  Tradeoff
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacot%2C+A">Arthur Jacot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19075" title="Abstract">arXiv:2305.19075</a> (replaced) [<a href="/pdf/2305.19075" title="Download PDF">pdf</a>, <a href="/format/2305.19075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Conditioned Imitation Learning with Base Skill Priors under  Unstructured Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongkuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xiangtong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiaojie Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenguang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00639" title="Abstract">arXiv:2306.00639</a> (replaced) [<a href="/pdf/2306.00639" title="Download PDF">pdf</a>, <a href="/format/2306.00639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Being Right for Whose Right Reasons?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakobsen%2C+T+S+T">Terne Sasha Thorn Jakobsen</a>, 
<a href="/search/cs?searchtype=author&query=Cabello%2C+L">Laura Cabello</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B8gaard%2C+A">Anders S&#xf8;gaard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02865" title="Abstract">arXiv:2306.02865</a> (replaced) [<a href="/pdf/2306.02865" title="Download PDF">pdf</a>, <a href="/format/2306.02865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seizing Serendipity: Exploiting the Value of Past Success in Off-Policy  Actor-Critic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianying Ji</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03655" title="Abstract">arXiv:2306.03655</a> (replaced) [<a href="/pdf/2306.03655" title="Download PDF">pdf</a>, <a href="/format/2306.03655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning under Adversarial Nonlinear Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolev%2C+P">Pavel Kolev</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>, 
<a href="/search/cs?searchtype=author&query=Muehlebach%2C+M">Michael Muehlebach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03865" title="Abstract">arXiv:2306.03865</a> (replaced) [<a href="/pdf/2306.03865" title="Download PDF">pdf</a>, <a href="/format/2306.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Position-and-Stiffness Control of Underactuated  Antagonistic Tendon-Driven Continuum Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+B">Bowen Yi</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yeman Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dikai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+G">Jose Guadalupe Romero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05880" title="Abstract">arXiv:2306.05880</a> (replaced) [<a href="/pdf/2306.05880" title="Download PDF">pdf</a>, <a href="/format/2306.05880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Continuous Modeling for Imputation and Forecasting with  Implicit Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naour%2C+E+L">Etienne Le Naour</a>, 
<a href="/search/cs?searchtype=author&query=Serrano%2C+L">Louis Serrano</a>, 
<a href="/search/cs?searchtype=author&query=Migus%2C+L">L&#xe9;on Migus</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Agoua%2C+G">Ghislain Agoua</a>, 
<a href="/search/cs?searchtype=author&query=Baskiotis%2C+N">Nicolas Baskiotis</a>, 
<a href="/search/cs?searchtype=author&query=Gallinari%2C+P">Patrick Gallinari</a>, 
<a href="/search/cs?searchtype=author&query=Guigue%2C+V">Vincent Guigue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07261" title="Abstract">arXiv:2306.07261</a> (replaced) [<a href="/pdf/2306.07261" title="Download PDF">pdf</a>, <a href="/format/2306.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unprocessing Seven Years of Algorithmic Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruz%2C+A+F">Andr&#xe9; F. Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Hardt%2C+M">Moritz Hardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07469" title="Abstract">arXiv:2306.07469</a> (replaced) [<a href="/pdf/2306.07469" title="Download PDF">pdf</a>, <a href="/format/2306.07469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Democratizing LEO Satellite Network Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izhikevich%2C+L">Liz Izhikevich</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Manda Tran</a>, 
<a href="/search/cs?searchtype=author&query=Izhikevich%2C+K">Katherine Izhikevich</a>, 
<a href="/search/cs?searchtype=author&query=Akiwate%2C+G">Gautam Akiwate</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-Print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08247" title="Abstract">arXiv:2306.08247</a> (replaced) [<a href="/pdf/2306.08247" title="Download PDF">pdf</a>, <a href="/format/2306.08247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion in Diffusion: Cyclic One-Way Diffusion for  Text-Vision-Conditioned Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhihao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Ye Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09109" title="Abstract">arXiv:2306.09109</a> (replaced) [<a href="/pdf/2306.09109" title="Download PDF">pdf</a>, <a href="/format/2306.09109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAVI: Category-Agnostic Image Collections with High-Quality 3D Shape and  Pose Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Maninis%2C+K">Kevis-Kokitsi Maninis</a>, 
<a href="/search/cs?searchtype=author&query=Engelhardt%2C+A">Andreas Engelhardt</a>, 
<a href="/search/cs?searchtype=author&query=Karpur%2C+A">Arjun Karpur</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+K">Karen Truong</a>, 
<a href="/search/cs?searchtype=author&query=Sargent%2C+K">Kyle Sargent</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+S">Stefan Popov</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Andr&#xe9; Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Martin-Brualla%2C+R">Ricardo Martin-Brualla</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+K">Kaushal Patel</a>, 
<a href="/search/cs?searchtype=author&query=Vlasic%2C+D">Daniel Vlasic</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+V">Vittorio Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Makadia%2C+A">Ameesh Makadia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Ce Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Howard Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera ready. Project page: <a href="https://navidataset.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09675" title="Abstract">arXiv:2306.09675</a> (replaced) [<a href="/pdf/2306.09675" title="Download PDF">pdf</a>, <a href="/format/2306.09675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Class Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Depeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+C">Cheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhigang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Information Fusion
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Fusion, 2023, 102, 102021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10474" title="Abstract">arXiv:2306.10474</a> (replaced) [<a href="/pdf/2306.10474" title="Download PDF">pdf</a>, <a href="/format/2306.10474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Universal Semantic-Geometric Representation for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yingdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hanchen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023. Project website: <a href="https://semantic-geometric-representation.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10577" title="Abstract">arXiv:2306.10577</a> (replaced) [<a href="/pdf/2306.10577" title="Download PDF">pdf</a>, <a href="/format/2306.10577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenDataVal: a Unified Benchmark for Data Valuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K+F">Kevin Fu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Weixin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yongchan Kwon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, NeurIPS 2023 Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13345" title="Abstract">arXiv:2306.13345</a> (replaced) [<a href="/pdf/2306.13345" title="Download PDF">pdf</a>, <a href="/format/2306.13345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate melting point prediction through autonomous physics-informed  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Klimanova%2C+O">Olga Klimanova</a>, 
<a href="/search/cond-mat?searchtype=author&query=Miryashkin%2C+T">Timofei Miryashkin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shapeev%2C+A">Alexander Shapeev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14941" title="Abstract">arXiv:2306.14941</a> (replaced) [<a href="/pdf/2306.14941" title="Download PDF">pdf</a>, <a href="/format/2306.14941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIMMF: Semantics-aware Interactive Multiagent Motion Forecasting for  Autonomous Vehicle Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nivash%2C+V+K">Vidyaa Krishnan Nivash</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H. Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15010" title="Abstract">arXiv:2306.15010</a> (replaced) [<a href="/pdf/2306.15010" title="Download PDF">pdf</a>, <a href="/format/2306.15010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient High-Resolution Template Matching with Vector Quantized  Nearest Neighbour Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ankit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sintorn%2C+I">Ida-Maria Sintorn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15489" title="Abstract">arXiv:2306.15489</a> (replaced) [<a href="/pdf/2306.15489" title="Download PDF">pdf</a>, <a href="/format/2306.15489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precursor-of-Anomaly Detection for Irregular Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jhin%2C+S+Y">Sheo Yon Jhin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD 2023 accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16585" title="Abstract">arXiv:2306.16585</a> (replaced) [<a href="/pdf/2306.16585" title="Download PDF">pdf</a>, <a href="/format/2306.16585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeMLaPS: Real-time Semantic Mapping with Latent Prior Networks and  Quasi-Planar Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tarrio%2C+J">Juan Tarrio</a>, 
<a href="/search/cs?searchtype=author&query=Agapito%2C+L">Lourdes Agapito</a>, 
<a href="/search/cs?searchtype=author&query=Alcantarilla%2C+P+F">Pablo F. Alcantarilla</a>, 
<a href="/search/cs?searchtype=author&query=Vakhitov%2C+A">Alexander Vakhitov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RA-L 2023. 8 pages, 7 figures. Project page: <a href="http://jingwenwang95.github.io/SeMLaPS">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16978" title="Abstract">arXiv:2306.16978</a> (replaced) [<a href="/pdf/2306.16978" title="Download PDF">pdf</a>, <a href="/format/2306.16978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Coverage Paths in Unknown Environments with Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jonnarth%2C+A">Arvi Jonnarth</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17439" title="Abstract">arXiv:2306.17439</a> (replaced) [<a href="/pdf/2306.17439" title="Download PDF">pdf</a>, <a href="/format/2306.17439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Robust Watermarking for AI-Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuandong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ananth%2C+P">Prabhanjan Ananth</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00527" title="Abstract">arXiv:2307.00527</a> (replaced) [<a href="/pdf/2307.00527" title="Download PDF">pdf</a>, <a href="/format/2307.00527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks based Log Anomaly Detection and Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiayang Shi</a>, 
<a href="/search/cs?searchtype=author&query=van+Leeuwen%2C+M">Matthijs van Leeuwen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Engineering Applications of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02599" title="Abstract">arXiv:2307.02599</a> (replaced) [<a href="/pdf/2307.02599" title="Download PDF">pdf</a>, <a href="/format/2307.02599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evade ChatGPT Detectors via A Single Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shuyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wanyun Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03601" title="Abstract">arXiv:2307.03601</a> (replaced) [<a href="/pdf/2307.03601" title="Download PDF">pdf</a>, <a href="/format/2307.03601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shilong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peize Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shoufa Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Min Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code has been released at <a href="https://github.com/jshilong/GPT4RoI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05000" title="Abstract">arXiv:2307.05000</a> (replaced) [<a href="/pdf/2307.05000" title="Download PDF">pdf</a>, <a href="/format/2307.05000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Point-based Volumetric Avatar: Surface-guided Neural Points for  Efficient and Photorealistic Volumetric Head Avatar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Di Kang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+L">Linchao Bao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIGGRAPH Asia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05295" title="Abstract">arXiv:2307.05295</a> (replaced) [<a href="/pdf/2307.05295" title="Download PDF">pdf</a>, <a href="/format/2307.05295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Rate-Splitting Multiple Access in Beyond Diagonal  RIS-assisted URLLC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soleymani%2C+M">Mohammad Soleymani</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria%2C+I">Ignacio Santamaria</a>, 
<a href="/search/cs?searchtype=author&query=Jorswieck%2C+E">Eduard Jorswieck</a>, 
<a href="/search/cs?searchtype=author&query=Clerckx%2C+B">Bruno Clerckx</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Transaction of Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07085" title="Abstract">arXiv:2307.07085</a> (replaced) [<a href="/pdf/2307.07085" title="Download PDF">pdf</a>, <a href="/ps/2307.07085" title="Download PostScript">ps</a>, <a href="/format/2307.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-learned molecular mechanics force field for the simulation of  protein-ligand systems and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Takaba%2C+K">Kenichiro Takaba</a>, 
<a href="/search/physics?searchtype=author&query=Pulido%2C+I">Iv&#xe1;n Pulido</a>, 
<a href="/search/physics?searchtype=author&query=Behara%2C+P+K">Pavan Kumar Behara</a>, 
<a href="/search/physics?searchtype=author&query=Henry%2C+M">Mike Henry</a>, 
<a href="/search/physics?searchtype=author&query=MacDermott-Opeskin%2C+H">Hugo MacDermott-Opeskin</a>, 
<a href="/search/physics?searchtype=author&query=Chodera%2C+J+D">John D. Chodera</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuanqing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12482" title="Abstract">arXiv:2307.12482</a> (replaced) [<a href="/pdf/2307.12482" title="Download PDF">pdf</a>, <a href="/ps/2307.12482" title="Download PostScript">ps</a>, <a href="/format/2307.12482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight Approximations for Graphical House Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+H">Hadi Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=McGregor%2C+A">Andrew McGregor</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+R">Rik Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Vaish%2C+R">Rohit Vaish</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+V">Vignesh Viswanathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Computer Science and Game Theory (cs.GT); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12613" title="Abstract">arXiv:2307.12613</a> (replaced) [<a href="/pdf/2307.12613" title="Download PDF">pdf</a>, <a href="/format/2307.12613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning-free one-bit covariance estimation using data-driven dithering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dirksen%2C+S">Sjoerd Dirksen</a>, 
<a href="/search/math?searchtype=author&query=Maly%2C+J">Johannes Maly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Section 1.2 with effective rank-aware error bounds added to latest version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13421" title="Abstract">arXiv:2307.13421</a> (replaced) [<a href="/pdf/2307.13421" title="Download PDF">pdf</a>, <a href="/format/2307.13421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Learning Dynamics of Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vashisht%2C+R">Rahul Vashisht</a>, 
<a href="/search/cs?searchtype=author&query=Ramaswamy%2C+H+G">Harish G. Ramaswamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings at ECAI-2023 IOS Press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14791" title="Abstract">arXiv:2307.14791</a> (replaced) [<a href="/pdf/2307.14791" title="Download PDF">pdf</a>, <a href="/format/2307.14791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Parallelization of Software Network Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+F">Francisco Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F+M+V">Fernando M. V. Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Pedrosa%2C+L">Luis Pedrosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 14 figures, to be published in NSDI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16500" title="Abstract">arXiv:2307.16500</a> (replaced) [<a href="/pdf/2307.16500" title="Download PDF">pdf</a>, <a href="/ps/2307.16500" title="Download PostScript">ps</a>, <a href="/format/2307.16500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Linear Height and Linear Size-to-Height Increase for Macro Tree  Transducers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gallot%2C+P">Paul Gallot</a>, 
<a href="/search/cs?searchtype=author&query=Maneth%2C+S">Sebastian Maneth</a>, 
<a href="/search/cs?searchtype=author&query=Nakano%2C+K">Keisuke Nakano</a>, 
<a href="/search/cs?searchtype=author&query=Peyrat%2C+C">Charles Peyrat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16506" title="Abstract">arXiv:2307.16506</a> (replaced) [<a href="/pdf/2307.16506" title="Download PDF">pdf</a>, <a href="/format/2307.16506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Equivariant Neural Networks for Particle Physics: PELICAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Bogatskiy%2C+A">Alexander Bogatskiy</a>, 
<a href="/search/hep-ph?searchtype=author&query=Hoffman%2C+T">Timothy Hoffman</a>, 
<a href="/search/hep-ph?searchtype=author&query=Miller%2C+D+W">David W. Miller</a>, 
<a href="/search/hep-ph?searchtype=author&query=Offermann%2C+J+T">Jan T. Offermann</a>, 
<a href="/search/hep-ph?searchtype=author&query=Liu%2C+X">Xiaoyang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 34 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01497" title="Abstract">arXiv:2308.01497</a> (replaced) [<a href="/pdf/2308.01497" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Displays Emergent Ability to Interpret Novel  Literary Metaphors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichien%2C+N">Nicholas Ichien</a>, 
<a href="/search/cs?searchtype=author&query=Stamenkovi%C4%87%2C+D">Du&#x161;an Stamenkovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Holyoak%2C+K+J">Keith J. Holyoak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02182" title="Abstract">arXiv:2308.02182</a> (replaced) [<a href="/pdf/2308.02182" title="Download PDF">pdf</a>, <a href="/format/2308.02182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoML4ETC: Automated Neural Architecture Search for Real-World  Encrypted Traffic Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malekghaini%2C+N">Navid Malekghaini</a>, 
<a href="/search/cs?searchtype=author&query=Akbari%2C+E">Elham Akbari</a>, 
<a href="/search/cs?searchtype=author&query=Salahuddin%2C+M+A">Mohammad A. Salahuddin</a>, 
<a href="/search/cs?searchtype=author&query=Limam%2C+N">Noura Limam</a>, 
<a href="/search/cs?searchtype=author&query=Boutaba%2C+R">Raouf Boutaba</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+B">Bertrand Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Moteau%2C+S">Stephanie Moteau</a>, 
<a href="/search/cs?searchtype=author&query=Tuffin%2C+S">Stephane Tuffin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted for publication in IEEE TNSM journal. Please cite that version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02383" title="Abstract">arXiv:2308.02383</a> (replaced) [<a href="/pdf/2308.02383" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What do we know about the disruption index in scientometrics? An  overview of the literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leibel%2C+C">Christian Leibel</a>, 
<a href="/search/cs?searchtype=author&query=Bornmann%2C+L">Lutz Bornmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 13 tables, 9 figures. Submitted to "Scientometrics"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02416" title="Abstract">arXiv:2308.02416</a> (replaced) [<a href="/pdf/2308.02416" title="Download PDF">pdf</a>, <a href="/format/2308.02416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local-Global Temporal Fusion Network with an Attention Mechanism for  Multiple and Multiclass Arrhythmia Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+Y+K">Yun Kwan Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+M">Minji Lee</a>, 
<a href="/search/eess?searchtype=author&query=Jo%2C+K">Kunwook Jo</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+H+S">Hee Seok Song</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02490" title="Abstract">arXiv:2308.02490</a> (replaced) [<a href="/pdf/2308.02490" title="Download PDF">pdf</a>, <a href="/format/2308.02490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update results of OpenFlamingo-9B (MPT), LLaMA-Adapter v2-7B, and Otter-9B (MPT). Code, data and leaderboard: <a href="https://github.com/yuweihao/MM-Vet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04123" title="Abstract">arXiv:2308.04123</a> (replaced) [<a href="/pdf/2308.04123" title="Download PDF">pdf</a>, <a href="/format/2308.04123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twinning Commercial Radio Waveforms in the Colosseum Wireless Network  Emulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villa%2C+D">Davide Villa</a>, 
<a href="/search/cs?searchtype=author&query=Uvaydov%2C+D">Daniel Uvaydov</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Johari%2C+P">Pedram Johari</a>, 
<a href="/search/cs?searchtype=author&query=Jornet%2C+J+M">Josep Miquel Jornet</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04711" title="Abstract">arXiv:2308.04711</a> (replaced) [<a href="/pdf/2308.04711" title="Download PDF">pdf</a>, <a href="/format/2308.04711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Answering Unseen Questions With Smaller Language Models Using Rationale  Generation and Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartill%2C+T">Tim Hartill</a>, 
<a href="/search/cs?searchtype=author&query=Benavides-Prado%2C+D">Diana Benavides-Prado</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Riddle%2C+P+J">Patricia J. Riddle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05042" title="Abstract">arXiv:2308.05042</a> (replaced) [<a href="/pdf/2308.05042" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Electrical Grid with Discrete Energy Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grebel%2C+H">H. Grebel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07418" title="Abstract">arXiv:2308.07418</a> (replaced) [<a href="/pdf/2308.07418" title="Download PDF">pdf</a>, <a href="/format/2308.07418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Adaptive and Differentiable Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingxuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+V">Varun Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chenglong Ye</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning for Modeling and Computing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09259" title="Abstract">arXiv:2308.09259</a> (replaced) [<a href="/pdf/2308.09259" title="Download PDF">pdf</a>, <a href="/format/2308.09259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRGNN: Mitigating the Impact of Distribution Shift on Graph Neural  Networks via Test-Time Feature Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Rui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jielong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+F">Feng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xionghu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Linbo Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11131" title="Abstract">arXiv:2308.11131</a> (replaced) [<a href="/pdf/2308.11131" title="Download PDF">pdf</a>, <a href="/format/2308.11131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential  Behavior Comprehension in Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+R">Rong Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kounianhua Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+S">Shigang Quan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated Version. Few-shot ReLLa is now able to outperform full-shot CTR models trained on the entire training set
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12966" title="Abstract">arXiv:2308.12966</a> (replaced) [<a href="/pdf/2308.12966" title="Download PDF">pdf</a>, <a href="/format/2308.12966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qwen-VL: A Versatile Vision-Language Model for Understanding,  Localization, Text Reading, and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinze Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Shuai Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Sinan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Junyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code, demo and models are available at <a href="https://github.com/QwenLM/Qwen-VL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14714" title="Abstract">arXiv:2308.14714</a> (replaced) [<a href="/pdf/2308.14714" title="Download PDF">pdf</a>, <a href="/format/2308.14714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Surveillance Stackelberg Game: Co-Optimizing Defense  Placement and Patrol Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=John%2C+Y">Yohan John</a>, 
<a href="/search/eess?searchtype=author&query=Diaz-Garcia%2C+G">Gilberto Diaz-Garcia</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>, 
<a href="/search/eess?searchtype=author&query=Marden%2C+J+R">Jason R. Marden</a>, 
<a href="/search/eess?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, jointly submitted to the IEEE Control Systems Letters and the 2024 American Control Conference. Replaced to fix typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16687" title="Abstract">arXiv:2308.16687</a> (replaced) [<a href="/pdf/2308.16687" title="Download PDF">pdf</a>, <a href="/format/2308.16687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shmidman%2C+S">Shaltiel Shmidman</a>, 
<a href="/search/cs?searchtype=author&query=Shmidman%2C+A">Avi Shmidman</a>, 
<a href="/search/cs?searchtype=author&query=Koppel%2C+M">Moshe Koppel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated second version, with links to two question-answering models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01429" title="Abstract">arXiv:2309.01429</a> (replaced) [<a href="/pdf/2309.01429" title="Download PDF">pdf</a>, <a href="/format/2309.01429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Segment Anything Model for Change Detection in HR Remote  Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Daifeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kuiwu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bruzzone%2C+L">Lorenzo Bruzzone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01490" title="Abstract">arXiv:2309.01490</a> (replaced) [<a href="/pdf/2309.01490" title="Download PDF">pdf</a>, <a href="/format/2309.01490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Maximum Power Transfer for Movable device in Wireless Power  Transfer system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jun-Kim%2C+D">Dong Jun-Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10pages, 10 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03004" title="Abstract">arXiv:2309.03004</a> (replaced) [<a href="/pdf/2309.03004" title="Download PDF">pdf</a>, <a href="/format/2309.03004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theoretical Explanation of Activation Sparsity through Flat Minima and  Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Ze Peng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03084" title="Abstract">arXiv:2309.03084</a> (replaced) [<a href="/pdf/2309.03084" title="Download PDF">pdf</a>, <a href="/format/2309.03084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pure Monte Carlo Counterfactual Regret Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Ju Qi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Ting Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hei%2C+F">Falun Hei</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhemei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yunfeng Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06950" title="Abstract">arXiv:2309.06950</a> (replaced) [<a href="/pdf/2309.06950" title="Download PDF">pdf</a>, <a href="/format/2309.06950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Active Metric-Semantic SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yuezhan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Spasojevic%2C+I">Igor Spasojevic</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Saurav Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to RA-L for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07038" title="Abstract">arXiv:2309.07038</a> (replaced) [<a href="/pdf/2309.07038" title="Download PDF">pdf</a>, <a href="/format/2309.07038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reinforcement Learning for Jumping Monopods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bussola%2C+R">Riccardo Bussola</a>, 
<a href="/search/cs?searchtype=author&query=Focchi%2C+M">Michele Focchi</a>, 
<a href="/search/cs?searchtype=author&query=Del+Prete%2C+A">Andrea Del Prete</a>, 
<a href="/search/cs?searchtype=author&query=Fontanelli%2C+D">Daniele Fontanelli</a>, 
<a href="/search/cs?searchtype=author&query=Palopoli%2C+L">Luigi Palopoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07891" title="Abstract">arXiv:2309.07891</a> (replaced) [<a href="/pdf/2309.07891" title="Download PDF">pdf</a>, <a href="/format/2309.07891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandNeRF: Learning to Reconstruct Hand-Object Interaction Scene from a  Single RGB Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hongsuk Choi</a>, 
<a href="/search/cs?searchtype=author&query=Chavan-Dafle%2C+N">Nikhil Chavan-Dafle</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiacheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Isler%2C+V">Volkan Isler</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunsoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages including the supplementary material, 8 tables, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08730" title="Abstract">arXiv:2309.08730</a> (replaced) [<a href="/pdf/2309.08730" title="Download PDF">pdf</a>, <a href="/format/2309.08730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MusiLingo: Bridging Music and Text with Pre-trained Language Models for  Music Captioning and Query Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deng%2C+Z">Zihao Deng</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Y">Yinghao Ma</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yudong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+R">Rongchen Guo</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Benetos%2C+E">Emmanouil Benetos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08861" title="Abstract">arXiv:2309.08861</a> (replaced) [<a href="/pdf/2309.08861" title="Download PDF">pdf</a>, <a href="/format/2309.08861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demo: Intelligent Radar Detection in CBRS Band in the Colosseum Wireless  Network Emulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villa%2C+D">Davide Villa</a>, 
<a href="/search/cs?searchtype=author&query=Uvaydov%2C+D">Daniel Uvaydov</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Johari%2C+P">Pedram Johari</a>, 
<a href="/search/cs?searchtype=author&query=Jornet%2C+J+M">Josep Miquel Jornet</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09323" title="Abstract">arXiv:2309.09323</a> (replaced) [<a href="/pdf/2309.09323" title="Download PDF">pdf</a>, <a href="/format/2309.09323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Answering Layer 3 queries with DiscoSCMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">Heyang Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09379" title="Abstract">arXiv:2309.09379</a> (replaced) [<a href="/pdf/2309.09379" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Analysis of Internal Reliability for Uncertainty  Quantification of Dense Image Matching in Multi-view Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Debao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Rongjun Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Figure 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09408" title="Abstract">arXiv:2309.09408</a> (replaced) [<a href="/pdf/2309.09408" title="Download PDF">pdf</a>, <a href="/format/2309.09408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Online Distillation: Promoting Safe Reinforcement Learning by  Offline Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinning Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10448" title="Abstract">arXiv:2309.10448</a> (replaced) [<a href="/pdf/2309.10448" title="Download PDF">pdf</a>, <a href="/format/2309.10448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-AI Interactions and Societal Pitfalls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+F">Francisco Castro</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+S">S&#xe9;bastien Martin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10687" title="Abstract">arXiv:2309.10687</a> (replaced) [<a href="/pdf/2309.10687" title="Download PDF">pdf</a>, <a href="/format/2309.10687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EchoPrompt: Instructing the Model to Rephrase Queries for Improved  In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mekala%2C+R+R">Rajasekhar Reddy Mekala</a>, 
<a href="/search/cs?searchtype=author&query=Razeghi%2C+Y">Yasaman Razeghi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sameer Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11625" title="Abstract">arXiv:2309.11625</a> (replaced) [<a href="/pdf/2309.11625" title="Download PDF">pdf</a>, <a href="/format/2309.11625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Legitimate Interest is the New Consent -- Large-Scale Measurement and  Legal Compliance of IAB Europe TCF Paywalls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morel%2C+V">Victor Morel</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+C">Cristiana Santos</a>, 
<a href="/search/cs?searchtype=author&query=Fredholm%2C+V">Viktor Fredholm</a>, 
<a href="/search/cs?searchtype=author&query=Thunberg%2C+A">Adam Thunberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at WPES2023, minor modifications following feedback from the community
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12852" title="Abstract">arXiv:2309.12852</a> (replaced) [<a href="/pdf/2309.12852" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Differential Evolution with Simulation-Based Hybridization and  Self-Adaptation for Inventory Management Under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>, 
<a href="/search/math?searchtype=author&query=Mishra%2C+V">Vivek Mishra</a>, 
<a href="/search/math?searchtype=author&query=Kundu%2C+S">Sukanya Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, AsiaSIM 2023 (Springer)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12899" title="Abstract">arXiv:2309.12899</a> (replaced) [<a href="/pdf/2309.12899" title="Download PDF">pdf</a>, <a href="/format/2309.12899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OptCtrlPoints: Finding the Optimal Control Points for Biharmonic 3D  Shape Deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kunho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Uy%2C+M+A">Mikaela Angelina Uy</a>, 
<a href="/search/cs?searchtype=author&query=Paschalidou%2C+D">Despoina Paschalidou</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+A">Alec Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L+J">Leonidas J. Guibas</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+M">Minhyuk Sung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pacific Graphics 2023 (Full Paper). Project page: <a href="https://soulmates2.github.io/publications/OptCtrlPoints/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13691" title="Abstract">arXiv:2309.13691</a> (replaced) [<a href="/pdf/2309.13691" title="Download PDF">pdf</a>, <a href="/format/2309.13691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Simultaneous Information and Energy Transmission through Quantum  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+B+K">Bishal Kumar Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>, 
<a href="/search/quant-ph?searchtype=author&query=Madhok%2C+V">Vaibhav Madhok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14976" title="Abstract">arXiv:2309.14976</a> (replaced) [<a href="/pdf/2309.14976" title="Download PDF">pdf</a>, <a href="/format/2309.14976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoCaE: Mixture of Calibrated Experts Significantly Improves Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oksuz%2C+K">Kemal Oksuz</a>, 
<a href="/search/cs?searchtype=author&query=Kuzucu%2C+S">Selim Kuzucu</a>, 
<a href="/search/cs?searchtype=author&query=Joy%2C+T">Tom Joy</a>, 
<a href="/search/cs?searchtype=author&query=Dokania%2C+P+K">Puneet K. Dokania</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15395" title="Abstract">arXiv:2309.15395</a> (replaced) [<a href="/pdf/2309.15395" title="Download PDF">pdf</a>, <a href="/format/2309.15395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free, Regret-Optimal Best Policy Identification in Online CMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Honghao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lei Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16670" title="Abstract">arXiv:2309.16670</a> (replaced) [<a href="/pdf/2309.16670" title="Download PDF">pdf</a>, <a href="/format/2309.16670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decaf: Monocular Deformation Capture for Face and Hand Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimada%2C+S">Soshi Shimada</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16707" title="Abstract">arXiv:2309.16707</a> (replaced) [<a href="/pdf/2309.16707" title="Download PDF">pdf</a>, <a href="/format/2309.16707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy for Blockchain-based Decentralized Physical Infrastructure  Networks (DePIN)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ballandies%2C+M+C">Mark C. Ballandies</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+A+C+C">Andrew Chung Chee Law</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J+C">Joshua C. Yang</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6sken%2C+C">Christophe G&#xf6;sken</a>, 
<a href="/search/cs?searchtype=author&query=Andrew%2C+M">Michael Andrew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00489" title="Abstract">arXiv:2310.00489</a> (replaced) [<a href="/pdf/2310.00489" title="Download PDF">pdf</a>, <a href="/format/2310.00489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic DAG Discovery for Interpretable Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+i">ianxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenchao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuncong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanchi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01248" title="Abstract">arXiv:2310.01248</a> (replaced) [<a href="/e-print/2310.01248" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Emotional Expression and Cohesion in Image-Based Playlist  Description and Music Topics: A Continuous Parameterization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yuelyu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruoyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhongqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huiyun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Becasue I find some important fourmulation need to change
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01404" title="Abstract">arXiv:2310.01404</a> (replaced) [<a href="/pdf/2310.01404" title="Download PDF">pdf</a>, <a href="/format/2310.01404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H-InDex: Visual Reinforcement Learning with Hand-Informed  Representations for Dexterous Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruizhe Shi</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jiaxin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhecheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code and videos: <a href="https://yanjieze.com/H-InDex">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02071" title="Abstract">arXiv:2310.02071</a> (replaced) [<a href="/pdf/2310.02071" title="Download PDF">pdf</a>, <a href="/format/2310.02071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-to-End Embodied Decision Making via Multi-modal Large  Language Model: Explorations with GPT4-Vision and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haozhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zefan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuchi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Baobao Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures, Code and data: <a href="https://github.com/pkunlp-icler/PCA-EVAL/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02601" title="Abstract">arXiv:2310.02601</a> (replaced) [<a href="/pdf/2310.02601" title="Download PDF">pdf</a>, <a href="/format/2310.02601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicDrive: Street View Generation with Diverse 3D Geometry Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://flymin.github.io/magicdrive">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02778" title="Abstract">arXiv:2310.02778</a> (replaced) [<a href="/pdf/2310.02778" title="Download PDF">pdf</a>, <a href="/format/2310.02778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating UMLS Knowledge into Large Language Models for Medical  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Marrese-Taylor%2C+E">Edison Marrese-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Y">Yuhe Ke</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03026" title="Abstract">arXiv:2310.03026</a> (replaced) [<a href="/pdf/2310.03026" title="Download PDF">pdf</a>, <a href="/format/2310.03026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LanguageMPC: Large Language Models as Decision Makers for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sha%2C+H">Hao Sha</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuxuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03320" title="Abstract">arXiv:2310.03320</a> (replaced) [<a href="/e-print/2310.03320" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioBridge: Bridging Biomedical Foundation Models via Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+B">Balasubramaniam Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+V+N">Vassilis N. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Rangwala%2C+H">Huzefa Rangwala</a>, 
<a href="/search/cs?searchtype=author&query=Anubhai%2C+R">Rishita Anubhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> this paper needs further internal review for being published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03328" title="Abstract">arXiv:2310.03328</a> (replaced) [<a href="/pdf/2310.03328" title="Download PDF">pdf</a>, <a href="/format/2310.03328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reformulating Domain Adaptation of Large Language Models as  Adapt-Retrieve-Revise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=wan%2C+Z">Zhen wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yating Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yexiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Fei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kurohashi%2C+S">Sadao Kurohashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03684" title="Abstract">arXiv:2310.03684</a> (replaced) [<a href="/pdf/2310.03684" title="Download PDF">pdf</a>, <a href="/format/2310.03684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robey%2C+A">Alexander Robey</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03986" title="Abstract">arXiv:2310.03986</a> (replaced) [<a href="/pdf/2310.03986" title="Download PDF">pdf</a>, <a href="/format/2310.03986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Multimodal Learning with Missing Modalities via  Parameter-Efficient Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reza%2C+M+K">Md Kaykobad Reza</a>, 
<a href="/search/cs?searchtype=author&query=Prater-Bennette%2C+A">Ashley Prater-Bennette</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+M+S">M. Salman Asif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04069" title="Abstract">arXiv:2310.04069</a> (replaced) [<a href="/pdf/2310.04069" title="Download PDF">pdf</a>, <a href="/format/2310.04069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-temporal flow patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosyfaki%2C+C">Chrysanthi Kosyfaki</a>, 
<a href="/search/cs?searchtype=author&query=Mamoulis%2C+N">Nikos Mamoulis</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Reynold Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+B">Ben Kao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04158" title="Abstract">arXiv:2310.04158</a> (replaced) [<a href="/pdf/2310.04158" title="Download PDF">pdf</a>, <a href="/format/2310.04158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Victima: Drastically Increasing Address Translation Reach by Leveraging  Underutilized Cache Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+K">Konstantinos Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H+C">Hong Chul Nam</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+F+N">F. Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+R">Rahul Bera</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rakesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bartolini%2C+D">Davide-Basilio Bartolini</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 56th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Operating Systems (cs.OS)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04443" title="Abstract">arXiv:2310.04443</a> (replaced) [<a href="/pdf/2310.04443" title="Download PDF">pdf</a>, <a href="/format/2310.04443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Mobility Question Answering (Vision Paper)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04457" title="Abstract">arXiv:2310.04457</a> (replaced) [<a href="/pdf/2310.04457" title="Download PDF">pdf</a>, <a href="/format/2310.04457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProGO: Probabilistic Global Optimizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/math?searchtype=author&query=Ghosh%2C+S">Sujit Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04668" title="Abstract">arXiv:2310.04668</a> (replaced) [<a href="/pdf/2310.04668" title="Download PDF">pdf</a>, <a href="/format/2310.04668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-free Node Classification on Graphs with Large Language Models  (LLMS)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhikai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haitao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongzhi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haoyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code will be available soon via <a href="https://github.com/CurryTang/LLMGNN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04780" title="Abstract">arXiv:2310.04780</a> (replaced) [<a href="/pdf/2310.04780" title="Download PDF">pdf</a>, <a href="/format/2310.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenglin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xianan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Na Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaomei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04993" title="Abstract">arXiv:2310.04993</a> (replaced) [<a href="/pdf/2310.04993" title="Download PDF">pdf</a>, <a href="/format/2310.04993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-augmented Temporal Point Process for Streaming Event Sequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Siqiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Caigao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongyan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Gangwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaoyun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Y">James Y. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05185" title="Abstract">arXiv:2310.05185</a> (replaced) [<a href="/pdf/2310.05185" title="Download PDF">pdf</a>, <a href="/format/2310.05185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational  Knowledge Graph Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haoran Luo</a>, 
<a href="/search/cs?searchtype=author&query=E%2C+H">Haihong E</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Tianyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yikai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zichen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kaiyang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shiyao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Meina Song</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05280" title="Abstract">arXiv:2310.05280</a> (replaced) [<a href="/pdf/2310.05280" title="Download PDF">pdf</a>, <a href="/format/2310.05280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona  Biases in Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05364" title="Abstract">arXiv:2310.05364</a> (replaced) [<a href="/pdf/2310.05364" title="Download PDF">pdf</a>, <a href="/format/2310.05364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Multi-modal Entity Alignment via Iteratively Fusing Modality  Similarity Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bolin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lingbing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05472" title="Abstract">arXiv:2310.05472</a> (replaced) [<a href="/pdf/2310.05472" title="Download PDF">pdf</a>, <a href="/format/2310.05472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Tutoring System: Experience of Linking Software Engineering  and Programming Teaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Noller%2C+Y">Yannic Noller</a>, 
<a href="/search/cs?searchtype=author&query=Dandekar%2C+A">Ashish Dandekar</a>, 
<a href="/search/cs?searchtype=author&query=Roychoudhury%2C+A">Abhik Roychoudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05597" title="Abstract">arXiv:2310.05597</a> (replaced) [<a href="/pdf/2310.05597" title="Download PDF">pdf</a>, <a href="/format/2310.05597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can language models learn analogical reasoning? Investigating training  objectives and comparisons to human performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petersen%2C+M+R">Molly R. Petersen</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Plas%2C+L">Lonneke van der Plas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05664" title="Abstract">arXiv:2310.05664</a> (replaced) [<a href="/pdf/2310.05664" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViTs are Everywhere: A Comprehensive Study Showcasing Vision  Transformers in Different Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mia%2C+M+S">Md Sohag Mia</a>, 
<a href="/search/cs?searchtype=author&query=Arnob%2C+A+B+H">Abu Bakor Hayat Arnob</a>, 
<a href="/search/cs?searchtype=author&query=Naim%2C+A">Abdu Naim</a>, 
<a href="/search/cs?searchtype=author&query=Voban%2C+A+A+B">Abdullah Al Bary Voban</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Shariful Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCD-2023. arXiv admin note: substantial text overlap with <a href="/abs/2208.04309">arXiv:2208.04309</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05768" title="Abstract">arXiv:2310.05768</a> (replaced) [<a href="/pdf/2310.05768" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DANet: Enhancing Small Object Detection through an Efficient Deformable  Attention Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mia%2C+M+S">Md Sohag Mia</a>, 
<a href="/search/cs?searchtype=author&query=Voban%2C+A+A+B">Abdullah Al Bary Voban</a>, 
<a href="/search/cs?searchtype=author&query=Arnob%2C+A+B+H">Abu Bakor Hayat Arnob</a>, 
<a href="/search/cs?searchtype=author&query=Naim%2C+A">Abdu Naim</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+K">Md Kawsar Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md Shariful Islam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCD-23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05873" title="Abstract">arXiv:2310.05873</a> (replaced) [<a href="/pdf/2310.05873" title="Download PDF">pdf</a>, <a href="/format/2310.05873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geom-Erasing: Geometry-Driven Removal of Implicit Concept in Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J">James Kwok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06927" title="Abstract">arXiv:2310.06927</a> (replaced) [<a href="/pdf/2310.06927" title="Download PDF">pdf</a>, <a href="/format/2310.06927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Fine-tuning for Inference Acceleration of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurtic%2C+E">Eldar Kurtic</a>, 
<a href="/search/cs?searchtype=author&query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Goin%2C+M">Michael Goin</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07118" title="Abstract">arXiv:2310.07118</a> (replaced) [<a href="/pdf/2310.07118" title="Download PDF">pdf</a>, <a href="/ps/2310.07118" title="Download PostScript">ps</a>, <a href="/format/2310.07118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unclonable Non-Interactive Zero-Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jawale%2C+R">Ruta Jawale</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+D">Dakshita Khurana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07171" title="Abstract">arXiv:2310.07171</a> (replaced) [<a href="/pdf/2310.07171" title="Download PDF">pdf</a>, <a href="/format/2310.07171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Generalization via Information-Theoretic Distribution  Diversification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheshun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07321" title="Abstract">arXiv:2310.07321</a> (replaced) [<a href="/pdf/2310.07321" title="Download PDF">pdf</a>, <a href="/format/2310.07321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of Cross-Domain Data on German Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dada%2C+A">Amin Dada</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+E">Kaleb E Smith</a>, 
<a href="/search/cs?searchtype=author&query=Idrissi-Yaghir%2C+A">Ahmad Idrissi-Yaghir</a>, 
<a href="/search/cs?searchtype=author&query=Seibold%2C+C+M">Constantin Marc Seibold</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Heiliger%2C+L">Lars Heiliger</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+C+M">Christoph M. Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yonghui Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure, accepted at Findings of the Association for Computational Linguistics: EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07397" title="Abstract">arXiv:2310.07397</a> (replaced) [<a href="/pdf/2310.07397" title="Download PDF">pdf</a>, <a href="/format/2310.07397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target-oriented Proactive Dialogue Systems with Personalization: Problem  Formulation and Dataset Curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dongding Lin</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+C+T">Chak Tou Leong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP-2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07582" title="Abstract">arXiv:2310.07582</a> (replaced) [<a href="/pdf/2310.07582" title="Download PDF">pdf</a>, <a href="/format/2310.07582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Latent World Models in Simple Transformers: A Case Study on  Othello-GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazineh%2C+D+S">Dean S. Hazineh</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+J">Jeffery Chiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07653" title="Abstract">arXiv:2310.07653</a> (replaced) [<a href="/pdf/2310.07653" title="Download PDF">pdf</a>, <a href="/format/2310.07653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini-DALLE3: Interactive Text to Image by Prompting Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zeqiang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Project page at <a href="https://minidalle3.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07682" title="Abstract">arXiv:2310.07682</a> (replaced) [<a href="/pdf/2310.07682" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of MET Overexpression in Non-Small Cell Lung Adenocarcinomas  from Hematoxylin and Eosin Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ingale%2C+K">Kshitij Ingale</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+H">Sun Hae Hong</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+J+S+K">Josh S.K. Bell</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+A">Abbas Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Welch%2C+A">Amy Welch</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+L">Lingdao Sha</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+I">Irvin Ho</a>, 
<a href="/search/cs?searchtype=author&query=Nagpal%2C+K">Kunal Nagpal</a>, 
<a href="/search/cs?searchtype=author&query=BenTaieb%2C+A">Aicha BenTaieb</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R+P">Rohan P Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Stumpe%2C+M+C">Martin C Stumpe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07805" title="Abstract">arXiv:2310.07805</a> (replaced) [<a href="/pdf/2310.07805" title="Download PDF">pdf</a>, <a href="/format/2310.07805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Modeling with Phase Stochastic Bridges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiatao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+L">Laurent Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+E+A">Evangelos A. Theodorou</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J">Josh Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shuangfei Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07849" title="Abstract">arXiv:2310.07849</a> (replaced) [<a href="/pdf/2310.07849" title="Download PDF">pdf</a>, <a href="/format/2310.07849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Data Generation with Large Language Models for Text  Classification: Potential and Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hangxiao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhuoran Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07865" title="Abstract">arXiv:2310.07865</a> (replaced) [<a href="/pdf/2310.07865" title="Download PDF">pdf</a>, <a href="/ps/2310.07865" title="Download PostScript">ps</a>, <a href="/format/2310.07865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Specter (and Spectra) of Miner Extractable Value
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Angeris%2C+G">Guillermo Angeris</a>, 
<a href="/search/math?searchtype=author&query=Chitra%2C+T">Tarun Chitra</a>, 
<a href="/search/math?searchtype=author&query=Diamandis%2C+T">Theo Diamandis</a>, 
<a href="/search/math?searchtype=author&query=Kulkarni%2C+K">Kshitij Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Combinatorics (math.CO); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07958" title="Abstract">arXiv:2310.07958</a> (replaced) [<a href="/pdf/2310.07958" title="Download PDF">pdf</a>, <a href="/format/2310.07958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Deep Learning for Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Md Mahbubur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ceka%2C+I">Ira Ceka</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengzhi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Saikat Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+B">Baishakhi Ray</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+W">Wei Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE 2024 (not camera-ready version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08008" title="Abstract">arXiv:2310.08008</a> (replaced) [<a href="/pdf/2310.08008" title="Download PDF">pdf</a>, <a href="/format/2310.08008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Human Adversarial and Affable Samples on BERT  Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elangovan%2C+A">Aparna Elangovan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayuan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Verspoor%2C+K">Karin Verspoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08072" title="Abstract">arXiv:2310.08072</a> (replaced) [<a href="/pdf/2310.08072" title="Download PDF">pdf</a>, <a href="/format/2310.08072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Generative Question-Answering on Synthetic Data Obtained from  an Instruct-tuned Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+K">Kosuke Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Omi%2C+T">Takahiro Omi</a>, 
<a href="/search/cs?searchtype=author&query=Arima%2C+K">Kosuke Arima</a>, 
<a href="/search/cs?searchtype=author&query=Ishigaki%2C+T">Tatsuya Ishigaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PACLIC 2023 short paper, 4 pages (6 pages including references), 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08163" title="Abstract">arXiv:2310.08163</a> (replaced) [<a href="/pdf/2310.08163" title="Download PDF">pdf</a>, <a href="/format/2310.08163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Decentralized IDentifiers with Proof of Membership to Enable  Trust in IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pino%2C+A">Alessandro Pino</a>, 
<a href="/search/cs?searchtype=author&query=Margaria%2C+D">Davide Margaria</a>, 
<a href="/search/cs?searchtype=author&query=Vesco%2C+A">Andrea Vesco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08338" title="Abstract">arXiv:2310.08338</a> (replaced) [<a href="/pdf/2310.08338" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A cry for help: Early detection of brain injury in newborns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Onu%2C+C+C">Charles C. Onu</a>, 
<a href="/search/eess?searchtype=author&query=Latremouille%2C+S">Samantha Latremouille</a>, 
<a href="/search/eess?searchtype=author&query=Gorin%2C+A">Arsenii Gorin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Junhao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ekwochi%2C+U">Uchenna Ekwochi</a>, 
<a href="/search/eess?searchtype=author&query=Ubuane%2C+P+O">Peter O. Ubuane</a>, 
<a href="/search/eess?searchtype=author&query=Kehinde%2C+O+A">Omolara A. Kehinde</a>, 
<a href="/search/eess?searchtype=author&query=Salisu%2C+M+A">Muhammad A. Salisu</a>, 
<a href="/search/eess?searchtype=author&query=Briggs%2C+D">Datonye Briggs</a>, 
<a href="/search/eess?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/eess?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08371" title="Abstract">arXiv:2310.08371</a> (replaced) [<a href="/pdf/2310.08371" title="Download PDF">pdf</a>, <a href="/format/2310.08371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case Morphs using Wasserstein ALI and Improved MIPGAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelly%2C+U+M">Una M. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Nauta%2C+M">Meike Nauta</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Spreeuwers%2C+L+J">Luuk J. Spreeuwers</a>, 
<a href="/search/cs?searchtype=author&query=Veldhuis%2C+R+N+J">Raymond N. J. Veldhuis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08439" title="Abstract">arXiv:2310.08439</a> (replaced) [<a href="/pdf/2310.08439" title="Download PDF">pdf</a>, <a href="/format/2310.08439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TensorMD: Scalable Tensor-Diagram based Machine Learning Interatomic  Potential on Heterogeneous Many-Core Processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/physics?searchtype=author&query=Ouyang%2C+Y">Yucheng Ouyang</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Z">Zhenchuan Chen</a>, 
<a href="/search/physics?searchtype=author&query=Lin%2C+R">Rongfen Lin</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+X">Xingyu Gao</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+L">Lifang Wang</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+F">Fang Li</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Y">Yin Liu</a>, 
<a href="/search/physics?searchtype=author&query=Shang%2C+H">Honghui Shang</a>, 
<a href="/search/physics?searchtype=author&query=Song%2C+H">Haifeng Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08453" title="Abstract">arXiv:2310.08453</a> (replaced) [<a href="/pdf/2310.08453" title="Download PDF">pdf</a>, <a href="/format/2310.08453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Lead-vehicle Kinematics For Rear-end Crash Scenario Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Flannagan%2C+C">Carol Flannagan</a>, 
<a href="/search/cs?searchtype=author&query=Sander%2C+U">Ulrich Sander</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4rgman%2C+J">Jonas B&#xe4;rgman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08475" title="Abstract">arXiv:2310.08475</a> (replaced) [<a href="/pdf/2310.08475" title="Download PDF">pdf</a>, <a href="/format/2310.08475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Edit Multimodal Large Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Bozhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingbin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08586" title="Abstract">arXiv:2310.08586</a> (replaced) [<a href="/pdf/2310.08586" title="Download PDF">pdf</a>, <a href="/format/2310.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PonderV2: Pave the Way for 3D Foundation Model with A Universal  Pre-training Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haoyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Honghui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sha Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xianglong He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.00157">arXiv:2301.00157</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item304">Cross-lists</a></li>
<li><a href="#item342">Replacements</a></li>
</ul>
<small>[ total of 566 entries:  <b>1-566</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2310">2310</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
