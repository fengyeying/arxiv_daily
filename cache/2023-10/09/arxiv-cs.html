<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu  5 Oct 23  to  Fri  6 Oct 23, announced Mon,  9 Oct 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item267">Cross-lists</a></li>
<li><a href="#item315">Replacements</a></li>
</ul>
<small>[ total of 491 entries:  <b>1-491</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon,  9 Oct 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03745" title="Abstract">arXiv:2310.03745</a> [<a href="/pdf/2310.03745" title="Download PDF">pdf</a>, <a href="/format/2310.03745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Hyperelasticity with Physics-Informed Probabilistic Diffusion  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tac%2C+V">Vahidullah Tac</a>, 
<a href="/search/cs?searchtype=author&query=Rausch%2C+M+K">Manuel K Rausch</a>, 
<a href="/search/cs?searchtype=author&query=Bilionis%2C+I">Ilias Bilionis</a>, 
<a href="/search/cs?searchtype=author&query=Costabal%2C+F+S">Francisco Sahli Costabal</a>, 
<a href="/search/cs?searchtype=author&query=Tepole%2C+A+B">Adrian Buganza Tepole</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many natural materials exhibit highly complex, nonlinear, anisotropic, and
heterogeneous mechanical properties. Recently, it has been demonstrated that
data-driven strain energy functions possess the flexibility to capture the
behavior of these complex materials with high accuracy while satisfying
physics-based constraints. However, most of these approaches disregard the
uncertainty in the estimates and the spatial heterogeneity of these materials.
In this work, we leverage recent advances in generative models to address these
issues. We use as building block neural ordinary equations (NODE) that -- by
construction -- create polyconvex strain energy functions, a key property of
realistic hyperelastic material models. We combine this approach with
probabilistic diffusion models to generate new samples of strain energy
functions. This technique allows us to sample a vector of Gaussian white noise
and translate it to NODE parameters thereby representing plausible strain
energy functions. We extend our approach to spatially correlated diffusion
resulting in heterogeneous material properties for arbitrary geometries. We
extensively test our method with synthetic and experimental data on biological
tissues and run finite element simulations with various degrees of spatial
heterogeneity. We believe this approach is a major step forward including
uncertainty in predictive, data-driven models of hyperelasticity
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03755" title="Abstract">arXiv:2310.03755</a> [<a href="/pdf/2310.03755" title="Download PDF">pdf</a>, <a href="/format/2310.03755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Network Code for 2D Transient Problems  (PINN-2DT) Compatible with Google Colab
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maczuga%2C+P">Pawe&#x142; Maczuga</a>, 
<a href="/search/cs?searchtype=author&query=Skocze%C5%84%2C+M">Maciej Skocze&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=Ro%C5%BCnawski%2C+P">Przemys&#x142;aw Ro&#x17c;nawski</a>, 
<a href="/search/cs?searchtype=author&query=T%C5%82uszcz%2C+F">Filip T&#x142;uszcz</a>, 
<a href="/search/cs?searchtype=author&query=Szubert%2C+M">Marcin Szubert</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81o%C5%9B%2C+M">Marcin &#x141;o&#x15b;</a>, 
<a href="/search/cs?searchtype=author&query=Dzwinel%2C+W">Witold Dzwinel</a>, 
<a href="/search/cs?searchtype=author&query=Pingali%2C+K">Keshav Pingali</a>, 
<a href="/search/cs?searchtype=author&query=Paszy%C5%84ski%2C+M">Maciej Paszy&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG); Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present an open-source Physics Informed Neural Network environment for
simulations of transient phenomena on two-dimensional rectangular domains, with
the following features: (1) it is compatible with Google Colab which allows
automatic execution on cloud environment; (2) it supports two dimensional
time-dependent PDEs; (3) it provides simple interface for definition of the
residual loss, boundary condition and initial loss, together with their
weights; (4) it support Neumann and Dirichlet boundary conditions; (5) it
allows for customizing the number of layers and neurons per layer, as well as
for arbitrary activation function; (6) the learning rate and number of epochs
are available as parameters; (7) it automatically differentiates PINN with
respect to spatial and temporal variables; (8) it provides routines for
plotting the convergence (with running average), initial conditions learnt, 2D
and 3D snapshots from the simulation and movies (9) it includes a library of
problems: (a) non-stationary heat transfer; (b) wave equation modeling a
tsunami; (c) atmospheric simulations including thermal inversion; (d) tumor
growth simulations.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03761" title="Abstract">arXiv:2310.03761</a> [<a href="/pdf/2310.03761" title="Download PDF">pdf</a>, <a href="/format/2310.03761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timeseries on IIoT Platforms: Requirements and Survey for Digital Twins  in Process Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%B6lle%2C+C">Christoph N&#xf6;lle</a>, 
<a href="/search/cs?searchtype=author&query=Kannisto%2C+P">Petri Kannisto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In the pursue for sustainability in process industry, digital twins
necessitate the communication and storage of timeseries data about Industrial
Internet of Things (IIoT). Regarding timeseries, this paper first presents a
set of requirements specific to process industries. Then, it surveys how
existing IIoT technologies meet the requirements. The technologies include the
API specifications Asset Administration Shell (AAS), Digital Twin Definition
Language (DTDL), NGSI-LD and Open Platform Communications Unified Architecture
(OPC UA) as well as six commercial platforms. All the technologies leave
significant gaps regarding the requirements, which means that tailor-made
extensions are necessary.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03766" title="Abstract">arXiv:2310.03766</a> [<a href="/pdf/2310.03766" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Literature Based Discovery (LBD): Towards Hypothesis Generation and  Knowledge Discovery in Biomedical Text Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhasuran%2C+B">Balu Bhasuran</a>, 
<a href="/search/cs?searchtype=author&query=Murugesan%2C+G">Gurusamy Murugesan</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+J">Jeyakumar Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 Pages, 5 Figures, 4 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Biomedical knowledge is growing in an astounding pace with a majority of this
knowledge is represented as scientific publications. Text mining tools and
methods represents automatic approaches for extracting hidden patterns and
trends from this semi structured and unstructured data. In Biomedical Text
mining, Literature Based Discovery (LBD) is the process of automatically
discovering novel associations between medical terms otherwise mentioned in
disjoint literature sets. LBD approaches proven to be successfully reducing the
discovery time of potential associations that are hidden in the vast amount of
scientific literature. The process focuses on creating concept profiles for
medical terms such as a disease or symptom and connecting it with a drug and
treatment based on the statistical significance of the shared profiles. This
knowledge discovery approach introduced in 1989 still remains as a core task in
text mining. Currently the ABC principle based two approaches namely open
discovery and closed discovery are mostly explored in LBD process. This review
starts with general introduction about text mining followed by biomedical text
mining and introduces various literature resources such as MEDLINE, UMLS, MESH,
and SemMedDB. This is followed by brief introduction of the core ABC principle
and its associated two approaches open discovery and closed discovery in LBD
process. This review also discusses the deep learning applications in LBD by
reviewing the role of transformer models and neural networks based LBD models
and its future aspects. Finally, reviews the key biomedical discoveries
generated through LBD approaches in biomedicine and conclude with the current
limitations and future directions of LBD.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03767" title="Abstract">arXiv:2310.03767</a> [<a href="/pdf/2310.03767" title="Download PDF">pdf</a>, <a href="/format/2310.03767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning Algorithms for Hybrid V2X Communication: A  Benchmarking Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boukhalfa%2C+F">Fouzi Boukhalfa</a>, 
<a href="/search/cs?searchtype=author&query=Alami%2C+R">Reda Alami</a>, 
<a href="/search/cs?searchtype=author&query=Achab%2C+M">Mastane Achab</a>, 
<a href="/search/cs?searchtype=author&query=Moulines%2C+E">Eric Moulines</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In today's era, autonomous vehicles demand a safety level on par with
aircraft. Taking a cue from the aerospace industry, which relies on redundancy
to achieve high reliability, the automotive sector can also leverage this
concept by building redundancy in V2X (Vehicle-to-Everything) technologies.
Given the current lack of reliable V2X technologies, this idea is particularly
promising. By deploying multiple RATs (Radio Access Technologies) in parallel,
the ongoing debate over the standard technology for future vehicles can be put
to rest. However, coordinating multiple communication technologies is a complex
task due to dynamic, time-varying channels and varying traffic conditions. This
paper addresses the vertical handover problem in V2X using Deep Reinforcement
Learning (DRL) algorithms. The goal is to assist vehicles in selecting the most
appropriate V2X technology (DSRC/V-VLC) in a serpentine environment. The
results show that the benchmarked algorithms outperform the current
state-of-the-art approaches in terms of redundancy and usage rate of V-VLC
headlights. This result is a significant reduction in communication costs while
maintaining a high level of reliability. These results provide strong evidence
for integrating advanced DRL decision mechanisms into the architecture as a
promising approach to solving the vertical handover problem in V2X.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03770" title="Abstract">arXiv:2310.03770</a> [<a href="/pdf/2310.03770" title="Download PDF">pdf</a>, <a href="/format/2310.03770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive reduced order modeling: empowering data-driven modeling with  selective knowledge transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadeethum%2C+T">Teeratorn Kadeethum</a>, 
<a href="/search/cs?searchtype=author&query=O%27Malley%2C+D">Daniel O&#x27;Malley</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+H+S">Hari S. Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hongkyu Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Data-driven modeling can suffer from a constant demand for data, leading to
reduced accuracy and impractical for engineering applications due to the high
cost and scarcity of information. To address this challenge, we propose a
progressive reduced order modeling framework that minimizes data cravings and
enhances data-driven modeling's practicality. Our approach selectively
transfers knowledge from previously trained models through gates, similar to
how humans selectively use valuable knowledge while ignoring unuseful
information. By filtering relevant information from previous models, we can
create a surrogate model with minimal turnaround time and a smaller training
set that can still achieve high accuracy. We have tested our framework in
several cases, including transport in porous media, gravity-driven flow, and
finite deformation in hyperelastic materials. Our results illustrate that
retaining information from previous models and utilizing a valuable portion of
that knowledge can significantly improve the accuracy of the current model. We
have demonstrated the importance of progressive knowledge transfer and its
impact on model accuracy with reduced training samples. For instance, our
framework with four parent models outperforms the no-parent counterpart trained
on data nine times larger. Our research unlocks data-driven modeling's
potential for practical engineering applications by mitigating the data
scarcity issue. Our proposed framework is a significant step toward more
efficient and cost-effective data-driven modeling, fostering advancements
across various fields.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03772" title="Abstract">arXiv:2310.03772</a> [<a href="/pdf/2310.03772" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Alternative Feature Extraction Pipelines For Clinical Note  Phenotyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniel%2C+N">Neil Daniel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 0 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A common practice in the medical industry is the use of clinical notes, which
consist of detailed patient observations. However, electronic health record
systems frequently do not contain these observations in a structured format,
rendering patient information challenging to assess and evaluate automatically.
Using computational systems for the extraction of medical attributes offers
many applications, including longitudinal analysis of patients, risk
assessment, and hospital evaluation. Recent work has constructed successful
methods for phenotyping: extracting medical attributes from clinical notes.
BERT-based models can be used to transform clinical notes into a series of
representations, which are then condensed into a single document representation
based on their CLS embeddings and passed into an LSTM (Mulyar et al., 2020).
Though this pipeline yields a considerable performance improvement over
previous results, it requires extensive convergence time. This method also does
not allow for predicting attributes not yet identified in clinical notes.
<br />Considering the wide variety of medical attributes that may be present in a
clinical note, we propose an alternative pipeline utilizing ScispaCy (Neumann
et al., 2019) for the extraction of common diseases. We then train various
supervised learning models to associate the presence of these conditions with
patient attributes. Finally, we replicate a ClinicalBERT (Alsentzer et al.,
2019) and LSTM-based approach for purposes of comparison. We find that
alternative methods moderately underperform the replicated LSTM approach. Yet,
considering a complex tradeoff between accuracy and runtime, in addition to the
fact that the alternative approach also allows for the detection of medical
conditions that are not already present in a clinical note, its usage may be
considered as a supplement to established methods.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03773" title="Abstract">arXiv:2310.03773</a> [<a href="/pdf/2310.03773" title="Download PDF">pdf</a>, <a href="/format/2310.03773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional data learning using convolutional neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galarza%2C+J">Jose Galarza</a>, 
<a href="/search/cs?searchtype=author&query=Oraby%2C+T">Tamer Oraby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we show how convolutional neural networks (CNN) can be used in
regression and classification learning problems of noisy and non-noisy
functional data. The main idea is to transform the functional data into a 28 by
28 image. We use a specific but typical architecture of a convolutional neural
network to perform all the regression exercises of parameter estimation and
functional form classification. First, we use some functional case studies of
functional data with and without random noise to showcase the strength of the
new method. In particular, we use it to estimate exponential growth and decay
rates, the bandwidths of sine and cosine functions, and the magnitudes and
widths of curve peaks. We also use it to classify the monotonicity and
curvatures of functional data, algebraic versus exponential growth, and the
number of peaks of functional data. Second, we apply the same convolutional
neural networks to Lyapunov exponent estimation in noisy and non-noisy chaotic
data, in estimating rates of disease transmission from epidemic curves, and in
detecting the similarity of drug dissolution profiles. Finally, we apply the
method to real-life data to detect Parkinson's disease patients in a
classification problem. The method, although simple, shows high accuracy and is
promising for future use in engineering and medical applications.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03774" title="Abstract">arXiv:2310.03774</a> [<a href="/pdf/2310.03774" title="Download PDF">pdf</a>, <a href="/ps/2310.03774" title="Download PostScript">ps</a>, <a href="/format/2310.03774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Game Strategies for Social Networks with Self-Interested  Individuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jond%2C+H+B">Hossein B. Jond</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal submission under review. arXiv admin note: substantial text overlap with <a href="/abs/2310.03095">arXiv:2310.03095</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">A social network population engages in collective actions as a direct result
of forming a particular opinion. The strategic interactions among the
individuals acting independently and selfishly naturally portray a
noncooperative game. Nash equilibrium allows for self-enforcing strategic
interactions between selfish and self-interested individuals. This paper
presents a differential game approach to the opinion formation problem in
social networks to investigate the evolution of opinions as a result of a Nash
equilibrium. The opinion of each individual is described by a differential
equation, which is the continuous-time Hegselmann-Krause model for opinion
dynamics with a time delay in input. The objective of each individual is to
seek optimal strategies for her own opinion evolution by minimizing an
individual cost function. Two differential game problems emerge, one for a
population that is not stubborn and another for a population that is stubborn.
The open-loop Nash equilibrium actions and their associated opinion
trajectories are derived for both differential games using Pontryagin's
principle. Additionally, the receding horizon control scheme is used to
practice feedback strategies where the information flow is restricted by fixed
and complete social graphs as well as the second neighborhood concept. The game
strategies were executed on the well-known Zachary's Karate Club social
network. The resulting opinion trajectories associated with the game strategies
showed consensus, polarization, and disagreement in final opinions.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03775" title="Abstract">arXiv:2310.03775</a> [<a href="/pdf/2310.03775" title="Download PDF">pdf</a>, <a href="/format/2310.03775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidden Markov Models for Stock Market Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Catello%2C+L">Luigi Catello</a>, 
<a href="/search/eess?searchtype=author&query=Ruggiero%2C+L">Ludovica Ruggiero</a>, 
<a href="/search/eess?searchtype=author&query=Schiavone%2C+L">Lucia Schiavone</a>, 
<a href="/search/eess?searchtype=author&query=Valentino%2C+M">Mario Valentino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The stock market presents a challenging environment for accurately predicting
future stock prices due to its intricate and ever-changing nature. However, the
utilization of advanced methodologies can significantly enhance the precision
of stock price predictions. One such method is Hidden Markov Models (HMMs).
HMMs are statistical models that can be used to model the behavior of a
partially observable system, making them suitable for modeling stock prices
based on historical data. Accurate stock price predictions can help traders
make better investment decisions, leading to increased profits.
<br />In this article, we trained and tested a Hidden Markov Model for the purpose
of predicting a stock closing price based on its opening price and the
preceding day's prices. The model's performance has been evaluated using two
indicators: Mean Average Prediction Error (MAPE), which specifies the average
accuracy of our model, and Directional Prediction Accuracy (DPA), a newly
introduced indicator that accounts for the number of fractional change
predictions that are correct in sign.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03777" title="Abstract">arXiv:2310.03777</a> [<a href="/pdf/2310.03777" title="Download PDF">pdf</a>, <a href="/format/2310.03777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saifullah%2C+S">Saifullah Saifullah</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Agne%2C+S">Stefan Agne</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sheraz Ahmed</a> (2 and 3) ((1) Department of Computer Science, University of Kaiserslautern-Landau, Kaiserslautern, Rhineland-Palatinate, Germany, (2) German Research Center for Artificial Intelligence, DFKI GmbH, Kaiserslautern, Rhineland-Palatinate, Germany, (3) DeepReader GmbH, Kaiserlautern, Germany)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we introduce strategies for developing private Key Information
Extraction (KIE) systems by leveraging large pretrained document foundation
models in conjunction with differential privacy (DP), federated learning (FL),
and Differentially Private Federated Learning (DP-FL). Through extensive
experimentation on six benchmark datasets (FUNSD, CORD, SROIE, WildReceipts,
XFUND, and DOCILE), we demonstrate that large document foundation models can be
effectively fine-tuned for the KIE task under private settings to achieve
adequate performance while maintaining strong privacy guarantees. Moreover, by
thoroughly analyzing the impact of various training and model parameters on
model performance, we propose simple yet effective guidelines for achieving an
optimal privacy-utility trade-off for the KIE task under global DP. Finally, we
introduce FeAm-DP, a novel DP-FL algorithm that enables efficiently upscaling
global DP from a standalone context to a multi-client federated environment. We
conduct a comprehensive evaluation of the algorithm across various client and
privacy settings, and demonstrate its capability to achieve comparable
performance and privacy guarantees to standalone DP, even when accommodating an
increasing number of participating clients. Overall, our study offers valuable
insights into the development of private KIE systems, and highlights the
potential of document foundation models for privacy-preserved Document AI
applications. To the best of authors' knowledge, this is the first work that
explores privacy preserved document KIE using document foundation models.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03778" title="Abstract">arXiv:2310.03778</a> [<a href="/pdf/2310.03778" title="Download PDF">pdf</a>, <a href="/format/2310.03778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Boosting Models for User Response Prediction Using  Adversarial Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonsung Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, ACM RecSys 2023 Challenge Workshop accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The ACM RecSys Challenge 2023, organized by ShareChat, aims to predict the
probability of the app being installed. This paper describes the lightweight
solution to this challenge. We formulate the task as a user response prediction
task. For rapid prototyping for the task, we propose a lightweight solution
including the following steps: 1) using adversarial validation, we effectively
eliminate uninformative features from a dataset; 2) to address noisy continuous
features and categorical features with a large number of unique values, we
employ feature engineering techniques.; 3) we leverage Gradient Boosted
Decision Trees (GBDT) for their exceptional performance and scalability. The
experiments show that a single LightGBM model, without additional ensembling,
performs quite well. Our team achieved ninth place in the challenge with the
final leaderboard score of 6.059065. Code for our approach can be found here:
https://github.com/choco9966/recsys-challenge-2023.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03779" title="Abstract">arXiv:2310.03779</a> [<a href="/pdf/2310.03779" title="Download PDF">pdf</a>, <a href="/format/2310.03779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HandMeThat: Human-Robot Communication in Physical and Social  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yanming Wan</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiayuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022 (Dataset and Benchmark Track). First two authors contributed equally. Project page: <a href="http://handmethat.csail.mit.edu/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">We introduce HandMeThat, a benchmark for a holistic evaluation of instruction
understanding and following in physical and social environments. While previous
datasets primarily focused on language grounding and planning, HandMeThat
considers the resolution of human instructions with ambiguities based on the
physical (object states and relations) and social (human actions and goals)
information. HandMeThat contains 10,000 episodes of human-robot interactions.
In each episode, the robot first observes a trajectory of human actions towards
her internal goal. Next, the robot receives a human instruction and should take
actions to accomplish the subgoal set through the instruction. In this paper,
we present a textual interface for our benchmark, where the robot interacts
with a virtual environment through textual commands. We evaluate several
baseline models on HandMeThat, and show that both offline and online
reinforcement learning algorithms perform poorly on HandMeThat, suggesting
significant room for future work on physical and social human-robot
communications and interactions.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03780" title="Abstract">arXiv:2310.03780</a> [<a href="/pdf/2310.03780" title="Download PDF">pdf</a>, <a href="/format/2310.03780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4  Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phung%2C+T">Tung Phung</a>, 
<a href="/search/cs?searchtype=author&query=P%C4%83durean%2C+V">Victor-Alexandru P&#x103;durean</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anjali Singh</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+C">Christopher Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Cambronero%2C+J">Jos&#xe9; Cambronero</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+G">Gustavo Soares</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Generative AI and large language models hold great promise in enhancing
programming education by automatically generating individualized feedback for
students. We investigate the role of generative AI models in providing human
tutor-style programming hints to help students resolve errors in their buggy
programs. Recent works have benchmarked state-of-the-art models for various
feedback generation scenarios; however, their overall quality is still inferior
to human tutors and not yet ready for real-world deployment. In this paper, we
seek to push the limits of generative AI models toward providing high-quality
programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a
first step, our technique leverages GPT-4 as a ``tutor'' model to generate
hints -- it boosts the generative quality by using symbolic information of
failing test cases and fixes in prompts. As a next step, our technique
leverages GPT-3.5, a weaker model, as a ``student'' model to further validate
the hint quality -- it performs an automatic quality validation by simulating
the potential utility of providing this feedback. We show the efficacy of our
technique via extensive evaluation using three real-world datasets of Python
programs covering a variety of concepts ranging from basic algorithms to
regular expressions and data analysis using pandas library.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03812" title="Abstract">arXiv:2310.03812</a> [<a href="/pdf/2310.03812" title="Download PDF">pdf</a>, <a href="/format/2310.03812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makinen%2C+T+L">T. Lucas Makinen</a>, 
<a href="/search/cs?searchtype=author&query=Alsing%2C+J">Justin Alsing</a>, 
<a href="/search/cs?searchtype=author&query=Wandelt%2C+B+D">Benjamin D. Wandelt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 2 tables. Submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Set-based learning is an essential component of modern deep learning and
network science. Graph Neural Networks (GNNs) and their edge-free counterparts
Deepsets have proven remarkably useful on ragged and topologically challenging
datasets. The key to learning informative embeddings for set members is a
specified aggregation function, usually a sum, max, or mean. We propose
Fishnets, an aggregation strategy for learning information-optimal embeddings
for sets of data for both Bayesian inference and graph aggregation. We
demonstrate that i) Fishnets neural summaries can be scaled optimally to an
arbitrary number of data objects, ii) Fishnets aggregations are robust to
changes in data distribution, unlike standard deepsets, iii) Fishnets saturate
Bayesian information content and extend to regimes where MCMC techniques fail
and iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. We
show that by adopting a Fishnets aggregation scheme for message passing, GNNs
can achieve state-of-the-art performance versus architecture size on
ogbn-protein data over existing benchmarks with a fraction of learnable
parameters and faster training time.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03813" title="Abstract">arXiv:2310.03813</a> [<a href="/pdf/2310.03813" title="Download PDF">pdf</a>, <a href="/format/2310.03813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Cold-start Bundle Recommendation via Popularity-based  Coalescence and Curriculum Heating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hyunsik Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong-eun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Jeongin Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+U">U Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">How can we accurately recommend cold-start bundles to users? The cold-start
problem in bundle recommendation is critical in practical scenarios since new
bundles are continuously created for various marketing purposes. Despite its
importance, no previous studies have addressed cold-start bundle
recommendation. Moreover, existing methods for cold-start item recommendation
overly rely on historical information, even for unpopular bundles, failing to
tackle the primary challenge of the highly skewed distribution of bundle
interactions. In this work, we propose CoHeat (Popularity-based Coalescence and
Curriculum Heating), an accurate approach for the cold-start bundle
recommendation. CoHeat tackles the highly skewed distribution of bundle
interactions by incorporating both historical and affiliation information based
on the bundle's popularity when estimating the user-bundle relationship.
Furthermore, CoHeat effectively learns latent representations by exploiting
curriculum learning and contrastive learning. CoHeat demonstrates superior
performance in cold-start bundle recommendation, achieving up to 193% higher
nDCG@20 compared to the best competitor.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03814" title="Abstract">arXiv:2310.03814</a> [<a href="/pdf/2310.03814" title="Download PDF">pdf</a>, <a href="/format/2310.03814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Control of District Cooling Energy Plant with Reinforcement  Learning and MPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zhong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Chaudhari%2C+A">Aditya Chaudhari</a>, 
<a href="/search/eess?searchtype=author&query=Coffman%2C+A+R">Austin R. Coffman</a>, 
<a href="/search/eess?searchtype=author&query=Barooah%2C+P">Prabir Barooah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 figures. arXiv admin note: text overlap with <a href="/abs/2203.07500">arXiv:2203.07500</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider the problem of optimal control of district cooling energy plants
(DCEPs) consisting of multiple chillers, a cooling tower, and a thermal energy
storage (TES), in the presence of time-varying electricity price. A
straightforward application of model predictive control (MPC) requires solving
a challenging mixed-integer nonlinear program (MINLP) because of the on/off of
chillers and the complexity of the DCEP model. Reinforcement learning (RL) is
an attractive alternative since its real-time control computation is much
simpler. But designing an RL controller is challenging due to myriad design
choices and computationally intensive training.
<br />In this paper, we propose an RL controller and an MPC controller for
minimizing the electricity cost of a DCEP, and compare them via simulations.
The two controllers are designed to be comparable in terms of objective and
information requirements. The RL controller uses a novel Q-learning algorithm
that is based on least-squares policy iteration. We describe the design choices
for the RL controller, including the choice of state space and basis functions,
that are found to be effective. The proposed MPC controller does not need a
mixed integer solver for implementation, but only a nonlinear program (NLP)
solver. A rule-based baseline controller is also proposed to aid in comparison.
Simulation results show that the proposed RL and MPC controllers achieve
similar savings over the baseline controller, about 17%.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03817" title="Abstract">arXiv:2310.03817</a> [<a href="/pdf/2310.03817" title="Download PDF">pdf</a>, <a href="/ps/2310.03817" title="Download PostScript">ps</a>, <a href="/format/2310.03817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logical Languages Accepted by Transformer Encoders with Hard Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barcelo%2C+P">Pablo Barcelo</a>, 
<a href="/search/cs?searchtype=author&query=Kozachinskiy%2C+A">Alexander Kozachinskiy</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A+W">Anthony Widjaja Lin</a>, 
<a href="/search/cs?searchtype=author&query=Podolskii%2C+V">Vladimir Podolskii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We contribute to the study of formal languages that can be recognized by
transformer encoders. We focus on two self-attention mechanisms: (1) UHAT
(Unique Hard Attention Transformers) and (2) AHAT (Average Hard Attention
Transformers). UHAT encoders are known to recognize only languages inside the
circuit complexity class ${\sf AC}^0$, i.e., accepted by a family of poly-sized
and depth-bounded boolean circuits with unbounded fan-ins. On the other hand,
AHAT encoders can recognize languages outside ${\sf AC}^0$), but their
expressive power still lies within the bigger circuit complexity class ${\sf
TC}^0$, i.e., ${\sf AC}^0$-circuits extended by majority gates. We first show a
negative result that there is an ${\sf AC}^0$-language that cannot be
recognized by an UHAT encoder. On the positive side, we show that UHAT encoders
can recognize a rich fragment of ${\sf AC}^0$-languages, namely, all languages
definable in first-order logic with arbitrary unary numerical predicates. This
logic, includes, for example, all regular languages from ${\sf AC}^0$. We then
show that AHAT encoders can recognize all languages of our logic even when we
enrich it with counting terms. We apply these results to derive new results on
the expressive power of UHAT and AHAT up to permutation of letters (a.k.a.
Parikh images).
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03821" title="Abstract">arXiv:2310.03821</a> [<a href="/pdf/2310.03821" title="Download PDF">pdf</a>, <a href="/format/2310.03821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WLST: Weak Labels Guided Self-training for Weakly-supervised Domain  Adaptation on 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsou%2C+T">Tsung-Lin Tsou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tsung-Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W+H">Winston H. Hsu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In the field of domain adaptation (DA) on 3D object detection, most of the
work is dedicated to unsupervised domain adaptation (UDA). Yet, without any
target annotations, the performance gap between the UDA approaches and the
fully-supervised approach is still noticeable, which is impractical for
real-world applications. On the other hand, weakly-supervised domain adaptation
(WDA) is an underexplored yet practical task that only requires few labeling
effort on the target domain. To improve the DA performance in a cost-effective
way, we propose a general weak labels guided self-training framework, WLST,
designed for WDA on 3D object detection. By incorporating autolabeler, which
can generate 3D pseudo labels from 2D bounding boxes, into the existing
self-training pipeline, our method is able to generate more robust and
consistent pseudo labels that would benefit the training process on the target
domain. Extensive experiments demonstrate the effectiveness, robustness, and
detector-agnosticism of our WLST framework. Notably, it outperforms previous
state-of-the-art methods on all evaluation tasks.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03823" title="Abstract">arXiv:2310.03823</a> [<a href="/pdf/2310.03823" title="Download PDF">pdf</a>, <a href="/format/2310.03823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECAvg: An Edge-Cloud Collaborative Learning Approach using Averaged  Weights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mih%2C+A+N">Atah Nuh Mih</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hung Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kawnine%2C+A">Asfia Kawnine</a>, 
<a href="/search/cs?searchtype=author&query=Wachowicz%2C+M">Monica Wachowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Key words: edge-cloud collaboration, averaging weights, Edge AI, edge computing, cloud computing, transfer learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The use of edge devices together with cloud provides a collaborative
relationship between both classes of devices where one complements the
shortcomings of the other. Resource-constraint edge devices can benefit from
the abundant computing power provided by servers by offloading computationally
intensive tasks to the server. Meanwhile, edge devices can leverage their close
proximity to the data source to perform less computationally intensive tasks on
the data. In this paper, we propose a collaborative edge-cloud paradigm called
ECAvg in which edge devices pre-train local models on their respective datasets
and transfer the models to the server for fine-tuning. The server averages the
pre-trained weights into a global model, which is fine-tuned on the combined
data from the various edge devices. The local (edge) models are then updated
with the weights of the global (server) model. We implement a CIFAR-10
classification task using MobileNetV2, a CIFAR-100 classification task using
ResNet50, and an MNIST classification using a neural network with a single
hidden layer. We observed performance improvement in the CIFAR-10 and CIFAR-100
classification tasks using our approach, where performance improved on the
server model with averaged weights and the edge models had a better performance
after model update. On the MNIST classification, averaging weights resulted in
a drop in performance on both the server and edge models due to negative
transfer learning. From the experiment results, we conclude that our approach
is successful when implemented on deep neural networks such as MobileNetV2 and
ResNet50 instead of simple neural networks.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03827" title="Abstract">arXiv:2310.03827</a> [<a href="/pdf/2310.03827" title="Download PDF">pdf</a>, <a href="/format/2310.03827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Audio-Visual Features for Multimodal Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muppalla%2C+S">Sneha Muppalla</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Shan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deepfakes are AI-generated media in which an image or video has been
digitally modified. The advancements made in deepfake technology have led to
privacy and security issues. Most deepfake detection techniques rely on the
detection of a single modality. Existing methods for audio-visual detection do
not always surpass that of the analysis based on single modalities. Therefore,
this paper proposes an audio-visual-based method for deepfake detection, which
integrates fine-grained deepfake identification with binary classification. We
categorize the samples into four types by combining labels specific to each
single modality. This method enhances the detection under intra-domain and
cross-domain testing.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03830" title="Abstract">arXiv:2310.03830</a> [<a href="/pdf/2310.03830" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Older and younger adults are influenced differently by dark pattern  designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anaraky%2C+R+G">Reza Ghaiumy Anaraky</a>, 
<a href="/search/cs?searchtype=author&query=Lowens%2C+B">Byron Lowens</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yao Li</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+K+A">Kaileigh A. Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Risius%2C+M">Marten Risius</a>, 
<a href="/search/cs?searchtype=author&query=Page%2C+X">Xinru Page</a>, 
<a href="/search/cs?searchtype=author&query=Wisniewski%2C+P">Pamela Wisniewski</a>, 
<a href="/search/cs?searchtype=author&query=Soleimani%2C+M">Masoumeh Soleimani</a>, 
<a href="/search/cs?searchtype=author&query=Soltani%2C+M">Morteza Soltani</a>, 
<a href="/search/cs?searchtype=author&query=Knijnenburg%2C+B">Bart Knijnenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Considering that prior research has found older users undergo a different
privacy decision-making process compared to younger adults, more research is
needed to inform the behavioral privacy disclosure effects of these strategies
for different age groups. To address this gap, we used an existing dataset of
an experiment with a photo-tagging Facebook application. This experiment had a
2x2x5 between-subjects design where the manipulations were common dark pattern
design strategies: framing (positive vs. negative), privacy defaults (opt-in
vs. opt-out), and justification messages (positive normative, negative
normative, positive rationale, negative rationale, none). We compared older
(above 65 years old, N=44) and young adults (18 to 25 years old, N=162) privacy
concerns and disclosure behaviors (i.e., accepting or refusing automated photo
tagging) in the scope of dark pattern design. Overall, we find support for the
effectiveness of dark pattern designs in the sense that positive framing and
opt-out privacy defaults significantly increased disclosure behavior, while
negative justification messages significantly decreased privacy concerns.
Regarding older adults, our results show that certain dark patterns do lead to
more disclosure than for younger adults, but also to increased privacy concerns
for older adults than for younger.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03831" title="Abstract">arXiv:2310.03831</a> [<a href="/pdf/2310.03831" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIFT -- File Fragment Classification Without Metadata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Shahid Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A vital issue of file carving in digital forensics is type classification of
file fragments when the filesystem metadata is missing. Over the past decades,
there have been several efforts for developing methods to classify file
fragments. In this research, a novel sifting approach, named SIFT (Sifting File
Types), is proposed. SIFT outperforms the other state-of-the-art techniques by
at least 8%. (1) One of the significant differences between SIFT and others is
that SIFT uses a single byte as a separate feature, i.e., a total of 256 (0x00
- 0xFF) features. We also call this a lossless feature (information)
extraction, i.e., there is no loss of information. (2) The other significant
difference is the technique used to estimate inter-Classes and intra-Classes
information gain of a feature. Unlike others, SIFT adapts TF-IDF for this
purpose, and computes and assigns weight to each byte (feature) in a fragment
(sample). With these significant differences and approaches, SIFT produces
promising (better) results compared to other works.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03833" title="Abstract">arXiv:2310.03833</a> [<a href="/pdf/2310.03833" title="Download PDF">pdf</a>, <a href="/format/2310.03833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning A Disentangling Representation For PU Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zamzam%2C+O">Omar Zamzam</a>, 
<a href="/search/cs?searchtype=author&query=Akrami%2C+H">Haleh Akrami</a>, 
<a href="/search/cs?searchtype=author&query=Soltanolkotabi%2C+M">Mahdi Soltanolkotabi</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+R">Richard Leahy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we address the problem of learning a binary (positive vs.
negative) classifier given Positive and Unlabeled data commonly referred to as
PU learning. Although rudimentary techniques like clustering,
out-of-distribution detection, or positive density estimation can be used to
solve the problem in low-dimensional settings, their efficacy progressively
deteriorates with higher dimensions due to the increasing complexities in the
data distribution. In this paper we propose to learn a neural network-based
data representation using a loss function that can be used to project the
unlabeled data into two (positive and negative) clusters that can be easily
identified using simple clustering techniques, effectively emulating the
phenomenon observed in low-dimensional settings. We adopt a vector quantization
technique for the learned representations to amplify the separation between the
learned unlabeled data clusters. We conduct experiments on simulated PU data
that demonstrate the improved performance of our proposed method compared to
the current state-of-the-art approaches. We also provide some theoretical
justification for our two cluster-based approach and our algorithmic choices.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03834" title="Abstract">arXiv:2310.03834</a> [<a href="/pdf/2310.03834" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Methodology for a Medium Voltage Single Stage LLC Resonant Solar  PV Inverter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhuvela%2C+P">Parthkumar Bhuvela</a>, 
<a href="/search/eess?searchtype=author&query=Taghavi%2C+H">Hooman Taghavi</a>, 
<a href="/search/eess?searchtype=author&query=Nasiri%2C+A">Adel Nasiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">An inverter is generally employed with MV LFT to connect to the grid in a
grid-tied PV system. However, in some single-stage topologies, the LFTs are
replaced by HFT combined with an unfolder inverter. Generally, these topologies
have limited use at high-power MV grids due to high switching losses on the
primary side. This study proposes an LLC resonant converter-based single-stage
inverter design procedure. Resonant converters make use of ZVS to reduce
switching losses. The design includes both the resonant tank as well as output
filter components. The design is verified by simulations in MATLAB/Simulink for
various loads and input voltages at 13.8kV grid output voltage. THD simulations
validate the filter design.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03837" title="Abstract">arXiv:2310.03837</a> [<a href="/pdf/2310.03837" title="Download PDF">pdf</a>, <a href="/format/2310.03837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative passive imaging by iterative holography: The example of  helioseismic holography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=M%C3%BCller%2C+B">Bj&#xf6;rn M&#xfc;ller</a>, 
<a href="/search/math?searchtype=author&query=Hohage%2C+T">Thorsten Hohage</a>, 
<a href="/search/math?searchtype=author&query=Fournier%2C+D">Damien Fournier</a>, 
<a href="/search/math?searchtype=author&query=Gizon%2C+L">Laurent Gizon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In passive imaging, one attempts to reconstruct some coefficients in a wave
equation from correlations of observed randomly excited solutions to this wave
equation. Many methods proposed for this class of inverse problem so far are
only qualitative, e.g., trying to identify the support of a perturbation. Major
challenges are the increase in dimensionality when computing correlations from
primary data in a preprocessing step, and often very poor pointwise
signal-to-noise ratios. In this paper, we propose an approach that addresses
both of these challenges: It works only on the primary data while implicitly
using the full information contained in the correlation data, and it provides
quantitative estimates and convergence by iteration.
<br />Our work is motivated by helioseismic holography, a powerful imaging method
to map heterogenities and flows in the solar interior. We show that the
back-propagation used in classical helioseismic holography can be interpreted
as the adjoint of the Fr\'echet derivative of the operator which maps the
properties of the solar interior to the correlation data on the solar surface.
The theoretical and numerical framework for passive imaging problems developed
in this paper extends helioseismic holography to nonlinear problems and allows
for quantitative reconstructions. We present a proof of concept in uniform
media.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03838" title="Abstract">arXiv:2310.03838</a> [<a href="/pdf/2310.03838" title="Download PDF">pdf</a>, <a href="/format/2310.03838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chameleon: Increasing Label-Only Membership Leakage with Adaptive  Poisoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+H">Harsh Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Severi%2C+G">Giorgio Severi</a>, 
<a href="/search/cs?searchtype=author&query=Oprea%2C+A">Alina Oprea</a>, 
<a href="/search/cs?searchtype=author&query=Ullman%2C+J">Jonathan Ullman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The integration of machine learning (ML) in numerous critical applications
introduces a range of privacy concerns for individuals who provide their
datasets for model training. One such privacy risk is Membership Inference
(MI), in which an attacker seeks to determine whether a particular data sample
was included in the training dataset of a model. Current state-of-the-art MI
attacks capitalize on access to the model's predicted confidence scores to
successfully perform membership inference, and employ data poisoning to further
enhance their effectiveness. In this work, we focus on the less explored and
more realistic label-only setting, where the model provides only the predicted
label on a queried sample. We show that existing label-only MI attacks are
ineffective at inferring membership in the low False Positive Rate (FPR)
regime. To address this challenge, we propose a new attack Chameleon that
leverages a novel adaptive data poisoning strategy and an efficient query
selection method to achieve significantly more accurate membership inference
than existing label-only attacks, especially at low FPRs.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03840" title="Abstract">arXiv:2310.03840</a> [<a href="/pdf/2310.03840" title="Download PDF">pdf</a>, <a href="/format/2310.03840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextualized Structural Self-supervised Learning for Ontology Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Ontology matching (OM) entails the identification of semantic relationships
between concepts within two or more knowledge graphs (KGs) and serves as a
critical step in integrating KGs from various sources. Recent advancements in
deep OM models have harnessed the power of transformer-based language models
and the advantages of knowledge graph embedding. Nevertheless, these OM models
still face persistent challenges, such as a lack of reference alignments,
runtime latency, and unexplored different graph structures within an end-to-end
framework. In this study, we introduce a novel self-supervised learning OM
framework with input ontologies, called LaKERMap. This framework capitalizes on
the contextual and structural information of concepts by integrating implicit
knowledge into transformers. Specifically, we aim to capture multiple
structural contexts, encompassing both local and global interactions, by
employing distinct training objectives. To assess our methods, we utilize the
Bio-ML datasets and tasks. The findings from our innovative approach reveal
that LaKERMap surpasses state-of-the-art systems in terms of alignment quality
and inference time. Our models and codes are available here:
https://github.com/ellenzhuwang/lakermap.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03841" title="Abstract">arXiv:2310.03841</a> [<a href="/pdf/2310.03841" title="Download PDF">pdf</a>, <a href="/format/2310.03841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALBERTA: ALgorithm-Based Error Resilience in Transformer Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vasu Singh</a>, 
<a href="/search/cs?searchtype=author&query=Filipiuk%2C+M">Micha&#x142; Filipiuk</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+S+K+S">Siva Kumar Sastry Hari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Vision Transformers are being increasingly deployed in safety-critical
applications that demand high reliability. It is crucial to ensure the
correctness of their execution in spite of potential errors such as transient
hardware errors. We propose a novel algorithm-based resilience framework called
ALBERTA that allows us to perform end-to-end resilience analysis and protection
of transformer-based architectures. First, our work develops an efficient
process of computing and ranking the resilience of transformers layers. We find
that due to the large size of transformer models, applying traditional network
redundancy to a subset of the most vulnerable layers provides high error
coverage albeit with impractically high overhead. We address this shortcoming
by providing a software-directed, checksum-based error detection technique
aimed at protecting the most vulnerable general matrix multiply (GEMM) layers
in the transformer models that use either floating-point or integer arithmetic.
Results show that our approach achieves over 99% coverage for errors that
result in a mismatch at less than 0.2% computation overhead. Lastly, we present
the applicability of our framework in various modern GPU architectures under
different numerical precisions. We introduce an efficient self-correction
mechanism for resolving erroneous detection with an average overhead of less
than 0.002% (with a 2% overhead to resolve each erroneous detection).
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03843" title="Abstract">arXiv:2310.03843</a> [<a href="/pdf/2310.03843" title="Download PDF">pdf</a>, <a href="/format/2310.03843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less is More: On the Feature Redundancy of Pretrained Models When  Transferring to Few-shot Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Difan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transferring a pretrained model to a downstream task can be as easy as
conducting linear probing with target data, that is, training a linear
classifier upon frozen features extracted from the pretrained model. As there
may exist significant gaps between pretraining and downstream datasets, one may
ask whether all dimensions of the pretrained features are useful for a given
downstream task. We show that, for linear probing, the pretrained features can
be extremely redundant when the downstream data is scarce, or few-shot. For
some cases such as 5-way 1-shot tasks, using only 1\% of the most important
feature dimensions is able to recover the performance achieved by using the
full representation. Interestingly, most dimensions are redundant only under
few-shot settings and gradually become useful when the number of shots
increases, suggesting that feature redundancy may be the key to characterizing
the "few-shot" nature of few-shot transfer problems. We give a theoretical
understanding of this phenomenon and show how dimensions with high variance and
small distance between class centroids can serve as confounding factors that
severely disturb classification results under few-shot settings. As an attempt
at solving this problem, we find that the redundant features are difficult to
identify accurately with a small number of training samples, but we can instead
adjust feature magnitude with a soft mask based on estimated feature
importance. We show that this method can generally improve few-shot transfer
performance across various pretrained models and downstream datasets.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03848" title="Abstract">arXiv:2310.03848</a> [<a href="/pdf/2310.03848" title="Download PDF">pdf</a>, <a href="/format/2310.03848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenIncrement: A Unified Framework for Open Set Recognition and Deep  Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Grohnfeldt%2C+C">Claas Grohnfeldt</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 1st Workshop on Visual Continual Learning in conjunction with ICCV
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In most works on deep incremental learning research, it is assumed that novel
samples are pre-identified for neural network retraining. However, practical
deep classifiers often misidentify these samples, leading to erroneous
predictions. Such misclassifications can degrade model performance. Techniques
like open set recognition offer a means to detect these novel samples,
representing a significant area in the machine learning domain.
<br />In this paper, we introduce a deep class-incremental learning framework
integrated with open set recognition. Our approach refines class-incrementally
learned features to adapt them for distance-based open set recognition.
Experimental results validate that our method outperforms state-of-the-art
incremental learning techniques and exhibits superior performance in open set
recognition compared to baseline methods.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03855" title="Abstract">arXiv:2310.03855</a> [<a href="/pdf/2310.03855" title="Download PDF">pdf</a>, <a href="/format/2310.03855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive anisotropic Bayesian meshing for inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bocchinfuso%2C+A">Albero Bocchinfuso</a>, 
<a href="/search/math?searchtype=author&query=Calvetti%2C+D">Daniela Calvetti</a>, 
<a href="/search/math?searchtype=author&query=Somersalo%2C+E">Erkki Somersalo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider inverse problems estimating distributed parameters from indirect
noisy observations through discretization of continuum models described by
partial differential or integral equations. It is well understood that the
errors arising from the discretization can be detrimental for ill-posed inverse
problems, as discretization error behaves as correlated noise. While this
problem can be avoided with a discretization fine enough to suppress the
modeling error level below that of the exogenous noise that is addressed, e.g.,
by regularization, the computational resources needed to deal with the
additional degrees of freedom may require high performance computing
environment. Following an earlier idea, we advocate the notion that the
discretization is one of the unknowns of the inverse problem, and is updated
iteratively together with the solution. In this approach, the discretization,
defined in terms of an underlying metric, is refined selectively only where the
representation power of the current mesh is insufficient. In this paper we
allow the metrics and meshes to be anisotropic, and we show that this leads to
significant reduction of memory allocation and computing time.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03856" title="Abstract">arXiv:2310.03856</a> [<a href="/pdf/2310.03856" title="Download PDF">pdf</a>, <a href="/format/2310.03856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Voice Biometrics: One-Shot Learning Approach for Audio Deepfake  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Awais Khan</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+K+M">Khalid Mahmood Malik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The Automatic Speaker Verification (ASV) system is vulnerable to fraudulent
activities using audio deepfakes, also known as logical-access voice spoofing
attacks. These deepfakes pose a concerning threat to voice biometrics due to
recent advancements in generative AI and speech synthesis technologies. While
several deep learning models for speech synthesis detection have been
developed, most of them show poor generalizability, especially when the attacks
have different statistical distributions from the ones seen. Therefore, this
paper presents Quick-SpoofNet, an approach for detecting both seen and unseen
synthetic attacks in the ASV system using one-shot learning and metric learning
techniques. By using the effective spectral feature set, the proposed method
extracts compact and representative temporal embeddings from the voice samples
and utilizes metric learning and triplet loss to assess the similarity index
and distinguish different embeddings. The system effectively clusters similar
speech embeddings, classifying bona fide speeches as the target class and
identifying other clusters as spoofing attacks. The proposed system is
evaluated using the ASVspoof 2019 logical access (LA) dataset and tested
against unseen deepfake attacks from the ASVspoof 2021 dataset. Additionally,
its generalization ability towards unseen bona fide speech is assessed using
speech data from the VSDC dataset.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03859" title="Abstract">arXiv:2310.03859</a> [<a href="/pdf/2310.03859" title="Download PDF">pdf</a>, <a href="/format/2310.03859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Living Lab Evaluation for Life and Social Sciences Search Platforms --  LiLAS at CLEF 2021
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaer%2C+P">Philipp Schaer</a>, 
<a href="/search/cs?searchtype=author&query=Schaible%2C+J">Johann Schaible</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+L+J">Leyla Jael Castro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages. Advances in Information Retrieval - 43rd European Conference on IR Research, ECIR 2021, Virtual Event, March 28 - April 1, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Meta-evaluation studies of system performances in controlled offline
evaluation campaigns, like TREC and CLEF, show a need for innovation in
evaluating IR-systems. The field of academic search is no exception to this.
This might be related to the fact that relevance in academic search is
multilayered and therefore the aspect of user-centric evaluation is becoming
more and more important. The Living Labs for Academic Search (LiLAS) lab aims
to strengthen the concept of user-centric living labs for the domain of
academic search by allowing participants to evaluate their retrieval approaches
in two real-world academic search systems from the life sciences and the social
sciences. To this end, we provide participants with metadata on the systems'
content as well as candidate lists with the task to rank the most relevant
candidate to the top. Using the STELLA-infrastructure, we allow participants to
easily integrate their approaches into the real-world systems and provide the
possibility to compare different approaches at the same time.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03861" title="Abstract">arXiv:2310.03861</a> [<a href="/pdf/2310.03861" title="Download PDF">pdf</a>, <a href="/format/2310.03861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Barycentric Coordinates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dodik%2C+A">Ana Dodik</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+O">Oded Stein</a>, 
<a href="/search/cs?searchtype=author&query=Sitzmann%2C+V">Vincent Sitzmann</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+J">Justin Solomon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://anadodik.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a variational technique to optimize for generalized barycentric
coordinates that offers additional control compared to existing models. Prior
work represents barycentric coordinates using meshes or closed-form formulae,
in practice limiting the choice of objective function. In contrast, we directly
parameterize the continuous function that maps any coordinate in a polytope's
interior to its barycentric coordinates using a neural field. This formulation
is enabled by our theoretical characterization of barycentric coordinates,
which allows us to construct neural fields that parameterize the entire
function class of valid coordinates. We demonstrate the flexibility of our
model using a variety of objective functions, including multiple smoothness and
deformation-aware energies; as a side contribution, we also present
mathematically-justified means of measuring and minimizing objectives like
total variation on discontinuous neural fields. We offer a practical
acceleration strategy, present a thorough validation of our algorithm, and
demonstrate several applications.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03865" title="Abstract">arXiv:2310.03865</a> [<a href="/pdf/2310.03865" title="Download PDF">pdf</a>, <a href="/format/2310.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Complexity of Program Phases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karuvally%2C+A">Arjun Karuvally</a>, 
<a href="/search/cs?searchtype=author&query=Moss%2C+J+E+B">J. Eliot B. Moss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In resource limited computing systems, sequence prediction models must
operate under tight constraints. Various models are available that cater to
prediction under these conditions that in some way focus on reducing the cost
of implementation. These resource constrained sequence prediction models, in
practice, exhibit a fundamental tradeoff between the cost of implementation and
the quality of its predictions. This fundamental tradeoff seems to be largely
unexplored for models for different tasks. Here we formulate the necessary
theory and an associated empirical procedure to explore this tradeoff space for
a particular family of machine learning models such as deep neural networks. We
anticipate that the knowledge of the behavior of this tradeoff may be
beneficial in understanding the theoretical and practical limits of creation
and deployment of models for resource constrained tasks.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03866" title="Abstract">arXiv:2310.03866</a> [<a href="/pdf/2310.03866" title="Download PDF">pdf</a>, <a href="/format/2310.03866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Repairing Natural Language to SQL Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+Z+H">Aidan Z.H. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Brancas%2C+R">Ricardo Brancas</a>, 
<a href="/search/cs?searchtype=author&query=Esteves%2C+P">Pedro Esteves</a>, 
<a href="/search/cs?searchtype=author&query=Aparicio%2C+S">Sofia Aparicio</a>, 
<a href="/search/cs?searchtype=author&query=Nadkarni%2C+J+P">Joao Pedro Nadkarni</a>, 
<a href="/search/cs?searchtype=author&query=Terra-Neves%2C+M">Miguel Terra-Neves</a>, 
<a href="/search/cs?searchtype=author&query=Manquinho%2C+V">Vasco Manquinho</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+R">Ruben Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Data analysts use SQL queries to access and manipulate data on their
databases. However, these queries are often challenging to write, and small
mistakes can lead to unexpected data output. Recent work has explored several
ways to automatically synthesize queries based on a user-provided
specification. One promising technique called text-to-SQL consists of the user
providing a natural language description of the intended behavior and the
database's schema. Even though text-to-SQL tools are becoming more accurate,
there are still many instances where they fail to produce the correct query.
<br />In this paper, we analyze when text-to-SQL tools fail to return the correct
query and show that it is often the case that the returned query is close to a
correct query. We propose to repair these failing queries using a
mutation-based approach that is agnostic to the text-to-SQL tool being used. We
evaluate our approach on two recent text-to-SQL tools, RAT-SQL and SmBoP, and
show that our approach can repair a significant number of failing queries.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03870" title="Abstract">arXiv:2310.03870</a> [<a href="/pdf/2310.03870" title="Download PDF">pdf</a>, <a href="/format/2310.03870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Regularization Improves Placenta Segmentation in Fetal EPI  MRI Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yingcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Karani%2C+N">Neerav Karani</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+N">Neel Dey</a>, 
<a href="/search/cs?searchtype=author&query=Abulnaga%2C+S+M">S. Mazdak Abulnaga</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junshen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Grant%2C+P+E">P. Ellen Grant</a>, 
<a href="/search/cs?searchtype=author&query=Turk%2C+E+A">Esra Abaci Turk</a>, 
<a href="/search/cs?searchtype=author&query=Golland%2C+P">Polina Golland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The placenta plays a crucial role in fetal development. Automated 3D placenta
segmentation from fetal EPI MRI holds promise for advancing prenatal care. This
paper proposes an effective semi-supervised learning method for improving
placenta segmentation in fetal EPI MRI time series. We employ consistency
regularization loss that promotes consistency under spatial transformation of
the same image and temporal consistency across nearby images in a time series.
The experimental results show that the method improves the overall segmentation
accuracy and provides better performance for outliers and hard samples. The
evaluation also indicates that our method improves the temporal coherency of
the prediction, which could lead to more accurate computation of temporal
placental biomarkers. This work contributes to the study of the placenta and
prenatal clinical decision-making. Code is available at
https://github.com/firstmover/cr-seg.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03873" title="Abstract">arXiv:2310.03873</a> [<a href="/pdf/2310.03873" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuromorphic Robust Framework for Concurrent Estimation and Control in  Dynamical Systems using Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadvand%2C+R">Reza Ahmadvand</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+S+S">Sarah Safura Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Banad%2C+Y+M">Yaser Mike Banad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Concurrent estimation and control of robotic systems remains an ongoing
challenge, where controllers rely on data extracted from states/parameters
riddled with uncertainties and noises. Framework suitability hinges on task
complexity and computational constraints, demanding a balance between
computational efficiency and mission-critical accuracy. This study leverages
recent advancements in neuromorphic computing, particularly spiking neural
networks (SNNs), for estimation and control applications. Our presented
framework employs a recurrent network of leaky integrate-and-fire (LIF)
neurons, mimicking a linear quadratic regulator (LQR) through a robust
filtering strategy, a modified sliding innovation filter (MSIF). Benefiting
from both the robustness of MSIF and the computational efficiency of SNN, our
framework customizes SNN weight matrices to match the desired system model
without requiring training. Additionally, the network employs a biologically
plausible firing rule similar to predictive coding. In the presence of
uncertainties, we compare the SNN-LQR-MSIF with non-spiking LQR-MSIF and the
optimal linear quadratic Gaussian (LQG) strategy. Evaluation across a workbench
linear problem and a satellite rendezvous maneuver, implementing the
Clohessy-Wiltshire (CW) model in space robotics, demonstrates that the
SNN-LQR-MSIF achieves acceptable performance in computational efficiency,
robustness, and accuracy. This positions it as a promising solution for
addressing dynamic systems' concurrent estimation and control challenges in
dynamic systems.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03878" title="Abstract">arXiv:2310.03878</a> [<a href="/pdf/2310.03878" title="Download PDF">pdf</a>, <a href="/format/2310.03878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic and Human-AI Interactive Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+Y">Yao Dou</a>, 
<a href="/search/cs?searchtype=author&query=Laban%2C+P">Philippe Laban</a>, 
<a href="/search/cs?searchtype=author&query=Gardent%2C+C">Claire Gardent</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACL 2024, Tutorial
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this tutorial, we focus on text-to-text generation, a class of natural
language generation (NLG) tasks, that takes a piece of text as input and then
generates a revision that is improved according to some specific criteria
(e.g., readability or linguistic styles), while largely retaining the original
meaning and the length of the text. This includes many useful applications,
such as text simplification, paraphrase generation, style transfer, etc. In
contrast to text summarization and open-ended text completion (e.g., story),
the text-to-text generation tasks we discuss in this tutorial are more
constrained in terms of semantic consistency and targeted language styles. This
level of control makes these tasks ideal testbeds for studying the ability of
models to generate text that is both semantically adequate and stylistically
appropriate. Moreover, these tasks are interesting from a technical standpoint,
as they require complex combinations of lexical and syntactical
transformations, stylistic control, and adherence to factual knowledge, -- all
at once. With a special focus on text simplification and revision, this
tutorial aims to provide an overview of the state-of-the-art natural language
generation research from four major aspects -- Data, Models, Human-AI
Collaboration, and Evaluation -- and to discuss and showcase a few significant
and recent advances: (1) the use of non-retrogressive approaches; (2) the shift
from fine-tuning to prompting with large language models; (3) the development
of new learnable metric and fine-grained human evaluation framework; (4) a
growing body of studies and datasets on non-English languages; (5) the rise of
HCI+NLP+Accessibility interdisciplinary research to create real-world writing
assistant systems.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03879" title="Abstract">arXiv:2310.03879</a> [<a href="/pdf/2310.03879" title="Download PDF">pdf</a>, <a href="/format/2310.03879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non Commutative Convolutional Signal Models in Neural Networks:  Stability to Small Deformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parada-Mayorga%2C+A">Alejandro Parada-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+L">Landon Butler</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper we discuss the results recently published in~[1] about
algebraic signal models (ASMs) based on non commutative algebras and their use
in convolutional neural networks. Relying on the general tools from algebraic
signal processing (ASP), we study the filtering and stability properties of non
commutative convolutional filters. We show how non commutative filters can be
stable to small perturbations on the space of operators. We also show that
although the spectral components of the Fourier representation in a non
commutative signal model are associated to spaces of dimension larger than one,
there is a trade-off between stability and selectivity similar to that observed
for commutative models. Our results have direct implications for group neural
networks, multigraph neural networks and quaternion neural networks, among
other non commutative architectures. We conclude by corroborating these results
through numerical experiments.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03882" title="Abstract">arXiv:2310.03882</a> [<a href="/pdf/2310.03882" title="Download PDF">pdf</a>, <a href="/format/2310.03882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small batch deep reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Obando-Ceron%2C+J">Johan Obando-Ceron</a>, 
<a href="/search/cs?searchtype=author&query=Bellemare%2C+M+G">Marc G. Bellemare</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In value-based deep reinforcement learning with replay memories, the batch
size parameter specifies how many transitions to sample for each gradient
update. Although critical to the learning process, this value is typically not
adjusted when proposing new algorithms. In this work we present a broad
empirical study that suggests {\em reducing} the batch size can result in a
number of significant performance gains; this is surprising, as the general
tendency when training neural networks is towards larger batch sizes for
improved performance. We complement our experimental findings with a set of
empirical analyses towards better understanding this phenomenon.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03883" title="Abstract">arXiv:2310.03883</a> [<a href="/pdf/2310.03883" title="Download PDF">pdf</a>, <a href="/format/2310.03883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surrogate-based Real-time Curbside Management for Ride-hailing and  Delivery Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vishnoi%2C+S+C">Suyash C. Vishnoi</a>, 
<a href="/search/eess?searchtype=author&query=Simoni%2C+M+D">Michele D. Simoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The present work investigates surrogate model-based optimization for
real-time curbside traffic management operations. An optimization problem is
formulated to minimize the congestion on roadway segments caused by vehicles
stopping on the segment (e.g., ride-hailing or delivery operations) and
implemented in a model predictive control framework. A hybrid simulation
approach where main traffic flows interact with individually modeled stopping
vehicles is adopted. Due to its non-linearity, the optimization problem is
coupled with a meta-heuristic. However, because simulations are time expensive
and hence unsuitable for real-time control, a trained surrogate model that
takes the decision variables as inputs and approximates the objective function
is employed to replace the simulation within the meta-heuristic algorithm.
Several modeling techniques (i.e., linear regression, polynomial regression,
neural network, radial basis network, regression tree ensemble, and Gaussian
process regression) are compared based on their accuracy in reproducing
solutions to the problem and computational tractability for real-time control
under different configurations of simulation parameters. It is found that
Gaussian process regression is the most suited for use as a surrogate model for
the given problem. Finally, a realistic application with multiple ride-hailing
vehicle operations is presented. The proposed approach for controlling the stop
positions of vehicles is able to achieve an improvement of 20.65% over the
uncontrolled case. The example shows the potential of the proposed approach in
reducing the negative impacts of stopping vehicles and favorable computational
properties.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03884" title="Abstract">arXiv:2310.03884</a> [<a href="/pdf/2310.03884" title="Download PDF">pdf</a>, <a href="/format/2310.03884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Geometry for the Working Information Theorist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+K+V">Kumar Vijay Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M+A">M. Ashok Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+T+L">Ting-Kam Leonard Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Differential Geometry (math.DG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Information geometry is a study of statistical manifolds, that is, spaces of
probability distributions from a geometric perspective. Its classical
information-theoretic applications relate to statistical concepts such as
Fisher information, sufficient statistics, and efficient estimators. Today,
information geometry has emerged as an interdisciplinary field that finds
applications in diverse areas such as radar sensing, array signal processing,
quantum physics, deep learning, and optimal transport. This article presents an
overview of essential information geometry to initiate an information theorist,
who may be unfamiliar with this exciting area of research. We explain the
concepts of divergences on statistical manifolds, generalized notions of
distances, orthogonality, and geodesics, thereby paving the way for concrete
applications and novel theoretical investigations. We also highlight some
recent information-geometric developments, which are of interest to the broader
information theory community.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03885" title="Abstract">arXiv:2310.03885</a> [<a href="/pdf/2310.03885" title="Download PDF">pdf</a>, <a href="/format/2310.03885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthy Formal Natural Language Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gordon%2C+C+S">Colin S. Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Matskevich%2C+S">Sergey Matskevich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2205.07811">arXiv:2205.07811</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 ACM SIGPLAN International Symposium on New
  Ideas, New Paradigms, and Reflections on Programming and Software (Onward!
  '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Interactive proof assistants are computer programs carefully constructed to
check a human-designed proof of a mathematical claim with high confidence in
the implementation. However, this only validates truth of a formal claim, which
may have been mistranslated from a claim made in natural language. This is
especially problematic when using proof assistants to formally verify the
correctness of software with respect to a natural language specification. The
translation from informal to formal remains a challenging, time-consuming
process that is difficult to audit for correctness.
<br />This paper shows that it is possible to build support for specifications
written in expressive subsets of natural language, within existing proof
assistants, consistent with the principles used to establish trust and
auditability in proof assistants themselves. We implement a means to provide
specifications in a modularly extensible formal subset of English, and have
them automatically translated into formal claims, entirely within the Lean
proof assistant. Our approach is extensible (placing no permanent restrictions
on grammatical structure), modular (allowing information about new words to be
distributed alongside libraries), and produces proof certificates explaining
how each word was interpreted and how the sentence's structure was used to
compute the meaning.
<br />We apply our prototype to the translation of various English descriptions of
formal specifications from a popular textbook into Lean formalizations; all can
be translated correctly with a modest lexicon with only minor modifications
related to lexicon size.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03888" title="Abstract">arXiv:2310.03888</a> [<a href="/pdf/2310.03888" title="Download PDF">pdf</a>, <a href="/format/2310.03888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Domain Analysis of Nonlinear Series Elastic Actuator via  Describing Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirao%2C+M">Motohiro Hirao</a>, 
<a href="/search/cs?searchtype=author&query=Kurkcu%2C+B">Burak Kurkcu</a>, 
<a href="/search/cs?searchtype=author&query=Ghanbarpour%2C+A">Alireza Ghanbarpour</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by 2023 IEEE ROBIO conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Nonlinear stiffness SEAs (NSEAs) inspired by biological muscles offer promise
in achieving adaptable stiffness for assistive robots. While assistive robots
are often designed and compared based on torque capability and control
bandwidth, NSEAs have not been systematically designed in the frequency domain
due to their nonlinearity. The describing function, an analytical concept for
nonlinear systems, offers a means to understand their behavior in the frequency
domain. This paper introduces a frequency domain analysis of nonlinear series
elastic actuators using the describing function method. This framework aims to
equip researchers and engineers with tools for improved design and control in
assistive robotics.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03890" title="Abstract">arXiv:2310.03890</a> [<a href="/pdf/2310.03890" title="Download PDF">pdf</a>, <a href="/format/2310.03890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Neural Network Training with Rooted Logistic Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Veluswami%2C+P+R">Praveen Raj Veluswami</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+H">Harsh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S+N">Sathya N. Ravi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Many neural networks deployed in the real world scenarios are trained using
cross entropy based loss functions. From the optimization perspective, it is
known that the behavior of first order methods such as gradient descent
crucially depend on the separability of datasets. In fact, even in the most
simplest case of binary classification, the rate of convergence depends on two
factors: (1) condition number of data matrix, and (2) separability of the
dataset. With no further pre-processing techniques such as
over-parametrization, data augmentation etc., separability is an intrinsic
quantity of the data distribution under consideration. We focus on the
landscape design of the logistic function and derive a novel sequence of {\em
strictly} convex functions that are at least as strict as logistic loss. The
minimizers of these functions coincide with those of the minimum norm solution
wherever possible. The strict convexity of the derived function can be extended
to finetune state-of-the-art models and applications. In empirical experimental
analysis, we apply our proposed rooted logistic objective to multiple deep
models, e.g., fully-connected neural networks and transformers, on various of
classification benchmarks. Our results illustrate that training with rooted
loss function is converged faster and gains performance improvements.
Furthermore, we illustrate applications of our novel rooted loss function in
generative modeling based downstream applications, such as finetuning StyleGAN
model with the rooted loss. The code implementing our losses and models can be
found here for open source software development purposes:
https://anonymous.4open.science/r/rooted_loss.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03891" title="Abstract">arXiv:2310.03891</a> [<a href="/pdf/2310.03891" title="Download PDF">pdf</a>, <a href="/format/2310.03891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HDNA: A graph-based change detection in HTML pages(Deface Attack  Detection)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhi%2C+M">Mahdi Akhi</a>, 
<a href="/search/cs?searchtype=author&query=Ghazizadeh%2C+N">Nona Ghazizadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In this paper, a new approach called HDNA (HTML DNA) is introduced for
analyzing and comparing Document Object Model (DOM) trees in order to detect
differences in HTML pages. This method assigns an identifier to each HTML page
based on its structure, which proves to be particularly useful for detecting
variations caused by server-side updates, user interactions or potential
security risks. The process involves preprocessing the HTML content generating
a DOM tree and calculating the disparities between two or more trees. By
assigning weights to the nodes valuable insights about their hierarchical
importance are obtained. The effectiveness of the HDNA approach has been
demonstrated in identifying changes in DOM trees even when dynamically
generated content is involved. Not does this method benefit web developers,
testers, and security analysts by offering a deeper understanding of how web
pages evolve. It also helps ensure the functionality and performance of web
applications. Additionally, it enables detection and response to
vulnerabilities that may arise from modifications in DOM structures. As the web
ecosystem continues to evolve HDNA proves to be a tool, for individuals engaged
in web development, testing, or security analysis.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03893" title="Abstract">arXiv:2310.03893</a> [<a href="/pdf/2310.03893" title="Download PDF">pdf</a>, <a href="/format/2310.03893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing the Features of Mitotic Figures Using a Conditional  Diffusion Probabilistic Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahadir%2C+C+D">Cagla Deniz Bahadir</a>, 
<a href="/search/cs?searchtype=author&query=Liechty%2C+B">Benjamin Liechty</a>, 
<a href="/search/cs?searchtype=author&query=Pisapia%2C+D+J">David J. Pisapia</a>, 
<a href="/search/cs?searchtype=author&query=Sabuncu%2C+M+R">Mert R. Sabuncu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Deep Generative Models Workshop at Medical Image Computing and Computer Assisted Intervention (MICCAI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Mitotic figure detection in histology images is a hard-to-define, yet
clinically significant task, where labels are generated with pathologist
interpretations and where there is no ``gold-standard'' independent
ground-truth. However, it is well-established that these interpretation based
labels are often unreliable, in part, due to differences in expertise levels
and human subjectivity. In this paper, our goal is to shed light on the
inherent uncertainty of mitosis labels and characterize the mitotic figure
classification task in a human interpretable manner. We train a probabilistic
diffusion model to synthesize patches of cell nuclei for a given mitosis label
condition. Using this model, we can then generate a sequence of synthetic
images that correspond to the same nucleus transitioning into the mitotic
state. This allows us to identify different image features associated with
mitosis, such as cytoplasm granularity, nuclear density, nuclear irregularity
and high contrast between the nucleus and the cell body. Our approach offers a
new tool for pathologists to interpret and communicate the features driving the
decision to recognize a mitotic figure.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03895" title="Abstract">arXiv:2310.03895</a> [<a href="/pdf/2310.03895" title="Download PDF">pdf</a>, <a href="/format/2310.03895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TWICE Dataset: Digital Twin of Test Scenarios in a Controlled  Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neto%2C+L+N">Leonardo Novicki Neto</a>, 
<a href="/search/cs?searchtype=author&query=Reway%2C+F">Fabio Reway</a>, 
<a href="/search/cs?searchtype=author&query=Poledna%2C+Y">Yuri Poledna</a>, 
<a href="/search/cs?searchtype=author&query=Drechsler%2C+M+F">Maikol Funk Drechsler</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+E+P">Eduardo Parente Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+W">Werner Huber</a>, 
<a href="/search/cs?searchtype=author&query=Icking%2C+C">Christian Icking</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 13 figures, submitted to IEEE Sensors Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Ensuring the safe and reliable operation of autonomous vehicles under adverse
weather remains a significant challenge. To address this, we have developed a
comprehensive dataset composed of sensor data acquired in a real test track and
reproduced in the laboratory for the same test scenarios. The provided dataset
includes camera, radar, LiDAR, inertial measurement unit (IMU), and GPS data
recorded under adverse weather conditions (rainy, night-time, and snowy
conditions). We recorded test scenarios using objects of interest such as car,
cyclist, truck and pedestrian -- some of which are inspired by EURONCAP
(European New Car Assessment Programme). The sensor data generated in the
laboratory is acquired by the execution of simulation-based tests in
hardware-in-the-loop environment with the digital twin of each real test
scenario. The dataset contains more than 2 hours of recording, which totals
more than 280GB of data. Therefore, it is a valuable resource for researchers
in the field of autonomous vehicles to test and improve their algorithms in
adverse weather conditions, as well as explore the simulation-to-reality gap.
The dataset is available for download at: https://twicedataset.github.io/site/
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03897" title="Abstract">arXiv:2310.03897</a> [<a href="/pdf/2310.03897" title="Download PDF">pdf</a>, <a href="/format/2310.03897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Break-Resilient Codes for Forensic 3D Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Canran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sima%2C+J">Jin Sima</a>, 
<a href="/search/cs?searchtype=author&query=Raviv%2C+N">Netanel Raviv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">3D printing brings about a revolution in consumption and distribution of
goods, but poses a significant risk to public safety. Any individual with
internet access and a commodity printer can now produce untraceable firearms,
keys, and dangerous counterfeit products. To aid government authorities in
combating these new security threats, objects are often tagged with identifying
information. This information, also known as fingerprints, is written into the
object using various bit embedding techniques, such as varying the width of the
molten thermoplastic layers. Yet, due to the adversarial nature of the problem,
it is important to devise tamper resilient fingerprinting techniques, so that
the fingerprint could be extracted even if the object was damaged. While
fingerprinting various forms of digital media (such as videos, images, etc.)
has been studied extensively in the past, 3D printing is a relatively new
medium which is exposed to different types of adversarial physical tampering
that do not exist in the digital world. This paper focuses on one such type of
adversarial tampering, where the adversary breaks the object to at most a
certain number of parts. This gives rise to a new adversarial coding problem,
which is formulated and investigated herein. We survey the existing technology,
present an abstract problem definition, provide lower bounds for the required
redundancy, and construct a code which attains it up to asymptotically small
factors. Notably, the problem bears some resemblance to the torn paper channel,
which was recently studied for applications in DNA storage.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03898" title="Abstract">arXiv:2310.03898</a> [<a href="/pdf/2310.03898" title="Download PDF">pdf</a>, <a href="/format/2310.03898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Incremental Learning Using Generative Experience Replay Based on  Time-aware Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zizhao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning new tasks accumulatively without forgetting remains a critical
challenge in continual learning. Generative experience replay addresses this
challenge by synthesizing pseudo-data points for past learned tasks and later
replaying them for concurrent training along with the new tasks' data.
Generative replay is the best strategy for continual learning under a strict
class-incremental setting when certain constraints need to be met: (i) constant
model size, (ii) no pre-training dataset, and (iii) no memory buffer for
storing past tasks' data. Inspired by the biological nervous system mechanisms,
we introduce a time-aware regularization method to dynamically fine-tune the
three training objective terms used for generative replay: supervised learning,
latent regularization, and data reconstruction. Experimental results on major
benchmarks indicate that our method pushes the limit of brain-inspired
continual learners under such strict settings, improves memory retention, and
increases the average performance over continually arriving tasks.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03899" title="Abstract">arXiv:2310.03899</a> [<a href="/pdf/2310.03899" title="Download PDF">pdf</a>, <a href="/format/2310.03899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrysFormer: Protein Structure Prediction via 3d Patterson Maps and  Partial Structure Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dun%2C+C">Chen Dun</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Qiutai Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shikai Jin</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+R">Ria Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+M+D">Mitchell D. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+G+N">George N. Phillips, Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Determining the structure of a protein has been a decades-long open question.
A protein's three-dimensional structure often poses nontrivial computation
costs, when classical simulation algorithms are utilized. Advances in the
transformer neural network architecture -- such as AlphaFold2 -- achieve
significant improvements for this problem, by learning from a large dataset of
sequence information and corresponding protein structures. Yet, such methods
only focus on sequence information; other available prior knowledge, such as
protein crystallography and partial structure of amino acids, could be
potentially utilized. To the best of our knowledge, we propose the first
transformer-based model that directly utilizes protein crystallography and
partial structure information to predict the electron density maps of proteins.
Via two new datasets of peptide fragments (2-residue and 15-residue) , we
demonstrate our method, dubbed \texttt{CrysFormer}, can achieve accurate
predictions, based on a much smaller dataset size and with reduced computation
costs.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03900" title="Abstract">arXiv:2310.03900</a> [<a href="/pdf/2310.03900" title="Download PDF">pdf</a>, <a href="/ps/2310.03900" title="Download PostScript">ps</a>, <a href="/format/2310.03900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Game Approach to Multi-dimensional Opinion Dynamics in Social Networks  with Stubborn Strategist Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jond%2C+H+B">Hossein B. Jond</a>, 
<a href="/search/cs?searchtype=author&query=Y%C4%B1ld%C4%B1z%2C+A">Aykut Y&#x131;ld&#x131;z</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In a social network, individuals express their opinions on several
interdependent topics, and therefore the evolution of their opinions on these
topics is also mutually dependent. In this work, we propose a differential game
model for the multi-dimensional opinion formation of a social network whose
population of agents interacts according to a communication graph. Each
individual's opinion evolves according to an aggregation of disagreements
between the agent's opinions and its graph neighbors on multiple interdependent
topics exposed to an unknown extraneous disturbance. For a social network with
strategist agents the opinions evolve over time with respect to the
minimization of a quadratic cost function that solely represents each
individual's motives against the disturbance. We find the unique
Nash/worst-case equilibrium solution for the proposed differential game model
of coupled multi-dimensional opinions under an open-loop information structure.
Moreover, we propose a distributed implementation of the Nash/worst-case
equilibrium solution. We examine the non-distributed and proposed distributed
open-loop Nash/worst-case strategies on a small social network with strategist
agents in a two-dimensional opinion space. Then we compare the opinions evolved
based on the Nash/worst-case strategy with the opinions corresponding to social
optimality actions for non-strategist agents.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03903" title="Abstract">arXiv:2310.03903</a> [<a href="/pdf/2310.03903" title="Download PDF">pdf</a>, <a href="/format/2310.03903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Multi-Agent Coordination Abilities in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agashe%2C+S">Saaket Agashe</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+E">Xin Eric Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">A pivotal aim in contemporary AI research is to develop agents proficient in
multi-agent coordination, enabling effective collaboration with both humans and
other systems. Large Language Models (LLMs), with their notable ability to
understand, generate, and interpret language in a human-like manner, stand out
as promising candidates for the development of such agents. In this study, we
build and assess the effectiveness of agents crafted using LLMs in various
coordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework,
specifically designed to enable LLMs to play coordination games. With the
LLM-Co framework, we conduct our evaluation with three game environments and
organize the evaluation into five aspects: Theory of Mind, Situated Reasoning,
Sustained Coordination, Robustness to Partners, and Explicit Assistance. First,
the evaluation of the Theory of Mind and Situated Reasoning reveals the
capabilities of LLM to infer the partner's intention and reason actions
accordingly. Then, the evaluation around Sustained Coordination and Robustness
to Partners further showcases the ability of LLMs to coordinate with an unknown
partner in complex long-horizon tasks, outperforming Reinforcement Learning
baselines. Lastly, to test Explicit Assistance, which refers to the ability of
an agent to offer help proactively, we introduce two novel layouts into the
Overcooked-AI benchmark, examining if agents can prioritize helping their
partners, sacrificing time that could have been spent on their tasks. This
research underscores the promising capabilities of LLMs in sophisticated
coordination environments and reveals the potential of LLMs in building strong
real-world agents for multi-agent coordination.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03906" title="Abstract">arXiv:2310.03906</a> [<a href="/pdf/2310.03906" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyDCM: Custom Data Center Models with Reinforcement Learning for  Sustainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+A">Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez%2C+R+L">Ricardo Luna Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Markovikj%2C+D">Dejan Markovikj</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+L+D">Lekhapriya Dheeraj Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+L">Lorenz Krause</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbanpour%2C+S">Sahand Ghorbanpour</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S">Sajad Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation (BuildSys '23), November 15--16, 2023, Istanbul, Turkey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The increasing global emphasis on sustainability and reducing carbon
emissions is pushing governments and corporations to rethink their approach to
data center design and operation. Given their high energy consumption and
exponentially large computational workloads, data centers are prime candidates
for optimizing power consumption, especially in areas such as cooling and IT
energy usage. A significant challenge in this pursuit is the lack of a
configurable and scalable thermal data center model that offers an end-to-end
pipeline. Data centers consist of multiple IT components whose geometric
configuration and heat dissipation make thermal modeling difficult. This paper
presents PyDCM, a customizable Data Center Model implemented in Python, that
allows users to create unique configurations of IT equipment with custom server
specifications and geometric arrangements of IT cabinets. The use of vectorized
thermal calculations makes PyDCM orders of magnitude faster (30 times) than
current Energy Plus modeling implementations and scales sublinearly with the
number of CPUs. Also, PyDCM enables the use of Deep Reinforcement Learning via
the Gymnasium wrapper to optimize data center cooling and offers a
user-friendly platform for testing various data center design prototypes.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03908" title="Abstract">arXiv:2310.03908</a> [<a href="/pdf/2310.03908" title="Download PDF">pdf</a>, <a href="/format/2310.03908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realizing XR Applications Using 5G-Based 3D Holographic Communication  and Mobile Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Dun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+E">Ekram Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">3D holographic communication has the potential to revolutionize the way
people interact with each other in virtual spaces, offering immersive and
realistic experiences. However, demands for high data rates, extremely low
latency, and high computations to enable this technology pose a significant
challenge. To address this challenge, we propose a novel job scheduling
algorithm that leverages Mobile Edge Computing (MEC) servers in order to
minimize the total latency in 3D holographic communication. One of the
motivations for this work is to prevent the uncanny valley effect, which can
occur when the latency hinders the seamless and real-time rendering of
holographic content, leading to a less convincing and less engaging user
experience. Our proposed algorithm dynamically allocates computation tasks to
MEC servers, considering the network conditions, computational capabilities of
the servers, and the requirements of the 3D holographic communication
application. We conduct extensive experiments to evaluate the performance of
our algorithm in terms of latency reduction, and the results demonstrate that
our approach significantly outperforms other baseline methods. Furthermore, we
present a practical scenario involving Augmented Reality (AR), which not only
illustrates the applicability of our algorithm but also highlights the
importance of minimizing latency in achieving high-quality holographic views.
By efficiently distributing the computation workload among MEC servers and
reducing the overall latency, our proposed algorithm enhances the user
experience in 3D holographic communications and paves the way for the
widespread adoption of this technology in various applications, such as
telemedicine, remote collaboration, and entertainment.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03911" title="Abstract">arXiv:2310.03911</a> [<a href="/pdf/2310.03911" title="Download PDF">pdf</a>, <a href="/format/2310.03911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coloring Deep CNN Layers with Activation Hue Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouchard%2C+L">Louis-Fran&#xe7;ois Bouchard</a>, 
<a href="/search/cs?searchtype=author&query=Lazreg%2C+M+B">Mohsen Ben Lazreg</a>, 
<a href="/search/cs?searchtype=author&query=Toews%2C+M">Matthew Toews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a novel hue-like angular parameter to model the structure
of deep convolutional neural network (CNN) activation space, referred to as the
{\em activation hue}, for the purpose of regularizing models for more effective
learning. The activation hue generalizes the notion of color hue angle in
standard 3-channel RGB intensity space to $N$-channel activation space. A
series of observations based on nearest neighbor indexing of activation vectors
with pre-trained networks indicate that class-informative activations are
concentrated about an angle $\theta$ in both the $(x,y)$ image plane and in
multi-channel activation space. A regularization term in the form of hue-like
angular $\theta$ labels is proposed to complement standard one-hot loss.
Training from scratch using combined one-hot + activation hue loss improves
classification performance modestly for a wide variety of classification tasks,
including ImageNet.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03912" title="Abstract">arXiv:2310.03912</a> [<a href="/pdf/2310.03912" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTDK-BO: High Dimensional Bayesian Optimization with Reinforced  Transformer Deep kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shmakov%2C+A">Alexander Shmakov</a>, 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbanpour%2C+S">Sahand Ghorbanpour</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+R+L">Ricardo Luna Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+A">Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Bayesian Optimization (BO), guided by Gaussian process (GP) surrogates, has
proven to be an invaluable technique for efficient, high-dimensional, black-box
optimization, a critical problem inherent to many applications such as
industrial design and scientific computing. Recent contributions have
introduced reinforcement learning (RL) to improve the optimization performance
on both single function optimization and \textit{few-shot} multi-objective
optimization. However, even few-shot techniques fail to exploit similarities
shared between closely related objectives. In this paper, we combine recent
developments in Deep Kernel Learning (DKL) and attention-based Transformer
models to improve the modeling powers of GP surrogates with meta-learning. We
propose a novel method for improving meta-learning BO surrogates by
incorporating attention mechanisms into DKL, empowering the surrogates to adapt
to contextual information gathered during the BO process. We combine this
Transformer Deep Kernel with a learned acquisition function trained with
continuous Soft Actor-Critic Reinforcement Learning to aid in exploration. This
Reinforced Transformer Deep Kernel (RTDK-BO) approach yields state-of-the-art
results in continuous high-dimensional optimization problems.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03913" title="Abstract">arXiv:2310.03913</a> [<a href="/pdf/2310.03913" title="Download PDF">pdf</a>, <a href="/format/2310.03913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRAIL Team Description Paper for RoboCup@Home 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsuji%2C+C">Chikaha Tsuji</a>, 
<a href="/search/cs?searchtype=author&query=Komukai%2C+D">Dai Komukai</a>, 
<a href="/search/cs?searchtype=author&query=Shirasaka%2C+M">Mimo Shirasaka</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+H">Hikaru Wada</a>, 
<a href="/search/cs?searchtype=author&query=Omija%2C+T">Tsunekazu Omija</a>, 
<a href="/search/cs?searchtype=author&query=Horo%2C+A">Aoi Horo</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+D">Daiki Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+S">Saki Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Ikoma%2C+S">So Ikoma</a>, 
<a href="/search/cs?searchtype=author&query=Tsunashima%2C+S">Soshi Tsunashima</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+M">Masato Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Ishimoto%2C+K">Koki Ishimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+Y">Yuya Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Matsushima%2C+T">Tatsuya Matsushima</a>, 
<a href="/search/cs?searchtype=author&query=Iwasawa%2C+Y">Yusuke Iwasawa</a>, 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+Y">Yutaka Matsuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Our team, TRAIL, consists of AI/ML laboratory members from The University of
Tokyo. We leverage our extensive research experience in state-of-the-art
machine learning to build general-purpose in-home service robots. We previously
participated in two competitions using Human Support Robot (HSR): RoboCup@Home
Japan Open 2020 (DSPL) and World Robot Summit 2020, equivalent to RoboCup World
Tournament. Throughout the competitions, we showed that a data-driven approach
is effective for performing in-home tasks. Aiming for further development of
building a versatile and fast-adaptable system, in RoboCup @Home 2023, we unify
three technologies that have recently been evaluated as components in the
fields of deep learning and robot learning into a real household robot system.
In addition, to stimulate research all over the RoboCup@Home community, we
build a platform that manages data collected from each site belonging to the
community around the world, taking advantage of the characteristics of the
community.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03914" title="Abstract">arXiv:2310.03914</a> [<a href="/pdf/2310.03914" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing High School Students to Version Control, Continuous  Integration, and Quality Assurance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latessa%2C+J">Joseph Latessa</a>, 
<a href="/search/cs?searchtype=author&query=Huria%2C+A">Aadi Huria</a>, 
<a href="/search/cs?searchtype=author&query=Raju%2C+D">Deepak Raju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software Engineering concepts such as version control, continuous
integration, and unit testing are often not presented in college computer
science curriculums until the third year of study, after completing several
semesters of programming courses. Throughout the summer of 2023, two high
school students volunteered in our lab at Wayne State University where I'm a
graduate research assistant and Ph.D. student in computer science. The students
had taken AP Computer Science but had no prior experience with software
engineering or software testing. This paper documents our experience devising a
group project to teach the requisite software engineering skills to implement
automated tests that meaningfully contribute to open-source scientific
computing projects developed in connection with our lab. We describe the
concepts covered, tools used, and software tests written in this early
introduction to software engineering while maintaining shared emphases on
education and the deployment of our work.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03915" title="Abstract">arXiv:2310.03915</a> [<a href="/pdf/2310.03915" title="Download PDF">pdf</a>, <a href="/format/2310.03915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust  Closed-Loop Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tumma%2C+N">Neehal Tumma</a>, 
<a href="/search/cs?searchtype=author&query=Lechner%2C+M">Mathias Lechner</a>, 
<a href="/search/cs?searchtype=author&query=Loo%2C+N">Noel Loo</a>, 
<a href="/search/cs?searchtype=author&query=Hasani%2C+R">Ramin Hasani</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Developing autonomous agents that can interact with changing environments is
an open challenge in machine learning. Robustness is particularly important in
these settings as agents are often fit offline on expert demonstrations but
deployed online where they must generalize to the closed feedback loop within
the environment. In this work, we explore the application of recurrent neural
networks to tasks of this nature and understand how a parameterization of their
recurrent connectivity influences robustness in closed-loop settings.
Specifically, we represent the recurrent connectivity as a function of rank and
sparsity and show both theoretically and empirically that modulating these two
variables has desirable effects on network dynamics. The proposed low-rank,
sparse connectivity induces an interpretable prior on the network that proves
to be most amenable for a class of models known as closed-form continuous-time
neural networks (CfCs). We find that CfCs with fewer parameters can outperform
their full-rank, fully-connected counterparts in the online setting under
distribution shift. This yields memory-efficient and robust agents while
opening a new perspective on how we can modulate network dynamics through
connectivity.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03916" title="Abstract">arXiv:2310.03916</a> [<a href="/pdf/2310.03916" title="Download PDF">pdf</a>, <a href="/format/2310.03916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a Foundation Model for Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Der%2C+A">Audrey Der</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A foundation model is a machine learning model trained on a large and diverse
set of data, typically using self-supervised learning-based pre-training
techniques, that can be adapted to various downstream tasks. However, current
research on time series pre-training has mostly focused on models pre-trained
solely on data from a single domain, resulting in a lack of knowledge about
other types of time series. However, current research on time series
pre-training has predominantly focused on models trained exclusively on data
from a single domain. As a result, these models possess domain-specific
knowledge that may not be easily transferable to time series from other
domains. In this paper, we aim to develop an effective time series foundation
model by leveraging unlabeled samples from multiple domains. To achieve this,
we repurposed the publicly available UCR Archive and evaluated four existing
self-supervised learning-based pre-training methods, along with a novel method,
on the datasets. We tested these methods using four popular neural network
architectures for time series to understand how the pre-training methods
interact with different network designs. Our experimental results show that
pre-training improves downstream classification tasks by enhancing the
convergence of the fine-tuning process. Furthermore, we found that the proposed
pre-training method, when combined with the Transformer model, outperforms the
alternatives.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03918" title="Abstract">arXiv:2310.03918</a> [<a href="/pdf/2310.03918" title="Download PDF">pdf</a>, <a href="/format/2310.03918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised SFQ-Based Spiking Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karamuftuoglu%2C+M+A">Mustafa Altay Karamuftuoglu</a>, 
<a href="/search/cs?searchtype=author&query=Ucpinar%2C+B+Z">Beyza Zeynep Ucpinar</a>, 
<a href="/search/cs?searchtype=author&query=Razmkhah%2C+S">Sasan Razmkhah</a>, 
<a href="/search/cs?searchtype=author&query=Kamal%2C+M">Mehdi Kamal</a>, 
<a href="/search/cs?searchtype=author&query=Pedram%2C+M">Massoud Pedram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Single Flux Quantum (SFQ) technology represents a groundbreaking advancement
in computational efficiency and ultra-high-speed neuromorphic processing. The
key features of SFQ technology, particularly data representation, transmission,
and processing through SFQ pulses, closely mirror fundamental aspects of
biological neural structures. Consequently, SFQ-based circuits emerge as an
ideal candidate for realizing Spiking Neural Networks (SNNs). This study
presents a proof-of-concept demonstration of an SFQ-based SNN architecture,
showcasing its capacity for ultra-fast switching at remarkably low energy
consumption per output activity. Notably, our work introduces innovative
approaches: (i) We introduce a novel spike-timing-dependent plasticity
mechanism to update synapses and to trace spike-activity by incorporating a
leaky non-destructive readout circuit. (ii) We propose a novel method to
dynamically regulate the threshold behavior of leaky integrate and fire
superconductor neurons, enhancing the adaptability of our SNN architecture.
(iii) Our research incorporates a novel winner-take-all mechanism, aligning
with practical strategies for SNN development and enabling effective
decision-making processes. The effectiveness of these proposed structural
enhancements is evaluated by integrating high-level models into the BindsNET
framework. By leveraging BindsNET, we model the online training of an SNN,
integrating the novel structures into the learning process. To ensure the
robustness and functionality of our circuits, we employ JoSIM for circuit
parameter extraction and functional verification through simulation.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03919" title="Abstract">arXiv:2310.03919</a> [<a href="/pdf/2310.03919" title="Download PDF">pdf</a>, <a href="/format/2310.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Content-based Time Series Retrieval System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Der%2C+A">Audrey Der</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M. Phillips</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A Content-based Time Series Retrieval (CTSR) system is an information
retrieval system for users to interact with time series emerged from multiple
domains, such as finance, healthcare, and manufacturing. For example, users
seeking to learn more about the source of a time series can submit the time
series as a query to the CTSR system and retrieve a list of relevant time
series with associated metadata. By analyzing the retrieved metadata, users can
gather more information about the source of the time series. Because the CTSR
system is required to work with time series data from diverse domains, it needs
a high-capacity model to effectively measure the similarity between different
time series. On top of that, the model within the CTSR system has to compute
the similarity scores in an efficient manner as the users interact with the
system in real-time. In this paper, we propose an effective and efficient CTSR
model that outperforms alternative models, while still providing reasonable
inference runtimes. To demonstrate the capability of the proposed method in
solving business problems, we compare it against alternative models using our
in-house transaction data. Our findings reveal that the proposed model is the
most suitable solution compared to others for our transaction data problem.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03923" title="Abstract">arXiv:2310.03923</a> [<a href="/pdf/2310.03923" title="Download PDF">pdf</a>, <a href="/format/2310.03923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Fusion: Real-time Open-Vocabulary 3D Mapping and Queryable Scene  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamazaki%2C+K">Kashu Yamazaki</a>, 
<a href="/search/cs?searchtype=author&query=Hanyu%2C+T">Taisei Hanyu</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+K">Khoa Vo</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Precise 3D environmental mapping is pivotal in robotics. Existing methods
often rely on predefined concepts during training or are time-intensive when
generating semantic maps. This paper presents Open-Fusion, a groundbreaking
approach for real-time open-vocabulary 3D mapping and queryable scene
representation using RGB-D data. Open-Fusion harnesses the power of a
pre-trained vision-language foundation model (VLFM) for open-set semantic
comprehension and employs the Truncated Signed Distance Function (TSDF) for
swift 3D scene reconstruction. By leveraging the VLFM, we extract region-based
embeddings and their associated confidence maps. These are then integrated with
3D knowledge from TSDF using an enhanced Hungarian-based feature-matching
mechanism. Notably, Open-Fusion delivers outstanding annotation-free 3D
segmentation for open-vocabulary without necessitating additional 3D training.
Benchmark tests on the ScanNet dataset against leading zero-shot methods
highlight Open-Fusion's superiority. Furthermore, it seamlessly combines the
strengths of region-based VLFM and TSDF, facilitating real-time 3D scene
comprehension that includes object concepts and open-world semantics. We
encourage the readers to view the demos on our project page:
https://uark-aicv.github.io/OpenFusion
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03925" title="Abstract">arXiv:2310.03925</a> [<a href="/pdf/2310.03925" title="Download PDF">pdf</a>, <a href="/format/2310.03925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Learning for Time Series Data\\with 2D Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Der%2C+A">Audrey Der</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multitask learning (MTL) aims to develop a unified model that can handle a
set of closely related tasks simultaneously. By optimizing the model across
multiple tasks, MTL generally surpasses its non-MTL counterparts in terms of
generalizability. Although MTL has been extensively researched in various
domains such as computer vision, natural language processing, and
recommendation systems, its application to time series data has received
limited attention. In this paper, we investigate the application of MTL to the
time series classification (TSC) problem. However, when we integrate the
state-of-the-art 1D convolution-based TSC model with MTL, the performance of
the TSC model actually deteriorates. By comparing the 1D convolution-based
models with the Dynamic Time Warping (DTW) distance function, it appears that
the underwhelming results stem from the limited expressive power of the 1D
convolutional layers. To overcome this challenge, we propose a novel design for
a 2D convolution-based model that enhances the model's expressiveness.
Leveraging this advantage, our proposed method outperforms competing approaches
on both the UCR Archive and an industrial transaction TSC dataset.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03927" title="Abstract">arXiv:2310.03927</a> [<a href="/pdf/2310.03927" title="Download PDF">pdf</a>, <a href="/format/2310.03927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving classifier decision boundaries using nearest neighbors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Johannes Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural networks are not learning optimal decision boundaries. We show that
decision boundaries are situated in areas of low training data density. They
are impacted by few training samples which can easily lead to overfitting. We
provide a simple algorithm performing a weighted average of the prediction of a
sample and its nearest neighbors' (computed in latent space) leading to a minor
favorable outcomes for a variety of important measures for neural networks. In
our evaluation, we employ various self-trained and pre-trained convolutional
neural networks to show that our approach improves (i) resistance to label
noise, (ii) robustness against adversarial attacks, (iii) classification
accuracy, and to some degree even (iv) interpretability. While improvements are
not necessarily large in all four areas, our approach is conceptually simple,
i.e., improvements come without any modification to network architecture,
training procedure or dataset. Furthermore, they are in stark contrast to prior
works that often require trade-offs among the four objectives or provide
valuable, but non-actionable insights.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03928" title="Abstract">arXiv:2310.03928</a> [<a href="/pdf/2310.03928" title="Download PDF">pdf</a>, <a href="/format/2310.03928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the evolution of research topics during the COVID-19 pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Invernici%2C+F">Francesco Invernici</a>, 
<a href="/search/cs?searchtype=author&query=Bernasconi%2C+A">Anna Bernasconi</a>, 
<a href="/search/cs?searchtype=author&query=Ceri%2C+S">Stefano Ceri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The COVID-19 pandemic has changed the research agendas of most scientific
communities, resulting in an overwhelming production of research articles in a
variety of domains, including medicine, virology, epidemiology, economy,
psychology, and so on. Several open-access corpora and literature hubs were
established; among them, the COVID-19 Open Research Dataset (CORD-19) has
systematically gathered scientific contributions for 2.5 years, by collecting
and indexing over one million articles. Here, we present the CORD-19 Topic
Visualizer (CORToViz), a method and associated visualization tool for
inspecting the CORD-19 textual corpus of scientific abstracts. Our method is
based upon a careful selection of up-to-date technologies (including large
language models), resulting in an architecture for clustering articles along
orthogonal dimensions and extraction techniques for temporal topic mining.
Topic inspection is supported by an interactive dashboard, providing fast,
one-click visualization of topic contents as word clouds and topic trends as
time series, equipped with easy-to-drive statistical testing for analyzing the
significance of topic emergence along arbitrarily selected time windows. The
processes of data preparation and results visualization are completely general
and virtually applicable to any corpus of textual documents - thus suited for
effective adaptation to other contexts.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03930" title="Abstract">arXiv:2310.03930</a> [<a href="/pdf/2310.03930" title="Download PDF">pdf</a>, <a href="/format/2310.03930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GroundLink: A Dataset Unifying Human Body Movement and Ground Reaction  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xingjian Han</a>, 
<a href="/search/cs?searchtype=author&query=Senderling%2C+B">Benjamin Senderling</a>, 
<a href="/search/cs?searchtype=author&query=To%2C+S">Stanley To</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Deepak Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Whiting%2C+E">Emily Whiting</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+J">Jun Saito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">The physical plausibility of human motions is vital to various applications
in fields including but not limited to graphics, animation, robotics, vision,
biomechanics, and sports science. While fully simulating human motions with
physics is an extreme challenge, we hypothesize that we can treat this
complexity as a black box in a data-driven manner if we focus on the ground
contact, and have sufficient observations of physics and human activities in
the real world. To prove our hypothesis, we present GroundLink, a unified
dataset comprised of captured ground reaction force (GRF) and center of
pressure (CoP) synchronized to standard kinematic motion captures. GRF and CoP
of GroundLink are not simulated but captured at high temporal resolution using
force platforms embedded in the ground for uncompromising measurement accuracy.
This dataset contains 368 processed motion trials (~1.59M recorded frames) with
19 different movements including locomotion and weight-shifting actions such as
tennis swings to signify the importance of capturing physics paired with
kinematics. GroundLinkNet, our benchmark neural network model trained with
GroundLink, supports our hypothesis by predicting GRFs and CoPs accurately and
plausibly on unseen motions from various sources. The dataset, code, and
benchmark models are made public for further research on various downstream
tasks leveraging the rich physics information at
https://csr.bu.edu/groundlink/.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03932" title="Abstract">arXiv:2310.03932</a> [<a href="/pdf/2310.03932" title="Download PDF">pdf</a>, <a href="/format/2310.03932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Low-level Geometry to High-level Concepts in Visual Servoing of  Robot Manipulation Task Using Event Knowledge Graphs and Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jagersand%2C+M">Martin Jagersand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a framework of building knowledgeable robot control
in the scope of smart human-robot interaction, by empowering a basic
uncalibrated visual servoing controller with contextual knowledge through the
joint usage of event knowledge graphs (EKGs) and large-scale pretrained
vision-language models (VLMs). The framework is expanded in twofold: first, we
interpret low-level image geometry as high-level concepts, allowing us to
prompt VLMs and to select geometric features of points and lines for motor
control skills; then, we create an event knowledge graph (EKG) to conceptualize
a robot manipulation task of interest, where the main body of the EKG is
characterized by an executable behavior tree, and the leaves by semantic
concepts relevant to the manipulation context. We demonstrate, in an
uncalibrated environment with real robot trials, that our method lowers the
reliance of human annotation during task interfacing, allows the robot to
perform activities of daily living more easily by treating low-level
geometric-based motor control skills as high-level concepts, and is beneficial
in building cognitive thinking for smart robot applications.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03937" title="Abstract">arXiv:2310.03937</a> [<a href="/pdf/2310.03937" title="Download PDF">pdf</a>, <a href="/format/2310.03937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models as Masked Audio-Video Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nunez%2C+E">Elvis Nunez</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yanzi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Rastegari%2C+M">Mohammad Rastegari</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S">Sachin Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Horton%2C+M">Maxwell Horton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Over the past several years, the synchronization between audio and visual
signals has been leveraged to learn richer audio-visual representations. Aided
by the large availability of unlabeled videos, many unsupervised training
frameworks have demonstrated impressive results in various downstream audio and
video tasks. Recently, Masked Audio-Video Learners (MAViL) has emerged as a
state-of-the-art audio-video pre-training framework. MAViL couples contrastive
learning with masked autoencoding to jointly reconstruct audio spectrograms and
video frames by fusing information from both modalities. In this paper, we
study the potential synergy between diffusion models and MAViL, seeking to
derive mutual benefits from these two frameworks. The incorporation of
diffusion into MAViL, combined with various training efficiency methodologies
that include the utilization of a masking ratio curriculum and adaptive batch
sizing, results in a notable 32% reduction in pre-training Floating-Point
Operations (FLOPS) and an 18% decrease in pre-training wall clock time.
Crucially, this enhanced efficiency does not compromise the model's performance
in downstream audio-classification tasks when compared to MAViL's performance.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03938" title="Abstract">arXiv:2310.03938</a> [<a href="/pdf/2310.03938" title="Download PDF">pdf</a>, <a href="/format/2310.03938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EFFUSE: Efficient Self-Supervised Feature Fusion for E2E ASR in  Multilingual and Low Resource Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+T">Tejes Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Self-Supervised Learning (SSL) models have demonstrated exceptional
performance in various speech tasks, particularly in low-resource and
multilingual domains. Recent works show that fusing SSL models could achieve
superior performance compared to using one SSL model. However, fusion models
have increased model parameter size, leading to longer inference times. In this
paper, we propose a novel approach of predicting other SSL models' features
from a single SSL model, resulting in a light-weight framework with competitive
performance. Our experiments show that SSL feature prediction models outperform
individual SSL models in multilingual speech recognition tasks. The leading
prediction model achieves an average SUPERB score increase of 135.4 in
ML-SUPERB benchmarks. Moreover, our proposed framework offers an efficient
solution, as it reduces the resulting model parameter size and inference times
compared to previous fusion models.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03940" title="Abstract">arXiv:2310.03940</a> [<a href="/pdf/2310.03940" title="Download PDF">pdf</a>, <a href="/format/2310.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard View Selection for Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+F">Fabio Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Rapant%2C+I">Ivo Rapant</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many Contrastive Learning (CL) methods train their models to be invariant to
different "views" of an image input for which a good data augmentation pipeline
is crucial. While considerable efforts were directed towards improving pre-text
tasks, architectures, or robustness (e.g., Siamese networks or teacher-softmax
centering), the majority of these methods remain strongly reliant on the random
sampling of operations within the image augmentation pipeline, such as the
random resized crop or color distortion operation. In this paper, we argue that
the role of the view generation and its effect on performance has so far
received insufficient attention. To address this, we propose an easy,
learning-free, yet powerful Hard View Selection (HVS) strategy designed to
extend the random view generation to expose the pretrained model to harder
samples during CL training. It encompasses the following iterative steps: 1)
randomly sample multiple views and create pairs of two views, 2) run forward
passes for each view pair on the currently trained model, 3) adversarially
select the pair yielding the worst loss, and 4) run the backward pass with the
selected pair. In our empirical analysis we show that under the hood, HVS
increases task difficulty by controlling the Intersection over Union of views
during pretraining. With only 300-epoch pretraining, HVS is able to closely
rival the 800-epoch DINO baseline which remains very favorable even when
factoring in the slowdown induced by the additional forwards of HVS.
Additionally, HVS consistently achieves accuracy improvements on ImageNet
between 0.55% and 1.9% on linear evaluation and similar improvements on
transfer tasks across multiple CL methods, such as DINO, SimSiam, and SimCLR.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03941" title="Abstract">arXiv:2310.03941</a> [<a href="/pdf/2310.03941" title="Download PDF">pdf</a>, <a href="/format/2310.03941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaTeX: Language Pattern-aware Triggering Event Detection for Adverse  Experience during Pandemics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kaiqun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yangxiao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kolady%2C+D">Deepthi Kolady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1911.08684">arXiv:1911.08684</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The COVID-19 pandemic has accentuated socioeconomic disparities across
various racial and ethnic groups in the United States. While previous studies
have utilized traditional survey methods like the Household Pulse Survey (HPS)
to elucidate these disparities, this paper explores the role of social media
platforms in both highlighting and addressing these challenges. Drawing from
real-time data sourced from Twitter, we analyzed language patterns related to
four major types of adverse experiences: loss of employment income (LI), food
scarcity (FS), housing insecurity (HI), and unmet needs for mental health
services (UM). We first formulate a sparsity optimization problem that extracts
low-level language features from social media data sources. Second, we propose
novel constraints on feature similarity exploiting prior knowledge about the
similarity of the language patterns among the adverse experiences. The proposed
problem is challenging to solve due to the non-convexity objective and
non-smoothness penalties. We develop an algorithm based on the alternating
direction method of multipliers (ADMM) framework to solve the proposed
formulation. Extensive experiments and comparisons to other models on
real-world social media and the detection of adverse experiences justify the
efficacy of our model.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03946" title="Abstract">arXiv:2310.03946</a> [<a href="/pdf/2310.03946" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved prediction of ligand-protein binding affinities by  meta-modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Ho-Joon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Emani%2C+P+S">Prashant S. Emani</a>, 
<a href="/search/cs?searchtype=author&query=Gerstein%2C+M+B">Mark B. Gerstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 3 main tables, 6 main figures, 6 supplementary figures, and supporting information. For 8 supplementary tables and code, see <a href="https://github.com/Lee1701/Lee2023a">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The accurate screening of candidate drug ligands against target proteins
through computational approaches is of prime interest to drug development
efforts, as filtering potential candidates would save time and expenses for
finding drugs. Such virtual screening depends in part on methods to predict the
binding affinity between ligands and proteins. Given many computational models
for binding affinity prediction with varying results across targets, we herein
develop a meta-modeling framework by integrating published empirical
structure-based docking and sequence-based deep learning models. In building
this framework, we evaluate many combinations of individual models, training
databases, and linear and nonlinear meta-modeling approaches. We show that many
of our meta-models significantly improve affinity predictions over individual
base models. Our best meta-models achieve comparable performance to
state-of-the-art exclusively structure-based deep learning tools. Overall, we
demonstrate that diverse modeling approaches can be ensembled together to gain
substantial improvement in binding affinity prediction while allowing control
over input features such as physicochemical properties or molecular
descriptors.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03951" title="Abstract">arXiv:2310.03951</a> [<a href="/pdf/2310.03951" title="Download PDF">pdf</a>, <a href="/format/2310.03951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Natural Language Inference for Reducing Large Language Model  Ungrounded Hallucinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+D">Deren Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Mengya">Mengya</a> (Mia)Hu, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+V">Vincent Yun</a>, 
<a href="/search/cs?searchtype=author&query=Ching%2C+E">Emily Ching</a>, 
<a href="/search/cs?searchtype=author&query=Kamal%2C+E">Eslam Kamal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source code is available at <a href="https://github.com/microsoft/CoNLI_hallucination">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) can generate fluent natural language texts when
given relevant documents as background context. This ability has attracted
considerable interest in developing industry applications of LLMs. However,
LLMs are prone to generate hallucinations that are not supported by the
provided sources. In this paper, we propose a hierarchical framework to detect
and mitigate such ungrounded hallucination. Our framework uses Chain of Natural
Language Inference (CoNLI) for hallucination detection and hallucination
reduction via post-editing. Our approach achieves state-of-the-art performance
on hallucination detection and enhances text quality through rewrite, using
LLMs without any fine-tuning or domain-specific prompt engineering. We show
that this simple plug-and-play framework can serve as an effective choice for
hallucination detection and reduction, achieving competitive performance across
various contexts.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03952" title="Abstract">arXiv:2310.03952</a> [<a href="/pdf/2310.03952" title="Download PDF">pdf</a>, <a href="/format/2310.03952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ILSH: The Imperial Light-Stage Head Dataset for Human Head View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiali Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Youngkyoon Jang</a>, 
<a href="/search/cs?searchtype=author&query=Papaioannou%2C+A">Athanasios Papaioannou</a>, 
<a href="/search/cs?searchtype=author&query=Kampouris%2C+C">Christos Kampouris</a>, 
<a href="/search/cs?searchtype=author&query=Potamias%2C+R+A">Rolandos Alexandros Potamias</a>, 
<a href="/search/cs?searchtype=author&query=Papantoniou%2C+F+P">Foivos Paraperas Papantoniou</a>, 
<a href="/search/cs?searchtype=author&query=Galanakis%2C+E">Efstathios Galanakis</a>, 
<a href="/search/cs?searchtype=author&query=Leonardis%2C+A">Ales Leonardis</a>, 
<a href="/search/cs?searchtype=author&query=Zafeiriou%2C+S">Stefanos Zafeiriou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Workshop, 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces the Imperial Light-Stage Head (ILSH) dataset, a novel
light-stage-captured human head dataset designed to support view synthesis
academic challenges for human heads. The ILSH dataset is intended to facilitate
diverse approaches, such as scene-specific or generic neural rendering,
multiple-view geometry, 3D vision, and computer graphics, to further advance
the development of photo-realistic human avatars. This paper details the setup
of a light-stage specifically designed to capture high-resolution (4K) human
head images and describes the process of addressing challenges (preprocessing,
ethical issues) in collecting high-quality data. In addition to the data
collection, we address the split of the dataset into train, validation, and
test sets. Our goal is to design and support a fair view synthesis challenge
task for this novel dataset, such that a similar level of performance can be
maintained and expected when using the test set, as when using the validation
set. The ILSH dataset consists of 52 subjects captured using 24 cameras with
all 82 lighting sources turned on, resulting in a total of 1,248 close-up head
images, border masks, and camera pose pairs.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03953" title="Abstract">arXiv:2310.03953</a> [<a href="/pdf/2310.03953" title="Download PDF">pdf</a>, <a href="/format/2310.03953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CineTransfer: Controlling a Robot to Imitate Cinematographic Style from  a Single Example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pueyo%2C+P">Pablo Pueyo</a>, 
<a href="/search/cs?searchtype=author&query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="/search/cs?searchtype=author&query=Murillo%2C+A+C">Ana C. Murillo</a>, 
<a href="/search/cs?searchtype=author&query=Schwager%2C+M">Mac Schwager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work presents CineTransfer, an algorithmic framework that drives a robot
to record a video sequence that mimics the cinematographic style of an input
video. We propose features that abstract the aesthetic style of the input
video, so the robot can transfer this style to a scene with visual details that
are significantly different from the input video. The framework builds upon
CineMPC, a tool that allows users to control cinematographic features, like
subjects' position on the image and the depth of field, by manipulating the
intrinsics and extrinsics of a cinematographic camera. However, CineMPC
requires a human expert to specify the desired style of the shot (composition,
camera motion, zoom, focus, etc). CineTransfer bridges this gap, aiming a fully
autonomous cinematographic platform. The user chooses a single input video as a
style guide. CineTransfer extracts and optimizes two important style features,
the composition of the subject in the image and the scene depth of field, and
provides instructions for CineMPC to control the robot to record an output
sequence that matches these features as closely as possible. In contrast with
other style transfer methods, our approach is a lightweight and portable
framework which does not require deep network training or extensive datasets.
Experiments with real and simulated videos demonstrate the system's ability to
analyze and transfer style between recordings, and are available in the
supplementary video.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03956" title="Abstract">arXiv:2310.03956</a> [<a href="/pdf/2310.03956" title="Download PDF">pdf</a>, <a href="/format/2310.03956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Descent Provably Solves Nonlinear Tomographic Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+S">Sara Fridovich-Keil</a>, 
<a href="/search/cs?searchtype=author&query=Valdivia%2C+F">Fabrizio Valdivia</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>, 
<a href="/search/cs?searchtype=author&query=Recht%2C+B">Benjamin Recht</a>, 
<a href="/search/cs?searchtype=author&query=Soltanolkotabi%2C+M">Mahdi Soltanolkotabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Optimization and Control (math.OC); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">In computed tomography (CT), the forward model consists of a linear Radon
transform followed by an exponential nonlinearity based on the attenuation of
light according to the Beer-Lambert Law. Conventional reconstruction often
involves inverting this nonlinearity as a preprocessing step and then solving a
convex inverse problem. However, this nonlinear measurement preprocessing
required to use the Radon transform is poorly conditioned in the vicinity of
high-density materials, such as metal. This preprocessing makes CT
reconstruction methods numerically sensitive and susceptible to artifacts near
high-density regions. In this paper, we study a technique where the signal is
directly reconstructed from raw measurements through the nonlinear forward
model. Though this optimization is nonconvex, we show that gradient descent
provably converges to the global optimum at a geometric rate, perfectly
reconstructing the underlying signal with a near minimal number of random
measurements. We also prove similar results in the under-determined setting
where the number of measurements is significantly smaller than the dimension of
the signal. This is achieved by enforcing prior structural information about
the signal through constraints on the optimization variables. We illustrate the
benefits of direct nonlinear CT reconstruction with cone-beam CT experiments on
synthetic and real 3D volumes. We show that this approach reduces metal
artifacts compared to a commercial reconstruction of a human skull with metal
dental crowns.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03957" title="Abstract">arXiv:2310.03957</a> [<a href="/pdf/2310.03957" title="Download PDF">pdf</a>, <a href="/format/2310.03957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding prompt engineering may not require rethinking  generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akinwande%2C+V">Victor Akinwande</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yiding Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sam%2C+D">Dylan Sam</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Zero-shot learning in prompted vision-language models, the practice of
crafting prompts to build classifiers without an explicit training process, has
achieved impressive performance in many settings. This success presents a
seemingly surprising observation: these methods suffer relatively little from
overfitting, i.e., when a prompt is manually engineered to achieve low error on
a given training set (thus rendering the method no longer actually zero-shot),
the approach still performs well on held-out test data. In this paper, we show
that we can explain such performance well via recourse to classical PAC-Bayes
bounds. Specifically, we show that the discrete nature of prompts, combined
with a PAC-Bayes prior given by a language model, results in generalization
bounds that are remarkably tight by the standards of the literature: for
instance, the generalization bound of an ImageNet classifier is often within a
few percentage points of the true test error. We demonstrate empirically that
this holds for existing handcrafted prompts and prompts generated through
simple greedy search. Furthermore, the resulting bound is well-suited for model
selection: the models with the best bound typically also have the best test
performance. This work thus provides a possible justification for the
widespread practice of prompt engineering, even if it seems that such methods
could potentially overfit the training data.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03958" title="Abstract">arXiv:2310.03958</a> [<a href="/pdf/2310.03958" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The &quot;Seen but Unnoticed&quot; Vocabulary of Natural Touch: Revolutionizing  Direct Interaction with Our Devices and One Another (UIST 2021 Vision)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hinckley%2C+K">Ken Hinckley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages. Non-archival UIST Vision paper accepted and presented at the 34th Annual ACM Symposium on User Interface Software and Technology (UIST 2021) by Ken Hinckley. This is the definitive "published" version as the Association of Computing Machinery (ACM) does not archive UIST Vision papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This UIST Vision argues that "touch" input and interaction remains in its
infancy when viewed in context of the seen but unnoticed vocabulary of natural
human behaviors, activity, and environments that surround direct interaction
with displays. Unlike status-quo touch interaction -- a shadowplay of fingers
on a single screen -- I argue that our perspective of direct interaction should
encompass the full rich context of individual use (whether via touch, sensors,
or in combination with other modalities), as well as collaborative activity
where people are engaged in local (co-located), remote (tele-present), and
hybrid work. We can further view touch through the lens of the "Society of
Devices," where each person's activities span many complementary, oft-distinct
devices that offer the right task affordance (input modality, screen size,
aspect ratio, or simply a distinct surface with dedicated purpose) at the right
place and time. While many hints of this vision already exist (see references),
I speculate that a comprehensive program of research to systematically
inventory, sense, and design interactions around such human behaviors and
activities -- and that fully embrace touch as a multi-modal, multi-sensor,
multi-user, and multi-device construct -- could revolutionize both individual
and collaborative interaction with technology.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03959" title="Abstract">arXiv:2310.03959</a> [<a href="/pdf/2310.03959" title="Download PDF">pdf</a>, <a href="/format/2310.03959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Increasing the Robustness of Predictive Steering-Control  Autonomous Navigation Systems Against Dash Cam Image Angle Perturbations Due  to Pothole Encounters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aarya%2C+S">Shivam Aarya</a> (Johns Hopkins University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vehicle manufacturers are racing to create autonomous navigation and steering
control algorithms for their vehicles. These software are made to handle
various real-life scenarios such as obstacle avoidance and lane maneuvering.
There is some ongoing research to incorporate pothole avoidance into these
autonomous systems. However, there is very little research on the effect of
hitting a pothole on the autonomous navigation software that uses cameras to
make driving decisions. Perturbations in the camera angle when hitting a
pothole can cause errors in the predicted steering angle. In this paper, we
present a new model to compensate for such angle perturbations and reduce any
errors in steering control prediction algorithms. We evaluate our model on
perturbations of publicly available datasets and show our model can reduce the
errors in the estimated steering angle from perturbed images to 2.3%, making
autonomous steering control robust against the dash cam image angle
perturbations induced when one wheel of a car goes over a pothole.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03963" title="Abstract">arXiv:2310.03963</a> [<a href="/pdf/2310.03963" title="Download PDF">pdf</a>, <a href="/format/2310.03963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Emotion Transfer For Cross-Lingual Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuke Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+D">Danming Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Zero-shot emotion transfer in cross-lingual speech synthesis aims to transfer
emotion from an arbitrary speech reference in the source language to the
synthetic speech in the target language. Building such a system faces
challenges of unnatural foreign accents and difficulty in modeling the shared
emotional expressions of different languages. Building on the DelightfulTTS
neural architecture, this paper addresses these challenges by introducing
specifically-designed modules to model the language-specific prosody features
and language-shared emotional expressions separately. Specifically, the
language-specific speech prosody is learned by a non-autoregressive predictive
coding (NPC) module to improve the naturalness of the synthetic cross-lingual
speech. The shared emotional expression between different languages is
extracted from a pre-trained self-supervised model HuBERT with strong
generalization capabilities. We further use hierarchical emotion modeling to
capture more comprehensive emotions across different languages. Experimental
results demonstrate the proposed framework's effectiveness in synthesizing
bi-lingual emotional speech for the monolingual target speaker without
emotional training data.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03964" title="Abstract">arXiv:2310.03964</a> [<a href="/pdf/2310.03964" title="Download PDF">pdf</a>, <a href="/format/2310.03964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Learnable Counter-condition Analysis Framework for Functional  Connectivity-based Neurological Disorder Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+E">Eunsong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+D">Da-woon Heo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jiwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Suk%2C+H">Heung-Il Suk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">To understand the biological characteristics of neurological disorders with
functional connectivity (FC), recent studies have widely utilized deep
learning-based models to identify the disease and conducted post-hoc analyses
via explainable models to discover disease-related biomarkers. Most existing
frameworks consist of three stages, namely, feature selection, feature
extraction for classification, and analysis, where each stage is implemented
separately. However, if the results at each stage lack reliability, it can
cause misdiagnosis and incorrect analysis in afterward stages. In this study,
we propose a novel unified framework that systemically integrates diagnoses
(i.e., feature selection and feature extraction) and explanations. Notably, we
devised an adaptive attention network as a feature selection approach to
identify individual-specific disease-related connections. We also propose a
functional network relational encoder that summarizes the global topological
properties of FC by learning the inter-network relations without pre-defined
edges between functional networks. Last but not least, our framework provides a
novel explanatory power for neuroscientific interpretation, also termed
counter-condition analysis. We simulated the FC that reverses the diagnostic
information (i.e., counter-condition FC): converting a normal brain to be
abnormal and vice versa. We validated the effectiveness of our framework by
using two large resting-state functional magnetic resonance imaging (fMRI)
datasets, Autism Brain Imaging Data Exchange (ABIDE) and REST-meta-MDD, and
demonstrated that our framework outperforms other competing methods for disease
identification. Furthermore, we analyzed the disease-related neurological
patterns based on counter-condition analysis.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03965" title="Abstract">arXiv:2310.03965</a> [<a href="/pdf/2310.03965" title="Download PDF">pdf</a>, <a href="/format/2310.03965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thought Propagation: An Analogical Approach to Complex Reasoning with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junchi Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have achieved remarkable success in reasoning
tasks with the development of prompting methods. However, existing prompting
approaches cannot reuse insights of solving similar problems and suffer from
accumulated errors in multi-step reasoning, since they prompt LLMs to reason
\textit{from scratch}. To address these issues, we propose
\textbf{\textit{Thought Propagation} (TP)}, which explores the analogous
problems and leverages their solutions to enhance the complex reasoning ability
of LLMs. These analogous problems are related to the input one, with reusable
solutions and problem-solving strategies. Thus, it is promising to propagate
insights of solving previous analogous problems to inspire new problem-solving.
To achieve this, TP first prompts LLMs to propose and solve a set of analogous
problems that are related to the input one. Then, TP reuses the results of
analogous problems to directly yield a new solution or derive a
knowledge-intensive plan for execution to amend the initial solution obtained
from scratch. TP is compatible with existing prompting approaches, allowing
plug-and-play generalization and enhancement in a wide range of tasks without
much labor in task-specific prompt engineering. Experiments across three
challenging tasks demonstrate TP enjoys a substantial improvement over the
baselines by an average of 12\% absolute increase in finding the optimal
solutions in Shortest-path Reasoning, 13\% improvement of human preference in
Creative Writing, and 15\% enhancement in the task completion rate of LLM-Agent
Planning.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03967" title="Abstract">arXiv:2310.03967</a> [<a href="/pdf/2310.03967" title="Download PDF">pdf</a>, <a href="/format/2310.03967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sub-token ViT Embedding via Stochastic Resonance Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lao%2C+D">Dong Lao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yangchao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+Y">Tian Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alex Wong</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We discover the presence of quantization artifacts in Vision Transformers
(ViTs), which arise due to the image tokenization step inherent in these
architectures. These artifacts result in coarsely quantized features, which
negatively impact performance, especially on downstream dense prediction tasks.
We present a zero-shot method to improve how pre-trained ViTs handle spatial
quantization. In particular, we propose to ensemble the features obtained from
perturbing input images via sub-token spatial translations, inspired by
Stochastic Resonance, a method traditionally applied to climate dynamics and
signal processing. We term our method ``Stochastic Resonance Transformer"
(SRT), which we show can effectively super-resolve features of pre-trained
ViTs, capturing more of the local fine-grained structures that might otherwise
be neglected as a result of tokenization. SRT can be applied at any layer, on
any task, and does not require any fine-tuning. The advantage of the former is
evident when applied to monocular depth prediction, where we show that
ensembling model outputs are detrimental while applying SRT on intermediate ViT
features outperforms the baseline models by an average of 4.7% and 14.9% on the
RMSE and RMSE-log metrics across three different architectures. When applied to
semi-supervised video object segmentation, SRT also improves over the baseline
models uniformly across all metrics, and by an average of 2.4% in F&amp;J score. We
further show that these quantization artifacts can be attenuated to some extent
via self-distillation. On the unsupervised salient region segmentation, SRT
improves upon the base model by an average of 2.1% on the maxF metric. Finally,
despite operating purely on pixel-level features, SRT generalizes to non-dense
prediction tasks such as image retrieval and object discovery, yielding
consistent improvements of up to 2.6% and 1.0% respectively.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03968" title="Abstract">arXiv:2310.03968</a> [<a href="/pdf/2310.03968" title="Download PDF">pdf</a>, <a href="/format/2310.03968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultimate limit on learning non-Markovian behavior: Fisher information  rate and excess information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riechers%2C+P+M">Paul M. Riechers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">We address the fundamental limits of learning unknown parameters of any
stochastic process from time-series data, and discover exact closed-form
expressions for how optimal inference scales with observation length. Given a
parametrized class of candidate models, the Fisher information of observed
sequence probabilities lower-bounds the variance in model estimation from
finite data. As sequence-length increases, the minimal variance scales as the
square inverse of the length -- with constant coefficient given by the
information rate. We discover a simple closed-form expression for this
information rate, even in the case of infinite Markov order. We furthermore
obtain the exact analytic lower bound on model variance from the
observation-induced metadynamic among belief states. We discover ephemeral,
exponential, and more general modes of convergence to the asymptotic
information rate. Surprisingly, this myopic information rate converges to the
asymptotic Fisher information rate with exactly the same relaxation timescales
that appear in the myopic entropy rate as it converges to the Shannon entropy
rate for the process. We illustrate these results with a sequence of examples
that highlight qualitatively distinct features of stochastic processes that
shape optimal learning.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03969" title="Abstract">arXiv:2310.03969</a> [<a href="/pdf/2310.03969" title="Download PDF">pdf</a>, <a href="/ps/2310.03969" title="Download PostScript">ps</a>, <a href="/format/2310.03969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Age of Information in Non-terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yanwu Lu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Howard Yang</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+N">Nikolaos Pappas</a>, 
<a href="/search/eess?searchtype=author&query=Geraci%2C+G">Giovanni Geraci</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+C">Chuan Ma</a>, 
<a href="/search/eess?searchtype=author&query=Quek%2C+T+Q+S">Tony Q. S. Quek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Non-terrestrial networks (NTN), particularly low Earth orbit (LEO) satellite
networks, have emerged as a promising solution to overcome the limitations of
traditional terrestrial networks in the context of next-generation (6G)
wireless systems. In this paper, we focus on analyzing the timeliness of
information delivery in NTN through the concept of Age of Information (AoI). We
propose an on-off process to approximate the service process between LEO
satellites and a source node located on the Earth's surface. By utilizing
stochastic geometry, we derive a closed-form expression for the time-average
AoI in an NTN. This expression also applies to on-off processes with one
component following an exponential distribution while the other has its
probability density function supported on a bounded interval. Numerical results
validate the accuracy of our analysis and demonstrate the impact of source
status update rate and satellite constellation density on the time-average AoI.
Our work fills a gap in the literature by providing a comprehensive analysis of
AoI in NTN and offers new insights into the performance of LEO satellite
networks.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03970" title="Abstract">arXiv:2310.03970</a> [<a href="/pdf/2310.03970" title="Download PDF">pdf</a>, <a href="/format/2310.03970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Computation of an Elliptic Eigenvalue Optimization Problem with  a Phase-Field Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Y">Yifeng Xu</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+S">Shengfeng Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 24 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we discuss adaptive approximations of an elliptic eigenvalue
optimization problem in a phase-field setting by a conforming finite element
method. An adaptive algorithm is proposed and implemented in several two
dimensional numerical examples for illustration of efficiency and accuracy.
Theoretical findings consist in the vanishing limit of a subsequence of
estimators and the convergence of the relevant subsequence of
adaptively-generated solutions to a solution to the continuous optimality
system.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03971" title="Abstract">arXiv:2310.03971</a> [<a href="/pdf/2310.03971" title="Download PDF">pdf</a>, <a href="/format/2310.03971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized Transformer Language Model Implementations on Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+W+U">Mohammad Wali Ur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Abrar%2C+M+M">Murad Mehrab Abrar</a>, 
<a href="/search/cs?searchtype=author&query=Copening%2C+H+G">Hunter Gibbons Copening</a>, 
<a href="/search/cs?searchtype=author&query=Hariri%2C+S">Salim Hariri</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Sicong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Satam%2C+P">Pratik Satam</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+S">Soheil Salehi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication on 22nd International Conference of Machine Learning and Applications, ICMLA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Large-scale transformer-based models like the Bidirectional Encoder
Representations from Transformers (BERT) are widely used for Natural Language
Processing (NLP) applications, wherein these models are initially pre-trained
with a large corpus with millions of parameters and then fine-tuned for a
downstream NLP task. One of the major limitations of these large-scale models
is that they cannot be deployed on resource-constrained devices due to their
large model size and increased inference latency. In order to overcome these
limitations, such large-scale models can be converted to an optimized
FlatBuffer format, tailored for deployment on resource-constrained edge
devices. Herein, we evaluate the performance of such FlatBuffer transformed
MobileBERT models on three different edge devices, fine-tuned for Reputation
analysis of English language tweets in the RepLab 2013 dataset. In addition,
this study encompassed an evaluation of the deployed models, wherein their
latency, performance, and resource efficiency were meticulously assessed. Our
experiment results show that, compared to the original BERT large model, the
converted and quantized MobileBERT models have 160$\times$ smaller footprints
for a 4.1% drop in accuracy while analyzing at least one tweet per second on
edge devices. Furthermore, our study highlights the privacy-preserving aspect
of TinyML systems as all data is processed locally within a serverless
environment.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03975" title="Abstract">arXiv:2310.03975</a> [<a href="/pdf/2310.03975" title="Download PDF">pdf</a>, <a href="/ps/2310.03975" title="Download PostScript">ps</a>, <a href="/format/2310.03975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HuBERTopic: Enhancing Semantic Representation of HuBERT through  Self-supervision Utilizing Topic Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maekaku%2C+T">Takashi Maekaku</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fujita%2C+Y">Yuya Fujita</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, the usefulness of self-supervised representation learning (SSRL)
methods has been confirmed in various downstream tasks. Many of these models,
as exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral
features or the model's own representation features. From previous studies, it
is known that the pseudo-labels contain semantic information. However, the
masked prediction task, the learning criterion of HuBERT, focuses on local
contextual information and may not make effective use of global semantic
information such as speaker, theme of speech, and so on. In this paper, we
propose a new approach to enrich the semantic representation of HuBERT. We
apply topic model to pseudo-labels to generate a topic label for each
utterance. An auxiliary topic classification task is added to HuBERT by using
topic labels as teachers. This allows additional global semantic information to
be incorporated in an unsupervised manner. Experimental results demonstrate
that our method achieves comparable or better performance than the baseline in
most tasks, including automatic speech recognition and five out of the eight
SUPERB tasks. Moreover, we find that topic labels include various information
about utterance, such as gender, speaker, and its theme. This highlights the
effectiveness of our approach in capturing multifaceted semantic nuances.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03976" title="Abstract">arXiv:2310.03976</a> [<a href="/pdf/2310.03976" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Self: Users&#x27; Perceptions of Potential of AI on  Interpersonal Communication and Self
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yue Fu</a>, 
<a href="/search/cs?searchtype=author&query=Foell%2C+S">Sami Foell</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hiniker%2C+A">Alexis Hiniker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the rapidly evolving landscape of AI-mediated communication (AIMC), tools
powered by Large Language Models (LLMs) are becoming integral to interpersonal
communication. Employing a mixed-methods approach, we conducted a one-week
diary and interview study to explore users' perceptions of these tools' ability
to: 1) support interpersonal communication in the short-term, and 2) lead to
potential long-term effects. Our findings indicate that participants view AIMC
support favorably, citing benefits such as increased communication confidence,
and finding precise language to express their thoughts, navigating linguistic
and cultural barriers. However, the study also uncovers current limitations of
AIMC tools, including verbosity, unnatural responses, and excessive emotional
intensity. These shortcomings are further exacerbated by user concerns about
inauthenticity and potential overreliance on the technology. Furthermore, we
identified four key communication spaces delineated by communication stakes
(high or low) and relationship dynamics (formal or informal) that
differentially predict users' attitudes toward AIMC tools. Specifically,
participants found the tool is more suitable for communicating in formal
relationships than informal ones and more beneficial in high-stakes than
low-stakes communication.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03977" title="Abstract">arXiv:2310.03977</a> [<a href="/pdf/2310.03977" title="Download PDF">pdf</a>, <a href="/format/2310.03977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfect Alignment May be Poisonous to Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huayi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Contrastive Learning (GCL) aims to learn node representations by
aligning positive pairs and separating negative ones. However, limited research
has been conducted on the inner law behind specific augmentations used in
graph-based learning. What kind of augmentation will help downstream
performance, how does contrastive learning actually influence downstream tasks,
and why the magnitude of augmentation matters? This paper seeks to address
these questions by establishing a connection between augmentation and
downstream performance, as well as by investigating the generalization of
contrastive learning. Our findings reveal that GCL contributes to downstream
tasks mainly by separating different classes rather than gathering nodes of the
same class. So perfect alignment and augmentation overlap which draw all
intra-class samples the same can not explain the success of contrastive
learning. Then in order to comprehend how augmentation aids the contrastive
learning process, we conduct further investigations into its generalization,
finding that perfect alignment that draw positive pair the same could help
contrastive loss but is poisonous to generalization, on the contrary, imperfect
alignment enhances the model's generalization ability. We analyse the result by
information theory and graph spectrum theory respectively, and propose two
simple but effective methods to verify the theories. The two methods could be
easily applied to various GCL algorithms and extensive experiments are
conducted to prove its effectiveness.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03981" title="Abstract">arXiv:2310.03981</a> [<a href="/pdf/2310.03981" title="Download PDF">pdf</a>, <a href="/format/2310.03981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUPre: Cross-domain Unsupervised Pre-training for Few-Shot Cell  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Weibin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingzhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhaozheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While pre-training on object detection tasks, such as Common Objects in
Contexts (COCO) [1], could significantly boost the performance of cell
segmentation, it still consumes on massive fine-annotated cell images [2] with
bounding boxes, masks, and cell types for every cell in every image, to
fine-tune the pre-trained model. To lower the cost of annotation, this work
considers the problem of pre-training DNN models for few-shot cell
segmentation, where massive unlabeled cell images are available but only a
small proportion is annotated. Hereby, we propose Cross-domain Unsupervised
Pre-training, namely CUPre, transferring the capability of object detection and
instance segmentation for common visual objects (learned from COCO) to the
visual domain of cells using unlabeled images. Given a standard COCO
pre-trained network with backbone, neck, and head modules, CUPre adopts an
alternate multi-task pre-training (AMT2) procedure with two sub-tasks -- in
every iteration of pre-training, AMT2 first trains the backbone with cell
images from multiple cell datasets via unsupervised momentum contrastive
learning (MoCo) [3], and then trains the whole model with vanilla COCO datasets
via instance segmentation. After pre-training, CUPre fine-tunes the whole model
on the cell segmentation task using a few annotated images. We carry out
extensive experiments to evaluate CUPre using LIVECell [2] and BBBC038 [4]
datasets in few-shot instance segmentation settings. The experiment shows that
CUPre can outperform existing pre-training methods, achieving the highest
average precision (AP) for few-shot cell segmentation and detection.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03983" title="Abstract">arXiv:2310.03983</a> [<a href="/pdf/2310.03983" title="Download PDF">pdf</a>, <a href="/format/2310.03983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Floyd-Warshall Algorithm Re-implemented Using 3D-Tensors and  Hardware Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anjary%2C+T">Taher Anjary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The Floyd-Warshall(FW) algorithm, is an ancient but a largely important
algorithm used to solve the all-pairs simple-paths(APSP) problem. While the
algorithm is available for use in open-source graph optimization libraries such
as NetworkX, they do not take advantage of modern parallel processing hardware
such as Graphics Processing Units(GPUs), which would reduce compute time to a
fraction of its iterative or recursive implementations. In this work, a
re-implementation of the Floyd-Warshall algorithm using open-source GPU
libraries such as PyTorch is presented. A further implementation of the
R-Kleene is also described, a slightly newer algorithm used for solving the
APSP problem in a divide-and-conquer, recursive but highly parallelized
architecture. In addition, a random graph generator that generates a wide range
of graphs of different scales is also contributed, where the densities and
connectivities are controlled using some heuristics. The run-times of the GPU
accelerated FW algorithm and R-Kleene on these heuristically generated graphs
are evaluated against each other and to the widely used implementation from
NetworkX. The code for the GPU implementation of the algorithms, the random
graph generator, and the Blender animation file are available at
https://github.com/tanjary21/APSP_GPU/.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03984" title="Abstract">arXiv:2310.03984</a> [<a href="/pdf/2310.03984" title="Download PDF">pdf</a>, <a href="/format/2310.03984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaRec: Adaptive Sequential Recommendation for Reinforcing Long-term  User Engagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhenghai Xue</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qingpeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+T">Tianyou Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lantao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Kun Gai</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Growing attention has been paid to Reinforcement Learning (RL) algorithms
when optimizing long-term user engagement in sequential recommendation tasks.
One challenge in large-scale online recommendation systems is the constant and
complicated changes in users' behavior patterns, such as interaction rates and
retention tendencies. When formulated as a Markov Decision Process (MDP), the
dynamics and reward functions of the recommendation system are continuously
affected by these changes. Existing RL algorithms for recommendation systems
will suffer from distribution shift and struggle to adapt in such an MDP. In
this paper, we introduce a novel paradigm called Adaptive Sequential
Recommendation (AdaRec) to address this issue. AdaRec proposes a new
distance-based representation loss to extract latent information from users'
interaction trajectories. Such information reflects how RL policy fits to
current user behavior patterns, and helps the policy to identify subtle changes
in the recommendation system. To make rapid adaptation to these changes, AdaRec
encourages exploration with the idea of optimism under uncertainty. The
exploration is further guarded by zero-order action optimization to ensure
stable recommendation quality in complicated environments. We conduct extensive
empirical analyses in both simulator-based and live sequential recommendation
tasks, where AdaRec exhibits superior long-term performance compared to all
baseline algorithms.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03985" title="Abstract">arXiv:2310.03985</a> [<a href="/pdf/2310.03985" title="Download PDF">pdf</a>, <a href="/format/2310.03985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dementia Assessment Using Mandarin Speech with an Attention-based Speech  Recognition Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zih-Jyun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Ju Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+P">Po-Chih Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Likai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chaur-Jong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng-Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Dementia diagnosis requires a series of different testing methods, which is
complex and time-consuming. Early detection of dementia is crucial as it can
prevent further deterioration of the condition. This paper utilizes a speech
recognition model to construct a dementia assessment system tailored for
Mandarin speakers during the picture description task. By training an
attention-based speech recognition model on voice data closely resembling
real-world scenarios, we have significantly enhanced the model's recognition
capabilities. Subsequently, we extracted the encoder from the speech
recognition model and added a linear layer for dementia assessment. We
collected Mandarin speech data from 99 subjects and acquired their clinical
assessments from a local hospital. We achieved an accuracy of 92.04% in
Alzheimer's disease detection and a mean absolute error of 9% in clinical
dementia rating score prediction.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03986" title="Abstract">arXiv:2310.03986</a> [<a href="/pdf/2310.03986" title="Download PDF">pdf</a>, <a href="/format/2310.03986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Multimodal Learning with Missing Modalities via  Parameter-Efficient Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reza%2C+M+K">Md Kaykobad Reza</a>, 
<a href="/search/cs?searchtype=author&query=Prater-Bennette%2C+A">Ashley Prater-Bennette</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+M+S">M. Salman Asif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal learning seeks to utilize data from multiple sources to improve
the overall performance of downstream tasks. It is desirable for redundancies
in the data to make multimodal systems robust to missing or corrupted
observations in some correlated modalities. However, we observe that the
performance of several existing multimodal networks significantly deteriorates
if one or multiple modalities are absent at test time. To enable robustness to
missing modalities, we propose simple and parameter-efficient adaptation
procedures for pretrained multimodal networks. In particular, we exploit
low-rank adaptation and modulation of intermediate features to compensate for
the missing modalities. We demonstrate that such adaptation can partially
bridge performance drop due to missing modalities and outperform independent,
dedicated networks trained for the available modality combinations in some
cases. The proposed adaptation requires extremely small number of parameters
(e.g., fewer than 0.7% of the total parameters in most experiments). We conduct
a series of experiments to highlight the robustness of our proposed method
using diverse datasets for RGB-thermal and RGB-Depth semantic segmentation,
multimodal material segmentation, and multimodal sentiment analysis tasks. Our
proposed method demonstrates versatility across various tasks and datasets, and
outperforms existing methods for robust multimodal learning with missing
modalities.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03991" title="Abstract">arXiv:2310.03991</a> [<a href="/pdf/2310.03991" title="Download PDF">pdf</a>, <a href="/format/2310.03991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+A+B">Abe Bohan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianxing He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+Y">Yung-Sung Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing watermarking algorithms are vulnerable to paraphrase attacks because
of their token-level design. To address this issue, we propose SemStamp, a
robust sentence-level semantic watermarking algorithm based on
locality-sensitive hashing (LSH), which partitions the semantic space of
sentences. The algorithm encodes and LSH-hashes a candidate sentence generated
by an LLM, and conducts sentence-level rejection sampling until the sampled
sentence falls in watermarked partitions in the semantic embedding space. A
margin-based constraint is used to enhance its robustness. To show the
advantages of our algorithm, we propose a "bigram" paraphrase attack using the
paraphrase that has the fewest bigram overlaps with the original sentence. This
attack is shown to be effective against the existing token-level watermarking
method. Experimental results show that our novel semantic watermark algorithm
is not only more robust than the previous state-of-the-art method on both
common and bigram paraphrase attacks, but also is better at preserving the
quality of generation.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03992" title="Abstract">arXiv:2310.03992</a> [<a href="/pdf/2310.03992" title="Download PDF">pdf</a>, <a href="/format/2310.03992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-Adapted Implicit Distribution Alignment Networks for Cross-Corpus  Speech Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yuan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jincen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+H">Hailun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Li Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenming Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we propose a new unsupervised domain adaptation (DA) method
called layer-adapted implicit distribution alignment networks (LIDAN) to
address the challenge of cross-corpus speech emotion recognition (SER). LIDAN
extends our previous ICASSP work, deep implicit distribution alignment networks
(DIDAN), whose key contribution lies in the introduction of a novel
regularization term called implicit distribution alignment (IDA). This term
allows DIDAN trained on source (training) speech samples to remain applicable
to predicting emotion labels for target (testing) speech samples, regardless of
corpus variance in cross-corpus SER. To further enhance this method, we extend
IDA to layer-adapted IDA (LIDA), resulting in LIDAN. This layer-adpated
extention consists of three modified IDA terms that consider emotion labels at
different levels of granularity. These terms are strategically arranged within
different fully connected layers in LIDAN, aligning with the increasing
emotion-discriminative abilities with respect to the layer depth. This
arrangement enables LIDAN to more effectively learn emotion-discriminative and
corpus-invariant features for SER across various corpora compared to DIDAN. It
is also worthy to mention that unlike most existing methods that rely on
estimating statistical moments to describe pre-assumed explicit distributions,
both IDA and LIDA take a different approach. They utilize an idea of target
sample reconstruction to directly bridge the feature distribution gap without
making assumptions about their distribution type. As a result, DIDAN and LIDAN
can be viewed as implicit cross-corpus SER methods. To evaluate LIDAN, we
conducted extensive cross-corpus SER experiments on EmoDB, eNTERFACE, and CASIA
corpora. The experimental results demonstrate that LIDAN surpasses recent
state-of-the-art explicit unsupervised DA methods in tackling cross-corpus SER
tasks.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03994" title="Abstract">arXiv:2310.03994</a> [<a href="/pdf/2310.03994" title="Download PDF">pdf</a>, <a href="/format/2310.03994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeMiST: Detection and Mitigation of Stealthy Analog Hardware Trojans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oriero%2C+E">Enahoro Oriero</a>, 
<a href="/search/cs?searchtype=author&query=Khalid%2C+F">Faiq Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+S+R">Syed Rafay Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Hardware and Architectural Support for Security and Privacy (HASP) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR); Systems and Control (eess.SY)

</div>
<p class="mathjax">The global semiconductor supply chain involves design and fabrication at
various locations, which leads to multiple security vulnerabilities, e.g.,
Hardware Trojan (HT) insertion. Although most HTs target digital circuits, HTs
can be inserted in analog circuits. Therefore, several techniques have been
developed for HT insertions in analog circuits. Capacitance-based Analog
Hardware Trojan (AHT) is one of the stealthiest HT that can bypass most
existing HT detection techniques because it uses negligible charge accumulation
in the capacitor to generate stealthy triggers. To address the charge sharing
and accumulation issues, we propose a novel way to detect such
capacitance-based AHT in this paper. Secondly, we critically analyzed existing
AHTs to highlight their respective limitations. We proposed a stealthier
capacitor-based AHT (fortified AHT) that can bypass our novel AHT detection
technique by addressing these limitations. Finally, by critically analyzing the
proposed fortified AHT and existing AHTs, we developed a robust two-phase
framework (DeMiST) in which a synchronous system can mitigate the effects of
capacitance-based stealthy AHTs by turning off the triggering capability of
AHT. In the first phase, we demonstrate how the synchronous system can avoid
the AHT during run-time by controlling the supply voltage of the intermediate
combinational circuits. In the second phase, we proposed a supply voltage duty
cycle-based validation technique to detect capacitance-based AHTs. Furthermore,
DeMiST amplified the switching activity for charge accumulation to such a
degree that it can be easily detectable using existing switching activity-based
HT detection techniques.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03997" title="Abstract">arXiv:2310.03997</a> [<a href="/pdf/2310.03997" title="Download PDF">pdf</a>, <a href="/format/2310.03997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RISA: Round-Robin Intra-Rack Friendly Scheduling Algorithm for  Disaggregated Datacenters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabir%2C+R">Rashadul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+R+G">Ryan G. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Nikdast%2C+M">Mahdi Nikdast</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Recent trends see a move away from a fixed-resource server-centric datacenter
model to a more adaptable "disaggregated" datacenter model. These disaggregated
datacenters can then dynamically group resources to the specific requirements
of an incoming workload, thereby improving efficiency. To properly utilize
these disaggregated datacenters, workload allocation techniques must examine
the current state of the datacenter and choose resources that not only optimize
the current workload request, but future ones. Since disaggregated datacenters
are severely bottlenecked by the available network resources, our work proposes
a heuristic-based approach called RISA, which significantly reduces the network
usage of workload allocations in disaggregated datacenters. Compared to the
state-of-the-art, RISA reduces the power consumption for optical components by
33% and reduces the average CPU-RAM round-trip latency by 50%. Additionally,
RISA significantly outperforms the state-of-the-art in terms of execution time.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03999" title="Abstract">arXiv:2310.03999</a> [<a href="/pdf/2310.03999" title="Download PDF">pdf</a>, <a href="/format/2310.03999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runtime Monitoring DNN-Based Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chih-Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luttenberger%2C+M">Michael Luttenberger</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rongjie Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Deep neural networks (DNNs) are instrumental in realizing complex perception
systems. As many of these applications are safety-critical by design,
engineering rigor is required to ensure that the functional insufficiency of
the DNN-based perception is not the source of harm. In addition to conventional
static verification and testing techniques employed during the design phase,
there is a need for runtime verification techniques that can detect critical
events, diagnose issues, and even enforce requirements. This tutorial aims to
provide readers with a glimpse of techniques proposed in the literature. We
start with classical methods proposed in the machine learning community, then
highlight a few techniques proposed by the formal methods community. While we
surely can observe similarities in the design of monitors, how the decision
boundaries are created vary between the two communities. We conclude by
highlighting the need to rigorously design monitors, where data availability
outside the operational domain plays an important role.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04003" title="Abstract">arXiv:2310.04003</a> [<a href="/pdf/2310.04003" title="Download PDF">pdf</a>, <a href="/format/2310.04003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Federated Learning in a Wireless World with Foundation  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+H">Howard H. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y+C">Y. C. Tay</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+K+F+E">Kai Fong Ernest Chong</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q. S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Foundation models (FMs) are general-purpose artificial intelligence (AI)
models that have recently enabled multiple brand-new generative AI
applications. The rapid advances in FMs serve as an important contextual
backdrop for the vision of next-generation wireless networks, where federated
learning (FL) is a key enabler of distributed network intelligence. Currently,
the exploration of the interplay between FMs and FL is still in its nascent
stage. Naturally, FMs are capable of boosting the performance of FL, and FL
could also leverage decentralized data and computing resources to assist in the
training of FMs. However, the exceptionally high requirements that FMs have for
computing resources, storage, and communication overhead would pose critical
challenges to FL-enabled wireless networks. In this article, we explore the
extent to which FMs are suitable for FL over wireless networks, including a
broad overview of research challenges and opportunities. In particular, we
discuss multiple new paradigms for realizing future intelligent networks that
integrate FMs and FL. We also consolidate several broad research directions
associated with these paradigms.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04004" title="Abstract">arXiv:2310.04004</a> [<a href="/pdf/2310.04004" title="Download PDF">pdf</a>, <a href="/format/2310.04004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-Style: Cascading U-nets with Multi-level Speaker and Style Modeling  for Zero-Shot Voice Cloning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+J">Jian Cong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qiao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Zero-shot speaker cloning aims to synthesize speech for any target speaker
unseen during TTS system building, given only a single speech reference of the
speaker at hand. Although more practical in real applications, the current
zero-shot methods still produce speech with undesirable naturalness and speaker
similarity. Moreover, endowing the target speaker with arbitrary speaking
styles in the zero-shot setup has not been considered. This is because the
unique challenge of zero-shot speaker and style cloning is to learn the
disentangled speaker and style representations from only short references
representing an arbitrary speaker and an arbitrary style. To address this
challenge, we propose U-Style, which employs Grad-TTS as the backbone,
particularly cascading a speaker-specific encoder and a style-specific encoder
between the text encoder and the diffusion decoder. Thus, leveraging signal
perturbation, U-Style is explicitly decomposed into speaker- and style-specific
modeling parts, achieving better speaker and style disentanglement. To improve
unseen speaker and style modeling ability, these two encoders conduct
multi-level speaker and style modeling by skip-connected U-nets, incorporating
the representation extraction and information reconstruction process. Besides,
to improve the naturalness of synthetic speech, we adopt mean-based instance
normalization and style adaptive layer normalization in these encoders to
perform representation extraction and condition adaptation, respectively.
Experiments show that U-Style significantly surpasses the state-of-the-art
methods in unseen speaker cloning regarding naturalness and speaker similarity.
Notably, U-Style can transfer the style from an unseen source speaker to
another unseen target speaker, achieving flexible combinations of desired
speaker timbre and style in zero-shot voice cloning.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04007" title="Abstract">arXiv:2310.04007</a> [<a href="/pdf/2310.04007" title="Download PDF">pdf</a>, <a href="/format/2310.04007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Safety for Mixed-Autonomy Traffic with Delays and Disturbances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Chenguang Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Huan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Various control strategies and field experiments have been designed for
connected and automated vehicles (CAVs) to stabilize mixed traffic that
contains both CAVs and Human-driven Vehicles (HVs). The effect of these
stabilizing CAV control strategies on traffic safety is still under
investigation. In an effort to prioritize safety over stability, a
safety-critical filter via control barrier functions (CBFs) can be designed by
modifying the stabilizing nominal control input in a minimal fashion and
imparting collision-free driving behaviors for CAVs and HVs. However, such
formal safety guarantees can be violated if there are delays in the actuation
and communication channels of the CAV. Considering both actuator and sensor
delays, and disturbances, we propose robust safety-critical traffic control
(RSTC) design to ensure ``robust safety'' of the mixed traffic. While
predictor-based CBF has been developed to compensate for the actuator delay,
uncertain speed disturbances from the head vehicle cause prediction error and
require novel robust CBF design. Besides, safety-critical control with sensor
delay also remains an open question. In RSTC, a state predictor with bounded
error is designed, and robust CBF constraints are constructed to guarantee
safety under actuator delay and disturbances. When there is a sensor delay, a
state observer is designed and integrated with a predictor-based CBF to ensure
robust safety. Numerical simulations demonstrate that the proposed RSTC avoids
rear-end collisions for two unsafe traffic scenarios in the presence of
actuator, sensor delays and disturbances.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04010" title="Abstract">arXiv:2310.04010</a> [<a href="/pdf/2310.04010" title="Download PDF">pdf</a>, <a href="/format/2310.04010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Excision and Recovery: Enhancing Surface Anomaly Detection with  Attention-based Single Deterministic Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">YeongHyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungho Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M+J">Myung Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yeonho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Juneho Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Anomaly detection (AD) in surface inspection is an essential yet challenging
task in manufacturing due to the quantity imbalance problem of scarce abnormal
data. To overcome the above, a reconstruction encoder-decoder (ED) such as
autoencoder or U-Net which is trained with only anomaly-free samples is widely
adopted, in the hope that unseen abnormals should yield a larger reconstruction
error than normal. Over the past years, researches on self-supervised
reconstruction-by-inpainting have been reported. They mask out suspected
defective regions for inpainting in order to make them invisible to the
reconstruction ED to deliberately cause inaccurate reconstruction for
abnormals. However, their limitation is multiple random masking to cover the
whole input image due to defective regions not being known in advance. We
propose a novel reconstruction-by-inpainting method dubbed Excision and
Recovery (EAR) that features single deterministic masking. For this, we exploit
a pre-trained spatial attention model to predict potential suspected defective
regions that should be masked out. We also employ a variant of U-Net as our ED
to further limit the reconstruction ability of the U-Net model for abnormals,
in which skip connections of different layers can be selectively disabled. In
the training phase, all the skip connections are switched on to fully take the
benefits from the U-Net architecture. In contrast, for inferencing, we only
keep deeper skip connections with shallower connections off. We validate the
effectiveness of EAR using an MNIST pre-trained attention for a commonly used
surface AD dataset, KolektorSDD2. The experimental results show that EAR
achieves both better AD performance and higher throughput than state-of-the-art
methods. We expect that the proposed EAR model can be widely adopted as
training and inference strategies for AD purposes.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04011" title="Abstract">arXiv:2310.04011</a> [<a href="/pdf/2310.04011" title="Download PDF">pdf</a>, <a href="/format/2310.04011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-continuity s-version of finite element method with B-spline  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Magome%2C+N">Nozomi Magome</a>, 
<a href="/search/math?searchtype=author&query=Morita%2C+N">Naoki Morita</a>, 
<a href="/search/math?searchtype=author&query=Kaneko%2C+S">Shigeki Kaneko</a>, 
<a href="/search/math?searchtype=author&query=Mitsume%2C+N">Naoto Mitsume</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 15 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper proposes a strategy to solve the problems of the conventional
s-version of finite element method (SFEM) fundamentally. Because SFEM can
reasonably model an analytical domain by superimposing meshes with different
spatial resolutions, it has intrinsic advantages of local high accuracy, low
computation time, and simple meshing procedure. However, it has disadvantages
such as accuracy of numerical integration and matrix singularity. Although
several additional techniques have been proposed to mitigate these limitations,
they are computationally expensive or ad-hoc, and detract from its strengths.
To solve these issues, we propose a novel strategy called B-spline based SFEM.
To improve the accuracy of numerical integration, we employed cubic B-spline
basis functions with $C^2$-continuity across element boundaries as the global
basis functions. To avoid matrix singularity, we applied different basis
functions to different meshes. Specifically, we employed the Lagrange basis
functions as local basis functions. The numerical results indicate that using
the proposed method, numerical integration can be calculated with sufficient
accuracy without any additional techniques used in conventional SFEM.
Furthermore, the proposed method avoids matrix singularity and is superior to
conventional methods in terms of convergence for solving linear equations.
Therefore, the proposed method has the potential to reduce computation time
while maintaining a comparable accuracy to conventional SFEM.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04015" title="Abstract">arXiv:2310.04015</a> [<a href="/pdf/2310.04015" title="Download PDF">pdf</a>, <a href="/format/2310.04015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning via Look-Alike Clustering: A Precise Analysis of Model  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javanmard%2C+A">Adel Javanmard</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at the Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">While personalized recommendations systems have become increasingly popular,
ensuring user data protection remains a paramount concern in the development of
these learning systems. A common approach to enhancing privacy involves
training models using anonymous data rather than individual data. In this
paper, we explore a natural technique called \emph{look-alike clustering},
which involves replacing sensitive features of individuals with the cluster's
average values. We provide a precise analysis of how training models using
anonymous cluster centers affects their generalization capabilities. We focus
on an asymptotic regime where the size of the training set grows in proportion
to the features dimension. Our analysis is based on the Convex Gaussian Minimax
Theorem (CGMT) and allows us to theoretically understand the role of different
model components on the generalization error. In addition, we demonstrate that
in certain high-dimensional regimes, training over anonymous cluster centers
acts as a regularization and improves generalization error of the trained
models. Finally, we corroborate our asymptotic theory with finite-sample
numerical experiments where we observe a perfect match when the sample size is
only of order of a few hundreds.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04017" title="Abstract">arXiv:2310.04017</a> [<a href="/pdf/2310.04017" title="Download PDF">pdf</a>, <a href="/format/2310.04017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PGraphDTA: Improving Drug Target Interaction Prediction using Protein  Language Models and Contact Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bal%2C+R">Rakesh Bal</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yijia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Developing and discovering new drugs is a complex and resource-intensive
endeavor that often involves substantial costs, time investment, and safety
concerns. A key aspect of drug discovery involves identifying novel drug-target
(DT) interactions. Existing computational methods for predicting DT
interactions have primarily focused on binary classification tasks, aiming to
determine whether a DT pair interacts or not. However, protein-ligand
interactions exhibit a continuum of binding strengths, known as binding
affinity, presenting a persistent challenge for accurate prediction. In this
study, we investigate various techniques employed in Drug Target Interaction
(DTI) prediction and propose novel enhancements to enhance their performance.
Our approaches include the integration of Protein Language Models (PLMs) and
the incorporation of Contact Map information as an inductive bias within
current models. Through extensive experimentation, we demonstrate that our
proposed approaches outperform the baseline models considered in this study,
presenting a compelling case for further development in this direction. We
anticipate that the insights gained from this work will significantly narrow
the search space for potential drugs targeting specific proteins, thereby
accelerating drug discovery. Code and data for PGraphDTA are available at
https://anonymous.4open.science/r/PGraphDTA.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04018" title="Abstract">arXiv:2310.04018</a> [<a href="/pdf/2310.04018" title="Download PDF">pdf</a>, <a href="/ps/2310.04018" title="Download PostScript">ps</a>, <a href="/format/2310.04018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Higher-order Clusterability on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianzhong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Analysis of higher-order organizations, usually small connected subgraphs
called motifs, is a fundamental task on complex networks. This paper studies a
new problem of testing higher-order clusterability: given query access to an
undirected graph, can we judge whether this graph can be partitioned into a few
clusters of highly-connected motifs? This problem is an extension of the former
work proposed by Czumaj et al. (STOC' 15), who recognized cluster structure on
graphs using the framework of property testing. In this paper, a good graph
cluster on high dimensions is first defined for higher-order clustering. Then,
query lower bound is given for testing whether this kind of good cluster
exists. Finally, an optimal sublinear-time algorithm is developed for testing
clusterability based on triangles.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04020" title="Abstract">arXiv:2310.04020</a> [<a href="/pdf/2310.04020" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Snail Homing and Mating Search Algorithm: A Novel Bio-Inspired  Metaheuristic Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A+J">Anand J Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+I+R">Ishaan R Kale</a>, 
<a href="/search/cs?searchtype=author&query=Shastri%2C+A">Apoorva Shastri</a>, 
<a href="/search/cs?searchtype=author&query=Khandekar%2C+A">Aayush Khandekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 Pages, 11 Figures, 24 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">In this paper, a novel Snail Homing and Mating Search (SHMS) algorithm is
proposed. It is inspired from the biological behaviour of the snails. Snails
continuously travels to find food and a mate, leaving behind a trail of mucus
that serves as a guide for their return. Snails tend to navigate by following
the available trails on the ground and responding to cues from nearby shelter
homes. The proposed SHMS algorithm is investigated by solving several unimodal
and multimodal functions. The solutions are validated using standard
statistical tests such as two-sided and pairwise signed rank Wilcoxon test and
Friedman rank test. The solution obtained from the SHMS algorithm exhibited
superior robustness as well as search space exploration capabilities within the
less computational cost. The real-world application of SHMS algorithm is
successfully demonstrated in the engineering design domain by solving three
cases of design and economic optimization shell and tube heat exchanger
problem. The objective function value and other statistical results obtained
using SHMS algorithm are compared with other well-known metaheuristic
algorithms.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04022" title="Abstract">arXiv:2310.04022</a> [<a href="/pdf/2310.04022" title="Download PDF">pdf</a>, <a href="/format/2310.04022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Methods for Shape Optimization Problems in Liquid Crystal  Tactoids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adler%2C+J+H">James H. Adler</a>, 
<a href="/search/math?searchtype=author&query=Andrei%2C+A+S">Anca S. Andrei</a>, 
<a href="/search/math?searchtype=author&query=Atherton%2C+T+J">Timothy J. Atherton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Anisotropic fluids, such as nematic liquid crystals, can form non-spherical
equilibrium shapes known as tactoids. Predicting the shape of these structures
as a function of material parameters is challenging and paradigmatic of a
broader class of problems that combine shape and order. Here, we develop a
discrete shape optimization approach with finite elements to find the
configuration of a two-dimensional tactoid using the Landau de Gennes framework
and a Q-tensor representation. Efficient solution of the resulting constrained
energy minimization problem is achieved using a quasi-Newton and nested
iteration algorithm. Numerical validation is performed with benchmark solutions
and compared against experimental data and earlier work. We explore physically
motivated subproblems, whereby the shape and order are separately held fixed,
to explore the role of both and examine material parameter dependence of the
convergence. Nested iteration significantly improves both the computational
cost and convergence of numerical solutions of these highly deformable
materials.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04027" title="Abstract">arXiv:2310.04027</a> [<a href="/pdf/2310.04027" title="Download PDF">pdf</a>, <a href="/format/2310.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Financial Sentiment Analysis via Retrieval Augmented Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Boyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+A">Ali Babar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao-Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM International Conference on AI in Finance (ICAIF) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Statistical Finance (q-fin.ST); Trading and Market Microstructure (q-fin.TR)

</div>
<p class="mathjax">Financial sentiment analysis is critical for valuation and investment
decision-making. Traditional NLP models, however, are limited by their
parameter size and the scope of their training datasets, which hampers their
generalization capabilities and effectiveness in this field. Recently, Large
Language Models (LLMs) pre-trained on extensive corpora have demonstrated
superior performance across various NLP tasks due to their commendable
zero-shot abilities. Yet, directly applying LLMs to financial sentiment
analysis presents challenges: The discrepancy between the pre-training
objective of LLMs and predicting the sentiment label can compromise their
predictive performance. Furthermore, the succinct nature of financial news,
often devoid of sufficient context, can significantly diminish the reliability
of LLMs' sentiment analysis. To address these challenges, we introduce a
retrieval-augmented LLMs framework for financial sentiment analysis. This
framework includes an instruction-tuned LLMs module, which ensures LLMs behave
as predictors of sentiment labels, and a retrieval-augmentation module which
retrieves additional context from reliable external sources. Benchmarked
against traditional models and LLMs like ChatGPT and LLaMA, our approach
achieves 15\% to 48\% performance gain in accuracy and F1 score.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04028" title="Abstract">arXiv:2310.04028</a> [<a href="/pdf/2310.04028" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic prediction of quantitative traits: a machine learner&#x27;s guide  focused on height
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourguignon%2C+L">Lucie Bourguignon</a>, 
<a href="/search/cs?searchtype=author&query=Weis%2C+C">Caroline Weis</a>, 
<a href="/search/cs?searchtype=author&query=Jutzeler%2C+C+R">Catherine R. Jutzeler</a>, 
<a href="/search/cs?searchtype=author&query=Adamer%2C+M">Michael Adamer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN)

</div>
<p class="mathjax">Machine learning and deep learning have been celebrating many successes in
the application to biological problems, especially in the domain of protein
folding. Another equally complex and important question has received relatively
little attention by the machine learning community, namely the one of
prediction of complex traits from genetics. Tackling this problem requires
in-depth knowledge of the related genetics literature and awareness of various
subtleties associated with genetic data. In this guide, we provide an overview
for the machine learning community on current state of the art models and
associated subtleties which need to be taken into consideration when developing
new models for phenotype prediction. We use height as an example of a
continuous-valued phenotype and provide an introduction to benchmark datasets,
confounders, feature selection, and common metrics.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04034" title="Abstract">arXiv:2310.04034</a> [<a href="/pdf/2310.04034" title="Download PDF">pdf</a>, <a href="/format/2310.04034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A short report on preconditioned Anderson acceleration method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+K">Kewang Chen</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+Y">Ye Ji</a>, 
<a href="/search/math?searchtype=author&query=M%C3%B6ller%2C+M">Matthias M&#xf6;ller</a>, 
<a href="/search/math?searchtype=author&query=Vuik%2C+C">Cornelis Vuik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this report, we present a versatile and efficient preconditioned Anderson
acceleration (PAA) method for fixed-point iterations. The proposed framework
offers flexibility in balancing convergence rates (linear, super-linear, or
quadratic) and computational costs related to the Jacobian matrix. Our approach
recovers various fixed-point iteration techniques, including Picard, Newton,
and quasi-Newton iterations. The PAA method can be interpreted as employing
Anderson acceleration (AA) as its own preconditioner or as an accelerator for
quasi-Newton methods when their convergence is insufficient. Adaptable to a
wide range of problems with differing degrees of nonlinearity and complexity,
the method achieves improved convergence rates and robustness by incorporating
suitable preconditioners. We test multiple preconditioning strategies on
various problems and investigate a delayed update strategy for preconditioners
to further reduce the computational costs.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04038" title="Abstract">arXiv:2310.04038</a> [<a href="/pdf/2310.04038" title="Download PDF">pdf</a>, <a href="/format/2310.04038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Projection Learning and Tensor Decomposition Based Incomplete  Multi-view Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+W">Wei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiuyi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Neural Networks and Learning Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Incomplete multi-view clustering (IMVC) has received increasing attention
since it is often that some views of samples are incomplete in reality. Most
existing methods learn similarity subgraphs from original incomplete multi-view
data and seek complete graphs by exploring the incomplete subgraphs of each
view for spectral clustering. However, the graphs constructed on the original
high-dimensional data may be suboptimal due to feature redundancy and noise.
Besides, previous methods generally ignored the graph noise caused by the
inter-class and intra-class structure variation during the transformation of
incomplete graphs and complete graphs. To address these problems, we propose a
novel Joint Projection Learning and Tensor Decomposition Based method (JPLTD)
for IMVC. Specifically, to alleviate the influence of redundant features and
noise in high-dimensional data, JPLTD introduces an orthogonal projection
matrix to project the high-dimensional features into a lower-dimensional space
for compact feature learning.Meanwhile, based on the lower-dimensional space,
the similarity graphs corresponding to instances of different views are
learned, and JPLTD stacks these graphs into a third-order low-rank tensor to
explore the high-order correlations across different views. We further consider
the graph noise of projected data caused by missing samples and use a
tensor-decomposition based graph filter for robust clustering.JPLTD decomposes
the original tensor into an intrinsic tensor and a sparse tensor. The intrinsic
tensor models the true data similarities. An effective optimization algorithm
is adopted to solve the JPLTD model. Comprehensive experiments on several
benchmark datasets demonstrate that JPLTD outperforms the state-of-the-art
methods. The code of JPLTD is available at https://github.com/weilvNJU/JPLTD.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04039" title="Abstract">arXiv:2310.04039</a> [<a href="/pdf/2310.04039" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the Reasoning with Redundant Information Provided Ability of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenbei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in Large Language Models (LLMs) have demonstrated
impressive capabilities across a range of natural language processing tasks,
especially in reasoning, a cornerstone for achieving Artificial General
Intelligence (AGI). However, commonly used benchmarks may not fully encapsulate
the inferential abilities of these models in real-world scenarios. To address
this gap, a new form of Question-Answering (QA) task, termed Reasoning with
Redundant Information Provided (RRIP), is introduced. The study designed a
modified version of the grade school math 8K (GSM-8K) dataset which has several
variants focusing on different attributes of redundant information. This
investigation evaluates two popular LLMs, LlaMA2-13B-chat and generative
pre-trained transformer 3.5 (GPT-3.5), contrasting their performance on
traditional QA tasks against the RRIP tasks. Findings indicate that while these
models achieved moderate success on standard QA benchmarks, their performance
notably declines when assessed on RRIP tasks. The study not only highlights the
limitations of current LLMs in handling redundant information but also suggests
that future training of these models should focus on incorporating redundant
information into the training data to increase the performance on RRIP tasks.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04041" title="Abstract">arXiv:2310.04041</a> [<a href="/pdf/2310.04041" title="Download PDF">pdf</a>, <a href="/format/2310.04041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observation-Guided Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Junoh Kang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinyoung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sungik Choi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a novel diffusion model called observation-guided diffusion
probabilistic model (OGDM), which effectively addresses the trade-off between
quality control and fast sampling. Our approach reestablishes the training
objective by integrating the guidance of the observation process with the
Markov chain in a principled way. This is achieved by introducing an additional
loss term derived from the observation based on the conditional discriminator
on noise level, which employs Bernoulli distribution indicating whether its
input lies on the (noisy) real manifold or not. This strategy allows us to
optimize the more accurate negative log-likelihood induced in the inference
stage especially when the number of function evaluations is limited. The
proposed training method is also advantageous even when incorporated only into
the fine-tuning process, and it is compatible with various fast inference
strategies since our method yields better denoising networks using the exactly
same inference procedure without incurring extra computational cost. We
demonstrate the effectiveness of the proposed training algorithm using diverse
inference methods on strong diffusion model baselines.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04042" title="Abstract">arXiv:2310.04042</a> [<a href="/pdf/2310.04042" title="Download PDF">pdf</a>, <a href="/format/2310.04042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bivariate Estimation-of-Distribution Algorithms Can Find an Exponential  Number of Optima
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>, 
<a href="/search/cs?searchtype=author&query=Krejca%2C+M+S">Martin S. Krejca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Finding a large set of optima in a multimodal optimization landscape is a
challenging task. Classical population-based evolutionary algorithms typically
converge only to a single solution. While this can be counteracted by applying
niching strategies, the number of optima is nonetheless trivially bounded by
the population size. Estimation-of-distribution algorithms (EDAs) are an
alternative, maintaining a probabilistic model of the solution space instead of
a population. Such a model is able to implicitly represent a solution set far
larger than any realistic population size.
<br />To support the study of how optimization algorithms handle large sets of
optima, we propose the test function EqualBlocksOneMax (EBOM). It has an easy
fitness landscape with exponentially many optima. We show that the bivariate
EDA mutual-information-maximizing input clustering, without any
problem-specific modification, quickly generates a model that behaves very
similarly to a theoretically ideal model for EBOM, which samples each of the
exponentially many optima with the same maximal probability. We also prove via
mathematical means that no univariate model can come close to having this
property: If the probability to sample an optimum is at least
inverse-polynomial, there is a Hamming ball of logarithmic radius such that,
with high probability, each sample is in this ball.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04043" title="Abstract">arXiv:2310.04043</a> [<a href="/pdf/2310.04043" title="Download PDF">pdf</a>, <a href="/format/2310.04043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In the Blink of an Eye: Event-based Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Peers%2C+P">Pieter Peers</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaopeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Heide%2C+F">Felix Heide</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Special Interest Group for Computer GRAPHICS,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce a wearable single-eye emotion recognition device and a real-time
approach to recognizing emotions from partial observations of an emotion that
is robust to changes in lighting conditions. At the heart of our method is a
bio-inspired event-based camera setup and a newly designed lightweight Spiking
Eye Emotion Network (SEEN). Compared to conventional cameras, event-based
cameras offer a higher dynamic range (up to 140 dB vs. 80 dB) and a higher
temporal resolution. Thus, the captured events can encode rich temporal cues
under challenging lighting conditions. However, these events lack texture
information, posing problems in decoding temporal information effectively. SEEN
tackles this issue from two different perspectives. First, we adopt
convolutional spiking layers to take advantage of the spiking neural network's
ability to decode pertinent temporal information. Second, SEEN learns to
extract essential spatial cues from corresponding intensity frames and
leverages a novel weight-copy scheme to convey spatial attention to the
convolutional spiking layers during training and inference. We extensively
validate and demonstrate the effectiveness of our approach on a specially
collected Single-eye Event-based Emotion (SEE) dataset. To the best of our
knowledge, our method is the first eye-based emotion recognition method that
leverages event-based cameras and spiking neural network.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04044" title="Abstract">arXiv:2310.04044</a> [<a href="/pdf/2310.04044" title="Download PDF">pdf</a>, <a href="/format/2310.04044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-based 3D Collision-distance Estimation Network with Probabilistic  Graph Rewiring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Minjae Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yeseung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Daehyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We aim to solve the problem of data-driven collision-distance estimation
given 3-dimensional (3D) geometries. Conventional algorithms suffer from low
accuracy due to their reliance on limited representations, such as point
clouds. In contrast, our previous graph-based model, GraphDistNet, achieves
high accuracy using edge information but incurs higher message-passing costs
with growing graph size, limiting its applicability to 3D geometries. To
overcome these challenges, we propose GDN-R, a novel 3D graph-based estimation
network.GDN-R employs a layer-wise probabilistic graph-rewiring algorithm
leveraging the differentiable Gumbel-top-K relaxation. Our method accurately
infers minimum distances through iterative graph rewiring and updating relevant
embeddings. The probabilistic rewiring enables fast and robust embedding with
respect to unforeseen categories of geometries. Through 41,412 random benchmark
tasks with 150 pairs of 3D objects, we show GDN-R outperforms state-of-the-art
baseline methods in terms of accuracy and generalizability. We also show that
the proposed rewiring improves the update performance reducing the size of the
estimation model. We finally show its batch prediction and auto-differentiation
capabilities for trajectory optimization in both simulated and real-world
scenarios.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04047" title="Abstract">arXiv:2310.04047</a> [<a href="/pdf/2310.04047" title="Download PDF">pdf</a>, <a href="/format/2310.04047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+Q+I">Quazi Ishtiaque Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=TehraniJamsaz%2C+A">Ali TehraniJamsaz</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+H+D">Hung D Phan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Jannesari%2C+A">Ali Jannesari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Parallelizing sequentially written programs is a challenging task. Even
experienced developers need to spend considerable time finding parallelism
opportunities and then actually writing parallel versions of sequentially
written programs. To address this issue, we present AUTOPARLLM, a framework for
automatically discovering parallelism and generating the parallel version of
the sequentially written program. Our framework consists of two major
components: i) a heterogeneous Graph Neural Network (GNN) based parallelism
discovery and parallel pattern detection module, and ii) an LLM-based code
generator to generate the parallel counterpart of the sequential programs. We
use the GNN to learn the flow-aware characteristics of the programs to identify
parallel regions in sequential programs and then construct an enhanced prompt
using the GNN's results for the LLM-based generator to finally produce the
parallel counterparts of the sequential programs. We evaluate AUTOPARLLM on 11
applications of 2 well-known benchmark suites: NAS Parallel Benchmark and
Rodinia Benchmark. Our results show that AUTOPARLLM is indeed effective in
improving the state-of-the-art LLM-based models for the task of parallel code
generation in terms of multiple code generation metrics. AUTOPARLLM also
improves the average runtime of the parallel code generated by the
state-of-the-art LLMs by as high as 3.4% and 2.9% for the NAS Parallel
Benchmark and Rodinia Benchmark respectively. Additionally, to overcome the
issue that well-known metrics for translation evaluation have not been
optimized to evaluate the quality of the generated parallel code, we propose
OMPScore for evaluating the quality of the generated code. We show that
OMPScore exhibits a better correlation with human judgment than existing
metrics, measured by up to 75% improvement of Spearman correlation.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04055" title="Abstract">arXiv:2310.04055</a> [<a href="/pdf/2310.04055" title="Download PDF">pdf</a>, <a href="/format/2310.04055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kick Bad Guys Out! Zero-Knowledge-Proof-Based Anomaly Detection in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shanshan Han</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Buyukates%2C+B">Baturalp Buyukates</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Weizhao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chaoyang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) systems are vulnerable to malicious clients that
submit poisoned local models to achieve their adversarial goals, such as
preventing the convergence of the global model or inducing the global model to
misclassify some data. Many existing defense mechanisms are impractical in
real-world FL systems, as they require prior knowledge of the number of
malicious clients or rely on re-weighting or modifying submissions. This is
because adversaries typically do not announce their intentions before
attacking, and re-weighting might change aggregation results even in the
absence of attacks. To address these challenges in real FL systems, this paper
introduces a cutting-edge anomaly detection approach with the following
features: i) Detecting the occurrence of attacks and performing defense
operations only when attacks happen; ii) Upon the occurrence of an attack,
further detecting the malicious client models and eliminating them without
harming the benign ones; iii) Ensuring honest execution of defense mechanisms
at the server by leveraging a zero-knowledge proof mechanism. We validate the
superior performance of the proposed approach with extensive experiments.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04058" title="Abstract">arXiv:2310.04058</a> [<a href="/pdf/2310.04058" title="Download PDF">pdf</a>, <a href="/format/2310.04058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game-Theoretic Analysis of (Non-)Refundable Fees in the Lightning  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumble%2C+S+P">Satwik Prabhu Kumble</a>, 
<a href="/search/cs?searchtype=author&query=Epema%2C+D">Dick Epema</a>, 
<a href="/search/cs?searchtype=author&query=Roos%2C+S">Stefanie Roos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">In PCNs, nodes that forward payments between a source and a receiver are paid
a small fee if the payment is successful. The fee is a compensation for
temporarily committing funds to the payment. However, payments may fail due to
insufficient funds or attacks, often after considerable delays of up to several
days, leaving a node without compensation. Furthermore, attackers can
intentionally cause failed payments, e.g., to infer private information (like
channel balances), without any cost in fees. In this paper, we first use
extensive form games to formally characterize the conditions that lead to
rational intermediaries refusing (or agreeing) to forward payments. A decision
made by an intermediary to forward or not depends on the probability of
failure, which they approximate based on past experience. We then propose and
analyze an alternative fee model that allows the sender to determine and pay a
fraction of the fee to intermediaries in a non refundable manner. A rational
sender chooses the fraction such that the intermediaries' utility for
forwarding the payment exceeds their utility for not forwarding. Our simulation
study, based on real world Lightning snapshots, confirms that our novel
mechanism can increase the probability of successful payments by 12 percent and
decrease routing fees for senders by about 6 percent if all nodes behave
rationally. Furthermore, previously cost free probing attacks now require that
the attacker pays 1500 satoshis for every 1 million satoshis inferred. Finally,
we propose a modification to the Hash Time Locked Contract to enable secure
payments of the non refundable fees.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04059" title="Abstract">arXiv:2310.04059</a> [<a href="/pdf/2310.04059" title="Download PDF">pdf</a>, <a href="/format/2310.04059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEFT: A new distance-based feature set for keystroke dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaluarachchi%2C+N">Nuwan Kaluarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Kandanaarachchi%2C+S">Sevvandi Kandanaarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kristen Moore</a>, 
<a href="/search/cs?searchtype=author&query=Arakala%2C+A">Arathi Arakala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 3 tables, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Keystroke dynamics is a behavioural biometric utilised for user
identification and authentication. We propose a new set of features based on
the distance between keys on the keyboard, a concept that has not been
considered before in keystroke dynamics. We combine flight times, a popular
metric, with the distance between keys on the keyboard and call them as
Distance Enhanced Flight Time features (DEFT). This novel approach provides
comprehensive insights into a person's typing behaviour, surpassing typing
velocity alone. We build a DEFT model by combining DEFT features with other
previously used keystroke dynamic features. The DEFT model is designed to be
device-agnostic, allowing us to evaluate its effectiveness across three
commonly used devices: desktop, mobile, and tablet. The DEFT model outperforms
the existing state-of-the-art methods when we evaluate its effectiveness across
two datasets. We obtain accuracy rates exceeding 99% and equal error rates
below 10% on all three devices.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04063" title="Abstract">arXiv:2310.04063</a> [<a href="/pdf/2310.04063" title="Download PDF">pdf</a>, <a href="/format/2310.04063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Globally Optimal Resource Allocation Design for Discrete Phase Shift  IRS-Assisted Multiuser Networks with Perfect and Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongfang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>, 
<a href="/search/cs?searchtype=author&query=Gerstacker%2C+W">Wolfgang Gerstacker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Intelligent reflecting surfaces (IRSs) are a promising low-cost solution for
achieving high spectral and energy efficiency in future communication systems
by enabling the customization of wireless propagation environments. Despite the
plethora of research on resource allocation design for IRS-assisted multiuser
communication systems, the optimal design and the corresponding performance
upper bound are still not fully understood. To bridge this gap in knowledge, in
this paper, we investigate the optimal resource allocation design for
IRS-assisted multiuser systems employing practical discrete IRS phase shifters.
In particular, we jointly optimize the beamforming vector at the base station
(BS) and the discrete IRS phase shifts to minimize the total transmit power for
the cases of perfect and imperfect channel state information (CSI) knowledge.
To this end, two novel algorithms based on the generalized Benders
decomposition (GBD) method are developed to obtain the globally optimal
solution for perfect and imperfect CSI, respectively. Moreover, to facilitate
practical implementation, we propose two corresponding low-complexity
suboptimal algorithms with guaranteed convergence by capitalizing on successive
convex approximation (SCA). In particular, for imperfect CSI, we adopt a
bounded error model to characterize the CSI uncertainty and propose a new
transformation to convexify the robust quality-of-service (QoS) constraints.
Our numerical results confirm the optimality of the proposed GBD-based
algorithms for the considered system for both perfect and imperfect CSI.
Furthermore, we unveil that both proposed SCA-based algorithms can achieve a
close-to-optimal performance within a few iterations. Moreover, compared with
the state-of-the-art solution based on the alternating optimization (AO)
method, the proposed SCA-based scheme achieves a significant performance gain
with low complexity.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04064" title="Abstract">arXiv:2310.04064</a> [<a href="/pdf/2310.04064" title="Download PDF">pdf</a>, <a href="/ps/2310.04064" title="Download PostScript">ps</a>, <a href="/format/2310.04064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Capture Higher-order Correlations? Generalizing Matrix Softmax  Attention to Kronecker Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alman%2C+J">Josh Alman</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the classical transformer attention scheme, we are given three $n \times
d$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is
to compute a new $n \times d$ size matrix $D^{-1} \exp(QK^\top) V$ where $D =
\mathrm{diag}( \exp(QK^\top) {\bf 1}_n )$. In this work, we study a
generalization of attention which captures triple-wise correlations. This
generalization is able to solve problems about detecting triple-wise
connections that were shown to be impossible for transformers. The potential
downside of this generalization is that it appears as though computations are
even more difficult, since the straightforward algorithm requires cubic time in
$n$. However, we show that in the bounded-entry setting (which arises in
practice, and which is well-studied in both theory and practice), there is
actually a near-linear time algorithm. More precisely, we show that bounded
entries are both necessary and sufficient for quickly performing generalized
computations:
<br />$\bullet$ On the positive side, if all entries of the input matrices are
bounded above by $o(\sqrt[3]{\log n})$ then we show how to approximate the
``tensor-type'' attention matrix in $n^{1+o(1)}$ time.
<br />$\bullet$ On the negative side, we show that if the entries of the input
matrices may be as large as $\Omega(\sqrt[3]{\log n})$, then there is no
algorithm that runs faster than $n^{3-o(1)}$ (assuming the Strong Exponential
Time Hypothesis from fine-grained complexity theory).
<br />We also show that our construction, algorithms, and lower bounds naturally
generalize to higher-order tensors and correlations. Interestingly, the higher
the order of the tensors, the lower the bound on the entries needs to be for an
efficient algorithm. Our results thus yield a natural tradeoff between the
boundedness of the entries, and order of the tensor one may use for more
expressive, efficient attention computation.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04069" title="Abstract">arXiv:2310.04069</a> [<a href="/pdf/2310.04069" title="Download PDF">pdf</a>, <a href="/format/2310.04069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-temporal flow patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosyfaki%2C+C">Chrysanthi Kosyfaki</a>, 
<a href="/search/cs?searchtype=author&query=Mamoulis%2C+N">Nikos Mamoulis</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Reynold Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+B">Ben Kao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Transportation companies and organizations routinely collect huge volumes of
passenger transportation data. By aggregating these data (e.g., counting the
number of passengers going from a place to another in every 30 minute
interval), it becomes possible to analyze the movement behavior of passengers
in a metropolitan area. In this paper, we study the problem of finding
important trends in passenger movements at varying granularities, which is
useful in a wide range of applications such as target marketing, scheduling,
and travel intent prediction. Specifically, we study the extraction of movement
patterns between regions that have significant flow. The huge number of
possible patterns render their detection computationally hard. We propose
algorithms that greatly reduce the search space and the computational cost of
pattern detection. We study variants of patterns that could be useful to
different problem instances, such as constrained patterns and top-k ranked
patterns.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04072" title="Abstract">arXiv:2310.04072</a> [<a href="/pdf/2310.04072" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Regulation in Europe: From the AI Act to Future Regulatory Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hacker%2C+P">Philipp Hacker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final version forthcoming in: Ifeoma Ajunwa &amp; Jeremias Adams-Prassl (eds), Oxford Handbook of Algorithmic Governance and the Law, Oxford University Press, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This chapter provides a comprehensive discussion on AI regulation in the
European Union, contrasting it with the more sectoral and self-regulatory
approach in the UK. It argues for a hybrid regulatory strategy that combines
elements from both philosophies, emphasizing the need for agility and safe
harbors to ease compliance. The paper examines the AI Act as a pioneering
legislative effort to address the multifaceted challenges posed by AI,
asserting that, while the Act is a step in the right direction, it has
shortcomings that could hinder the advancement of AI technologies. The paper
also anticipates upcoming regulatory challenges, such as the management of
toxic content, environmental concerns, and hybrid threats. It advocates for
immediate action to create protocols for regulated access to high-performance,
potentially open-source AI systems. Although the AI Act is a significant
legislative milestone, it needs additional refinement and global collaboration
for the effective governance of rapidly evolving AI technologies.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04074" title="Abstract">arXiv:2310.04074</a> [<a href="/pdf/2310.04074" title="Download PDF">pdf</a>, <a href="/format/2310.04074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Aspect Extraction from Scientific Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marshalova%2C+A">Anna Marshalova</a>, 
<a href="/search/cs?searchtype=author&query=Bruches%2C+E">Elena Bruches</a>, 
<a href="/search/cs?searchtype=author&query=Batura%2C+T">Tatiana Batura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Being able to extract from scientific papers their main points, key insights,
and other important information, referred to here as aspects, might facilitate
the process of conducting a scientific literature review. Therefore, the aim of
our research is to create a tool for automatic aspect extraction from
Russian-language scientific texts of any domain. In this paper, we present a
cross-domain dataset of scientific texts in Russian, annotated with such
aspects as Task, Contribution, Method, and Conclusion, as well as a baseline
algorithm for aspect extraction, based on the multilingual BERT model
fine-tuned on our data. We show that there are some differences in aspect
representation in different domains, but even though our model was trained on a
limited number of scientific domains, it is still able to generalize to new
domains, as was proved by cross-domain experiments. The code and the dataset
are available at
\url{https://github.com/anna-marshalova/automatic-aspect-extraction-from-scientific-texts}.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04076" title="Abstract">arXiv:2310.04076</a> [<a href="/pdf/2310.04076" title="Download PDF">pdf</a>, <a href="/format/2310.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Clustering in High Dimensional Spaces: Sketches and  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen-Addad%2C+V">Vincent Cohen-Addad</a>, 
<a href="/search/cs?searchtype=author&query=Saulpic%2C+D">David Saulpic</a>, 
<a href="/search/cs?searchtype=author&query=Schwiegelshohn%2C+C">Chris Schwiegelshohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FOCS 2023. Abstract reduced for arxiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In all state-of-the-art sketching and coreset techniques for clustering, as
well as in the best known fixed-parameter tractable approximation algorithms,
randomness plays a key role. For the classic $k$-median and $k$-means problems,
there are no known deterministic dimensionality reduction procedure or coreset
construction that avoid an exponential dependency on the input dimension $d$,
the precision parameter $\varepsilon^{-1}$ or $k$. Furthermore, there is no
coreset construction that succeeds with probability $1-1/n$ and whose size does
not depend on the number of input points, $n$. This has led researchers in the
area to ask what is the power of randomness for clustering sketches [Feldman,
WIREs Data Mining Knowl. Discov'20]. Similarly, the best approximation ratio
achievable deterministically without a complexity exponential in the dimension
are $\Omega(1)$ for both $k$-median and $k$-means, even when allowing a
complexity FPT in the number of clusters $k$. This stands in sharp contrast
with the $(1+\varepsilon)$-approximation achievable in that case, when allowing
randomization.
<br />In this paper, we provide deterministic sketches constructions for
clustering, whose size bounds are close to the best-known randomized ones. We
also construct a deterministic algorithm for computing
$(1+\varepsilon)$-approximation to $k$-median and $k$-means in high dimensional
Euclidean spaces in time $2^{k^2/\varepsilon^{O(1)}} poly(nd)$, close to the
best randomized complexity.
<br />Furthermore, our new insights on sketches also yield a randomized coreset
construction that uses uniform sampling, that immediately improves over the
recent results of [Braverman et al. FOCS '22] by a factor $k$.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04078" title="Abstract">arXiv:2310.04078</a> [<a href="/pdf/2310.04078" title="Download PDF">pdf</a>, <a href="/format/2310.04078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Myopia: Learning from Positive and Unlabeled Data through  Holistic Predictive Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Wenhai Wan</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+C">Chuanxin Geng</a>, 
<a href="/search/cs?searchtype=author&query=LI%2C+S">Shaoyuan LI</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songcan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning binary classifiers from positive and unlabeled data (PUL) is vital
in many real-world applications, especially when verifying negative examples is
difficult. Despite the impressive empirical performance of recent PUL methods,
challenges like accumulated errors and increased estimation bias persist due to
the absence of negative labels. In this paper, we unveil an intriguing yet
long-overlooked observation in PUL: \textit{resampling the positive data in
each training iteration to ensure a balanced distribution between positive and
unlabeled examples results in strong early-stage performance. Furthermore,
predictive trends for positive and negative classes display distinctly
different patterns.} Specifically, the scores (output probability) of unlabeled
negative examples consistently decrease, while those of unlabeled positive
examples show largely chaotic trends. Instead of focusing on classification
within individual time frames, we innovatively adopt a holistic approach,
interpreting the scores of each example as a temporal point process (TPP). This
reformulates the core problem of PUL as recognizing trends in these scores. We
then propose a novel TPP-inspired measure for trend detection and prove its
asymptotic unbiasedness in predicting changes. Notably, our method accomplishes
PUL without requiring additional parameter tuning or prior assumptions,
offering an alternative perspective for tackling this problem. Extensive
experiments verify the superiority of our method, particularly in a highly
imbalanced real-world setting, where it achieves improvements of up to $11.3\%$
in key metrics. The code is available at
\href{https://github.com/wxr99/HolisticPU}{https://github.com/wxr99/HolisticPU}.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04080" title="Abstract">arXiv:2310.04080</a> [<a href="/pdf/2310.04080" title="Download PDF">pdf</a>, <a href="/format/2310.04080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Average Networks for Monte Carlo Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalojanov%2C+J">Javor Kalojanov</a>, 
<a href="/search/cs?searchtype=author&query=Thurston%2C+K">Kimball Thurston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We present a method for converting denoising neural networks from spatial
into spatio-temporal ones by modifying the network architecture and loss
function. We insert Robust Average blocks at arbitrary depths in the network
graph. Each block performs latent space interpolation with trainable weights
and works on the sequence of image representations from the preceding spatial
components of the network. The temporal connections are kept live during
training by forcing the network to predict a denoised frame from subsets of the
input sequence. Using temporal coherence for denoising improves image quality
and reduces temporal flickering independent of scene or image complexity.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04081" title="Abstract">arXiv:2310.04081</a> [<a href="/pdf/2310.04081" title="Download PDF">pdf</a>, <a href="/format/2310.04081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deeply Supervised Semantic Segmentation Method Based on GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Q">Qiyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zeng Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, ITSC conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">In recent years, the field of intelligent transportation has witnessed rapid
advancements, driven by the increasing demand for automation and efficiency in
transportation systems. Traffic safety, one of the tasks integral to
intelligent transport systems, requires accurately identifying and locating
various road elements, such as road cracks, lanes, and traffic signs. Semantic
segmentation plays a pivotal role in achieving this task, as it enables the
partition of images into meaningful regions with accurate boundaries. In this
study, we propose an improved semantic segmentation model that combines the
strengths of adversarial learning with state-of-the-art semantic segmentation
techniques. The proposed model integrates a generative adversarial network
(GAN) framework into the traditional semantic segmentation model, enhancing the
model's performance in capturing complex and subtle features in transportation
images. The effectiveness of our approach is demonstrated by a significant
boost in performance on the road crack dataset compared to the existing
methods, \textit{i.e.,} SEGAN. This improvement can be attributed to the
synergistic effect of adversarial learning and semantic segmentation, which
leads to a more refined and accurate representation of road structures and
conditions. The enhanced model not only contributes to better detection of road
cracks but also to a wide range of applications in intelligent transportation,
such as traffic sign recognition, vehicle detection, and lane segmentation.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04084" title="Abstract">arXiv:2310.04084</a> [<a href="/pdf/2310.04084" title="Download PDF">pdf</a>, <a href="/format/2310.04084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite element discretization of the steady, generalized Navier-Stokes  equations with inhomogeneous Dirichlet boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Je%C3%9Fberger%2C+J">Julius Je&#xdf;berger</a>, 
<a href="/search/math?searchtype=author&query=Kaltenbach%2C+A">Alex Kaltenbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 1 figure, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a finite element discretization for the steady, generalized
Navier-Stokes equations for fluids with shear-dependent viscosity, completed
with inhomogeneous Dirichlet boundary conditions and an inhomogeneous
divergence constraint. We establish (weak) convergence of discrete solutions as
well as a priori error estimates for the velocity vector field and the scalar
kinematic pressure. Numerical experiments complement the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04086" title="Abstract">arXiv:2310.04086</a> [<a href="/pdf/2310.04086" title="Download PDF">pdf</a>, <a href="/format/2310.04086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Chess Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masouris%2C+A">Athanasios Masouris</a>, 
<a href="/search/cs?searchtype=author&query=van+Gemert%2C+J">Jan van Gemert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Chess recognition refers to the task of identifying the chess pieces
configuration from a chessboard image. Contrary to the predominant approach
that aims to solve this task through the pipeline of chessboard detection,
square localization, and piece classification, we rely on the power of deep
learning models and introduce two novel methodologies to circumvent this
pipeline and directly predict the chessboard configuration from the entire
image. In doing so, we avoid the inherent error accumulation of the sequential
approaches and the need for intermediate annotations. Furthermore, we introduce
a new dataset, Chess Recognition Dataset (ChessReD), specifically designed for
chess recognition that consists of 10,800 images and their corresponding
annotations. In contrast to existing synthetic datasets with limited angles,
this dataset comprises a diverse collection of real images of chess formations
captured from various angles using smartphone cameras; a sensor choice made to
ensure real-world applicability. We use this dataset to both train our model
and evaluate and compare its performance to that of the current
state-of-the-art. Our approach in chess recognition on this new benchmark
dataset outperforms related approaches, achieving a board recognition accuracy
of 15.26% ($\approx$7x better than the current state-of-the-art).
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04090" title="Abstract">arXiv:2310.04090</a> [<a href="/pdf/2310.04090" title="Download PDF">pdf</a>, <a href="/ps/2310.04090" title="Download PostScript">ps</a>, <a href="/format/2310.04090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Proof Synthesis Algorithm for a Mathematical Vernacular in the  Calculus of Constructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We present an incomplete proof synthesis method for the Calculus of
Constructions which is always terminating and a complete Vernacular for the
Calculus of Constructions based on this method.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04094" title="Abstract">arXiv:2310.04094</a> [<a href="/pdf/2310.04094" title="Download PDF">pdf</a>, <a href="/format/2310.04094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching COVID-19 clinical research using graphical abstracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Invernici%2C+F">Francesco Invernici</a>, 
<a href="/search/cs?searchtype=author&query=Bernasconi%2C+A">Anna Bernasconi</a>, 
<a href="/search/cs?searchtype=author&query=Ceri%2C+S">Stefano Ceri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Objective. Graphical abstracts are small graphs of concepts that visually
summarize the main findings of scientific articles. While graphical abstracts
are customarily used in scientific publications to anticipate and summarize
their main results, we propose them as a means for expressing graph searches
over existing literature. Materials and methods. We consider the COVID-19 Open
Research Dataset (CORD-19), a corpus of more than one million abstracts; each
of them is described as a graph of co-occurring ontological terms, selected
from the Unified Medical Language System (UMLS) and the Ontology of Coronavirus
Infectious Disease (CIDO). Graphical abstracts are also expressed as graphs of
ontological terms, possibly augmented by utility terms describing their
interactions (e.g., "associated with", "increases", "induces"). We build a
co-occurrence network of concepts mentioned in the corpus; we then identify the
best matches of graphical abstracts on the network. We exploit graph database
technology and shortest-path queries. Results. We build a large co-occurrence
network, consisting of 128,249 entities and 47,198,965 relationships. A
well-designed interface allows users to explore the network by formulating or
adapting queries in the form of an abstract; it produces a bibliography of
publications, globally ranked; each publication is further associated with the
specific parts of the abstract that it explains, thereby allowing the user to
understand each aspect of the matching. Discussion and Conclusion. Our approach
supports the process of scientific hypothesis formulation and evidence search;
it can be reapplied to any scientific domain, although our mastering of UMLS
makes it most suited to clinical domains.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04097" title="Abstract">arXiv:2310.04097</a> [<a href="/pdf/2310.04097" title="Download PDF">pdf</a>, <a href="/format/2310.04097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Gender on the Evaluation of Security Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mbaka%2C+W">Winnie Mbaka</a>, 
<a href="/search/cs?searchtype=author&query=Tuma%2C+K">Katja Tuma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Security decisions are made by human analysts under uncertain conditions
which leaves room for bias judgement. However, little is known about how
demographics like gender and education impact these judgments. We conducted an
empirical study to investigate their influence on security decision
evaluations, addressing this knowledge gap.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04099" title="Abstract">arXiv:2310.04099</a> [<a href="/pdf/2310.04099" title="Download PDF">pdf</a>, <a href="/format/2310.04099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusVPR: Efficient Visual Place Recognition with Clustering-based  Weighted Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shamsolmoali%2C+P">Pourya Shamsolmoali</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual place recognition (VPR) is a highly challenging task that has a wide
range of applications, including robot navigation and self-driving vehicles.
VPR is particularly difficult due to the presence of duplicate regions and the
lack of attention to small objects in complex scenes, resulting in recognition
deviations. In this paper, we present ClusVPR, a novel approach that tackles
the specific issues of redundant information in duplicate regions and
representations of small objects. Different from existing methods that rely on
Convolutional Neural Networks (CNNs) for feature map generation, ClusVPR
introduces a unique paradigm called Clustering-based Weighted Transformer
Network (CWTNet). CWTNet leverages the power of clustering-based weighted
feature maps and integrates global dependencies to effectively address visual
deviations encountered in large-scale VPR problems. We also introduce the
optimized-VLAD (OptLAD) layer that significantly reduces the number of
parameters and enhances model efficiency. This layer is specifically designed
to aggregate the information obtained from scale-wise image patches.
Additionally, our pyramid self-supervised strategy focuses on extracting
representative and diverse information from scale-wise image patches instead of
entire images, which is crucial for capturing representative and diverse
information in VPR. Extensive experiments on four VPR datasets show our model's
superior performance compared to existing models while being less complex.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04100" title="Abstract">arXiv:2310.04100</a> [<a href="/pdf/2310.04100" title="Download PDF">pdf</a>, <a href="/format/2310.04100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressiveness Results for Timed Modal Mu-Calculi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cleaveland%2C+R">Rance Cleaveland</a>, 
<a href="/search/cs?searchtype=author&query=Keiren%2C+J+J+A">Jeroen J.A. Keiren</a>, 
<a href="/search/cs?searchtype=author&query=Fontana%2C+P">Peter Fontana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">This paper establishes relative expressiveness results for several modal
mu-calculi interpreted over timed automata. These mu-calculi combine modalities
for expressing passage of (real) time with a general framework for defining
formulas recursively; several variants have been proposed in the literature. We
show that one logic, which we call $L^{rel}_{\nu,\mu}$, is strictly more
expressive than the other mu-calculi considered. It is also more expressive
than the temporal logic TCTL, while the other mu-calculi are incomparable with
TCTL in the setting of general timed automata.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04102" title="Abstract">arXiv:2310.04102</a> [<a href="/pdf/2310.04102" title="Download PDF">pdf</a>, <a href="/ps/2310.04102" title="Download PostScript">ps</a>, <a href="/format/2310.04102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Welfare and Facility Location
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lam%2C+A">Alexander Lam</a>, 
<a href="/search/cs?searchtype=author&query=Aziz%2C+H">Haris Aziz</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+T">Toby Walsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We consider the problem of locating a facility to serve a set of agents
located along a line. The Nash welfare objective function, defined as the
product of the agents' utilities, is known to provide a compromise between
fairness and efficiency in resource allocation problems. We apply this welfare
notion to the facility location problem, converting individual costs to
utilities and analyzing the facility placement that maximizes the Nash welfare.
We give a polynomial-time approximation algorithm to compute this facility
location, and prove results suggesting that it achieves a good balance of
fairness and efficiency. Finally, we take a mechanism design perspective and
propose a strategy-proof mechanism with a bounded approximation ratio for Nash
welfare.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04104" title="Abstract">arXiv:2310.04104</a> [<a href="/pdf/2310.04104" title="Download PDF">pdf</a>, <a href="/format/2310.04104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marketing to Children Through Online Targeted Advertising: Targeting  Mechanisms and Legal Aspects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medjkoune%2C+T">Tinhinane Medjkoune</a>, 
<a href="/search/cs?searchtype=author&query=Goga%2C+O">Oana Goga</a>, 
<a href="/search/cs?searchtype=author&query=Senechal%2C+J">Juliette Senechal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Many researchers and organizations, such as WHO and UNICEF, have raised
awareness of the dangers of advertisements targeted at children. While most
existing laws only regulate ads on television that may reach children,
lawmakers have been working on extending regulations to online advertising and,
for example, forbid (e.g., the DSA) or restrict (e.g., the COPPA) advertising
based on profiling to children. At first sight, ad platforms such as Google
seem to protect children by not allowing advertisers to target their ads to
users who are less than 18 years old. However, this paper shows that other
targeting features can be exploited to reach children. For example, on YouTube,
advertisers can target their ads to users watching a particular video through
placement-based targeting, a form of contextual targeting. Hence, advertisers
can target children by placing their ads in children-focused videos. Through a
series of ad experiments, we show that placement-based targeting is possible on
children-focused videos and enables marketing to children. In addition, our ad
experiments show that advertisers can use targeting based on profiling (e.g.,
interest, location, behavior) in combination with placement-based advertising
on children-focused videos. We discuss the lawfulness of these two practices
concerning DSA and COPPA. Finally, we investigate to which extent real-world
advertisers are employing placement-based targeting to reach children with ads
on YouTube. We propose a measurement methodology consisting of building a
Chrome extension to capture ads and instrument six browser profiles to watch
children-focused videos. Our results show that 7% of ads that appear in the
children-focused videos we test use placement-based targeting. Hence, targeting
children with ads on YouTube is not only hypothetically possible but also
occurs in practice...
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04110" title="Abstract">arXiv:2310.04110</a> [<a href="/pdf/2310.04110" title="Download PDF">pdf</a>, <a href="/format/2310.04110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated 3D Segmentation of Kidneys and Tumors in MICCAI KiTS 2023  Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Myronenko%2C+A">Andriy Myronenko</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dong Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yufan He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Daguang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023, KITS 2023 challenge 1st place
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Kidney and Kidney Tumor Segmentation Challenge (KiTS) 2023 offers a platform
for researchers to compare their solutions to segmentation from 3D CT. In this
work, we describe our submission to the challenge using automated segmentation
of Auto3DSeg available in MONAI. Our solution achieves the average dice of
0.835 and surface dice of 0.723, which ranks first and wins the KiTS 2023
challenge.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04111" title="Abstract">arXiv:2310.04111</a> [<a href="/pdf/2310.04111" title="Download PDF">pdf</a>, <a href="/format/2310.04111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Random Texture Detection using Beta Distribution Statistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molander%2C+S">Soeren Molander</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This note describes a method for detecting dense random texture using fully
connected points sampled on image edges. An edge image is randomly sampled with
points, the standard L2 distance is calculated between all connected points in
a neighbourhood. For each point, a check is made if the point intersects with
an image edge. If this is the case, a unity value is added to the distance,
otherwise zero. From this an edge excess index is calculated for the fully
connected edge graph in the range [1.0..2.0], where 1.0 indicate no edges. The
ratio can be interpreted as a sampled Bernoulli process with unknown
probability. The Bayesian posterior estimate of the probability can be
associated with its conjugate prior which is a Beta($\alpha$, $\beta$)
distribution, with hyper parameters $\alpha$ and $\beta$ related to the number
of edge crossings. Low values of $\beta$ indicate a texture rich area, higher
values less rich. The method has been applied to real-time SLAM-based moving
object detection, where points are confined to tracked boxes (rois).
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04113" title="Abstract">arXiv:2310.04113</a> [<a href="/pdf/2310.04113" title="Download PDF">pdf</a>, <a href="/format/2310.04113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doppler-only Single-scan 3D Vehicle Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galeote-Luque%2C+A">Andres Galeote-Luque</a>, 
<a href="/search/cs?searchtype=author&query=Kubelka%2C+V">Vladim&#xed;r Kubelka</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+M">Martin Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz-Sarmiento%2C+J">Jose-Raul Ruiz-Sarmiento</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Jimenez%2C+J">Javier Gonzalez-Jimenez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a novel 3D odometry method that recovers the full motion of a
vehicle only from a Doppler-capable range sensor. It leverages the radial
velocities measured from the scene, estimating the sensor's velocity from a
single scan. The vehicle's 3D motion, defined by its linear and angular
velocities, is calculated taking into consideration its kinematic model which
provides a constraint between the velocity measured at the sensor frame and the
vehicle frame.
<br />Experiments carried out prove the viability of our single-sensor method
compared to mounting an additional IMU. Our method provides the translation of
the sensor, which cannot be reliably determined from an IMU, as well as its
rotation. Its short-term accuracy and fast operation (~5ms) make it a proper
candidate to supply the initialization to more complex localization algorithms
or mapping pipelines. Not only does it reduce the error of the mapper, but it
does so at a comparable level of accuracy as an IMU would. All without the need
to mount and calibrate an extra sensor on the vehicle.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04117" title="Abstract">arXiv:2310.04117</a> [<a href="/pdf/2310.04117" title="Download PDF">pdf</a>, <a href="/format/2310.04117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Performance with Minimal Resources for Real-Time Transition  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orhan%2C+Z+O">Zeynep Ozge Orhan</a>, 
<a href="/search/cs?searchtype=author&query=Prete%2C+A+D">Andrea Dal Prete</a>, 
<a href="/search/cs?searchtype=author&query=Bolotnikova%2C+A">Anastasia Bolotnikova</a>, 
<a href="/search/cs?searchtype=author&query=Gandolla%2C+M">Marta Gandolla</a>, 
<a href="/search/cs?searchtype=author&query=Ijspeert%2C+A">Auke Ijspeert</a>, 
<a href="/search/cs?searchtype=author&query=Bouri%2C+M">Mohamed Bouri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for a conference. 7 pages including references, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Assistive devices, such as exoskeletons and prostheses, have revolutionized
the field of rehabilitation and mobility assistance. Efficiently detecting
transitions between different activities, such as walking, stair ascending and
descending, and sitting, is crucial for ensuring adaptive control and enhancing
user experience. We here present an approach for real-time transition
detection, aimed at optimizing the processing-time performance. By establishing
activity-specific threshold values through trained machine learning models, we
effectively distinguish motion patterns and we identify transition moments
between locomotion modes. This threshold-based method improves real-time
embedded processing time performance by up to 11 times compared to machine
learning approaches. The efficacy of the developed finite-state machine is
validated using data collected from three different measurement systems.
Moreover, experiments with healthy participants were conducted on an active
pelvis orthosis to validate the robustness and reliability of our approach. The
proposed algorithm achieved high accuracy in detecting transitions between
activities. These promising results show the robustness and reliability of the
method, reinforcing its potential for integration into practical applications.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04118" title="Abstract">arXiv:2310.04118</a> [<a href="/pdf/2310.04118" title="Download PDF">pdf</a>, <a href="/format/2310.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration and updates for conjunctive linear algebra queries through  expressibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+T">Thomas Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Riveros%2C+C">Cristian Riveros</a>, 
<a href="/search/cs?searchtype=author&query=Vansummeren%2C+S">Stijn Vansummeren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 79 pages total: 15 main body, 3 of references and 61 of appendix which contains detailed proofs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Databases (cs.DB); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Due to the importance of linear algebra and matrix operations in data
analytics, there is significant interest in using relational query optimization
and processing techniques for evaluating (sparse) linear algebra programs. In
particular, in recent years close connections have been established between
linear algebra programs and relational algebra that allow transferring
optimization techniques of the latter to the former. In this paper, we ask
ourselves which linear algebra programs in MATLANG correspond to the
free-connex and q-hierarchical fragments of conjunctive first-order logic. Both
fragments have desirable query processing properties: free-connex conjunctive
queries support constant-delay enumeration after a linear-time preprocessing
phase, and q-hierarchical conjunctive queries further allow constant-time
updates. By characterizing the corresponding fragments of MATLANG, we hence
identify the fragments of linear algebra programs that one can evaluate with
constant-delay enumeration after linear-time preprocessing and with
constant-time updates. To derive our results, we improve and generalize
previous correspondences between MATLANG and relational algebra evaluated over
semiring-annotated relations. In addition, we identify properties on semirings
that allow to generalize the complexity bounds for free-connex and
q-hierarchical conjunctive queries from Boolean annotations to general
semirings.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04122" title="Abstract">arXiv:2310.04122</a> [<a href="/pdf/2310.04122" title="Download PDF">pdf</a>, <a href="/format/2310.04122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VI-Diff: Unpaired Visible-Infrared Translation Diffusion Model for  Single Modality Labeled Visible-Infrared Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visible-Infrared person re-identification (VI-ReID) in real-world scenarios
poses a significant challenge due to the high cost of cross-modality data
annotation. Different sensing cameras, such as RGB/IR cameras for good/poor
lighting conditions, make it costly and error-prone to identify the same person
across modalities. To overcome this, we explore the use of single-modality
labeled data for the VI-ReID task, which is more cost-effective and practical.
By labeling pedestrians in only one modality (e.g., visible images) and
retrieving in another modality (e.g., infrared images), we aim to create a
training set containing both originally labeled and modality-translated data
using unpaired image-to-image translation techniques. In this paper, we propose
VI-Diff, a diffusion model that effectively addresses the task of
Visible-Infrared person image translation. Through comprehensive experiments,
we demonstrate that VI-Diff outperforms existing diffusion and GAN models,
making it a promising solution for VI-ReID with single-modality labeled data.
Our approach can be a promising solution to the VI-ReID task with
single-modality labeled data and serves as a good starting point for future
study. Code will be available.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04126" title="Abstract">arXiv:2310.04126</a> [<a href="/pdf/2310.04126" title="Download PDF">pdf</a>, <a href="/ps/2310.04126" title="Download PostScript">ps</a>, <a href="/format/2310.04126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-discrete unscented Kalman filtering framework by MATLAB ODE  solvers and square-root methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kulikova%2C+M">Maria Kulikova</a>, 
<a href="/search/math?searchtype=author&query=Kulikov%2C+G">Gennady Kulikov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica, 142: Paper ID 110396, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses the problem of designing the {\it continuous-discrete}
unscented Kalman filter (UKF) implementation methods. More precisely, the aim
is to propose the MATLAB-based UKF algorithms for {\it accurate} and {\it
robust} state estimation of stochastic dynamic systems. The accuracy of the
{\it continuous-discrete} nonlinear filters heavily depends on how the
implementation method manages the discretization error arisen at the filter
prediction step. We suggest the elegant and accurate implementation framework
for tracking the hidden states by utilizing the MATLAB built-in numerical
integration schemes developed for solving ordinary differential equations
(ODEs). The accuracy is boosted by the discretization error control involved in
all MATLAB ODE solvers. This keeps the discretization error below the tolerance
value provided by users, automatically. Meanwhile, the robustness of the UKF
filtering methods is examined in terms of the stability to roundoff. In
contrast to the pseudo-square-root UKF implementations established in
engineering literature, which are based on the one-rank Cholesky updates, we
derive the stable square-root methods by utilizing the $J$-orthogonal
transformations for calculating the Cholesky square-root factors.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04127" title="Abstract">arXiv:2310.04127</a> [<a href="/pdf/2310.04127" title="Download PDF">pdf</a>, <a href="/format/2310.04127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A complex-scaled boundary integral equation for time-harmonic water  waves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dhia%2C+A+B">Anne-Sophie Bonnet-Ben Dhia</a>, 
<a href="/search/math?searchtype=author&query=Faria%2C+L+M">Luiz M. Faria</a>, 
<a href="/search/math?searchtype=author&query=P%C3%A9rez-Arancibia%2C+C">Carlos P&#xe9;rez-Arancibia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">This paper presents a novel boundary integral equation (BIE) formulation for
the two-dimensional time-harmonic water-waves problem. It utilizes a
complex-scaled Laplace's free-space Green's function, resulting in a BIE posed
on the infinite boundaries of the domain. The perfectly matched layer (PML)
coordinate stretching that is used to render propagating waves exponentially
decaying, allows for the effective truncation and discretization of the BIE
unbounded domain. We show through a variety of numerical examples that, despite
the logarithmic growth of the complex-scaled Laplace's free-space Green's
function, the truncation errors are exponentially small with respect to the
truncation length. Our formulation uses only simple function evaluations (e.g.
complex logarithms and square roots), hence avoiding the need to compute the
involved water-wave Green's function. Finally, we show that the proposed
approach can also be used to find complex resonances through a \emph{linear}
eigenvalue problem since the Green's function is frequency-independent.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04128" title="Abstract">arXiv:2310.04128</a> [<a href="/pdf/2310.04128" title="Download PDF">pdf</a>, <a href="/format/2310.04128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning with Fast and Forgetful Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morad%2C+S">Steven Morad</a>, 
<a href="/search/cs?searchtype=author&query=Kortvelesy%2C+R">Ryan Kortvelesy</a>, 
<a href="/search/cs?searchtype=author&query=Liwicki%2C+S">Stephan Liwicki</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Nearly all real world tasks are inherently partially observable,
necessitating the use of memory in Reinforcement Learning (RL). Most model-free
approaches summarize the trajectory into a latent Markov state using memory
models borrowed from Supervised Learning (SL), even though RL tends to exhibit
different training and efficiency characteristics. Addressing this discrepancy,
we introduce Fast and Forgetful Memory, an algorithm-agnostic memory model
designed specifically for RL. Our approach constrains the model search space
via strong structural priors inspired by computational psychology. It is a
drop-in replacement for recurrent neural networks (RNNs) in recurrent RL
algorithms, achieving greater reward than RNNs across various recurrent
benchmarks and algorithms without changing any hyperparameters. Moreover, Fast
and Forgetful Memory exhibits training speeds two orders of magnitude faster
than RNNs, attributed to its logarithmic time and linear space complexity. Our
implementation is available at https://github.com/proroklab/ffm.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04130" title="Abstract">arXiv:2310.04130</a> [<a href="/pdf/2310.04130" title="Download PDF">pdf</a>, <a href="/ps/2310.04130" title="Download PostScript">ps</a>, <a href="/format/2310.04130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Errata to: &quot;Faster Deterministic Exponential Time Algorithm for Energy  Games and Mean Payoff Games&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Austin%2C+P">Peter Austin</a>, 
<a href="/search/cs?searchtype=author&query=Dell%27Erba%2C+D">Daniele Dell&#x27;Erba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">An improved exponential time algorithm for Energy Games and Mean Payoff Games
has been recently proposed in ICALP 19. The new algorithm prevents some of the
repetitive operations performed by the classic value iteration algorithm of
Brim et al., leading to an approach with time complexity
$O(\min(mnW,mn2^{n/2}\log W))$. Unfortunately, the pseudo-code of the algorithm
includes inaccuracies that violate two Lemmata used in the correctness and
complexity proofs. In this technical report, we describe the problems, propose
a fixed version of the algorithm, and correct the proofs for the Lemmata.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04132" title="Abstract">arXiv:2310.04132</a> [<a href="/pdf/2310.04132" title="Download PDF">pdf</a>, <a href="/format/2310.04132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minors solve the elliptic curve discrete logarithm problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A">Ansari Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Mahalanobis%2C+A">Ayan Mahalanobis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Algebraic Geometry (math.AG)

</div>
<p class="mathjax">The elliptic curve discrete logarithm problem is of fundamental importance in
public-key cryptography. It is in use for a long time. Moreover, it is an
interesting challenge in computational mathematics. Its solution is supposed to
provide interesting research directions.
<br />In this paper, we explore ways to solve the elliptic curve discrete logarithm
problem. Our results are mostly computational. However, it seems, the methods
that we develop and directions that we pursue can provide a potent attack on
this problem. This work follows our earlier work, where we tried to solve this
problem by finding a zero minor in a matrix over the same finite field on which
the elliptic curve is defined. This paper is self-contained.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04134" title="Abstract">arXiv:2310.04134</a> [<a href="/pdf/2310.04134" title="Download PDF">pdf</a>, <a href="/format/2310.04134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiC: Exploring Vision Transformer in Convolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingzhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While models derived from Vision Transformers (ViTs) have been phonemically
surging, pre-trained models cannot seamlessly adapt to arbitrary resolution
images without altering the architecture and configuration, such as sampling
the positional encoding, limiting their flexibility for various vision tasks.
For instance, the Segment Anything Model (SAM) based on ViT-Huge requires all
input images to be resized to 1024$\times$1024. To overcome this limitation, we
propose the Multi-Head Self-Attention Convolution (MSA-Conv) that incorporates
Self-Attention within generalized convolutions, including standard, dilated,
and depthwise ones. Enabling transformers to handle images of varying sizes
without retraining or rescaling, the use of MSA-Conv further reduces
computational costs compared to global attention in ViT, which grows costly as
image size increases. Later, we present the Vision Transformer in Convolution
(TiC) as a proof of concept for image classification with MSA-Conv, where two
capacity enhancing strategies, namely Multi-Directional Cyclic Shifted
Mechanism and Inter-Pooling Mechanism, have been proposed, through establishing
long-distance connections between tokens and enlarging the effective receptive
field. Extensive experiments have been carried out to validate the overall
effectiveness of TiC. Additionally, ablation studies confirm the performance
improvement made by MSA-Conv and the two capacity enhancing strategies
separately. Note that our proposal aims at studying an alternative to the
global attention used in ViT, while MSA-Conv meets our goal by making TiC
comparable to state-of-the-art on ImageNet-1K. Code will be released at
https://github.com/zs670980918/MSA-Conv.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04140" title="Abstract">arXiv:2310.04140</a> [<a href="/pdf/2310.04140" title="Download PDF">pdf</a>, <a href="/format/2310.04140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Routing Arena: A Benchmark Suite for Neural Routing Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thyssens%2C+D">Daniela Thyssens</a>, 
<a href="/search/cs?searchtype=author&query=Dernedde%2C+T">Tim Dernedde</a>, 
<a href="/search/cs?searchtype=author&query=Falkner%2C+J+K">Jonas K. Falkner</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Thieme%2C+L">Lars Schmidt-Thieme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Neural Combinatorial Optimization has been researched actively in the last
eight years. Even though many of the proposed Machine Learning based approaches
are compared on the same datasets, the evaluation protocol exhibits essential
flaws and the selection of baselines often neglects State-of-the-Art Operations
Research approaches. To improve on both of these shortcomings, we propose the
Routing Arena, a benchmark suite for Routing Problems that provides a seamless
integration of consistent evaluation and the provision of baselines and
benchmarks prevalent in the Machine Learning- and Operations Research field.
The proposed evaluation protocol considers the two most important evaluation
cases for different applications: First, the solution quality for an a priori
fixed time budget and secondly the anytime performance of the respective
methods. By setting the solution trajectory in perspective to a Best Known
Solution and a Base Solver's solutions trajectory, we furthermore propose the
Weighted Relative Average Performance (WRAP), a novel evaluation metric that
quantifies the often claimed runtime efficiency of Neural Routing Solvers. A
comprehensive first experimental evaluation demonstrates that the most recent
Operations Research solvers generate state-of-the-art results in terms of
solution quality and runtime efficiency when it comes to the vehicle routing
problem. Nevertheless, some findings highlight the advantages of neural
approaches and motivate a shift in how neural solvers should be conceptualized.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04145" title="Abstract">arXiv:2310.04145</a> [<a href="/pdf/2310.04145" title="Download PDF">pdf</a>, <a href="/format/2310.04145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Zero to Hero: Detecting Leaked Data through Synthetic Data  Injection and Model Querying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+A+K+H">Anthony K. H. Tung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Safeguarding the Intellectual Property (IP) of data has become critically
important as machine learning applications continue to proliferate, and their
success heavily relies on the quality of training data. While various
mechanisms exist to secure data during storage, transmission, and consumption,
fewer studies have been developed to detect whether they are already leaked for
model training without authorization. This issue is particularly challenging
due to the absence of information and control over the training process
conducted by potential attackers.
<br />In this paper, we concentrate on the domain of tabular data and introduce a
novel methodology, Local Distribution Shifting Synthesis (\textsc{LDSS}), to
detect leaked data that are used to train classification models. The core
concept behind \textsc{LDSS} involves injecting a small volume of synthetic
data--characterized by local shifts in class distribution--into the owner's
dataset. This enables the effective identification of models trained on leaked
data through model querying alone, as the synthetic data injection results in a
pronounced disparity in the predictions of models trained on leaked and
modified datasets. \textsc{LDSS} is \emph{model-oblivious} and hence compatible
with a diverse range of classification models, such as Naive Bayes, Decision
Tree, and Random Forest. We have conducted extensive experiments on seven types
of classification models across five real-world datasets. The comprehensive
results affirm the reliability, robustness, fidelity, security, and efficiency
of \textsc{LDSS}.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04148" title="Abstract">arXiv:2310.04148</a> [<a href="/pdf/2310.04148" title="Download PDF">pdf</a>, <a href="/format/2310.04148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Neuron Segmentation with Multi-Agent Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shenglong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI 23 main track paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The performance of existing supervised neuron segmentation methods is highly
dependent on the number of accurate annotations, especially when applied to
large scale electron microscopy (EM) data. By extracting semantic information
from unlabeled data, self-supervised methods can improve the performance of
downstream tasks, among which the mask image model (MIM) has been widely used
due to its simplicity and effectiveness in recovering original information from
masked images. However, due to the high degree of structural locality in EM
images, as well as the existence of considerable noise, many voxels contain
little discriminative information, making MIM pretraining inefficient on the
neuron segmentation task. To overcome this challenge, we propose a
decision-based MIM that utilizes reinforcement learning (RL) to automatically
search for optimal image masking ratio and masking strategy. Due to the vast
exploration space, using single-agent RL for voxel prediction is impractical.
Therefore, we treat each input patch as an agent with a shared behavior policy,
allowing for multi-agent collaboration. Furthermore, this multi-agent model can
capture dependencies between voxels, which is beneficial for the downstream
segmentation task. Experiments conducted on representative EM datasets
demonstrate that our approach has a significant advantage over alternative
self-supervised methods on the task of neuron segmentation. Code is available
at \url{https://github.com/ydchen0806/dbMiM}.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04152" title="Abstract">arXiv:2310.04152</a> [<a href="/pdf/2310.04152" title="Download PDF">pdf</a>, <a href="/format/2310.04152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Neural Radiance Field using Near-Surface Sampling with Point  Cloud Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+H+B">Hye Bin Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H+M">Hyun Min Han</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+S">Sung Soo Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+I+Y">Il Yong Chun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance field (NeRF) is an emerging view synthesis method that
samples points in a three-dimensional (3D) space and estimates their existence
and color probabilities. The disadvantage of NeRF is that it requires a long
training time since it samples many 3D points. In addition, if one samples
points from occluded regions or in the space where an object is unlikely to
exist, the rendering quality of NeRF can be degraded. These issues can be
solved by estimating the geometry of 3D scene. This paper proposes a
near-surface sampling framework to improve the rendering quality of NeRF. To
this end, the proposed method estimates the surface of a 3D object using depth
images of the training set and sampling is performed around there only. To
obtain depth information on a novel view, the paper proposes a 3D point cloud
generation method and a simple refining method for projected depth from a point
cloud. Experimental results show that the proposed near-surface sampling NeRF
framework can significantly improve the rendering quality, compared to the
original NeRF and a state-of-the-art depth-based NeRF method. In addition, one
can significantly accelerate the training time of a NeRF model with the
proposed near-surface sampling framework.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04155" title="Abstract">arXiv:2310.04155</a> [<a href="/pdf/2310.04155" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Preservation Metadata Standard for Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+U">Udaya Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Bharti%2C+S">Sneha Bharti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">We have so many languages to communicate with others as humans. There are
approximately 7000 languages in the world, and many are becoming extinct for a
variety of reasons. In order to preserve and prevent the extinction of these
languages, we need to preserve them. One way of preservation is to have a
preservation metadata for languages. Metadata is data about data. Metadata is
required for item description, preservation, and retrieval. There are various
types of metadata, e.g., descriptive, administrative, structural, preservation,
etc. After the literature study, the authors observed that there is a lack of
study on the preservation metadata for language. Consequently, the purpose of
this paper is to demonstrate the need for language preservation metadata. We
found some archaeological metadata standards for this purpose, and after
applying inclusion and exclusion criteria, we chose three archaeological
metadata standards, namely: Archaeon-core, CARARE, and LIDO (Lightweight
Information Describing Objects) for mapping metadata.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04158" title="Abstract">arXiv:2310.04158</a> [<a href="/pdf/2310.04158" title="Download PDF">pdf</a>, <a href="/format/2310.04158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Victima: Drastically Increasing Address Translation Reach by Leveraging  Underutilized Cache Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+K">Konstantinos Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+H+C">Hong Chul Nam</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+F+N">F. Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+R">Rahul Bera</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rakesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bartolini%2C+D">Davide-Basilio Bartolini</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 56th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">Address translation is a performance bottleneck in data-intensive workloads
due to large datasets and irregular access patterns that lead to frequent
high-latency page table walks (PTWs). PTWs can be reduced by using (i) large
hardware TLBs or (ii) large software-managed TLBs. Unfortunately, both
solutions have significant drawbacks: increased access latency, power and area
(for hardware TLBs), and costly memory accesses, the need for large contiguous
memory blocks, and complex OS modifications (for software-managed TLBs). We
present Victima, a new software-transparent mechanism that drastically
increases the translation reach of the processor by leveraging the
underutilized resources of the cache hierarchy. The key idea of Victima is to
repurpose L2 cache blocks to store clusters of TLB entries, thereby providing
an additional low-latency and high-capacity component that backs up the
last-level TLB and thus reduces PTWs. Victima has two main components. First, a
PTW cost predictor (PTW-CP) identifies costly-to-translate addresses based on
the frequency and cost of the PTWs they lead to. Second, a TLB-aware cache
replacement policy prioritizes keeping TLB entries in the cache hierarchy by
considering (i) the translation pressure (e.g., last-level TLB miss rate) and
(ii) the reuse characteristics of the TLB entries. Our evaluation results show
that in native (virtualized) execution environments Victima improves average
end-to-end application performance by 7.4% (28.7%) over the baseline four-level
radix-tree-based page table design and by 6.2% (20.1%) over a state-of-the-art
software-managed TLB, across 11 diverse data-intensive workloads. Victima (i)
is effective in both native and virtualized environments, (ii) is completely
transparent to application and system software, and (iii) incurs very small
area and power overheads on a modern high-end CPU.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04159" title="Abstract">arXiv:2310.04159</a> [<a href="/pdf/2310.04159" title="Download PDF">pdf</a>, <a href="/format/2310.04159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amortized Network Intervention to Steer the Excitatory Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wendi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We tackle the challenge of large-scale network intervention for guiding
excitatory point processes, such as infectious disease spread or traffic
congestion control. Our model-based reinforcement learning utilizes neural ODEs
to capture how the networked excitatory point processes will evolve subject to
the time-varying changes in network topology. Our approach incorporates
Gradient-Descent based Model Predictive Control (GD-MPC), offering policy
flexibility to accommodate prior knowledge and constraints. To address the
intricacies of planning and overcome the high dimensionality inherent to such
decision-making problems, we design an Amortize Network Interventions (ANI)
framework, allowing for the pooling of optimal policies from history and other
contexts, while ensuring a permutation equivalent property. This property
enables efficient knowledge transfer and sharing across diverse contexts. Our
approach has broad applications, from curbing infectious disease spread to
reducing carbon emissions through traffic light optimization, and thus has the
potential to address critical societal and environmental challenges.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04162" title="Abstract">arXiv:2310.04162</a> [<a href="/pdf/2310.04162" title="Download PDF">pdf</a>, <a href="/format/2310.04162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Light-LOAM: A Lightweight LiDAR Odometry and Mapping based on  Graph-Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Shiquan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+L">Lin Hua</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chunhui Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Simultaneous Localization and Mapping (SLAM) plays an important role in robot
autonomy. Reliability and efficiency are the two most valued features for
applying SLAM in robot applications. In this paper, we consider achieving a
reliable LiDAR-based SLAM function in computation-limited platforms, such as
quadrotor UAVs based on graph-based point cloud association. First, contrary to
most works selecting salient features for point cloud registration, we propose
a non-conspicuous feature selection strategy for reliability and robustness
purposes. Then a two-stage correspondence selection method is used to register
the point cloud, which includes a KD-tree-based coarse matching followed by a
graph-based matching method that uses geometric consistency to vote out
incorrect correspondences. Additionally, we propose an odometry approach where
the weight optimizations are guided by vote results from the aforementioned
geometric consistency graph. In this way, the optimization of LiDAR odometry
rapidly converges and evaluates a fairly accurate transformation resulting in
the back-end module efficiently finishing the mapping task. Finally, we
evaluate our proposed framework on the KITTI odometry dataset and real-world
environments. Experiments show that our SLAM system achieves a comparative
level or higher level of accuracy with more balanced computation efficiency
compared with the mainstream LiDAR-based SLAM solutions.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04171" title="Abstract">arXiv:2310.04171</a> [<a href="/pdf/2310.04171" title="Download PDF">pdf</a>, <a href="/format/2310.04171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heehyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinhyeok Choi</a>, 
<a href="/search/cs?searchtype=author&query=Whang%2C+J+J">Joyce Jiyoung Whang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 3 tables. 23rd IEEE International Conference on Data Mining Workshops (ICDMW)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Fraud detection aims to discover fraudsters deceiving other users by, for
example, leaving fake reviews or making abnormal transactions. Graph-based
fraud detection methods consider this task as a classification problem with two
classes: frauds or normal. We address this problem using Graph Neural Networks
(GNNs) by proposing a dynamic relation-attentive aggregation mechanism. Based
on the observation that many real-world graphs include different types of
relations, we propose to learn a node representation per relation and aggregate
the node representations using a learnable attention function that assigns a
different attention coefficient to each relation. Furthermore, we combine the
node representations from different layers to consider both the local and
global structures of a target node, which is beneficial to improving the
performance of fraud detection on graphs with heterophily. By employing dynamic
graph attention in all the aggregation processes, our method adaptively
computes the attention coefficients for each node. Experimental results show
that our method, DRAG, outperforms state-of-the-art fraud detection methods on
real-world benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04172" title="Abstract">arXiv:2310.04172</a> [<a href="/pdf/2310.04172" title="Download PDF">pdf</a>, <a href="/format/2310.04172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards 6D MCL for LiDARs in 3D TSDF Maps on Embedded Systems with GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eisoldt%2C+M">Marc Eisoldt</a>, 
<a href="/search/cs?searchtype=author&query=Mock%2C+A">Alexander Mock</a>, 
<a href="/search/cs?searchtype=author&query=Porrmann%2C+M">Mario Porrmann</a>, 
<a href="/search/cs?searchtype=author&query=Wiemann%2C+T">Thomas Wiemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Monte Carlo Localization is a widely used approach in the field of mobile
robotics. While this problem has been well studied in the 2D case, global
localization in 3D maps with six degrees of freedom has so far been too
computationally demanding. Hence, no mobile robot system has yet been presented
in literature that is able to solve it in real-time. The computationally most
intensive step is the evaluation of the sensor model, but it also offers high
parallelization potential. This work investigates the massive parallelization
of the evaluation of particles in truncated signed distance fields for
three-dimensional laser scanners on embedded GPUs. The implementation on the
GPU is 30 times as fast and more than 50 times more energy efficient compared
to a CPU implementation.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04178" title="Abstract">arXiv:2310.04178</a> [<a href="/pdf/2310.04178" title="Download PDF">pdf</a>, <a href="/format/2310.04178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing the Attribution Stability Indicator: a Measure for Time  Series XAI Attributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlegel%2C+U">Udo Schlegel</a>, 
<a href="/search/cs?searchtype=author&query=Keim%2C+D+A">Daniel A. Keim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, ECML-PKDD Workshop XAI-TS: Explainable AI for Time Series: Advances and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given the increasing amount and general complexity of time series data in
domains such as finance, weather forecasting, and healthcare, there is a
growing need for state-of-the-art performance models that can provide
interpretable insights into underlying patterns and relationships. Attribution
techniques enable the extraction of explanations from time series models to
gain insights but are hard to evaluate for their robustness and
trustworthiness. We propose the Attribution Stability Indicator (ASI), a
measure to incorporate robustness and trustworthiness as properties of
attribution techniques for time series into account. We extend a perturbation
analysis with correlations of the original time series to the perturbed
instance and the attributions to include wanted properties in the measure. We
demonstrate the wanted properties based on an analysis of the attributions in a
dimension-reduced space and the ASI scores distribution over three whole time
series classification datasets.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04179" title="Abstract">arXiv:2310.04179</a> [<a href="/pdf/2310.04179" title="Download PDF">pdf</a>, <a href="/format/2310.04179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropic Score metric: Decoupling Topology and Size in Training-free NAS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cavagnero%2C+N">Niccol&#xf2; Cavagnero</a>, 
<a href="/search/cs?searchtype=author&query=Robbiano%2C+L">Luca Robbiano</a>, 
<a href="/search/cs?searchtype=author&query=Pistilli%2C+F">Francesca Pistilli</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>, 
<a href="/search/cs?searchtype=author&query=Averta%2C+G">Giuseppe Averta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural Networks design is a complex and often daunting task, particularly for
resource-constrained scenarios typical of mobile-sized models. Neural
Architecture Search is a promising approach to automate this process, but
existing competitive methods require large training time and computational
resources to generate accurate models. To overcome these limits, this paper
contributes with: i) a novel training-free metric, named Entropic Score, to
estimate model expressivity through the aggregated element-wise entropy of its
activations; ii) a cyclic search algorithm to separately yet synergistically
search model size and topology. Entropic Score shows remarkable ability in
searching for the topology of the network, and a proper combination with
LogSynflow, to search for model size, yields superior capability to completely
design high-performance Hybrid Transformers for edge applications in less than
1 GPU hour, resulting in the fastest and most accurate NAS method for ImageNet
classification.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04180" title="Abstract">arXiv:2310.04180</a> [<a href="/pdf/2310.04180" title="Download PDF">pdf</a>, <a href="/format/2310.04180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degradation-Aware Self-Attention Based Transformer for Blind Image  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingguo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kang Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ningzhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wei Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Compared to CNN-based methods, Transformer-based methods achieve impressive
image restoration outcomes due to their abilities to model remote dependencies.
However, how to apply Transformer-based methods to the field of blind
super-resolution (SR) and further make an SR network adaptive to degradation
information is still an open problem. In this paper, we propose a new
degradation-aware self-attention-based Transformer model, where we incorporate
contrastive learning into the Transformer network for learning the degradation
representations of input images with unknown noise. In particular, we integrate
both CNN and Transformer components into the SR network, where we first use the
CNN modulated by the degradation information to extract local features, and
then employ the degradation-aware Transformer to extract global semantic
features. We apply our proposed model to several popular large-scale benchmark
datasets for testing, and achieve the state-of-the-art performance compared to
existing methods. In particular, our method yields a PSNR of 32.43 dB on the
Urban100 dataset at $\times$2 scale, 0.94 dB higher than DASR, and 26.62 dB on
the Urban100 dataset at $\times$4 scale, 0.26 dB improvement over KDSR, setting
a new benchmark in this area. Source code is available at:
https://github.com/I2-Multimedia-Lab/DSAT/tree/main.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04181" title="Abstract">arXiv:2310.04181</a> [<a href="/pdf/2310.04181" title="Download PDF">pdf</a>, <a href="/format/2310.04181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffPrompter: Differentiable Implicit Visual Prompts for  Semantic-Segmentation in Adverse Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalwar%2C+S">Sanket Kalwar</a>, 
<a href="/search/cs?searchtype=author&query=Ungarala%2C+M">Mihir Ungarala</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shruti Jain</a>, 
<a href="/search/cs?searchtype=author&query=Monis%2C+A">Aaron Monis</a>, 
<a href="/search/cs?searchtype=author&query=Konda%2C+K+R">Krishna Reddy Konda</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Sourav Garg</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+K+M">K Madhava Krishna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Semantic segmentation in adverse weather scenarios is a critical task for
autonomous driving systems. While foundation models have shown promise, the
need for specialized adaptors becomes evident for handling more challenging
scenarios. We introduce DiffPrompter, a novel differentiable visual and latent
prompting mechanism aimed at expanding the learning capabilities of existing
adaptors in foundation models. Our proposed $\nabla$HFC image processing block
excels particularly in adverse weather conditions, where conventional methods
often fall short. Furthermore, we investigate the advantages of jointly
training visual and latent prompts, demonstrating that this combined approach
significantly enhances performance in out-of-distribution scenarios. Our
differentiable visual prompts leverage parallel and series architectures to
generate prompts, effectively improving object segmentation tasks in adverse
conditions. Through a comprehensive series of experiments and evaluations, we
provide empirical evidence to support the efficacy of our approach. Project
page at https://diffprompter.github.io.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04182" title="Abstract">arXiv:2310.04182</a> [<a href="/pdf/2310.04182" title="Download PDF">pdf</a>, <a href="/format/2310.04182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit-explicit schemes for incompressible flow problems with variable  viscosity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barrenechea%2C+G+R">Gabriel R. Barrenechea</a>, 
<a href="/search/math?searchtype=author&query=Castillo%2C+E">Ernesto Castillo</a>, 
<a href="/search/math?searchtype=author&query=Pacheco%2C+D+R+Q">Douglas R. Q. Pacheco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work we study different Implicit-Explicit (IMEX) schemes for
incompressible flow problems with variable viscosity. Unlike most previous work
on IMEX schemes, which focuses on the convective part, we here focus on
treating parts of the diffusive term explicitly to reduce the coupling between
the velocity components. We present different, both monolithic and
fractional-step, IMEX alternatives for the variable-viscosity Navier--Stokes
system, analysing their theoretical and algorithmic properties. Stability
results are proven for all the methods presented, with all these results being
unconditional, except for one of the discretisations using a fractional-step
scheme, where a CFL condition (in terms of the problem data) is required for
showing stability. Our analysis is supported by a series of numerical
experiments.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04183" title="Abstract">arXiv:2310.04183</a> [<a href="/pdf/2310.04183" title="Download PDF">pdf</a>, <a href="/format/2310.04183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indirect Meltdown: Building Novel Side-Channel Attacks from  Transient-Execution Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+D">Daniel Weber</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+F">Fabian Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Gerlach%2C+L">Lukas Gerlach</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+M">Michael Schwarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at ESORICS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The transient-execution attack Meltdown leaks sensitive information by
transiently accessing inaccessible data during out-of-order execution. Although
Meltdown is fixed in hardware for recent CPU generations, most
currently-deployed CPUs have to rely on software mitigations, such as KPTI.
Still, Meltdown is considered non-exploitable on current systems. In this
paper, we show that adding another layer of indirection to Meltdown transforms
a transient-execution attack into a side-channel attack, leaking metadata
instead of data. We show that despite software mitigations, attackers can still
leak metadata from other security domains by observing the success rate of
Meltdown on non-secret data. With LeakIDT, we present the first cache-line
granular monitoring of kernel addresses. LeakIDT allows an attacker to obtain
cycle-accurate timestamps for attacker-chosen interrupts. We use our attack to
get accurate inter-keystroke timings and fingerprint visited websites. While we
propose a low-overhead software mitigation to prevent the exploitation of
LeakIDT, we emphasize that the side-channel aspect of transient-execution
attacks should not be underestimated.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04185" title="Abstract">arXiv:2310.04185</a> [<a href="/pdf/2310.04185" title="Download PDF">pdf</a>, <a href="/format/2310.04185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Edge Orchestration of Serverless Functions with Probabilistic  Caching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Herrera%2C+M">Manuel Herrera</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Ge Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Liqiao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zhengyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangtao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Serverless edge computing adopts an event-based paradigm that provides
back-end services on an as-used basis, resulting in efficient resource
utilization. To improve the end-to-end latency and revenue, service providers
need to optimize the number and placement of serverless containers while
considering the system cost incurred by the provisioning. The particular reason
for this circumstance is that frequently creating and destroying containers not
only increases the system cost but also degrades the time responsiveness due to
the cold-start process. Function caching is a common approach to mitigate the
coldstart issue. However, function caching requires extra hardware resources
and hence incurs extra system costs. Furthermore, the dynamic and bursty nature
of serverless invocations remains an under-explored area. Hence, it is vitally
important for service providers to conduct a context-aware request distribution
and container caching policy for serverless edge computing. In this paper, we
study the request distribution and container caching problem in serverless edge
computing. We prove the proposed problem is NP-hard and hence difficult to find
a global optimal solution. We jointly consider the distributed and resource
constrained nature of edge computing and propose an optimized request
distribution algorithm that adapts to the dynamics of serverless invocations
with a theoretical performance guarantee. Also, we propose a context-aware
probabilistic caching policy that incorporates a number of characteristics of
serverless invocations. Via simulation and implementation results, we
demonstrate the superiority of the proposed algorithm by outperforming existing
caching policies in terms of the overall system cost and cold-start frequency
by up to 62.1% and 69.1%, respectively.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04189" title="Abstract">arXiv:2310.04189</a> [<a href="/pdf/2310.04189" title="Download PDF">pdf</a>, <a href="/format/2310.04189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap between Human Motion and Action Semantics via Kinematic  Phrases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zizheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of motion understanding is to establish a reliable mapping between
motion and action semantics, while it is a challenging many-to-many problem. An
abstract action semantic (i.e., walk forwards) could be conveyed by
perceptually diverse motions (walk with arms up or swinging), while a motion
could carry different semantics w.r.t. its context and intention. This makes an
elegant mapping between them difficult. Previous attempts adopted
direct-mapping paradigms with limited reliability. Also, current automatic
metrics fail to provide reliable assessments of the consistency between motions
and action semantics. We identify the source of these problems as the
significant gap between the two modalities. To alleviate this gap, we propose
Kinematic Phrases (KP) that take the objective kinematic facts of human motion
with proper abstraction, interpretability, and generality characteristics.
Based on KP as a mediator, we can unify a motion knowledge base and build a
motion understanding system. Meanwhile, KP can be automatically converted from
motions and to text descriptions with no subjective bias, inspiring Kinematic
Prompt Generation (KPG) as a novel automatic motion generation benchmark. In
extensive experiments, our approach shows superiority over other methods. Our
code and data would be made publicly available at https://foruck.github.io/KP.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04190" title="Abstract">arXiv:2310.04190</a> [<a href="/pdf/2310.04190" title="Download PDF">pdf</a>, <a href="/format/2310.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Redundant Graph Neural Networks with Improved Expressiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bause%2C+F">Franka Bause</a>, 
<a href="/search/cs?searchtype=author&query=Moustafa%2C+S">Samir Moustafa</a>, 
<a href="/search/cs?searchtype=author&query=Langguth%2C+J">Johannes Langguth</a>, 
<a href="/search/cs?searchtype=author&query=Gansterer%2C+W+N">Wilfried N. Gansterer</a>, 
<a href="/search/cs?searchtype=author&query=Kriege%2C+N+M">Nils M. Kriege</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Message passing graph neural networks iteratively compute node embeddings by
aggregating messages from all neighbors. This procedure can be viewed as a
neural variant of the Weisfeiler-Leman method, which limits their expressive
power. Moreover, oversmoothing and oversquashing restrict the number of layers
these networks can effectively utilize. The repeated exchange and encoding of
identical information in message passing amplifies oversquashing. We propose a
novel aggregation scheme based on neighborhood trees, which allows for
controlling the redundancy by pruning branches of the unfolding trees
underlying standard message passing. We prove that reducing redundancy improves
expressivity and experimentally show that it alleviates oversquashing. We
investigate the interaction between redundancy in message passing and
redundancy in computation and propose a compact representation of neighborhood
trees, from which we compute node and graph embeddings via a neural tree
canonization technique. Our method is provably more expressive than the
Weisfeiler-Leman method, less susceptible to oversquashing than message passing
neural networks, and provides high classification accuracy on widely-used
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04192" title="Abstract">arXiv:2310.04192</a> [<a href="/pdf/2310.04192" title="Download PDF">pdf</a>, <a href="/format/2310.04192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reviving Meltdown 3a
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+D">Daniel Weber</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+F">Fabian Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Gerlach%2C+L">Lukas Gerlach</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+M">Michael Schwarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at ESORICS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Since the initial discovery of Meltdown and Spectre in 2017, different
variants of these attacks have been discovered. One often overlooked variant is
Meltdown 3a, also known as Meltdown-CPL-REG. Even though Meltdown-CPL-REG was
initially discovered in 2018, the available information regarding the
vulnerability is still sparse. In this paper, we analyze Meltdown-CPL-REG on 19
different CPUs from different vendors using an automated tool. We observe that
the impact is more diverse than documented and differs from CPU to CPU.
Surprisingly, while the newest Intel CPUs do not seem affected by
Meltdown-CPL-REG, the newest available AMD CPUs (Zen3+) are still affected by
the vulnerability. Furthermore, given our attack primitive CounterLeak, we show
that besides up-to-date patches, Meltdown-CPL-REG can still be exploited as we
reenable performance-counter-based attacks on cryptographic algorithms, break
KASLR, and mount Spectre attacks. Although Meltdown-CPL-REG is not as powerful
as other transient-execution attacks, its attack surface should not be
underestimated.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04194" title="Abstract">arXiv:2310.04194</a> [<a href="/pdf/2310.04194" title="Download PDF">pdf</a>, <a href="/format/2310.04194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Authenticity of Rendered Portraits with  Identity-Consistent Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Luyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongliang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaogang Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite rapid advances in computer graphics, creating high-quality
photo-realistic virtual portraits is prohibitively expensive. Furthermore, the
well-know ''uncanny valley'' effect in rendered portraits has a significant
impact on the user experience, especially when the depiction closely resembles
a human likeness, where any minor artifacts can evoke feelings of eeriness and
repulsiveness. In this paper, we present a novel photo-realistic portrait
generation framework that can effectively mitigate the ''uncanny valley''
effect and improve the overall authenticity of rendered portraits. Our key idea
is to employ transfer learning to learn an identity-consistent mapping from the
latent space of rendered portraits to that of real portraits. During the
inference stage, the input portrait of an avatar can be directly transferred to
a realistic portrait by changing its appearance style while maintaining the
facial identity. To this end, we collect a new dataset, Daz-Rendered-Faces-HQ
(DRFHQ), that is specifically designed for rendering-style portraits. We
leverage this dataset to fine-tune the StyleGAN2 generator, using our carefully
crafted framework, which helps to preserve the geometric and color features
relevant to facial identity. We evaluate our framework using portraits with
diverse gender, age, and race variations. Qualitative and quantitative
evaluations and ablation studies show the advantages of our method compared to
state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04196" title="Abstract">arXiv:2310.04196</a> [<a href="/pdf/2310.04196" title="Download PDF">pdf</a>, <a href="/format/2310.04196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mlirSynth: Automatic, Retargetable Program Raising in Multi-Level IR  using Program Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brauckmann%2C+A">Alexander Brauckmann</a>, 
<a href="/search/cs?searchtype=author&query=Polgreen%2C+E">Elizabeth Polgreen</a>, 
<a href="/search/cs?searchtype=author&query=Grosser%2C+T">Tobias Grosser</a>, 
<a href="/search/cs?searchtype=author&query=O%27Boyle%2C+M+F+P">Michael F. P. O&#x27;Boyle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">MLIR is an emerging compiler infrastructure for modern hardware, but existing
programs cannot take advantage of MLIR's high-performance compilation if they
are described in lower-level general purpose languages. Consequently, to avoid
programs needing to be rewritten manually, this has led to efforts to
automatically raise lower-level to higher-level dialects in MLIR. However,
current methods rely on manually-defined raising rules, which limit their
applicability and make them challenging to maintain as MLIR dialects evolve.
<br />We present mlirSynth -- a novel approach which translates programs from
lower-level MLIR dialects to high-level ones without manually defined rules.
Instead, it uses available dialect definitions to construct a program space and
searches it effectively using type constraints and equivalences. We demonstrate
its effectiveness \revi{by raising C programs} to two distinct high-level MLIR
dialects, which enables us to use existing high-level dialect specific
compilation flows. On Polybench, we show a greater coverage than previous
approaches, resulting in geomean speedups of 2.5x (Intel) and 3.4x (AMD) over
state-of-the-art compilation flows for the C programming language. mlirSynth
also enables retargetability to domain-specific accelerators, resulting in a
geomean speedup of 21.6x on a TPU.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04197" title="Abstract">arXiv:2310.04197</a> [<a href="/pdf/2310.04197" title="Download PDF">pdf</a>, <a href="/format/2310.04197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threat Trekker: An Approach to Cyber Threat Hunting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bienzobas%2C+%C3%81+C">&#xc1;ngel Casanova Bienzobas</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Maci%C3%A1n%2C+A">Alfonso S&#xe1;nchez-Maci&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I am disseminating this outcome to all of you, despite the fact that the results may appear somewhat idealistic, given that certain datasets utilized for the training of the machine learning model comprise simulated data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Threat hunting is a proactive methodology for exploring, detecting and
mitigating cyberattacks within complex environments. As opposed to conventional
detection systems, threat hunting strategies assume adversaries have
infiltrated the system; as a result they proactively search out any unusual
patterns or activities which might indicate intrusion attempts.
<br />Historically, this endeavour has been pursued using three investigation
methodologies: (1) Hypothesis-Driven Investigations; (2) Indicator of
Compromise (IOC); and (3) High-level machine learning analysis-based
approaches. Therefore, this paper introduces a novel machine learning paradigm
known as Threat Trekker. This proposal utilizes connectors to feed data
directly into an event streaming channel for processing by the algorithm and
provide feedback back into its host network.
<br />Conclusions drawn from these experiments clearly establish the efficacy of
employing machine learning for classifying more subtle attacks.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04205" title="Abstract">arXiv:2310.04205</a> [<a href="/pdf/2310.04205" title="Download PDF">pdf</a>, <a href="/format/2310.04205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keyword Augmented Retrieval: Novel framework for Information Retrieval  integrated with speech interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purwar%2C+A">Anupam Purwar</a>, 
<a href="/search/cs?searchtype=author&query=Sundar%2C+R">Rahul Sundar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Retrieving answers in a quick and low cost manner without hallucinations from
a combination of structured and unstructured data using Language models is a
major hurdle which prevents employment of Language models in knowledge
retrieval automation. This becomes accentuated when one wants to integrate a
speech interface. Besides, for commercial search and chatbot applications,
complete reliance on commercial large language models (LLMs) like GPT 3.5 etc.
can be very costly. In this work, authors have addressed this problem by first
developing a keyword based search framework which augments discovery of the
context to be provided to the large language model. The keywords in turn are
generated by LLM and cached for comparison with keywords generated by LLM
against the query raised. This significantly reduces time and cost to find the
context within documents. Once the context is set, LLM uses that to provide
answers based on a prompt tailored for Q&amp;A. This research work demonstrates
that use of keywords in context identification reduces the overall inference
time and cost of information retrieval. Given this reduction in inference time
and cost with the keyword augmented retrieval framework, a speech based
interface for user input and response readout was integrated. This allowed a
seamless interaction with the language model.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04213" title="Abstract">arXiv:2310.04213</a> [<a href="/pdf/2310.04213" title="Download PDF">pdf</a>, <a href="/format/2310.04213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Aware Neural Networks for Fast Contingency Analysis of Power  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nakiganda%2C+A+M">Agnes M. Nakiganda</a>, 
<a href="/search/eess?searchtype=author&query=Cheylan%2C+C">Catherine Cheylan</a>, 
<a href="/search/eess?searchtype=author&query=Chatzivasileiadis%2C+S">Spyros Chatzivasileiadis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Training Neural Networks able to capture the topology changes of the power
grid is one of the significant challenges towards the adoption of machine
learning techniques for N-k security computations and a wide range of other
operations that involve grid reconfiguration. As the number of N-k scenarios
increases exponentially with increasing system size, such problems are
extremely time-consuming to solve with traditional solvers. In this paper, we
combine Physics-Informed Neural Networks with both a Guided-Dropout (GD) (which
associates dedicated neurons with specific line connections/disconnections) and
an edge-varying Graph Neural Neural Network (GNN) architecture to learn the
setpoints for a grid that considers all probable single-line reconfigurations
(all critical N-1 scenarios) and subsequently apply the trained models to N-k
scenarios. We demonstrate how incorporating the underlying physical equations
for the network equations along with the GD and the GNN methods, performs with
N-1, N-2, and N-3 case studies. Using the AC Power Flow as a guiding
application, we test our methods on the 14-bus, 30-bus, 57-bus, and 118-bus
systems, and we compare the models in terms of the accuracy and computational
performance that each one achieves for each study and provide recommendations
on their adoption for contingency analysis of power systems.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04216" title="Abstract">arXiv:2310.04216</a> [<a href="/pdf/2310.04216" title="Download PDF">pdf</a>, <a href="/format/2310.04216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-Effective Retraining of Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahadevan%2C+A">Ananth Mahadevan</a>, 
<a href="/search/cs?searchtype=author&query=Mathioudakis%2C+M">Michael Mathioudakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">It is important to retrain a machine learning (ML) model in order to maintain
its performance as the data changes over time. However, this can be costly as
it usually requires processing the entire dataset again. This creates a
trade-off between retraining too frequently, which leads to unnecessary
computing costs, and not retraining often enough, which results in stale and
inaccurate ML models. To address this challenge, we propose ML systems that
make automated and cost-effective decisions about when to retrain an ML model.
We aim to optimize the trade-off by considering the costs associated with each
decision. Our research focuses on determining whether to retrain or keep an
existing ML model based on various factors, including the data, the model, and
the predictive queries answered by the model. Our main contribution is a
Cost-Aware Retraining Algorithm called Cara, which optimizes the trade-off over
streams of data and queries. To evaluate the performance of Cara, we analyzed
synthetic datasets and demonstrated that Cara can adapt to different data
drifts and retraining costs while performing similarly to an optimal
retrospective algorithm. We also conducted experiments with real-world datasets
and showed that Cara achieves better accuracy than drift detection baselines
while making fewer retraining decisions, ultimately resulting in lower total
costs.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04218" title="Abstract">arXiv:2310.04218</a> [<a href="/pdf/2310.04218" title="Download PDF">pdf</a>, <a href="/format/2310.04218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence  Classes with the same Skeleton
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V+S">Vidya Sagar Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages, 2 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Causal DAGs (also known as Bayesian networks) are a popular tool for encoding
conditional dependencies between random variables. In a causal DAG, the random
variables are modeled as vertices in the DAG, and it is stipulated that every
random variable is independent of its ancestors conditioned on its parents. It
is possible, however, for two different causal DAGs on the same set of random
variables to encode exactly the same set of conditional dependencies. Such
causal DAGs are said to be Markov equivalent, and equivalence classes of Markov
equivalent DAGs are known as Markov Equivalent Classes (MECs). Beautiful
combinatorial characterizations of MECs have been developed in the past few
decades, and it is known, in particular that all DAGs in the same MEC must have
the same ''skeleton'' (underlying undirected graph) and v-structures (induced
subgraph of the form $a\rightarrow b \leftarrow c$).
<br />These combinatorial characterizations also suggest several natural
algorithmic questions. One of these is: given an undirected graph $G$ as input,
how many distinct Markov equivalence classes have the skeleton $G$? Much work
has been devoted in the last few years to this and other closely related
problems. However, to the best of our knowledge, a polynomial time algorithm
for the problem remains unknown.
<br />In this paper, we make progress towards this goal by giving a fixed parameter
tractable algorithm for the above problem, with the parameters being the
treewidth and the maximum degree of the input graph $G$. The main technical
ingredient in our work is a construction we refer to as shadow, which lets us
create a "local description'' of long-range constraints imposed by the
combinatorial characterizations of MECs.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04220" title="Abstract">arXiv:2310.04220</a> [<a href="/pdf/2310.04220" title="Download PDF">pdf</a>, <a href="/format/2310.04220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial second-order positive and asymptotic preserving filtered $P_N$  schemes for nonlinear radiative transfer equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xiaojing Xu</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+S">Song Jiang</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+W">Wenjun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A spatial second-order scheme for the nonlinear radiative transfer equations
is introduced in this paper. The discretization scheme is based on the filtered
spherical harmonics ($FP_N$) method for the angular variable and the unified
gas kinetic scheme (UGKS) framework for the spatial and temporal variables
respectively. In order to keep the scheme positive and second-order accuracy,
firstly, we use the implicit Monte Carlo linearization method [6] in the
construction of the UGKS numerical boundary fluxes. Then, by carefully
analyzing the constructed second-order fluxes involved in the macro-micro
decomposition, which is induced by the $FP_N$ angular discretization, we
establish the sufficient conditions that guarantee the positivity of the
radiative energy density and material temperature. Finally, we employ linear
scaling limiters for the angular variable in the $P_N$ reconstruction and for
the spatial variable in the piecewise linear slopes reconstruction
respectively, which are shown to be realizable and reasonable to enforce the
sufficient conditions holding. Thus, the desired scheme, called the
$PPFP_N$-based UGKS, is obtained. Furthermore, in the regime $\epsilon\ll 1$
and the regime $\epsilon=O(1)$, a simplified spatial second-order scheme,
called the $PPFP_N$-based SUGKS, is presented, which possesses all the
properties of the non-simplified one. Inheriting the merit of UGKS, the
proposed schemes are asymptotic preserving. By employing the $FP_N$ method for
the angular variable, the proposed schemes are almost free of ray effects. To
our best knowledge, this is the first time that spatial second-order, positive,
asymptotic preserving and almost free of ray effects schemes are constructed
for the nonlinear radiative transfer equations without operator splitting.
Various numerical experiments are included to validate the properties of the
proposed schemes.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04227" title="Abstract">arXiv:2310.04227</a> [<a href="/pdf/2310.04227" title="Download PDF">pdf</a>, <a href="/ps/2310.04227" title="Download PostScript">ps</a>, <a href="/format/2310.04227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Identification of Nonlinear Dynamics with Side Information  (SINDy-SI)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Machado%2C+G+F">Gabriel F. Machado</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+M">Morgan Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Modern societies have an abundance of data yet good system models are rare.
Unfortunately, many of the current system identification and machine learning
techniques fail to generalize outside of the training set, producing models
that violate basic physical laws. This work proposes a novel method for the
Sparse Identification of Nonlinear Dynamics with Side Information (SINDy-SI).
SINDy-SI is an iterative method that uses Sum-of-Squares (SOS) programming to
learn optimally fitted models while guaranteeing that the learned model
satisfies side information, such as symmetry's and physical laws. Guided by the
principle of Occam's razor, that the simplest or most regularized best fitted
model is typically the superior choice, during each iteration SINDy-SI prunes
the basis functions associated with small coefficients, yielding a sparse
dynamical model upon termination. Through several numerical experiments we will
show how the combination of side information constraints and sparse polynomial
representation cultivates dynamical models that obey known physical laws while
displaying impressive generalized performance beyond the training set.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04230" title="Abstract">arXiv:2310.04230</a> [<a href="/pdf/2310.04230" title="Download PDF">pdf</a>, <a href="/format/2310.04230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lending Interaction Wings to Recommender Systems with Conversational  Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiarui Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fanghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengyue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yue Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems trained on offline historical user behaviors are
embracing conversational techniques to online query user preference. Unlike
prior conversational recommendation approaches that systemically combine
conversational and recommender parts through a reinforcement learning
framework, we propose CORE, a new offline-training and online-checking paradigm
that bridges a COnversational agent and REcommender systems via a unified
uncertainty minimization framework. It can benefit any recommendation platform
in a plug-and-play style. Here, CORE treats a recommender system as an offline
relevance score estimator to produce an estimated relevance score for each
item; while a conversational agent is regarded as an online relevance score
checker to check these estimated scores in each session. We define uncertainty
as the summation of unchecked relevance scores. In this regard, the
conversational agent acts to minimize uncertainty via querying either
attributes or items. Based on the uncertainty minimization framework, we derive
the expected certainty gain of querying each attribute and item, and develop a
novel online decision tree algorithm to decide what to query at each turn.
Experimental results on 8 industrial datasets show that CORE could be
seamlessly employed on 9 popular recommendation approaches. We further
demonstrate that our conversational agent could communicate as a human if
empowered by a pre-trained large language model.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04231" title="Abstract">arXiv:2310.04231</a> [<a href="/pdf/2310.04231" title="Download PDF">pdf</a>, <a href="/format/2310.04231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indoor Positioning based on Active Radar Sensing and Passive Reflectors:  Concepts &amp; Initial Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlachter%2C+P">Pascal Schlachter</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhibin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+N">Naveed Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaofeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hinderer%2C+S">Sven Hinderer</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Work-in-Progress Papers at the 13th
  International Conference on Indoor Positioning and Indoor Navigation
  (IPIN-WiP 2023), September 25 - 28, 2023, Nuremberg, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">To navigate reliably in indoor environments, an industrial autonomous vehicle
must know its position. However, current indoor vehicle positioning
technologies either lack accuracy, usability or are too expensive. Thus, we
propose a novel concept called local reference point assisted active radar
positioning, which is able to overcome these drawbacks. It is based on
distributing passive retroreflectors in the indoor environment such that each
position of the vehicle can be identified by a unique reflection characteristic
regarding the reflectors. To observe these characteristics, the autonomous
vehicle is equipped with an active radar system. On one hand, this paper
presents the basic idea and concept of our new approach towards indoor vehicle
positioning and especially focuses on the crucial placement of the reflectors.
On the other hand, it also provides a proof of concept by conducting a full
system simulation including the placement of the local reference points, the
radar-based distance estimation and the comparison of two different positioning
methods. It successfully demonstrates the feasibility of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04232" title="Abstract">arXiv:2310.04232</a> [<a href="/pdf/2310.04232" title="Download PDF">pdf</a>, <a href="/format/2310.04232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The WayHome: Long-term Motion Prediction on Dynamically Scaled
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheerer%2C+K">Kay Scheerer</a>, 
<a href="/search/cs?searchtype=author&query=Michalke%2C+T">Thomas Michalke</a>, 
<a href="/search/cs?searchtype=author&query=Mathes%2C+J">Juergen Mathes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the key challenges for autonomous vehicles is the ability to
accurately predict the motion of other objects in the surrounding environment,
such as pedestrians or other vehicles. In this contribution, a novel motion
forecasting approach for autonomous vehicles is developed, inspired by the work
of Gilles et al. [1]. We predict multiple heatmaps with a neuralnetwork-based
model for every traffic participant in the vicinity of the autonomous vehicle;
with one heatmap per timestep. The heatmaps are used as input to a novel
sampling algorithm that extracts coordinates corresponding to the most likely
future positions. We experiment with different encoders and decoders, as well
as a comparison of two loss functions. Additionally, a new grid-scaling
technique is introduced, showing further improved performance. Overall, our
approach improves stateof-the-art miss rate performance for the
function-relevant prediction interval of 3 seconds while being competitive in
longer prediction intervals (up to eight seconds). The evaluation is done on
the public 2022 Waymo motion challenge.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04236" title="Abstract">arXiv:2310.04236</a> [<a href="/pdf/2310.04236" title="Download PDF">pdf</a>, <a href="/format/2310.04236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization with pattern-avoiding input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berendsohn%2C+B+A">Benjamin Aram Berendsohn</a>, 
<a href="/search/cs?searchtype=author&query=Kozma%2C+L">L&#xe1;szl&#xf3; Kozma</a>, 
<a href="/search/cs?searchtype=author&query=Opler%2C+M">Michal Opler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Permutation pattern-avoidance is a central concept of both enumerative and
extremal combinatorics. In this paper we study the effect of permutation
pattern-avoidance on the complexity of optimization problems.
<br />In the context of the dynamic optimality conjecture (Sleator, Tarjan, STOC
1983), Chalermsook, Goswami, Kozma, Mehlhorn, and Saranurak (FOCS 2015)
conjectured that the amortized access cost of an optimal binary search tree
(BST) is $O(1)$ whenever the access sequence avoids some fixed pattern. They
showed a bound of $2^{\alpha{(n)}^{O(1)}}$, which was recently improved to
$2^{\alpha{(n)}(1+o(1))}$ by Chalermsook, Pettie, and Yingchareonthawornchai
(2023); here $n$ is the BST size and $\alpha(\cdot)$ the inverse-Ackermann
function. In this paper we resolve the conjecture, showing a tight $O(1)$
bound. This indicates a barrier to dynamic optimality: any candidate online BST
(e.g., splay trees or greedy trees) must match this optimum, but current
analysis techniques only give superconstant bounds.
<br />More broadly, we argue that the easiness of pattern-avoiding input is a
general phenomenon, not limited to BSTs or even to data structures. To
illustrate this, we show that when the input avoids an arbitrary, fixed, a
priori unknown pattern, one can efficiently compute a $k$-server solution of
$n$ requests from a unit interval, with total cost $n^{O(1/\log k)}$, in
contrast to the worst-case $\Theta(n/k)$ bound; and a traveling salesman tour
of $n$ points from a unit box, of length $O(\log{n})$, in contrast to the
worst-case $\Theta(\sqrt{n})$ bound; similar results hold for the euclidean
minimum spanning tree, Steiner tree, and nearest-neighbor graphs.
<br />We show both results to be tight. Our techniques build on the Marcus-Tardos
proof of the Stanley-Wilf conjecture, and on the recently emerging concept of
twin-width; we believe our techniques to be more generally applicable.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04237" title="Abstract">arXiv:2310.04237</a> [<a href="/pdf/2310.04237" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Written and spoken corpus of real and fake social media postings about  COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chin%2C+N+B">Ng Bee Chin</a>, 
<a href="/search/cs?searchtype=author&query=Nicole%2C+N+Z+E">Ng Zhi Ee Nicole</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+K">Kyla Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Dylann%2C+L+Y+H">Lee Yong Han Dylann</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Liu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+X">Xu Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study investigates the linguistic traits of fake news and real news.
There are two parts to this study: text data and speech data. The text data for
this study consisted of 6420 COVID-19 related tweets re-filtered from Patwa et
al. (2021). After cleaning, the dataset contained 3049 tweets, with 2161
labeled as 'real' and 888 as 'fake'. The speech data for this study was
collected from TikTok, focusing on COVID-19 related videos. Research assistants
fact-checked each video's content using credible sources and labeled them as
'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entries
and 109 fake entries from 200 TikTok videos with a total word count of 53,710
words. The data was analysed using the Linguistic Inquiry and Word Count (LIWC)
software to detect patterns in linguistic data. The results indicate a set of
linguistic features that distinguish fake news from real news in both written
and speech data. This offers valuable insights into the role of language in
shaping trust, social media interactions, and the propagation of fake news.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04238" title="Abstract">arXiv:2310.04238</a> [<a href="/pdf/2310.04238" title="Download PDF">pdf</a>, <a href="/format/2310.04238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bringing Quantum Algorithms to Automated Machine Learning: A Systematic  Review of AutoML Frameworks Regarding Extensibility for QML Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klau%2C+D">Dennis Klau</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6ller%2C+M">Marc Z&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Tutschku%2C+C">Christian Tutschku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Whitepaper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This work describes the selection approach and analysis of existing AutoML
frameworks regarding their capability of a) incorporating Quantum Machine
Learning (QML) algorithms into this automated solving approach of the AutoML
framing and b) solving a set of industrial use-cases with different ML problem
types by benchmarking their most important characteristics. For that, available
open-source tools are condensed into a market overview and suitable frameworks
are systematically selected on a multi-phase, multi-criteria approach. This is
done by considering software selection approaches, as well as in terms of the
technical perspective of AutoML. The requirements for the framework selection
are divided into hard and soft criteria regarding their software and ML
attributes. Additionally, a classification of AutoML frameworks is made into
high- and low-level types, inspired by the findings of. Finally, we select Ray
and AutoGluon as the suitable low- and high-level frameworks respectively, as
they fulfil all requirements sufficiently and received the best evaluation
feedback during the use-case study. Based on those findings, we build an
extended Automated Quantum Machine Learning (AutoQML) framework with
QC-specific pipeline steps and decision characteristics for hardware and
software constraints.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04239" title="Abstract">arXiv:2310.04239</a> [<a href="/pdf/2310.04239" title="Download PDF">pdf</a>, <a href="/format/2310.04239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representative Days and Hours with Piecewise Linear Transitions for  Power System Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moradi-Sepahvand%2C+M">Mojtaba Moradi-Sepahvand</a>, 
<a href="/search/eess?searchtype=author&query=Tindemans%2C+S+H">Simon H. Tindemans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Electric demand and renewable power are highly variable, and the solution of
a planning model relies on capturing this variability. This paper proposes a
hybrid multi-area method that effectively captures both the intraday and
interday chronology of real data considering extreme values, using a limited
number of representative days, and time points within each day. An
optimization-based representative extraction method is proposed to improve
intraday chronology capturing. It ensures higher precision in preserving data
chronology and extreme values than hierarchical clustering methods. The
proposed method is based on a piecewise linear demand and supply
representation, which reduces approximation errors compared to the traditional
piecewise constant formulation. Additionally, sequentially linked day blocks
with identical representatives, created through a mapping process, are employed
for interday chronology capturing. To evaluate the efficiency of the proposed
method, a comprehensive expansion co-planning model is developed, including
transmission lines, energy storage systems, and wind farms.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04241" title="Abstract">arXiv:2310.04241</a> [<a href="/pdf/2310.04241" title="Download PDF">pdf</a>, <a href="/format/2310.04241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Auxiliary Tasks for Learning Representations for Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+M">Moritz Lange</a>, 
<a href="/search/cs?searchtype=author&query=Krystiniak%2C+N">Noah Krystiniak</a>, 
<a href="/search/cs?searchtype=author&query=Engelhardt%2C+R+C">Raphael C. Engelhardt</a>, 
<a href="/search/cs?searchtype=author&query=Konen%2C+W">Wolfgang Konen</a>, 
<a href="/search/cs?searchtype=author&query=Wiskott%2C+L">Laurenz Wiskott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning state representations has gained steady popularity in reinforcement
learning (RL) due to its potential to improve both sample efficiency and
returns on many environments. A straightforward and efficient method is to
generate representations with a distinct neural network trained on an auxiliary
task, i.e. a task that differs from the actual RL task. While a whole range of
such auxiliary tasks has been proposed in the literature, a comparison on
typical continuous control benchmark environments is computationally expensive
and has, to the best of our knowledge, not been performed before. This paper
presents such a comparison of common auxiliary tasks, based on hundreds of
agents trained with state-of-the-art off-policy RL algorithms. We compare
possible improvements in both sample efficiency and returns for environments
ranging from simple pendulum to a complex simulated robotics task. Our findings
show that representation learning with auxiliary tasks is beneficial for
environments of higher dimension and complexity, and that learning environment
dynamics is preferable to predicting rewards. We believe these insights will
enable other researchers to make more informed decisions on how to utilize
representation learning for their specific problem.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04244" title="Abstract">arXiv:2310.04244</a> [<a href="/pdf/2310.04244" title="Download PDF">pdf</a>, <a href="/format/2310.04244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing Chronology and Extreme Values of Representative Days for  Planning of Transmission Lines and Long-Term Energy Storage Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moradi-Sepahvand%2C+M">Mojtaba Moradi-Sepahvand</a>, 
<a href="/search/eess?searchtype=author&query=Tindemans%2C+S+H">Simon H. Tindemans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE PowerTech 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Belgrade PowerTech, pp. 1-6. IEEE, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The growing penetration of renewable energy sources (RESs) is inevitable to
reach net zero emissions. In this regard, optimal planning and operation of
power systems are becoming more critical due to the need for modeling the
short-term variability of RES output power and load demand. Considering hourly
time steps of one or more years to model the operational details in a long-term
expansion planning scheme can lead to a practically unsolvable model.
Therefore, a clustering-based hybrid time series aggregation algorithm is
proposed in this paper to capture both extreme values and temporal dynamics of
input data by some extracted representatives. The proposed method is examined
in a complex co-planning model for transmission lines, wind power plants
(WPPs), short-term battery and long-term pumped hydroelectric energy storage
systems. The effectiveness of proposed mixed-integer linear programming (MILP)
model is evaluated using a modified 6-bus Garver test system. The simulation
results confirm the proposed model efficacy, especially in modeling long-term
energy storage systems.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04246" title="Abstract">arXiv:2310.04246</a> [<a href="/pdf/2310.04246" title="Download PDF">pdf</a>, <a href="/ps/2310.04246" title="Download PostScript">ps</a>, <a href="/format/2310.04246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully discrete Galerkin scheme for a semilinear subdiffusion equation  with nonsmooth data and time-dependent coefficient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=P%C5%82ociniczak%2C+%C5%81">&#x141;ukasz P&#x142;ociniczak</a>, 
<a href="/search/math?searchtype=author&query=Ta%C5%BAbierski%2C+K">Kacper Ta&#x17a;bierski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We couple the L1 discretization of the Caputo fractional derivative in time
with the Galerkin scheme to devise a linear numerical method for the semilinear
subdiffusion equation. Two important points that we make are: nonsmooth initial
data and time-dependent diffusion coefficient. We prove the stability and
convergence of the method under weak assumptions concerning regularity of the
diffusivity. We find optimal pointwise in space and global in time errors,
which are verified with several numerical experiments.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04247" title="Abstract">arXiv:2310.04247</a> [<a href="/pdf/2310.04247" title="Download PDF">pdf</a>, <a href="/format/2310.04247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic segmentation of longitudinal thermal images for identification  of hot and cool spots in urban areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramani%2C+V">Vasantha Ramani</a>, 
<a href="/search/cs?searchtype=author&query=Arjunan%2C+P">Pandarasamy Arjunan</a>, 
<a href="/search/cs?searchtype=author&query=Poolla%2C+K">Kameshwar Poolla</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+C">Clayton Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents the analysis of semantically segmented, longitudinally,
and spatially rich thermal images collected at the neighborhood scale to
identify hot and cool spots in urban areas. An infrared observatory was
operated over a few months to collect thermal images of different types of
buildings on the educational campus of the National University of Singapore. A
subset of the thermal image dataset was used to train state-of-the-art deep
learning models to segment various urban features such as buildings,
vegetation, sky, and roads. It was observed that the U-Net segmentation model
with `resnet34' CNN backbone has the highest mIoU score of 0.99 on the test
dataset, compared to other models such as DeepLabV3, DeeplabV3+, FPN, and
PSPnet. The masks generated using the segmentation models were then used to
extract the temperature from thermal images and correct for differences in the
emissivity of various urban features. Further, various statistical measure of
the temperature extracted using the predicted segmentation masks is shown to
closely match the temperature extracted using the ground truth masks. Finally,
the masks were used to identify hot and cool spots in the urban feature at
various instances of time. This forms one of the very few studies demonstrating
the automated analysis of thermal images, which can be of potential use to
urban planners for devising mitigation strategies for reducing the urban heat
island (UHI) effect, improving building energy efficiency, and maximizing
outdoor thermal comfort.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04253" title="Abstract">arXiv:2310.04253</a> [<a href="/pdf/2310.04253" title="Download PDF">pdf</a>, <a href="/format/2310.04253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Camouflaged Object Detection: A Large-Scale Dataset and  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+H">Hongbo Bi</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tian-Zhu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ranwan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+J">Jinghui Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiufang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we provide a comprehensive study on a new task called
collaborative camouflaged object detection (CoCOD), which aims to
simultaneously detect camouflaged objects with the same properties from a group
of relevant images. To this end, we meticulously construct the first
large-scale dataset, termed CoCOD8K, which consists of 8,528 high-quality and
elaborately selected images with object mask annotations, covering 5
superclasses and 70 subclasses. The dataset spans a wide range of natural and
artificial camouflage scenes with diverse object appearances and backgrounds,
making it a very challenging dataset for CoCOD. Besides, we propose the first
baseline model for CoCOD, named bilateral-branch network (BBNet), which
explores and aggregates co-camouflaged cues within a single image and between
images within a group, respectively, for accurate camouflaged object detection
in given images. This is implemented by an inter-image collaborative feature
exploration (CFE) module, an intra-image object feature search (OFS) module,
and a local-global refinement (LGR) module. We benchmark 18 state-of-the-art
models, including 12 COD algorithms and 6 CoSOD algorithms, on the proposed
CoCOD8K dataset under 5 widely used evaluation metrics. Extensive experiments
demonstrate the effectiveness of the proposed method and the significantly
superior performance compared to other competitors. We hope that our proposed
dataset and model will boost growth in the COD community. The dataset, model,
and results will be available at: https://github.com/zc199823/BBNet--CoCOD.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04256" title="Abstract">arXiv:2310.04256</a> [<a href="/pdf/2310.04256" title="Download PDF">pdf</a>, <a href="/ps/2310.04256" title="Download PostScript">ps</a>, <a href="/format/2310.04256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wardrop equilibrium and Braess&#x27;s paradox for varying demand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verbree%2C+J">Jasper Verbree</a>, 
<a href="/search/cs?searchtype=author&query=Cherukuri%2C+A">Ashish Cherukuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This work explores the relationship between the set of Wardrop
equilibria~(WE) of a routing game, the total demand of that game, and the
occurrence of Braess's paradox~(BP). The BP formalizes the counter-intuitive
fact that for some networks, removing a path from the network decreases
congestion at WE. For a single origin-destination routing games with affine
cost functions, the first part of this work provides tools for analyzing the
evolution of the WE as the demand varies. It characterizes the piece-wise
affine nature of this dependence by showing that the set of directions in which
the WE can vary in each piece is the solution of a variational inequality
problem. In the process we establish various properties of changes in the set
of used and minimal-cost paths as demand varies. As a consequence of these
characterizations, we derive a procedure to obtain the WE for all demands above
a certain threshold. The second part of the paper deals with detecting the
presence of BP in a network. We supply a number of sufficient conditions that
reveal the presence of BP and that are computationally tractable. We also
discuss a different perspective on BP, where we establish that a path causing
BP at a particular demand must be strictly beneficial to the network at a lower
demand. Several examples throughout this work illustrate and elaborate our
findings.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04257" title="Abstract">arXiv:2310.04257</a> [<a href="/pdf/2310.04257" title="Download PDF">pdf</a>, <a href="/format/2310.04257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Solving Close Enough Orienteering Problem with Overlapped  Neighborhoods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qiuchen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Boyle%2C+D">David Boyle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The Close Enough Traveling Salesman Problem (CETSP) is a well-known variant
of the classic Traveling Salesman Problem whereby the agent may complete its
mission at any point within a target neighborhood. Heuristics based on
overlapped neighborhoods, known as Steiner Zones (SZ), have gained attention in
addressing CETSPs. While SZs offer effective approximations to the original
graph, their inherent overlap imposes constraints on the search space,
potentially conflicting with global optimization objectives. Here we present
the Close Enough Orienteering Problem with Non-uniform Neighborhoods (CEOP-N),
which extends CETSP by introducing variable prize attributes and non-uniform
cost considerations for prize collection. To tackle CEOP-N, we develop a new
approach featuring a Randomized Steiner Zone Discretization (RSZD) scheme
coupled with a hybrid algorithm based on Particle Swarm Optimization (PSO) and
Ant Colony System (ACS) - CRaSZe-AntS. The RSZD scheme identifies sub-regions
for PSO exploration, and ACS determines the discrete visiting sequence. We
evaluate the RSZD's discretization performance on CEOP instances derived from
established CETSP instances, and compare CRaSZe-AntS against the most relevant
state-of-the-art heuristic focused on single-neighborhood optimization for
CEOP. We also compare the performance of the interior search within SZs and the
boundary search on individual neighborhoods in the context of CEOP-N. Our
results show CRaSZe-AntS can yield comparable solution quality with
significantly reduced computation time compared to the single-neighborhood
strategy, where we observe an averaged 140.44% increase in prize collection and
55.18% reduction of execution time. CRaSZe-AntS is thus highly effective in
solving emerging CEOP-N, examples of which include truck-and-drone delivery
scenarios.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04259" title="Abstract">arXiv:2310.04259</a> [<a href="/pdf/2310.04259" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Safety Objective for the Calibration of the Intelligent Driver  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adjenughwure%2C+K">Kingsley Adjenughwure</a>, 
<a href="/search/cs?searchtype=author&query=Tejada%2C+A">Arturo Tejada</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+P+F+V">Pedro F. V. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Hogema%2C+J">Jeroen Hogema</a>, 
<a href="/search/cs?searchtype=author&query=Klunder%2C+G">Gerdien Klunder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to the Transportation Research Records Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The intelligent driver model (IDM) is one of the most widely used
car-following (CF) models in recent years. The parameters of this model have
been calibrated using real trajectories obtained from naturalistic driving
,driving simulator experiment and drone data. An important aspect of the model
calibration process is defining the main objective of the calibration. This
objective, influences the objective function and the performance measure for
the calibration. For example, to calibrate CF models, the objective is usually
to minimize the error in measured spacing or speed while important safety
aspects of the models such as the collision avoidance mechanisms are ignored.
For such models, there is no guarantee that the calibrated parameters will
preserve the safety properties of the model since they are not explicitly taken
into account. To explicitly account for the safety properties during
calibration, this paper proposes a simple objective function which minimizes
both the error in the actual measured spacing (as it is currently done) and the
error in the dynamic safety spacing (desired minimum gap) derived from the
collision free property of the IDM model. The proposed objective function is
used to calibrate two variants of the IDM using vehicle trajectories obtained
with drone from a Dutch highway. The calibration performance is then compared
in terms of the error in actual spacing and time gap. The results show that the
proposed safety objective 15 function leads to lower errors in spacing and time
gap compared to when minimizing for only spacing and preserves collision
property of the IDM.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04264" title="Abstract">arXiv:2310.04264</a> [<a href="/pdf/2310.04264" title="Download PDF">pdf</a>, <a href="/format/2310.04264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C(NN)FD -- deep learning predictions of tip clearance variations on  multi-stage axial compressors aerodynamic performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruni%2C+G">Giuseppe Bruni</a>, 
<a href="/search/cs?searchtype=author&query=Maleki%2C+S">Sepehr Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Krishnababu%2C+S+K">Senthil K. Krishnababu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.05889">arXiv:2306.05889</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Application of deep learning methods to physical simulations such as CFD
(Computational Fluid Dynamics), have been so far of limited industrial
relevance. This paper demonstrates the development and application of a deep
learning framework for real-time predictions of the impact of tip clearance
variations on the aerodynamic performance of multi-stage axial compressors in
gas turbines. The proposed C(NN)FD architecture is proven to be scalable to
industrial applications, and achieves in real-time accuracy comparable to the
CFD benchmark. The deployed model, is readily integrated within the
manufacturing and build process of gas turbines, thus providing the opportunity
to analytically assess the impact on performance and potentially reduce
requirements for expensive physical tests.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04266" title="Abstract">arXiv:2310.04266</a> [<a href="/pdf/2310.04266" title="Download PDF">pdf</a>, <a href="/format/2310.04266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms  Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Hariry%2C+M">Matteo El-Hariry</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+A">Antoine Richard</a>, 
<a href="/search/cs?searchtype=author&query=Muralidharan%2C+V">Vivek Muralidharan</a>, 
<a href="/search/cs?searchtype=author&query=Yalcin%2C+B+C">Baris Can Yalcin</a>, 
<a href="/search/cs?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/cs?searchtype=author&query=Olivares-Mendez%2C+M">Miguel Olivares-Mendez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This investigation introduces a novel deep reinforcement learning-based suite
to control floating platforms in both simulated and real-world environments.
Floating platforms serve as versatile test-beds to emulate microgravity
environments on Earth. Our approach addresses the system and environmental
uncertainties in controlling such platforms by training policies capable of
precise maneuvers amid dynamic and unpredictable conditions. Leveraging
state-of-the-art deep reinforcement learning techniques, our suite achieves
robustness, adaptability, and good transferability from simulation to reality.
Our Deep Reinforcement Learning (DRL) framework provides advantages such as
fast training times, large-scale testing capabilities, rich visualization
options, and ROS bindings for integration with real-world robotic systems.
Beyond policy development, our suite provides a comprehensive platform for
researchers, offering open-access at
https://github.com/elharirymatteo/RANS/tree/ICRA24.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04268" title="Abstract">arXiv:2310.04268</a> [<a href="/pdf/2310.04268" title="Download PDF">pdf</a>, <a href="/format/2310.04268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Workload-aware and Learned Z-Indexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pai%2C+S">Sachith Pai</a>, 
<a href="/search/cs?searchtype=author&query=Mathioudakis%2C+M">Michael Mathioudakis</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this paper, a learned and workload-aware variant of a Z-index, which
jointly optimizes storage layout and search structures, as a viable solution
for the above challenges of spatial indexing. Specifically, we first formulate
a cost function to measure the performance of a Z-index on a dataset for a
range-query workload. Then, we optimize the Z-index structure by minimizing the
cost function through adaptive partitioning and ordering for index
construction. Moreover, we design a novel page-skipping mechanism to improve
its query performance by reducing access to irrelevant data pages. Our
extensive experiments show that our index improves range query time by 40% on
average over the baselines, while always performing better or comparably to
state-of-the-art spatial indexes. Additionally, our index maintains good point
query performance while providing favourable construction time and index size
tradeoffs.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04269" title="Abstract">arXiv:2310.04269</a> [<a href="/pdf/2310.04269" title="Download PDF">pdf</a>, <a href="/format/2310.04269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Semantic Conflicts using Static Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Jesus%2C+G+S">Galileu Santos de Jesus</a>, 
<a href="/search/cs?searchtype=author&query=Borba%2C+P+H+M">Paulo Henrique Monteiro Borba</a>, 
<a href="/search/cs?searchtype=author&query=de+Almeida%2C+R+B">Rodrigo Bonif&#xe1;cio de Almeida</a>, 
<a href="/search/cs?searchtype=author&query=de+Oliveira%2C+M+B">Matheus Barbosa de Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Version control system tools empower developers to independently work on
their development tasks. These tools also facilitate the integration of changes
through merging operations, and report textual conflicts. However, when
developers integrate their changes, they might encounter other types of
conflicts that are not detected by current merge tools. In this paper, we focus
on dynamic semantic conflicts, which occur when merging reports no textual
conflicts but results in undesired interference - causing unexpected program
behavior at runtime. To address this issue, we propose a technique that
explores the use of static analysis to detect interference when merging
contributions from two developers. We evaluate our technique using a dataset of
99 experimental units extracted from merge scenarios. The results provide
evidence that our technique presents significant interference detection
capability. It outperforms, in terms of F1 score and recall, previous methods
that rely on dynamic analysis for detecting semantic conflicts, but these show
better precision. Our technique precision is comparable to the ones observed in
other studies that also leverage static analysis or use theorem proving
techniques to detect semantic conflicts, albeit with significantly improved
overall performance.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04270" title="Abstract">arXiv:2310.04270</a> [<a href="/pdf/2310.04270" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Evaluation of Large Language Models on Benchmark  Biomedical Text Processing Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahan%2C+I">Israt Jahan</a>, 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jimmy Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2306.04504">arXiv:2306.04504</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, Large Language Models (LLM) have demonstrated impressive capability
to solve a wide range of tasks. However, despite their success across various
tasks, no prior work has investigated their capability in the biomedical domain
yet. To this end, this paper aims to evaluate the performance of LLMs on
benchmark biomedical tasks. For this purpose, we conduct a comprehensive
evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.
To the best of our knowledge, this is the first work that conducts an extensive
evaluation and comparison of various LLMs in the biomedical domain.
Interestingly, we find based on our evaluation that in biomedical datasets that
have smaller training sets, zero-shot LLMs even outperform the current
state-of-the-art fine-tuned biomedical models. This suggests that pretraining
on large text corpora makes LLMs quite specialized even in the biomedical
domain. We also find that not a single LLM can outperform other LLMs in all
tasks, with the performance of different LLMs may vary depending on the task.
While their performance is still quite poor in comparison to the biomedical
models that were fine-tuned on large training sets, our findings demonstrate
that LLMs have the potential to be a valuable tool for various biomedical tasks
that lack large annotated data.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04271" title="Abstract">arXiv:2310.04271</a> [<a href="/pdf/2310.04271" title="Download PDF">pdf</a>, <a href="/format/2310.04271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Servoing by Recombining Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Argus%2C+M">Max Argus</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Abhijeet Nayak</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchner%2C+M">Martin B&#xfc;chner</a>, 
<a href="/search/cs?searchtype=author&query=Galesso%2C+S">Silvio Galesso</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>, 
<a href="/search/cs?searchtype=author&query=Brox%2C+T">Thomas Brox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="http://compservo.cs.uni-freiburg.de">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Learning-based manipulation policies from image inputs often show weak task
transfer capabilities. In contrast, visual servoing methods allow efficient
task transfer in high-precision scenarios while requiring only a few
demonstrations. In this work, we present a framework that formulates the visual
servoing task as graph traversal. Our method not only extends the robustness of
visual servoing, but also enables multitask capability based on a few
task-specific demonstrations. We construct demonstration graphs by splitting
existing demonstrations and recombining them. In order to traverse the
demonstration graph in the inference case, we utilize a similarity function
that helps select the best demonstration for a specific task. This enables us
to compute the shortest path through the graph. Ultimately, we show that
recombining demonstrations leads to higher task-respective success. We present
extensive simulation and real-world experimental results that demonstrate the
efficacy of our approach.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04276" title="Abstract">arXiv:2310.04276</a> [<a href="/pdf/2310.04276" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From task structures to world models: What do LLMs know?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+I">Ilker Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+L+A">L.A. Paul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">In what sense does a large language model have knowledge? The answer to this
question extends beyond the capabilities of a particular AI system, and
challenges our assumptions about the nature of knowledge and intelligence. We
answer by granting LLMs "instrumental knowledge"; knowledge defined by a
certain set of abilities. We then ask how such knowledge is related to the more
ordinary, "worldly" knowledge exhibited by human agents, and explore this in
terms of the degree to which instrumental knowledge can be said to incorporate
the structured world models of cognitive science. We discuss ways LLMs could
recover degrees of worldly knowledge, and suggest such recovery will be
governed by an implicit, resource-rational tradeoff between world models and
task demands.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04283" title="Abstract">arXiv:2310.04283</a> [<a href="/pdf/2310.04283" title="Download PDF">pdf</a>, <a href="/format/2310.04283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Error-Propagation of Inexact Deflation for Principal Component  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+F">Fangshuo Liao</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+L">Junhyung Lyle Kim</a>, 
<a href="/search/cs?searchtype=author&query=Barnum%2C+C">Cruz Barnum</a>, 
<a href="/search/cs?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Principal Component Analysis (PCA) is a popular tool in data analysis,
especially when the data is high-dimensional. PCA aims to find subspaces,
spanned by the so-called \textit{principal components}, that best explain the
variance in the dataset. The deflation method is a popular meta-algorithm --
used to discover such subspaces -- that sequentially finds individual principal
components, starting from the most important one and working its way towards
the less important ones. However, due to its sequential nature, the numerical
error introduced by not estimating principal components exactly -- e.g., due to
numerical approximations through this process -- propagates, as deflation
proceeds. To the best of our knowledge, this is the first work that
mathematically characterizes the error propagation of the inexact deflation
method, and this is the key contribution of this paper. We provide two main
results: $i)$ when the sub-routine for finding the leading eigenvector is
generic, and $ii)$ when power iteration is used as the sub-routine. In the
latter case, the additional directional information from power iteration allows
us to obtain a tighter error bound than the analysis of the sub-routine
agnostic case. As an outcome, we provide explicit characterization on how the
error progresses and affects subsequent principal component estimations for
this fundamental problem.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04284" title="Abstract">arXiv:2310.04284</a> [<a href="/pdf/2310.04284" title="Download PDF">pdf</a>, <a href="/format/2310.04284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Finite Element Method Approach for Trajectory Generation via  Time-Optimal Control and Model Predictive Control Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Solano-Castellanos%2C+J+A">Jose A. Solano-Castellanos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper a framework for solving the time optimal control (TOC) using
Galerkin's Weighted Residuals Method (GWRM) and Sequential Convex Programming
(SCP) is proposed. The proposed method solves the two-point boundary value
problem, avoiding the use of shooting methods that rely heavily on the
appropriate initialization of the adjoint state and optimal time. Since TOC
yields an open-loop controller, a Model Predictive Control (MPC) scheme is
employed to track both the optimal trajectory and controller, allowing the
system to reject disturbances. The approach is validated using the Dubins' car
dynamics for optimal time trajectory generation.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04285" title="Abstract">arXiv:2310.04285</a> [<a href="/pdf/2310.04285" title="Download PDF">pdf</a>, <a href="/format/2310.04285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Robustness via Score-Based Adversarial Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kollovieh%2C+M">Marcel Kollovieh</a>, 
<a href="/search/cs?searchtype=author&query=Gosch%2C+L">Lukas Gosch</a>, 
<a href="/search/cs?searchtype=author&query=Scholten%2C+Y">Yan Scholten</a>, 
<a href="/search/cs?searchtype=author&query=Lienen%2C+M">Marten Lienen</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Most adversarial attacks and defenses focus on perturbations within small
$\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture all
relevant semantic-preserving perturbations, and hence, the scope of robustness
evaluations is limited. In this work, we introduce Score-Based Adversarial
Generation (ScoreAG), a novel framework that leverages the advancements in
score-based generative models to generate adversarial examples beyond
$\ell_p$-norm constraints, so-called unrestricted adversarial examples,
overcoming their limitations. Unlike traditional methods, ScoreAG maintains the
core semantics of images while generating realistic adversarial examples,
either by transforming existing images or synthesizing new ones entirely from
scratch. We further exploit the generative capability of ScoreAG to purify
images, empirically enhancing the robustness of classifiers. Our extensive
empirical evaluation demonstrates that ScoreAG matches the performance of
state-of-the-art attacks and defenses across multiple benchmarks. This work
highlights the importance of investigating adversarial examples bounded by
semantics rather than $\ell_p$-norm constraints. ScoreAG represents an
important step towards more encompassing robustness assessments.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04286" title="Abstract">arXiv:2310.04286</a> [<a href="/pdf/2310.04286" title="Download PDF">pdf</a>, <a href="/format/2310.04286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-constrained symbolic model discovery for polyconvex  incompressible hyperelastic materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+B">Bahador Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">WaiChing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Soft Condensed Matter (cond-mat.soft)

</div>
<p class="mathjax">We present a machine learning framework capable of consistently inferring
mathematical expressions of the hyperelastic energy functionals for
incompressible materials from sparse experimental data and physical laws. To
achieve this goal, we propose a polyconvex neural additive model (PNAM) that
enables us to express the hyperelasticity model in a learnable feature space
while enforcing polyconvexity. An upshot of this feature space obtained via
PNAM is that (1) it is spanned by a set univariate basis that can be
re-parametrized with a more complex mathematical form, and (2) the resultant
elasticity model is guaranteed to fulfill the polyconvexity, which ensures that
the acoustic tensor remains elliptic for any deformation. To further improve
the interpretability, we use genetic programming to convert each univariate
basis into a compact mathematical expression. The resultant multi-variable
mathematical models obtained from this proposed framework are not only more
interpretable but are also proven to fulfill physical laws. By controlling the
compactness of the learned symbolic form, the machine learning-generated
mathematical model also requires fewer arithmetic operations than the deep
neural network counterparts during deployment. This latter attribute is crucial
for scaling large-scale simulations where the constitutive responses of every
integration point must be updated within each incremental time step. We compare
our proposed model discovery framework against other state-of-the-art
alternatives to assess the robustness and efficiency of the training algorithms
and examine the trade-off between interpretability, accuracy, and precision of
the learned symbolic hyperelasticity models obtained from different approaches.
Our numerical results suggest that our approach extrapolates well outside the
training data regime due to the precise incorporation of physics-based
knowledge.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04288" title="Abstract">arXiv:2310.04288</a> [<a href="/pdf/2310.04288" title="Download PDF">pdf</a>, <a href="/format/2310.04288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Searching for Optimal Runtime Assurance via Reachability and  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Miller%2C+K">Kristina Miller</a>, 
<a href="/search/eess?searchtype=author&query=Zeitler%2C+C+K">Christopher K. Zeitler</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+W">William Shen</a>, 
<a href="/search/eess?searchtype=author&query=Hobbs%2C+K">Kerianne Hobbs</a>, 
<a href="/search/eess?searchtype=author&query=Mitra%2C+S">Sayan Mitra</a>, 
<a href="/search/eess?searchtype=author&query=Schierman%2C+J">John Schierman</a>, 
<a href="/search/eess?searchtype=author&query=Viswanathan%2C+M">Mahesh Viswanathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">A runtime assurance system (RTA) for a given plant enables the exercise of an
untrusted or experimental controller while assuring safety with a backup (or
safety) controller. The relevant computational design problem is to create a
logic that assures safety by switching to the safety controller as needed,
while maximizing some performance criteria, such as the utilization of the
untrusted controller. Existing RTA design strategies are well-known to be
overly conservative and, in principle, can lead to safety violations. In this
paper, we formulate the optimal RTA design problem and present a new approach
for solving it. Our approach relies on reward shaping and reinforcement
learning. It can guarantee safety and leverage machine learning technologies
for scalability. We have implemented this algorithm and present experimental
results comparing our approach with state-of-the-art reachability and
simulation-based RTA approaches in a number of scenarios using aircraft models
in 3D space with complex safety requirements. Our approach can guarantee safety
while increasing utilization of the experimental controller over existing
approaches.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04289" title="Abstract">arXiv:2310.04289</a> [<a href="/pdf/2310.04289" title="Download PDF">pdf</a>, <a href="/format/2310.04289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dataset of Anatomical Environments for Medical Robots: Modeling  Respiratory Deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fried%2C+I">Inbar Fried</a>, 
<a href="/search/cs?searchtype=author&query=Hoelscher%2C+J">Janine Hoelscher</a>, 
<a href="/search/cs?searchtype=author&query=Akulian%2C+J+A">Jason A. Akulian</a>, 
<a href="/search/cs?searchtype=author&query=Alterovitz%2C+R">Ron Alterovitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Anatomical models of a medical robot's environment can significantly help
guide design and development of a new robotic system. These models can be used
for benchmarking motion planning algorithms, evaluating controllers, optimizing
mechanical design choices, simulating procedures, and even as resources for
data generation. Currently, the time-consuming task of generating these
environments is repeatedly performed by individual research groups and rarely
shared broadly. This not only leads to redundant efforts, but also makes it
challenging to compare systems and algorithms accurately. In this work, we
present a collection of clinically-relevant anatomical environments for medical
robots operating in the lungs. Since anatomical deformation is a fundamental
challenge for medical robots operating in the lungs, we describe a way to model
respiratory deformation in these environments using patient-derived data. We
share the environments and deformation data publicly by adding them to the
Medical Robotics Anatomical Dataset (Med-RAD), our public dataset of anatomical
environments for medical robots.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04290" title="Abstract">arXiv:2310.04290</a> [<a href="/pdf/2310.04290" title="Download PDF">pdf</a>, <a href="/format/2310.04290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model order reduction by convex displacement interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cucchiara%2C+S">Simona Cucchiara</a>, 
<a href="/search/math?searchtype=author&query=Iollo%2C+A">Angelo Iollo</a>, 
<a href="/search/math?searchtype=author&query=Taddei%2C+T">Tommaso Taddei</a>, 
<a href="/search/math?searchtype=author&query=Telib%2C+H">Haysam Telib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a nonlinear interpolation technique for parametric fields that
exploits optimal transportation of coherent structures of the solution to
achieve accurate performance. The approach generalizes the nonlinear
interpolation procedure introduced in [Iollo, Taddei, J. Comput. Phys., 2022]
to multi-dimensional parameter domains and to datasets of several snapshots.
Given a library of high-fidelity simulations, we rely on a scalar testing
function and on a point set registration method to identify coherent structures
of the solution field in the form of sorted point clouds. Given a new parameter
value, we exploit a regression method to predict the new point cloud; then, we
resort to a boundary-aware registration technique to define bijective mappings
that deform the new point cloud into the point clouds of the neighboring
elements of the dataset, while preserving the boundary of the domain; finally,
we define the estimate as a weighted combination of modes obtained by composing
the neighboring snapshots with the previously-built mappings. We present
several numerical examples for compressible and incompressible, viscous and
inviscid flows to demonstrate the accuracy of the method. Furthermore, we
employ the nonlinear interpolation procedure to augment the dataset of
simulations for linear-subspace projection-based model reduction: our data
augmentation procedure is designed to reduce offline costs -- which are
dominated by snapshot generation -- of model reduction techniques for nonlinear
advection-dominated problems.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04292" title="Abstract">arXiv:2310.04292</a> [<a href="/pdf/2310.04292" title="Download PDF">pdf</a>, <a href="/format/2310.04292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Foundational Models for Molecular Learning on Large-Scale  Multi-Task Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beaini%2C+D">Dominique Beaini</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shenyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cunha%2C+J+A">Joao Alex Cunha</a>, 
<a href="/search/cs?searchtype=author&query=Moisescu-Pareja%2C+G">Gabriela Moisescu-Pareja</a>, 
<a href="/search/cs?searchtype=author&query=Dymov%2C+O">Oleksandr Dymov</a>, 
<a href="/search/cs?searchtype=author&query=Maddrell-Mander%2C+S">Samuel Maddrell-Mander</a>, 
<a href="/search/cs?searchtype=author&query=McLean%2C+C">Callum McLean</a>, 
<a href="/search/cs?searchtype=author&query=Wenkel%2C+F">Frederik Wenkel</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+L">Luis M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Mohamud%2C+J+H">Jama Hussein Mohamud</a>, 
<a href="/search/cs?searchtype=author&query=Parviz%2C+A">Ali Parviz</a>, 
<a href="/search/cs?searchtype=author&query=Craig%2C+M">Michael Craig</a>, 
<a href="/search/cs?searchtype=author&query=Koziarski%2C+M">Micha&#x142; Koziarski</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiarui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhaocheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gabellini%2C+C">Cristian Gabellini</a>, 
<a href="/search/cs?searchtype=author&query=Klaser%2C+K">Kerstin Klaser</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+J">Josef Dean</a>, 
<a href="/search/cs?searchtype=author&query=Wognum%2C+C">Cas Wognum</a>, 
<a href="/search/cs?searchtype=author&query=Sypetkowski%2C+M">Maciej Sypetkowski</a>, 
<a href="/search/cs?searchtype=author&query=Rabusseau%2C+G">Guillaume Rabusseau</a>, 
<a href="/search/cs?searchtype=author&query=Rabbany%2C+R">Reihaneh Rabbany</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+C">Christopher Morris</a>, 
<a href="/search/cs?searchtype=author&query=Ravanelli%2C+M">Mirco Ravanelli</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+G">Guy Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Tossou%2C+P">Prudencio Tossou</a>, 
<a href="/search/cs?searchtype=author&query=Mary%2C+H">Hadrien Mary</a>, 
<a href="/search/cs?searchtype=author&query=Bois%2C+T">Therence Bois</a>, 
<a href="/search/cs?searchtype=author&query=Fitzgibbon%2C+A">Andrew Fitzgibbon</a>, 
<a href="/search/cs?searchtype=author&query=Banaszewski%2C+B">B&#x142;a&#x17c;ej Banaszewski</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+C">Chad Martin</a>, 
<a href="/search/cs?searchtype=author&query=Masters%2C+D">Dominic Masters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, pre-trained foundation models have enabled significant advancements
in multiple fields. In molecular machine learning, however, where datasets are
often hand-curated, and hence typically small, the lack of datasets with
labeled features, and codebases to manage those datasets, has hindered the
development of foundation models. In this work, we present seven novel datasets
categorized by size into three distinct categories: ToyMix, LargeMix and
UltraLarge. These datasets push the boundaries in both the scale and the
diversity of supervised labels for molecular learning. They cover nearly 100
million molecules and over 3000 sparsely defined tasks, totaling more than 13
billion individual labels of both quantum and biological nature. In comparison,
our datasets contain 300 times more data points than the widely used OGB-LSC
PCQM4Mv2 dataset, and 13 times more than the quantum-only QM1B dataset. In
addition, to support the development of foundational models based on our
proposed datasets, we present the Graphium graph machine learning library which
simplifies the process of building and training molecular machine learning
models for multi-task and multi-level molecular datasets. Finally, we present a
range of baseline results as a starting point of multi-task and multi-level
training on these datasets. Empirically, we observe that performance on
low-resource biological datasets show improvement by also training on large
amounts of quantum data. This indicates that there may be potential in
multi-task and multi-level training of a foundation model and fine-tuning it to
resource-constrained downstream tasks.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04294" title="Abstract">arXiv:2310.04294</a> [<a href="/pdf/2310.04294" title="Download PDF">pdf</a>, <a href="/format/2310.04294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph learning in robotics: a survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pistilli%2C+F">Francesca Pistilli</a>, 
<a href="/search/cs?searchtype=author&query=Averta%2C+G">Giuseppe Averta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep neural networks for graphs have emerged as a powerful tool for learning
on complex non-euclidean data, which is becoming increasingly common for a
variety of different applications. Yet, although their potential has been
widely recognised in the machine learning community, graph learning is largely
unexplored for downstream tasks such as robotics applications. To fully unlock
their potential, hence, we propose a review of graph neural architectures from
a robotics perspective. The paper covers the fundamentals of graph-based
models, including their architecture, training procedures, and applications. It
also discusses recent advancements and challenges that arise in applied
settings, related for example to the integration of perception,
decision-making, and control. Finally, the paper provides an extensive review
of various robotic applications that benefit from learning on graph structures,
such as bodies and contacts modelling, robotic manipulation, action
recognition, fleet motion planning, and many more. This survey aims to provide
readers with a thorough understanding of the capabilities and limitations of
graph neural architectures in robotics, and to highlight potential avenues for
future research.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04295" title="Abstract">arXiv:2310.04295</a> [<a href="/pdf/2310.04295" title="Download PDF">pdf</a>, <a href="/format/2310.04295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Representations for Intervention Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saengkyongam%2C+S">Sorawit Saengkyongam</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+E">Elan Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+N">Niklas Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jonas Peters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The premise of identifiable and causal representation learning is to improve
the current representation learning paradigm in terms of generalizability or
robustness. Despite recent progress in questions of identifiability, more
theoretical results demonstrating concrete advantages of these methods for
downstream tasks are needed. In this paper, we consider the task of
intervention extrapolation: predicting how interventions affect an outcome,
even when those interventions are not observed at training time, and show that
identifiable representations can provide an effective solution to this task
even if the interventions affect the outcome non-linearly. Our setup includes
an outcome Y, observed features X, which are generated as a non-linear
transformation of latent features Z, and exogenous action variables A, which
influence Z. The objective of intervention extrapolation is to predict how
interventions on A that lie outside the training support of A affect Y. Here,
extrapolation becomes possible if the effect of A on Z is linear and the
residual when regressing Z on A has full support. As Z is latent, we combine
the task of intervention extrapolation with identifiable representation
learning, which we call Rep4Ex: we aim to map the observed features X into a
subspace that allows for non-linear extrapolation in A. We show using Wiener's
Tauberian theorem that the hidden representation is identifiable up to an
affine transformation in Z-space, which is sufficient for intervention
extrapolation. The identifiability is characterized by a novel constraint
describing the linearity assumption of A on Z. Based on this insight, we
propose a method that enforces the linear invariance constraint and can be
combined with any type of autoencoder. We validate our theoretical findings
through synthetic experiments and show that our approach succeeds in predicting
the effects of unseen interventions.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04303" title="Abstract">arXiv:2310.04303</a> [<a href="/pdf/2310.04303" title="Download PDF">pdf</a>, <a href="/format/2310.04303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernelization for Counting Problems on Graphs: Preserving the Number of  Minimum Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jansen%2C+B+M+P">Bart M.P. Jansen</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Steenhoven%2C+B">Bart van der Steenhoven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended abstract appears in the proceedings of IPEC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">A kernelization for a parameterized decision problem $\mathcal{Q}$ is a
polynomial-time preprocessing algorithm that reduces any parameterized instance
$(x,k)$ into an instance $(x',k')$ whose size is bounded by a function of $k$
alone and which has the same yes/no answer for $\mathcal{Q}$. Such
preprocessing algorithms cannot exist in the context of counting problems, when
the answer to be preserved is the number of solutions, since this number can be
arbitrarily large compared to $k$. However, we show that for counting minimum
feedback vertex sets of size at most $k$, and for counting minimum dominating
sets of size at most $k$ in a planar graph, there is a polynomial-time
algorithm that either outputs the answer or reduces to an instance $(G',k')$ of
size polynomial in $k$ with the same number of minimum solutions. This shows
that a meaningful theory of kernelization for counting problems is possible and
opens the door for future developments. Our algorithms exploit that if the
number of solutions exceeds $2^{\mathsf{poly}(k)}$, the size of the input is
exponential in terms of $k$ so that the running time of a parameterized
counting algorithm can be bounded by $\mathsf{poly}(n)$. Otherwise, we can use
gadgets that slightly increase $k$ to represent choices among $2^{O(k)}$
options by only $\mathsf{poly}(k)$ vertices.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04304" title="Abstract">arXiv:2310.04304</a> [<a href="/pdf/2310.04304" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coding by Design: GPT-4 empowers Agile Model Driven Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadik%2C+A+R">Ahmed R. Sadik</a>, 
<a href="/search/cs?searchtype=author&query=Brulin%2C+S">Sebastian Brulin</a>, 
<a href="/search/cs?searchtype=author&query=Olhofer%2C+M">Markus Olhofer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Multiagent Systems (cs.MA); Programming Languages (cs.PL)

</div>
<p class="mathjax">Generating code from a natural language using Large Language Models (LLMs)
such as ChatGPT, seems groundbreaking. Yet, with more extensive use, it's
evident that this approach has its own limitations. The inherent ambiguity of
natural language presents challenges for complex software designs. Accordingly,
our research offers an Agile Model-Driven Development (MDD) approach that
enhances code auto-generation using OpenAI's GPT-4. Our work emphasizes
"Agility" as a significant contribution to the current MDD method, particularly
when the model undergoes changes or needs deployment in a different programming
language. Thus, we present a case-study showcasing a multi-agent simulation
system of an Unmanned Vehicle Fleet. In the first and second layer of our
approach, we constructed a textual representation of the case-study using
Unified Model Language (UML) diagrams. In the next layer, we introduced two
sets of constraints that minimize model ambiguity. Object Constraints Language
(OCL) is applied to fine-tune the code constructions details, while FIPA
ontology is used to shape communication semantics and protocols. Ultimately,
leveraging GPT-4, our last layer auto-generates code in both Java and Python.
The Java code is deployed within the JADE framework, while the Python code is
deployed in PADE framework. Concluding our research, we engaged in a
comprehensive evaluation of the generated code. From a behavioural standpoint,
the auto-generated code aligned perfectly with the expected UML sequence
diagram. Structurally, we compared the complexity of code derived from UML
diagrams constrained solely by OCL to that influenced by both OCL and
FIPA-ontology. Results indicate that ontology-constrained model produce
inherently more intricate code, but it remains manageable and low-risk for
further testing and maintenance.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04306" title="Abstract">arXiv:2310.04306</a> [<a href="/pdf/2310.04306" title="Download PDF">pdf</a>, <a href="/format/2310.04306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards A Robust Group-level Emotion Recognition via Uncertainty-Aware  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qirong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaohua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenming Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Group-level emotion recognition (GER) is an inseparable part of human
behavior analysis, aiming to recognize an overall emotion in a multi-person
scene. However, the existing methods are devoted to combing diverse emotion
cues while ignoring the inherent uncertainties under unconstrained
environments, such as congestion and occlusion occurring within a group.
Additionally, since only group-level labels are available, inconsistent emotion
predictions among individuals in one group can confuse the network. In this
paper, we propose an uncertainty-aware learning (UAL) method to extract more
robust representations for GER. By explicitly modeling the uncertainty of each
individual, we utilize stochastic embedding drawn from a Gaussian distribution
instead of deterministic point embedding. This representation captures the
probabilities of different emotions and generates diverse predictions through
this stochasticity during the inference stage. Furthermore,
uncertainty-sensitive scores are adaptively assigned as the fusion weights of
individuals' face within each group. Moreover, we develop an image enhancement
module to enhance the model's robustness against severe noise. The overall
three-branch model, encompassing face, object, and scene component, is guided
by a proportional-weighted fusion strategy and integrates the proposed
uncertainty-aware method to produce the final group-level output. Experimental
results demonstrate the effectiveness and generalization ability of our method
across three widely used databases.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04311" title="Abstract">arXiv:2310.04311</a> [<a href="/pdf/2310.04311" title="Download PDF">pdf</a>, <a href="/format/2310.04311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Deep Joint Source-Channel Coding with Decoder-Only Side  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+S+F">Selim F. Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Ozyilkan%2C+E">Ezgi Ozyilkan</a>, 
<a href="/search/cs?searchtype=author&query=Gunduz%2C+D">Deniz Gunduz</a>, 
<a href="/search/cs?searchtype=author&query=Erkip%2C+E">Elza Erkip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider low-latency image transmission over a noisy wireless channel when
correlated side information is present only at the receiver side (the Wyner-Ziv
scenario). In particular, we are interested in developing practical schemes
using a data-driven joint source-channel coding (JSCC) approach, which has been
previously shown to outperform conventional separation-based approaches in the
practical finite blocklength regimes, and to provide graceful degradation with
channel quality. We propose a novel neural network architecture that
incorporates the decoder-only side information at multiple stages at the
receiver side. Our results demonstrate that the proposed method succeeds in
integrating the side information, yielding improved performance at all channel
noise levels in terms of the various distortion criteria considered here,
especially at low channel signal-to-noise ratios (SNRs) and small bandwidth
ratios (BRs). We also provide the source code of the proposed method to enable
further research and reproducibility of the results.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04313" title="Abstract">arXiv:2310.04313</a> [<a href="/pdf/2310.04313" title="Download PDF">pdf</a>, <a href="/format/2310.04313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Scale Korean Text Dataset for Classifying Biased Speech in  Real-World Online Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dasol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jooyoung Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Eunsun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jinwoo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Heejune Park</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Dongbin Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the growth of online services, the need for advanced text classification
algorithms, such as sentiment analysis and biased text detection, has become
increasingly evident. The anonymous nature of online services often leads to
the presence of biased and harmful language, posing challenges to maintaining
the health of online communities. This phenomenon is especially relevant in
South Korea, where large-scale hate speech detection algorithms have not yet
been broadly explored. In this paper, we introduce a new comprehensive,
large-scale dataset collected from a well-known South Korean SNS platform. Our
proposed dataset provides annotations including (1) Preferences, (2)
Profanities, and (3) Nine types of Bias for the text samples, enabling
multi-task learning for simultaneous classification of user-generated texts.
Leveraging state-of-the-art BERT-based language models, our approach surpasses
human-level accuracy across diverse classification tasks, as measured by
various metrics. Beyond academic contributions, our work can provide practical
solutions for real-world hate speech and bias mitigation, contributing directly
to the improvement of online community health. Our work provides a robust
foundation for future research aiming to improve the quality of online
discourse and foster societal well-being. All source codes and datasets are
publicly accessible at https://github.com/Dasol-Choi/KoMultiText.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04314" title="Abstract">arXiv:2310.04314</a> [<a href="/pdf/2310.04314" title="Download PDF">pdf</a>, <a href="/format/2310.04314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Graph Inference with Limited Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianglin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yue Bai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yun Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Latent graph inference (LGI) aims to jointly learn the underlying graph
structure and node representations from data features. However, existing LGI
methods commonly suffer from the issue of supervision starvation, where massive
edge weights are learned without semantic supervision and do not contribute to
the training loss. Consequently, these supervision-starved weights, which may
determine the predictions of testing samples, cannot be semantically optimal,
resulting in poor generalization. In this paper, we observe that this issue is
actually caused by the graph sparsification operation, which severely destroys
the important connections established between pivotal nodes and labeled ones.
To address this, we propose to restore the corrupted affinities and replenish
the missed supervision for better LGI. The key challenge then lies in
identifying the critical nodes and recovering the corrupted affinities. We
begin by defining the pivotal nodes as $k$-hop starved nodes, which can be
identified based on a given adjacency matrix. Considering the high
computational burden, we further present a more efficient alternative inspired
by CUR matrix decomposition. Subsequently, we eliminate the starved nodes by
reconstructing the destroyed connections. Extensive experiments on
representative benchmarks demonstrate that reducing the starved nodes
consistently improves the performance of state-of-the-art LGI methods,
especially under extremely limited supervision (6.12% improvement on Pubmed
with a labeling rate of only 0.3%).
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04315" title="Abstract">arXiv:2310.04315</a> [<a href="/pdf/2310.04315" title="Download PDF">pdf</a>, <a href="/format/2310.04315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fostering Enterprise Conversations Around Data on Collaboration  Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+A">Arjun Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Brehmer%2C+M">Matthew Brehmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In enterprise organizations, data-driven decision making processes include
the use of business intelligence dashboards and collaborative deliberation on
communication platforms such as Slack or Teams. However, apart from those in
data analyst roles, there is shallow engagement with dashboard content due to
insufficient guidance, context, or access. Through a co-design study with nine
enterprise professionals who use dashboard content to communicate with their
colleagues, we identified design requirements for sharing selections from
dashboards as interactive snapshots on collaboration platforms. We then
developed Philo, an interactive demonstration environment centered around the
template-based retargeting of dashboard content. Using Philo as a design probe,
we interviewed our co-design participants and six additional data
professionals, ultimately arriving at a set of design guidelines for fostering
conversations around data in enterprise settings.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04323" title="Abstract">arXiv:2310.04323</a> [<a href="/pdf/2310.04323" title="Download PDF">pdf</a>, <a href="/format/2310.04323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjustable Robust Reinforcement Learning for Online 3D Bin Packing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuxin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Fangzhen Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Designing effective policies for the online 3D bin packing problem (3D-BPP)
has been a long-standing challenge, primarily due to the unpredictable nature
of incoming box sequences and stringent physical constraints. While current
deep reinforcement learning (DRL) methods for online 3D-BPP have shown
promising results in optimizing average performance over an underlying box
sequence distribution, they often fail in real-world settings where some
worst-case scenarios can materialize. Standard robust DRL algorithms tend to
overly prioritize optimizing the worst-case performance at the expense of
performance under normal problem instance distribution. To address these
issues, we first introduce a permutation-based attacker to investigate the
practical robustness of both DRL-based and heuristic methods proposed for
solving online 3D-BPP. Then, we propose an adjustable robust reinforcement
learning (AR2L) framework that allows efficient adjustment of robustness
weights to achieve the desired balance of the policy's performance in average
and worst-case environments. Specifically, we formulate the objective function
as a weighted sum of expected and worst-case returns, and derive the lower
performance bound by relating to the return under a mixture dynamics. To
realize this lower bound, we adopt an iterative procedure that searches for the
associated mixture dynamics and improves the corresponding policy. We integrate
this procedure into two popular robust adversarial algorithms to develop the
exact and approximate AR2L algorithms. Experiments demonstrate that AR2L is
versatile in the sense that it improves policy robustness while maintaining an
acceptable level of performance for the nominal case.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04327" title="Abstract">arXiv:2310.04327</a> [<a href="/pdf/2310.04327" title="Download PDF">pdf</a>, <a href="/format/2310.04327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Program Synthesis with Best-First Bottom-Up Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ameen%2C+S">Saqib Ameen</a>, 
<a href="/search/cs?searchtype=author&query=Lelis%2C+L+H+S">Levi H. S. Lelis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the Journal of Artificial Intelligence Research (JAIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Cost-guided bottom-up search (BUS) algorithms use a cost function to guide
the search to solve program synthesis tasks. In this paper, we show that
current state-of-the-art cost-guided BUS algorithms suffer from a common
problem: they can lose useful information given by the model and fail to
perform the search in a best-first order according to a cost function. We
introduce a novel best-first bottom-up search algorithm, which we call Bee
Search, that does not suffer information loss and is able to perform
cost-guided bottom-up synthesis in a best-first manner. Importantly, Bee Search
performs best-first search with respect to the generation of programs, i.e., it
does not even create in memory programs that are more expensive than the
solution program. It attains best-first ordering with respect to generation by
performing a search in an abstract space of program costs. We also introduce a
new cost function that better uses the information provided by an existing cost
model. Empirical results on string manipulation and bit-vector tasks show that
Bee Search can outperform existing cost-guided BUS approaches when employing
more complex domain-specific languages (DSLs); Bee Search and previous
approaches perform equally well with simpler DSLs. Furthermore, our new cost
function with Bee Search outperforms previous cost functions on string
manipulation tasks.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04328" title="Abstract">arXiv:2310.04328</a> [<a href="/pdf/2310.04328" title="Download PDF">pdf</a>, <a href="/format/2310.04328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Losses for Decision-Focused Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schutte%2C+N">Noah Schutte</a>, 
<a href="/search/cs?searchtype=author&query=Postek%2C+K">Krzysztof Postek</a>, 
<a href="/search/cs?searchtype=author&query=Yorke-Smith%2C+N">Neil Yorke-Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Optimization models used to make discrete decisions often contain uncertain
parameters that are context-dependent and are estimated through prediction. To
account for the quality of the decision made based on the prediction,
decision-focused learning (end-to-end predict-then-optimize) aims at training
the predictive model to minimize regret, i.e., the loss incurred by making a
suboptimal decision. Despite the challenge of this loss function being possibly
non-convex and in general non-differentiable, effective gradient-based learning
approaches have been proposed to minimize the expected loss, using the
empirical loss as a surrogate. However, empirical regret can be an ineffective
surrogate because the uncertainty in the optimization model makes the empirical
regret unequal to the expected regret in expectation. To illustrate the impact
of this inequality, we evaluate the effect of aleatoric and epistemic
uncertainty on the accuracy of empirical regret as a surrogate. Next, we
propose three robust loss functions that more closely approximate expected
regret. Experimental results show that training two state-of-the-art
decision-focused learning approaches using robust regret losses improves
test-sample empirical regret in general while keeping computational time
equivalent relative to the number of training epochs.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04329" title="Abstract">arXiv:2310.04329</a> [<a href="/pdf/2310.04329" title="Download PDF">pdf</a>, <a href="/format/2310.04329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pika: Empowering Non-Programmers to Author Executable Governance  Policies in Online Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+N">Nicolas Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Rukanskait%C4%97%2C+J">Julija Rukanskait&#x117;</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Internet users have formed a wide array of online communities with nuanced
and diverse community goals and norms. However, most online platforms only
offer a limited set of governance models in their software infrastructure and
leave little room for customization. Consequently, technical proficiency
becomes a prerequisite for online communities to build governance policies in
code, excluding non-programmers from participation in designing community
governance. In this paper, we present Pika, a system that empowers
non-programmers to author a wide range of executable governance policies. At
its core, Pika incorporates a declarative language that decomposes governance
policies into modular components, thereby facilitating expressive policy
authoring through a user-friendly, form-based web interface. Our user studies
with 17 participants show that Pika can empower non-programmers to author
governance policies approximately 2.5 times faster than programmers who author
in code. We also provide insights about Pika's expressivity in supporting
diverse policies that online communities want.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04331" title="Abstract">arXiv:2310.04331</a> [<a href="/pdf/2310.04331" title="Download PDF">pdf</a>, <a href="/format/2310.04331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game, Set, and Conflict: Evaluating Conflict and Game Frames in Indian  Election News Coverage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chebrolu%2C+T">Tejasvi Chebrolu</a>, 
<a href="/search/cs?searchtype=author&query=Chowdary%2C+R">Rohan Chowdary</a>, 
<a href="/search/cs?searchtype=author&query=Vardhan%2C+N+H">N Harsha Vardhan</a>, 
<a href="/search/cs?searchtype=author&query=Kumaraguru%2C+P">Ponnurangam Kumaraguru</a>, 
<a href="/search/cs?searchtype=author&query=Rajadesingan%2C+A">Ashwin Rajadesingan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICWSM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">News frames refer to how journalists organize and present information to
convey a particular message or perspective to their readers. When covering
elections, these frames shape how the public perceives electoral issues and
events. This study examines how news frames, especially conflict and game
frames, were employed by news organizations in India to cover the 2014 and 2019
general elections. We analyzed how the frames varied temporally, by region, and
by the party being featured in the articles. Key findings include (i) conflict
and games frames are employed more often in highly electorally consequential
states (higher legislative seats) than in other states (ii) articles featuring
challenger parties are more likely to have conflict and game frame articles
than those featuring incumbent parties (iii) the national parties (BJP,
Bharatiya Janata Party) and (INC, Indian National Congress) disproportionately
feature in articles having conflict frames. Overall, our analysis highlights
the evolving nature of election campaigns and how conflict and game frames play
a major part in them.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04332" title="Abstract">arXiv:2310.04332</a> [<a href="/pdf/2310.04332" title="Download PDF">pdf</a>, <a href="/format/2310.04332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Parameterized Complexity of Multiway Near-Separator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jansen%2C+B+M+P">Bart M. P. Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Shivesh K. Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference version to appear at the International Symposium on Parameterized and Exact Computation (IPEC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study a new graph separation problem called Multiway Near-Separator. Given
an undirected graph $G$, integer $k$, and terminal set $T \subseteq V(G)$, it
asks whether there is a vertex set $S \subseteq V(G) \setminus T$ of size at
most $k$ such that in graph $G-S$, no pair of distinct terminals can be
connected by two pairwise internally vertex-disjoint paths. Hence each terminal
pair can be separated in $G-S$ by removing at most one vertex. The problem is
therefore a generalization of (Node) Multiway Cut, which asks for a vertex set
for which each terminal is in a different component of $G-S$. We develop a
fixed-parameter tractable algorithm for Multiway Near-Separator running in time
$2^{O(k \log k)} * n^{O(1)}$. Our algorithm is based on a new pushing lemma for
solutions with respect to important separators, along with two problem-specific
ingredients. The first is a polynomial-time subroutine to reduce the number of
terminals in the instance to a polynomial in the solution size $k$ plus the
size of a given suboptimal solution. The second is a polynomial-time algorithm
that, given a graph $G$ and terminal set $T \subseteq V(G)$ along with a single
vertex $x \in V(G)$ that forms a multiway near-separator, computes a
14-approximation for the problem of finding a multiway near-separator not
containing $x$.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04334" title="Abstract">arXiv:2310.04334</a> [<a href="/pdf/2310.04334" title="Download PDF">pdf</a>, <a href="/format/2310.04334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saliency-Guided Hidden Associative Replay for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qilong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Do not distribute
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Continual Learning is a burgeoning domain in next-generation AI, focusing on
training neural networks over a sequence of tasks akin to human learning. While
CL provides an edge over traditional supervised learning, its central challenge
remains to counteract catastrophic forgetting and ensure the retention of prior
tasks during subsequent learning. Amongst various strategies to tackle this,
replay based methods have emerged as preeminent, echoing biological memory
mechanisms. However, these methods are memory intensive, often preserving
entire data samples, an approach inconsistent with humans selective memory
retention of salient experiences. While some recent works have explored the
storage of only significant portions of data in episodic memory, the inherent
nature of partial data necessitates innovative retrieval mechanisms. Current
solutions, like inpainting, approximate full data reconstruction from partial
cues, a method that diverges from genuine human memory processes. Addressing
these nuances, this paper presents the Saliency Guided Hidden Associative
Replay for Continual Learning. This novel framework synergizes associative
memory with replay-based strategies. SHARC primarily archives salient data
segments via sparse memory encoding. Importantly, by harnessing associative
memory paradigms, it introduces a content focused memory retrieval mechanism,
promising swift and near-perfect recall, bringing CL a step closer to authentic
human memory processes. Extensive experimental results demonstrate the
effectiveness of our proposed method for various continual learning tasks.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04342" title="Abstract">arXiv:2310.04342</a> [<a href="/pdf/2310.04342" title="Download PDF">pdf</a>, <a href="/format/2310.04342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minerva: Decentralized Collaborative Query Processing over  InterPlanetary File System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhiyi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bowen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Q">Qianlan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuedong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Data silos create barriers in accessing and utilizing data dispersed over
networks. Directly sharing data easily suffers from the long downloading time,
the single point failure and the untraceable data usage. In this paper, we
present Minerva, a peer-to-peer cross-cluster data query system based on
InterPlanetary File System (IPFS). Minerva makes use of the distributed Hash
table (DHT) lookup to pinpoint the locations that store content chunks. We
theoretically model the DHT query delay and introduce the fat Merkle tree
structure as well as the DHT caching to reduce it. We design the query plan for
read and write operations on top of Apache Drill that enables the collaborative
query with decentralized workers. We conduct comprehensive experiments on
Minerva, and the results show that Minerva achieves up to $2.08 \times$ query
performance acceleration compared to the original IPFS data query, and could
complete data analysis queries on the Internet-like environments within an
average latency of $0.615$ second. With collaborative query, Minerva could
perform up to $1.39 \times$ performance acceleration than centralized query
with raw data shipment.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04343" title="Abstract">arXiv:2310.04343</a> [<a href="/pdf/2310.04343" title="Download PDF">pdf</a>, <a href="/format/2310.04343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Geometry Guided Protein Sequence and Backbone Structure  Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenqiao Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenxian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Proteins are macromolecules responsible for essential functions in almost all
living organisms. Designing reasonable proteins with desired functions is
crucial. A protein's sequence and structure are strongly correlated and they
together determine its function. In this paper, we propose NAEPro, a model to
jointly design Protein sequence and structure based on automatically detected
functional sites. NAEPro is powered by an interleaving network of attention and
equivariant layers, which can capture global correlation in a whole sequence
and local influence from nearest amino acids in three dimensional (3D) space.
Such an architecture facilitates effective yet economic message passing at two
levels. We evaluate our model and several strong baselines on two protein
datasets, $\beta$-lactamase and myoglobin. Experimental results show that our
model consistently achieves the highest amino acid recovery rate, TM-score, and
the lowest RMSD among all competitors. These findings prove the capability of
our model to design protein sequences and structures that closely resemble
their natural counterparts. Furthermore, in-depth analysis further confirms our
model's ability to generate highly effective proteins capable of binding to
their target metallocofactors. We provide code, data and models in Github.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04346" title="Abstract">arXiv:2310.04346</a> [<a href="/pdf/2310.04346" title="Download PDF">pdf</a>, <a href="/format/2310.04346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Serverless Architecture for Efficient and Scalable Monte Carlo Markov  Chain Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castagna%2C+F">Fabio Castagna</a>, 
<a href="/search/cs?searchtype=author&query=Trombetta%2C+A">Alberto Trombetta</a>, 
<a href="/search/cs?searchtype=author&query=Landoni%2C+M">Marco Landoni</a>, 
<a href="/search/cs?searchtype=author&query=Andreon%2C+S">Stefano Andreon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures. Appeared in ICCBDC '23: Proceedings of the 2023 7th International Conference on Cloud and Big Data Computing - August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM)

</div>
<p class="mathjax">Computer power is a constantly increasing demand in scientific data analyses,
in particular when Markov Chain Monte Carlo (MCMC) methods are involved, for
example for estimating integral functions or Bayesian posterior probabilities.
In this paper, we describe the benefits of a parallel computation of MCMC using
a cloud-based, serverless architecture: first, the computation time can be
spread over thousands of processes, hence greatly reducing the time the user
should wait to have its computation completed. Second, the overhead time
required for running in parallel several processes is minor and grows
logarithmically with respect to the number of processes. Third, the serverless
approach does not require time-consuming efforts for maintaining and updating
the computing infrastructure when/if the number of walkers increases or for
adapting the code to optimally use the infrastructure. The benefits are
illustrated with the computation of the posterior probability distribution of a
real astronomical analysis.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04349" title="Abstract">arXiv:2310.04349</a> [<a href="/pdf/2310.04349" title="Download PDF">pdf</a>, <a href="/format/2310.04349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Grasp: from Somewhere to Anywhere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%A9l%C3%A9non%2C+F">Fran&#xe7;ois H&#xe9;l&#xe9;non</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+J">Johann Huber</a>, 
<a href="/search/cs?searchtype=author&query=Amar%2C+F+B">Fa&#xef;z Ben Amar</a>, 
<a href="/search/cs?searchtype=author&query=Doncieux%2C+S">St&#xe9;phane Doncieux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Robotic grasping is still a partially solved, multidisciplinary problem where
data-driven techniques play an increasing role. The sparse nature of rewards
make the automatic generation of grasping datasets challenging, especially for
unconventional morphologies or highly actuated end-effectors. Most approaches
for obtaining large-scale datasets rely on numerous human-provided
demonstrations or heavily engineered solutions that do not scale well. Recent
advances in Quality-Diversity (QD) methods have investigated how to learn
object grasping at a specific pose with different robot morphologies. The
present work introduces a pipeline for adapting QD-generated trajectories to
new object poses. Using an RGB-D data stream, the vision pipeline first detects
the targeted object, predicts its 6-DOF pose, and finally tracks it. An
automatically generated reach-and-grasp trajectory can then be adapted by
projecting it relatively to the object frame. Hundreds of trajectories have
been deployed into the real world on several objects and with different robotic
setups: a Franka Research 3 with a parallel gripper and a UR5 with a dexterous
SIH Schunk hand. The transfer ratio obtained when applying transformation to
the object pose matches the one obtained when the object pose matches the
simulation, demonstrating the efficiency of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04353" title="Abstract">arXiv:2310.04353</a> [<a href="/pdf/2310.04353" title="Download PDF">pdf</a>, <a href="/format/2310.04353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language-Agent Approach to Formal Theorem-Proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+A">Amitayush Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yeming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
<p class="mathjax">Language agents, which use a large language model (LLM) capable of in-context
learning to interact with an external environment, have recently emerged as a
promising approach to control tasks. We present the first language-agent
approach to formal theorem-proving. Our method, COPRA, uses a high-capacity,
black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.
During the search, the policy can select proof tactics and retrieve lemmas and
definitions from an external database. Each selected tactic is executed in the
underlying proof framework, and the execution feedback is used to build the
prompt for the next policy invocation. The search also tracks selected
information from its history and uses it to reduce hallucinations and
unnecessary LLM queries.
<br />We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks
from the Compcert project. On these benchmarks, COPRA is significantly better
than one-shot invocations of GPT-4, as well as state-of-the-art models
fine-tuned on proof data, at finding correct proofs quickly.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04356" title="Abstract">arXiv:2310.04356</a> [<a href="/pdf/2310.04356" title="Download PDF">pdf</a>, <a href="/format/2310.04356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping the DeFi Crime Landscape: An Evidence-based Picture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carpentier-Desjardins%2C+C">Catherine Carpentier-Desjardins</a>, 
<a href="/search/cs?searchtype=author&query=Paquet-Clouston%2C+M">Masarah Paquet-Clouston</a>, 
<a href="/search/cs?searchtype=author&query=Kitzler%2C+S">Stefan Kitzler</a>, 
<a href="/search/cs?searchtype=author&query=Haslhofer%2C+B">Bernhard Haslhofer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Over the past years, decentralized finance (DeFi) has been the target of
numerous profit-driven crimes. However, until now, the full prevalence and
cumulative impact of these crimes have not been assessed. This study provides a
first comprehensive assessment of profit-driven crimes targeting the DeFi
sector. To achieve this, we collected data on 1155 crime events from 2017 to
2022. Of these, 1050 were related to the DeFi industry and 105 to the
centralized finance (CeFi) industry. Focusing on the former, a taxonomy was
developed to clarify the similarities and differences among these crimes. All
events were mapped onto the DeFi stack to assess the impacted technical layers,
and the financial damages were quantified to gauge their scale. The findings
show that the entire cryptoasset industry has suffered a minimum loss of
US$30B, with two thirds related to centralized finance (CeFi) and one third to
DeFi. Focusing solely on the latter, the results highlight that during an
attack, a DeFi actor (an entity developing a DeFi technology) can serve as a
direct target, as a perpetrator, or as an intermediary. The findings show that
DeFi actors are the first victims of crimes targeting the DeFi industry: 52% of
crime events targeted them, primarily due to technical vulnerabilities at the
protocol layer, and these events accounted for 83% of all recorded financial
damages. On the other hand, in 40% of crime events, DeFi actors were themselves
malicious perpetrators, predominantly misusing contracts at the cryptoasset
layer (e.g., rug pull scams). However, these events accounted for only 17% of
all financial damages. The study's findings offer a preliminary assessment of
the size and scope of crime events within the DeFi sector and highlight the
vulnerable position of DeFi actors in the ecosystem.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04358" title="Abstract">arXiv:2310.04358</a> [<a href="/pdf/2310.04358" title="Download PDF">pdf</a>, <a href="/format/2310.04358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring speech-generic and depression-specific knowledge for  Alzheimer&#x27;s disease detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Ziyun Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei-Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Ji Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures. Accepted by ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The detection of Alzheimer's disease (AD) from spontaneous speech has
attracted increasing attention while the sparsity of training data remains an
important issue. This paper handles the issue by knowledge transfer,
specifically from both speech-generic and depression-specific knowledge. The
paper first studies sequential knowledge transfer from generic foundation
models pretrained on large amounts of speech and text data. A block-wise
analysis is performed for AD diagnosis based on the representations extracted
from different intermediate blocks of different foundation models. Apart from
the knowledge from speech-generic representations, this paper also proposes to
simultaneously transfer the knowledge from a speech depression detection task
based on the high comorbidity rates of depression and AD. A parallel knowledge
transfer framework is studied that jointly learns the information shared
between these two tasks. Experimental results show that the proposed method
improves AD and depression detection, and produces a state-of-the-art F1 score
of 0.928 for AD diagnosis on the commonly used ADReSSo dataset.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04360" title="Abstract">arXiv:2310.04360</a> [<a href="/pdf/2310.04360" title="Download PDF">pdf</a>, <a href="/format/2310.04360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwimXYZ: A large-scale dataset of synthetic swimming motions and videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%C3%A9nol%C3%A9%2C+F">Fiche Gu&#xe9;nol&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+S">Sevestre Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Camila%2C+G">Gonzalez-Barral Camila</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+L">Leglaive Simon</a>, 
<a href="/search/cs?searchtype=author&query=Renaud%2C+S">S&#xe9;guier Renaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MIG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Technologies play an increasingly important role in sports and become a real
competitive advantage for the athletes who benefit from it. Among them, the use
of motion capture is developing in various sports to optimize sporting
gestures. Unfortunately, traditional motion capture systems are expensive and
constraining. Recently developed computer vision-based approaches also struggle
in certain sports, like swimming, due to the aquatic environment. One of the
reasons for the gap in performance is the lack of labeled datasets with
swimming videos. In an attempt to address this issue, we introduce SwimXYZ, a
synthetic dataset of swimming motions and videos. SwimXYZ contains 3.4 million
frames annotated with ground truth 2D and 3D joints, as well as 240 sequences
of swimming motions in the SMPL parameters format. In addition to making this
dataset publicly available, we present use cases for SwimXYZ in swimming stroke
clustering and 2D pose estimation.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04361" title="Abstract">arXiv:2310.04361</a> [<a href="/pdf/2310.04361" title="Download PDF">pdf</a>, <a href="/format/2310.04361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Transformer Activation Sparsity with Dynamic Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pi%C3%B3rczy%C5%84ski%2C+M">Miko&#x142;aj Pi&#xf3;rczy&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Szatkowski%2C+F">Filip Szatkowski</a>, 
<a href="/search/cs?searchtype=author&query=Ba%C5%82azy%2C+K">Klaudia Ba&#x142;azy</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B3jcik%2C+B">Bartosz W&#xf3;jcik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformer models, despite their impressive performance, often face
practical limitations due to their high computational requirements. At the same
time, previous studies have revealed significant activation sparsity in these
models, indicating the presence of redundant computations. In this paper, we
propose Dynamic Sparsified Transformer Inference (DSTI), a method that
radically reduces the inference cost of Transformer models by enforcing
activation sparsity and subsequently transforming a dense model into its sparse
Mixture of Experts (MoE) version. We demonstrate that it is possible to train
small gating networks that successfully predict the relative contribution of
each expert during inference. Furthermore, we introduce a mechanism that
dynamically determines the number of executed experts individually for each
token. DSTI can be applied to any Transformer-based architecture and has
negligible impact on the accuracy. For the BERT-base classification model, we
reduce inference cost by almost 60%.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04363" title="Abstract">arXiv:2310.04363</a> [<a href="/pdf/2310.04363" title="Download PDF">pdf</a>, <a href="/format/2310.04363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amortizing intractable inference in large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+E+J">Edward J. Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+M">Moksh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Elmoznino%2C+E">Eric Elmoznino</a>, 
<a href="/search/cs?searchtype=author&query=Kaddar%2C+Y">Younesse Kaddar</a>, 
<a href="/search/cs?searchtype=author&query=Lajoie%2C+G">Guillaume Lajoie</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages; code: <a href="https://github.com/GFNOrg/gfn-lm-tuning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Autoregressive large language models (LLMs) compress knowledge from their
training data through next-token conditional distributions. This limits
tractable querying of this knowledge to start-to-end autoregressive sampling.
However, many tasks of interest -- including sequence continuation, infilling,
and other forms of constrained generation -- involve sampling from intractable
posterior distributions. We address this limitation by using amortized Bayesian
inference to sample from these intractable posteriors. Such amortization is
algorithmically achieved by fine-tuning LLMs via diversity-seeking
reinforcement learning algorithms: generative flow networks (GFlowNets). We
empirically demonstrate that this distribution-matching paradigm of LLM
fine-tuning can serve as an effective alternative to maximum-likelihood
training and reward-maximizing policy optimization. As an important
application, we interpret chain-of-thought reasoning as a latent variable
modeling problem and demonstrate that our approach enables data-efficient
adaptation of LLMs to tasks that require multi-step rationalization and tool
use.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04364" title="Abstract">arXiv:2310.04364</a> [<a href="/pdf/2310.04364" title="Download PDF">pdf</a>, <a href="/format/2310.04364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Backpressure Routing with Wireless Link Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+G">Gunjan Verma</a>, 
<a href="/search/cs?searchtype=author&query=Swami%2C+A">Ananthram Swami</a>, 
<a href="/search/cs?searchtype=author&query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, accepted to IEEE CAMSAP 2023. arXiv admin note: text overlap with <a href="/abs/2211.10748">arXiv:2211.10748</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Backpressure (BP) routing is a well-established framework for distributed
routing and scheduling in wireless multi-hop networks. However, the basic BP
scheme suffers from poor end-to-end delay due to the drawbacks of slow startup,
random walk, and the last packet problem. Biased BP with shortest path
awareness can address the first two drawbacks, and sojourn time-based backlog
metrics have been proposed for the last packet problem. Furthermore, these BP
variations require no additional signaling overhead in each time step compared
to the basic BP. In this work, we further address three long-standing
challenges associated with the aforementioned low-cost BP variations, including
optimal scaling of the biases, bias maintenance under mobility, and
incorporating sojourn time awareness into biased BP. Our analysis and
experimental results show that proper scaling of biases can be achieved with
the help of common link features, which can effectively reduce end-to-end delay
of BP by mitigating the random walk of packets under low-to-medium traffic,
including the last packet scenario. In addition, our low-overhead bias
maintenance scheme is shown to be effective under mobility, and our
bio-inspired sojourn time-aware backlog metric is demonstrated to be more
efficient and effective for the last packet problem than existing approaches
when incorporated into biased BP.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04366" title="Abstract">arXiv:2310.04366</a> [<a href="/pdf/2310.04366" title="Download PDF">pdf</a>, <a href="/format/2310.04366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swordfish: A Framework for Evaluating Deep Neural Network-based  Basecalling using Computation-In-Memory with Non-Ideal Memristors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahroodi%2C+T">Taha Shahroodi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mahdi Zahedi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haiyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Lindegger%2C+J">Joel Lindegger</a>, 
<a href="/search/cs?searchtype=author&query=Firtina%2C+C">Can Firtina</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+S">Stephan Wong</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>, 
<a href="/search/cs?searchtype=author&query=Hamdioui%2C+S">Said Hamdioui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 56th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET); Genomics (q-bio.GN)

</div>
<p class="mathjax">Basecalling, an essential step in many genome analysis studies, relies on
large Deep Neural Networks (DNNs) to achieve high accuracy. Unfortunately,
these DNNs are computationally slow and inefficient, leading to considerable
delays and resource constraints in the sequence analysis process. A
Computation-In-Memory (CIM) architecture using memristors can significantly
accelerate the performance of DNNs. However, inherent device non-idealities and
architectural limitations of such designs can greatly degrade the basecalling
accuracy, which is critical for accurate genome analysis. To facilitate the
adoption of memristor-based CIM designs for basecalling, it is important to (1)
conduct a comprehensive analysis of potential CIM architectures and (2) develop
effective strategies for mitigating the possible adverse effects of inherent
device non-idealities and architectural limitations.
<br />This paper proposes Swordfish, a novel hardware/software co-design framework
that can effectively address the two aforementioned issues. Swordfish
incorporates seven circuit and device restrictions or non-idealities from
characterized real memristor-based chips. Swordfish leverages various
hardware/software co-design solutions to mitigate the basecalling accuracy loss
due to such non-idealities. To demonstrate the effectiveness of Swordfish, we
take Bonito, the state-of-the-art (i.e., accurate and fast), open-source
basecaller as a case study. Our experimental results using Sword-fish show that
a CIM architecture can realistically accelerate Bonito for a wide range of real
datasets by an average of 25.7x, with an accuracy loss of 6.01%.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04368" title="Abstract">arXiv:2310.04368</a> [<a href="/pdf/2310.04368" title="Download PDF">pdf</a>, <a href="/format/2310.04368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Core Calculus for Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crichton%2C+W">Will Crichton</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthi%2C+S">Shriram Krishnamurthi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at POPL'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Passive documents and active programs now widely comingle. Document languages
include Turing-complete programming elements, and programming languages include
sophisticated document notations. However, there are no formal foundations that
model these languages. This matters because the interaction between document
and program is complicated and can be error-prone. In this paper we describe
several of these problems, then taxonomize these document languages, and model
them as levels of a document calculus. We employ the calculus as a foundation
for implementing complex runtime features such as reactivity, as well as for
proving a few useful theorems regarding the boundary of content and
computation. We intend for the document calculus to provide a theoretical basis
for new document languages, and to enable designers to clean up the unsavory
corners of existing ones.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04369" title="Abstract">arXiv:2310.04369</a> [<a href="/pdf/2310.04369" title="Download PDF">pdf</a>, <a href="/format/2310.04369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MBTFNet: Multi-Band Temporal-Frequency Neural Network For Singing Voice  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhouxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhili Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+S">Shubo Lv</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Runduo Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenjiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A typical neural speech enhancement (SE) approach mainly handles speech and
noise mixtures, which is not optimal for singing voice enhancement scenarios.
Music source separation (MSS) models treat vocals and various accompaniment
components equally, which may reduce performance compared to the model that
only considers vocal enhancement. In this paper, we propose a novel multi-band
temporal-frequency neural network (MBTFNet) for singing voice enhancement,
which particularly removes background music, noise and even backing vocals from
singing recordings. MBTFNet combines inter and intra-band modeling for better
processing of full-band signals. Dual-path modeling are introduced to expand
the receptive field of the model. We propose an implicit personalized
enhancement (IPE) stage based on signal-to-noise ratio (SNR) estimation, which
further improves the performance of MBTFNet. Experiments show that our proposed
model significantly outperforms several state-of-the-art SE and MSS models.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04373" title="Abstract">arXiv:2310.04373</a> [<a href="/pdf/2310.04373" title="Download PDF">pdf</a>, <a href="/format/2310.04373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confronting Reward Model Overoptimization with Constrained RLHF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskovitz%2C+T">Ted Moskovitz</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Aaditya K. Singh</a>, 
<a href="/search/cs?searchtype=author&query=Strouse%2C+D">DJ Strouse</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A+D">Anca D. Dragan</a>, 
<a href="/search/cs?searchtype=author&query=McAleer%2C+S">Stephen McAleer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models are typically aligned with human preferences by
optimizing $\textit{reward models}$ (RMs) fitted to human feedback. However,
human preferences are multi-faceted, and it is increasingly common to derive
reward from a composition of simpler reward models which each capture a
different aspect of language quality. This itself presents a challenge, as it
is difficult to appropriately weight these component RMs when combining them.
Compounding this difficulty, because any RM is only a proxy for human
evaluation, this process is vulnerable to $\textit{overoptimization}$, wherein
past a certain point, accumulating higher reward is associated with worse human
ratings. In this paper, we perform, to our knowledge, the first study on
overoptimization in composite RMs, showing that correlation between component
RMs has a significant effect on the locations of these points. We then
introduce an approach to solve this issue using constrained reinforcement
learning as a means of preventing the agent from exceeding each RM's threshold
of usefulness. Our method addresses the problem of weighting component RMs by
learning dynamic weights, naturally given by the Lagrange multipliers. As a
result, each RM stays within the range at which it is an effective proxy,
improving evaluation performance. Finally, we introduce an adaptive method
using gradient-free optimization to identify and optimize towards these points
during a single run.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04376" title="Abstract">arXiv:2310.04376</a> [<a href="/pdf/2310.04376" title="Download PDF">pdf</a>, <a href="/format/2310.04376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-linear Time Dispersion of Mobile Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudo%2C+Y">Yuichi Sudo</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+M">Masahiro Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+J">Junya Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yonghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Masuzawa%2C+T">Toshimitsu Masuzawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Consider that there are $k\le n$ agents in a simple, connected, and
undirected graph $G=(V,E)$ with $n$ nodes and $m$ edges. The goal of the
dispersion problem is to move these $k$ agents to distinct nodes. Agents can
communicate only when they are at the same node, and no other means of
communication such as whiteboards are available. We assume that the agents
operate synchronously. We consider two scenarios: when all agents are initially
located at any single node (rooted setting) and when they are initially
distributed over any one or more nodes (general setting). Kshemkalyani and
Sharma presented a dispersion algorithm for the general setting, which uses
$O(m_k)$ time and $\log(k+\delta)$ bits of memory per agent [OPODIS 2021].
Here, $m_k$ is the maximum number of edges in any induced subgraph of $G$ with
$k$ nodes, and $\delta$ is the maximum degree of $G$. This algorithm is the
fastest in the literature, as no algorithm with $o(m_k)$ time has been
discovered even for the rooted setting. In this paper, we present faster
algorithms for both the rooted and general settings. First, we present an
algorithm for the rooted setting that solves the dispersion problem in $O(k\log
\min(k,\delta))=O(k\log k)$ time using $O(\log \delta)$ bits of memory per
agent. Next, we propose an algorithm for the general setting that achieves
dispersion in $O(k (\log k)\cdot (\log \min(k,\delta))=O(k \log^2 k)$ time
using $O(\log (k+\delta))$ bits.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04378" title="Abstract">arXiv:2310.04378</a> [<a href="/pdf/2310.04378" title="Download PDF">pdf</a>, <a href="/format/2310.04378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Consistency Models: Synthesizing High-Resolution Images with  Few-Step Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Simian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yiqin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longbo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Latent Diffusion models (LDMs) have achieved remarkable results in
synthesizing high-resolution images. However, the iterative sampling process is
computationally intensive and leads to slow generation. Inspired by Consistency
Models (song et al.), we propose Latent Consistency Models (LCMs), enabling
swift inference with minimal steps on any pre-trained LDMs, including Stable
Diffusion (rombach et al). Viewing the guided reverse diffusion process as
solving an augmented probability flow ODE (PF-ODE), LCMs are designed to
directly predict the solution of such ODE in latent space, mitigating the need
for numerous iterations and allowing rapid, high-fidelity sampling. Efficiently
distilled from pre-trained classifier-free guided diffusion models, a
high-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training.
Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel method
that is tailored for fine-tuning LCMs on customized image datasets. Evaluation
on the LAION-5B-Aesthetics dataset demonstrates that LCMs achieve
state-of-the-art text-to-image generation performance with few-step inference.
Project Page: https://latent-consistency-models.github.io/
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04381" title="Abstract">arXiv:2310.04381</a> [<a href="/pdf/2310.04381" title="Download PDF">pdf</a>, <a href="/format/2310.04381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hermes: Unlocking Security Analysis of Cellular Network Protocols by  Synthesizing Finite State Machines from Natural Language Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishtiaq%2C+A+A">Abdullah Al Ishtiaq</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S+S+S">Sarkar Snigdha Sarathi Das</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+S+M+M">Syed Md Mukit Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Ranjbar%2C+A">Ali Ranjbar</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+K">Kai Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhezheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Akon%2C+M">Mujtahid Akon</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+S+R">Syed Rafiul Hussain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at USENIX Security 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, we present Hermes, an end-to-end framework to automatically
generate formal representations from natural language cellular specifications.
We first develop a neural constituency parser, NEUTREX, to process
transition-relevant texts and extract transition components (i.e., states,
conditions, and actions). We also design a domain-specific language to
translate these transition components to logical formulas by leveraging
dependency parse trees. Finally, we compile these logical formulas to generate
transitions and create the formal model as finite state machines. To
demonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and
5G RRC specifications and obtain an overall accuracy of 81-87%, which is a
substantial improvement over the state-of-the-art. Our security analysis of the
extracted models uncovers 3 new vulnerabilities and identifies 19 previous
attacks in 4G and 5G specifications, and 7 deviations in commercial 4G
basebands.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04384" title="Abstract">arXiv:2310.04384</a> [<a href="/pdf/2310.04384" title="Download PDF">pdf</a>, <a href="/format/2310.04384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware Trace Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%A4hnle%2C+R">Reiner H&#xe4;hnle</a>, 
<a href="/search/cs?searchtype=author&query=Kamburjan%2C+E">Eduard Kamburjan</a>, 
<a href="/search/cs?searchtype=author&query=Scaletta%2C+M">Marco Scaletta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The behavior of concurrent, asynchronous procedures depends in general on the
call context, because of the global protocol that governs scheduling. This
context cannot be specified with the state-based Hoare-style contracts common
in deductive verification. Recent work generalized state-based to trace
contracts, which permit to specify the internal behavior of a procedure, such
as calls or state changes, but not its call context. In this article we propose
a program logic of context-aware trace contracts for specifying global behavior
of asynchronous programs. We also provide a sound proof system that addresses
two challenges: To observe the program state not merely at the end points of a
procedure, we introduce the novel concept of an observation quantifier. And to
combat combinatorial explosion of possible call sequences of procedures, we
transfer Liskov's principle of behavioral subtyping to the analysis of
asynchronous procedures.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04391" title="Abstract">arXiv:2310.04391</a> [<a href="/pdf/2310.04391" title="Download PDF">pdf</a>, <a href="/ps/2310.04391" title="Download PostScript">ps</a>, <a href="/format/2310.04391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Hierarchy of Spectral Isomorphism Invariants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arvind%2C+V">V. Arvind</a>, 
<a href="/search/cs?searchtype=author&query=Fuhlbr%C3%BCck%2C+F">Frank Fuhlbr&#xfc;ck</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6bler%2C+J">Johannes K&#xf6;bler</a>, 
<a href="/search/cs?searchtype=author&query=Verbitsky%2C+O">Oleg Verbitsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We consider a hierarchy of graph invariants that naturally extends the
spectral invariants defined by F\"urer (Lin. Alg. Appl. 2010) based on angles
between the projections of standard basis vectors onto an eigenspace of the
adjacency matrix of a graph. We provide a purely combinatorial characterization
of this hierarchy in terms of the walk counts. This allows us to give a
complete answer to F\"urer's question about the strength of his invariants in
distinguishing non-isomorphic graphs in comparison to the 2-dimensional
Weisfeiler-Leman algorithm, extending the recent work of Rattan and Seppelt
(SODA 2023). As another application of the characterization, we prove that
almost all graphs are determined up to isomorphism by their eigenvalues and
angles, which is closely related to the long-standing open problem whether
almost all graphs are determined by their spectrum. Finally, we describe the
exact relationship between the hierarchy and the Weisfeiler-Leman algorithms
for small dimensions, as also some other important spectral characteristics of
a graph such as the generalized and the main spectra.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04395" title="Abstract">arXiv:2310.04395</a> [<a href="/pdf/2310.04395" title="Download PDF">pdf</a>, <a href="/format/2310.04395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Self-Consistency for Data-Efficient Amortized Bayesian  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+M">Marvin Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+D">Daniel Habermann</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCrkner%2C+P">Paul-Christian B&#xfc;rkner</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>, 
<a href="/search/cs?searchtype=author&query=Radev%2C+S+T">Stefan T. Radev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a method to improve the efficiency and accuracy of amortized
Bayesian inference (ABI) by leveraging universal symmetries in the
probabilistic joint model $p(\theta, y)$ of parameters $\theta$ and data $y$.
In a nutshell, we invert Bayes' theorem and estimate the marginal likelihood
based on approximate representations of the joint model. Upon perfect
approximation, the marginal likelihood is constant across all parameter values
by definition. However, approximation error leads to undesirable variance in
the marginal likelihood estimates across different parameter values. We
formulate violations of this symmetry as a loss function to accelerate the
learning dynamics of conditional neural density estimators. We apply our method
to a bimodal toy problem with an explicit likelihood (likelihood-based) and a
realistic model with an implicit likelihood (simulation-based).
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04399" title="Abstract">arXiv:2310.04399</a> [<a href="/pdf/2310.04399" title="Download PDF">pdf</a>, <a href="/format/2310.04399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Stability in Simultaneous Speech Translation: A  Revision-Controllable Decoding Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junkun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jian Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jing Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Simultaneous Speech-to-Text translation serves a critical role in real-time
crosslingual communication. Despite the advancements in recent years,
challenges remain in achieving stability in the translation process, a concern
primarily manifested in the flickering of partial results. In this paper, we
propose a novel revision-controllable method designed to address this issue.
Our method introduces an allowed revision window within the beam search pruning
process to screen out candidate translations likely to cause extensive
revisions, leading to a substantial reduction in flickering and, crucially,
providing the capability to completely eliminate flickering. The experiments
demonstrate the proposed method can significantly improve the decoding
stability without compromising substantially on the translation quality.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04400" title="Abstract">arXiv:2310.04400</a> [<a href="/pdf/2310.04400" title="Download PDF">pdf</a>, <a href="/format/2310.04400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Embedding Collapse when Scaling up Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xingzhuo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junwei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Ximei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baixu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+M">Mingsheng Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Recent advances in deep foundation models have led to a promising trend of
developing large recommendation models to leverage vast amounts of available
data. However, we experiment to scale up existing recommendation models and
observe that the enlarged models do not improve satisfactorily. In this
context, we investigate the embedding layers of enlarged models and identify a
phenomenon of embedding collapse, which ultimately hinders scalability, wherein
the embedding matrix tends to reside in a low-dimensional subspace. Through
empirical and theoretical analysis, we demonstrate that the feature interaction
module specific to recommendation models has a two-sided effect. On the one
hand, the interaction restricts embedding learning when interacting with
collapsed embeddings, exacerbating the collapse issue. On the other hand,
feature interaction is crucial in mitigating the fitting of spurious features,
thereby improving scalability. Based on this analysis, we propose a simple yet
effective multi-embedding design incorporating embedding-set-specific
interaction modules to capture diverse patterns and reduce collapse. Extensive
experiments demonstrate that this proposed design provides consistent
scalability for various recommendation models.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04406" title="Abstract">arXiv:2310.04406</a> [<a href="/pdf/2310.04406" title="Download PDF">pdf</a>, <a href="/format/2310.04406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Agent Tree Search Unifies Reasoning Acting and Planning in  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Andy Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shlapentokh-Rothman%2C+M">Michal Shlapentokh-Rothman</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website and code can be found at <a href="https://andyz245.github.io/LanguageAgentTreeSearch">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">While large language models (LLMs) have demonstrated impressive performance
on a range of decision-making tasks, they rely on simple acting processes and
fall short of broad deployment as autonomous agents. We introduce LATS
(Language Agent Tree Search), a general framework that synergizes the
capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration
from Monte Carlo tree search in model-based reinforcement learning, LATS
employs LLMs as agents, value functions, and optimizers, repurposing their
latent strengths for enhanced decision-making. What is crucial in this method
is the use of an environment for external feedback, which offers a more
deliberate and adaptive problem-solving mechanism that moves beyond the
limitations of existing techniques. Our experimental evaluation across diverse
domains, such as programming, HotPotQA, and WebShop, illustrates the
applicability of LATS for both reasoning and acting. In particular, LATS
achieves 94.4\% for programming on HumanEval with GPT-4 and an average score of
75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness
and generality of our method.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04407" title="Abstract">arXiv:2310.04407</a> [<a href="/pdf/2310.04407" title="Download PDF">pdf</a>, <a href="/format/2310.04407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy-Gradient Training of Language Models for Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+D">Jonathan D. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Cardie%2C+C">Claire Cardie</a>, 
<a href="/search/cs?searchtype=author&query=Brantley%2C+K">Kiant&#xe9; Brantley</a>, 
<a href="/search/cs?searchtype=author&query=Joachim%2C+T">Thorsten Joachim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text retrieval plays a crucial role in incorporating factual knowledge for
decision making into language processing pipelines, ranging from chat-based web
search to question answering systems. Current state-of-the-art text retrieval
models leverage pre-trained large language models (LLMs) to achieve competitive
performance, but training LLM-based retrievers via typical contrastive losses
requires intricate heuristics, including selecting hard negatives and using
additional supervision as learning signals. This reliance on heuristics stems
from the fact that the contrastive loss itself is heuristic and does not
directly optimize the downstream metrics of decision quality at the end of the
processing pipeline. To address this issue, we introduce Neural PG-RANK, a
novel training algorithm that learns to rank by instantiating a LLM as a
Plackett-Luce ranking policy. Neural PG-RANK provides a principled method for
end-to-end training of retrieval models as part of larger decision systems via
policy gradient, with little reliance on complex heuristics, and it effectively
unifies the training objective with downstream decision-making quality. We
conduct extensive experiments on various text retrieval benchmarks. The results
demonstrate that when the training objective aligns with the evaluation setup,
Neural PG-RANK yields remarkable in-domain performance improvement, with
substantial out-of-domain generalization to some critical datasets employed in
downstream question answering tasks.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04408" title="Abstract">arXiv:2310.04408</a> [<a href="/pdf/2310.04408" title="Download PDF">pdf</a>, <a href="/format/2310.04408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fangyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weijia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunsol Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Retrieving documents and prepending them in-context at inference time
improves performance of language model (LMs) on a wide range of tasks. However,
these documents, often spanning hundreds of words, make inference substantially
more expensive. We propose compressing the retrieved documents into textual
summaries prior to in-context integration. This not only reduces the
computational costs but also relieves the burden of LMs to identify relevant
information in long retrieved documents. We present two compressors -- an
extractive compressor which selects useful sentences from retrieved documents
and an abstractive compressor which generates summaries by synthesizing
information from multiple documents. Both compressors are trained to improve
LMs' performance on end tasks when the generated summaries are prepended to the
LMs' input, while keeping the summary concise.If the retrieved documents are
irrelevant to the input or offer no additional information to LM, our
compressor can return an empty string, implementing selective augmentation.We
evaluate our approach on language modeling task and open domain question
answering task. We achieve a compression rate of as low as 6% with minimal loss
in performance for both tasks, significantly outperforming the off-the-shelf
summarization models. We show that our compressors trained for one LM can
transfer to other LMs on the language modeling task and provide summaries
largely faithful to the retrieved documents.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04411" title="Abstract">arXiv:2310.04411</a> [<a href="/pdf/2310.04411" title="Download PDF">pdf</a>, <a href="/format/2310.04411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding, Predicting and Better Resolving Q-Value Divergence in  Offline-RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Rui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 20 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The divergence of the Q-value estimation has been a prominent issue in
offline RL, where the agent has no access to real dynamics. Traditional beliefs
attribute this instability to querying out-of-distribution actions when
bootstrapping value targets. Though this issue can be alleviated with policy
constraints or conservative Q estimation, a theoretical understanding of the
underlying mechanism causing the divergence has been absent. In this work, we
aim to thoroughly comprehend this mechanism and attain an improved solution. We
first identify a fundamental pattern, self-excitation, as the primary cause of
Q-value estimation divergence in offline RL. Then, we propose a novel
Self-Excite Eigenvalue Measure (SEEM) metric based on Neural Tangent Kernel
(NTK) to measure the evolving property of Q-network at training, which provides
an intriguing explanation of the emergence of divergence. For the first time,
our theory can reliably decide whether the training will diverge at an early
stage, and even predict the order of the growth for the estimated Q-value, the
model's norm, and the crashing step when an SGD optimizer is used. The
experiments demonstrate perfect alignment with this theoretic analysis.
Building on our insights, we propose to resolve divergence from a novel
perspective, namely improving the model's architecture for better extrapolating
behavior. Through extensive empirical studies, we identify LayerNorm as a good
solution to effectively avoid divergence without introducing detrimental bias,
leading to superior performance. Experimental results prove that it can still
work in some most challenging settings, i.e. using only 1 transitions of the
dataset, where all previous methods fail. Moreover, it can be easily plugged
into modern offline RL methods and achieve SOTA results on many challenging
tasks. We also give unique insights into its effectiveness.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04412" title="Abstract">arXiv:2310.04412</a> [<a href="/pdf/2310.04412" title="Download PDF">pdf</a>, <a href="/format/2310.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedConv: Enhancing Convolutional Neural Networks for Handling Data  Heterogeneity in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peiran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liangqiong Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures. Equal contribution by P. Xu and Z. Wang
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Federated learning (FL) is an emerging paradigm in machine learning, where a
shared model is collaboratively learned using data from multiple devices to
mitigate the risk of data leakage. While recent studies posit that Vision
Transformer (ViT) outperforms Convolutional Neural Networks (CNNs) in
addressing data heterogeneity in FL, the specific architectural components that
underpin this advantage have yet to be elucidated. In this paper, we
systematically investigate the impact of different architectural elements, such
as activation functions and normalization layers, on the performance within
heterogeneous FL. Through rigorous empirical analyses, we are able to offer the
first-of-its-kind general guidance on micro-architecture design principles for
heterogeneous FL.
<br />Intriguingly, our findings indicate that with strategic architectural
modifications, pure CNNs can achieve a level of robustness that either matches
or even exceeds that of ViTs when handling heterogeneous data clients in FL.
Additionally, our approach is compatible with existing FL techniques and
delivers state-of-the-art solutions across a broad spectrum of FL benchmarks.
The code is publicly available at https://github.com/UCSC-VLAA/FedConv
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04413" title="Abstract">arXiv:2310.04413</a> [<a href="/pdf/2310.04413" title="Download PDF">pdf</a>, <a href="/format/2310.04413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Z">Zhang-Wei Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aviral Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Karnik%2C+S">Sathwik Karnik</a>, 
<a href="/search/cs?searchtype=author&query=Bhandwaldar%2C+A">Abhishek Bhandwaldar</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>, 
<a href="/search/cs?searchtype=author&query=Laroche%2C+R">Romain Laroche</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline policy learning is aimed at learning decision-making policies using
existing datasets of trajectories without collecting additional data. The
primary motivation for using reinforcement learning (RL) instead of supervised
learning techniques such as behavior cloning is to find a policy that achieves
a higher average return than the trajectories constituting the dataset.
However, we empirically find that when a dataset is dominated by suboptimal
trajectories, state-of-the-art offline RL algorithms do not substantially
improve over the average return of trajectories in the dataset. We argue this
is due to an assumption made by current offline RL algorithms of staying close
to the trajectories in the dataset. If the dataset primarily consists of
sub-optimal trajectories, this assumption forces the policy to mimic the
suboptimal actions. We overcome this issue by proposing a sampling strategy
that enables the policy to only be constrained to ``good data" rather than all
actions in the dataset (i.e., uniform sampling). We present a realization of
the sampling strategy and an algorithm that can be used as a plug-and-play
module in standard offline RL algorithms. Our evaluation demonstrates
significant performance gains in 72 imbalanced datasets, D4RL dataset, and
across three different offline RL algorithms. Code is available at
https://github.com/Improbable-AI/dw-offline-rl.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04414" title="Abstract">arXiv:2310.04414</a> [<a href="/pdf/2310.04414" title="Download PDF">pdf</a>, <a href="/format/2310.04414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model  Generalization Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoxiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+X">Xingjian Leng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Analyzing model performance in various unseen environments is a critical
research problem in the machine learning community. To study this problem, it
is important to construct a testbed with out-of-distribution test sets that
have broad coverage of environmental discrepancies. However, existing testbeds
typically either have a small number of domains or are synthesized by image
corruptions, hindering algorithm design that demonstrates real-world
effectiveness. In this paper, we introduce CIFAR-10-Warehouse, consisting of
180 datasets collected by prompting image search engines and diffusion models
in various ways. Generally sized between 300 and 8,000 images, the datasets
contain natural images, cartoons, certain colors, or objects that do not
naturally appear. With CIFAR-10-W, we aim to enhance the evaluation and deepen
the understanding of two generalization tasks: domain generalization and model
accuracy prediction in various out-of-distribution environments. We conduct
extensive benchmarking and comparison experiments and show that CIFAR-10-W
offers new and interesting insights inherent to these tasks. We also discuss
other fields that would benefit from CIFAR-10-W.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04415" title="Abstract">arXiv:2310.04415</a> [<a href="/pdf/2310.04415" title="Download PDF">pdf</a>, <a href="/format/2310.04415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Do We Need Weight Decay in Modern Deep Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andriushchenko%2C+M">Maksym Andriushchenko</a>, 
<a href="/search/cs?searchtype=author&query=D%27Angelo%2C+F">Francesco D&#x27;Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Varre%2C+A">Aditya Varre</a>, 
<a href="/search/cs?searchtype=author&query=Flammarion%2C+N">Nicolas Flammarion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Weight decay is a broadly used technique for training state-of-the-art deep
networks, including large language models. Despite its widespread usage, its
role remains poorly understood. In this work, we highlight that the role of
weight decay in modern deep learning is different from its regularization
effect studied in classical learning theory. For overparameterized deep
networks, we show how weight decay modifies the optimization dynamics enhancing
the ever-present implicit regularization of SGD via the loss stabilization
mechanism. In contrast, for underparameterized large language models trained
with nearly online SGD, we describe how weight decay balances the bias-variance
tradeoff in stochastic optimization leading to lower training loss. Moreover,
we show that weight decay also prevents sudden loss divergences for bfloat16
mixed-precision training which is a crucial tool for LLM training. Overall, we
present a unifying perspective from ResNets on vision tasks to LLMs: weight
decay is never useful as an explicit regularizer but instead changes the
training dynamics in a desirable way. Our code is available at
https://github.com/tml-epfl/why-weight-decay.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04416" title="Abstract">arXiv:2310.04416</a> [<a href="/pdf/2310.04416" title="Download PDF">pdf</a>, <a href="/format/2310.04416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alice Benchmarks: Connecting Real World Object Re-Identification with  the Synthetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoxiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yue Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For object re-identification (re-ID), learning from synthetic data has become
a promising strategy to cheaply acquire large-scale annotated datasets and
effective models, with few privacy concerns. Many interesting research problems
arise from this strategy, e.g., how to reduce the domain gap between synthetic
source and real-world target. To facilitate developing more new approaches in
learning from synthetic data, we introduce the Alice benchmarks, large-scale
datasets providing benchmarks as well as evaluation protocols to the research
community. Within the Alice benchmarks, two object re-ID tasks are offered:
person and vehicle re-ID. We collected and annotated two challenging real-world
target datasets: AlicePerson and AliceVehicle, captured under various
illuminations, image resolutions, etc. As an important feature of our real
target, the clusterability of its training set is not manually guaranteed to
make it closer to a real domain adaptation test scenario. Correspondingly, we
reuse existing PersonX and VehicleX as synthetic source domains. The primary
goal is to train models from synthetic data that can work effectively in the
real world. In this paper, we detail the settings of Alice benchmarks, provide
an analysis of existing commonly-used domain adaptation methods, and discuss
some interesting future directions. An online server will be set up for the
community to evaluate methods conveniently and fairly.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04418" title="Abstract">arXiv:2310.04418</a> [<a href="/pdf/2310.04418" title="Download PDF">pdf</a>, <a href="/format/2310.04418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Interpolation for Relative Positions Improves Long Context  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanda Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chong You</a>, 
<a href="/search/cs?searchtype=author&query=Guruganesh%2C+G">Guru Guruganesh</a>, 
<a href="/search/cs?searchtype=author&query=Ainslie%2C+J">Joshua Ainslie</a>, 
<a href="/search/cs?searchtype=author&query=Ontanon%2C+S">Santiago Ontanon</a>, 
<a href="/search/cs?searchtype=author&query=Zaheer%2C+M">Manzil Zaheer</a>, 
<a href="/search/cs?searchtype=author&query=Sanghai%2C+S">Sumit Sanghai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Bhojanapalli%2C+S">Srinadh Bhojanapalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Preventing the performance decay of Transformers on inputs longer than those
used for training has been an important challenge in extending the context
length of these models. Though the Transformer architecture has fundamentally
no limits on the input sequence lengths it can process, the choice of position
encoding used during training can limit the performance of these models on
longer inputs. We propose a novel functional relative position encoding with
progressive interpolation, FIRE, to improve Transformer generalization to
longer contexts. We theoretically prove that this can represent some of the
popular relative position encodings, such as T5's RPE, Alibi, and Kerple. We
next empirically show that FIRE models have better generalization to longer
contexts on both zero-shot language modeling and long text benchmarks.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04420" title="Abstract">arXiv:2310.04420</a> [<a href="/pdf/2310.04420" title="Download PDF">pdf</a>, <a href="/format/2310.04420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex  Selectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+A+F">Andrew F. Luo</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+M+M">Margaret M. Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Tarr%2C+M+J">Michael J. Tarr</a>, 
<a href="/search/cs?searchtype=author&query=Wehbe%2C+L">Leila Wehbe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Understanding the functional organization of higher visual cortex is a
central focus in neuroscience. Past studies have primarily mapped the visual
and semantic selectivity of neural populations using hand-selected stimuli,
which may potentially bias results towards pre-existing hypotheses of visual
cortex functionality. Moving beyond conventional approaches, we introduce a
data-driven method that generates natural language descriptions for images
predicted to maximally activate individual voxels of interest. Our method --
Semantic Captioning Using Brain Alignments ("BrainSCUBA") -- builds upon the
rich embedding space learned by a contrastive vision-language model and
utilizes a pre-trained large language model to generate interpretable captions.
We validate our method through fine-grained voxel-level captioning across
higher-order visual regions. We further perform text-conditioned image
synthesis with the captions, and show that our images are semantically coherent
and yield high predicted activations. Finally, to demonstrate how our method
enables scientific discovery, we perform exploratory investigations on the
distribution of "person" representations in the brain, and discover
fine-grained semantic selectivity in body-selective areas. Unlike earlier
studies that decode text, our method derives voxel-wise captions of semantic
selectivity. Our results show that BrainSCUBA is a promising means for
understanding functional preferences in the brain, and provides motivation for
further hypothesis-driven investigation of visual cortex.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon,  9 Oct 23</h3>
<dl>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03747" title="Abstract">arXiv:2310.03747</a> (cross-list from eess.SP) [<a href="/pdf/2310.03747" title="Download PDF">pdf</a>, <a href="/format/2310.03747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Knowledge-Driven Cross-view Contrastive Learning for EEG  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weng%2C+W">Weining Weng</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+Y">Yang Gu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qihui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yingying Huang</a>, 
<a href="/search/eess?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yiqiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Due to the abundant neurophysiological information in the
electroencephalogram (EEG) signal, EEG signals integrated with deep learning
methods have gained substantial traction across numerous real-world tasks.
However, the development of supervised learning methods based on EEG signals
has been hindered by the high cost and significant label discrepancies to
manually label large-scale EEG datasets. Self-supervised frameworks are adopted
in vision and language fields to solve this issue, but the lack of EEG-specific
theoretical foundations hampers their applicability across various tasks. To
solve these challenges, this paper proposes a knowledge-driven cross-view
contrastive learning framework (KDC2), which integrates neurological theory to
extract effective representations from EEG with limited labels. The KDC2 method
creates scalp and neural views of EEG signals, simulating the internal and
external representation of brain activity. Sequentially, inter-view and
cross-view contrastive learning pipelines in combination with various
augmentation methods are applied to capture neural features from different
views. By modeling prior neural knowledge based on homologous neural
information consistency theory, the proposed method extracts invariant and
complementary neural knowledge to generate combined representations.
Experimental results on different downstream tasks demonstrate that our method
outperforms state-of-the-art methods, highlighting the superior generalization
of neural knowledge-supported EEG representations across various brain tasks.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03748" title="Abstract">arXiv:2310.03748</a> (cross-list from eess.SP) [<a href="/pdf/2310.03748" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Synchrony Component Self-Organization in Brain Computer Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Niu%2C+X">Xu Niu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+N">Na Lu</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+H">Huan Luo</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+R">Ruofan Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Phase synchrony information plays a crucial role in analyzing functional
brain connectivity and identifying brain activities. A widely adopted feature
extraction pipeline, composed of preprocessing, selection of EEG acquisition
channels, and phase locking value (PLV) calculation, has achieved success in
motor imagery classification (MI). However, this pipeline is manual and reliant
on expert knowledge, limiting its convenience and adaptability to different
application scenarios. Moreover, most studies have employed mediocre
data-independent spatial filters to suppress noise, impeding the exploration of
more significant phase synchronization phenomena. To address the issues, we
propose the concept of phase synchrony component self-organization, which
enables the adaptive learning of data-dependent spatial filters for automating
both the preprocessing and channel selection procedures. Based on this concept,
the first deep learning end-to-end network is developed, which directly
extracts phase synchrony-based features from raw EEG signals and perform
classification. The network learns optimal filters during training, which are
obtained when the network achieves peak classification results. Extensive
experiments have demonstrated that our network outperforms state-of-the-art
methods. Remarkably, through the learned optimal filters, significant phase
synchronization phenomena can be observed. Specifically, by calculating the PLV
between a pair of signals extracted from each sample using two of the learned
spatial filters, we have obtained an average PLV exceeding 0.87 across all
tongue MI samples. This high PLV indicates a groundbreaking discovery in the
synchrony pattern of tongue MI.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03749" title="Abstract">arXiv:2310.03749</a> (cross-list from eess.SP) [<a href="/pdf/2310.03749" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCVCNet: Sliding cross-vector convolution network for cross-task and  inter-individual-set EEG-based cognitive workload recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhan%2C+Z">Zhiyuan Zhan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jianhua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+Z">Zhong Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a generic approach for applying the cognitive workload
recognizer by exploiting common electroencephalogram (EEG) patterns across
different human-machine tasks and individual sets. We propose a neural network
called SCVCNet, which eliminates task- and individual-set-related interferences
in EEGs by analyzing finer-grained frequency structures in the power spectral
densities. The SCVCNet utilizes a sliding cross-vector convolution (SCVC)
operation, where paired input layers representing the theta and alpha power are
employed. By extracting the weights from a kernel matrix's central row and
column, we compute the weighted sum of the two vectors around a specified scalp
location. Next, we introduce an inter-frequency-point feature integration
module to fuse the SCVC feature maps. Finally, we combined the two modules with
the output-channel pooling and classification layers to construct the model. To
train the SCVCNet, we employ the regularized least-square method with ridge
regression and the extreme learning machine theory. We validate its performance
using three databases, each consisting of distinct tasks performed by
independent participant groups. The average accuracy (0.6813 and 0.6229) and F1
score (0.6743 and 0.6076) achieved in two different validation paradigms show
partially higher performance than the previous works. All features and
algorithms are available on website:https://github.com/7ohnKeats/SCVCNet.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03750" title="Abstract">arXiv:2310.03750</a> (cross-list from eess.SP) [<a href="/pdf/2310.03750" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Health diagnosis and recuperation of aged Li-ion batteries with data  analytics and equivalent circuit modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Made%2C+R+I">Riko I Made</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jing Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jintao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Moh%2C+L+C+H">Lionel C. H. Moh</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhaolin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/eess?searchtype=author&query=Chiam%2C+S+Y">Sing Yang Chiam</a>, 
<a href="/search/eess?searchtype=author&query=Khoo%2C+E">Edwin Khoo</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xuesong Yin</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+G+W">Guangyuan Wesley Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Battery health assessment and recuperation play a crucial role in the
utilization of second-life Li-ion batteries. However, due to ambiguous aging
mechanisms and lack of correlations between the recovery effects and
operational states, it is challenging to accurately estimate battery health and
devise a clear strategy for cell rejuvenation. This paper presents aging and
reconditioning experiments of 62 commercial high-energy type lithium iron
phosphate (LFP) cells, which supplement existing datasets of high-power LFP
cells. The relatively large-scale data allow us to use machine learning models
to predict cycle life and identify important indicators of recoverable
capacity. Considering cell-to-cell inconsistencies, an average test error of
$16.84\% \pm 1.87\%$ (mean absolute percentage error) for cycle life prediction
is achieved by gradient boosting regressor given information from the first 80
cycles. In addition, it is found that some of the recoverable lost capacity is
attributed to the lateral lithium non-uniformity within the electrodes. An
equivalent circuit model is built and experimentally validated to demonstrate
how such non-uniformity can be accumulated, and how it can give rise to
recoverable capacity loss. SHapley Additive exPlanations (SHAP) analysis also
reveals that battery operation history significantly affects the capacity
recovery.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03751" title="Abstract">arXiv:2310.03751</a> (cross-list from eess.SP) [<a href="/pdf/2310.03751" title="Download PDF">pdf</a>, <a href="/format/2310.03751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Illustration of Interleaved Learning using Kalman Filter for  Linear Least Squares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=John%2C+M">Majnu John</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yihren Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Interleaved learning in machine learning algorithms is a biologically
inspired training method with promising results. In this short note, we
illustrate the interleaving mechanism via a simple statistical and optimization
framework based on Kalman Filter for Linear Least Squares.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03752" title="Abstract">arXiv:2310.03752</a> (cross-list from eess.SP) [<a href="/pdf/2310.03752" title="Download PDF">pdf</a>, <a href="/format/2310.03752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Sequential Decoder for Transient High-Density  Electromyography in Hand Gesture Recognition Using Subject-Embedded Transfer  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Azar%2C+G+A">Golara Ahmadi Azar</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Q">Qin Hu</a>, 
<a href="/search/eess?searchtype=author&query=Emami%2C+M">Melika Emami</a>, 
<a href="/search/eess?searchtype=author&query=Fletcher%2C+A">Alyson Fletcher</a>, 
<a href="/search/eess?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>, 
<a href="/search/eess?searchtype=author&query=Atashzar%2C+S+F">S. Farokh Atashzar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Hand gesture recognition (HGR) has gained significant attention due to the
increasing use of AI-powered human-computer interfaces that can interpret the
deep spatiotemporal dynamics of biosignals from the peripheral nervous system,
such as surface electromyography (sEMG). These interfaces have a range of
applications, including the control of extended reality, agile prosthetics, and
exoskeletons. However, the natural variability of sEMG among individuals has
led researchers to focus on subject-specific solutions. Deep learning methods,
which often have complex structures, are particularly data-hungry and can be
time-consuming to train, making them less practical for subject-specific
applications. In this paper, we propose and develop a generalizable, sequential
decoder of transient high-density sEMG (HD-sEMG) that achieves 73% average
accuracy on 65 gestures for partially-observed subjects through
subject-embedded transfer learning, leveraging pre-knowledge of HGR acquired
during pre-training. The use of transient HD-sEMG before gesture stabilization
allows us to predict gestures with the ultimate goal of counterbalancing system
control delays. The results show that the proposed generalized models
significantly outperform subject-specific approaches, especially when the
training data is limited, and there is a significant number of gesture classes.
By building on pre-knowledge and incorporating a multiplicative
subject-embedded structure, our method comparatively achieves more than 13%
average accuracy across partially observed subjects with minimal data
availability. This work highlights the potential of HD-sEMG and demonstrates
the benefits of modeling common patterns across users to reduce the need for
large amounts of data for new users, enhancing practicality.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03753" title="Abstract">arXiv:2310.03753</a> (cross-list from eess.SP) [<a href="/pdf/2310.03753" title="Download PDF">pdf</a>, <a href="/format/2310.03753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECGNet: A generative adversarial network (GAN) approach to the synthesis  of 12-lead ECG signals from single lead inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bagga%2C+M">Max Bagga</a>, 
<a href="/search/eess?searchtype=author&query=Jeon%2C+H">Hyunbae Jeon</a>, 
<a href="/search/eess?searchtype=author&query=Issokson%2C+A">Alex Issokson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electrocardiography (ECG) signal generation has been heavily explored using
generative adversarial networks (GAN) because the implementation of 12-lead
ECGs is not always feasible. The GAN models have achieved remarkable results in
reproducing ECG signals but are only designed for multiple lead inputs and the
features the GAN model preserves have not been identified-limiting the
generated signals use in cardiovascular disease (CVD)-predictive models. This
paper presents ECGNet which is a procedure that generates a complete set of
12-lead ECG signals from any single lead input using a GAN framework with a
bidirectional long short-term memory (LSTM) generator and a convolutional
neural network (CNN) discriminator. Cross and auto-correlation analysis
performed on the generated signals identifies features conserved during the
signal generation-i.e., features that can characterize the unique-nature of
each signal and thus likely indicators of CVD. Finally, by using ECG signals
annotated with the CVD-indicative features detailed by the correlation analysis
as inputs for a CVD-onset-predictive CNN model, we overcome challenges
preventing the prediction of multiple-CVD targets. Our models are experimented
on 15s 12-lead ECG dataset recorded using MyoVista's wavECG. Functional outcome
data for each patient is recorded and used in the CVD-predictive model. Our
best GAN model achieves state-of-the-art accuracy with Frechet Distance (FD)
scores of 4.73, 4.89, 5.18, 4.77, 4.71, and 5.55 on the V1-V6 pre-cordial leads
respectively and shows strength in preserving the P-Q segments and R-peaks in
the generated signals. To the best of our knowledge, ECGNet is the first to
predict all of the remaining eleven leads from the input of any single lead.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03754" title="Abstract">arXiv:2310.03754</a> (cross-list from eess.SP) [<a href="/pdf/2310.03754" title="Download PDF">pdf</a>, <a href="/format/2310.03754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMGTFNet: Fuzzy Vision Transformer to decode Upperlimb sEMG signals for  Hand Gestures Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=C%C3%B3rdova%2C+J+C">Joseph Cherre C&#xf3;rdova</a>, 
<a href="/search/eess?searchtype=author&query=Flores%2C+C">Christian Flores</a>, 
<a href="/search/eess?searchtype=author&query=Andreu-Perez%2C+J">Javier Andreu-Perez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Fuzzy Systems (FUZZ)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Myoelectric control is an area of electromyography of increasing interest
nowadays, particularly in applications such as Hand Gesture Recognition (HGR)
for bionic prostheses. Today's focus is on pattern recognition using Machine
Learning and, more recently, Deep Learning methods. Despite achieving good
results on sparse sEMG signals, the latter models typically require large
datasets and training times. Furthermore, due to the nature of stochastic sEMG
signals, traditional models fail to generalize samples for atypical or noisy
values. In this paper, we propose the design of a Vision Transformer (ViT)
based architecture with a Fuzzy Neural Block (FNB) called EMGTFNet to perform
Hand Gesture Recognition from surface electromyography (sEMG) signals. The
proposed EMGTFNet architecture can accurately classify a variety of hand
gestures without any need for data augmentation techniques, transfer learning
or a significant increase in the number of parameters in the network. The
accuracy of the proposed model is tested using the publicly available NinaPro
database consisting of 49 different hand gestures. Experiments yield an average
test accuracy of 83.57\% \&amp; 3.5\% using a 200 ms window size and only 56,793
trainable parameters. Our results outperform the ViT without FNB, thus
demonstrating that including FNB improves its performance. Our proposal
framework EMGTFNet reported the significant potential for its practical
application for prosthetic control.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03756" title="Abstract">arXiv:2310.03756</a> (cross-list from eess.SP) [<a href="/pdf/2310.03756" title="Download PDF">pdf</a>, <a href="/format/2310.03756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-channel EEG Data Analysis for Poor Neuro-prognostication in  Comatose Patients with Self and Cross-channel Attention Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qadir%2C+H+A">Hemin Ali Qadir</a>, 
<a href="/search/eess?searchtype=author&query=Nesaragi%2C+N">Naimahmed Nesaragi</a>, 
<a href="/search/eess?searchtype=author&query=Halvorsen%2C+P+S">Per Steiner Halvorsen</a>, 
<a href="/search/eess?searchtype=author&query=Balasingham%2C+I">Ilangko Balasingham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, 50th Computing in Cardiology conference in Atlanta, Georgia, USA on 1st - 4th October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work investigates the predictive potential of bipolar
electroencephalogram (EEG) recordings towards efficient prediction of poor
neurological outcomes. A retrospective design using a hybrid deep learning
approach is utilized to optimize an objective function aiming for high
specificity, i.e., true positive rate (TPR) with reduced false positives (&lt;
0.05). A multi-channel EEG array of 18 bipolar channel pairs from a randomly
selected 5-minute segment in an hour is kept. In order to determine the outcome
prediction, a combination of a feature encoder with 1-D convolutional layers,
learnable position encoding, a context network with attention mechanisms, and
finally, a regressor and classifier blocks are used. The feature encoder
extricates local temporal and spatial features, while the following position
encoding and attention mechanisms attempt to capture global temporal
dependencies. Results: The proposed framework by our team, OUS IVS, when
validated on the challenge hidden validation data, exhibited a score of 0.57.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03757" title="Abstract">arXiv:2310.03757</a> (cross-list from eess.SP) [<a href="/pdf/2310.03757" title="Download PDF">pdf</a>, <a href="/format/2310.03757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Healthcare with EOG: A Novel Approach to Sleep Stage  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maiti%2C+S">Suvadeep Maiti</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+S+K">Shivam Kumar Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Bapi%2C+R+S">Raju S. Bapi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce an innovative approach to automated sleep stage classification
using EOG signals, addressing the discomfort and impracticality associated with
EEG data acquisition. In addition, it is important to note that this approach
is untapped in the field, highlighting its potential for novel insights and
contributions. Our proposed SE-Resnet-Transformer model provides an accurate
classification of five distinct sleep stages from raw EOG signal. Extensive
validation on publically available databases (SleepEDF-20, SleepEDF-78, and
SHHS) reveals noteworthy performance, with macro-F1 scores of 74.72, 70.63, and
69.26, respectively. Our model excels in identifying REM sleep, a crucial
aspect of sleep disorder investigations. We also provide insight into the
internal mechanisms of our model using techniques such as 1D-GradCAM and t-SNE
plots. Our method improves the accessibility of sleep stage classification
while decreasing the need for EEG modalities. This development will have
promising implications for healthcare and the incorporation of wearable
technology into sleep studies, thereby advancing the field's potential for
enhanced diagnostics and patient comfort.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03758" title="Abstract">arXiv:2310.03758</a> (cross-list from eess.SP) [<a href="/pdf/2310.03758" title="Download PDF">pdf</a>, <a href="/format/2310.03758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Uniform Signal Recovery in Nonlinear Generative  Compressed Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Junren Chen</a>, 
<a href="/search/eess?searchtype=author&query=Scarlett%2C+J">Jonathan Scarlett</a>, 
<a href="/search/eess?searchtype=author&query=Ng%2C+M+K">Michael K. Ng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhaoqiang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In generative compressed sensing (GCS), we want to recover a signal
$\mathbf{x}^* \in \mathbb{R}^n$ from $m$ measurements ($m\ll n$) using a
generative prior $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$, where $G$ is typically
an $L$-Lipschitz continuous generative model and $\mathbb{B}_2^k(r)$ represents
the radius-$r$ $\ell_2$-ball in $\mathbb{R}^k$. Under nonlinear measurements,
most prior results are non-uniform, i.e., they hold with high probability for a
fixed $\mathbf{x}^*$ rather than for all $\mathbf{x}^*$ simultaneously. In this
paper, we build a unified framework to derive uniform recovery guarantees for
nonlinear GCS where the observation model is nonlinear and possibly
discontinuous or unknown. Our framework accommodates GCS with 1-bit/uniformly
quantized observations and single index models as canonical examples.
Specifically, using a single realization of the sensing ensemble and
generalized Lasso, {\em all} $\mathbf{x}^*\in G(\mathbb{B}_2^k(r))$ can be
recovered up to an $\ell_2$-error at most $\epsilon$ using roughly
$\tilde{O}({k}/{\epsilon^2})$ samples, with omitted logarithmic factors
typically being dominated by $\log L$. Notably, this almost coincides with
existing non-uniform guarantees up to logarithmic factors, hence the uniformity
costs very little. As part of our technical contributions, we introduce the
Lipschitz approximation to handle discontinuous observation models. We also
develop a concentration inequality that produces tighter bounds for product
processes whose index sets have low metric entropy. Experimental results are
presented to corroborate our theory.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03759" title="Abstract">arXiv:2310.03759</a> (cross-list from eess.SP) [<a href="/pdf/2310.03759" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Deep Learning Technique for Morphology Preserved Fetal ECG  Extraction from Mother ECG using 1D-CycleGAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Basak%2C+P">Promit Basak</a>, 
<a href="/search/eess?searchtype=author&query=Sakib%2C+A+H+M+N">A.H.M Nazmus Sakib</a>, 
<a href="/search/eess?searchtype=author&query=Chowdhury%2C+M+E+H">Muhammad E. H. Chowdhury</a>, 
<a href="/search/eess?searchtype=author&query=Al-Emadi%2C+N">Nasser Al-Emadi</a>, 
<a href="/search/eess?searchtype=author&query=Yalcin%2C+H+C">Huseyin Cagatay Yalcin</a>, 
<a href="/search/eess?searchtype=author&query=Pedersen%2C+S">Shona Pedersen</a>, 
<a href="/search/eess?searchtype=author&query=Mahmud%2C+S">Sakib Mahmud</a>, 
<a href="/search/eess?searchtype=author&query=Kiranyaz%2C+S">Serkan Kiranyaz</a>, 
<a href="/search/eess?searchtype=author&query=Al-Maadeed%2C+S">Somaya Al-Maadeed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 235, 2024, 121196, ISSN
  0957-4174
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Monitoring the electrical pulse of fetal heart through a non-invasive fetal
electrocardiogram (fECG) can easily detect abnormalities in the developing
heart to significantly reduce the infant mortality rate and post-natal
complications. Due to the overlapping of maternal and fetal R-peaks, the low
amplitude of the fECG, systematic and ambient noises, typical signal extraction
methods, such as adaptive filters, independent component analysis, empirical
mode decomposition, etc., are unable to produce satisfactory fECG. While some
techniques can produce accurate QRS waves, they often ignore other important
aspects of the ECG. Our approach, which is based on 1D CycleGAN, can
reconstruct the fECG signal from the mECG signal while maintaining the
morphology due to extensive preprocessing and appropriate framework. The
performance of our solution was evaluated by combining two available datasets
from Physionet, "Abdominal and Direct Fetal ECG Database" and "Fetal
electrocardiograms, direct and abdominal with reference heartbeat annotations",
where it achieved an average PCC and Spectral-Correlation score of 88.4% and
89.4%, respectively. It detects the fQRS of the signal with accuracy,
precision, recall and F1 score of 92.6%, 97.6%, 94.8% and 96.4%, respectively.
It can also accurately produce the estimation of fetal heart rate and R-R
interval with an error of 0.25% and 0.27%, respectively. The main contribution
of our work is that, unlike similar studies, it can retain the morphology of
the ECG signal with high fidelity. The accuracy of our solution for fetal heart
rate and R-R interval length is comparable to existing state-of-the-art
techniques. This makes it a highly effective tool for early diagnosis of fetal
heart diseases and regular health checkups of the fetus.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03760" title="Abstract">arXiv:2310.03760</a> (cross-list from eess.SP) [<a href="/pdf/2310.03760" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Deep Neural Network Architecture and Feature Extraction  Designs for Sensor-based Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ahangarani%2C+D">Danial Ahangarani</a>, 
<a href="/search/eess?searchtype=author&query=Shirazi%2C+M">Mohammad Shirazi</a>, 
<a href="/search/eess?searchtype=author&query=Ashraf%2C+N">Navid Ashraf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Seventh International Conference on Internet of Things and Applications (IoT 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The extensive ubiquitous availability of sensors in smart devices and the
Internet of Things (IoT) has opened up the possibilities for implementing
sensor-based activity recognition. As opposed to traditional sensor time-series
processing and hand-engineered feature extraction, in light of deep learning's
proven effectiveness across various domains, numerous deep methods have been
explored to tackle the challenges in activity recognition, outperforming the
traditional signal processing and traditional machine learning approaches. In
this work, by performing extensive experimental studies on two human activity
recognition datasets, we investigate the performance of common deep learning
and machine learning approaches as well as different training mechanisms (such
as contrastive learning), and various feature representations extracted from
the sensor time-series data and measure their effectiveness for the human
activity recognition task.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03762" title="Abstract">arXiv:2310.03762</a> (cross-list from eess.SP) [<a href="/pdf/2310.03762" title="Download PDF">pdf</a>, <a href="/format/2310.03762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Multicarrier Multiantenna Systems for LoS Channel Charting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yassine%2C+T">Taha Yassine</a> (IRT b-com, Hypermedia), 
<a href="/search/eess?searchtype=author&query=Magoarou%2C+L+L">Luc Le Magoarou</a> (INSA Rennes, IETR), 
<a href="/search/eess?searchtype=author&query=Crussi%C3%A8re%2C+M">Matthieu Crussi&#xe8;re</a> (IETR), 
<a href="/search/eess?searchtype=author&query=Paquelet%2C+S">Stephane Paquelet</a> (IRT b-com)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Channel charting (CC) consists in learning a mapping between the space of raw
channel observations, made available from pilot-based channel estimation in
multicarrier multiantenna system, and a low-dimensional space where close
points correspond to channels of user equipments (UEs) close spatially. Among
the different methods of learning this mapping, some rely on a distance measure
between channel vectors. Such a distance should reliably reflect the local
spatial neighborhoods of the UEs. The recently proposed phase-insensitive (PI)
distance exhibits good properties in this regards, but suffers from ambiguities
due to both its periodic and oscillatory aspects, making users far away from
each other appear closer in some cases. In this paper, a thorough theoretical
analysis of the said distance and its limitations is provided, giving insights
on how they can be mitigated. Guidelines for designing systems capable of
learning quality charts are consequently derived. Experimental validation is
then conducted on synthetic and realistic data in different scenarios.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03789" title="Abstract">arXiv:2310.03789</a> (cross-list from stat.ML) [<a href="/pdf/2310.03789" title="Download PDF">pdf</a>, <a href="/format/2310.03789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Droplets of Good Representations: Grokking as a First Order Phase  Transition in Two Layer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rubin%2C+N">Noa Rubin</a>, 
<a href="/search/stat?searchtype=author&query=Seroussi%2C+I">Inbar Seroussi</a>, 
<a href="/search/stat?searchtype=author&query=Ringel%2C+Z">Zohar Ringel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
<p class="mathjax">A key property of deep neural networks (DNNs) is their ability to learn new
features during training. This intriguing aspect of deep learning stands out
most clearly in recently reported Grokking phenomena. While mainly reflected as
a sudden increase in test accuracy, Grokking is also believed to be a beyond
lazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here
we apply a recent development in the theory of feature learning, the adaptive
kernel approach, to two teacher-student models with cubic-polynomial and
modular addition teachers. We provide analytical predictions on feature
learning and Grokking properties of these models and demonstrate a mapping
between Grokking and the theory of phase transitions. We show that after
Grokking, the state of the DNN is analogous to the mixed phase following a
first-order phase transition. In this mixed phase, the DNN generates useful
internal representations of the teacher that are sharply distinct from those
before the transition.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03808" title="Abstract">arXiv:2310.03808</a> (cross-list from math.OC) [<a href="/pdf/2310.03808" title="Download PDF">pdf</a>, <a href="/format/2310.03808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safe First-Order Method for Pricing-Based Resource Allocation in  Safety-Critical Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Turan%2C+B">Berkay Turan</a>, 
<a href="/search/math?searchtype=author&query=Hutchinson%2C+S">Spencer Hutchinson</a>, 
<a href="/search/math?searchtype=author&query=Alizadeh%2C+M">Mahnoosh Alizadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We introduce a novel algorithm for solving network utility maximization (NUM)
problems that arise in resource allocation schemes over networks with known
safety-critical constraints, where the constraints form an arbitrary convex and
compact feasible set. Inspired by applications where customers' demand can only
be affected through posted prices and real-time two-way communication with
customers is not available, we require an algorithm to generate ``safe
prices''. This means that at no iteration should the realized demand in
response to the posted prices violate the safety constraints of the network.
Thus, in contrast to existing distributed first-order methods, our algorithm,
called safe pricing for NUM (SPNUM), is guaranteed to produce feasible primal
iterates at all iterations. At the heart of the algorithm lie two key steps
that must go hand in hand to guarantee safety and convergence: 1) applying a
projected gradient method on a shrunk feasible set to get the desired demand,
and 2) estimating the price response function of the users and determining the
price so that the induced demand is close to the desired demand. We ensure
safety by adjusting the shrinkage to account for the error between the induced
demand and the desired demand. In addition, by gradually reducing the amount of
shrinkage and the step size of the gradient method, we prove that the primal
iterates produced by the SPNUM achieve a sublinear static regret of ${\cal
O}(\log{(T)})$ after $T$ time steps.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03845" title="Abstract">arXiv:2310.03845</a> (cross-list from astro-ph.EP) [<a href="/pdf/2310.03845" title="Download PDF">pdf</a>, <a href="/format/2310.03845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Euclid: Identification of asteroid streaks in simulated images using  deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=P%C3%B6ntinen%2C+M">M. P&#xf6;ntinen</a> (1), 
<a href="/search/astro-ph?searchtype=author&query=Granvik%2C+M">M. Granvik</a> (1 and 2), 
<a href="/search/astro-ph?searchtype=author&query=Nucita%2C+A+A">A. A. Nucita</a> (3 and 4 and 5), 
<a href="/search/astro-ph?searchtype=author&query=Conversi%2C+L">L. Conversi</a> (6 and 7), 
<a href="/search/astro-ph?searchtype=author&query=Altieri%2C+B">B. Altieri</a> (7), 
<a href="/search/astro-ph?searchtype=author&query=Carry%2C+B">B. Carry</a> (8), 
<a href="/search/astro-ph?searchtype=author&query=O%27Riordan%2C+C+M">C. M. O&#x27;Riordan</a> (9), 
<a href="/search/astro-ph?searchtype=author&query=Scott%2C+D">D. Scott</a> (10), 
<a href="/search/astro-ph?searchtype=author&query=Aghanim%2C+N">N. Aghanim</a> (11), 
<a href="/search/astro-ph?searchtype=author&query=Amara%2C+A">A. Amara</a> (12), 
<a href="/search/astro-ph?searchtype=author&query=Amendola%2C+L">L. Amendola</a> (13), 
<a href="/search/astro-ph?searchtype=author&query=Auricchio%2C+N">N. Auricchio</a> (14), 
<a href="/search/astro-ph?searchtype=author&query=Baldi%2C+M">M. Baldi</a> (15 and 14 and 16), 
<a href="/search/astro-ph?searchtype=author&query=Bonino%2C+D">D. Bonino</a> (17), 
<a href="/search/astro-ph?searchtype=author&query=Branchini%2C+E">E. Branchini</a> (18 and 19), 
<a href="/search/astro-ph?searchtype=author&query=Brescia%2C+M">M. Brescia</a> (20 and 21), 
<a href="/search/astro-ph?searchtype=author&query=Camera%2C+S">S. Camera</a> (22 and 23 and 17), 
<a href="/search/astro-ph?searchtype=author&query=Capobianco%2C+V">V. Capobianco</a> (17), 
<a href="/search/astro-ph?searchtype=author&query=Carbone%2C+C">C. Carbone</a> (24), 
<a href="/search/astro-ph?searchtype=author&query=Carretero%2C+J">J. Carretero</a> (25 and 26), 
<a href="/search/astro-ph?searchtype=author&query=Castellano%2C+M">M. Castellano</a> (27), 
<a href="/search/astro-ph?searchtype=author&query=Cavuoti%2C+S">S. Cavuoti</a> (21 and 28), 
<a href="/search/astro-ph?searchtype=author&query=Cimatti%2C+A">A. Cimatti</a> (29), 
<a href="/search/astro-ph?searchtype=author&query=Cledassou%2C+R">R. Cledassou</a> (30 and 31), 
<a href="/search/astro-ph?searchtype=author&query=Congedo%2C+G">G. Congedo</a> (32), 
<a href="/search/astro-ph?searchtype=author&query=Copin%2C+Y">Y. Copin</a> (33), 
<a href="/search/astro-ph?searchtype=author&query=Corcione%2C+L">L. Corcione</a> (17), 
<a href="/search/astro-ph?searchtype=author&query=Courbin%2C+F">F. Courbin</a> (34), 
<a href="/search/astro-ph?searchtype=author&query=Cropper%2C+M">M. Cropper</a> (35), 
<a href="/search/astro-ph?searchtype=author&query=Da+Silva%2C+A">A. Da Silva</a> (36 and 37), 
<a href="/search/astro-ph?searchtype=author&query=Degaudenzi%2C+H">H. Degaudenzi</a> (38), 
<a href="/search/astro-ph?searchtype=author&query=Dinis%2C+J">J. Dinis</a> (37 and 36), 
<a href="/search/astro-ph?searchtype=author&query=Dubath%2C+F">F. Dubath</a> (38), 
<a href="/search/astro-ph?searchtype=author&query=Dupac%2C+X">X. Dupac</a> (7), 
<a href="/search/astro-ph?searchtype=author&query=Dusini%2C+S">S. Dusini</a> (39), 
<a href="/search/astro-ph?searchtype=author&query=Farrens%2C+S">S. Farrens</a> (40), 
<a href="/search/astro-ph?searchtype=author&query=Ferriol%2C+S">S. Ferriol</a> (33), 
<a href="/search/astro-ph?searchtype=author&query=Frailis%2C+M">M. Frailis</a> (41), 
<a href="/search/astro-ph?searchtype=author&query=Franceschi%2C+E">E. Franceschi</a> (14), 
<a href="/search/astro-ph?searchtype=author&query=Fumana%2C+M">M. Fumana</a> (24), 
<a href="/search/astro-ph?searchtype=author&query=Galeotta%2C+S">S. Galeotta</a> (41),  et al. (76 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Up to 150000 asteroids will be visible in the images of the ESA Euclid space
telescope, and the instruments of Euclid offer multiband visual to
near-infrared photometry and slitless spectra of these objects. Most asteroids
will appear as streaks in the images. Due to the large number of images and
asteroids, automated detection methods are needed. A non-machine-learning
approach based on the StreakDet software was previously tested, but the results
were not optimal for short and/or faint streaks. We set out to improve the
capability to detect asteroid streaks in Euclid images by using deep learning.
<br />We built, trained, and tested a three-step machine-learning pipeline with
simulated Euclid images. First, a convolutional neural network (CNN) detected
streaks and their coordinates in full images, aiming to maximize the
completeness (recall) of detections. Then, a recurrent neural network (RNN)
merged snippets of long streaks detected in several parts by the CNN. Lastly,
gradient-boosted trees (XGBoost) linked detected streaks between different
Euclid exposures to reduce the number of false positives and improve the purity
(precision) of the sample.
<br />The deep-learning pipeline surpasses the completeness and reaches a similar
level of purity of a non-machine-learning pipeline based on the StreakDet
software. Additionally, the deep-learning pipeline can detect asteroids
0.25-0.5 magnitudes fainter than StreakDet. The deep-learning pipeline could
result in a 50% increase in the number of detected asteroids compared to the
StreakDet software. There is still scope for further refinement, particularly
in improving the accuracy of streak coordinates and enhancing the completeness
of the final stage of the pipeline, which involves linking detections across
multiple exposures.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03849" title="Abstract">arXiv:2310.03849</a> (cross-list from math.CO) [<a href="/pdf/2310.03849" title="Download PDF">pdf</a>, <a href="/ps/2310.03849" title="Download PostScript">ps</a>, <a href="/format/2310.03849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On two conjectures about the intersection of longest paths and cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guti%C3%A9rrez%2C+J">Juan Guti&#xe9;rrez</a>, 
<a href="/search/math?searchtype=author&query=Valqui%2C+C">Christian Valqui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A conjecture attributed to Smith states that every pair of longest cycles in
a $k$-connected graph intersect each other in at least $k$ vertices. In this
paper, we show that every pair of longest cycles in a~$k$-connected graph on
$n$ vertices intersect each other in at least~$\min\{n,8k-n-16\}$ vertices,
which confirms Smith's conjecture when $k\geq (n+16)/7$. An analog conjecture
for paths instead of cycles was stated by Hippchen. By a simple reduction, we
relate both conjectures, showing that Hippchen's conjecture is valid when
either $k \leq 6$ or $k \geq (n+9)/7$.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03872" title="Abstract">arXiv:2310.03872</a> (cross-list from eess.IV) [<a href="/pdf/2310.03872" title="Download PDF">pdf</a>, <a href="/format/2310.03872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FNOSeg3D: Resolution-Robust 3D Image Segmentation with Fourier Neural  Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wong%2C+K+C+L">Ken C. L. Wong</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongzhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Syeda-Mahmood%2C+T">Tanveer Syeda-Mahmood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by the IEEE International Symposium on Biomedical Imaging (ISBI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Due to the computational complexity of 3D medical image segmentation,
training with downsampled images is a common remedy for out-of-memory errors in
deep learning. Nevertheless, as standard spatial convolution is sensitive to
variations in image resolution, the accuracy of a convolutional neural network
trained with downsampled images can be suboptimal when applied on the original
resolution. To address this limitation, we introduce FNOSeg3D, a 3D
segmentation model robust to training image resolution based on the Fourier
neural operator (FNO). The FNO is a deep learning framework for learning
mappings between functions in partial differential equations, which has the
appealing properties of zero-shot super-resolution and global receptive field.
We improve the FNO by reducing its parameter requirement and enhancing its
learning capability through residual connections and deep supervision, and
these result in our FNOSeg3D model which is parameter efficient and resolution
robust. When tested on the BraTS'19 dataset, it achieved superior robustness to
training image resolution than other tested models with less than 1% of their
model parameters.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03874" title="Abstract">arXiv:2310.03874</a> (cross-list from physics.med-ph) [<a href="/pdf/2310.03874" title="Download PDF">pdf</a>, <a href="/format/2310.03874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking a foundation LLM on its ability to re-label structure names  in accordance with the AAPM TG-263 report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Holmes%2C+J">Jason Holmes</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+L">Lian Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Ding%2C+Y">Yuzhen Ding</a>, 
<a href="/search/physics?searchtype=author&query=Feng%2C+H">Hongying Feng</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/physics?searchtype=author&query=Wong%2C+W+W">William W. Wong</a>, 
<a href="/search/physics?searchtype=author&query=Vora%2C+S+A">Sujay A. Vora</a>, 
<a href="/search/physics?searchtype=author&query=Ashman%2C+J+B">Jonathan B. Ashman</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Purpose: To introduce the concept of using large language models (LLMs) to
re-label structure names in accordance with the American Association of
Physicists in Medicine (AAPM) Task Group (TG)-263 standard, and to establish a
benchmark for future studies to reference.
<br />Methods and Materials: The Generative Pre-trained Transformer (GPT)-4
application programming interface (API) was implemented as a Digital Imaging
and Communications in Medicine (DICOM) storage server, which upon receiving a
structure set DICOM file, prompts GPT-4 to re-label the structure names of both
target volumes and normal tissues according to the AAPM TG-263. Three disease
sites, prostate, head and neck, and thorax were selected for evaluation. For
each disease site category, 150 patients were randomly selected for manually
tuning the instructions prompt (in batches of 50) and 50 patients were randomly
selected for evaluation. Structure names that were considered were those that
were most likely to be relevant for studies utilizing structure contours for
many patients.
<br />Results: The overall re-labeling accuracy of both target volumes and normal
tissues for prostate, head and neck, and thorax cases was 96.0%, 98.5%, and
96.9% respectively. Re-labeling of target volumes was less accurate on average
except for prostate - 100%, 93.1%, and 91.1% respectively.
<br />Conclusions: Given the accuracy of GPT-4 in re-labeling structure names of
both target volumes and normal tissues as presented in this work, LLMs are
poised to be the preferred method for standardizing structure names in
radiation oncology, especially considering the rapid advancements in LLM
capabilities that are likely to continue.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03889" title="Abstract">arXiv:2310.03889</a> (cross-list from eess.AS) [<a href="/pdf/2310.03889" title="Download PDF">pdf</a>, <a href="/ps/2310.03889" title="Download PostScript">ps</a>, <a href="/format/2310.03889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Event-Relational Graph Representation Learning for Acoustic Scene  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hou%2C+Y">Yuanbo Hou</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+S">Siyang Song</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+C">Chuang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Botteldooren%2C+D">Dick Botteldooren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Signal Processing Letters, doi: 10.1109/LSP.2023.3319233
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Most deep learning-based acoustic scene classification (ASC) approaches
identify scenes based on acoustic features converted from audio clips
containing mixed information entangled by polyphonic audio events (AEs).
However, these approaches have difficulties in explaining what cues they use to
identify scenes. This paper conducts the first study on disclosing the
relationship between real-life acoustic scenes and semantic embeddings from the
most relevant AEs. Specifically, we propose an event-relational graph
representation learning (ERGL) framework for ASC to classify scenes, and
simultaneously answer clearly and straightly which cues are used in
classifying. In the event-relational graph, embeddings of each event are
treated as nodes, while relationship cues derived from each pair of nodes are
described by multi-dimensional edge features. Experiments on a real-life ASC
dataset show that the proposed ERGL achieves competitive performance on ASC by
learning embeddings of only a limited number of AEs. The results show the
feasibility of recognizing diverse acoustic scenes based on the audio
event-relational graph. Visualizations of graph representations learned by ERGL
are available here (https://github.com/Yuanbo2020/ERGL).
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03901" title="Abstract">arXiv:2310.03901</a> (cross-list from eess.AS) [<a href="/pdf/2310.03901" title="Download PDF">pdf</a>, <a href="/format/2310.03901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges and Insights: Exploring 3D Spatial Features and Complex  Networks on the MISP Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+Y">Yiwen Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Multi-channel multi-talker speech recognition presents formidable challenges
in the realm of speech processing, marked by issues such as background noise,
reverberation, and overlapping speech. Overcoming these complexities requires
leveraging contextual cues to separate target speech from a cacophonous mix,
enabling accurate recognition. Among these cues, the 3D spatial feature has
emerged as a cutting-edge solution, particularly when equipped with spatial
information about the target speaker. Its exceptional ability to discern the
target speaker within mixed audio, often rendering intermediate processing
redundant, paves the way for the direct training of "All-in-one" ASR models.
These models have demonstrated commendable performance on both simulated and
real-world data. In this paper, we extend this approach to the MISP dataset to
further validate its efficacy. We delve into the challenges encountered and
insights gained when applying 3D spatial features to MISP, while also exploring
preliminary experiments involving the replacement of these features with more
complex input and models.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03902" title="Abstract">arXiv:2310.03902</a> (cross-list from stat.ML) [<a href="/pdf/2310.03902" title="Download PDF">pdf</a>, <a href="/format/2310.03902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable benefits of annealing for estimating normalizing constants:  Importance Sampling, Noise-Contrastive Estimation, and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chehab%2C+O">Omar Chehab</a>, 
<a href="/search/stat?searchtype=author&query=Hyvarinen%2C+A">Aapo Hyvarinen</a>, 
<a href="/search/stat?searchtype=author&query=Risteski%2C+A">Andrej Risteski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent research has developed several Monte Carlo methods for estimating the
normalization constant (partition function) based on the idea of annealing.
This means sampling successively from a path of distributions that interpolate
between a tractable "proposal" distribution and the unnormalized "target"
distribution. Prominent estimators in this family include annealed importance
sampling and annealed noise-contrastive estimation (NCE). Such methods hinge on
a number of design choices: which estimator to use, which path of distributions
to use and whether to use a path at all; so far, there is no definitive theory
on which choices are efficient. Here, we evaluate each design choice by the
asymptotic estimation error it produces. First, we show that using NCE is more
efficient than the importance sampling estimator, but in the limit of
infinitesimal path steps, the difference vanishes. Second, we find that using
the geometric path brings down the estimation error from an exponential to a
polynomial function of the parameter distance between the target and proposal
distributions. Third, we find that the arithmetic path, while rarely used, can
offer optimality properties over the universally-used geometric path. In fact,
in a particular limit, the optimal path is arithmetic. Based on this theory, we
finally propose a two-step estimator to approximate the optimal path in an
efficient way.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03942" title="Abstract">arXiv:2310.03942</a> (cross-list from quant-ph) [<a href="/pdf/2310.03942" title="Download PDF">pdf</a>, <a href="/format/2310.03942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Distributed Quantum Computing by Qubit and Gate Graph  Partitioning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Davis%2C+M+G">Marc Grau Davis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chung%2C+J">Joaquin Chung</a>, 
<a href="/search/quant-ph?searchtype=author&query=Englund%2C+D">Dirk Englund</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kettimuthu%2C+R">Rajkumar Kettimuthu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at IEEE Quantum Week 2023 (QCE23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Distributed quantum computing is motivated by the difficulty in building
large-scale, individual quantum computers. To solve that problem, a large
quantum circuit is partitioned and distributed to small quantum computers for
execution. Partitions running on different quantum computers share quantum
information using entangled Bell pairs. However, entanglement generation and
purification introduces both a runtime and memory overhead on distributed
quantum computing. In this paper we study that trade-off by proposing two
techniques for partitioning large quantum circuits and for distribution to
small quantum computers. Our techniques map a quantum circuit to a graph
representation. We study two approaches: one that considers only gate
teleportation, and another that considers both gate and state teleportation to
achieve the distributed execution. Then we apply the METIS graph partitioning
algorithm to obtain the partitions and the number of entanglement requests
between them. We use the SeQUeNCe quantum communication simulator to measure
the time required for generating all the entanglements required to execute the
distributed circuit. We find that the best partitioning technique will depend
on the specific circuit of interest.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03945" title="Abstract">arXiv:2310.03945</a> (cross-list from stat.ML) [<a href="/pdf/2310.03945" title="Download PDF">pdf</a>, <a href="/format/2310.03945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Wasserstein distances for affine transformations of random vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hamm%2C+K">Keaton Hamm</a>, 
<a href="/search/stat?searchtype=author&query=Korzeniowski%2C+A">Andrzej Korzeniowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We expound on some known lower bounds of the quadratic Wasserstein distance
between random vectors in $\mathbb{R}^n$ with an emphasis on affine
transformations that have been used in manifold learning of data in Wasserstein
space. In particular, we give concrete lower bounds for rotated copies of
random vectors in $\mathbb{R}^2$ with uncorrelated components by computing the
Bures metric between the covariance matrices. We also derive upper bounds for
compositions of affine maps which yield a fruitful variety of diffeomorphisms
applied to an initial data measure. We apply these bounds to various
distributions including those lying on a 1-dimensional manifold in
$\mathbb{R}^2$ and illustrate the quality of the bounds. Finally, we give a
framework for mimicking handwritten digit or alphabet datasets that can be
applied in a manifold learning framework.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03978" title="Abstract">arXiv:2310.03978</a> (cross-list from quant-ph) [<a href="/pdf/2310.03978" title="Download PDF">pdf</a>, <a href="/format/2310.03978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantum Circuit Simulation by Tensor Network Methods on Modern  GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+F">Feng Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+H">Hanfeng Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kuang%2C+L">Lvlin Kuang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+B">Bing Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Efficient simulation of quantum circuits has become indispensable with the
rapid development of quantum hardware. The primary simulation methods are based
on state vectors and tensor networks. As the number of qubits and quantum gates
grows larger in current quantum devices, traditional state-vector based quantum
circuit simulation methods prove inadequate due to the overwhelming size of the
Hilbert space and extensive entanglement. Consequently, brutal force tensor
network simulation algorithms become the only viable solution in such
scenarios. The two main challenges faced in tensor network simulation
algorithms are optimal contraction path finding and efficient execution on
modern computing devices, with the latter determines the actual efficiency. In
this study, we investigate the optimization of such tensor network simulations
on modern GPUs and propose general optimization strategies from two aspects:
computational efficiency and accuracy. Firstly, we propose to transform
critical Einstein summation operations into GEMM operations, leveraging the
specific features of tensor network simulations to amplify the efficiency of
GPUs. Secondly, by analyzing the data characteristics of quantum circuits, we
employ extended precision to ensure the accuracy of simulation results and
mixed precision to fully exploit the potential of GPUs, resulting in faster and
more precise simulations. Our numerical experiments demonstrate that our
approach can achieve a 3.96x reduction in verification time for random quantum
circuit samples in the 18-cycle case of Sycamore, with sustained performance
exceeding 21 TFLOPS on one A100. This method can be easily extended to the
20-cycle case, maintaining the same performance, accelerating by 12.5x compared
to the state-of-the-art CPU-based results and 4.48-6.78x compared to the
state-of-the-art GPU-based results reported in the literature.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03993" title="Abstract">arXiv:2310.03993</a> (cross-list from math.AC) [<a href="/pdf/2310.03993" title="Download PDF">pdf</a>, <a href="/ps/2310.03993" title="Download PostScript">ps</a>, <a href="/format/2310.03993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong Algebras and Radical Sylvester-Gallai Configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Oliveira%2C+R">Rafael Oliveira</a>, 
<a href="/search/math?searchtype=author&query=Sengupta%2C+A+K">Akash Kumar Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages. Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Computational Complexity (cs.CC); Algebraic Geometry (math.AG); Combinatorics (math.CO)

</div>
<p class="mathjax">In this paper, we prove the following non-linear generalization of the
classical Sylvester-Gallai theorem. Let $\mathbb{K}$ be an algebraically closed
field of characteristic $0$, and $\mathcal{F}=\{F_1,\cdots,F_m\} \subset
\mathbb{K}[x_1,\cdots,x_N]$ be a set of irreducible homogeneous polynomials of
degree at most $d$ such that $F_i$ is not a scalar multiple of $F_j$ for $i\neq
j$. Suppose that for any two distinct $F_i,F_j\in \mathcal{F}$, there is $k\neq
i,j$ such that $F_k\in \mathrm{rad}(F_i,F_j)$. We prove that such radical SG
configurations must be low dimensional. More precisely, we show that there
exists a function $\lambda : \mathbb{N} \to \mathbb{N}$, independent of
$\mathbb{K},N$ and $m$, such that any such configuration $\mathcal{F}$ must
satisfy
<br />$$ \dim (\mathrm{span}_{\mathbb{K}}{\mathcal{F}}) \leq \lambda(d). $$
<br />Our result confirms a conjecture of Gupta [Gup14, Conjecture 2] and
generalizes the quadratic and cubic Sylvester-Gallai theorems of [S20,OS22].
Our result takes us one step closer towards the first deterministic polynomial
time algorithm for the Polynomial Identity Testing (PIT) problem for depth-4
circuits of bounded top and bottom fanins. Our result, when combined with the
Stillman uniformity type results of [AH20a,DLL19,ESS21], yields uniform bounds
for several algebraic invariants such as projective dimension, Betti numbers
and Castelnuovo-Mumford regularity of ideals generated by radical SG
configurations.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04006" title="Abstract">arXiv:2310.04006</a> (cross-list from math.OC) [<a href="/pdf/2310.04006" title="Download PDF">pdf</a>, <a href="/format/2310.04006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating optimization over the space of probability measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+S">Shi Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/math?searchtype=author&query=Tse%2C+O">Oliver Tse</a>, 
<a href="/search/math?searchtype=author&query=Wright%2C+S+J">Stephen J. Wright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Acceleration of gradient-based optimization methods is an issue of
significant practical and theoretical interest, particularly in machine
learning applications. Most research has focused on optimization over Euclidean
spaces, but given the need to optimize over spaces of probability measures in
many machine learning problems, it is of interest to investigate accelerated
gradient methods in this context too. To this end, we introduce a
Hamiltonian-flow approach that is analogous to moment-based approaches in
Euclidean space. We demonstrate that algorithms based on this approach can
achieve convergence rates of arbitrarily high order. Numerical examples
illustrate our claim.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04114" title="Abstract">arXiv:2310.04114</a> (cross-list from eess.IV) [<a href="/pdf/2310.04114" title="Download PDF">pdf</a>, <a href="/format/2310.04114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aorta Segmentation from 3D CT in MICCAI SEG.A. 2023 Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Myronenko%2C+A">Andriy Myronenko</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+D">Dong Yang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Y">Yufan He</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+D">Daguang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023, SEG.A. 2023 challenge 1st place
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Aorta provides the main blood supply of the body. Screening of aorta with
imaging helps for early aortic disease detection and monitoring. In this work,
we describe our solution to the Segmentation of the Aorta (SEG.A.231) from 3D
CT challenge. We use automated segmentation method Auto3DSeg available in
MONAI. Our solution achieves an average Dice score of 0.920 and 95th percentile
of the Hausdorff Distance (HD95) of 6.013, which ranks first and wins the
SEG.A. 2023 challenge.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04115" title="Abstract">arXiv:2310.04115</a> (cross-list from math.PR) [<a href="/pdf/2310.04115" title="Download PDF">pdf</a>, <a href="/format/2310.04115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov chain entropy games and the geometry of their Nash equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Choi%2C+M+C+H">Michael C.H. Choi</a>, 
<a href="/search/math?searchtype=author&query=Wolfer%2C+G">Geoffrey Wolfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Optimization and Control (math.OC); Computation (stat.CO)

</div>
<p class="mathjax">Consider the following two-person mixed strategy game of a probabilist
against Nature with respect to the parameters $(f, \mathcal{B},\pi)$, where $f$
is a convex function satisfying certain regularity conditions, $\mathcal{B}$ is
either the set $\{L_i\}_{i=1}^n$ or its convex hull with each $L_i$ being a
Markov infinitesimal generator on a finite state space $\mathcal{X}$ and $\pi$
is a given positive discrete distribution on $\mathcal{X}$. The probabilist
chooses a prior measure $\mu$ within the set of probability measures on
$\mathcal{B}$ denoted by $\mathcal{P}(\mathcal{B})$ and picks a $L \in
\mathcal{B}$ at random according to $\mu$, whereas Nature follows a pure
strategy to select $M \in \mathcal{L}(\pi)$, the set of $\pi$-reversible Markov
generators on $\mathcal{X}$. Nature pays an amount $D_f(M||L)$, the
$f$-divergence from $L$ to $M$, to the probabilist. We prove that a mixed
strategy Nash equilibrium always exists, and establish a minimax result on the
expected payoff of the game. This also contrasts with the pure strategy version
of the game where we show a Nash equilibrium may not exist. To find
approximately a mixed strategy Nash equilibrium, we propose and develop a
simple projected subgradient algorithm that provably converges with a rate of
$\mathcal{O}(1/\sqrt{t})$, where $t$ is the number of iterations. In addition,
we elucidate the relationships of Nash equilibrium with other seemingly
disparate notions such as weighted information centroid, Chebyshev center and
Bayes risk. This article generalizes the two-person game of a statistician
against Nature developed in the literature, and highlights the powerful
interplay and synergy between modern Markov chains theory and geometry,
information theory, game theory, optimization and mathematical statistics.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04141" title="Abstract">arXiv:2310.04141</a> (cross-list from math.OC) [<a href="/pdf/2310.04141" title="Download PDF">pdf</a>, <a href="/format/2310.04141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein distributionally robust risk-constrained iterative MPC for  motion planning: computationally efficient approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zolanvari%2C+A">Alireza Zolanvari</a>, 
<a href="/search/math?searchtype=author&query=Cherukuri%2C+A">Ashish Cherukuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, Proceedings of the IEEE Conference on Decision and Control, Singapore, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper considers a risk-constrained motion planning problem and aims to
find the solution combining the concepts of iterative model predictive control
(MPC) and data-driven distributionally robust (DR) risk-constrained
optimization. In the iterative MPC, at each iteration, safe states visited and
stored in the previous iterations are imposed as terminal constraints.
Furthermore, samples collected during the iteration are used in the subsequent
iterations to tune the ambiguity set of the DR constraints employed in the MPC.
In this method, the MPC problem becomes computationally burdensome when the
iteration number goes high. To overcome this challenge, the emphasis of this
paper is to reduce the real-time computational effort using two approximations.
First one involves clustering of data at the beginning of each iteration and
modifying the ambiguity set for the MPC scheme so that safety guarantees still
holds. The second approximation considers determining DR-safe regions at the
start of iteration and constraining the state in the MPC scheme to such safe
sets. We analyze the computational tractability of these approximations and
present a simulation example that considers path planning in the presence of
randomly moving obstacle.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04187" title="Abstract">arXiv:2310.04187</a> (cross-list from eess.IV) [<a href="/pdf/2310.04187" title="Download PDF">pdf</a>, <a href="/format/2310.04187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whole Slide Multiple Instance Learning for Predicting Axillary Lymph  Node Metastasis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shk%C3%ABmbi%2C+G">Glejdis Shk&#xeb;mbi</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+J+P">Johanna P. M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/eess?searchtype=author&query=Breininger%2C+K">Katharina Breininger</a>, 
<a href="/search/eess?searchtype=author&query=Sch%C3%BCffler%2C+P">Peter Sch&#xfc;ffler</a>, 
<a href="/search/eess?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for MICCAI DEMI Workshop 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Data Engineering in Medical Imaging. DEMI 2023. Lecture Notes in
  Computer Science, vol 14314. Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Breast cancer is a major concern for women's health globally, with axillary
lymph node (ALN) metastasis identification being critical for prognosis
evaluation and treatment guidance. This paper presents a deep learning (DL)
classification pipeline for quantifying clinical information from digital
core-needle biopsy (CNB) images, with one step less than existing methods. A
publicly available dataset of 1058 patients was used to evaluate the
performance of different baseline state-of-the-art (SOTA) DL models in
classifying ALN metastatic status based on CNB images. An extensive ablation
study of various data augmentation techniques was also conducted. Finally, the
manual tumor segmentation and annotation step performed by the pathologists was
assessed.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04223" title="Abstract">arXiv:2310.04223</a> (cross-list from math.CO) [<a href="/pdf/2310.04223" title="Download PDF">pdf</a>, <a href="/ps/2310.04223" title="Download PostScript">ps</a>, <a href="/format/2310.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary rigidity of finite CAT(0) cube complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chalopin%2C+J">J&#xe9;r&#xe9;mie Chalopin</a>, 
<a href="/search/math?searchtype=author&query=Chepoi%2C+V">Victor Chepoi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this note, we prove that finite CAT(0) cube complexes can be reconstructed
from their boundary distances (computed in their 1-skeleta). This result was
conjectured by Haslegrave, Scott, Tamitegama, and Tan (2023). The
reconstruction of a finite cell complex from the boundary distances is the
discrete version of the boundary rigidity problem, which is a classical problem
from Riemannian geometry. In the proofs, we use the bijection between CAT(0)
cube complexes and median graphs and the corner peelings of median graphs.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04249" title="Abstract">arXiv:2310.04249</a> (cross-list from eess.AS) [<a href="/pdf/2310.04249" title="Download PDF">pdf</a>, <a href="/format/2310.04249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis on the Influence of Synchronization Error on Fixed-filter  Active Noise Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+G">Guo Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The efficacy of active noise control technology in mitigating urban noise,
particularly in relation to low-frequency components, has been
well-established. In the realm of traditional academic research, adaptive
algorithms, such as the filtered reference least mean square method, are
extensively employed to achieve real-time noise reduction in many applications.
Nevertheless, the utilization of this technology in commercial goods is often
hindered by its significant computing complexity and inherent instability. In
this particular scenario, the adoption of the fixed-filter strategy emerges as
a viable alternative for addressing these challenges, albeit with a potential
trade-off in terms of noise reduction efficacy. This work aims to conduct a
theoretical investigation into the synchronization error of the digital Active
Noise Control (ANC) system. Keywords: Fixed-filter, Active noise control,
Multichannel active noise control.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04265" title="Abstract">arXiv:2310.04265</a> (cross-list from math.CO) [<a href="/pdf/2310.04265" title="Download PDF">pdf</a>, <a href="/ps/2310.04265" title="Download PostScript">ps</a>, <a href="/format/2310.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clique number of tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aboulker%2C+P">Pierre Aboulker</a>, 
<a href="/search/math?searchtype=author&query=Aubian%2C+G">Guillaume Aubian</a>, 
<a href="/search/math?searchtype=author&query=Charbit%2C+P">Pierre Charbit</a>, 
<a href="/search/math?searchtype=author&query=Lopes%2C+R">Raul Lopes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We introduce the notion of clique number of a tournament and investigate its
relation with the dichromatic number. In particular, it permits defining
$\dic$-bounded classes of tournaments, which is the paper's main topic.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04267" title="Abstract">arXiv:2310.04267</a> (cross-list from math.PR) [<a href="/pdf/2310.04267" title="Download PDF">pdf</a>, <a href="/ps/2310.04267" title="Download PostScript">ps</a>, <a href="/format/2310.04267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical probability spaces, ergodic decompositions, and transitions  to equilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ensarguet%2C+N">No&#xe9; Ensarguet</a>, 
<a href="/search/math?searchtype=author&query=Perrone%2C+P">Paolo Perrone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, part of this work appears in the dissertation of the first author submitted towards the degree of MSc in Mathematics and Foundations of Computer Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Logic in Computer Science (cs.LO); Category Theory (math.CT); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We study a category of probability spaces and measure-preserving Markov
kernels up to almost sure equality. This category contains, among its
isomorphisms, mod-zero isomorphisms of probability spaces. It also gives an
isomorphism between the space of values of a random variable and the
sigma-algebra that it generates on the outcome space, reflecting the standard
mathematical practice of using the two interchangeably, for example when taking
conditional expectations.
<br />We show that a number of constructions and results from classical probability
theory, mostly involving notions of equilibrium, can be expressed and proven in
terms of this category. In particular: - Given a stochastic dynamical system
acting on a standard Borel space, we show that the almost surely invariant
sigma-algebra can be obtained as a limit and as a colimit; - In the setting
above, the almost surely invariant sigma-algebra gives rise, up to isomorphism
of our category, to a standard Borel space; - As a corollary, we give a
categorical version of the ergodic decomposition theorem for stochastic
actions; - As an example, we show how de Finetti's theorem and the
Hewitt-Savage and Kolmogorov zero-one laws fit in this limit-colimit picture.
<br />This work uses the tools of categorical probability, in particular Markov
categories, as well as the theory of dagger categories.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04299" title="Abstract">arXiv:2310.04299</a> (cross-list from eess.IV) [<a href="/pdf/2310.04299" title="Download PDF">pdf</a>, <a href="/format/2310.04299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent ADMM Plug and Play PET Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sureau%2C+F">Florent Sureau</a>, 
<a href="/search/eess?searchtype=author&query=Latreche%2C+M">Mahdi Latreche</a>, 
<a href="/search/eess?searchtype=author&query=Savanier%2C+M">Marion Savanier</a>, 
<a href="/search/eess?searchtype=author&query=Comtat%2C+C">Claude Comtat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we investigate hybrid PET reconstruction algorithms based on
coupling a model-based variational reconstruction and the application of a
separately learnt Deep Neural Network operator (DNN) in an ADMM Plug and Play
framework. Following recent results in optimization, fixed point convergence of
the scheme can be achieved by enforcing an additional constraint on network
parameters during learning. We propose such an ADMM algorithm and show in a
realistic [18F]-FDG synthetic brain exam that the proposed scheme indeed lead
experimentally to convergence to a meaningful fixed point. When the proposed
constraint is not enforced during learning of the DNN, the proposed ADMM
algorithm was observed experimentally not to converge.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04318" title="Abstract">arXiv:2310.04318</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2310.04318" title="Download PDF">pdf</a>, <a href="/format/2310.04318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Order Reduction for the 1D Boltzmann-BGK Equation: Identifying  Intrinsic Variables Using Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Koellermeier%2C+J">Julian Koellermeier</a>, 
<a href="/search/physics?searchtype=author&query=Krah%2C+P">Philipp Krah</a>, 
<a href="/search/physics?searchtype=author&query=Reiss%2C+J">Julius Reiss</a>, 
<a href="/search/physics?searchtype=author&query=Schellin%2C+Z">Zachary Schellin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Kinetic equations are crucial for modeling non-equilibrium phenomena, but
their computational complexity is a challenge. This paper presents a
data-driven approach using reduced order models (ROM) to efficiently model
non-equilibrium flows in kinetic equations by comparing two ROM approaches:
Proper Orthogonal Decomposition (POD) and autoencoder neural networks (AE).
While AE initially demonstrate higher accuracy, POD's precision improves as
more modes are considered. Notably, our work recognizes that the classical
POD-MOR approach, although capable of accurately representing the non-linear
solution manifold of the kinetic equation, may not provide a parsimonious model
of the data due to the inherently non-linear nature of the data manifold. We
demonstrate how AEs are used in finding the intrinsic dimension of a system and
to allow correlating the intrinsic quantities with macroscopic quantities that
have a physical interpretation.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04336" title="Abstract">arXiv:2310.04336</a> (cross-list from q-fin.CP) [<a href="/pdf/2310.04336" title="Download PDF">pdf</a>, <a href="/format/2310.04336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Reinforcement Learning to Option Pricing and Hedging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Stoiljkovic%2C+Z">Zoran Stoiljkovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 14 figures, 8 tables, 3 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">This thesis provides an overview of the recent advances in reinforcement
learning in pricing and hedging financial instruments, with a primary focus on
a detailed explanation of the Q-Learning Black Scholes approach, introduced by
Halperin (2017). This reinforcement learning approach bridges the traditional
Black and Scholes (1973) model with novel artificial intelligence algorithms,
enabling option pricing and hedging in a completely model-free and data-driven
way. This paper also explores the algorithm's performance under different state
variables and scenarios for a European put option. The results reveal that the
model is an accurate estimator under different levels of volatility and hedging
frequency. Moreover, this method exhibits robust performance across various
levels of option's moneyness. Lastly, the algorithm incorporates proportional
transaction costs, indicating diverse impacts on profit and loss, affected by
different statistical properties of the state variables.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04338" title="Abstract">arXiv:2310.04338</a> (cross-list from math.PR) [<a href="/pdf/2310.04338" title="Download PDF">pdf</a>, <a href="/ps/2310.04338" title="Download PostScript">ps</a>, <a href="/format/2310.04338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near optimal bounds for weak and strong spatial mixing for the  anti-ferromagnetic Potts model on trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bencs%2C+F">Ferenc Bencs</a>, 
<a href="/search/math?searchtype=author&query=Berrekkal%2C+K">Khallil Berrekkal</a>, 
<a href="/search/math?searchtype=author&query=Regts%2C+G">Guus Regts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Mathematical Physics (math-ph); Combinatorics (math.CO)

</div>
<p class="mathjax">We show that the anti-ferromagnetic Potts model on trees exhibits strong
spatial mixing for a near-optimal range of parameters. Our work complements
recent results of Chen, Liu, Mani, and Moitra [arXiv.<a href="/abs/2304.01954">2304.01954</a>] who showed
this to be true in the infinite temperature setting, corresponding to uniform
proper colorings. We furthermore prove weak spatial mixing results
complementing results in [arXiv.<a href="/abs/2304.01954">2304.01954</a>].
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04345" title="Abstract">arXiv:2310.04345</a> (cross-list from math.OC) [<a href="/pdf/2310.04345" title="Download PDF">pdf</a>, <a href="/format/2310.04345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neur2RO: Neural Two-Stage Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dumouchelle%2C+J">Justin Dumouchelle</a>, 
<a href="/search/math?searchtype=author&query=Julien%2C+E">Esther Julien</a>, 
<a href="/search/math?searchtype=author&query=Kurtz%2C+J">Jannis Kurtz</a>, 
<a href="/search/math?searchtype=author&query=Khalil%2C+E+B">Elias B. Khalil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Robust optimization provides a mathematical framework for modeling and
solving decision-making problems under worst-case uncertainty. This work
addresses two-stage robust optimization (2RO) problems (also called adjustable
robust optimization), wherein first-stage and second-stage decisions are made
before and after uncertainty is realized, respectively. This results in a
nested min-max-min optimization problem which is extremely challenging
computationally, especially when the decisions are discrete. We propose
Neur2RO, an efficient machine learning-driven instantiation of
column-and-constraint generation (CCG), a classical iterative algorithm for
2RO. Specifically, we learn to estimate the value function of the second-stage
problem via a novel neural network architecture that is easy to optimize over
by design. Embedding our neural network into CCG yields high-quality solutions
quickly as evidenced by experiments on two 2RO benchmarks, knapsack and capital
budgeting. For knapsack, Neur2RO finds solutions that are within roughly $2\%$
of the best-known values in a few seconds compared to the three hours of the
state-of-the-art exact branch-and-price algorithm; for larger and more complex
instances, Neur2RO finds even better solutions. For capital budgeting, Neur2RO
outperforms three variants of the $k$-adaptability algorithm, particularly on
the largest instances, with a 5 to 10-fold reduction in solution time. Our code
and data are available at https://github.com/khalil-research/Neur2RO.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04348" title="Abstract">arXiv:2310.04348</a> (cross-list from math.OC) [<a href="/pdf/2310.04348" title="Download PDF">pdf</a>, <a href="/format/2310.04348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AccEq-DRT: Planning Demand-Responsive Transit to reduce inequality of  accessibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+D">Duo Wang</a>, 
<a href="/search/math?searchtype=author&query=Araldo%2C+A">Andrea Araldo</a>, 
<a href="/search/math?searchtype=author&query=Yacoubi%2C+M+A+E">Mounim A. El Yacoubi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Accessibility measures how well a location is connected to surrounding
opportunities. We focus on accessibility provided by Public Transit (PT). There
is an evident inequality in the distribution of accessibility between city
centers or close to main transportation corridors and suburbs. In the latter,
poor PT service leads to a chronic car-dependency. Demand-Responsive Transit
(DRT) is better suited for low-density areas than conventional fixed-route PT.
However, its potential to tackle accessibility inequality has not yet been
exploited. On the contrary, planning DRT without care to inequality (as in the
methods proposed so far) can further improve the accessibility gap in urban
areas.
<br />To the best of our knowledge this paper is the first to propose a DRT
planning strategy, which we call AccEq-DRT, aimed at reducing accessibility
inequality, while ensuring overall efficiency. To this aim, we combine a graph
representation of conventional PT and a Continuous Approximation (CA) model of
DRT. The two are combined in the same multi-layer graph, on which we compute
accessibility. We then devise a scoring function to estimate the need of each
area for an improvement, appropriately weighting population density and
accessibility. Finally, we provide a bilevel optimization method, where the
upper level is a heuristic to allocate DRT buses, guided by the scoring
function, and the lower level performs traffic assignment. Numerical results in
a simplified model of Montreal show that inequality, measured with the Atkinson
index, is reduced by up to 34\%.
<br />Keywords: DRT Public, Transportation, Accessibility, Continuous
Approximation, Network Design
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04352" title="Abstract">arXiv:2310.04352</a> (cross-list from stat.ML) [<a href="/pdf/2310.04352" title="Download PDF">pdf</a>, <a href="/format/2310.04352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Feature Importance Scores for Interpreting Tree-Based Methods and  Surrogates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Little%2C+C+O">Camille Olivia Little</a>, 
<a href="/search/stat?searchtype=author&query=Lina%2C+D+H">Debolina Halder Lina</a>, 
<a href="/search/stat?searchtype=author&query=Allen%2C+G+I">Genevera I. Allen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Across various sectors such as healthcare, criminal justice, national
security, finance, and technology, large-scale machine learning (ML) and
artificial intelligence (AI) systems are being deployed to make critical
data-driven decisions. Many have asked if we can and should trust these ML
systems to be making these decisions. Two critical components are prerequisites
for trust in ML systems: interpretability, or the ability to understand why the
ML system makes the decisions it does, and fairness, which ensures that ML
systems do not exhibit bias against certain individuals or groups. Both
interpretability and fairness are important and have separately received
abundant attention in the ML literature, but so far, there have been very few
methods developed to directly interpret models with regard to their fairness.
In this paper, we focus on arguably the most popular type of ML interpretation:
feature importance scores. Inspired by the use of decision trees in knowledge
distillation, we propose to leverage trees as interpretable surrogates for
complex black-box ML models. Specifically, we develop a novel fair feature
importance score for trees that can be used to interpret how each feature
contributes to fairness or bias in trees, tree-based ensembles, or tree-based
surrogates of any complex ML system. Like the popular mean decrease in impurity
for trees, our Fair Feature Importance Score is defined based on the mean
decrease (or increase) in group bias. Through simulations as well as real
examples on benchmark fairness datasets, we demonstrate that our Fair Feature
Importance Score offers valid interpretations for both tree-based ensembles and
tree-based surrogates of other ML systems.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04354" title="Abstract">arXiv:2310.04354</a> (cross-list from stat.ML) [<a href="/pdf/2310.04354" title="Download PDF">pdf</a>, <a href="/format/2310.04354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Transformations in Probabilistic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Schierenbeck%2C+T">Tom Schierenbeck</a>, 
<a href="/search/stat?searchtype=author&query=Vutov%2C+V">Vladimir Vutov</a>, 
<a href="/search/stat?searchtype=author&query=Dickhaus%2C+T">Thorsten Dickhaus</a>, 
<a href="/search/stat?searchtype=author&query=Beetz%2C+M">Michael Beetz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study addresses the predictive limitation of probabilistic circuits and
introduces transformations as a remedy to overcome it. We demonstrate this
limitation in robotic scenarios. We motivate that independent component
analysis is a sound tool to preserve the independence properties of
probabilistic circuits. Our approach is an extension of joint probability
trees, which are model-free deterministic circuits. By doing so, it is
demonstrated that the proposed approach is able to achieve higher likelihoods
while using fewer parameters compared to the joint probability trees on seven
benchmark data sets as well as on real robot data. Furthermore, we discuss how
to integrate transformations into tree-based learning routines. Finally, we
argue that exact inference with transformed quantile parameterized
distributions is not tractable. However, our approach allows for efficient
sampling and approximate inference.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04355" title="Abstract">arXiv:2310.04355</a> (cross-list from cond-mat.soft) [<a href="/pdf/2310.04355" title="Download PDF">pdf</a>, <a href="/format/2310.04355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of viscoelastic shear shock waves using finite volume  schemes with artificial compressibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Berjamin%2C+H">Harold Berjamin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The formation of shear shock waves in the brain has been proposed as one of
the plausible explanations for deep intracranial injuries. In fact, such
singular solutions emerge naturally in soft viscoelastic tissues under dynamic
loading conditions. To improve our understanding of the mechanical processes at
hand, the development of dedicated computational models is needed. The present
study concerns three-dimensional numerical models of incompressible
viscoelastic solids whose motion is analysed by means of shock-capturing finite
volume methods. More specifically, we focus on the use of the artificial
compressibility method, a technique that has been frequently employed in
computational fluid dynamics. The material behaviour is deduced from the
Fung--Simo quasi-linear viscoelasiticity theory (QLV) where the elastic
response is of Yeoh type. We analyse the accuracy of the method and demonstrate
its applicability for the study of nonlinear wave propagation in soft solids.
The numerical results cover accuracy tests, shock formation and wave
diffraction.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04367" title="Abstract">arXiv:2310.04367</a> (cross-list from stat.ML) [<a href="/pdf/2310.04367" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Marketplace Price Anomaly Detection System at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sarpal%2C+A">Akshit Sarpal</a>, 
<a href="/search/stat?searchtype=author&query=Kang%2C+Q">Qiwen Kang</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+F">Fangping Huang</a>, 
<a href="/search/stat?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/stat?searchtype=author&query=Wan%2C+L">Lijie Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Online marketplaces execute large volume of price updates that are initiated
by individual marketplace sellers each day on the platform. This price
democratization comes with increasing challenges with data quality. Lack of
centralized guardrails that are available for a traditional online retailer
causes a higher likelihood for inaccurate prices to get published on the
website, leading to poor customer experience and potential for revenue loss. We
present MoatPlus (Masked Optimal Anchors using Trees, Proximity-based Labeling
and Unsupervised Statistical-features), a scalable price anomaly detection
framework for a growing marketplace platform. The goal is to leverage proximity
and historical price trends from unsupervised statistical features to generate
an upper price bound. We build an ensemble of models to detect irregularities
in price-based features, exclude irregular features and use optimized weighting
scheme to build a reliable price bound in real-time pricing pipeline. We
observed that our approach improves precise anchor coverage by up to 46.6% in
high-vulnerability item subsets
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04396" title="Abstract">arXiv:2310.04396</a> (cross-list from quant-ph) [<a href="/pdf/2310.04396" title="Download PDF">pdf</a>, <a href="/format/2310.04396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpolating Parametrized Quantum Circuits using Blackbox Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Simon%2C+L">Lars Simon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eble%2C+H">Holger Eble</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kowalski%2C+H">Hagen-Henrik Kowalski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Radons%2C+M">Manuel Radons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This article focuses on developing classical surrogates for parametrized
quantum circuits using interpolation via (trigonometric) polynomials. We
develop two algorithms for the construction of such surrogates and prove
performance guarantees. The constructions are based on blackbox evaluations of
circuits, which may either be simulated or executed on quantum hardware. While
acknowledging the limitations of the blackbox approach compared to whitebox
evaluations, which exploit specific circuit properties, we demonstrate
scenarios in which the blackbox approach might prove beneficial. Sample
applications include but are not restricted to the approximation of VQEs and
the alleviaton of the barren plateau problem.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04417" title="Abstract">arXiv:2310.04417</a> (cross-list from stat.ML) [<a href="/pdf/2310.04417" title="Download PDF">pdf</a>, <a href="/format/2310.04417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Random Feature Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Saha%2C+E">Esha Saha</a>, 
<a href="/search/stat?searchtype=author&query=Tran%2C+G">Giang Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Figures, 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion probabilistic models have been successfully used to generate data
from noise. However, most diffusion models are computationally expensive and
difficult to interpret with a lack of theoretical justification. Random feature
models on the other hand have gained popularity due to their interpretability
but their application to complex machine learning tasks remains limited. In
this work, we present a diffusion model-inspired deep random feature model that
is interpretable and gives comparable numerical results to a fully connected
neural network having the same number of trainable parameters. Specifically, we
extend existing results for random features and derive generalization bounds
between the distribution of sampled data and the true distribution using
properties of score matching. We validate our findings by generating samples on
the fashion MNIST dataset and instrumental audio data.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon,  9 Oct 23</h3>
<dl>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1806.06298" title="Abstract">arXiv:1806.06298</a> (replaced) [<a href="/pdf/1806.06298" title="Download PDF">pdf</a>, <a href="/format/1806.06298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Generator Networks: Unsupervised Disentanglement of  Appearance and Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xianglei Xing</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tian Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y+N">Ying Nian Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The version of IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.08410" title="Abstract">arXiv:2002.08410</a> (replaced) [<a href="/pdf/2002.08410" title="Download PDF">pdf</a>, <a href="/format/2002.08410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Mixture Reduction with Composite Transportation Divergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Q">Qiong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+A+G">Archer Gong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+J">Jiahua Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.10239" title="Abstract">arXiv:2006.10239</a> (replaced) [<a href="/pdf/2006.10239" title="Download PDF">pdf</a>, <a href="/ps/2006.10239" title="Download PostScript">ps</a>, <a href="/format/2006.10239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local structure of idempotent algebras II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bulatov%2C+A+A">Andrei A. Bulatov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.03454" title="Abstract">arXiv:2012.03454</a> (replaced) [<a href="/pdf/2012.03454" title="Download PDF">pdf</a>, <a href="/format/2012.03454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger Calibration Lower Bounds via Sidestepping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+M">Mingda Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Valiant%2C+G">Gregory Valiant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> STOC 2021; v3 fixed a typo in the statement of Theorem 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.03893" title="Abstract">arXiv:2104.03893</a> (replaced) [<a href="/pdf/2104.03893" title="Download PDF">pdf</a>, <a href="/format/2104.03893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Fusion of EMG and Vision for Human Grasp Intent Inference in  Prosthetic Hand Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zandigohar%2C+M">Mehrshad Zandigohar</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mo Han</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+M">Mohammadreza Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Gunay%2C+S+Y">Sezen Yagmur Gunay</a>, 
<a href="/search/cs?searchtype=author&query=Furmanek%2C+M+P">Mariusz P. Furmanek</a>, 
<a href="/search/cs?searchtype=author&query=Yarossi%2C+M">Mathew Yarossi</a>, 
<a href="/search/cs?searchtype=author&query=Bonato%2C+P">Paolo Bonato</a>, 
<a href="/search/cs?searchtype=author&query=Onal%2C+C">Cagdas Onal</a>, 
<a href="/search/cs?searchtype=author&query=Padir%2C+T">Taskin Padir</a>, 
<a href="/search/cs?searchtype=author&query=Erdogmus%2C+D">Deniz Erdogmus</a>, 
<a href="/search/cs?searchtype=author&query=Schirner%2C+G">Gunar Schirner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to Frontiers for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.03645" title="Abstract">arXiv:2107.03645</a> (replaced) [<a href="/pdf/2107.03645" title="Download PDF">pdf</a>, <a href="/format/2107.03645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of hybrid machine learning models for non-linear system  identification of fatigue test rigs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Heindel%2C+L">Leonhard Heindel</a>, 
<a href="/search/eess?searchtype=author&query=Hantschke%2C+P">Peter Hantschke</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%A4stner%2C+M">Markus K&#xe4;stner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.02272" title="Abstract">arXiv:2111.02272</a> (replaced) [<a href="/pdf/2111.02272" title="Download PDF">pdf</a>, <a href="/format/2111.02272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Motif Kernel Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ditz%2C+J+C">Jonas C. Ditz</a>, 
<a href="/search/cs?searchtype=author&query=Reuter%2C+B">Bernhard Reuter</a>, 
<a href="/search/cs?searchtype=author&query=Pfeifer%2C+N">Nico Pfeifer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08190" title="Abstract">arXiv:2111.08190</a> (replaced) [<a href="/pdf/2111.08190" title="Download PDF">pdf</a>, <a href="/format/2111.08190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Augmentation Distributions using Transformed Risk Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatzipantazis%2C+E">Evangelos Chatzipantazis</a>, 
<a href="/search/cs?searchtype=author&query=Pertigkiozoglou%2C+S">Stefanos Pertigkiozoglou</a>, 
<a href="/search/cs?searchtype=author&query=Daniilidis%2C+K">Kostas Daniilidis</a>, 
<a href="/search/cs?searchtype=author&query=Dobriban%2C+E">Edgar Dobriban</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.10933" title="Abstract">arXiv:2111.10933</a> (replaced) [<a href="/pdf/2111.10933" title="Download PDF">pdf</a>, <a href="/format/2111.10933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Multi-Armed Bandits Can Outperform Centralized Upper  Confidence Bound Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingxuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mulle%2C+E">Ethan Mulle</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+C+S">Christopher Salomon Smith</a>, 
<a href="/search/cs?searchtype=author&query=Koppel%2C+A">Alec Koppel</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.11331" title="Abstract">arXiv:2111.11331</a> (replaced) [<a href="/pdf/2111.11331" title="Download PDF">pdf</a>, <a href="/format/2111.11331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Space Semantics for Lambek Calculus with Soft Subexponentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McPheat%2C+L">Lachlan McPheat</a>, 
<a href="/search/cs?searchtype=author&query=Wazni%2C+H">Hadi Wazni</a>, 
<a href="/search/cs?searchtype=author&query=Sadrzadeh%2C+M">Mehrnoosh Sadrzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="/abs/2111.11331">arXiv:2111.11331v2</a> was intended to replace <a href="/abs/2005.03074">arXiv:2005.03074</a>. now restoring <a href="/abs/2111.11331">arXiv:2111.11331v1</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.12143" title="Abstract">arXiv:2111.12143</a> (replaced) [<a href="/pdf/2111.12143" title="Download PDF">pdf</a>, <a href="/format/2111.12143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Initialization of Wide and Deep Neural Networks through Partial  Jacobians: General Theory and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doshi%2C+D">Darshil Doshi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Gromov%2C+A">Andrey Gromov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted (spotlight) at NeurIPS2023. Additional ResNet results. 42 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); High Energy Physics - Theory (hep-th); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03379" title="Abstract">arXiv:2112.03379</a> (replaced) [<a href="/pdf/2112.03379" title="Download PDF">pdf</a>, <a href="/format/2112.03379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Efficient Continuous Manifold Learning for Time Series Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seungwoo Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+W">Wonjun Ko</a>, 
<a href="/search/cs?searchtype=author&query=Mulyadi%2C+A+W">Ahmad Wisnu Mulyadi</a>, 
<a href="/search/cs?searchtype=author&query=Suk%2C+H">Heung-Il Suk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.01376" title="Abstract">arXiv:2201.01376</a> (replaced) [<a href="/pdf/2201.01376" title="Download PDF">pdf</a>, <a href="/format/2201.01376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic predictability and spatio-temporal contexts in human mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Poudyal%2C+B">Bibandhan Poudyal</a>, 
<a href="/search/physics?searchtype=author&query=Pacheco%2C+D">Diogo Pacheco</a>, 
<a href="/search/physics?searchtype=author&query=Oliveira%2C+M">Marcos Oliveira</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Z">Zexun Chen</a>, 
<a href="/search/physics?searchtype=author&query=Barbosa%2C+H">Hugo Barbosa</a>, 
<a href="/search/physics?searchtype=author&query=Menezes%2C+R">Ronaldo Menezes</a>, 
<a href="/search/physics?searchtype=author&query=Ghoshal%2C+G">Gourab Ghoshal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 48 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00885" title="Abstract">arXiv:2202.00885</a> (replaced) [<a href="/pdf/2202.00885" title="Download PDF">pdf</a>, <a href="/format/2202.00885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opted Out, Yet Tracked: Are Regulations Enough to Protect Your Privacy?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zengrui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+N">Nitesh Saxena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by The 24th Privacy Enhancing Technologies Symposium (PETs 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.04835" title="Abstract">arXiv:2202.04835</a> (replaced) [<a href="/pdf/2202.04835" title="Download PDF">pdf</a>, <a href="/format/2202.04835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robophysical model of spacetime dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/gr-qc?searchtype=author&query=Li%2C+S">Shengkai Li</a>, 
<a href="/search/gr-qc?searchtype=author&query=Gynai%2C+H+N">Hussain N. Gynai</a>, 
<a href="/search/gr-qc?searchtype=author&query=Tarr%2C+S">Steven Tarr</a>, 
<a href="/search/gr-qc?searchtype=author&query=Alicea-Mu%C3%B1oz%2C+E">Emily Alicea-Mu&#xf1;oz</a>, 
<a href="/search/gr-qc?searchtype=author&query=Laguna%2C+P">Pablo Laguna</a>, 
<a href="/search/gr-qc?searchtype=author&query=Li%2C+G">Gongjie Li</a>, 
<a href="/search/gr-qc?searchtype=author&query=Goldman%2C+D+I">Daniel I. Goldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Relativity and Quantum Cosmology (gr-qc)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06865" title="Abstract">arXiv:2203.06865</a> (replaced) [<a href="/pdf/2203.06865" title="Download PDF">pdf</a>, <a href="/format/2203.06865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement  Learning Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Vadori%2C+N">Nelson Vadori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Mathematical Finance (q-fin.MF)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.09725" title="Abstract">arXiv:2203.09725</a> (replaced) [<a href="/pdf/2203.09725" title="Download PDF">pdf</a>, <a href="/format/2203.09725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Game with Interactive Information Acquisition: Pipelined  Perfect Markov Bayesian Equilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.15471" title="Abstract">arXiv:2203.15471</a> (replaced) [<a href="/pdf/2203.15471" title="Download PDF">pdf</a>, <a href="/ps/2203.15471" title="Download PostScript">ps</a>, <a href="/format/2203.15471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State space models vs. multi-step predictors in predictive control: Are  state space models complicating safe data-driven designs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>, 
<a href="/search/math?searchtype=author&query=Wabersich%2C+K+P">Kim P. Wabersich</a>, 
<a href="/search/math?searchtype=author&query=Berberich%2C+J">Julian Berberich</a>, 
<a href="/search/math?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed an error in Equ. (15) (two matrices where added instead of concatenated)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00584" title="Abstract">arXiv:2205.00584</a> (replaced) [<a href="/pdf/2205.00584" title="Download PDF">pdf</a>, <a href="/format/2205.00584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Large Language Models Interactive: A Pioneer Study on Supporting  Complex Information-Seeking Tasks with Implicit Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadvand%2C+A">Ali Ahmadvand</a>, 
<a href="/search/cs?searchtype=author&query=Arabzadeh%2C+N">Negar Arabzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Kiseleva%2C+J">Julia Kiseleva</a>, 
<a href="/search/cs?searchtype=author&query=Sanz%2C+P+F">Patricio Figueroa Sanz</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Jauhar%2C+S">Sujay Jauhar</a>, 
<a href="/search/cs?searchtype=author&query=Gamon%2C+M">Michael Gamon</a>, 
<a href="/search/cs?searchtype=author&query=Agichtein%2C+E">Eugene Agichtein</a>, 
<a href="/search/cs?searchtype=author&query=Friend%2C+N">Ned Friend</a>, 
<a href="/search/cs?searchtype=author&query=Aniruddha">Aniruddha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09078" title="Abstract">arXiv:2205.09078</a> (replaced) [<a href="/pdf/2205.09078" title="Download PDF">pdf</a>, <a href="/format/2205.09078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Resource Allocation: Algorithmic Design Principles and Spectrum  of Achievable Performances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Besbes%2C+O">Omar Besbes</a>, 
<a href="/search/math?searchtype=author&query=Kanoria%2C+Y">Yash Kanoria</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+A">Akshit Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An earlier version of this paper appeared as an extended abstract in the Proceedings of the 23rd ACM Conference on Economics and Computation, EC'22 with the title "The Multi-secretary Problem with Many Types"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11023" title="Abstract">arXiv:2205.11023</a> (replaced) [<a href="/pdf/2205.11023" title="Download PDF">pdf</a>, <a href="/format/2205.11023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable  Usage Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jinu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+N">Neel Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Allamanis%2C+M">Miltiadis Allamanis</a>, 
<a href="/search/cs?searchtype=author&query=Svyatkovskiy%2C+A">Alexey Svyatkovskiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15376" title="Abstract">arXiv:2205.15376</a> (replaced) [<a href="/pdf/2205.15376" title="Download PDF">pdf</a>, <a href="/format/2205.15376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning with a Terminator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+G">Guy Tennenholtz</a>, 
<a href="/search/cs?searchtype=author&query=Merlis%2C+N">Nadav Merlis</a>, 
<a href="/search/cs?searchtype=author&query=Shani%2C+L">Lior Shani</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>, 
<a href="/search/cs?searchtype=author&query=Shalit%2C+U">Uri Shalit</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+G">Gal Chechik</a>, 
<a href="/search/cs?searchtype=author&query=Hallak%2C+A">Assaf Hallak</a>, 
<a href="/search/cs?searchtype=author&query=Dalal%2C+G">Gal Dalal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01306" title="Abstract">arXiv:2206.01306</a> (replaced) [<a href="/pdf/2206.01306" title="Download PDF">pdf</a>, <a href="/ps/2206.01306" title="Download PostScript">ps</a>, <a href="/format/2206.01306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deceptive Planning for Resource Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+S">Shenghui Chen</a>, 
<a href="/search/math?searchtype=author&query=Savas%2C+Y">Yagiz Savas</a>, 
<a href="/search/math?searchtype=author&query=Karabag%2C+M+O">Mustafa O. Karabag</a>, 
<a href="/search/math?searchtype=author&query=Sadler%2C+B+M">Brian M. Sadler</a>, 
<a href="/search/math?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05794" title="Abstract">arXiv:2206.05794</a> (replaced) [<a href="/pdf/2206.05794" title="Download PDF">pdf</a>, <a href="/format/2206.05794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galanti%2C+T">Tomer Galanti</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+Z+S">Zachary S. Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Gupte%2C+A">Aparna Gupte</a>, 
<a href="/search/cs?searchtype=author&query=Poggio%2C+T">Tomaso Poggio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14260" title="Abstract">arXiv:2207.14260</a> (replaced) [<a href="/pdf/2207.14260" title="Download PDF">pdf</a>, <a href="/format/2207.14260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Concept of Decentralization Through Time and Disciplines: A  Quantitative Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Di+Bona%2C+G">Gabriele Di Bona</a>, 
<a href="/search/physics?searchtype=author&query=Bracci%2C+A">Alberto Bracci</a>, 
<a href="/search/physics?searchtype=author&query=Perra%2C+N">Nicola Perra</a>, 
<a href="/search/physics?searchtype=author&query=Latora%2C+V">Vito Latora</a>, 
<a href="/search/physics?searchtype=author&query=Baronchelli%2C+A">Andrea Baronchelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures, and Supplemental Information
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPJ Data Science 12, 42 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00137" title="Abstract">arXiv:2208.00137</a> (replaced) [<a href="/pdf/2208.00137" title="Download PDF">pdf</a>, <a href="/format/2208.00137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient estimation and inference for the signed $&#x3b2;$-model in  directed signed networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+J">Junhui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07708" title="Abstract">arXiv:2208.07708</a> (replaced) [<a href="/e-print/2208.07708" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction Methods for Galois LCD codes over Finite Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+G+K">Gyanendra K. Verma</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Astha Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R+K">R. K. Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are several mathematical and English language typos we will submit a new one soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08401" title="Abstract">arXiv:2208.08401</a> (replaced) [<a href="/pdf/2208.08401" title="Download PDF">pdf</a>, <a href="/format/2208.08401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Inference for Online Prediction with Arbitrary Distribution  Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gibbs%2C+I">Isaac Gibbs</a>, 
<a href="/search/stat?searchtype=author&query=Cand%C3%A8s%2C+E">Emmanuel Cand&#xe8;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07274" title="Abstract">arXiv:2209.07274</a> (replaced) [<a href="/pdf/2209.07274" title="Download PDF">pdf</a>, <a href="/format/2209.07274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Grid WAR: Rethinking WAR for Starting Pitchers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brill%2C+R+S">Ryan S. Brill</a>, 
<a href="/search/cs?searchtype=author&query=Wyner%2C+A+J">Abraham J. Wyner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09631" title="Abstract">arXiv:2209.09631</a> (replaced) [<a href="/pdf/2209.09631" title="Download PDF">pdf</a>, <a href="/format/2209.09631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-Identification of French Unstructured Clinical Notes for Machine  Learning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tchouka%2C+Y">Yakini Tchouka</a>, 
<a href="/search/cs?searchtype=author&query=Couchot%2C+J">Jean-Fran&#xe7;ois Couchot</a>, 
<a href="/search/cs?searchtype=author&query=Coulmeau%2C+M">Maxime Coulmeau</a>, 
<a href="/search/cs?searchtype=author&query=Laiymani%2C+D">David Laiymani</a>, 
<a href="/search/cs?searchtype=author&query=Selles%2C+P">Philippe Selles</a>, 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+A">Azzedine Rahmani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12046" title="Abstract">arXiv:2209.12046</a> (replaced) [<a href="/pdf/2209.12046" title="Download PDF">pdf</a>, <a href="/format/2209.12046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blinder: End-to-end Privacy Protection in Sensing Systems via  Personalized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ardakanian%2C+O">Omid Ardakanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06281" title="Abstract">arXiv:2210.06281</a> (replaced) [<a href="/pdf/2210.06281" title="Download PDF">pdf</a>, <a href="/format/2210.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TwiRGCN: Temporally Weighted Graph Convolution for Question Answering  over Temporal Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Aditya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+A">Apoorv Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+C">Chitrank Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+S+M">Seyed Mehran Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Talukdar%2C+P">Partha Talukdar</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+S">Soumen Chakrabarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages + references + appendix
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 17th Conference of the European Chapter of the
  Association for Computational Linguistics (EACL 2023) pages 2049 to 2060
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09475" title="Abstract">arXiv:2210.09475</a> (replaced) [<a href="/pdf/2210.09475" title="Download PDF">pdf</a>, <a href="/format/2210.09475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMPNet: Attention as Message Passing for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+A">Syed Asad Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Haoran Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+B">Benjamin Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Caro%2C+J+O">Josue Ortega Caro</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+A+H+O">Antonio H. O. Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Zappala%2C+E">Emanuele Zappala</a>, 
<a href="/search/cs?searchtype=author&query=Bagherian%2C+M">Maryam Bagherian</a>, 
<a href="/search/cs?searchtype=author&query=Averill%2C+C">Christopher Averill</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+C+G">Chadi G. Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=Brbic%2C+M">Maria Brbic</a>, 
<a href="/search/cs?searchtype=author&query=Dhodapkar%2C+R+M">Rahul Madhav Dhodapkar</a>, 
<a href="/search/cs?searchtype=author&query=van+Dijk%2C+D">David van Dijk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages (12 + 4 pages appendix). 5 figures and 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11096" title="Abstract">arXiv:2210.11096</a> (replaced) [<a href="/pdf/2210.11096" title="Download PDF">pdf</a>, <a href="/format/2210.11096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust One-Shot Singing Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+N">Naoya Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M+K">Mayank Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11717" title="Abstract">arXiv:2210.11717</a> (replaced) [<a href="/pdf/2210.11717" title="Download PDF">pdf</a>, <a href="/format/2210.11717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Dataset Refinement for Problems in Computer Vision Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhijing Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+C">CheukTing Chung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 figures, to be published in ACM Computing Surveys
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14358" title="Abstract">arXiv:2210.14358</a> (replaced) [<a href="/pdf/2210.14358" title="Download PDF">pdf</a>, <a href="/format/2210.14358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Domain Long-Tailed Learning by Augmenting Disentangled  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Allan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17152" title="Abstract">arXiv:2210.17152</a> (replaced) [<a href="/pdf/2210.17152" title="Download PDF">pdf</a>, <a href="/format/2210.17152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Time-Scale Modification with Temporal Compressing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+E">Ernie Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Ju-Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chia-Ping Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03697" title="Abstract">arXiv:2211.03697</a> (replaced) [<a href="/pdf/2211.03697" title="Download PDF">pdf</a>, <a href="/format/2211.03697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension Reduction for Efficient Data-Enabled Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kaixiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+C">Chao Shang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03751" title="Abstract">arXiv:2211.03751</a> (replaced) [<a href="/pdf/2211.03751" title="Download PDF">pdf</a>, <a href="/format/2211.03751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotics of the Sketched Pseudoinverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=LeJeune%2C+D">Daniel LeJeune</a>, 
<a href="/search/math?searchtype=author&query=Patil%2C+P">Pratik Patil</a>, 
<a href="/search/math?searchtype=author&query=Javadi%2C+H">Hamid Javadi</a>, 
<a href="/search/math?searchtype=author&query=Baraniuk%2C+R+G">Richard G. Baraniuk</a>, 
<a href="/search/math?searchtype=author&query=Tibshirani%2C+R+J">Ryan J. Tibshirani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04205" title="Abstract">arXiv:2211.04205</a> (replaced) [<a href="/pdf/2211.04205" title="Download PDF">pdf</a>, <a href="/format/2211.04205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Semantics in Textual Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herel%2C+D">David Herel</a>, 
<a href="/search/cs?searchtype=author&query=Cisneros%2C+H">Hugo Cisneros</a>, 
<a href="/search/cs?searchtype=author&query=Mikolov%2C+T">Tomas Mikolov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07011" title="Abstract">arXiv:2211.07011</a> (replaced) [<a href="/pdf/2211.07011" title="Download PDF">pdf</a>, <a href="/format/2211.07011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Order Schemes for Gradient Flow with Respect to a Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+S">Saem Han</a>, 
<a href="/search/math?searchtype=author&query=Esedoglu%2C+S">Selim Esedoglu</a>, 
<a href="/search/math?searchtype=author&query=Garikipati%2C+K">Krishna Garikipati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12205" title="Abstract">arXiv:2211.12205</a> (replaced) [<a href="/pdf/2211.12205" title="Download PDF">pdf</a>, <a href="/format/2211.12205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utopia: Fast and Efficient Address Translation via Hybrid Restrictive &amp;  Flexible Virtual-to-Physical Address Mappings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+K">Konstantinos Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+R">Rahul Bera</a>, 
<a href="/search/cs?searchtype=author&query=Stojiljkovic%2C+K">Kosta Stojiljkovic</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+N">Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Firtina%2C+C">Can Firtina</a>, 
<a href="/search/cs?searchtype=author&query=Ausavarungnirun%2C+R">Rachata Ausavarungnirun</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rakesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Hajinazar%2C+N">Nastaran Hajinazar</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+N">Nandita Vijaykumar</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 56th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16641" title="Abstract">arXiv:2211.16641</a> (replaced) [<a href="/e-print/2211.16641" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting China&#x27;s CPI by Scanner Big Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Zhou%2C+Z">Zhenkun Zhou</a>, 
<a href="/search/econ?searchtype=author&query=Song%2C+Z">Zikun Song</a>, 
<a href="/search/econ?searchtype=author&query=Ren%2C+T">Tao Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We have updated the paper with more results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16785" title="Abstract">arXiv:2211.16785</a> (replaced) [<a href="/pdf/2211.16785" title="Download PDF">pdf</a>, <a href="/format/2211.16785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SafeSpace MFNet: Precise and Efficient MultiFeature Drone Detection  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+U">Misha Urooj Khan</a>, 
<a href="/search/cs?searchtype=author&query=Dil%2C+M">Mahnoor Dil</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+Z">Muhammad Zeshan Alam</a>, 
<a href="/search/cs?searchtype=author&query=Orakazi%2C+F+A">Farooq Alam Orakazi</a>, 
<a href="/search/cs?searchtype=author&query=Almasoud%2C+A+M">Abdullah M. Almasoud</a>, 
<a href="/search/cs?searchtype=author&query=Kaleem%2C+Z">Zeeshan Kaleem</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in IEEE TVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05701" title="Abstract">arXiv:2212.05701</a> (replaced) [<a href="/pdf/2212.05701" title="Download PDF">pdf</a>, <a href="/format/2212.05701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Vector Clocks: Low-Overhead Transparent Checkpointing for MPI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cooperman%2C+G">Gene Cooperman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06096" title="Abstract">arXiv:2212.06096</a> (replaced) [<a href="/pdf/2212.06096" title="Download PDF">pdf</a>, <a href="/format/2212.06096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Convolutional Kernels for Steerable CNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhdanov%2C+M">Maksim Zhdanov</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+N">Nico Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Cesa%2C+G">Gabriele Cesa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07877" title="Abstract">arXiv:2212.07877</a> (replaced) [<a href="/pdf/2212.07877" title="Download PDF">pdf</a>, <a href="/ps/2212.07877" title="Download PostScript">ps</a>, <a href="/format/2212.07877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifestations of Xenophobia in AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomasev%2C+N">Nenad Tomasev</a>, 
<a href="/search/cs?searchtype=author&query=Maynard%2C+J+L">Jonathan Leader Maynard</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+I">Iason Gabriel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09851" title="Abstract">arXiv:2301.09851</a> (replaced) [<a href="/pdf/2301.09851" title="Download PDF">pdf</a>, <a href="/format/2301.09851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neighborhood Homophily-based Graph Convolutional Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shengbo Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiajun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chenxuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Q">Qi Xuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 32nd ACM International Conference on Information and Knowledge Management (CIKM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09950" title="Abstract">arXiv:2301.09950</a> (replaced) [<a href="/pdf/2301.09950" title="Download PDF">pdf</a>, <a href="/format/2301.09950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-color Holograms Improve Brightness in Holographic Displays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavakl%C4%B1%2C+K">Koray Kavakl&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Liang Shi</a>, 
<a href="/search/cs?searchtype=author&query=%C3%9Crey%2C+H">Hakan &#xdc;rey</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+W">Wojciech Matusik</a>, 
<a href="/search/cs?searchtype=author&query=Ak%C5%9Fit%2C+K">Kaan Ak&#x15f;it</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Hardware Architecture (cs.AR); Human-Computer Interaction (cs.HC); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12291" title="Abstract">arXiv:2301.12291</a> (replaced) [<a href="/pdf/2301.12291" title="Download PDF">pdf</a>, <a href="/format/2301.12291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CancerUniT: Towards a Single Unified Model for Effective Detection,  Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection  of CT Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jieneng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yingda Xia</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Jiawen Yao</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jianpeng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+L">Le Lu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Fakai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+M">Mingyan Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Q">Qihang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+M">Mingze Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+W">Wei Fang</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yuxing Tang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Minfeng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jian Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yuqian Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+X">Xianghua Ye</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiaoli Yin</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zaiyi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Camera Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01665" title="Abstract">arXiv:2302.01665</a> (replaced) [<a href="/pdf/2302.01665" title="Download PDF">pdf</a>, <a href="/format/2302.01665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CVTNet: A Cross-View Transformer Network for Place Recognition Using  LiDAR Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guangming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xieyuanli Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Industrial Informatics 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13680" title="Abstract">arXiv:2302.13680</a> (replaced) [<a href="/pdf/2302.13680" title="Download PDF">pdf</a>, <a href="/format/2302.13680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multigrid solver for PDE-constrained optimization with uncertain  inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ciaramella%2C+G">Gabriele Ciaramella</a>, 
<a href="/search/math?searchtype=author&query=Nobile%2C+F">Fabio Nobile</a>, 
<a href="/search/math?searchtype=author&query=Vanzan%2C+T">Tommaso Vanzan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14357" title="Abstract">arXiv:2302.14357</a> (replaced) [<a href="/pdf/2302.14357" title="Download PDF">pdf</a>, <a href="/ps/2302.14357" title="Download PostScript">ps</a>, <a href="/format/2302.14357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Token-Wise Beam Search Algorithm for RNN-T
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keren%2C+G">Gil Keren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Presentation at ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05686" title="Abstract">arXiv:2303.05686</a> (replaced) [<a href="/pdf/2303.05686" title="Download PDF">pdf</a>, <a href="/format/2303.05686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI for Rapid Diffusion MRI with Improved Image Quality,  Reliability and Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sadikov%2C+A">Amir Sadikov</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+X">Xinlei Pan</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+H">Hannah Choi</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+L+T">Lanya T. Cai</a>, 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+P">Pratik Mukherjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06247" title="Abstract">arXiv:2303.06247</a> (replaced) [<a href="/pdf/2303.06247" title="Download PDF">pdf</a>, <a href="/format/2303.06247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task and Motion Planning with Large Language Models for Object  Rearrangement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Paxton%2C+C">Chris Paxton</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiqi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accpted by IEEE IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10865" title="Abstract">arXiv:2303.10865</a> (replaced) [<a href="/pdf/2303.10865" title="Download PDF">pdf</a>, <a href="/format/2303.10865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotating Objects via In-Hand Pivoting using Vision, Force and Touch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shiyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+M">Michael Wong</a>, 
<a href="/search/cs?searchtype=author&query=Kuli%C4%87%2C+D">Dana Kuli&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Cosgun%2C+A">Akansel Cosgun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00012" title="Abstract">arXiv:2304.00012</a> (replaced) [<a href="/pdf/2304.00012" title="Download PDF">pdf</a>, <a href="/format/2304.00012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task Learning for Post-transplant Cause of Death Analysis: A Case  Study on Liver Transplant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Sirui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Q">Qiaoyu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chia-yuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+N">Na Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hoot%2C+N+R">Nathan R. Hoot</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoqian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMIA Annual Symposium 2023 Best Student Paper Finalist
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00570" title="Abstract">arXiv:2304.00570</a> (replaced) [<a href="/pdf/2304.00570" title="Download PDF">pdf</a>, <a href="/format/2304.00570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedFTN: Personalized Federated Learning with Deep Feature Transformation  Network for Multi-institutional Low-count PET Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+H">Huidong Xie</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qiong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiongchao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+X">Xueqi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhicheng Feng</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+J">Jun Hou</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Biao Li</a>, 
<a href="/search/eess?searchtype=author&query=Rominger%2C+A">Axel Rominger</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+K">Kuangyu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Duncan%2C+J+S">James S. Duncan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, Accepted at Medical Image Analysis Journal (MedIA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00639" title="Abstract">arXiv:2304.00639</a> (replaced) [<a href="/pdf/2304.00639" title="Download PDF">pdf</a>, <a href="/format/2304.00639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerModelsADA: A Framework for Solving Optimal Power Flow using  Distributed Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alkhraijah%2C+M">Mohannad Alkhraijah</a>, 
<a href="/search/eess?searchtype=author&query=Harris%2C+R">Rachel Harris</a>, 
<a href="/search/eess?searchtype=author&query=Coffrin%2C+C">Carleton Coffrin</a>, 
<a href="/search/eess?searchtype=author&query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01814" title="Abstract">arXiv:2304.01814</a> (replaced) [<a href="/pdf/2304.01814" title="Download PDF">pdf</a>, <a href="/format/2304.01814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoreDiff: Contextual Error-Modulated Generalized Diffusion Model for  Low-Dose CT Denoising and Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+Q">Qi Gao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zilong Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Shan%2C+H">Hongming Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Medical Imaging, 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Medical Imaging, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10888" title="Abstract">arXiv:2304.10888</a> (replaced) [<a href="/pdf/2304.10888" title="Download PDF">pdf</a>, <a href="/format/2304.10888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust, Agile, Natural Legged Locomotion Skills in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zheyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianyu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page and videos: <a href="https://sites.google.com/view/adaptive-multiskill-locomotion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14993" title="Abstract">arXiv:2304.14993</a> (replaced) [<a href="/pdf/2304.14993" title="Download PDF">pdf</a>, <a href="/ps/2304.14993" title="Download PostScript">ps</a>, <a href="/format/2304.14993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses  for Solving Undergraduate Computer Science Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+I">Ishika Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Budhiraja%2C+R">Ritvik Budhiraja</a>, 
<a href="/search/cs?searchtype=author&query=Dev%2C+H">Harshal Dev</a>, 
<a href="/search/cs?searchtype=author&query=Kadia%2C+J">Jahnvi Kadia</a>, 
<a href="/search/cs?searchtype=author&query=Ataullah%2C+M+O">M. Osama Ataullah</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Sayan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Akolekar%2C+H+D">Harshal D. Akolekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in SIGCSE TS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01711" title="Abstract">arXiv:2305.01711</a> (replaced) [<a href="/pdf/2305.01711" title="Download PDF">pdf</a>, <a href="/format/2305.01711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengxiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lipani%2C+A">Aldo Lipani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Main Track) Camera-ready Version. Code is available at <a href="https://github.com/ZhengxiangShi/PowerfulPromptFT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02731" title="Abstract">arXiv:2305.02731</a> (replaced) [<a href="/pdf/2305.02731" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cluster-Based Opposition Differential Evolution Algorithm Boosted by a  Local Search for ECG Signal Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourvahab%2C+M">Mehran Pourvahab</a>, 
<a href="/search/cs?searchtype=author&query=Mousavirad%2C+S+J">Seyed Jalaleddin Mousavirad</a>, 
<a href="/search/cs?searchtype=author&query=Felizardo%2C+V">Virginie Felizardo</a>, 
<a href="/search/cs?searchtype=author&query=Pombo%2C+N">Nuno Pombo</a>, 
<a href="/search/cs?searchtype=author&query=Zacarias%2C+H">Henriques Zacarias</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadigheymasi%2C+H">Hamzeh Mohammadigheymasi</a>, 
<a href="/search/cs?searchtype=author&query=Pais%2C+S">Sebasti&#xe3;o Pais</a>, 
<a href="/search/cs?searchtype=author&query=Jafari%2C+S+N">Seyed Nooreddin Jafari</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+N+M">Nuno M.Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03040" title="Abstract">arXiv:2305.03040</a> (replaced) [<a href="/pdf/2305.03040" title="Download PDF">pdf</a>, <a href="/format/2305.03040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TUVF: Learning Generalizable Texture UV Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">An-Chieh Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueting Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://www.anjiecheng.me/TUVF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03584" title="Abstract">arXiv:2305.03584</a> (replaced) [<a href="/pdf/2305.03584" title="Download PDF">pdf</a>, <a href="/format/2305.03584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Now It Sounds Like You: Learning Personalized Vocabulary On Device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sid Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+A">Ashish Shenoy</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+P">Pierce Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+J">John Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Federated Learning, Personalization, On-device NLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04809" title="Abstract">arXiv:2305.04809</a> (replaced) [<a href="/pdf/2305.04809" title="Download PDF">pdf</a>, <a href="/format/2305.04809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remote Estimation of Gauss-Markov Processes over Multiple Channels: A  Whittle Index Policy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ornee%2C+T+Z">Tasmeen Zaman Ornee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures. This manuscript has been submitted to IEEE/ACM Transactions on Networking
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08851" title="Abstract">arXiv:2305.08851</a> (replaced) [<a href="/pdf/2305.08851" title="Download PDF">pdf</a>, <a href="/format/2305.08851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MV-Map: Offboard HD-Map Generation with Multi-view Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Ziyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Z">Ziqi Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14405" title="Abstract">arXiv:2305.14405</a> (replaced) [<a href="/pdf/2305.14405" title="Download PDF">pdf</a>, <a href="/format/2305.14405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuralMatrix: Compute the Entire Neural Networks with Linear Matrix  Operations for Efficient Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruiqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">An Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4figures, Submitted to 11th International Conference on Learning Representations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15612" title="Abstract">arXiv:2305.15612</a> (replaced) [<a href="/pdf/2305.15612" title="Download PDF">pdf</a>, <a href="/format/2305.15612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Ratio Estimation-based Bayesian Optimization with  Semi-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jungtaek Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16008" title="Abstract">arXiv:2305.16008</a> (replaced) [<a href="/pdf/2305.16008" title="Download PDF">pdf</a>, <a href="/format/2305.16008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-based Safe Autonomous UAV Docking with Panoramic Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thuan%2C+P+N">Phuoc Nguyen Thuan</a>, 
<a href="/search/cs?searchtype=author&query=Westerlund%2C+T">Tomi Westerlund</a>, 
<a href="/search/cs?searchtype=author&query=Queralta%2C+J+P">Jorge Pe&#xf1;a Queralta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16329" title="Abstract">arXiv:2305.16329</a> (replaced) [<a href="/pdf/2305.16329" title="Download PDF">pdf</a>, <a href="/format/2305.16329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple protocol to automate the executing, scaling, and  reconfiguration of Cloud-Native Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambroszkiewicz%2C+S">Stanislaw Ambroszkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Bartyna%2C+W">Waldemar Bartyna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> improved version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17154" title="Abstract">arXiv:2305.17154</a> (replaced) [<a href="/pdf/2305.17154" title="Download PDF">pdf</a>, <a href="/format/2305.17154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On convex decision regions in deep network representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C4%9Btkov%C3%A1%2C+L">Lenka T&#x11b;tkov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Br%C3%BCsch%2C+T">Thea Br&#xfc;sch</a>, 
<a href="/search/cs?searchtype=author&query=Scheidt%2C+T+K">Teresa Karen Scheidt</a>, 
<a href="/search/cs?searchtype=author&query=Mager%2C+F+M">Fabian Martin Mager</a>, 
<a href="/search/cs?searchtype=author&query=Aagaard%2C+R+%C3%98">Rasmus &#xd8;rtoft Aagaard</a>, 
<a href="/search/cs?searchtype=author&query=Foldager%2C+J">Jonathan Foldager</a>, 
<a href="/search/cs?searchtype=author&query=Alstr%C3%B8m%2C+T+S">Tommy Sonne Alstr&#xf8;m</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+L+K">Lars Kai Hansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17558" title="Abstract">arXiv:2305.17558</a> (replaced) [<a href="/pdf/2305.17558" title="Download PDF">pdf</a>, <a href="/format/2305.17558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Fast Finite Particle Variants of SVGD via Virtual Particle  Stochastic Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Das%2C+A">Aniket Das</a>, 
<a href="/search/stat?searchtype=author&query=Nagaraj%2C+D">Dheeraj Nagaraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear as a Spotlight Paper in The 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17590" title="Abstract">arXiv:2305.17590</a> (replaced) [<a href="/pdf/2305.17590" title="Download PDF">pdf</a>, <a href="/format/2305.17590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Action Knowledge and LLMs for Task Planning and Situation  Handling in Open Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Amiri%2C+S">Saeid Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+N">Nieqing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kaminski%2C+A">Andy Kaminski</a>, 
<a href="/search/cs?searchtype=author&query=Esselink%2C+C">Chad Esselink</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiqi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.01287">arXiv:2210.01287</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Autonomous Robots, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18030" title="Abstract">arXiv:2305.18030</a> (replaced) [<a href="/pdf/2305.18030" title="Download PDF">pdf</a>, <a href="/format/2305.18030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Search-Space Generation Neural Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Luming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tianyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zharkov%2C+I">Ilya Zharkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Graph visualization for DARTS, SuperResNet are omitted for arXiv version due to exceeding page dimension limit. Please refer to the open-review version for taking the visualizations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19523" title="Abstract">arXiv:2305.19523</a> (replaced) [<a href="/pdf/2305.19523" title="Download PDF">pdf</a>, <a href="/format/2305.19523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Explanations: LLM-to-LM Interpreter for Enhanced  Text-Attributed Graph Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxin He</a>, 
<a href="/search/cs?searchtype=author&query=Bresson%2C+X">Xavier Bresson</a>, 
<a href="/search/cs?searchtype=author&query=Laurent%2C+T">Thomas Laurent</a>, 
<a href="/search/cs?searchtype=author&query=Perold%2C+A">Adam Perold</a>, 
<a href="/search/cs?searchtype=author&query=LeCun%2C+Y">Yann LeCun</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19663" title="Abstract">arXiv:2305.19663</a> (replaced) [<a href="/pdf/2305.19663" title="Download PDF">pdf</a>, <a href="/format/2305.19663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structured Matrix Method for Nonequispaced Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lingsch%2C+L">Levi Lingsch</a>, 
<a href="/search/cs?searchtype=author&query=Michelis%2C+M">Mike Michelis</a>, 
<a href="/search/cs?searchtype=author&query=de+Bezenac%2C+E">Emmanuel de Bezenac</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+S+M">Sirani M. Perera</a>, 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00083" title="Abstract">arXiv:2306.00083</a> (replaced) [<a href="/pdf/2306.00083" title="Download PDF">pdf</a>, <a href="/format/2306.00083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bell sampling from quantum circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Hangleiter%2C+D">Dominik Hangleiter</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gullans%2C+M+J">Michael J. Gullans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7+14 pages, 2 figures. Comments welcome. v2: corrected typos, added references v3: added results, improved proofs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Quantum Gases (cond-mat.quant-gas); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02099" title="Abstract">arXiv:2306.02099</a> (replaced) [<a href="/pdf/2306.02099" title="Download PDF">pdf</a>, <a href="/format/2306.02099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroSURF: Neural Uncertainty-aware Robust Surface Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sang%2C+L">Lu Sang</a>, 
<a href="/search/cs?searchtype=author&query=Saroha%2C+A">Abhishek Saroha</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Maolin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02422" title="Abstract">arXiv:2306.02422</a> (replaced) [<a href="/pdf/2306.02422" title="Download PDF">pdf</a>, <a href="/format/2306.02422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Alternating Method for Bilevel Learning under the  Polyak-&#x141;ojasiewicz Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiao%2C+Q">Quan Xiao</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+S">Songtao Lu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03675" title="Abstract">arXiv:2306.03675</a> (replaced) [<a href="/pdf/2306.03675" title="Download PDF">pdf</a>, <a href="/format/2306.03675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potential of the Julia programming language for high energy physics  computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Eschle%2C+J">J. Eschle</a>, 
<a href="/search/hep-ph?searchtype=author&query=Gal%2C+T">T. Gal</a>, 
<a href="/search/hep-ph?searchtype=author&query=Giordano%2C+M">M. Giordano</a>, 
<a href="/search/hep-ph?searchtype=author&query=Gras%2C+P">P. Gras</a>, 
<a href="/search/hep-ph?searchtype=author&query=Hegner%2C+B">B. Hegner</a>, 
<a href="/search/hep-ph?searchtype=author&query=Heinrich%2C+L">L. Heinrich</a>, 
<a href="/search/hep-ph?searchtype=author&query=Acosta%2C+U+H">U. Hernandez Acosta</a>, 
<a href="/search/hep-ph?searchtype=author&query=Kluth%2C+S">S. Kluth</a>, 
<a href="/search/hep-ph?searchtype=author&query=Ling%2C+J">J. Ling</a>, 
<a href="/search/hep-ph?searchtype=author&query=Mato%2C+P">P. Mato</a>, 
<a href="/search/hep-ph?searchtype=author&query=Mikhasenko%2C+M">M. Mikhasenko</a>, 
<a href="/search/hep-ph?searchtype=author&query=Brice%C3%B1o%2C+A+M">A. Moreno Brice&#xf1;o</a>, 
<a href="/search/hep-ph?searchtype=author&query=Pivarski%2C+J">J. Pivarski</a>, 
<a href="/search/hep-ph?searchtype=author&query=Samaras-Tsakiris%2C+K">K. Samaras-Tsakiris</a>, 
<a href="/search/hep-ph?searchtype=author&query=Schulz%2C+O">O. Schulz</a>, 
<a href="/search/hep-ph?searchtype=author&query=Stewart%2C+G+.+A">G. .A. Stewart</a>, 
<a href="/search/hep-ph?searchtype=author&query=Strube%2C+J">J. Strube</a>, 
<a href="/search/hep-ph?searchtype=author&query=Vassilev%2C+V">V. Vassilev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures, 4 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computing. Comput Softw Big Sci 7, 10 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Programming Languages (cs.PL); High Energy Physics - Experiment (hep-ex); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04072" title="Abstract">arXiv:2306.04072</a> (replaced) [<a href="/pdf/2306.04072" title="Download PDF">pdf</a>, <a href="/format/2306.04072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple High Quality OoD Detection with L2 Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haas%2C+J">Jarrod Haas</a>, 
<a href="/search/cs?searchtype=author&query=Yolland%2C+W">William Yolland</a>, 
<a href="/search/cs?searchtype=author&query=Rabus%2C+B">Bernhard Rabus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04959" title="Abstract">arXiv:2306.04959</a> (replaced) [<a href="/pdf/2306.04959" title="Download PDF">pdf</a>, <a href="/format/2306.04959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMLSecurity: A Benchmark for Attacks and Defenses in Federated  Learning and Federated LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shanshan Han</a>, 
<a href="/search/cs?searchtype=author&query=Buyukates%2C+B">Baturalp Buyukates</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zijian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Han Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Weizhao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chaoyang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07506" title="Abstract">arXiv:2306.07506</a> (replaced) [<a href="/pdf/2306.07506" title="Download PDF">pdf</a>, <a href="/format/2306.07506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic-Centric Explanations for News Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dairui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Greene%2C+D">Derek Greene</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Ruihai Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07863" title="Abstract">arXiv:2306.07863</a> (replaced) [<a href="/pdf/2306.07863" title="Download PDF">pdf</a>, <a href="/format/2306.07863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Longtao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rundong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinrun Wang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07891" title="Abstract">arXiv:2306.07891</a> (replaced) [<a href="/pdf/2306.07891" title="Download PDF">pdf</a>, <a href="/format/2306.07891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Matching in Geometric Random Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sentenac%2C+F">Flore Sentenac</a>, 
<a href="/search/cs?searchtype=author&query=Noiry%2C+N">Nathan Noiry</a>, 
<a href="/search/cs?searchtype=author&query=Lerasle%2C+M">Matthieu Lerasle</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9nard%2C+L">Laurent M&#xe9;nard</a>, 
<a href="/search/cs?searchtype=author&query=Perchet%2C+V">Vianney Perchet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08261" title="Abstract">arXiv:2306.08261</a> (replaced) [<a href="/pdf/2306.08261" title="Download PDF">pdf</a>, <a href="/format/2306.08261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong regulatory graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gustafsson%2C+P">Patric Gustafsson</a>, 
<a href="/search/cs?searchtype=author&query=Petre%2C+I">Ion Petre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Molecular Networks (q-bio.MN); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11201" title="Abstract">arXiv:2306.11201</a> (replaced) [<a href="/pdf/2306.11201" title="Download PDF">pdf</a>, <a href="/format/2306.11201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Federated Learning with Auto-Tuned Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+L">Junhyung Lyle Kim</a>, 
<a href="/search/cs?searchtype=author&query=Toghani%2C+M+T">Mohammad Taha Toghani</a>, 
<a href="/search/cs?searchtype=author&query=Uribe%2C+C+A">C&#xe9;sar A. Uribe</a>, 
<a href="/search/cs?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11363" title="Abstract">arXiv:2306.11363</a> (replaced) [<a href="/pdf/2306.11363" title="Download PDF">pdf</a>, <a href="/format/2306.11363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Diffusion Models Are Fast Distribution Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiachen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+Z">Zhongjie Ba</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11695" title="Abstract">arXiv:2306.11695</a> (replaced) [<a href="/pdf/2306.11695" title="Download PDF">pdf</a>, <a href="/format/2306.11695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and Effective Pruning Approach for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingjie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bair%2C+A">Anna Bair</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page available at <a href="https://eric-mingjie.github.io/wanda/home.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14435" title="Abstract">arXiv:2306.14435</a> (replaced) [<a href="/pdf/2306.14435" title="Download PDF">pdf</a>, <a href="/format/2306.14435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DragDiffusion: Harnessing Diffusion Models for Interactive Point-based  Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yujun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Chuhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiachun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanshu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+V+Y+F">Vincent Y. F. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Song Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is released at <a href="https://github.com/Yujun-Shi/DragDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15350" title="Abstract">arXiv:2306.15350</a> (replaced) [<a href="/pdf/2306.15350" title="Download PDF">pdf</a>, <a href="/format/2306.15350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CellViT: Vision Transformers for Precise Cell Segmentation and  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=H%C3%B6rst%2C+F">Fabian H&#xf6;rst</a>, 
<a href="/search/eess?searchtype=author&query=Rempe%2C+M">Moritz Rempe</a>, 
<a href="/search/eess?searchtype=author&query=Heine%2C+L">Lukas Heine</a>, 
<a href="/search/eess?searchtype=author&query=Seibold%2C+C">Constantin Seibold</a>, 
<a href="/search/eess?searchtype=author&query=Keyl%2C+J">Julius Keyl</a>, 
<a href="/search/eess?searchtype=author&query=Baldini%2C+G">Giulia Baldini</a>, 
<a href="/search/eess?searchtype=author&query=Ugurel%2C+S">Selma Ugurel</a>, 
<a href="/search/eess?searchtype=author&query=Siveke%2C+J">Jens Siveke</a>, 
<a href="/search/eess?searchtype=author&query=Gr%C3%BCnwald%2C+B">Barbara Gr&#xfc;nwald</a>, 
<a href="/search/eess?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/eess?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, appendix included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03887" title="Abstract">arXiv:2307.03887</a> (replaced) [<a href="/pdf/2307.03887" title="Download PDF">pdf</a>, <a href="/format/2307.03887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Prototypical Part Networks with Reward Reweighing,  Reselection, and Retraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Netzorg%2C+R">Robin Netzorg</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bin Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05782" title="Abstract">arXiv:2307.05782</a> (replaced) [<a href="/pdf/2307.05782" title="Download PDF">pdf</a>, <a href="/format/2307.05782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Douglas%2C+M+R">Michael R. Douglas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages (v2: added references, corrected typos)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; High Energy Physics - Theory (hep-th); History and Overview (math.HO); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06362" title="Abstract">arXiv:2307.06362</a> (replaced) [<a href="/pdf/2307.06362" title="Download PDF">pdf</a>, <a href="/format/2307.06362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Seroussi%2C+I">Inbar Seroussi</a>, 
<a href="/search/stat?searchtype=author&query=Miron%2C+A">Asaf Miron</a>, 
<a href="/search/stat?searchtype=author&query=Ringel%2C+Z">Zohar Ringel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06966" title="Abstract">arXiv:2307.06966</a> (replaced) [<a href="/pdf/2307.06966" title="Download PDF">pdf</a>, <a href="/format/2307.06966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-wise Linear Mode Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adilova%2C+L">Linara Adilova</a>, 
<a href="/search/cs?searchtype=author&query=Andriushchenko%2C+M">Maksym Andriushchenko</a>, 
<a href="/search/cs?searchtype=author&query=Kamp%2C+M">Michael Kamp</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+A">Asja Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09087" title="Abstract">arXiv:2307.09087</a> (replaced) [<a href="/pdf/2307.09087" title="Download PDF">pdf</a>, <a href="/format/2307.09087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hitchhiker&#x27;s Guide to Malicious Third-Party Dependencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ladisa%2C+P">Piergiorgio Ladisa</a>, 
<a href="/search/cs?searchtype=author&query=Sahin%2C+M">Merve Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Ponta%2C+S+E">Serena Elisa Ponta</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+M">Marco Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+M">Matias Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Barais%2C+O">Olivier Barais</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED '23), November 30, 2023, Copenhagen, Denmark
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09447" title="Abstract">arXiv:2307.09447</a> (replaced) [<a href="/pdf/2307.09447" title="Download PDF">pdf</a>, <a href="/format/2307.09447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Aggregation for Recommending Items to Group of Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Due%C3%B1as-Ler%C3%ADn%2C+J">Jorge Due&#xf1;as-Ler&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Lara-Cabrera%2C+R">Ra&#xfa;l Lara-Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+F">Fernando Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Bobadilla%2C+J">Jes&#xfa;s Bobadilla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10274" title="Abstract">arXiv:2307.10274</a> (replaced) [<a href="/pdf/2307.10274" title="Download PDF">pdf</a>, <a href="/format/2307.10274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning  Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liao%2C+F">Feng-Ting Liao</a>, 
<a href="/search/eess?searchtype=author&query=Chan%2C+Y">Yung-Chieh Chan</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yi-Chang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Hsu%2C+C">Chan-Jan Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Shiu%2C+D">Da-shan Shiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> F-T Liao and Y-C Chan contributed equally; paper accepted to ASRU2023; code and model weights available in <a href="https://github.com/mtkresearch/clairaudience">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11256" title="Abstract">arXiv:2307.11256</a> (replaced) [<a href="/pdf/2307.11256" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable cascaded thermal neuristors for neuromorphic computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+E">Erbin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan-Hang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Di+Ventra%2C+M">Massimiliano Di Ventra</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+I+K">Ivan K. Schuller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11865" title="Abstract">arXiv:2307.11865</a> (replaced) [<a href="/pdf/2307.11865" title="Download PDF">pdf</a>, <a href="/format/2307.11865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction  Execution for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivkin%2C+D">Dmitriy Rivkin</a>, 
<a href="/search/cs?searchtype=author&query=Kakodkar%2C+N">Nikhil Kakodkar</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Baghi%2C+B+H">Bobak H. Baghi</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13717" title="Abstract">arXiv:2307.13717</a> (replaced) [<a href="/pdf/2307.13717" title="Download PDF">pdf</a>, <a href="/format/2307.13717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Leakage of Fuzzy Matchers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durbet%2C+A">Axel Durbet</a>, 
<a href="/search/cs?searchtype=author&query=Thiry-Atighehchi%2C+K">Kevin Thiry-Atighehchi</a>, 
<a href="/search/cs?searchtype=author&query=Chagnon%2C+D">Dorine Chagnon</a>, 
<a href="/search/cs?searchtype=author&query=Grollemund%2C+P">Paul-Marie Grollemund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16708" title="Abstract">arXiv:2307.16708</a> (replaced) [<a href="/pdf/2307.16708" title="Download PDF">pdf</a>, <a href="/format/2307.16708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Meets Adaptive Filtering: A Stein&#x27;s Unbiased Risk  Estimator Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Esmaeilbeig%2C+Z">Zahra Esmaeilbeig</a>, 
<a href="/search/eess?searchtype=author&query=Soltanalian%2C+M">Mojtaba Soltanalian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2011.07458">arXiv:2011.07458</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16888" title="Abstract">arXiv:2307.16888</a> (replaced) [<a href="/pdf/2307.16888" title="Download PDF">pdf</a>, <a href="/format/2307.16888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdooring Instruction-Tuned Large Language Models with Virtual Prompt  Injection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+V">Vikas Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+V">Vijay Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00206" title="Abstract">arXiv:2308.00206</a> (replaced) [<a href="/pdf/2308.00206" title="Download PDF">pdf</a>, <a href="/format/2308.00206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkullGAN: Synthetic Skull CT Generation with Generative Adversarial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Naftchi-Ardebili%2C+K">Kasra Naftchi-Ardebili</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+K">Karanpartap Singh</a>, 
<a href="/search/eess?searchtype=author&query=Pourabolghasem%2C+R">Reza Pourabolghasem</a>, 
<a href="/search/eess?searchtype=author&query=Ghanouni%2C+P">Pejman Ghanouni</a>, 
<a href="/search/eess?searchtype=author&query=Popelka%2C+G+R">Gerald R. Popelka</a>, 
<a href="/search/eess?searchtype=author&query=Pauly%2C+K+B">Kim Butts Pauly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01028" title="Abstract">arXiv:2308.01028</a> (replaced) [<a href="/pdf/2308.01028" title="Download PDF">pdf</a>, <a href="/format/2308.01028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Success Rate of Payment Routing using Non-stationary Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+A">Aayush Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Abhinav Rai</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01251" title="Abstract">arXiv:2308.01251</a> (replaced) [<a href="/pdf/2308.01251" title="Download PDF">pdf</a>, <a href="/format/2308.01251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for  Old Landslide Detection through Fusing High-Resolution Remote Sensing Images  and Digital Elevation Model Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yuexing Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junchuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+D">Daqing Ge</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wei Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02434" title="Abstract">arXiv:2308.02434</a> (replaced) [<a href="/pdf/2308.02434" title="Download PDF">pdf</a>, <a href="/format/2308.02434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Search method for Zermelo&#x27;s navigation problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Precioso%2C+D">Daniel Precioso</a>, 
<a href="/search/cs?searchtype=author&query=Milson%2C+R">Robert Milson</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+L">Louis Bu</a>, 
<a href="/search/cs?searchtype=author&query=Menchions%2C+Y">Yvonne Menchions</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Ullate%2C+D">David G&#xf3;mez-Ullate</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05014" title="Abstract">arXiv:2308.05014</a> (replaced) [<a href="/pdf/2308.05014" title="Download PDF">pdf</a>, <a href="/format/2308.05014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Empirical Study of Bugs in Open-Source Federated  Learning Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Weijie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fu Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lingling Fan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">JingZhu He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08896" title="Abstract">arXiv:2308.08896</a> (replaced) [<a href="/pdf/2308.08896" title="Download PDF">pdf</a>, <a href="/format/2308.08896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Resource Allocation for U-Shaped Parallel Split Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Song Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Guanqiao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xianhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoxia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09375" title="Abstract">arXiv:2308.09375</a> (replaced) [<a href="/pdf/2308.09375" title="Download PDF">pdf</a>, <a href="/format/2308.09375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Processing and Machine Learning for Hyperspectral Unmixing: An  Overview and the HySUPP Python Package
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rasti%2C+B">Behnood Rasti</a> (HZDR), 
<a href="/search/eess?searchtype=author&query=Zouaoui%2C+A">Alexandre Zouaoui</a> (Thoth), 
<a href="/search/eess?searchtype=author&query=Mairal%2C+J">Julien Mairal</a> (Thoth), 
<a href="/search/eess?searchtype=author&query=Chanussot%2C+J">Jocelyn Chanussot</a> (Thoth)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11053" title="Abstract">arXiv:2308.11053</a> (replaced) [<a href="/pdf/2308.11053" title="Download PDF">pdf</a>, <a href="/format/2308.11053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra Dual-Path Compression For Joint Echo Cancellation And Noise  Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yi Luo</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+R">Rongzhi Gu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Weihua Li</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Z">Zhuocheng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Weng%2C+C">Chao Weng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of INTERSPEECH
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11804" title="Abstract">arXiv:2308.11804</a> (replaced) [<a href="/pdf/2308.11804" title="Download PDF">pdf</a>, <a href="/format/2308.11804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Illusions in Multi-Modal Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagdasaryan%2C+E">Eugene Bagdasaryan</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+R">Rishi Jha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shmatikov%2C+V">Vitaly Shmatikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11838" title="Abstract">arXiv:2308.11838</a> (replaced) [<a href="/e-print/2308.11838" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Benchmark Study on Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Linwei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Younan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haolan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Minjing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There was an error in the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12462" title="Abstract">arXiv:2308.12462</a> (replaced) [<a href="/pdf/2308.12462" title="Download PDF">pdf</a>, <a href="/format/2308.12462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming General Knowledge Loss with Selective Parameter Update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Janson%2C+P">Paul Janson</a>, 
<a href="/search/cs?searchtype=author&query=Aljundi%2C+R">Rahaf Aljundi</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15177" title="Abstract">arXiv:2308.15177</a> (replaced) [<a href="/pdf/2308.15177" title="Download PDF">pdf</a>, <a href="/format/2308.15177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancements on a saturated control for stabilizing a quadcopter:  adaptive and robustness analysis in the flat output space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Do%2C+H">Huu-Thinh Do</a>, 
<a href="/search/eess?searchtype=author&query=Blanchini%2C+F">Franco Blanchini</a>, 
<a href="/search/eess?searchtype=author&query=Prodan%2C+I">Ionela Prodan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03882" title="Abstract">arXiv:2309.03882</a> (replaced) [<a href="/pdf/2309.03882" title="Download PDF">pdf</a>, <a href="/format/2309.03882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Are Not Robust Multiple Choice Selectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chujie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add new LLMs' results and more analyses. Experimental results will be released at <a href="https://github.com/chujiezheng/LLM-MCQ-Bias">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05257" title="Abstract">arXiv:2309.05257</a> (replaced) [<a href="/pdf/2309.05257" title="Download PDF">pdf</a>, <a href="/format/2309.05257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionFormer: A Multi-sensory Fusion in Bird&#x27;s-Eye-View and Temporal  Consistent Transformer for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunyong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianyun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weibo Mao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Maochun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingxia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qihao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiru Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+P">Peihan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaicheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05938" title="Abstract">arXiv:2309.05938</a> (replaced) [<a href="/e-print/2309.05938" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Answering Subjective Induction Questions on Products by Summarizing  Multi-sources Multi-viewpoints Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yufeng Zhang</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng-xiang Wang</a> (3), 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianxing Yu</a> (1, 2 and 4) ((1) School of Artificial Intelligence, Sun Yat-sen University, Zhuhai 519082 (2) Guangdong Key Laboratory of Big Data Analysis and Processing, 510006, China (3) China National Institute of Standardization, 100088, China (4) Pazhou Lab, Guangzhou, 510330, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1. There are some errors in the data analysis table in the dataset SupQA, which needs to be corrected. 2. There is something wrong with the partial expression of the formula. 3. It will be resubmitted after modification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06229" title="Abstract">arXiv:2309.06229</a> (replaced) [<a href="/pdf/2309.06229" title="Download PDF">pdf</a>, <a href="/format/2309.06229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreciseBugCollector: Extensible, Executable and Precise Bug-fix  Collection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">He Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Goues%2C+C+L">Claire Le Goues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the industry challenge track of ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07182" title="Abstract">arXiv:2309.07182</a> (replaced) [<a href="/pdf/2309.07182" title="Download PDF">pdf</a>, <a href="/format/2309.07182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sleep Stage Classification Using a Pre-trained Deep Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ardeshir%2C+H">Hassan Ardeshir</a>, 
<a href="/search/eess?searchtype=author&query=Araghi%2C+M">Mohammad Araghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07617" title="Abstract">arXiv:2309.07617</a> (replaced) [<a href="/pdf/2309.07617" title="Download PDF">pdf</a>, <a href="/format/2309.07617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Influence Robustness of Nodes in Multiplex Networks against Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Boqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiaojiao Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The quality of the images has been improved, paragraphs have been polished to fit the camera-ready version, and the paper has been accepted by COMPLEX NETWORK 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Networking and Internet Architecture (cs.NI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09059" title="Abstract">arXiv:2309.09059</a> (replaced) [<a href="/pdf/2309.09059" title="Download PDF">pdf</a>, <a href="/format/2309.09059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Monte Carlo quadrature with optimal confidence intervals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kunsch%2C+R+J">Robert J. Kunsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09464" title="Abstract">arXiv:2309.09464</a> (replaced) [<a href="/e-print/2309.09464" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Adversarial Training Cost with Gradient Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+H">Huihui Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Siqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Camtepe%2C+S">Seyit Camtepe</a>, 
<a href="/search/cs?searchtype=author&query=Nepal%2C+S">Surya Nepal</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are some issues of the experiments. Withraw this manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09826" title="Abstract">arXiv:2309.09826</a> (replaced) [<a href="/pdf/2309.09826" title="Download PDF">pdf</a>, <a href="/format/2309.09826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract  Code Using Vulnerability-constrained Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Storhaug%2C+A">Andr&#xe9; Storhaug</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianyuan Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 2 tables, 5 listings, accepted to the 34th IEEE International Symposium on Software Reliability Engineering (ISSRE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10831" title="Abstract">arXiv:2309.10831</a> (replaced) [<a href="/pdf/2309.10831" title="Download PDF">pdf</a>, <a href="/format/2309.10831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Actively Learning Reinforcement Learning: A Stochastic Optimal Control  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramadan%2C+M+S">Mohammad S. Ramadan</a>, 
<a href="/search/cs?searchtype=author&query=Hayajnh%2C+M+A">Mahmoud A. Hayajnh</a>, 
<a href="/search/cs?searchtype=author&query=Tolley%2C+M+T">Michael T. Tolley</a>, 
<a href="/search/cs?searchtype=author&query=Vamvoudakis%2C+K+G">Kyriakos G. Vamvoudakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11912" title="Abstract">arXiv:2309.11912</a> (replaced) [<a href="/pdf/2309.11912" title="Download PDF">pdf</a>, <a href="/ps/2309.11912" title="Download PostScript">ps</a>, <a href="/format/2309.11912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The supersingular endomorphism ring problem given one endomorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merdy%2C+A+H+L">Arthur Herl&#xe9;dan Le Merdy</a> (LIP), 
<a href="/search/cs?searchtype=author&query=Wesolowski%2C+B">Benjamin Wesolowski</a> (CNRS, UMPA-ENSL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12245" title="Abstract">arXiv:2309.12245</a> (replaced) [<a href="/pdf/2309.12245" title="Download PDF">pdf</a>, <a href="/format/2309.12245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Input-image Normalization for Solving the Mode Collapse Problem  in GAN-based X-ray Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saad%2C+M+M">Muhammad Muneeb Saad</a>, 
<a href="/search/eess?searchtype=author&query=Rehmani%2C+M+H">Mubashir Husain Rehmani</a>, 
<a href="/search/eess?searchtype=author&query=O%27Reilly%2C+R">Ruairi O&#x27;Reilly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Elsevier Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12374" title="Abstract">arXiv:2309.12374</a> (replaced) [<a href="/pdf/2309.12374" title="Download PDF">pdf</a>, <a href="/ps/2309.12374" title="Download PostScript">ps</a>, <a href="/format/2309.12374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rational Aversion to Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Neth%2C+S">Sven Neth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Forthcoming in The British Journal for the Philosophy of Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Statistics (stat.OT)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13196" title="Abstract">arXiv:2309.13196</a> (replaced) [<a href="/pdf/2309.13196" title="Download PDF">pdf</a>, <a href="/format/2309.13196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterFormer: Clustering As A Universal Visual Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J+C">James C. Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongfang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13476" title="Abstract">arXiv:2309.13476</a> (replaced) [<a href="/pdf/2309.13476" title="Download PDF">pdf</a>, <a href="/format/2309.13476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical attention interpretation: an interpretable speech-level  transformer for bi-modal depression detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Q">Qingkun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Luz%2C+S">Saturnino Luz</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Fuente+Garcia%2C+S">Sofia de la Fuente Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14293" title="Abstract">arXiv:2309.14293</a> (replaced) [<a href="/pdf/2309.14293" title="Download PDF">pdf</a>, <a href="/format/2309.14293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAS-NeRF: Generative Neural Architecture Search for Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+S">Saeejith Nair</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shafiee%2C+M+J">Mohammad Javad Shafiee</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14674" title="Abstract">arXiv:2309.14674</a> (replaced) [<a href="/e-print/2309.14674" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Herpangina Data to Enhance Hospital-level Prediction of  Hand-Foot-and-Mouth Disease Admissions Using UPTST
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hailun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Huan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Ximing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> No finished yet
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15763" title="Abstract">arXiv:2309.15763</a> (replaced) [<a href="/pdf/2309.15763" title="Download PDF">pdf</a>, <a href="/ps/2309.15763" title="Download PostScript">ps</a>, <a href="/format/2309.15763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impossible and Conflicting Obligations in Justification Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faroldi%2C+F+L+G">Federico L. G. Faroldi</a>, 
<a href="/search/cs?searchtype=author&query=Ghari%2C+M">Meghdad Ghari</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+E">Eveline Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+T">Thomas Studer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16108" title="Abstract">arXiv:2309.16108</a> (replaced) [<a href="/pdf/2309.16108" title="Download PDF">pdf</a>, <a href="/format/2309.16108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yujia Bao</a>, 
<a href="/search/cs?searchtype=author&query=Sivanandan%2C+S">Srinivasan Sivanandan</a>, 
<a href="/search/cs?searchtype=author&query=Karaletsos%2C+T">Theofanis Karaletsos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16709" title="Abstract">arXiv:2309.16709</a> (replaced) [<a href="/pdf/2309.16709" title="Download PDF">pdf</a>, <a href="/format/2309.16709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Task Offloading and Resource Allocation in Aerial-Terrestrial UAV  Networks with Edge and Fog Computing for Post-Disaster Rescue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+G">Geng Sun</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+L">Long He</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zemin Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+S">Shuang Liang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jiahui Li</a>, 
<a href="/search/eess?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/eess?searchtype=author&query=Leung%2C+V+C+M">Victor C. M. Leung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Science and Game Theory (cs.GT); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17100" title="Abstract">arXiv:2309.17100</a> (replaced) [<a href="/pdf/2309.17100" title="Download PDF">pdf</a>, <a href="/format/2309.17100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Logs into Lumber: Preprocessing Tasks in Process Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dani%2C+V+S">Vinicius Stein Dani</a>, 
<a href="/search/cs?searchtype=author&query=Beerepoot%2C+I">Iris Beerepoot</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xixi Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EdbA'23 workshop, co-located with ICPM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17255" title="Abstract">arXiv:2309.17255</a> (replaced) [<a href="/pdf/2309.17255" title="Download PDF">pdf</a>, <a href="/format/2309.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs for the Life Sciences: Recent Developments, Challenges  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hastings%2C+J">Janna Hastings</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-Ruiz%2C+E">Ernesto Jim&#xe9;nez-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+V">Vanessa L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Pesquita%2C+C">Catia Pesquita</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0koda%2C+P">Petr &#x160;koda</a>, 
<a href="/search/cs?searchtype=author&query=Tamma%2C+V">Valentina Tamma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 1 figure, accepted for Transactions on Graph Data and Knowledge (TGDK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17277" title="Abstract">arXiv:2309.17277</a> (replaced) [<a href="/pdf/2309.17277" title="Download PDF">pdf</a>, <a href="/format/2309.17277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind  Aware GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaxian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+P">Paul Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Iwasawa%2C+Y">Yusuke Iwasawa</a>, 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+Y">Yutaka Matsuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00100" title="Abstract">arXiv:2310.00100</a> (replaced) [<a href="/pdf/2310.00100" title="Download PDF">pdf</a>, <a href="/format/2310.00100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Natural Language Processing Model for Radiology Reports --  The Summary is all you need!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindo%2C+M">Mariana Lindo</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+A+S">Ana Sofia Santos</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+A">Andr&#xe9; Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Luijten%2C+G">Gijs Luijten</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+G">Gustavo Correia</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Moon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+V">Victor Alves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00177" title="Abstract">arXiv:2310.00177</a> (replaced) [<a href="/pdf/2310.00177" title="Download PDF">pdf</a>, <a href="/format/2310.00177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural-preconditioned Poisson Solver for Mixed Dirichlet and Neumann  Boundary Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lan%2C+W">Weixian Lan</a>, 
<a href="/search/math?searchtype=author&query=Gueidon%2C+E">Elias Gueidon</a>, 
<a href="/search/math?searchtype=author&query=Kaneda%2C+A">Ayano Kaneda</a>, 
<a href="/search/math?searchtype=author&query=Panetta%2C+J">Julian Panetta</a>, 
<a href="/search/math?searchtype=author&query=Teran%2C+J">Joseph Teran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00516" title="Abstract">arXiv:2310.00516</a> (replaced) [<a href="/pdf/2310.00516" title="Download PDF">pdf</a>, <a href="/format/2310.00516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Efficiency and Privacy in Memory-Based Malware Classification  through Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sazzed%2C+S">Salim Sazzed</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+S">Sharif Ullah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE ICMLA-2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00558" title="Abstract">arXiv:2310.00558</a> (replaced) [<a href="/pdf/2310.00558" title="Download PDF">pdf</a>, <a href="/format/2310.00558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diving into the Depths of Spotting Text in Multi-Domain Noisy Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Alloy Das</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Sanket Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+U">Umapada Pal</a>, 
<a href="/search/cs?searchtype=author&query=Llad%C3%B3s%2C+J">Josep Llad&#xf3;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 images
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00704" title="Abstract">arXiv:2310.00704</a> (replaced) [<a href="/pdf/2310.00704" title="Download PDF">pdf</a>, <a href="/format/2310.00704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniAudio: An Audio Foundation Model Toward Universal Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00763" title="Abstract">arXiv:2310.00763</a> (replaced) [<a href="/pdf/2310.00763" title="Download PDF">pdf</a>, <a href="/format/2310.00763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Efficient Power Flow Learning for Network Contingencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pareek%2C+P">Parikshit Pareek</a>, 
<a href="/search/cs?searchtype=author&query=Deka%2C+D">Deepjyoti Deka</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+S">Sidhant Misra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00771" title="Abstract">arXiv:2310.00771</a> (replaced) [<a href="/pdf/2310.00771" title="Download PDF">pdf</a>, <a href="/format/2310.00771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training with Synthetic Data Helps Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zixuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+K">Keith Ross</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00785" title="Abstract">arXiv:2310.00785</a> (replaced) [<a href="/pdf/2310.00785" title="Download PDF">pdf</a>, <a href="/format/2310.00785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BooookScore: A systematic exploration of book-length summarization in  the era of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yapei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+T">Tanya Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Iyyer%2C+M">Mohit Iyyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00898" title="Abstract">arXiv:2310.00898</a> (replaced) [<a href="/pdf/2310.00898" title="Download PDF">pdf</a>, <a href="/format/2310.00898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enable Language Models to Implicitly Learn Self-Improvement From Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Le Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tianjian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuexin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00917" title="Abstract">arXiv:2310.00917</a> (replaced) [<a href="/pdf/2310.00917" title="Download PDF">pdf</a>, <a href="/format/2310.00917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Multi-Lingual Datasets for Pre-training: Towards  Enhancing Text Spotting Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Alloy Das</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Sanket Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Ayan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Saumik Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Llad%C3%B3s%2C+J">Josep Llad&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+U">Umapada Pal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01057" title="Abstract">arXiv:2310.01057</a> (replaced) [<a href="/pdf/2310.01057" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in Optimization: Adaptive Differential Evolution with  Diversification Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01320" title="Abstract">arXiv:2310.01320</a> (replaced) [<a href="/pdf/2310.01320" title="Download PDF">pdf</a>, <a href="/format/2310.01320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Avalon&#x27;s Game of Thoughts: Battle Against Deception through Recursive  Contemplation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zilong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Siyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qisen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Andrew Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02086" title="Abstract">arXiv:2310.02086</a> (replaced) [<a href="/pdf/2310.02086" title="Download PDF">pdf</a>, <a href="/format/2310.02086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bearing-Based Target Entrapping Control of Multiple Uncertain Agents  With Arbitrary Maneuvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Su%2C+H">Haifan Su</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Ziwen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+S">Shanying Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Cailian Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wenbin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, the paper has been accepted by IFAC WC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02107" title="Abstract">arXiv:2310.02107</a> (replaced) [<a href="/pdf/2310.02107" title="Download PDF">pdf</a>, <a href="/format/2310.02107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance Needs More Care: Rewriting Prompts for Instances Yields Better  Zero-Shot Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Saurabh Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengyue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Weiguo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Ziyu Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02134" title="Abstract">arXiv:2310.02134</a> (replaced) [<a href="/pdf/2310.02134" title="Download PDF">pdf</a>, <a href="/format/2310.02134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error estimates for the robust $&#x3b1;$-stable central limit theorem  under sublinear expectation by discrete approximation method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+L">Lianzi Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02239" title="Abstract">arXiv:2310.02239</a> (replaced) [<a href="/pdf/2310.02239" title="Download PDF">pdf</a>, <a href="/format/2310.02239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniGPT-5: Interleaved Vision-and-Language Generation via Generative  Vokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaizhi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuehai He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X+E">Xin Eric Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02373" title="Abstract">arXiv:2310.02373</a> (replaced) [<a href="/pdf/2310.02373" title="Download PDF">pdf</a>, <a href="/format/2310.02373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Effective Data Appraisal for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+X">Xu Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yangfeng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02492" title="Abstract">arXiv:2310.02492</a> (replaced) [<a href="/pdf/2310.02492" title="Download PDF">pdf</a>, <a href="/format/2310.02492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harvard Eye Fairness: A Large-Scale 3D Imaging Dataset for Equitable Eye  Diseases Screening and Fair Identity Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Min Shi</a>, 
<a href="/search/cs?searchtype=author&query=Elze%2C+T">Tobias Elze</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02520" title="Abstract">arXiv:2310.02520</a> (replaced) [<a href="/pdf/2310.02520" title="Download PDF">pdf</a>, <a href="/format/2310.02520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedDiffusion: Boosting Health Risk Prediction via Diffusion-based Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Suhan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Ziyi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Houping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+M">Mengdi Huai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02687" title="Abstract">arXiv:2310.02687</a> (replaced) [<a href="/pdf/2310.02687" title="Download PDF">pdf</a>, <a href="/format/2310.02687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Moyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lingzhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Bangyan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peidong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02799" title="Abstract">arXiv:2310.02799</a> (replaced) [<a href="/pdf/2310.02799" title="Download PDF">pdf</a>, <a href="/format/2310.02799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting Smart Contract Languages: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soud%2C+M">Majd Soud</a>, 
<a href="/search/cs?searchtype=author&query=Hj%C3%A1lmt%C3%BDsson%2C+G">G&#xed;sli Hj&#xe1;lmt&#xfd;sson</a>, 
<a href="/search/cs?searchtype=author&query=Hamdaqa%2C+M">Mohammad Hamdaqa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02842" title="Abstract">arXiv:2310.02842</a> (replaced) [<a href="/pdf/2310.02842" title="Download PDF">pdf</a>, <a href="/format/2310.02842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dun%2C+C">Chen Dun</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+M+H">Mirian Hipolito Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Awadallah%2C+A+H">Ahmed Hassan Awadallah</a>, 
<a href="/search/cs?searchtype=author&query=Kyrillidis%2C+A">Anastasios Kyrillidis</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+R">Robert Sim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03022" title="Abstract">arXiv:2310.03022</a> (replaced) [<a href="/pdf/2310.03022" title="Download PDF">pdf</a>, <a href="/format/2310.03022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for  Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeonghye Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Woojun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+Y">Youngchul Sung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03030" title="Abstract">arXiv:2310.03030</a> (replaced) [<a href="/pdf/2310.03030" title="Download PDF">pdf</a>, <a href="/format/2310.03030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-MolBERTa: GPT Molecular Features Language Model for molecular  property prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Balaji%2C+S">Suryanarayanan Balaji</a>, 
<a href="/search/physics?searchtype=author&query=Magar%2C+R">Rishikesh Magar</a>, 
<a href="/search/physics?searchtype=author&query=Jadhav%2C+Y">Yayati Jadhav</a>, 
<a href="/search/physics?searchtype=author&query=Farimani%2C+a+A+B">and Amir Barati Farimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper has 17 pages, 4 figures and 4 tables, along with 71 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03149" title="Abstract">arXiv:2310.03149</a> (replaced) [<a href="/pdf/2310.03149" title="Download PDF">pdf</a>, <a href="/format/2310.03149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attributing Learned Concepts in Neural Networks to Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konz%2C+N">Nicholas Konz</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+C">Charles Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+M">Madelyn Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Jonathan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D">Davis Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03156" title="Abstract">arXiv:2310.03156</a> (replaced) [<a href="/pdf/2310.03156" title="Download PDF">pdf</a>, <a href="/format/2310.03156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedHyper: A Universal and Robust Learning Rate Scheduler for Federated  Learning with Hypergradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03205" title="Abstract">arXiv:2310.03205</a> (replaced) [<a href="/pdf/2310.03205" title="Download PDF">pdf</a>, <a href="/format/2310.03205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youwang%2C+K">Kim Youwang</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+L">Lee Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Sung-Bin%2C+K">Kim Sung-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Suekyeong Nam</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+J">Janghoon Ju</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, and 3 tables for the main paper. 8 pages, 6 figures and 3 tables for the appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03281" title="Abstract">arXiv:2310.03281</a> (replaced) [<a href="/e-print/2310.03281" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 5&#x27; UTR Language Model for Decoding Untranslated Regions of mRNA and  Function Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y">Yanyi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yupeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+L">Le Cong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jason Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Sorry for withdrawing this manuscript. Because we want to major revised this manuscript, and it need some time
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03304" title="Abstract">arXiv:2310.03304</a> (replaced) [<a href="/pdf/2310.03304" title="Download PDF">pdf</a>, <a href="/format/2310.03304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Personalized Story Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kevin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanlin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Andrew Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03443" title="Abstract">arXiv:2310.03443</a> (replaced) [<a href="/pdf/2310.03443" title="Download PDF">pdf</a>, <a href="/ps/2310.03443" title="Download PostScript">ps</a>, <a href="/format/2310.03443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The North System for Formosa Speech Recognition Challenge 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li-Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kai-Chen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-Shin Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03528" title="Abstract">arXiv:2310.03528</a> (replaced) [<a href="/pdf/2310.03528" title="Download PDF">pdf</a>, <a href="/ps/2310.03528" title="Download PostScript">ps</a>, <a href="/format/2310.03528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best-Response Dynamics in Tullock Contests with Convex Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Abheek Ghosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages. WINE '23 version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03559" title="Abstract">arXiv:2310.03559</a> (replaced) [<a href="/pdf/2310.03559" title="Download PDF">pdf</a>, <a href="/format/2310.03559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedSyn: Text-guided Anatomy-aware Synthesis of High-Fidelity 3D CT  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+L">Li Sun</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+W">Wei Peng</a>, 
<a href="/search/eess?searchtype=author&query=Visweswaran%2C+S">Shyam Visweswaran</a>, 
<a href="/search/eess?searchtype=author&query=Batmanghelich%2C+K">Kayhan Batmanghelich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03574" title="Abstract">arXiv:2310.03574</a> (replaced) [<a href="/pdf/2310.03574" title="Download PDF">pdf</a>, <a href="/ps/2310.03574" title="Download PostScript">ps</a>, <a href="/format/2310.03574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on a gap in the proof of the minimum distance for Projective  Reed-Muller Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%B8rensen%2C+A+B">Anders Bj&#xe6;rt S&#xf8;rensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03605" title="Abstract">arXiv:2310.03605</a> (replaced) [<a href="/pdf/2310.03605" title="Download PDF">pdf</a>, <a href="/format/2310.03605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FASER: Binary Code Similarity Search through the use of Intermediate  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collyer%2C+J">Josh Collyer</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+T">Tim Watson</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+I">Iain Phillips</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, To be presented as Conference on Applied Machine Learning for Information Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03611" title="Abstract">arXiv:2310.03611</a> (replaced) [<a href="/pdf/2310.03611" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GENER: A Parallel Layer Deep Learning Network To Detect Gene-Gene  Interactions From Gene Expression Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fakhry%2C+A">Ahmed Fakhry</a>, 
<a href="/search/cs?searchtype=author&query=Khafagy%2C+R">Raneem Khafagy</a>, 
<a href="/search/cs?searchtype=author&query=Ludl%2C+A">Adriaan-Alexander Ludl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03668" title="Abstract">arXiv:2310.03668</a> (replaced) [<a href="/pdf/2310.03668" title="Download PDF">pdf</a>, <a href="/format/2310.03668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sainz%2C+O">Oscar Sainz</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Ferrero%2C+I">Iker Garc&#xed;a-Ferrero</a>, 
<a href="/search/cs?searchtype=author&query=Agerri%2C+R">Rodrigo Agerri</a>, 
<a href="/search/cs?searchtype=author&query=de+Lacalle%2C+O+L">Oier Lopez de Lacalle</a>, 
<a href="/search/cs?searchtype=author&query=Rigau%2C+G">German Rigau</a>, 
<a href="/search/cs?searchtype=author&query=Agirre%2C+E">Eneko Agirre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03736" title="Abstract">arXiv:2310.03736</a> (replaced) [<a href="/pdf/2310.03736" title="Download PDF">pdf</a>, <a href="/format/2310.03736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering Single-Crossing Preferences From Approval Ballots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Constantinescu%2C+A">Andrei Constantinescu</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in WINE'23; add acknowledgements, change formatting, minor corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item267">Cross-lists</a></li>
<li><a href="#item315">Replacements</a></li>
</ul>
<small>[ total of 491 entries:  <b>1-491</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2310">2310</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
